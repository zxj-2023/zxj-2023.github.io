<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="上机实验：决策树 任务1：分支节点的选择方法 现有一个数据集 weekend.txt，目标是根据一个人的特征来预测其周末是否出行。 所有特征均为二元特征，取值为 0 或 1，其中“status”（目标特征也是类别）表示用户的周末是否出行，1 表示出行，0 表示不出行，“marriageStatus”表示申请人是否已婚、“hasChild”表示申请人是否有小孩、“hasAppointme">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习——上机4——决策树">
<meta property="og:url" content="http://example.com/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/index.html">
<meta property="og:site_name" content="Zhang XiJun">
<meta property="og:description" content="上机实验：决策树 任务1：分支节点的选择方法 现有一个数据集 weekend.txt，目标是根据一个人的特征来预测其周末是否出行。 所有特征均为二元特征，取值为 0 或 1，其中“status”（目标特征也是类别）表示用户的周末是否出行，1 表示出行，0 表示不出行，“marriageStatus”表示申请人是否已婚、“hasChild”表示申请人是否有小孩、“hasAppointme">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc">
<meta property="og:image" content="http://example.com/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/main_7_1.svg">
<meta property="og:image" content="https://ai-studio-static-online.cdn.bcebos.com/f7c9f4d97660416b9ac354a1bcd6c87efcb7a0958cfa4579bf70a83d01ee64f7">
<meta property="og:image" content="https://ai-studio-static-online.cdn.bcebos.com/eb46fe19bf43414290f904042a511f25140e1908a2eb4c2e81c52450f1de68bd">
<meta property="article:published_time" content="2025-04-02T16:00:00.000Z">
<meta property="article:modified_time" content="2025-04-04T12:12:22.000Z">
<meta property="article:author" content="张熙浚">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="大学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc">


<link rel="canonical" href="http://example.com/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/","path":"2025/04/03/college/大二下/机器学习/上机/上机4——决策树/","title":"机器学习——上机4——决策树"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>机器学习——上机4——决策树 | Zhang XiJun</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Zhang XiJun</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">BLOGS</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-number">1.</span> <span class="nav-text">上机实验：决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A11%E5%88%86%E6%94%AF%E8%8A%82%E7%82%B9%E7%9A%84%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95"><span class="nav-number">1.1.</span> <span class="nav-text">任务1：分支节点的选择方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A12%E5%B8%B8%E8%A7%81%E7%9A%84%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95"><span class="nav-number">1.2.</span> <span class="nav-text">任务2：常见的决策树算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A13%E5%88%A9%E7%94%A8%E4%BB%BB%E5%8A%A11%E7%9A%84cal_infogain%E5%87%BD%E6%95%B0%E8%87%AA%E8%A1%8C%E5%AE%9E%E7%8E%B0id3%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95"><span class="nav-number">1.3.</span> <span class="nav-text">任务3：利用任务1的cal_infoGain函数自行实现ID3决策树算法</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="张熙浚"
      src="/images/zxjavatar.gif">
  <p class="site-author-name" itemprop="name">张熙浚</p>
  <div class="site-description" itemprop="description">zxj Blogs</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">177</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">64</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zxj-2023" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxj-2023" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=2902065320&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;2902065320&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener me" target="_blank"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zxj-2023.github.io/" title="https:&#x2F;&#x2F;zxj-2023.github.io" rel="noopener" target="_blank">Zhang XiJun</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org" rel="noopener" target="_blank">NexT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="机器学习——上机4——决策树 | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习——上机4——决策树
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-03 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-03T00:00:00+08:00">2025-04-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-04-04 20:12:22" itemprop="dateModified" datetime="2025-04-04T20:12:22+08:00">2025-04-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="本文总阅读量 far fa-eye 次"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="上机实验决策树">上机实验：决策树</h1>
<h2 id="任务1分支节点的选择方法">任务1：分支节点的选择方法</h2>
<p>现有一个数据集
weekend.txt，目标是根据一个人的特征来预测其周末是否出行。</p>
<p>所有特征均为二元特征，取值为 0 或
1，其中“status”（目标特征也是类别）表示用户的周末是否出行，1 表示出行，0
表示不出行，“marriageStatus”表示申请人是否已婚、“hasChild”表示申请人是否有小孩、“hasAppointment”表示申请人是否有约、“weather”表示天气是否晴朗。</p>
<p>已知信息熵和信息增益的公式为：</p>
<p><span class="math display">$$\text{Entropy}(D)=-\sum_{k=1}^{C}p_k
\cdot log_2(p_k)$$</span></p>
<p><span class="math display">$$\text{InfoGain}(D,
a)=\text{Entropy}(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|}
\cdot\text{Entropy}(D^v)$$</span></p>
<p>请完成以下三个内容：</p>
<ul>
<li><p>请自定义函数 cal_entropy(data,
feature_name)计算数据集data关于feature_name的信息熵。输入参数 data 为
DataFrame，feature_name 为目标特征(或类别)的名称；</p></li>
<li><p>请调用 cal_entropy() 函数计算决策树分支之前的信息熵，保存为
data_entropy；</p></li>
<li><p>请自定义函数 cal_infoGain(data, base_entropy) 计算 weekend.txt
中各个特征的信息增益，保存为列表 infogains，并选择信息增益最大的分支节点
best_feature。</p></li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入必要库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据（假设文件为tab分隔，包含特征和目标变量&#x27;status&#x27;）</span></span><br><span class="line">weekend_data = pd.read_table(<span class="string">&#x27;weekend.txt&#x27;</span>, sep=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义熵计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数（如：status特征中&quot;出门&quot;和&quot;不出门&quot;的数量）</span></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（注意：熵公式为负数求和）</span></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算初始信息熵（假设目标特征列为&#x27;status&#x27;）</span></span><br><span class="line">data_entropy = cal_entropy(weekend_data, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义信息增益计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 获取所有特征名称</span></span><br><span class="line">    feature_list.remove(<span class="string">&#x27;status&#x27;</span>)  <span class="comment"># 移除目标特征（避免计算自身）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布（如：天气特征的&quot;晴朗/下雨/阴天&quot;）</span></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历特征的每个取值</span></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line">            <span class="comment"># 获取特征取当前值的子集</span></span><br><span class="line">            subset = data[data[feature] == value]</span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算子集的熵并累加加权熵</span></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算信息增益（信息增益 = 基础熵 - 条件熵）</span></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到信息增益最大的特征</span></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大增益值</span></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 对应的最优特征名称</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"><span class="comment">## 执行信息增益计算</span></span><br><span class="line">infogains, best_feature = cal_infoGain(weekend_data, data_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 结果输出</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;各特征的信息增益：&#x27;</span>, infogains)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n信息增益最大的特征：&#x27;</span>, best_feature)</span><br></pre></td></tr></table></figure>
<pre><code>各特征的信息增益： [0.0076, 0.0076, 0.0322, 0.0868]</code></pre>
<p>​</p>
<pre><code>信息增益最大的特征： weather</code></pre>
<blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc"></p>
<h2 id="任务2常见的决策树算法">任务2：常见的决策树算法</h2>
<p>现在有一份有关商品销量的数据集product.csv，数据集的离散型特征信息如下：</p>
<table>
<thead>
<tr>
<th>特征名称</th>
<th>取值说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>天气</td>
<td>1：天气好；0：天气坏</td>
</tr>
<tr>
<td>是否周末</td>
<td>1：是；0：不是</td>
</tr>
<tr>
<td>是否有促销</td>
<td>1：有促销；0：没有促销</td>
</tr>
<tr>
<td>销量</td>
<td>1：销量高；0：销量低</td>
</tr>
</tbody>
</table>
<p>请完成以下三个内容： - 请根据提供的商品销量数据集 data，使用 sklearn
中的
DecisionTreeClassifier()函数构建决策树模型，模型选择分支结点的特征以Gini指数为判定准则；
- 训练模型，并对测试集test_X进行预测，将预测结果存为
pred_y，进行模型评估； - 将构建的决策树模型进行可视化。</p>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz  <span class="comment"># 补全export_graphviz导入</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;product.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取除目标特征以外的其他特征的数据记录X</span></span><br><span class="line">X = data[[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>]]  <span class="comment"># 使用双括号选择多列</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取目标特征`销量`的数据记录y</span></span><br><span class="line">y = data[<span class="string">&quot;销量&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用train_test_split函数划分训练集train_X, train_y和测试集test_X, test_y</span></span><br><span class="line"><span class="comment">## 测试集所占比例为0.1,random_state为0</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 构建分支节点选择方法为基尼指数的决策树模型tree_model，进行模型训练、测试与性能评估</span></span><br><span class="line">tree_model = DecisionTreeClassifier(criterion=<span class="string">&#x27;gini&#x27;</span>)  <span class="comment"># 设置基尼指数准则</span></span><br><span class="line">tree_model.fit(train_X, train_y)  <span class="comment"># 模型训练</span></span><br><span class="line"></span><br><span class="line">pred_y = tree_model.predict(test_X)  <span class="comment"># 测试集预测</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型分类报告：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y))  <span class="comment"># 输出评估报告</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 决策树可视化（修正特征名称与数据列一致）</span></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line">dot_data = export_graphviz(</span><br><span class="line">    tree_model,</span><br><span class="line">    out_file=<span class="literal">None</span>,</span><br><span class="line">    feature_names=[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>],  <span class="comment"># 修正为完整特征名称</span></span><br><span class="line">    class_names=[<span class="string">&quot;销量低&quot;</span>, <span class="string">&quot;销量高&quot;</span>],</span><br><span class="line">    filled=<span class="literal">True</span>,</span><br><span class="line">    rounded=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph</span><br></pre></td></tr></table></figure>
<pre><code>模型分类报告：

              precision    recall  f1-score   support</code></pre>
<p>​</p>
<pre><code>           0       1.00      0.50      0.67         2

           1       0.67      1.00      0.80         2</code></pre>
<p>​</p>
<pre><code>    accuracy                           0.75         4

   macro avg       0.83      0.75      0.73         4

weighted avg       0.83      0.75      0.73         4</code></pre>
<p>​</p>
<p>​<br>
<img src="/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/main_7_1.svg" alt="svg"> ​</p>
<blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/f7c9f4d97660416b9ac354a1bcd6c87efcb7a0958cfa4579bf70a83d01ee64f7">
<img src="https://ai-studio-static-online.cdn.bcebos.com/eb46fe19bf43414290f904042a511f25140e1908a2eb4c2e81c52450f1de68bd"></p>
<h2 id="任务3利用任务1的cal_infogain函数自行实现id3决策树算法">任务3：利用任务1的cal_infoGain函数自行实现ID3决策树算法</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的熵计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line"></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数分布</span></span><br><span class="line"></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line"></span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（Σ -p_i log2(p_i)）</span></span><br><span class="line"></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的信息增益计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line"></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line"></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 所有特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自动识别目标特征（假设目标特征不在特征列表中）</span></span><br><span class="line"></span><br><span class="line">    target_feature = [col <span class="keyword">for</span> col <span class="keyword">in</span> feature_list <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> data.columns][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    feature_list = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]  <span class="comment"># 移除目标特征</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line"></span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布</span></span><br><span class="line"></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line"></span><br><span class="line">            subset = data[data[feature] == value]  <span class="comment"># 特征取当前值的子集</span></span><br><span class="line"></span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line"></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 累加加权熵</span></span><br><span class="line"></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, target_feature)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算信息增益</span></span><br><span class="line"></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line"></span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 选择最优特征</span></span><br><span class="line"></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大信息增益值</span></span><br><span class="line"></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line"></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 最优特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## ID3决策树实现</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ID3DecisionTree</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="literal">None</span>  <span class="comment"># 存储决策树结构</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = <span class="literal">None</span>  <span class="comment"># 目标特征名称</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, data, target_feature</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        训练决策树模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 包含特征和目标列的DataFrame</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param target_feature: 目标特征名称（如&#x27;销量&#x27;）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = target_feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取特征列表（排除目标特征）</span></span><br><span class="line"></span><br><span class="line">        features = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建决策树</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="variable language_">self</span>._build_tree(data, features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_tree</span>(<span class="params">self, data, features</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 当前节点的数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param features: 当前可用的特征列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 字典形式的树节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件1：所有样本属于同一类别</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(data[<span class="variable language_">self</span>.target].unique()) == <span class="number">1</span>:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: data[<span class="variable language_">self</span>.target].values[<span class="number">0</span>],  <span class="comment"># 叶节点类别</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件2：无剩余特征可用时选择多数类</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> features:</span><br><span class="line"></span><br><span class="line">            class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),  <span class="comment"># 多数类</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算当前数据集的熵</span></span><br><span class="line"></span><br><span class="line">        base_entropy = cal_entropy(data, <span class="variable language_">self</span>.target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取最优特征和信息增益列表</span></span><br><span class="line"></span><br><span class="line">        info_gains, best_feature = cal_infoGain(data, base_entropy)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建当前树节点</span></span><br><span class="line"></span><br><span class="line">        node = &#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;feature&#x27;</span>: best_feature,  <span class="comment"># 分裂特征</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;info_gain&#x27;</span>: info_gains[features.index(best_feature)],  <span class="comment"># 信息增益值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data),  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;children&#x27;</span>: &#123;&#125;  <span class="comment"># 子节点</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建子树（排除当前最优特征）</span></span><br><span class="line"></span><br><span class="line">        remaining_features = [f <span class="keyword">for</span> f <span class="keyword">in</span> features <span class="keyword">if</span> f != best_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历最优特征的所有取值</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> data[best_feature].unique():</span><br><span class="line"></span><br><span class="line">            subset = data[data[best_feature] == value]  <span class="comment"># 获取子集</span></span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 处理空子集（采用父节点多数类）</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> subset.empty:</span><br><span class="line"></span><br><span class="line">                class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;samples&#x27;</span>: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 递归构建子树</span></span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = <span class="variable language_">self</span>._build_tree(subset, remaining_features)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        对新样本进行预测</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param X: 特征数据（DataFrame格式）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 预测结果列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        predictions = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历每个样本</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _, sample <span class="keyword">in</span> X.iterrows():</span><br><span class="line"></span><br><span class="line">            current_node = <span class="variable language_">self</span>.tree</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 遍历树直到叶节点</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                feature = current_node[<span class="string">&#x27;feature&#x27;</span>]  <span class="comment"># 当前分裂特征</span></span><br><span class="line"></span><br><span class="line">                value = sample[feature]  <span class="comment"># 样本在该特征的取值</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 处理未见过的特征值（采用当前节点多数类）</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> value <span class="keyword">not</span> <span class="keyword">in</span> current_node[<span class="string">&#x27;children&#x27;</span>]:</span><br><span class="line"></span><br><span class="line">                    class_counts = <span class="variable language_">self</span>._get_class_counts(current_node)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 选择样本数最多的类别</span></span><br><span class="line"></span><br><span class="line">                    predictions.append(<span class="built_in">max</span>(class_counts, key=class_counts.get))</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">break</span>  <span class="comment"># 跳出循环</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 移动到子节点</span></span><br><span class="line"></span><br><span class="line">                current_node = current_node[<span class="string">&#x27;children&#x27;</span>][value]</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 记录叶节点类别</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                predictions.append(current_node[<span class="string">&#x27;class&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_class_counts</span>(<span class="params">self, node</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归统计节点中的类别分布</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 类别计数字典</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        counts = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果是叶节点直接返回</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;node[<span class="string">&#x27;class&#x27;</span>]: node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归统计子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].values():</span><br><span class="line"></span><br><span class="line">            child_counts = <span class="variable language_">self</span>._get_class_counts(child)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> cls, cnt <span class="keyword">in</span> child_counts.items():</span><br><span class="line"></span><br><span class="line">                counts[cls] = counts.get(cls, <span class="number">0</span>) + cnt</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> counts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">visualize</span>(<span class="params">self, feature_names, class_names</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        可视化决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: graphviz对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        dot = graphviz.Digraph()  <span class="comment"># 创建有向图</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建图形</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._build_graph(dot, <span class="variable language_">self</span>.tree, feature_names, class_names)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_graph</span>(<span class="params">self, dot, node, feature_names, class_names, parent=<span class="literal">None</span>, edge_label=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建graphviz图形</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param dot: graphviz.Digraph对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param parent: 父节点（用于连接边）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param edge_label: 边标签（特征取值）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 叶节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;class_names[<span class="built_in">int</span>(node[<span class="string">&#x27;class&#x27;</span>])]&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),  <span class="comment"># 唯一节点ID</span></span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;box&quot;</span>,  <span class="comment"># 矩形框</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,  <span class="comment"># 填充颜色</span></span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightblue&quot;</span>  <span class="comment"># 浅蓝色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 内部节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;node[<span class="string">&#x27;feature&#x27;</span>]&#125;</span>\\nIG=<span class="subst">&#123;node[<span class="string">&#x27;info_gain&#x27;</span>]:<span class="number">.3</span>f&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;ellipse&quot;</span>,  <span class="comment"># 椭圆</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,</span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightgreen&quot;</span>  <span class="comment"># 浅绿色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建父节点到当前节点的边</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> parent:</span><br><span class="line"></span><br><span class="line">            dot.edge(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(parent)),</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label=edge_label  <span class="comment"># 显示特征取值</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归处理子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> value, child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].items():</span><br><span class="line"></span><br><span class="line">                <span class="variable language_">self</span>._build_graph(</span><br><span class="line"></span><br><span class="line">                    dot,</span><br><span class="line"></span><br><span class="line">                    child,</span><br><span class="line"></span><br><span class="line">                    feature_names,</span><br><span class="line"></span><br><span class="line">                    class_names,</span><br><span class="line"></span><br><span class="line">                    node,  <span class="comment"># 当前节点作为父节点</span></span><br><span class="line"></span><br><span class="line">                    <span class="built_in">str</span>(value)  <span class="comment"># 边标签为特征取值</span></span><br><span class="line"></span><br><span class="line">                )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>请我一杯咖啡吧！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.png" alt="张熙浚 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipay.png" alt="张熙浚 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/%E5%A4%A7%E5%AD%A6/" rel="tag"># 大学</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A1/" rel="prev" title="计算机系统基础——上机作业1">
                  <i class="fa fa-angle-left"></i> 计算机系统基础——上机作业1
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="next" title="机器学习——神经网络">
                  机器学习——神经网络 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">张熙浚</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="本站访问数 fa fa-user 次"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="本站总访问量 fa fa-eye 次"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="400" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.9.0/mermaid.min.js","integrity":"sha256-stuqcu2FrjYCXDOytWFA5SoUE/r3nkp6gTglzNSlavU="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>



  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
