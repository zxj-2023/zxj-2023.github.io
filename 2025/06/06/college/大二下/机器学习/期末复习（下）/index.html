<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="期末复习方差与偏差方差（Variance）和偏差（Bias）是机器学习中衡量模型性能的两个核心概念，它们共同构成了偏差-方差权衡（Bias-Variance Tradeoff）的基础框架。以下是两者的定义与区别： 1. 偏差（Bias）  定义：偏差是指模型预测的期望值与真实值之间的差异。它反映了模型本身的拟合能力，即是否能够准确捕捉数据中的规律。  2. 方差（Variance）  定义：方差是">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习——期末复习（下）">
<meta property="og:url" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/index.html">
<meta property="og:site_name" content="Zhang XiJun">
<meta property="og:description" content="期末复习方差与偏差方差（Variance）和偏差（Bias）是机器学习中衡量模型性能的两个核心概念，它们共同构成了偏差-方差权衡（Bias-Variance Tradeoff）的基础框架。以下是两者的定义与区别： 1. 偏差（Bias）  定义：偏差是指模型预测的期望值与真实值之间的差异。它反映了模型本身的拟合能力，即是否能够准确捕捉数据中的规律。  2. 方差（Variance）  定义：方差是">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250605223036362.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143758565.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143819352.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150830535.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150906475.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606154731476.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606155939884.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606172851748.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606175536310.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606182733022.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606184958951.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606195241433.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607110103570.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607114743211.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250611180451162.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124326529.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124446432.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125338029.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125506436.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125606040.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607150256290.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607155733314.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607165159235.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607170020467.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171119645.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171258284.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607175825520.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607181345721.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183201926.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183349866.png">
<meta property="og:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607184534217.png">
<meta property="article:published_time" content="2025-06-05T16:00:00.000Z">
<meta property="article:modified_time" content="2025-06-22T11:53:19.060Z">
<meta property="article:author" content="张熙浚">
<meta property="article:tag" content="大学">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250605223036362.png">


<link rel="canonical" href="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/","path":"2025/06/06/college/大二下/机器学习/期末复习（下）/","title":"机器学习——期末复习（下）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>机器学习——期末复习（下） | Zhang XiJun</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Zhang XiJun</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">BLOGS</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0"><span class="nav-number">1.</span> <span class="nav-text">期末复习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E5%B7%AE%E4%B8%8E%E5%81%8F%E5%B7%AE"><span class="nav-number">1.1.</span> <span class="nav-text">方差与偏差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.2.</span> <span class="nav-text">监督学习与无监督学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB"><span class="nav-number">1.3.</span> <span class="nav-text">贝叶斯分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">1.3.1.</span> <span class="nav-text">贝叶斯分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E8%AE%BA"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">贝叶斯决策论</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E8%A7%84%E5%88%99"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">贝叶斯决策规则</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%89%B9%E6%AE%8A%E6%83%85%E5%86%B5%EF%BC%9A0-1-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">1.3.1.3.</span> <span class="nav-text">特殊情况：0-1 损失函数</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E4%B8%8E%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87"><span class="nav-number">1.3.2.</span> <span class="nav-text">后验概率与先验概率</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">后验概率</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%EF%BC%88Prior-Probability%EF%BC%89"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">先验概率（Prior Probability）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.3.3.</span> <span class="nav-text">生成式模型和判别式模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E5%8C%BA%E5%88%AB"><span class="nav-number">1.3.3.1.</span> <span class="nav-text">核心区别</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AF%A6%E7%BB%86%E8%A7%A3%E9%87%8A"><span class="nav-number">1.3.3.2.</span> <span class="nav-text">详细解释</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%EF%BC%9A%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="nav-number">1.3.3.3.</span> <span class="nav-text">示例：二分类问题</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BB%BA%E6%A8%A1%E6%80%9D%E8%B7%AF"><span class="nav-number">1.3.4.</span> <span class="nav-text">生成式模型的建模思路</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">1.3.5.</span> <span class="nav-text">朴素贝叶斯分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B1%9E%E6%80%A7%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B%E6%80%A7%E5%81%87%E8%AE%BE"><span class="nav-number">1.3.5.1.</span> <span class="nav-text">属性条件独立性假设</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%BA%E4%BD%95%E5%8F%AF%E4%BB%A5%E5%BF%BD%E7%95%A5-P-mathbf-x"><span class="nav-number">1.3.5.2.</span> <span class="nav-text">为何可以忽略 $ P(\mathbf{x}) $?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%9A%84%E6%9C%80%E7%BB%88%E5%86%B3%E7%AD%96%E8%A7%84%E5%88%99"><span class="nav-number">1.3.5.3.</span> <span class="nav-text">朴素贝叶斯的最终决策规则</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%B1%BB%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87-P-c-%E7%9A%84%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95"><span class="nav-number">1.3.5.4.</span> <span class="nav-text">类先验概率 $ P(c) $ 的估计方法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87-P-x-i-c-%E7%9A%84%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95"><span class="nav-number">1.3.5.5.</span> <span class="nav-text">条件概率 $ P(x_i | c) $ 的估计方法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%8A%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-number">1.3.6.</span> <span class="nav-text">半朴素贝叶斯分类器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%8B%AC%E4%BE%9D%E8%B5%96%E4%BC%B0%E8%AE%A1%EF%BC%88ODE%EF%BC%89%E6%96%B9%E6%B3%95"><span class="nav-number">1.3.6.1.</span> <span class="nav-text">独依赖估计（ODE）方法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%B6%85%E7%88%B6%E7%8B%AC%E4%BE%9D%E8%B5%96%E4%BC%B0%E8%AE%A1%EF%BC%88SPODE%EF%BC%89"><span class="nav-number">1.3.6.2.</span> <span class="nav-text">超父独依赖估计（SPODE）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A0%91%E5%A2%9E%E5%BC%BA%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%EF%BC%88TAN-Tree-Augmented-Naive-Bayes%EF%BC%89"><span class="nav-number">1.3.6.3.</span> <span class="nav-text">树增强朴素贝叶斯（TAN: Tree-Augmented Naive Bayes）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91"><span class="nav-number">1.3.7.</span> <span class="nav-text">贝叶斯网</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#EM%E7%AE%97%E6%B3%95"><span class="nav-number">1.3.8.</span> <span class="nav-text">EM算法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3%EF%BC%9A%E8%A7%A3%E5%86%B3%E9%9A%90%E5%8F%98%E9%87%8F%E9%97%AE%E9%A2%98"><span class="nav-number">1.3.8.1.</span> <span class="nav-text">1. 核心思想：解决隐变量问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-number">1.3.8.2.</span> <span class="nav-text">2. 算法流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E7%A4%BA%E4%BE%8B%EF%BC%9A%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B%EF%BC%88GMM%EF%BC%89"><span class="nav-number">1.3.8.3.</span> <span class="nav-text">3. 示例：混合高斯模型（GMM）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%9C%E4%B8%9A"><span class="nav-number">1.3.9.</span> <span class="nav-text">作业</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1"><span class="nav-number">1.3.9.1.</span> <span class="nav-text">1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2"><span class="nav-number">1.3.9.2.</span> <span class="nav-text">2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3"><span class="nav-number">1.3.9.3.</span> <span class="nav-text">3</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#EM%E7%AE%97%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86"><span class="nav-number">1.3.9.3.1.</span> <span class="nav-text">EM算法的原理</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#EM%E7%AE%97%E6%B3%95%E5%AF%B9GMM%E7%9A%84%E5%85%B7%E4%BD%93%E6%B1%82%E8%A7%A3%E8%BF%87%E7%A8%8B"><span class="nav-number">1.3.9.3.2.</span> <span class="nav-text">EM算法对GMM的具体求解过程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">1.3.10.</span> <span class="nav-text">参考资料</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.4.</span> <span class="nav-text">集成学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%AA%E4%BD%93%E4%B8%8E%E9%9B%86%E6%88%90"><span class="nav-number">1.4.1.</span> <span class="nav-text">个体与集成</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">集成学习的基本概念</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%8A%95%E7%A5%A8%E6%B3%95%E7%9A%84%E9%9B%86%E6%88%90%E4%B8%AA%E4%BD%93%E5%AD%A6%E4%B9%A0%E5%99%A8%E7%9A%84%E6%94%B6%E6%95%9B%E6%80%A7%E4%BF%9D%E8%AF%81%EF%BC%9A"><span class="nav-number">1.4.1.2.</span> <span class="nav-text">基于投票法的集成个体学习器的收敛性保证：</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Boosting"><span class="nav-number">1.4.2.</span> <span class="nav-text">Boosting</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#AdaBoost"><span class="nav-number">1.4.2.1.</span> <span class="nav-text">AdaBoost</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%85%AC%E5%BC%8F%E8%A7%A3%E6%9E%90"><span class="nav-number">1.4.2.2.</span> <span class="nav-text">公式解析</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AdaBoost%E7%9A%84%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="nav-number">1.4.2.3.</span> <span class="nav-text">AdaBoost的优化目标</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%EF%BC%9A%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98-1"><span class="nav-number">1.4.2.4.</span> <span class="nav-text">示例：二分类问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#AdaBoost%E7%9A%84%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-number">1.4.2.5.</span> <span class="nav-text">AdaBoost的算法流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%87%8D%E8%B5%8B%E6%9D%83%E6%B3%95%E4%B8%8E%E9%87%8D%E9%87%87%E6%A0%B7%E6%B3%95"><span class="nav-number">1.4.2.6.</span> <span class="nav-text">重赋权法与重采样法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8B%93%E5%B1%95%EF%BC%9AGradient-Boosting"><span class="nav-number">1.4.2.7.</span> <span class="nav-text">拓展：Gradient Boosting</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#GBDT%EF%BC%88Gradient-Boosting-Decision-Tree%EF%BC%89%E4%B8%8EXGBoost"><span class="nav-number">1.4.2.7.1.</span> <span class="nav-text">GBDT（Gradient Boosting Decision Tree）与XGBoost</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Bagging"><span class="nav-number">1.4.3.</span> <span class="nav-text">Bagging</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Bagging%E4%B8%8EBoosting%E7%9A%84%E5%B7%AE%E5%BC%82"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">Bagging与Boosting的差异</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Bagging%E7%9A%84%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-number">1.4.3.2.</span> <span class="nav-text">Bagging的算法流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%87%AA%E5%8A%A9%E9%87%87%E6%A0%B7%E6%B3%95%EF%BC%88Bootstrap-Sampling%EF%BC%89"><span class="nav-number">1.4.3.3.</span> <span class="nav-text">自助采样法（Bootstrap Sampling）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="nav-number">1.4.3.4.</span> <span class="nav-text">随机森林</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%93%E5%90%88%E7%AD%96%E7%95%A5"><span class="nav-number">1.4.4.</span> <span class="nav-text">结合策略</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E5%B9%B3%E5%9D%87%E6%B3%95%EF%BC%88%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%EF%BC%89"><span class="nav-number">1.4.4.1.</span> <span class="nav-text">1.平均法（回归问题）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E6%8A%95%E7%A5%A8%E6%B3%95%EF%BC%88%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%89"><span class="nav-number">1.4.4.2.</span> <span class="nav-text">2.投票法（分类问题）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E5%AD%A6%E4%B9%A0%E6%B3%95%EF%BC%88Stacking%EF%BC%89"><span class="nav-number">1.4.4.3.</span> <span class="nav-text">3.学习法（Stacking）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E6%A0%B7%E6%80%A7"><span class="nav-number">1.4.5.</span> <span class="nav-text">多样性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%9C%E4%B8%9A-1"><span class="nav-number">1.4.6.</span> <span class="nav-text">作业</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-1"><span class="nav-number">1.4.6.1.</span> <span class="nav-text">1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1"><span class="nav-number">1.4.6.2.</span> <span class="nav-text">2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-1"><span class="nav-number">1.4.6.3.</span> <span class="nav-text">3</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%81%9A%E7%B1%BB"><span class="nav-number">1.5.</span> <span class="nav-text">聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E7%B1%BB%E4%BB%BB%E5%8A%A1"><span class="nav-number">1.5.1.</span> <span class="nav-text">聚类任务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F"><span class="nav-number">1.5.2.</span> <span class="nav-text">距离度量</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BF%9E%E7%BB%AD-%E7%A6%BB%E6%95%A3%E6%9C%89%E5%BA%8F"><span class="nav-number">1.5.2.1.</span> <span class="nav-text">连续&#x2F;离散有序</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A6%BB%E6%95%A3%E6%97%A0%E5%BA%8F"><span class="nav-number">1.5.2.2.</span> <span class="nav-text">离散无序</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"><span class="nav-number">1.5.3.</span> <span class="nav-text">性能度量</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A4%96%E9%83%A8%E6%8C%87%E6%A0%87"><span class="nav-number">1.5.3.1.</span> <span class="nav-text">外部指标</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%86%85%E9%83%A8%E6%8C%87%E6%A0%87"><span class="nav-number">1.5.3.2.</span> <span class="nav-text">内部指标</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8E%9F%E5%9E%8B%E8%81%9A%E7%B1%BB%E4%B8%8Ekmeans"><span class="nav-number">1.5.4.</span> <span class="nav-text">原型聚类与kmeans</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8E%9F%E5%9E%8B%E8%81%9A%E7%B1%BB"><span class="nav-number">1.5.4.1.</span> <span class="nav-text">原型聚类</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#K-Means-%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="nav-number">1.5.4.2.</span> <span class="nav-text">K-Means 聚类算法详解</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#K-Means%E7%9A%84%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-number">1.5.4.3.</span> <span class="nav-text">K-Means的算法流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#K-means"><span class="nav-number">1.5.4.4.</span> <span class="nav-text">K-means++</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BC%98%E5%8A%BF"><span class="nav-number">1.5.4.5.</span> <span class="nav-text">优势</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Bisecting-K-means"><span class="nav-number">1.5.4.6.</span> <span class="nav-text">Bisecting K-means</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BC%98%E5%8A%BF-1"><span class="nav-number">1.5.4.7.</span> <span class="nav-text">优势</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#LVQ%EF%BC%88%E5%AD%A6%E4%B9%A0%E5%90%91%E9%87%8F%E9%87%8F%E5%8C%96%EF%BC%89"><span class="nav-number">1.5.4.8.</span> <span class="nav-text">LVQ（学习向量量化）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E8%81%9A%E7%B1%BB%EF%BC%88Gaussian-Mixture-Model-GMM%EF%BC%89"><span class="nav-number">1.5.4.9.</span> <span class="nav-text">高斯混合聚类（Gaussian Mixture Model, GMM）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99-1"><span class="nav-number">1.5.5.</span> <span class="nav-text">参考资料</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%86%E5%BA%A6%E8%81%9A%E7%B1%BB%E4%B8%8EDBSCAN"><span class="nav-number">1.5.6.</span> <span class="nav-text">密度聚类与DBSCAN</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="nav-number">1.5.6.1.</span> <span class="nav-text">1. 核心概念</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-DBSCAN-%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-number">1.5.6.2.</span> <span class="nav-text">2. DBSCAN 算法流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E5%8F%82%E6%95%B0%E9%80%89%E6%8B%A9%E4%B8%8E%E5%BD%B1%E5%93%8D"><span class="nav-number">1.5.6.3.</span> <span class="nav-text">3. 参数选择与影响</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB%E4%B8%8EAGNES"><span class="nav-number">1.5.7.</span> <span class="nav-text">层次聚类与AGNES</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-AGNES-%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-number">1.5.7.1.</span> <span class="nav-text">1. AGNES 算法流程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E7%B0%87%E9%97%B4%E8%B7%9D%E7%A6%BB%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="nav-number">1.5.7.2.</span> <span class="nav-text">2. 簇间距离的定义</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB%E6%B3%95%E7%9A%84%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%A6%82%E4%B8%8B%E6%89%80%E7%A4%BA%EF%BC%9A"><span class="nav-number">1.5.7.3.</span> <span class="nav-text">层次聚类法的算法流程如下所示：</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%9C%E4%B8%9A-2"><span class="nav-number">1.5.8.</span> <span class="nav-text">作业</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2"><span class="nav-number">1.5.8.1.</span> <span class="nav-text">1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2"><span class="nav-number">1.5.8.2.</span> <span class="nav-text">2</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99-2"><span class="nav-number">1.5.9.</span> <span class="nav-text">参考资料</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.6.</span> <span class="nav-text">降维与度量学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#KNN"><span class="nav-number">1.6.1.</span> <span class="nav-text">KNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%8E%E7%BB%B4%E5%B5%8C%E5%85%A5"><span class="nav-number">1.6.2.</span> <span class="nav-text">低维嵌入</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MDS%E7%AE%97%E6%B3%95"><span class="nav-number">1.6.3.</span> <span class="nav-text">MDS算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95"><span class="nav-number">1.6.4.</span> <span class="nav-text">线性降维方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90"><span class="nav-number">1.6.5.</span> <span class="nav-text">主成分分析</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5%E4%B8%8E%E4%BC%98%E5%8C%96%E6%B1%82%E8%A7%A3"><span class="nav-number">1.6.5.1.</span> <span class="nav-text">协方差矩阵与优化求解</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#PCA%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC"><span class="nav-number">1.6.5.2.</span> <span class="nav-text">PCA的数学推导</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#PCA%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E9%80%89%E6%8B%A9"><span class="nav-number">1.6.5.3.</span> <span class="nav-text">PCA特征向量选择</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#PCA%E7%AE%97%E6%B3%95%E7%9A%84%E6%95%B4%E4%B8%AA%E6%B5%81%E7%A8%8B%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%EF%BC%9A"><span class="nav-number">1.6.5.4.</span> <span class="nav-text">PCA算法的整个流程如下图所示：</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%B8%E5%8C%96%E7%BA%BF%E6%80%A7%E9%99%8D%E7%BB%B4"><span class="nav-number">1.6.6.</span> <span class="nav-text">核化线性降维</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.6.7.</span> <span class="nav-text">流形学习</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AD%89%E5%BA%A6%E9%87%8F%E6%98%A0%E5%B0%84Isomap"><span class="nav-number">1.6.7.1.</span> <span class="nav-text">等度量映射Isomap</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E7%BA%BF%E6%80%A7%E5%B5%8C%E5%85%A5"><span class="nav-number">1.6.7.2.</span> <span class="nav-text">局部线性嵌入</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.6.8.</span> <span class="nav-text">度量学习</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#LMNN%EF%BC%88Large-Margin-Nearest-Neighbors%EF%BC%89%E8%AF%A6%E8%A7%A3"><span class="nav-number">1.6.8.1.</span> <span class="nav-text">LMNN（Large Margin Nearest Neighbors）详解</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%9C%E4%B8%9A-3"><span class="nav-number">1.6.9.</span> <span class="nav-text">作业</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-3"><span class="nav-number">1.6.9.1.</span> <span class="nav-text">1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3"><span class="nav-number">1.6.9.2.</span> <span class="nav-text">2</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.7.</span> <span class="nav-text">半监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%B9%E6%B3%95"><span class="nav-number">1.7.0.1.</span> <span class="nav-text">基于生成模型的方法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3SVM"><span class="nav-number">1.7.0.2.</span> <span class="nav-text">半监督SVM</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#TSVM-Transductive-Support-Vector-Machine"><span class="nav-number">1.7.0.2.1.</span> <span class="nav-text">TSVM(Transductive Support Vector Machine)</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9B%BE%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.7.0.3.</span> <span class="nav-text">图半监督学习</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%8F%E5%90%8C%E8%AE%AD%E7%BB%83"><span class="nav-number">1.7.1.</span> <span class="nav-text">协同训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%9C%E4%B8%9A-4"><span class="nav-number">1.7.2.</span> <span class="nav-text">作业</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-4"><span class="nav-number">1.7.2.1.</span> <span class="nav-text">1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-4"><span class="nav-number">1.7.2.2.</span> <span class="nav-text">2</span></a></li></ol></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="张熙浚"
      src="/images/zxjavatar.gif">
  <p class="site-author-name" itemprop="name">张熙浚</p>
  <div class="site-description" itemprop="description">zxj Blogs</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">127</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">47</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zxj-2023" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxj-2023" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=2902065320&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;2902065320&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener me" target="_blank"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zxj-2023.github.io/" title="https:&#x2F;&#x2F;zxj-2023.github.io" rel="noopener" target="_blank">Zhang XiJun</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org" rel="noopener" target="_blank">NexT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="机器学习——期末复习（下） | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习——期末复习（下）
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-06-06 00:00:00" itemprop="dateCreated datePublished" datetime="2025-06-06T00:00:00+08:00">2025-06-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-22 19:53:19" itemprop="dateModified" datetime="2025-06-22T19:53:19+08:00">2025-06-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="本文总阅读量 far fa-eye 次"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="期末复习"><a href="#期末复习" class="headerlink" title="期末复习"></a>期末复习</h2><h3 id="方差与偏差"><a href="#方差与偏差" class="headerlink" title="方差与偏差"></a>方差与偏差</h3><p>方差（Variance）和偏差（Bias）是机器学习中衡量模型性能的两个核心概念，它们共同构成了<strong>偏差-方差权衡</strong>（Bias-Variance Tradeoff）的基础框架。以下是两者的定义与区别：</p>
<p><strong>1. 偏差（Bias）</strong></p>
<ul>
<li><strong>定义</strong>：偏差是指模型预测的期望值与真实值之间的差异。它反映了模型本身的拟合能力，即是否能够准确捕捉数据中的规律。</li>
</ul>
<p><strong>2. 方差（Variance）</strong></p>
<ul>
<li><strong>定义</strong>：方差是指模型在不同训练数据集下预测结果的波动程度。它衡量了模型对训练数据中噪声或微小变化的敏感性。</li>
</ul>
<p><strong>3. 如何降低偏差与方差</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>目标</strong></th>
<th><strong>方法</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>降低偏差</strong></td>
<td>增加模型复杂度（如更多特征、更深的神经网络）、减少正则化强度</td>
<td>使用多项式回归替代线性回归</td>
</tr>
<tr>
<td><strong>降低方差</strong></td>
<td>增加训练数据、引入正则化（L1/L2）、使用集成方法（如 Bagging、Boosting）</td>
<td>随机森林（Bagging）降低决策树的方差</td>
</tr>
</tbody>
</table>
</div>
<p><strong>4. 总结</strong></p>
<ul>
<li><strong>偏差</strong>关注模型是否能准确拟合数据（<strong>学习能力</strong>），而<strong>方差</strong>关注模型对数据波动的稳定性（<strong>泛化能力</strong>）。</li>
<li>实际应用中需通过交叉验证、正则化或集成学习等技术平衡两者的关系。</li>
</ul>
<h3 id="监督学习与无监督学习"><a href="#监督学习与无监督学习" class="headerlink" title="监督学习与无监督学习"></a>监督学习与无监督学习</h3><p>以下是关于监督学习与无监督学习的核心区别总结：</p>
<p><strong>1. 监督学习（Supervised Learning）</strong></p>
<p><strong>任务类型</strong>：  </p>
<ul>
<li><strong>分类（Classification）</strong>：预测离散类别标签（如垃圾邮件/非垃圾邮件）。  </li>
<li><strong>回归（Regression）</strong>：预测连续数值标签（如房价预测）。  </li>
</ul>
<p><strong>特点</strong>：  </p>
<ul>
<li>需要<strong>带标签的样本</strong>（Labeled Data），即每个训练样本都有明确的输入 $ x $ 和输出 $ y $。  </li>
<li>模型通过学习输入与标签之间的映射关系进行预测。  </li>
</ul>
<p><strong>2. 无监督学习（Unsupervised Learning）</strong></p>
<p><strong>任务类型</strong>：  </p>
<ul>
<li><strong>聚类（Clustering）</strong>：将样本划分为具有相似特征的群体（如客户分群）。  </li>
<li><strong>降维（Dimensionality Reduction）</strong>：压缩数据维度同时保留关键信息（如PCA）。  </li>
</ul>
<p><strong>特点</strong>：  </p>
<ul>
<li>仅需<strong>无标签的样本</strong>（Unlabeled Data），无需预先定义输出目标。  </li>
<li>模型自主挖掘数据内在结构或分布规律。  </li>
</ul>
<h3 id="贝叶斯分类"><a href="#贝叶斯分类" class="headerlink" title="贝叶斯分类"></a>贝叶斯分类</h3><h4 id="贝叶斯分类器"><a href="#贝叶斯分类器" class="headerlink" title="贝叶斯分类器"></a>贝叶斯分类器</h4><h5 id="贝叶斯决策论"><a href="#贝叶斯决策论" class="headerlink" title="贝叶斯决策论"></a>贝叶斯决策论</h5><p>本质思想：寻找合适的参数使得「当前的样本情况发生的概率」最大。</p>
<p>又由于假设每一个样本相互独立（概率条件理想的情况下），因此可以用连乘的形式表示上述概率，当然由于概率较小导致连乘容易出现浮点数精度损失，因此尝尝采用取对数的方式来避免「下溢」问题。也就是所谓的「对数似然估计」方法。</p>
<p>在已知样本特征 $ \mathbf{x} $ 的条件下，选择分类结果 $ c_i $，使得分类的期望损失（Risk）最小<strong>。</strong></p>
<p><strong>(1) 损失函数 $ \lambda_{ij} $</strong></p>
<ul>
<li><strong>定义</strong>：$ \lambda_{ij} $ 是将真实类别为 $ c_j $ 的样本误分类为 $ c_i $ 所产生的损失。<ul>
<li>例如：<ul>
<li>在医学诊断中，若 $ c_1 $ 表示“患病”，$ c_2 $ 表示“未患病”：<ul>
<li>$ \lambda_{21} $：将实际患病（$ c_1 $）误判为未患病（$ c_2 $）的损失（可能更高）。</li>
<li>$ \lambda_{12} $：将实际未患病（$ c_2 $）误判为患病（$ c_1 $）的损失（可能较低）。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>(2) 条件风险（单个样本的期望损失）</strong></p>
<p>对于给定样本 $ \mathbf{x} $，若将其分类为 $ c_i $，则其<strong>条件风险</strong>为：</p>
<script type="math/tex; mode=display">
R(c_i | \mathbf{x}) = \sum_{j=1}^N \lambda_{ij} P(c_j | \mathbf{x})</script><ul>
<li><strong>含义</strong>：在已知 $ \mathbf{x} $ 的情况下，分类为 $ c_i $ 的平均损失。</li>
<li><strong>推导</strong>：<ul>
<li>$ P(c_j | \mathbf{x}) $：样本 $ \mathbf{x} $ 真实属于 $ c_j $ 的后验概率。</li>
<li>$ \lambda<em>{ij} $：若真实类别是 $ c_j $，但被分到 $ c_i $，则产生损失 $ \lambda</em>{ij} $。</li>
<li>因此，总期望损失是所有可能真实类别的加权和（权重为后验概率）。</li>
</ul>
</li>
</ul>
<p><strong>(3) 总体风险</strong></p>
<p>对于整个数据集，分类器 $ h(\mathbf{x}) $ 的<strong>总体风险</strong>为：</p>
<script type="math/tex; mode=display">
R(h) = \mathbb{E}_{\mathbf{x}}[R(h(\mathbf{x}) | \mathbf{x})] = \int R(h(\mathbf{x}) | \mathbf{x}) p(\mathbf{x}) d\mathbf{x}</script><ul>
<li><strong>含义</strong>：所有样本的平均条件风险。h为分类器（模型）</li>
<li><strong>目标</strong>：找到使 $ R(h) $ 最小的分类器 $ h(\mathbf{x}) $。</li>
</ul>
<h5 id="贝叶斯决策规则"><a href="#贝叶斯决策规则" class="headerlink" title="贝叶斯决策规则"></a><strong>贝叶斯决策规则</strong></h5><p>根据上述定义，贝叶斯决策论的分类规则是：</p>
<blockquote>
<p><strong>对于样本 $ \mathbf{x} $，选择使其条件风险 $ R(c_i | \mathbf{x}) $ 最小的类别 $ c_i $ 作为预测结果。</strong></p>
</blockquote>
<p>即：</p>
<script type="math/tex; mode=display">
h^*(\mathbf{x}) = \arg\min_{c_i} R(c_i | \mathbf{x}) = \arg\min_{c_i} \sum_{j=1}^N \lambda_{ij} P(c_j | \mathbf{x})</script><h5 id="特殊情况：0-1-损失函数"><a href="#特殊情况：0-1-损失函数" class="headerlink" title="特殊情况：0-1 损失函数"></a><strong>特殊情况：0-1 损失函数</strong></h5><p>当所有误分类的损失相同（即 $ \lambda<em>{ij} = 1 $ 对于 $ i \neq j $，$ \lambda</em>{ii} = 0 $）<strong>0-1 损失函数</strong>：</p>
<script type="math/tex; mode=display">
\lambda_{ij} = 
\begin{cases}
0, & \text{if } i = j \\
1, & \text{otherwise}
\end{cases}</script><p>此时条件风险简化为：</p>
<script type="math/tex; mode=display">
R(c_i | \mathbf{x}) = \sum_{j \neq i} P(c_j | \mathbf{x}) = 1 - P(c_i | \mathbf{x})</script><p>原因：概率之和为 1：$ \sum<em>{j=1}^N P(c_j | \mathbf{x}) = 1 $，因此 $ \sum</em>{j \neq i} P(c_j | \mathbf{x}) = 1 - P(c_i | \mathbf{x}) $。</p>
<p>此时，最小化风险等价于<strong>最大化后验概率</strong>，即：</p>
<script type="math/tex; mode=display">
h^*(\mathbf{x}) = \arg\max_{c_i} P(c_i | \mathbf{x})</script><p>这正是传统贝叶斯分类器的决策规则。</p>
<blockquote>
<p>即在x样本的情况下，分类正确的概率最大</p>
</blockquote>
<h4 id="后验概率与先验概率"><a href="#后验概率与先验概率" class="headerlink" title="后验概率与先验概率"></a>后验概率与先验概率</h4><h5 id="后验概率"><a href="#后验概率" class="headerlink" title="后验概率"></a>后验概率</h5><p>后验概率（Posterior Probability）是贝叶斯理论中的核心概念，指的是<strong>在观察到新证据（数据）后，对事件发生概率的修正</strong> 。<br>其本质是：</p>
<blockquote>
<p><strong>“已知结果（数据），反推原因（类别或参数）的概率”</strong> 。 </p>
</blockquote>
<p>已知结果（数据）B，反推最可能的原因A（后验概率 <em>P</em>(<em>A</em>∣<em>B</em>) ）</p>
<h5 id="先验概率（Prior-Probability）"><a href="#先验概率（Prior-Probability）" class="headerlink" title="先验概率（Prior Probability）"></a><strong>先验概率（Prior Probability）</strong></h5><p>先验概率是贝叶斯统计中的核心概念，指的是在<strong>观察到新数据之前</strong>，对某一事件或假设的概率估计。它是基于<strong>已有知识、经验或假设</strong>得出的初始概率，后续会通过新数据更新为更准确的<strong>后验概率</strong>。</p>
<p><strong>1. 核心定义</strong></p>
<ul>
<li><p><strong>数学表达</strong>：  </p>
<script type="math/tex; mode=display">
P(A)</script><ul>
<li>$ P(A) $：事件 $ A $ 的先验概率。</li>
<li>例如：$ A $ 表示“某人患有某种疾病”，则 $ P(A) $ 是该疾病的已知发病率（在未进行检测前的概率）。</li>
</ul>
</li>
<li><p><strong>与后验概率的区别</strong>：  </p>
<ul>
<li><strong>先验概率</strong>：$ P(A) $，在无新数据时的概率。  </li>
<li><strong>后验概率</strong>：$ P(A|B) $，在观察到数据 $ B $ 后更新的概率（通过贝叶斯定理计算）。</li>
</ul>
</li>
</ul>
<p><strong>2. 直观理解</strong></p>
<p><strong>(1) 类比：医学诊断</strong></p>
<ul>
<li><strong>先验概率</strong>：某种疾病的已知发病率（如 1%）。  </li>
<li><strong>新数据</strong>：患者接受检测，结果为阳性。  </li>
<li><strong>后验概率</strong>：结合发病率和检测结果，计算实际患病的概率（如 8.7%，参考贝叶斯定理的经典医学测试案例）。</li>
</ul>
<h4 id="生成式模型和判别式模型"><a href="#生成式模型和判别式模型" class="headerlink" title="生成式模型和判别式模型"></a>生成式模型和判别式模型</h4><h5 id="核心区别"><a href="#核心区别" class="headerlink" title="核心区别"></a><strong>核心区别</strong></h5><div class="table-container">
<table>
<thead>
<tr>
<th><strong>模型类型</strong></th>
<th><strong>建模目标</strong></th>
<th><strong>数学表达</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>判别式模型</strong></td>
<td>直接建模 $ P(c</td>
<td>\mathbf{x}) $</td>
<td>$ P(c</td>
<td>\mathbf{x}) $</td>
</tr>
<tr>
<td><strong>生成式模型</strong></td>
<td>先建模联合概率 $ P(\mathbf{x}, c) $，再推导 $ P(c</td>
<td>\mathbf{x}) $</td>
<td>$ P(c</td>
<td>\mathbf{x}) = \frac{P(\mathbf{x}</td>
<td>c)P(c)}{P(\mathbf{x})} $</td>
</tr>
</tbody>
</table>
</div>
<h5 id="详细解释"><a href="#详细解释" class="headerlink" title="详细解释"></a><strong>详细解释</strong></h5><p><strong>1. 判别式模型（Discriminative Model）</strong></p>
<ul>
<li><strong>目标</strong>：直接学习从输入 $ \mathbf{x} $ 到标签 $ c $ 的映射关系。</li>
<li><strong>数学本质</strong>：建模条件概率 $ P(c|\mathbf{x}) $，即“已知特征 $ \mathbf{x} $，预测类别 $ c $”。</li>
<li><strong>特点</strong>：<ul>
<li>不关心数据本身的分布，只关注分类边界。</li>
<li>例如：逻辑回归、支持向量机（SVM）、神经网络等。</li>
</ul>
</li>
</ul>
<p><strong>2. 生成式模型（Generative Model）</strong></p>
<ul>
<li><p><strong>目标</strong>：先学习数据的生成过程，即联合概率 $ P(\mathbf{x}, c) $，再通过贝叶斯定理推导条件概率 $ P(c|\mathbf{x}) $。</p>
</li>
<li><p><strong>数学步骤</strong>：</p>
<ol>
<li>建模 $ P(\mathbf{x}|c) $（特征在类别 $ c $ 下的分布）和 $ P(c) $（类别先验）。</li>
<li>根据贝叶斯定理计算后验概率：<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(\mathbf{x}|c)P(c)}{P(\mathbf{x})}</script></li>
<li>选择使 $ P(c|\mathbf{x}) $ 最大的类别作为预测结果。</li>
</ol>
</li>
</ul>
<h5 id="示例：二分类问题"><a href="#示例：二分类问题" class="headerlink" title="示例：二分类问题"></a><strong>示例：二分类问题</strong></h5><p>假设我们要判断一封邮件是否为垃圾邮件（$ c=spam $ 或 $ ham $）。</p>
<p><strong>判别式模型（逻辑回归）</strong></p>
<p>直接建模：</p>
<script type="math/tex; mode=display">
P(spam|\mathbf{x}) = \frac{1}{1 + e^{-(w^T \mathbf{x} + b)}}</script><p>若 $ P(spam|\mathbf{x}) &gt; 0.5 $，则判定为垃圾邮件。</p>
<p><strong>生成式模型（朴素贝叶斯）</strong></p>
<ol>
<li>建模联合概率：<script type="math/tex; mode=display">
P(\mathbf{x}, spam) = P(spam) \prod_{i} P(word_i|spam)</script><script type="math/tex; mode=display">
P(\mathbf{x}, ham) = P(ham) \prod_{i} P(word_i|ham)</script></li>
<li>计算后验概率：<script type="math/tex; mode=display">
P(spam|\mathbf{x}) = \frac{P(\mathbf{x}|spam)P(spam)}{P(\mathbf{x})}</script><script type="math/tex; mode=display">
P(ham|\mathbf{x}) = \frac{P(\mathbf{x}|ham)P(ham)}{P(\mathbf{x})}</script></li>
<li>选择概率更大的类别。</li>
</ol>
<h4 id="生成式模型的建模思路"><a href="#生成式模型的建模思路" class="headerlink" title="生成式模型的建模思路"></a>生成式模型的建模思路</h4><p>根据概率论的基本定义：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(\mathbf{x}, c)}{P(\mathbf{x})}</script><ul>
<li><strong>含义</strong>：<ul>
<li>$ P(\mathbf{x}, c) $：联合概率，表示特征 $ \mathbf{x} $ 和类别 $ c $ 同时发生的概率。</li>
<li>$ P(\mathbf{x}) $：边缘概率（证据），表示特征 $ \mathbf{x} $ 出现的概率，用于归一化。</li>
</ul>
</li>
</ul>
<p>根据贝叶斯定理，联合概率 $ P(\mathbf{x}, c) $ 可以分解为：</p>
<script type="math/tex; mode=display">
P(\mathbf{x}, c) = P(c) \cdot P(\mathbf{x}|c)</script><p>其中：</p>
<ul>
<li>$ P(c) $：类先验概率（Prior Probability），表示类别 $ c $ 在数据中的整体占比。</li>
<li>$ P(\mathbf{x}|c) $：似然度（Likelihood），表示在类别 $ c $ 下，特征 $ \mathbf{x} $ 出现的概率。</li>
</ul>
<p>将上述分解代入条件概率公式，得到：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(c) \cdot P(\mathbf{x}|c)}{P(\mathbf{x})}</script><p>产生问题：</p>
<p>在贝叶斯分类中，需要计算联合概率 <em>P</em>(<strong>x</strong>∣<em>c</em>) ，即在类别 <em>c</em> 下，特征向量 <strong>x</strong>=(<em>x</em>1,<em>x</em>2,…,<em>x**d</em>) 的条件概率。<br>若直接建模联合概率，需估计 <em>d</em> 个特征的所有可能组合的概率。例如：</p>
<ul>
<li>若每个特征有 <em>k</em> 个取值，类别数为 <em>K</em> ，则需要估计 <em>K</em>⋅<em>k**d</em> 个参数。</li>
<li>当特征维度 <em>d</em> 很大时（如文本分类中成千上万的词汇），参数数量呈指数级增长，导致计算不可行（<strong>维度灾难</strong> ）。</li>
</ul>
<p>举例：</p>
<ul>
<li><strong>低维空间</strong> ：假设只有 2 个特征（如“免费”和“中奖”），每个特征取值为 0 或 1，则特征空间共有 22=4 个可能的组合（即四个格子）。<ul>
<li>如果有 100 封邮件，每个格子平均有 25 封邮件（数据较密集）。</li>
</ul>
</li>
<li><strong>高维空间</strong> ：<br>当特征维度增加到 <em>d</em>=10,000 时，特征空间的组合数是 210,000 ，远大于宇宙中原子的数量（约 1080 ）。<ul>
<li>即使有 100 万封邮件，每个组合几乎都是空的（数据极度稀疏）。</li>
</ul>
</li>
</ul>
<p><strong>结果</strong> ：<br>在高维空间中，训练数据无法覆盖所有可能的特征组合，导致模型无法可靠估计联合概率 <em>P</em>(x∣c) 。</p>
<p>因此产生<strong>属性条件独立性假设</strong></p>
<h4 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h4><p>朴素贝叶斯分类器的核心思想是通过<strong>贝叶斯定理</strong>和<strong>属性条件独立性假设</strong>来简化计算，从而高效地进行分类。</p>
<h5 id="属性条件独立性假设"><a href="#属性条件独立性假设" class="headerlink" title="属性条件独立性假设"></a>属性条件独立性假设</h5><p>朴素贝叶斯的核心假设是：<strong>在已知类别 $ c $ 的条件下，所有属性（特征）之间相互独立</strong>。<br>因此，联合概率 $ P(\mathbf{x}|c) $ 可以分解为各属性独立概率的乘积：</p>
<script type="math/tex; mode=display">
P(\mathbf{x}|c) = \prod_{i=1}^d P(x_i|c)</script><p>其中 $ d $ 是特征的数量，$ x_i $ 是第 $ i $ 个特征的取值。</p>
<p>将此代入贝叶斯公式：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(c) \cdot \prod_{i=1}^d P(x_i|c)}{P(\mathbf{x})}</script><h5 id="为何可以忽略-P-mathbf-x"><a href="#为何可以忽略-P-mathbf-x" class="headerlink" title="为何可以忽略 $ P(\mathbf{x}) $?"></a><strong>为何可以忽略 $ P(\mathbf{x}) $?</strong></h5><p>在分类任务中，我们的目标是比较不同类别 $ c $ 的后验概率 $ P(c|\mathbf{x}) $，并选择最大值。由于 $ P(\mathbf{x}) $ 对所有类别来说是相同的常量（与类别无关），因此在最大化过程中可以忽略：</p>
<script type="math/tex; mode=display">
\arg\max_{c} P(c|\mathbf{x}) = \arg\max_{c} \left[ \frac{P(c) \cdot \prod_{i=1}^d P(x_i|c)}{P(\mathbf{x})} \right] = \arg\max_{c} \left[ P(c) \cdot \prod_{i=1}^d P(x_i|c) \right]</script><p>这就是公式中 $ P(\mathbf{x}) $ 被省略的原因。</p>
<blockquote>
<p>在比较的过程中，分母相同，可以忽略</p>
</blockquote>
<h5 id="朴素贝叶斯的最终决策规则"><a href="#朴素贝叶斯的最终决策规则" class="headerlink" title="朴素贝叶斯的最终决策规则"></a><strong>朴素贝叶斯的最终决策规则</strong></h5><p>简化后的决策规则为：</p>
<script type="math/tex; mode=display">
h_{nb}(\mathbf{x}) = \arg\max_{c} \left[ P(c) \cdot \prod_{i=1}^d P(x_i|c) \right]</script><p>即：</p>
<ul>
<li>计算每个类别的先验概率 $ P(c) $。</li>
<li>计算每个特征在该类别下的条件概率 $ P(x_i|c) $。</li>
<li>将这些概率相乘，选择乘积最大的类别作为预测结果。</li>
</ul>
<h5 id="类先验概率-P-c-的估计方法"><a href="#类先验概率-P-c-的估计方法" class="headerlink" title="类先验概率 $ P(c) $ 的估计方法"></a><strong>类先验概率 $ P(c) $ 的估计方法</strong></h5><p>基于<strong>大数定律</strong></p>
<script type="math/tex; mode=display">
P(c) = \frac{|D_c|}{|D|}</script><ul>
<li><p><strong>符号含义</strong>：</p>
<ul>
<li>$ D $：训练集，包含所有样本。</li>
<li>$ D_c $：训练集中类别为 $ c $ 的样本子集。</li>
<li>$ |D_c| $：类别 $ c $ 的样本数量。</li>
<li>$ |D| $：训练集总样本数量。</li>
</ul>
</li>
<li><p><strong>直观解释</strong>：<br>类先验概率等于该类别样本数占总样本数的比例。</p>
</li>
</ul>
<h5 id="条件概率-P-x-i-c-的估计方法"><a href="#条件概率-P-x-i-c-的估计方法" class="headerlink" title="条件概率 $ P(x_i | c) $ 的估计方法"></a><strong>条件概率 $ P(x_i | c) $ 的估计方法</strong></h5><p>在生成式模型（如朴素贝叶斯分类器）中，<strong>条件概率 $ P(x_i | c) $</strong> 表示在类别 $ c $ 下，第 $ i $ 个属性取值为 $ x_i $ 的概率。根据属性类型（离散或连续），其估计方法不同：</p>
<p><strong>1. 离散属性的条件概率估计</strong></p>
<p><strong>公式</strong>：</p>
<script type="math/tex; mode=display">
P(x_i | c) = \frac{|D_{c,x_i}|}{|D_c|}</script><ul>
<li><strong>符号含义</strong>：<ul>
<li>$ D_c $：训练集中类别为 $ c $ 的样本集合。</li>
<li>$ D_{c,x_i} $：$ D_c $ 中第 $ i $ 个属性取值为 $ x_i $ 的样本子集。</li>
<li>$ |D<em>{c,x_i}| $：$ D</em>{c,x_i} $ 的样本数量。</li>
<li>$ |D_c| $：类别 $ c $ 的总样本数量。</li>
</ul>
</li>
</ul>
<p><strong>直观解释</strong>：</p>
<ul>
<li>在类别 $ c $ 的样本中，统计第 $ i $ 个属性取值为 $ x_i $ 的频率，作为 $ P(x_i | c) $ 的估计。</li>
<li><strong>示例</strong>：<br>若类别 $ c=spam $（垃圾邮件）有 200 封，其中 150 封包含“免费”一词，则：<script type="math/tex; mode=display">
P(\text{“免费”} | spam) = \frac{150}{200} = 0.75</script></li>
</ul>
<p><strong>注意事项</strong>：</p>
<ul>
<li><strong>零概率问题</strong>：若某属性值在类别 $ c $ 中未出现，则 $ P(x_i | c) = 0 $，可能导致后续计算失效。<br><strong>解决方案</strong>：使用<strong>拉普拉斯平滑（Laplace Smoothing）</strong>，将公式改为：<script type="math/tex; mode=display">
P(x_i | c) = \frac{|D_{c,x_i}| + 1}{|D_c| + K}</script>其中 $ K $ 是该属性的取值总数。</li>
</ul>
<p><strong>2. 连续属性的条件概率估计</strong></p>
<p><strong>假设</strong>：属性服从正态分布（高斯分布）</p>
<script type="math/tex; mode=display">
p(x_i | c) = \frac{1}{\sqrt{2\pi}\sigma_{c,i}} \exp\left( -\frac{(x_i - \mu_{c,i})^2}{2\sigma_{c,i}^2} \right)</script><ul>
<li><strong>符号含义</strong>：<ul>
<li>$ \mu_{c,i} $：类别 $ c $ 在第 $ i $ 个属性上的均值。</li>
<li>$ \sigma_{c,i}^2 $：类别 $ c $ 在第 $ i $ 个属性上的方差。</li>
</ul>
</li>
</ul>
<p><strong>直观解释</strong>：</p>
<ul>
<li>假设在类别 $ c $ 下，属性 $ x<em>i $ 服从均值为 $ \mu</em>{c,i} $、方差为 $ \sigma_{c,i}^2 $ 的正态分布。</li>
<li><strong>示例</strong>：<br>若类别 $ c=spam $ 的“字数”属性均值 $ \mu<em>{spam, \text{字数}} = 500 $，方差 $ \sigma</em>{spam, \text{字数}}^2 = 100 $，则：<script type="math/tex; mode=display">
p(600 | spam) = \frac{1}{\sqrt{2\pi \cdot 100}} \exp\left( -\frac{(600 - 500)^2}{2 \cdot 100} \right) \approx 0.004</script></li>
</ul>
<p><strong>注意事项</strong>：</p>
<ul>
<li><strong>分布假设</strong>：若实际数据不符合正态分布，需调整假设（如使用核密度估计、对数变换等）。</li>
<li><strong>参数估计</strong>：均值和方差通过训练数据计算：<script type="math/tex; mode=display">
\mu_{c,i} = \frac{1}{|D_c|} \sum_{x \in D_c} x_i, \quad \sigma_{c,i}^2 = \frac{1}{|D_c|} \sum_{x \in D_c} (x_i - \mu_{c,i})^2</script></li>
</ul>
<h4 id="半朴素贝叶斯分类器"><a href="#半朴素贝叶斯分类器" class="headerlink" title="半朴素贝叶斯分类器"></a>半朴素贝叶斯分类器</h4><p>半朴素贝叶斯分类器是对传统<strong>朴素贝叶斯</strong>的改进，它在保留计算效率的同时，<strong>适当引入部分属性间的依赖关系</strong>，从而在分类性能和计算复杂度之间取得平衡。</p>
<h5 id="独依赖估计（ODE）方法"><a href="#独依赖估计（ODE）方法" class="headerlink" title="独依赖估计（ODE）方法"></a><strong>独依赖估计（ODE）方法</strong></h5><p><strong>(1) 定义</strong></p>
<p>独依赖估计（One-Dependent Estimator, ODE）是半朴素贝叶斯的一种实现方式，其核心假设是：</p>
<blockquote>
<p><strong>每个属性 $ x_i $ 在类别 $ c $ 之外最多依赖于一个其他属性（称为父属性 $ pa_i $）</strong>。</p>
</blockquote>
<p>数学表达式为：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) \propto P(c) \prod_{i=1}^d P(x_i | c, pa_i)</script><p>其中：</p>
<ul>
<li>$ pa_i $：属性 $ x_i $ 的父属性（依赖的单一属性）。</li>
<li>$ P(x_i | c, pa_i) $：在类别 $ c $ 和父属性 $ pa_i $ 下，属性 $ x_i $ 的条件概率。</li>
</ul>
<p><strong>(2) 直观理解</strong></p>
<ul>
<li>每个属性 $ x_i $ 的分布不仅受类别 $ c $ 影响，还受其父属性 $ pa_i $ 的影响。</li>
<li>例如，在文本分类中，若属性 $ x_1 $ 是“免费”，$ x_2 $ 是“中奖”，可设定 $ pa_2 = x_1 $，表示“中奖”在类别和“免费”的共同作用下出现。</li>
</ul>
<h5 id="超父独依赖估计（SPODE）"><a href="#超父独依赖估计（SPODE）" class="headerlink" title="超父独依赖估计（SPODE）"></a><strong>超父独依赖估计（SPODE）</strong></h5><p>超父独依赖估计（Super Parent One-Dependent Estimator, SPODE）是<strong>半朴素贝叶斯分类器</strong>的一种扩展，其核心思想是：</p>
<blockquote>
<p><strong>所有属性都依赖于同一个“超父”属性 $ x_i $</strong>，从而在保留部分依赖关系的同时避免完全联合概率的计算。</p>
</blockquote>
<p><strong>(1) 贝叶斯定理展开</strong></p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(\mathbf{x}, c)}{P(\mathbf{x})}</script><p>其中：</p>
<ul>
<li>$ P(\mathbf{x}, c) $：联合概率，表示特征 $ \mathbf{x} $ 和类别 $ c $ 同时发生的概率。</li>
<li>$ P(\mathbf{x}) $：证据（归一化因子）。</li>
</ul>
<p><strong>(2) 引入“超父”属性 $ x_i $</strong></p>
<p>假设所有属性 $ x_j (j \neq i) $ 在类别 $ c $ 下仅依赖于 $ x_i $，则：</p>
<script type="math/tex; mode=display">
P(\mathbf{x}, c) = P(c, x_i) \cdot P(x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_d | c, x_i)</script><p>进一步分解为：</p>
<script type="math/tex; mode=display">
P(\mathbf{x}, c) = P(c, x_i) \cdot \prod_{j \neq i} P(x_j | c, x_i)</script><p><strong>(3) 最终形式</strong></p>
<p>由于 $ P(\mathbf{x}) $ 对所有类别相同，可忽略，最终决策规则为：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) \propto P(c, x_i) \cdot \prod_{j=1}^d P(x_j | c, x_i)</script><p>其中：</p>
<ul>
<li>$ P(c, x_i) $：类别 $ c $ 和属性 $ x_i $ 的联合概率。</li>
<li>$ P(x_j | c, x_i) $：在类别 $ c $ 和 $ x_i $ 的条件下，属性 $ x_j $ 的概率。</li>
</ul>
<h5 id="树增强朴素贝叶斯（TAN-Tree-Augmented-Naive-Bayes）"><a href="#树增强朴素贝叶斯（TAN-Tree-Augmented-Naive-Bayes）" class="headerlink" title="树增强朴素贝叶斯（TAN: Tree-Augmented Naive Bayes）"></a><strong>树增强朴素贝叶斯（TAN: Tree-Augmented Naive Bayes）</strong></h5><p><strong>TAN</strong>（Tree-Augmented Naive Bayes）是<strong>半朴素贝叶斯分类器</strong>的一种扩展，旨在通过引入属性间的<strong>树状依赖关系</strong>，在保留计算效率的同时，显著提升分类性能。它结合了<strong>贝叶斯网络</strong>的建模能力和<strong>生成式模型</strong>的概率推理优势。</p>
<p><strong>1. 核心思想</strong></p>
<p>TAN 的核心假设是：</p>
<blockquote>
<p><strong>所有属性（特征）在类别 $ c $ 的基础上，形成一个以属性为节点的树状依赖结构</strong>，即每个属性最多依赖一个其他属性（父属性），且整个依赖图是一棵无环的树。</p>
</blockquote>
<p><strong>数学表达</strong>：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) \propto P(c) \cdot \prod_{i=1}^d P(x_i | c, pa_i)</script><p>其中：</p>
<ul>
<li>$ pa_i $：属性 $ x_i $ 的父属性（依赖的单一属性）。</li>
<li>$ P(x_i | c, pa_i) $：在类别 $ c $ 和父属性 $ pa_i $ 的条件下，属性 $ x_i $ 的条件概率。</li>
</ul>
<p><strong>2. TAN 的构建步骤</strong></p>
<p>TAN 通过以下步骤构建属性间的依赖结构：</p>
<p><strong>(1) 计算互信息（Mutual Information）</strong></p>
<p>互信息衡量两个属性之间的相关性：</p>
<script type="math/tex; mode=display">
I(x_i, x_j) = \sum_{x_i, x_j} P(x_i, x_j) \log \frac{P(x_i, x_j)}{P(x_i)P(x_j)}</script><ul>
<li><strong>含义</strong>：互信息越大，两个属性之间的依赖关系越强。</li>
</ul>
<p><strong>(2) 构建带权图</strong></p>
<ul>
<li>将所有属性视为图中的节点。</li>
<li>每对属性间的边权重设为互信息 $ I(x_i, x_j) $。</li>
</ul>
<p><strong>(3) 最大带权生成树（Maximum Weight Spanning Tree, MWST）</strong></p>
<p>使用克鲁斯卡尔（Kruskal）算法或普里姆（Prim）算法，选择一棵连接所有属性节点的树，使得：</p>
<ul>
<li>树的边权重（互信息）总和最大。</li>
<li>树中无环。</li>
</ul>
<p><strong>(4) 确定依赖方向</strong></p>
<ul>
<li>随机选择一个根节点（或根据领域知识指定）。</li>
<li>从根节点出发，确定每条边的方向（父属性 → 子属性）。</li>
</ul>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250605223036362.png" alt="image-20250605223036362"></p>
<h4 id="贝叶斯网"><a href="#贝叶斯网" class="headerlink" title="贝叶斯网"></a>贝叶斯网</h4><p>待学习</p>
<h4 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h4><p>EM算法（Expectation-Maximization Algorithm）是一种<strong>迭代优化算法</strong>，用于处理<strong>含有隐变量</strong>（Hidden Variables）或<strong>缺失数据</strong>的概率模型参数估计问题。它的核心思想是通过交替执行<strong>期望（E）步</strong>和<strong>最大化（M）步</strong>，逐步逼近模型参数的最大似然估计。</p>
<h5 id="1-核心思想：解决隐变量问题"><a href="#1-核心思想：解决隐变量问题" class="headerlink" title="1. 核心思想：解决隐变量问题"></a><strong>1. 核心思想：解决隐变量问题</strong></h5><p><strong>(1) 什么是隐变量？</strong></p>
<p>隐变量（Latent Variables）是模型中<strong>不可观测但影响观测数据</strong>的变量。例如：</p>
<ul>
<li><strong>混合高斯模型（GMM）</strong>：每个样本属于哪个高斯分布是隐变量。</li>
<li><strong>聚类任务</strong>：样本所属的聚类标签是隐变量。</li>
</ul>
<p><strong>(2) 问题挑战</strong></p>
<p>当存在隐变量时，直接最大化似然函数变得困难。例如：</p>
<script type="math/tex; mode=display">
\log P(\mathbf{x}|\theta) = \log \sum_z P(\mathbf{x}, z|\theta)</script><p>其中 $ z $ 是隐变量，$ \theta $ 是模型参数。由于对数中包含求和，直接求导无法分离参数。</p>
<p><strong>(3) EM算法的解决方案</strong></p>
<p>EM算法通过以下步骤迭代求解：</p>
<ol>
<li><strong>E步（期望）</strong>：用当前参数估计隐变量的后验分布（即“责任”分配）。</li>
<li><strong>M步（最大化）</strong>：基于隐变量的后验分布，最大化期望似然函数以更新参数。</li>
</ol>
<h5 id="2-算法流程"><a href="#2-算法流程" class="headerlink" title="2. 算法流程"></a><strong>2. 算法流程</strong></h5><p><strong>(1) 初始化参数</strong></p>
<p>选择初始参数 $ \theta^{(0)} $，例如随机初始化或通过启发式方法设定。</p>
<p><strong>(2) E步：计算隐变量后验分布</strong></p>
<p>给定当前参数 $ \theta^{(t)} $，计算隐变量 $ z $ 的后验概率：</p>
<script type="math/tex; mode=display">
Q^{(t)}(z) = P(z|\mathbf{x}, \theta^{(t)})</script><p>这一步为每个样本分配隐变量的概率分布（如样本属于某个聚类的概率）。</p>
<p><strong>(3) M步：最大化期望似然</strong></p>
<p>基于 $ Q^{(t)}(z) $，构造期望似然函数并最大化：</p>
<script type="math/tex; mode=display">
\theta^{(t+1)} = \arg\max_{\theta} \sum_z Q^{(t)}(z) \log P(\mathbf{x}, z|\theta)</script><p>这一步更新参数 $ \theta $，使得期望似然最大。</p>
<p><strong>(4) 收敛判断</strong></p>
<p>重复E步和M步直到参数收敛（如 $ |\theta^{(t+1)} - \theta^{(t)}| &lt; \epsilon $）或达到最大迭代次数。</p>
<h5 id="3-示例：混合高斯模型（GMM）"><a href="#3-示例：混合高斯模型（GMM）" class="headerlink" title="3. 示例：混合高斯模型（GMM）"></a><strong>3. 示例：混合高斯模型（GMM）</strong></h5><p>假设数据由多个高斯分布生成，但不知道每个样本属于哪个分布。</p>
<p><strong>(1) 模型定义</strong></p>
<ul>
<li>观测变量 $ x_i \in \mathbb{R}^d $：第 $ i $ 个样本。</li>
<li>隐变量 $ z_i \in {1, …, K} $：样本 $ x_i $ 所属的高斯分布。</li>
<li>参数 $ \theta = {\mu<em>k, \Sigma_k, \pi_k}</em>{k=1}^K $：<ul>
<li>$ \mu_k $：第 $ k $ 个高斯分布的均值。</li>
<li>$ \Sigma_k $：第 $ k $ 个高斯分布的协方差矩阵。</li>
<li>$ \pi_k $：第 $ k $ 个高斯分布的权重（先验概率）。</li>
</ul>
</li>
</ul>
<p><strong>(2) E步：计算责任分配</strong></p>
<p>对于每个样本 $ x_i $ 和类别 $ k $，计算责任（responsibility）：</p>
<script type="math/tex; mode=display">
\gamma_{ik}^{(t)} = P(z_i=k|x_i, \theta^{(t)}) = \frac{\pi_k^{(t)} \mathcal{N}(x_i|\mu_k^{(t)}, \Sigma_k^{(t)})}{\sum_{j=1}^K \pi_j^{(t)} \mathcal{N}(x_i|\mu_j^{(t)}, \Sigma_j^{(t)})}</script><p>含义：在当前参数下，样本 $ x_i $ 属于类别 $ k $ 的概率。</p>
<p><strong>(3) M步：更新参数</strong></p>
<p>根据责任 $ \gamma_{ik} $ 更新参数：</p>
<ul>
<li><strong>均值更新</strong>：<script type="math/tex; mode=display">
\mu_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)} x_i}{\sum_{i=1}^N \gamma_{ik}^{(t)}}</script></li>
<li><strong>协方差更新</strong>：<script type="math/tex; mode=display">
\Sigma_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)} (x_i - \mu_k^{(t+1)})(x_i - \mu_k^{(t+1)})^T}{\sum_{i=1}^N \gamma_{ik}^{(t)}}</script></li>
<li><strong>权重更新</strong>：<script type="math/tex; mode=display">
\pi_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)}}{N}</script></li>
</ul>
<p><strong>(4) 迭代终止</strong></p>
<p>当参数变化小于阈值或达到最大迭代次数时停止。</p>
<h4 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h4><h5 id="1"><a href="#1" class="headerlink" title="1"></a>1</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143758565.png" alt="image-20250606143758565"></p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143819352.png" alt="image-20250606143819352"></p>
<h5 id="2"><a href="#2" class="headerlink" title="2"></a>2</h5><p>已知观测数据-67，-48，6，8，14，16，23，24，28，29，41，49，56，60，75，试估计两个分量的高斯混合模型的5个参数。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150830535.png" alt="image-20250606150830535"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化观测数据</span></span><br><span class="line">data = np.array([-<span class="number">67</span>, -<span class="number">48</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">41</span>, <span class="number">49</span>, <span class="number">56</span>, <span class="number">60</span>,</span><br><span class="line">                 <span class="number">75</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类</span></span><br><span class="line">gmmModel = GaussianMixture(n_components=<span class="number">2</span>)</span><br><span class="line">gmmModel.fit(data)</span><br><span class="line">labels = gmmModel.predict(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels =&quot;</span>, labels)</span><br><span class="line">labels = [<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(labels)):</span><br><span class="line">    <span class="keyword">if</span> labels[i] == <span class="number">0</span>:</span><br><span class="line">        plt.scatter(i, data.take(i), s=<span class="number">15</span>, c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> labels[i] == <span class="number">1</span>:</span><br><span class="line">        plt.scatter(i, data.take(i), s=<span class="number">15</span>, c=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Gaussian Mixture Model&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;means =&quot;</span>, gmmModel.means_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;covariances =&quot;</span>, gmmModel.covariances_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights = &quot;</span>, gmmModel.weights_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150906475.png" alt="image-20250606150906475"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># means = [[ 32.98489643 -57.51107027]]</span></span><br><span class="line"><span class="comment"># covariances = [[429.45764867  90.24987882]]</span></span><br><span class="line"><span class="comment"># weights =  [[0.86682762 0.13317238]]</span></span><br></pre></td></tr></table></figure>
<h5 id="3"><a href="#3" class="headerlink" title="3"></a>3</h5><p>简要阐述下EM算法的原理，并给出EM算法对高斯混合模型GMM进行求解的具体过程。</p>
<h6 id="EM算法的原理"><a href="#EM算法的原理" class="headerlink" title="EM算法的原理"></a>EM算法的原理</h6><p>EM算法（期望最大化算法）是一种用于含有隐变量的概率模型参数估计的迭代优化方法。其核心思想是通过交替执行两个步骤来最大化观测数据的似然函数：</p>
<ol>
<li><strong>E步（期望步）</strong>：计算隐变量的后验期望（即责任），给定当前参数估计。</li>
<li><strong>M步（最大化步）</strong>：基于责任，最大化完全数据的期望似然函数以更新参数。</li>
</ol>
<p>EM算法通过不断优化似然函数的下界，最终收敛到局部最优解。以下具体阐述EM算法对高斯混合模型（GMM）的求解过程。</p>
<h6 id="EM算法对GMM的具体求解过程"><a href="#EM算法对GMM的具体求解过程" class="headerlink" title="EM算法对GMM的具体求解过程"></a><strong>EM算法对GMM的具体求解过程</strong></h6><p><strong>1. GMM模型定义</strong></p>
<p>GMM假设数据由 $ K $ 个高斯分布线性组合生成，其概率密度函数为：</p>
<script type="math/tex; mode=display">
p(\mathbf{x}|\theta) = \sum_{k=1}^K \alpha_k \cdot \mathcal{N}(\mathbf{x}|\mu_k, \Sigma_k)</script><p>其中：</p>
<ul>
<li>$ \alpha<em>k $：第 $ k $ 个高斯分布的权重（$ \sum</em>{k=1}^K \alpha_k = 1 $）。</li>
<li>$ \mu_k $：第 $ k $ 个高斯分布的均值向量。</li>
<li>$ \Sigma_k $：第 $ k $ 个高斯分布的协方差矩阵。</li>
<li>$ \theta = {\alpha<em>k, \mu_k, \Sigma_k}</em>{k=1}^K $：模型参数。</li>
</ul>
<p>隐变量 $ z_i \in {1,\dots,K} $ 表示样本 $ \mathbf{x}_i $ 的类别标签（未知）。</p>
<p><strong>2. EM算法步骤</strong></p>
<p><strong>(1) 初始化参数</strong></p>
<p>随机或通过K-means初始化：</p>
<ul>
<li>每个高斯分布的均值 $ \mu_k^{(0)} $、协方差 $ \Sigma_k^{(0)} $、权重 $ \alpha_k^{(0)} $。</li>
</ul>
<p><strong>(2) 迭代优化（E步与M步）</strong></p>
<p><strong>E步：计算责任（后验概率）</strong><br>对每个样本 $\mathbf{x}_i$ 和每个簇 $ k $，计算其属于第 $ k $ 个高斯分布的后验概率</p>
<script type="math/tex; mode=display">
\gamma(z_{ik}) = \frac{\alpha_k \cdot \mathcal{N}(\mathbf{x}_i | \mu_k, \Sigma_k)}{\sum_{j=1}^K \alpha_j \cdot \mathcal{N}(\mathbf{x}_i | \mu_j, \Sigma_j)}</script><p>此概率表示在当前参数下，样本 $ \mathbf{x}_i $ 属于第 $ k $ 个高斯分布的“责任”。</p>
<p><strong>M步：更新参数</strong><br>基于责任 $ \gamma(z_{ik}) $，最大化完全数据似然函数的期望，更新参数：</p>
<ul>
<li><strong>权重更新</strong>：<script type="math/tex; mode=display">
\alpha_k^{(new)} = \frac{1}{N} \sum_{i=1}^N \gamma(z_{ik})</script></li>
<li><strong>均值更新</strong>：<script type="math/tex; mode=display">
\mu_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) \mathbf{x}_i}{\sum_{i=1}^N \gamma(z_{ik})}</script></li>
<li><strong>协方差更新</strong>：<script type="math/tex; mode=display">
\Sigma_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) (\mathbf{x}_i - \mu_k^{(new)})(\mathbf{x}_i - \mu_k^{(new)})^\top}{\sum_{i=1}^N \gamma(z_{ik})}</script>若为单变量高斯分布，则更新方差：<script type="math/tex; mode=display">
\sigma_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) (x_i - \mu_k^{(new)})^2}{\sum_{i=1}^N \gamma(z_{ik})}</script></li>
</ul>
<p><strong>(3) 收敛判断</strong></p>
<p>计算对数似然函数：</p>
<script type="math/tex; mode=display">
\log p(\mathbf{X}|\theta) = \sum_{i=1}^N \log \left( \sum_{k=1}^K \alpha_k \cdot \mathcal{N}(\mathbf{x}_i|\mu_k, \Sigma_k) \right)</script><p>若对数似然的变化量小于阈值或达到最大迭代次数，则停止；否则重复E步和M步。。</p>
<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1RT411G7jJ/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">[5分钟学算法] #06 EM算法 你到底是哪个班级的_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/396007256">《统计学习方法_第二版》学习笔记第九章 - 知乎</a></p>
<h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><h4 id="个体与集成"><a href="#个体与集成" class="headerlink" title="个体与集成"></a>个体与集成</h4><h5 id="集成学习的基本概念"><a href="#集成学习的基本概念" class="headerlink" title="集成学习的基本概念"></a><strong>集成学习的基本概念</strong></h5><p>集成学习（Ensemble Learning）通过构建并结合<strong>多个学习器（基模型）</strong>来完成学习任务，其核心思想是“<strong>优而不同</strong>”，即<strong>通过多个弱学习器的协作提升整体性能</strong>，通常能获得比单一学习器更优的泛化能力 。 </p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606154731476.png" alt="image-20250606154731476"> </p>
<p>在上图的集成模型中，若个体学习器都属于同一类别，例如都是决策树或都是神经网络，则称该集成为同质的（homogeneous）;若个体学习器包含多种类型的学习算法，例如既有决策树又有神经网络，则称该集成为异质的（heterogenous）。</p>
<blockquote>
<p><strong>同质集成</strong>：个体学习器称为“基学习器”（base learner），对应的学习算法为“基学习算法”（base learning algorithm）。 </p>
<p><strong>异质集成</strong>：个体学习器称为“组件学习器”（component learner）或直称为“个体学习器”。</p>
</blockquote>
<p>集成学习的两个重要概念：<strong>准确性</strong>和<strong>多样性</strong>（diversity）。准确性指的是个体学习器不能太差，要有一定的准确度；多样性则是个体学习器之间的输出要具有差异性。</p>
<p>通过下面的这三个例子可以很容易看出这一点，准确度较高，差异度也较高，可以较好地提升集成性能。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606155939884.png" alt="image-20250606155939884"></p>
<p><strong>集成策略</strong>：如何结合多个基模型的预测结果，例如：  </p>
<ul>
<li><strong>投票法</strong>（Voting）：多数投票（硬投票）或概率加权（软投票）。  </li>
<li><strong>加权平均法</strong>：对基模型的输出赋予不同权重 。  </li>
<li><strong>Stacking</strong>：用元模型（Meta-Model）学习基模型的输出作为新特征 。</li>
</ul>
<h5 id="基于投票法的集成个体学习器的收敛性保证："><a href="#基于投票法的集成个体学习器的收敛性保证：" class="headerlink" title="基于投票法的集成个体学习器的收敛性保证："></a><strong>基于投票法的集成个体学习器的收敛性保证</strong>：</h5><p><strong>公式解析</strong></p>
<script type="math/tex; mode=display">
P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) = \sum_{k=0}^{\lfloor T/2 \rfloor} \binom{T}{k} (1-\epsilon)^k \epsilon^{T-k} \leq \exp\left(-\frac{1}{2} T (1 - 2\epsilon)^2\right)</script><p><strong>1. 公式含义</strong></p>
<ul>
<li><strong>$H(\boldsymbol{x})$</strong>：集成学习器的最终预测结果（如多数投票结果）。</li>
<li><strong>$f(\boldsymbol{x})$</strong>：真实标记。</li>
<li><strong>$\epsilon$</strong>：单个弱学习器的错误率（即 $P(h_t(\boldsymbol{x}) \neq f(\boldsymbol{x}))$），默认小于0.5。</li>
<li><strong>$T$</strong>：基学习器的数量。</li>
<li><strong>左边</strong>：集成学习器预测错误的概率（即至少有超过 $T/2$ 个基学习器预测错误的概率）。</li>
<li><strong>右边</strong>：对左边概率的指数级上限估计。</li>
</ul>
<p><strong>2. 推导思路</strong></p>
<ul>
<li>假设每个基学习器独立且错误率为 $\epsilon$，则错误次数服从<strong>二项分布</strong> $B(T, \epsilon)$。</li>
<li>集成错误的条件是“超过半数基学习器错误”，即错误次数 $k \leq \lfloor T/2 \rfloor$。</li>
</ul>
<p><strong>两个基本结论</strong></p>
<p><strong>1. 收敛速率随个体学习器数量 $T$ 指数下降</strong></p>
<ul>
<li><strong>数学体现</strong>：错误概率的上界是 $\exp(-cT)$ 形式，其中 $c = \frac{1}{2}(1 - 2\epsilon)^2$。</li>
</ul>
<p><strong>2. $\epsilon = 0.5$ 的个体学习器对收敛没有作用</strong></p>
<ul>
<li><strong>数学原因</strong>：当 $\epsilon = 0.5$ 时，$(1 - 2\epsilon)^2 = 0$，指数项变为 0，错误概率上界为 $\exp(0) = 1$，即错误概率无法降低。</li>
</ul>
<p>根据个体学习器的<strong>生成方式</strong>，目前集成学习可分为两类，代表作如下：</p>
<ol>
<li>个体学习器直接存在强依赖关系，必须串行生成的序列化方法：<strong>Boosting</strong>；</li>
<li>个体学习器间不存在强依赖关系，可以同时生成的并行化方法：<strong>Bagging</strong> 和 <strong>随机森林 (Random Forest)</strong>。</li>
</ol>
<h4 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a><strong>Boosting</strong></h4><p>Boosting是一种<strong>串行</strong>的工作机制，即<strong>个体学习器的训练存在依赖关系</strong>，必须一步一步序列化进行。</p>
<p>其<strong>基本思想</strong>是：<strong>增加前一个基学习器在训练过程中预测错误样本的权重，使得后续基学习器更加关注这些打标错误的训练样本，尽可能纠正这些错误，然后基于调整后的样本分布训练下一个基学习器</strong>，如此重复，一直向下串行直至产生需要的T个基学习器，Boosting最终对这T个学习器进行加权结合，产生学习器委员会。</p>
<p>Boosting族算法最著名、使用最为广泛的就是<strong>AdaBoost</strong>，因此下面主要是对AdaBoost算法进行介绍。</p>
<p>AdaBoost使用的是<strong>指数损失函数</strong>，因此AdaBoost的权值与样本分布的更新都是围绕着最小化指数损失函数进行的。</p>
<blockquote>
<p>看到这里回想一下之前的机器学习算法，<strong>不难发现机器学习的大部分带参模型只是改变了最优化目标中的损失函数</strong>：如果是Square loss，那就是最小二乘了；如果是Hinge Loss，那就是著名的SVM了；如果是log-Loss，那就是Logistic Regression了。</p>
</blockquote>
<h5 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h5><h5 id="公式解析"><a href="#公式解析" class="headerlink" title="公式解析"></a><strong>公式解析</strong></h5><script type="math/tex; mode=display">
H(\boldsymbol{x}) = \sum_{t=1}^T \alpha_t h_t(\boldsymbol{x})</script><script type="math/tex; mode=display">
\ell_{\exp}(H | \mathcal{D}) = \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}} \left[ e^{-f(\boldsymbol{x}) H(\boldsymbol{x})} \right]</script><p><strong>1. 符号含义</strong></p>
<ul>
<li><strong>$H(\boldsymbol{x})$</strong>：最终集成模型的预测结果，是 $T$ 个基学习器 $h_t(\boldsymbol{x})$ 的加权和。</li>
<li><strong>$\alpha_t$</strong>：第 $t$ 个基学习器的权重，表示其在集成中的重要性。</li>
<li><strong>$h_t(\boldsymbol{x})$</strong>：第 $t$ 个基学习器（如决策树、感知机等）。</li>
<li><strong>$f(\boldsymbol{x})$</strong>：真实标签，通常取值为 ${-1, +1}$（二分类问题）。</li>
<li><strong>$\mathcal{D}$</strong>：训练数据分布。</li>
<li><strong>$\ell_{\exp}$</strong>：指数损失函数（Exponential Loss）。</li>
</ul>
<p><strong>2. 指数损失函数的意义</strong></p>
<p>指数损失函数的形式为：</p>
<script type="math/tex; mode=display">
\ell_{\exp}(H | \mathcal{D}) = \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}} \left[ e^{-f(\boldsymbol{x}) H(\boldsymbol{x})} \right]</script><ul>
<li><strong>直观解释</strong>：<ul>
<li>当 $H(\boldsymbol{x})$ 与 $f(\boldsymbol{x})$ 同号时（预测正确），指数项 $e^{-f(\boldsymbol{x}) H(\boldsymbol{x})}$ 接近 0，损失小。</li>
<li>当 $H(\boldsymbol{x})$ 与 $f(\boldsymbol{x})$ 异号时（预测错误），指数项趋近于正无穷，损失极大。</li>
<li>因此，该损失函数对错误样本的惩罚非常严格，迫使模型优先修正错误。</li>
</ul>
</li>
</ul>
<h5 id="AdaBoost的优化目标"><a href="#AdaBoost的优化目标" class="headerlink" title="AdaBoost的优化目标"></a><strong>AdaBoost的优化目标</strong></h5><p>AdaBoost的目标是选择基学习器 $h_t$ 和权重 $\alpha_t$，使得集成模型 $H(\boldsymbol{x})$ 能够<strong>最小化指数损失函数</strong>：</p>
<script type="math/tex; mode=display">
\min_{\alpha_1, h_1, \dots, \alpha_T, h_T} \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}} \left[ e^{-f(\boldsymbol{x}) \sum_{t=1}^T \alpha_t h_t(\boldsymbol{x})} \right]</script><p><strong>优化策略</strong></p>
<p>AdaBoost采用<strong>前向分步算法（Forward Stagewise Algorithm）</strong>，逐轮迭代优化：</p>
<ol>
<li><strong>初始化样本权重</strong>：初始时所有样本权重相等。</li>
<li><strong>训练基学习器 $h_t$</strong>：在当前样本权重分布下，训练一个弱学习器 $h_t$。</li>
<li><strong>计算权重 $\alpha_t$</strong>：根据 $h_t$ 的错误率 $\epsilon_t$ 计算其权重：<script type="math/tex; mode=display">
\alpha_t = \frac{1}{2} \ln \left( \frac{1 - \epsilon_t}{\epsilon_t} \right)</script></li>
<li><strong>更新样本权重</strong>：提高被 $h_t$ 错分类样本的权重，降低正确分类样本的权重。</li>
<li><strong>重复步骤 2-4</strong>，直到训练完成 $T$ 轮。</li>
</ol>
<h5 id="示例：二分类问题-1"><a href="#示例：二分类问题-1" class="headerlink" title="示例：二分类问题"></a><strong>示例：二分类问题</strong></h5><p>假设一个二分类任务，真实标签 $f(\boldsymbol{x}) \in {-1, +1}$，集成模型预测值 $H(\boldsymbol{x}) = \sum_{t=1}^T \alpha_t h_t(\boldsymbol{x})$：</p>
<ul>
<li>若 $H(\boldsymbol{x}) &gt; 0$，预测为 $+1$；</li>
<li>若 $H(\boldsymbol{x}) &lt; 0$，预测为 $-1$。</li>
</ul>
<p>此时，指数损失函数的值反映了模型对错误样本的惩罚程度：</p>
<ul>
<li>正确预测时，$e^{-f(\boldsymbol{x}) H(\boldsymbol{x})} \approx 0$；</li>
<li>错误预测时，$e^{-f(\boldsymbol{x}) H(\boldsymbol{x})} \gg 1$。</li>
</ul>
<h5 id="AdaBoost的算法流程"><a href="#AdaBoost的算法流程" class="headerlink" title="AdaBoost的算法流程"></a>AdaBoost的算法流程</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606172851748.png" alt="image-20250606172851748"></p>
<h5 id="重赋权法与重采样法"><a href="#重赋权法与重采样法" class="headerlink" title="重赋权法与重采样法"></a>重赋权法与重采样法</h5><p>在集成学习中，<strong>Boosting 算法的核心在于动态调整样本权重</strong> ，以逐步聚焦难分类样本。Boosting 主要通过两种方法实现样本权重的更新：<strong>重赋权法（re-weighting）</strong> 和 <strong>重采样法（re-sampling）</strong> 。</p>
<blockquote>
<p><strong>重赋权法</strong> : 对每个样本附加一个权重，这时涉及到样本属性与标签的计算，都需要乘上一个权值。 <strong>重采样法</strong> : 对于一些无法接受带权样本的及学习算法，适合用“重采样法”进行处理。方法大致过程是，根据各个样本的权重，对训练数据进行重采样，初始时样本权重一样，每个样本被采样到的概率一致，每次从N个原始的训练样本中按照权重有放回采样N个样本作为训练集，然后计算训练集错误率，然后调整权重，重复采样，集成多个基学习器。</p>
</blockquote>
<p>从偏差-方差分解来看：Boosting算法主要关注于降低偏差，每轮的迭代都关注于训练过程中预测错误的样本，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成学习器。</p>
<h5 id="拓展：Gradient-Boosting"><a href="#拓展：Gradient-Boosting" class="headerlink" title="拓展：Gradient Boosting"></a>拓展：Gradient Boosting</h5><p>任务分为分类，回归，聚类，降维等，而分类中还分为二分类和多分类</p>
<p>从AdaBoost的算法流程来看，标准的AdaBoost只适用于二分类问题。</p>
<p>通过改造AdaBoost对样本分类的限制和损失函数，可以实现多分类或回归问题，这样改造出来的算法框架成为<strong>Gradient Boosting</strong></p>
<h6 id="GBDT（Gradient-Boosting-Decision-Tree）与XGBoost"><a href="#GBDT（Gradient-Boosting-Decision-Tree）与XGBoost" class="headerlink" title="GBDT（Gradient Boosting Decision Tree）与XGBoost"></a><strong>GBDT（Gradient Boosting Decision Tree）与XGBoost</strong></h6><p><strong>1. GBDT 的核心思想</strong></p>
<p>GBDT 是基于<strong>梯度提升（Gradient Boosting）</strong>框架的集成学习方法，其特点包括：</p>
<ul>
<li><strong>基学习器</strong>：使用<strong>CART（分类与回归树）</strong>作为个体学习器。</li>
<li><strong>损失函数</strong>：<ul>
<li><strong>回归问题</strong>：平方损失（Squared Loss）：<script type="math/tex; mode=display">
\text{err}(H_t(\boldsymbol{x}), f(\boldsymbol{x})) = (H_t(\boldsymbol{x}) - f(\boldsymbol{x}))^2</script></li>
<li><strong>二分类问题</strong>：对数似然损失（Log-Likelihood Loss，类似逻辑回归）：<script type="math/tex; mode=display">
\text{err}(H_t(\boldsymbol{x}), f(\boldsymbol{x})) = \log(1 + \exp(-f(\boldsymbol{x}) H_t(\boldsymbol{x})))</script></li>
<li><strong>多分类问题</strong>：扩展为多分类对数损失。</li>
</ul>
</li>
</ul>
<p><strong>2. XGBoost 的定位</strong></p>
<p>XGBoost（eXtreme Gradient Boosting）是 GBDT 的一种<strong>高效实现和改进</strong>，类似于 LIBSVM 对 SVM 的优化关系。其核心目标是：</p>
<ul>
<li><strong>提升训练速度</strong>：通过<strong>并行计算</strong>、<strong>内存优化</strong>等工程技巧。</li>
<li><strong>增强模型性能</strong>：引入<strong>正则化项</strong>、<strong>缺失值处理</strong>、<strong>自适应学习率</strong>等改进。</li>
</ul>
<blockquote>
<p>XGBoost即eXtremeGradient Boosting的缩写，XGBoost与GBDT的关系可以类比为<br>LIBSVM和SVM的关系，即XGBoOst是GBDT的一种高效实现和改进。</p>
<p>它并非一个全新的算法框架，而是对标准 GBDT 进行了<strong>大量的工程优化和算法增强</strong>。</p>
</blockquote>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606175536310.png" alt="image-20250606175536310"></p>
<h4 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h4><p>Bagging是一种<strong>并行式</strong>的集成学习方法，即<strong>基学习器的训练之间没有前后顺序可以同时进行</strong></p>
<p>Bagging使用<strong>“有放回”采样的方式选取训练集</strong>，对于包含m个样本的训练集，进行m次有放回的随机采样操作，从而得到m个样本的采样集，这样训练集中有<strong>接近36.8%</strong>的样本没有被采到，可用作验证集来对泛化性能进行“包外估计”(out-of-bag estimate)。</p>
<p>按照相同的方式重复进行，我们就可以采集到T个包含m个样本的数据集，从而训练出<strong>T个基学习器</strong>，最终对<strong>这T个基学习器的输出进行结合</strong>。</p>
<h5 id="Bagging与Boosting的差异"><a href="#Bagging与Boosting的差异" class="headerlink" title="Bagging与Boosting的差异"></a>Bagging与Boosting的差异</h5><p>Boosting算法一大特点是串行，这样诚然可以降低模型的偏差，增强拟合能力，但是当数据过大时，一大缺点就是会降低学习效率</p>
<p>Bagging作为并行式的集成学习方法，通过综合多个基学习器的结果，可以增加学习效率</p>
<p>二者差异性：</p>
<p>1.对目标的拟合程度：Boosting对目标有更好的拟合能力（偏差小）；Bagging则偏差相对大一些</p>
<p>2.运行效率：由于并行的特点，Bagging的运行效率是大于Boosting的</p>
<p>3.泛化能力：由于Bagging每个学习器不会受其他学习器的影响，泛化能力（方差大）相对于Boosting</p>
<p>更好</p>
<h5 id="Bagging的算法流程"><a href="#Bagging的算法流程" class="headerlink" title="Bagging的算法流程"></a>Bagging的算法流程</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606182733022.png" alt="image-20250606182733022"></p>
<p>可以看出Bagging主要通过<strong>样本的扰动</strong>来增加基学习器之间的多样性，因此Bagging的基学习器应为那些对训练集十分敏感的不稳定学习算法，例如：神经网络与决策树等。</p>
<p>从偏差-方差分解来看，Bagging算法主要关注于降低方差，即通过多次重复训练提高稳定性。</p>
<p>不同于AdaBoost的是，Bagging可以十分简单地移植到多分类、回归等问题。总的说起来则是：<strong>AdaBoost关注于降低偏差，而Bagging关注于降低方差。</strong></p>
<h5 id="自助采样法（Bootstrap-Sampling）"><a href="#自助采样法（Bootstrap-Sampling）" class="headerlink" title="自助采样法（Bootstrap Sampling）"></a>自助采样法（Bootstrap Sampling）</h5><p>在机器学习中，<strong>自助采样法（Bootstrap Sampling）</strong> 是 Bagging 算法的核心技术之一。其核心思想是从原始数据集中有放回地随机抽取样本，形成新的训练子集。这一过程的一个重要数学性质是：当样本量 $n$ 趋近于无穷大时，每个样本在 Bootstrap 样本集中<strong>未被抽中</strong>的概率趋近于 $\frac{1}{e} \approx 36.6\%$。以下是详细解析：</p>
<p><strong>1. 公式推导</strong></p>
<p>假设我们从 $n$ 个样本中<strong>有放回地</strong>抽取 $n$ 次，形成一个 Bootstrap 样本集。对于任意一个特定样本（如第 $i$ 个样本），它在某次抽样中<strong>未被选中</strong>的概率为：</p>
<script type="math/tex; mode=display">
1 - \frac{1}{n}</script><p>因此，它在整个 $n$ 次抽样中<strong>从未被选中</strong>的概率为：</p>
<script type="math/tex; mode=display">
\left(1 - \frac{1}{n}\right)^n</script><p>当 $n \to \infty$ 时，该概率的极限为：</p>
<script type="math/tex; mode=display">
\lim_{n \to \infty} \left(1 - \frac{1}{n}\right)^n = \frac{1}{e} \approx 0.3679 \quad (\text{即 } 36.6\%)</script><p>在每次 Bootstrap 采样中，约有 <strong>36.6% 的样本未被选中</strong> ，这些样本称为 <strong>Out-of-Bag（OOB，包外估计）样本</strong> 。</p>
<p><strong>2. OOB 样本的应用</strong></p>
<p>在 Bagging 算法中，OOB 样本具有以下重要作用：</p>
<ol>
<li><strong>无偏验证</strong>：<br>每个基学习器的训练数据不包含其对应的 OOB 样本，因此可以用这些样本直接评估模型性能（即 OOB 误差），无需额外的交叉验证。</li>
<li><strong>特征重要性评估</strong>：<br>在随机森林中，通过比较 OOB 样本在打乱某个特征后的预测误差变化，可以衡量该特征的重要性。</li>
</ol>
<p><strong>3. 与其他采样方法的对比</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>采样方法</strong></th>
<th><strong>是否放回</strong></th>
<th><strong>样本覆盖范围</strong></th>
<th><strong>典型应用场景</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Bootstrap 采样</strong></td>
<td>是</td>
<td>约 63.4% 样本被重复使用</td>
<td>Bagging、随机森林</td>
</tr>
<tr>
<td><strong>简单随机采样</strong></td>
<td>否</td>
<td>所有样本唯一出现</td>
<td>传统交叉验证</td>
</tr>
</tbody>
</table>
</div>
<h5 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h5><p>随机森林（Random Forest）是Bagging的一个拓展体，它的基学习器固定为<strong>决策树</strong>，多棵树也就组成了森林，而<strong>“随机”则在于选择划分属性的随机</strong>，随机森林在训练基学习器时，也采用有放回采样的方式添加样本扰动，同时它还引入了一种<strong>属性扰动</strong>，即在基决策树的训练过程中，在选择划分属性时，RF先从候选属性集中随机挑选出一个包含K个属性的子集，再从这个子集中选择最优划分属性 。</p>
<p>这样随机森林中基学习器的<strong>多样性不仅来自样本扰动，还来自属性扰动</strong>，从而进一步提升了基学习器之间的差异度。相比决策树的Bagging集成，随机森林的起始性能较差（由于属性扰动，基决策树的准确度有所下降），但随着基学习器数目的增多，随机森林往往会收敛到更低的泛化误差。同时不同于Bagging中决策树从所有属性集中选择最优划分属性，<strong>随机森林只在属性集的一个子集中选择划分属性，因此训练效率更高</strong>。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606184958951.png" alt="image-20250606184958951"></p>
<h4 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h4><p>在集成学习中，结合策略是将多个基学习器的输出整合为最终预测结果的关键步骤。以下是针对回归和分类问题的不同结合策略及其核心要点：</p>
<p><strong>定义</strong>：在训练好多个基学习器后，如何将其输出组合成集成模型的最终输出。</p>
<h5 id="1-平均法（回归问题）"><a href="#1-平均法（回归问题）" class="headerlink" title="1.平均法（回归问题）"></a><strong>1.平均法（回归问题）</strong></h5><ol>
<li><p><strong>简单平均法（Simple Averaging）</strong>  </p>
<ul>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
H(x) = \frac{1}{T} \sum_{i=1}^{T} h_i(x)</script></li>
<li><strong>特点</strong>：  <ul>
<li>直接对所有基学习器的预测结果取算术平均。  </li>
<li>计算简单，适合基学习器性能相近的场景。  </li>
<li>若部分基学习器表现较差，可能拖累整体性能。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>加权平均法（Weighted Averaging）</strong>  </p>
<ul>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
H(x) = \sum_{i=1}^{T} w_i h_i(x)</script>其中，$ w<em>i \geq 0 $ 且 $ \sum</em>{i=1}^{T} w_i = 1 $。  </li>
<li><strong>特点</strong>：  <ul>
<li>通过权重 $ w_i $ 调节各基学习器的贡献，灵活性更高。  </li>
<li>适用于基学习器性能差异较大的情况，可提升鲁棒性。  </li>
<li>权重可通过验证集性能（如RMSE、MAE）或优化算法（如梯度下降）确定。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h5 id="2-投票法（分类问题）"><a href="#2-投票法（分类问题）" class="headerlink" title="2.投票法（分类问题）"></a><strong>2.投票法（分类问题）</strong></h5><ol>
<li><p><strong>简单投票法（Majority Voting）</strong>  </p>
<ul>
<li><strong>原理</strong>：<br>每个基学习器对样本进行分类投票，最终结果由得票最多的类别决定。  </li>
<li><strong>公式</strong>（二分类示例）：  <script type="math/tex; mode=display">
H(x) = 
\begin{cases} 
1 & \text{若} \sum_{i=1}^{T} I(h_i(x) = 1) > T/2 \\
0 & \text{否则}
\end{cases}</script>其中，$ I(\cdot) $ 为指示函数。  </li>
<li><strong>特点</strong>：  <ul>
<li>简单高效，适合基学习器性能相近的场景。  </li>
<li>对异常分类器的鲁棒性较弱。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>加权投票法（Weighted Voting）</strong>  </p>
<ul>
<li><strong>原理</strong>：<br>给不同基学习器分配权重，最终结果由加权票数最高的类别决定。  </li>
<li><strong>公式</strong>（二分类示例）：  <script type="math/tex; mode=display">
H(x) = 
\begin{cases} 
1 & \text{若} \sum_{i=1}^{T} w_i I(h_i(x) = 1) > 0.5 \sum_{i=1}^{T} w_i \\
0 & \text{否则}
\end{cases}</script></li>
<li><strong>特点</strong>：  <ul>
<li>权重可根据基学习器的验证集准确率或领域知识设定。  </li>
<li>更适合处理性能差异较大的基学习器。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>绝对多数投票法（majority voting）提供了拒绝选项，这在可靠性要求很高的学习任务中是一个很好的机制。同时，对于分类任务，各个基学习器的输出值有两种类型，分别为类标记和类概率。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606195241433.png" alt="image-20250606195241433"></p>
<p>一些在产生类别标记的同时也生成置信度的学习器，置信度可转化为类概率使用，<strong>一般基于类概率进行结合往往比基于类标记进行结合的效果更好</strong>，需要注意的是对于异质集成，其类概率不能直接进行比较，此时需要将类概率转化为类标记输出，然后再投票。</p>
<h5 id="3-学习法（Stacking）"><a href="#3-学习法（Stacking）" class="headerlink" title="3.学习法（Stacking）"></a><strong>3.学习法（Stacking）</strong></h5><p><strong>学习法</strong>是一种更高级的结合策略，其核心思想是通过训练一个<strong>次级学习器（Meta-Learner）</strong> 来动态融合多个基学习器的输出。其中，<strong>Stacking（堆叠泛化）</strong> 是学习法的典型代表，它通过将基学习器的预测结果作为新特征，进一步训练一个次级模型，最终实现更优的泛化性能。</p>
<p><strong>Stacking 的基本原理</strong></p>
<p><strong>步骤概述</strong>：  </p>
<ul>
<li><strong>训练基学习器</strong>：使用原始数据训练 $ T $ 个基学习器（如决策树、SVM、神经网络等）。  </li>
<li><strong>生成新特征</strong>：对于每个样本，将 $ T $ 个基学习器的输出（预测结果）作为该样本的新特征，形成一个 $ m \times T $ 的数据集（$ m $ 为样本数量）。  </li>
<li><strong>训练次级学习器</strong>：使用新数据集（基学习器输出 + 真实标签）训练一个次级学习器（如逻辑回归、梯度提升树等），该学习器负责融合基学习器的预测结果。  </li>
</ul>
<p><strong>Stacking 的优势</strong></p>
<ol>
<li><strong>动态权重分配</strong>：<br>次级学习器可以自动学习基学习器的权重，无需人工设定。例如，若某个基学习器表现优异，次级学习器会赋予其更高的权重。  </li>
<li><strong>异质模型融合</strong>：<br>可以混合不同类型的基学习器（如线性模型与树模型），充分利用各自的特性。  </li>
<li><strong>提升泛化能力</strong>：<br>次级学习器通过学习基学习器的输出模式，能够捕捉更复杂的决策边界。</li>
</ol>
<p><strong>Stacking 的实现细节</strong></p>
<ol>
<li><p><strong>数据划分</strong>：  </p>
<ul>
<li>通常需将原始数据分为两部分：  <ul>
<li><strong>训练集</strong>：用于训练基学习器。  </li>
<li><strong>验证集</strong>：用于生成基学习器的输出（避免过拟合）。  </li>
</ul>
</li>
<li>或采用交叉验证（如 $ k $-折）生成基学习器的预测结果，确保次级学习器的训练数据不被污染。</li>
</ul>
</li>
<li><p><strong>基学习器输出类型</strong>：  </p>
<ul>
<li><strong>分类任务</strong>：基学习器输出类概率（Soft Voting），而非类别标签（Hard Voting）。例如，逻辑回归输出 $ P(c_j | x) $，随机森林输出节点样本的类别分布。  </li>
<li><strong>回归任务</strong>：基学习器直接输出预测值（如线性回归的 $\hat{y}$）。</li>
</ul>
</li>
<li><p><strong>次级学习器选择</strong>：  </p>
<ul>
<li><strong>多响应线性回归（MLR）</strong>：适用于基学习器输出可加权平均的情况，计算简单且鲁棒。  <script type="math/tex; mode=display">
H(x) = \sum_{i=1}^{T} w_i h_i(x)</script></li>
<li><strong>复杂模型</strong>：如梯度提升树、神经网络，可捕捉基学习器输出之间的非线性关系。  </li>
</ul>
</li>
</ol>
<h4 id="多样性"><a href="#多样性" class="headerlink" title="多样性"></a>多样性</h4><p>在集成学习中，<strong>多样性增强（Diversity Enhancement）</strong> 是提升模型性能的关键策略。通过引入多样性，可以降低基学习器之间的相关性，从而减少误差传递和过拟合风险。以下是四种常见的多样性增强方法及其核心要点：</p>
<p><strong>1. 数据样本扰动（Data Perturbation）</strong></p>
<p><strong>原理</strong>：通过修改训练数据的分布或采样方式，使每个基学习器看到不同的数据子集。  </p>
<p><strong>实现方式</strong>：  </p>
<ul>
<li><strong>Bagging（如随机森林）</strong>：  <ul>
<li>随机有放回地采样（Bootstrap），生成多个不同的训练集。  </li>
<li>对输入扰动敏感的基学习器（如决策树、神经网络）效果显著。  </li>
</ul>
</li>
<li><strong>示例</strong>：  <ul>
<li>决策树对数据扰动敏感，Bagging 可有效提升其泛化能力。  </li>
<li>线性模型（如线性回归、SVM）对数据扰动不敏感，Bagging 效果有限。  </li>
</ul>
</li>
</ul>
<p><strong>2. 输入属性扰动（Input Attribute Perturbation）</strong></p>
<p><strong>原理</strong>：通过改变输入特征的表示或选择，增加基学习器间的差异。  </p>
<p><strong>实现方式</strong>：  </p>
<ul>
<li><strong>特征子集采样</strong>：每次随机选择部分特征进行训练（如随机森林中的列扰动）。  </li>
<li><strong>特征变换</strong>：对特征进行缩放、旋转或加噪声等操作。  </li>
<li><strong>适用场景</strong>：  <ul>
<li>数据包含大量冗余属性时，可大幅加速训练并提升多样性。  </li>
<li>对高维数据（如图像、文本）尤其有效。  </li>
</ul>
</li>
</ul>
<p><strong>3. 输出属性扰动（Output Attribute Perturbation）</strong></p>
<p><strong>原理</strong>：通过修改训练样本的标签，间接影响基学习器的学习过程。  </p>
<p><strong>实现方式</strong>：  </p>
<ul>
<li><strong>随机翻转标签</strong>：对部分样本的标记进行随机更改（需谨慎使用，避免干扰模型）。  </li>
<li><strong>Dropout（神经网络）</strong>：  <ul>
<li>在训练过程中随机“关闭”部分神经元，强制网络学习更鲁棒的特征。  </li>
<li>类似于对输出属性的随机扰动，可提升模型泛化能力。  </li>
</ul>
</li>
</ul>
<p><strong>4. 算法参数扰动（Algorithm Parameter Perturbation）</strong></p>
<p><strong>原理</strong>：通过调整基学习器的超参数，生成不同的模型行为。  </p>
<p><strong>实现方式</strong>：  </p>
<ul>
<li><strong>正则化方法</strong>：L1/L2 正则化（如 Ridge、Lasso）限制模型复杂度，降低过拟合风险。 </li>
<li><strong>随机初始化</strong>：  神经网络的随机权重初始化可能导致收敛到不同局部最优解。  </li>
</ul>
<h4 id="作业-1"><a href="#作业-1" class="headerlink" title="作业"></a>作业</h4><h5 id="1-1"><a href="#1-1" class="headerlink" title="1"></a>1</h5><p>集成学习中常见的两种方法是什么？请分别介绍它们的原理和特点。集成学习相比于单个模型有什么优势和应用场景？</p>
<p><strong>集成学习常见方法、原理、特点及优势</strong></p>
<p><strong>常见方法</strong>：Bagging 和 Boosting<br><strong>原理与特点</strong>：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>原理</strong></th>
<th><strong>特点</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Bagging</strong></td>
<td>1. <strong>自助采样</strong>：从训练集有放回抽取多个子集<br>2. <strong>并行训练</strong>基模型<br>3. <strong>聚合预测</strong>（投票/平均）</td>
<td>- 降低方差<br>- 适合高方差模型（如未剪枝决策树）<br>- 并行化，训练快<br>- 代表：随机森林</td>
</tr>
<tr>
<td><strong>Boosting</strong></td>
<td>1. <strong>顺序训练</strong>：后一个模型修正前一个模型的错误<br>2. <strong>加权困难样本</strong><br>3. <strong>加权组合</strong>模型</td>
<td>- 降低偏差<br>- 需弱学习器（如树桩）<br>- 易过拟合（需正则化）<br>- 代表：AdaBoost, GBDT, XGBoost</td>
</tr>
</tbody>
</table>
</div>
<p><strong>集成学习的优势</strong>：  </p>
<ul>
<li><strong>提升泛化能力</strong>：降低过拟合（Bagging）或欠拟合（Boosting）风险  </li>
<li><strong>增强鲁棒性</strong>：减少异常值/噪声影响（如投票机制）  </li>
<li><strong>突破性能上限</strong>：组合多个弱模型达到强模型效果  </li>
</ul>
<p><strong>应用场景</strong>：  </p>
<ul>
<li><strong>分类任务</strong>：医疗诊断（整合多模型减少误诊）  </li>
<li><strong>回归任务</strong>：房价预测（融合不同树模型提升精度）  </li>
<li><strong>不平衡数据</strong>：Boosting 加权少数类样本  </li>
<li><strong>高维数据</strong>：随机森林自动特征选择  </li>
</ul>
<h5 id="2-1"><a href="#2-1" class="headerlink" title="2"></a>2</h5><p>如果在完全相同的训练集上训练了五个不同的模型，并且它们都达到了95%的准确率，是否还有机会通过结合这些模型来获得更好的结果？如果可以，该怎么做？如果不行，为什么？</p>
<p><strong>模型结合提升性能的可能性与方法</strong></p>
<p><strong>是否可能提升</strong>：<strong>是</strong>，但需满足条件：<strong>模型错误不相关</strong>（即犯错样本不同）。  </p>
<p><strong>如何实现</strong>：  </p>
<ol>
<li><strong>投票法（分类）</strong>：  <ul>
<li>多数投票：5个模型对样本 (x) 的预测为 ([A, A, B, A, C]) → 最终输出 (A)  </li>
<li><strong>关键要求</strong>：模型存在<strong>多样性</strong>（如使用SVM、决策树等不同算法）  </li>
</ul>
</li>
<li><strong>加权平均（回归）</strong>：  <ul>
<li>若模型精度不同，分配权重：$ y_{\text{final}} = w_1 y_1 + w_2 y_2 + \dots + w_5 y_5$</li>
<li>权重可通过验证集性能确定  </li>
</ul>
</li>
</ol>
<p><strong>若无法提升的情况</strong>：  </p>
<ul>
<li><strong>原因</strong>：模型高度相关（如相同算法、相同特征、相同超参）  </li>
<li><strong>数学解释</strong>：误差相关性 $rho \approx 1$ 时，集成误差 $\approx$单一模型误差  </li>
</ul>
<h5 id="3-1"><a href="#3-1" class="headerlink" title="3"></a>3</h5><p>是否可以通过在多个服务器上并行来加速随机森林的训练？AdaBoost集成呢？为什么？</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>算法</strong></th>
<th><strong>是否支持并行</strong></th>
<th><strong>原因</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>随机森林</strong></td>
<td>✅ <strong>是</strong></td>
<td>1. 树之间独立训练<br>2. 可分布式分配Bootstrap样本到不同服务器<br>3. 特征分裂也可并行（如选特征子集）</td>
</tr>
<tr>
<td><strong>AdaBoost</strong></td>
<td>❌ <strong>否</strong></td>
<td>1. 模型必须<strong>顺序训练</strong>：后一个模型依赖前一个模型的样本权重更新<br>2. 无法解耦迭代过程</td>
</tr>
</tbody>
</table>
</div>
<h3 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h3><h4 id="聚类任务"><a href="#聚类任务" class="headerlink" title="聚类任务"></a><strong>聚类任务</strong></h4><blockquote>
<p>我们之前学习的分类/回归任务都属于 有监督学习 需要我们提供样本与标签</p>
<p>而马上要学习的聚类任务和后续学习的降维则属于 无监督学习 仅需提供样本</p>
</blockquote>
<p>聚类是一种经典的<strong>无监督学习</strong>(unsupervised learning)方法，<strong>无监督学习的目标是通过对无标记训练样本的学习，发掘和揭示数据集本身潜在的结构与规律</strong>，即不依赖于训练数据集的类标记信息。</p>
<p>聚类试图将数据集中的样本划分为若干个通常是不相交的子集,<strong>每个子集称为一个“簇”( cluster)</strong>。通过这样的划分,每簇可能对应于一些潜在的概念(类别),如“浅色瓜”“深色瓜”,“有籽瓜”“无籽瓜”,甚至“本地瓜”“外地瓜”等;需说明的是,这些概念对聚类算法而言事先是未知的,聚类过程仅能自动形成簇结构, <strong>簇所对应的概念语义需由使用者来把握和命名</strong>。</p>
<p>直观上来说，聚类是将相似的样本聚在一起，从而形成一个<strong>类簇（cluster）</strong>。涉及两个问题</p>
<ul>
<li>如何<strong>度量相似性</strong>（similarity measure），这便是<strong>距离度量</strong>(distance measure)，在生活中我们说差别小则相似，对应到多维样本，每个样本可以对应于高维空间中的一个数据点，若它们的距离相近，我们便可以称它们相似。</li>
<li>如何<strong>评价聚类结果</strong>，这便是<strong>性能度量</strong>(validity index)</li>
</ul>
<h4 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h4><h5 id="连续-离散有序"><a href="#连续-离散有序" class="headerlink" title="连续/离散有序"></a>连续/离散有序</h5><p><strong>明可夫斯基距离（Minkowski Distance）</strong></p>
<p>明可夫斯基距离是一组常用的<strong>连续型距离度量</strong>，通过调整参数 $ p $ 可以统一表示多种距离形式，是欧氏距离和曼哈顿距离的推广。</p>
<p><strong>1. 公式定义</strong></p>
<p>对于两个 $ n $ 维向量 $ \boldsymbol{x}<em>i = (x</em>{i1}, x<em>{i2}, \dots, x</em>{in}) $ 和 $ \boldsymbol{x}<em>j = (x</em>{j1}, x<em>{j2}, \dots, x</em>{jn}) $，明可夫斯基距离的计算公式为：</p>
<script type="math/tex; mode=display">
\text{dist}_{\text{mk}}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \left( \sum_{u=1}^{n} |x_{iu} - x_{ju}|^p \right)^{\frac{1}{p}}</script><p>其中，$ p \geq 1 $ 是一个可调节的参数。</p>
<p><strong>2. 特殊情况</strong></p>
<ul>
<li><p><strong>当 $ p = 2 $</strong>：退化为<strong>欧氏距离（Euclidean Distance）</strong>  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{ed}}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \sqrt{\sum_{u=1}^{n} |x_{iu} - x_{ju}|^2}</script><ul>
<li><strong>几何意义</strong>：两点之间的直线距离。  </li>
<li><strong>适用场景</strong>：大多数机器学习算法（如KNN、PCA）默认使用欧氏距离。</li>
</ul>
</li>
<li><p><strong>当 $ p = 1 $</strong>：退化为<strong>曼哈顿距离（Manhattan Distance）</strong>  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{man}}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \sum_{u=1}^{n} |x_{iu} - x_{ju}|</script><ul>
<li><strong>几何意义</strong>：沿坐标轴移动的总距离（如棋盘格路径）。  </li>
<li><strong>适用场景</strong>：高维稀疏数据（如文本特征）、计算资源受限的场景。</li>
</ul>
</li>
<li><p><strong>当 $ p \to \infty $</strong>：退化为<strong>切比雪夫距离（Chebyshev Distance）</strong>  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{che}}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \max_{u} |x_{iu} - x_{ju}|</script><ul>
<li><strong>几何意义</strong>：各维度差值的最大值。  </li>
<li><strong>适用场景</strong>：关注最坏情况下的误差（如游戏AI路径规划）。</li>
</ul>
</li>
</ul>
<p><strong>3. 参数 $ p $ 的影响</strong></p>
<ul>
<li><strong>$ p $ 越小</strong>：距离计算越关注较小的维度差异（如曼哈顿距离对单个维度的扰动更敏感）。  </li>
<li><strong>$ p $ 越大</strong>：距离计算越关注较大的维度差异（如切比雪夫距离仅关注最大差值）。  </li>
<li><strong>选择依据</strong>：  <ul>
<li>数据分布是否均匀：若某些维度差异显著，可增大 $ p $。  </li>
<li>算法需求：如KNN中，高维数据可能更适合曼哈顿距离（缓解“维度灾难”）。</li>
</ul>
</li>
</ul>
<h5 id="离散无序"><a href="#离散无序" class="headerlink" title="离散无序"></a>离散无序</h5><p>我们知道属性分为两种：<strong>连续属性</strong>(continuous attribute)和<strong>离散属性</strong>（catergorical attribute有限个取值）。对于连续值的属性，一般都可以被学习器所用，有时会根据具体的情形作相应的预处理，例如：归一化等；而对于离散值的属性，需要作下面进一步的处理：</p>
<blockquote>
<p>若属性值之间<strong>存在序关系</strong>(ordinal attribute)，则可以将其转化为连续值，例如：身高属性“高”“中等”“矮”，可转化为{1, 0.5, 0}。 </p>
<p>若属性值之间<strong>不存在序关系</strong>(non-ordinal attribute)，则通常将其转化为向量的形式，例如：性别属性“男”“女”，可转化为{（1,0）,（0,1）}。</p>
</blockquote>
<p><strong>连续属性和存在序关系的离散属性都可以直接参与计算</strong>，而不存在序关系的<strong>无序属性，我们一般采用VDM（Value Difference Metric）进行距离的计算</strong></p>
<p>VDM 是一种专门用于<strong>离散无序属性</strong>的距离度量方法，通过统计信息量化不同类别间的差异。其核心思想是：<strong>若两个类别的样本在目标变量上的分布差异越大，则它们的距离越大</strong>。</p>
<p><strong>1. 公式解析</strong></p>
<script type="math/tex; mode=display">
\text{VDM}_p(a, b) = \sum_{i=1}^{k} \left| \frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}} \right|^p</script><ul>
<li><strong>符号含义</strong>：  <ul>
<li>$ a, b $：两个不同的类别值（如性别“男”和“女”）。  </li>
<li>$ m_{u,a,i} $：在属性 $ u $ 的第 $ i $ 个取值下，类别 $ a $ 的样本数量。  </li>
<li>$ m_{u,a} $：类别 $ a $ 的总样本数量。  </li>
<li>$ k $：属性 $ u $ 的不同取值数目（如颜色属性有红、蓝、绿三种取值，则 $ k=3 $）。  </li>
<li>$ p $：距离幂指数（通常取 $ p=1 $ 或 $ p=2 $）。</li>
</ul>
</li>
</ul>
<p><strong>2. 核心思想</strong></p>
<ul>
<li><strong>统计分布差异</strong>：<br>对于每个属性取值 $ i $，计算类别 $ a $ 和 $ b $ 的样本比例差异：  <script type="math/tex; mode=display">
\left| \frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}} \right|</script>该值越大，说明两个类别在该取值上的分布差异越大。  </li>
<li><strong>加权求和</strong>：<br>将所有属性取值的差异按 $ p $ 次方加权求和，得到最终的距离。</li>
</ul>
<p><strong>3. 示例说明</strong></p>
<p>假设我们有一个“颜色”属性（红、蓝、绿），目标变量是“是否购买商品”（0/1）。统计结果如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>颜色</th>
<th>购买（1）</th>
<th>不购买（0）</th>
<th>总计</th>
</tr>
</thead>
<tbody>
<tr>
<td>红</td>
<td>10</td>
<td>5</td>
<td>15</td>
</tr>
<tr>
<td>蓝</td>
<td>8</td>
<td>12</td>
<td>20</td>
</tr>
<tr>
<td>绿</td>
<td>3</td>
<td>7</td>
<td>10</td>
</tr>
</tbody>
</table>
</div>
<p>计算“红”与“蓝”之间的 VDM 距离（$ p=1 $）：</p>
<ol>
<li>计算每个颜色在购买/不购买的比例：  <ul>
<li>红：$ P(1) = 10/15 \approx 0.67 $，$ P(0) = 5/15 \approx 0.33 $  </li>
<li>蓝：$ P(1) = 8/20 = 0.4 $，$ P(0) = 12/20 = 0.6 $  </li>
</ul>
</li>
<li>计算差异并求和：  <script type="math/tex; mode=display">
\text{VDM}_1(\text{红}, \text{蓝}) = |0.67 - 0.4| + |0.33 - 0.6| = 0.27 + 0.27 = 0.54</script></li>
</ol>
<h4 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h4><p>于聚类算法不依赖于样本的真实类标，就不能像监督学习的分类那般，通过计算分对分错（即精确度或错误率）来评价学习器的好坏或作为学习过程中的优化目标。</p>
<p>直观上看,我们希望<strong>“物以类聚”</strong>,即同一簇的样本尽可能彼此相似,不同簇的样本尽可能不同换言之,聚类结果的<strong>“簇内相似度”( intra-cluster similarity)高且“簇间相似度” inter-cluster similarity)低</strong></p>
<p><strong>聚类性能度量有两类</strong></p>
<ul>
<li>“外部指标”(external index)：所谓外部指标就是已经有一个“参考模型”存在了，将当前模型与参考模型的比对结果作为指标。</li>
<li>“内部指标”( internal index)：所谓内部指标就是仅仅考虑当前模型的聚类结果。</li>
</ul>
<h5 id="外部指标"><a href="#外部指标" class="headerlink" title="外部指标"></a>外部指标</h5><p><strong>1.基本概念</strong></p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607110103570.png" alt="image-20250607110103570"></p>
<p>显然，$ a + b + c + d = \frac{m(m-1)}{2} $ 。</p>
<p><strong>2. 常用外部指标</strong></p>
<p><strong>（1）Jaccard系数（JC）</strong></p>
<script type="math/tex; mode=display">
\text{JC} = \frac{a}{a + b + c}</script><ul>
<li><strong>含义</strong>：衡量两个划分的重叠程度，仅考虑正确匹配（$ a $）与矛盾情况（$ b + c $）。  </li>
<li><strong>范围</strong>：$ [0, 1] $，值越大越好。  </li>
<li><strong>特点</strong>：对称性差，对噪声敏感 。</li>
</ul>
<p><strong>（2）Fowlkes-Mallows指数（FMI）</strong></p>
<script type="math/tex; mode=display">
\text{FMI} = \sqrt{\frac{a}{a + b} \cdot \frac{a}{a + c}}</script><ul>
<li><strong>含义</strong>：结合查准率（$ \frac{a}{a + c} $）和查全率（$ \frac{a}{a + b} $），反映正确匹配的综合能力。  </li>
<li><strong>范围</strong>：$ [0, 1] $，值越大越好。  </li>
<li><strong>特点</strong>：平衡性较好，适合小样本 。</li>
</ul>
<p><strong>（3）Rand指数（RI）</strong></p>
<script type="math/tex; mode=display">
\text{RI} = \frac{2(a + d)}{m(m - 1)}</script><ul>
<li><strong>含义</strong>：同时考虑正确匹配（$ a + d $）与总样本对数，适用于大规模数据。  </li>
<li><strong>范围</strong>：$ [0, 1] $，值越大越好。  </li>
<li><strong>特点</strong>：计算简单，但对噪声较鲁棒 。</li>
</ul>
<p><strong>常用指标</strong></p>
<ul>
<li><p><strong>调整兰德指数（Adjusted Rand Index, ARI）</strong>  </p>
<ul>
<li><strong>定义</strong>：衡量聚类结果与真实标签的匹配程度，调整随机聚类的影响，取值范围 [-1, 1]，值越大越好。  </li>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
\text{ARI} = \frac{\text{RI} - \mathbb{E}[\text{RI}]}{\max(\text{RI}) - \mathbb{E}[\text{RI}]}</script>其中 RI 是兰德指数（匹配样本对的比例）。</li>
</ul>
</li>
<li><p><strong>归一化互信息（Normalized Mutual Information, NMI）</strong>  </p>
<ul>
<li><strong>定义</strong>：衡量聚类结果与真实标签的信息共享程度，值越大越好。  </li>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
\text{NMI} = \frac{I(C; K)}{\sqrt{H(C) H(K)}}</script>其中 $ I(C; K) $ 是互信息，$ H(C) $ 和 $ H(K) $ 是熵。</li>
</ul>
</li>
<li><p><strong>Fowlkes-Mallows 指数（FMI）</strong>  </p>
<ul>
<li><strong>定义</strong>：基于聚类结果与真实标签的 TP、FP、TN、FN 计算，值越大越好。  </li>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
\text{FMI} = \sqrt{\frac{\text{TP}}{\text{TP} + \text{FP}} \cdot \frac{\text{TP}}{\text{TP} + \text{FN}}}</script></li>
</ul>
</li>
</ul>
<p><strong>优点</strong></p>
<ul>
<li>在有真实标签时，能更客观地评估聚类效果。</li>
<li>适用于验证聚类结果的业务意义（如客户分群是否符合预期）。</li>
</ul>
<p><strong>局限性</strong></p>
<ul>
<li>需要真实标签，不适用于纯无监督任务。</li>
<li>对标签噪声敏感（如标签错误会误导 $ K $ 的选择）。</li>
</ul>
<p><strong>3. 应用示例</strong></p>
<p>假设一个包含4个样本的数据集，参考标签为 ${A, A, B, B}$，聚类结果为 ${C, C, D, D}$：</p>
<ul>
<li><strong>计算样本对</strong>：  <ul>
<li>$ a = 2 $（样本1-2同簇，参考与聚类均同类）。  </li>
<li>$ b = 0 $（参考同类但聚类不同类）。  </li>
<li>$ c = 0 $（参考不同类但聚类同类）。  </li>
<li>$ d = 2 $（参考不同类且聚类不同类）。  </li>
</ul>
</li>
<li><strong>指标结果</strong>：  <ul>
<li>JC = $ \frac{2}{2+0+0} = 1 $（完美匹配）。  </li>
<li>FMI = $ \sqrt{\frac{2}{2+0} \cdot \frac{2}{2+0}} = 1 $。  </li>
<li>RI = $ \frac{2(2+2)}{4 \times 3} = \frac{8}{12} \approx 0.67 $。</li>
</ul>
</li>
</ul>
<h5 id="内部指标"><a href="#内部指标" class="headerlink" title="内部指标"></a>内部指标</h5><p>内部指标不依赖任何外部参考模型，直接通过<strong>簇内紧凑性</strong>和<strong>簇间分离性</strong>评估聚类结果。其核心思想是：</p>
<ul>
<li><strong>簇内高内聚</strong>：同一簇的样本尽可能相似（距离小）。  </li>
<li><strong>簇间低耦合</strong>：不同簇的样本尽可能不同（距离大）。</li>
</ul>
<p><strong>1. 基本定义</strong></p>
<p>设聚类结果为 $ C = {C_1, C_2, \dots, C_k} $，定义以下四个关键距离：</p>
<p><strong>（1）簇内平均距离（avg(C)）</strong></p>
<script type="math/tex; mode=display">
\text{avg}(C) = \frac{2}{|C|(|C| - 1)} \sum_{1 \leq i < j \leq |C|} \text{dist}(\boldsymbol{x}_i, \boldsymbol{x}_j)</script><ul>
<li><strong>含义</strong>：簇内所有样本对的平均距离。  </li>
<li><strong>目标</strong>：越小越好，表示簇内样本更紧密。</li>
</ul>
<p><strong>（2）簇内最大距离（diam(C)）</strong></p>
<script type="math/tex; mode=display">
\text{diam}(C) = \max_{1 \leq i < j \leq |C|} \text{dist}(\boldsymbol{x}_i, \boldsymbol{x}_j)</script><ul>
<li><strong>含义</strong>：簇内最远的两个样本之间的距离。  </li>
<li><strong>目标</strong>：越小越好，避免簇内存在离群点。</li>
</ul>
<p><strong>（3）簇间最小距离（$ d_{\min}(C_i, C_j) $）</strong></p>
<script type="math/tex; mode=display">
d_{\min}(C_i, C_j) = \min_{\boldsymbol{x}_i \in C_i, \boldsymbol{x}_j \in C_j} \text{dist}(\boldsymbol{x}_i, \boldsymbol{x}_j)</script><ul>
<li><strong>含义</strong>：簇 $ C_i $ 和 $ C_j $ 之间最近的两个样本的距离。  </li>
<li><strong>目标</strong>：越大越好，表示簇间分离度高。</li>
</ul>
<p><strong>（4）簇中心距离（$ d_{\text{cen}}(C_i, C_j) $）</strong></p>
<script type="math/tex; mode=display">
d_{\text{cen}}(C_i, C_j) = \text{dist}(\boldsymbol{\mu}_i, \boldsymbol{\mu}_j)</script><ul>
<li><strong>含义</strong>：簇 $ C_i $ 和 $ C_j $ 的中心点（均值向量）之间的距离。  </li>
<li><strong>目标</strong>：越大越好，表示簇中心相隔较远。</li>
</ul>
<p><strong>2. 常用内部指标</strong></p>
<p><strong>1. DB指数（Davies-Bouldin Index, DBI）</strong></p>
<ul>
<li><p><strong>公式</strong>：  </p>
<script type="math/tex; mode=display">
\text{DBI} = \frac{1}{k} \sum_{i=1}^{k} \max_{j \neq i} \left( \frac{\text{avg}(C_i) + \text{avg}(C_j)}{d_{\text{cen}}(\mu_i, \mu_j)} \right)</script><ul>
<li><strong>符号含义</strong>：  <ul>
<li>$ k $：簇的数量。  </li>
<li>$ \text{avg}(C_i) $：簇 $ C_i $ 内部样本的平均距离。  </li>
<li>$ d_{\text{cen}}(\mu_i, \mu_j) $：簇 $ C_i $ 和 $ C_j $ 的中心点（均值向量）之间的距离。  </li>
</ul>
</li>
<li><strong>目标</strong>：越小越好。  </li>
<li><strong>核心思想</strong>：对于每个簇 $ C<em>i $，找到与其“最竞争”的簇 $ C_j $（即 $ \frac{\text{avg}(C_i) + \text{avg}(C_j)}{d</em>{\text{cen}}(\mu_i, \mu_j)} $ 最大的簇），并取所有簇的平均值。  </li>
</ul>
</li>
<li><p><strong>示例</strong>：<br>若簇 $ C_1 $ 和 $ C_2 $ 的平均距离分别为 2 和 3，中心距离为 5，则它们的比值为 $ \frac{2+3}{5} = 1 $。若这是 $ C_1 $ 的最大比值，则 $ C_1 $ 对 DBI 的贡献为 1。最终 DBI 是所有簇贡献的平均值。  </p>
</li>
</ul>
<p><strong>2. Dunn指数（Dunn Index, DI）</strong></p>
<ul>
<li><p><strong>公式</strong>：  </p>
<script type="math/tex; mode=display">
\text{DI} = \min_{1 \leq i \leq k} \left\{ \frac{\min_{j \neq i} d_{\min}(C_i, C_j)}{\max_{1 \leq l \leq k} \text{diam}(C_l)} \right\}</script><ul>
<li><strong>符号含义</strong>：  <ul>
<li>$ d_{\min}(C_i, C_j) $：簇 $ C_i $ 和 $ C_j $ 之间的最小距离（最近样本对的距离）。  </li>
<li>$ \text{diam}(C_l) $：簇 $ C_l $ 内的最大距离（最远样本对的距离）。  </li>
</ul>
</li>
<li><strong>目标</strong>：越大越好。  </li>
<li><strong>核心思想</strong>：  <ul>
<li>分子：所有簇对之间的最小距离中的最小值（即最“脆弱”的簇间分离度）。  </li>
<li>分母：所有簇中的最大直径（最“松散”的簇内紧凑度）。  </li>
<li>指数越大，表示簇间分离度高且簇内紧凑。  </li>
</ul>
</li>
</ul>
</li>
<li><p><strong>示例</strong>：<br>假设簇对 $ (C_1, C_2) $ 的最小距离为 5，簇 $ C_3 $ 的最大直径为 10，则 DI 为 $ \frac{5}{10} = 0.5 $。  </p>
</li>
</ul>
<p><strong>3. 轮廓系数（Silhouette Coefficient）</strong></p>
<ul>
<li><p><strong>单一样本的轮廓系数</strong>：  </p>
<script type="math/tex; mode=display">
s = \frac{b - a}{\max(a, b)}</script><ul>
<li><strong>符号含义</strong>：  <ul>
<li>$ a $：样本到同簇其他样本的平均距离（簇内凝聚度）。  </li>
<li>$ b $：样本到最近簇中样本的平均距离（簇间分离度）。  </li>
</ul>
</li>
<li><strong>取值范围</strong>：$ [-1, 1] $，越接近 1 表示聚类效果越好。  </li>
<li><strong>核心思想</strong>：  <ul>
<li>若 $ a &lt; b $（同簇紧密，异簇疏远），则 $ s &gt; 0 $，样本分类合理。  </li>
<li>若 $ a &gt; b $（同簇松散，异簇更近），则 $ s &lt; 0 $，样本可能被错误分类。  </li>
</ul>
</li>
</ul>
</li>
<li><p><strong>整体轮廓系数</strong>：所有样本轮廓系数的平均值。  </p>
</li>
<li><p><strong>示例</strong>：<br>若某样本 $ a = 2 $，$ b = 5 $，则 $ s = \frac{5-2}{5} = 0.6 $，表明该样本分类合理。  </p>
</li>
</ul>
<p><strong>4.肘部法则（Elbow Method）</strong></p>
<p>肘部法则是一种<strong>经验性方法</strong>，常用于确定K-means等聚类算法的最优簇数（$ K $）。其核心思想是通过观察误差平方和（SSE, Sum of Squared Errors）随 $ K $ 值变化的趋势，寻找“肘部点”（即 SSE 下降速度明显减缓的拐点），从而选择最优的 $ K $ 值</p>
<ul>
<li><p><strong>SSE（误差平方和）</strong>：衡量每个样本到其所属簇中心的距离平方和，公式为：</p>
<script type="math/tex; mode=display">
\text{SSE} = \sum_{i=1}^n \|x_i - \mu_{c_i}\|^2</script><p>其中 $ x<em>i $ 是样本点，$ \mu</em>{c_i} $ 是其所属簇中心。</p>
</li>
<li><p><strong>趋势分析</strong>：</p>
<ul>
<li>当 $ K $ 增大时，SSE 会不断减小（因为簇越多，每个簇的样本越密集）。</li>
<li>但当 $ K $ 增加到某个值后，SSE 的下降速度会显著放缓，形成“肘部”形状。</li>
</ul>
</li>
<li><p><strong>肘部点的意义</strong>：<br>肘部点对应的 $ K $ 值是<strong>模型复杂度</strong>（簇数）与<strong>聚类效果</strong>（SSE）之间的平衡点。</p>
</li>
</ul>
<p><strong>指标对比与选择</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>指标</strong></th>
<th><strong>计算方式</strong></th>
<th><strong>目标</strong></th>
<th><strong>适用场景</strong></th>
<th><strong>局限性</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>DBI</td>
<td>簇内平均距离与簇中心距离的比值</td>
<td>越小越好</td>
<td>球形簇，需指定 $ k $</td>
<td>对离群点敏感</td>
</tr>
<tr>
<td>Dunn指数</td>
<td>簇间最小距离与簇内最大直径的比值</td>
<td>越大越好</td>
<td>强调簇间分离与簇内紧凑</td>
<td>计算复杂，受离群点影响</td>
</tr>
<tr>
<td>轮廓系数</td>
<td>样本到同簇/异簇的平均距离差</td>
<td>越接近 1 越好</td>
<td>快速评估，适合 K-Means</td>
<td>对非球形簇不敏感</td>
</tr>
</tbody>
</table>
</div>
<h4 id="原型聚类与kmeans"><a href="#原型聚类与kmeans" class="headerlink" title="原型聚类与kmeans"></a>原型聚类与kmeans</h4><h5 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h5><p>原型聚类即“<strong>基于原型的聚类</strong>”（prototype-based clustering），原型表示模板的意思，就是通过参考一个模板向量或模板分布的方式来完成聚类的过程，通常情形下算法先对原型进行初始化,然后对原型进行迭代更新求解。采用不同的原型表、不同的求解方式,将产生不同的算法。</p>
<p>常见的K-Means便是基于簇中心（原型向量）来实现聚类，混合高斯聚类则是基于簇分布（概率模型）来实现聚类。</p>
<h5 id="K-Means-聚类算法详解"><a href="#K-Means-聚类算法详解" class="headerlink" title="K-Means 聚类算法详解"></a><strong>K-Means 聚类算法详解</strong></h5><p><strong>目标函数</strong>：最小化所有样本到其所属簇中心的平方距离之和：  </p>
<script type="math/tex; mode=display">
E = \sum_{i=1}^{k} \sum_{\boldsymbol{x} \in C_i} \|\boldsymbol{x} - \boldsymbol{\mu}_i\|_2^2</script><p>其中，$ \boldsymbol{\mu}<em>i = \frac{1}{|C_i|} \sum</em>{\boldsymbol{x} \in C_i} \boldsymbol{x} $ 是簇 $ C_i $ 的均值向量。</p>
<p><strong>算法步骤</strong></p>
<ol>
<li><strong>初始化簇中心</strong>：随机选择 $ k $ 个样本作为初始簇中心。  <ul>
<li><strong>改进方法</strong>：K-Means++ 算法可提升初始中心的质量。  </li>
</ul>
</li>
<li><strong>分配样本到最近簇</strong>：对每个样本 $ \boldsymbol{x} $，计算其到所有簇中心的距离，将其分配到距离最近的簇 $ C_i $。  </li>
<li><strong>更新簇中心</strong>：重新计算每个簇的均值向量 $ \boldsymbol{\mu}_i $。  </li>
<li><strong>迭代终止条件</strong>：  <ul>
<li>达到预设的最大迭代次数；  </li>
<li>簇中心不再显著变化（如变化幅度小于阈值 $ \epsilon $）；  </li>
<li>样本分配不再改变。</li>
</ul>
</li>
</ol>
<p><strong>如何选择 $ k $ 值？</strong></p>
<ul>
<li><strong>肘部法则（Elbow Method）</strong>：绘制 $ k $ 与误差 $ E $ 的关系曲线，选择误差下降显著变缓的 $ k $ 值。  </li>
<li><strong>轮廓系数（Silhouette Coefficient）</strong>：计算每个样本的轮廓系数，选择平均轮廓系数最大的 $ k $。  </li>
</ul>
<h5 id="K-Means的算法流程"><a href="#K-Means的算法流程" class="headerlink" title="K-Means的算法流程"></a>K-Means的算法流程</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607114743211.png" alt="image-20250607114743211"></p>
<h5 id="K-means"><a href="#K-means" class="headerlink" title="K-means++"></a>K-means++</h5><p>此法相对于 K-means 做出了一个小的改进。在一开始选择 k 个聚类中心时，并不是随机初始化 k 个，而是首先随机出 1 个，然后循环 k−1<em>k</em>−1 次选择剩下的 k-1 个聚类中心。选择的规则是：每次选择最不可能成为新的聚类中心的样本，或者是到所有聚类中心的最小距离最大的样本。</p>
<h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a><strong>优势</strong></h5><p><strong>避免不良初始化</strong> ：传统K-means随机初始化可能导致中心过于集中，而K-means++通过“最大化最小距离”策略，使初始中心分布更均匀。</p>
<h5 id="Bisecting-K-means"><a href="#Bisecting-K-means" class="headerlink" title="Bisecting K-means"></a>Bisecting K-means</h5><p>此法叫做二分 K-means 算法。具体的，在一开始将所有的样本划分为一个簇，然后每次选择一个误差最大的簇进行二分裂，不断分裂直到收敛。这种方法不能使得 Loss 最小，但是可以作为 K-means 算法的一个预热，比如可以通过这种方法得到一个相对合理的簇中心，然后再利用 K-means 算法进行聚类。</p>
<h5 id="优势-1"><a href="#优势-1" class="headerlink" title="优势"></a><strong>优势</strong></h5><p><strong>降低计算复杂度</strong> ：每次仅对一个簇进行二分，时间复杂度为 <em>O</em>(<em>k</em>⋅<em>m</em>⋅<em>n</em>) ，适合大规模数据。</p>
<p><strong>提供合理初始中心</strong> ：可作为传统K-means的预处理，减少随机初始化的影响。</p>
<h5 id="LVQ（学习向量量化）"><a href="#LVQ（学习向量量化）" class="headerlink" title="LVQ（学习向量量化）"></a><strong>LVQ（学习向量量化）</strong></h5><p><strong>核心思想</strong>：<br>LVQ 是一种<strong>有监督的原型聚类算法</strong>，结合了神经网络与向量量化技术。它通过维护一组<strong>原型向量</strong>（Prototype Vectors）来代表不同类别，并利用这些原型对数据进行分类或聚类。与 K-Means 类似，LVQ 会为每个簇分配一个原型向量，但其更新规则受类别标签的指导，因此更适用于分类任务 。</p>
<p><strong>算法特点</strong>：  </p>
<ul>
<li><strong>有监督学习</strong>：需要已知类别标签来调整原型向量，使同类样本更接近对应原型，异类样本远离原型。  </li>
<li><strong>拓扑结构建模</strong>：通过原型向量捕捉数据的局部特征，类似于自组织映射（SOM），但更具针对性。  </li>
<li><strong>硬聚类</strong>：每个样本最终被分配到最近的原型对应的类别，不提供概率输出 。</li>
</ul>
<h5 id="高斯混合聚类（Gaussian-Mixture-Model-GMM）"><a href="#高斯混合聚类（Gaussian-Mixture-Model-GMM）" class="headerlink" title="高斯混合聚类（Gaussian Mixture Model, GMM）"></a><strong>高斯混合聚类（Gaussian Mixture Model, GMM）</strong></h5><p> 一句话概述算法：高斯混合聚类算法是一种概率模型，假设数据由多个高斯分布混合而成，通过迭代优化参数以拟合数据分布，常用于无监督学习中的聚类任务。</p>
<p>算法过程：</p>
<p>初始化参数： 随机初始化每个分量的均值、协方差矩阵和混合系数。</p>
<p>E 步（Expectation）： 对每个数据点，计算它属于每个分量的后验概率，即计算每个分量的权重。</p>
<p>M 步（Maximization）： 使用E步计算得到的后验概率，更新每个分量的均值、协方差矩阵和混合系数。</p>
<p>迭代： 重复执行E步和M步，直到模型参数收敛或达到预定的迭代次数。</p>
<p>GMM的优点包括对各种形状和方向的聚类簇建模能力，以及对数据分布的灵活性。它在许多领域，如模式识别、图像处理和自然语言处理等，都有广泛的应用。<br><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250611180451162.png" alt="image-20250611180451162"></p>
<p>以下是高斯混合聚类（GMM）算法的详细步骤及EM算法中E步与M步的解释：</p>
<p><strong>算法流程解析</strong></p>
<p><strong>输入</strong>：样本集 $ D = {x_1, x_2, \dots, x_m} $，混合成分个数 $ k $。<br><strong>输出</strong>：簇划分 $ C = {C_1, C_2, \dots, C_k} $。</p>
<p><strong>步骤详解</strong></p>
<ol>
<li><p><strong>初始化模型参数</strong><br>随机初始化或通过K-means初步估计以下参数：</p>
<ul>
<li><strong>混合系数</strong> $ \alpha<em>i $（满足 $ \sum</em>{i=1}^k \alpha_i = 1 $）。</li>
<li><strong>均值向量</strong> $ \mu_i $。</li>
<li><strong>协方差矩阵</strong> $ \Sigma_i $。</li>
</ul>
</li>
<li><p><strong>迭代优化参数（EM循环）</strong><br>重复以下步骤直到收敛（如对数似然变化小于阈值）：</p>
<ul>
<li><p><strong>E步（期望步）</strong>：<br>对每个样本 $ x<em>j $，计算其由第 $ i $ 个高斯分布生成的<strong>后验概率</strong>（责任度 $ \gamma</em>{ji} $）：</p>
<script type="math/tex; mode=display">
\gamma_{ji} = p(z_j = i | x_j) = \frac{\alpha_i \mathcal{N}(x_j | \mu_i, \Sigma_i)}{\sum_{l=1}^k \alpha_l \mathcal{N}(x_j | \mu_l, \Sigma_l)}</script><p>其中 $ \mathcal{N}(x | \mu, \Sigma) $ 是高斯分布的概率密度函数。</p>
</li>
<li><p><strong>M步（最大化步）</strong>：<br>根据当前的责任度 $ \gamma_{ji} $，更新模型参数：</p>
<ol>
<li><strong>新均值向量</strong>：<script type="math/tex; mode=display">
\mu_i' = \frac{\sum_{j=1}^m \gamma_{ji} x_j}{\sum_{j=1}^m \gamma_{ji}}</script></li>
<li><strong>新协方差矩阵</strong>：<script type="math/tex; mode=display">
\Sigma_i' = \frac{\sum_{j=1}^m \gamma_{ji} (x_j - \mu_i')(x_j - \mu_i')^\top}{\sum_{j=1}^m \gamma_{ji}}</script></li>
<li><strong>新混合系数</strong>：<script type="math/tex; mode=display">
\alpha_i' = \frac{\sum_{j=1}^m \gamma_{ji}}{m}</script></li>
</ol>
</li>
</ul>
</li>
<li><p><strong>簇划分</strong>  </p>
<ul>
<li>初始化空簇 $ C_i = \varnothing $。</li>
<li>对每个样本 $ x<em>j $，计算其属于各簇的后验概率 $ \lambda_j = \arg\max_i \gamma</em>{ji} $。</li>
<li>将 $ x<em>j $ 分配到簇 $ C</em>{\lambda_j} $ 中。</li>
</ul>
</li>
</ol>
<p><strong>E步与M步的核心作用</strong></p>
<p><strong>E步（期望步）</strong></p>
<ul>
<li><strong>目标</strong>：基于当前参数 $ (\alpha<em>i, \mu_i, \Sigma_i) $，计算每个样本 $ x_j $ 属于各高斯分布的<strong>责任度</strong> $ \gamma</em>{ji} $。</li>
<li><strong>意义</strong>：<ul>
<li>责任度反映了在当前模型下，样本 $ x_j $ 由第 $ i $ 个高斯分布生成的概率。</li>
<li><strong>软分配</strong>：允许样本部分属于多个簇，而非硬划分。</li>
</ul>
</li>
</ul>
<p><strong>M步（最大化步）</strong></p>
<ul>
<li><strong>目标</strong>：根据责任度 $ \gamma_{ji} $，重新估计模型参数 $ (\alpha_i’, \mu_i’, \Sigma_i’) $，以最大化数据的对数似然。</li>
<li><strong>关键公式</strong>：<ul>
<li><strong>均值更新</strong>：加权平均样本点，权重为责任度。</li>
<li><strong>协方差更新</strong>：加权样本点的方差，反映簇内数据分布。</li>
<li><strong>混合系数更新</strong>：各簇样本的“有效数量”占总样本的比例。</li>
</ul>
</li>
</ul>
<h4 id="参考资料-1"><a href="#参考资料-1" class="headerlink" title="参考资料"></a>参考资料</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/smileyan9/article/details/135398479">西瓜书读书笔记整理（九） —— 第九章 聚类_西瓜书笔记第9章-CSDN博客</a></p>
<h4 id="密度聚类与DBSCAN"><a href="#密度聚类与DBSCAN" class="headerlink" title="密度聚类与DBSCAN"></a>密度聚类与DBSCAN</h4><blockquote>
<p>若样本分布为同心的两个环，kmeans则无法做到良好的聚类效果，因此引出密度聚类</p>
</blockquote>
<p>密度聚类是一种基于<strong>样本分布密集程度</strong>的无监督学习方法，其核心思想是：<strong>将高密度区域划分为同一簇，低密度区域视为噪声或边界</strong>。</p>
<p>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是密度聚类的典型代表，通过两个关键参数 $ \epsilon $ 和 $ MinPts $ 描述样本分布的紧密性。</p>
<h5 id="1-核心概念"><a href="#1-核心概念" class="headerlink" title="1. 核心概念"></a><strong>1. 核心概念</strong></h5><ol>
<li><strong>$ \epsilon $-邻域</strong>  <ul>
<li>定义：与样本 $ x $ 距离不超过 $ \epsilon $ 的所有样本集合。  </li>
<li>作用：衡量样本周围的局部密度。  </li>
</ul>
</li>
<li><strong>核心对象（Core Object）</strong>  <ul>
<li>定义：若样本 $ x $ 的 $ \epsilon $-邻域内包含至少 $ MinPts $ 个样本，则 $ x $ 是核心对象。  </li>
<li>作用：作为簇的生长起点，确保簇的最小密度要求。  </li>
</ul>
</li>
<li><strong>密度直达（Directly Density-Reachable）</strong>  <ul>
<li>定义：若样本 $ x_j $ 位于核心对象 $ x_i $ 的 $ \epsilon $-邻域内，则称 $ x_i $ 可密度直达 $ x_j $。  </li>
<li>作用：建立核心对象与邻近样本的直接连接。  </li>
</ul>
</li>
<li><strong>密度可达（Density-Reachable）</strong>  <ul>
<li>定义：若存在样本序列 $ x<em>i, p_1, p_2, \dots, p_n, x_j $，其中 $ p_i $ 密度直达 $ p</em>{i+1} $，则称 $ x_i $ 可密度可达 $ x_j $。  </li>
<li>作用：通过链式传递扩展簇的范围。  </li>
</ul>
</li>
<li><strong>密度相连（Density-Connected）</strong>  <ul>
<li>定义：若样本 $ x_i $ 和 $ x_j $ 均可密度可达某个公共样本 $ x_k $，则称 $ x_i $ 和 $ x_j $ 密度相连。  </li>
<li>作用：确保簇的连通性，避免碎片化。  </li>
</ul>
</li>
</ol>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124326529.png" alt="image-20250607124326529"></p>
<p><strong>DBSCN定义的簇</strong></p>
<ul>
<li>定义：最大密度相连的样本集合为一个簇</li>
<li>有两个性质：1.连接性：同一个簇内任意两样本，必然密度相连2.最大性：密度可达的两个样本必<br>定属于同一个簇</li>
</ul>
<h5 id="2-DBSCAN-算法流程"><a href="#2-DBSCAN-算法流程" class="headerlink" title="2. DBSCAN 算法流程"></a><strong>2. DBSCAN 算法流程</strong></h5><p>简单来理解DBSCAN：<strong>找出一个核心对象所有密度可达的样本集合形成簇</strong>。首先从数据集中任选一个核心对象A，找出所有A密度可达的样本集合，将这些样本形成一个密度相连的类簇，直到所有的核心对象都遍历完。DBSCAN算法的流程如下图所示：</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124446432.png" alt="image-20250607124446432"></p>
<h5 id="3-参数选择与影响"><a href="#3-参数选择与影响" class="headerlink" title="3. 参数选择与影响"></a><strong>3. 参数选择与影响</strong></h5><ul>
<li><p><strong>$ \epsilon $（邻域半径）</strong>：  </p>
<ul>
<li>过小：可能导致多数样本被标记为噪声，簇数量增加。  </li>
<li>过大：可能导致不同簇合并，簇数量减少。  </li>
<li><strong>选择方法</strong>：通过<strong>K-Distance图</strong>（排序后的第 $ k $ 近邻距离）观察“拐点”。  </li>
</ul>
</li>
<li><p><strong>$ MinPts $（最小样本数）</strong>：  </p>
<ul>
<li>控制簇的最小密度阈值。  </li>
<li>通常取 $ d+1 $（$ d $ 为特征维度），避免在高维空间中误判噪声。  </li>
</ul>
</li>
</ul>
<h4 id="层次聚类与AGNES"><a href="#层次聚类与AGNES" class="headerlink" title="层次聚类与AGNES"></a>层次聚类与AGNES</h4><p>层次聚类是一种通过构建<strong>树状结构（Dendrogram）</strong>将数据划分为不同层次的聚类方法。其核心思想是：  </p>
<ul>
<li><strong>凝聚型（Agglomerative）</strong>：从每个样本作为一个独立簇开始，逐步合并最相似的簇，直到达到预设的簇数或形成一个唯一簇。  </li>
<li><strong>分裂型（Divisive）</strong>：与凝聚型相反，从整个数据集作为一个簇开始，逐步分裂为更小的簇。  </li>
</ul>
<p>本节重点介绍<strong>AGNES（Agglomerative Nesting）</strong>，一种经典的自底向上的层次聚类算法。</p>
<h5 id="1-AGNES-算法流程"><a href="#1-AGNES-算法流程" class="headerlink" title="1. AGNES 算法流程"></a><strong>1. AGNES 算法流程</strong></h5><ol>
<li><strong>初始化</strong>：每个样本作为一个独立簇。  </li>
<li><strong>迭代合并</strong>：  <ul>
<li>计算所有簇对之间的距离。  </li>
<li>合并距离最近的两个簇。  </li>
</ul>
</li>
<li><strong>终止条件</strong>：  <ul>
<li>达到预设的簇数 $ k $；  </li>
<li>所有簇之间的距离大于阈值。  </li>
</ul>
</li>
</ol>
<h5 id="2-簇间距离的定义"><a href="#2-簇间距离的定义" class="headerlink" title="2. 簇间距离的定义"></a><strong>2. 簇间距离的定义</strong></h5><p>AGNES 的关键在于如何定义<strong>簇间距离</strong>，常见的三种方法如下：</p>
<p><strong>（1）最小距离（Single Linkage）</strong></p>
<script type="math/tex; mode=display">
d_{\min}(C_i, C_j) = \min_{\boldsymbol{x} \in C_i, \boldsymbol{z} \in C_j} \text{dist}(\boldsymbol{x}, \boldsymbol{z})</script><ul>
<li><strong>含义</strong>：两个簇之间最近的两个样本的距离。  </li>
</ul>
<p><strong>（2）最大距离（Complete Linkage）</strong></p>
<script type="math/tex; mode=display">
d_{\max}(C_i, C_j) = \max_{\boldsymbol{x} \in C_i, \boldsymbol{z} \in C_j} \text{dist}(\boldsymbol{x}, \boldsymbol{z})</script><ul>
<li><strong>含义</strong>：两个簇之间最远的两个样本的距离。    </li>
</ul>
<p><strong>（3）平均距离（Average Linkage）</strong></p>
<script type="math/tex; mode=display">
d_{\text{avg}}(C_i, C_j) = \frac{1}{|C_i| |C_j|} \sum_{\boldsymbol{x} \in C_i} \sum_{\boldsymbol{z} \in C_j} \text{dist}(\boldsymbol{x}, \boldsymbol{z})</script><ul>
<li><strong>含义</strong>：两个簇所有样本对距离的平均值。  </li>
</ul>
<h5 id="层次聚类法的算法流程如下所示："><a href="#层次聚类法的算法流程如下所示：" class="headerlink" title="层次聚类法的算法流程如下所示："></a>层次聚类法的算法流程如下所示：</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125338029.png" alt="image-20250607125338029"></p>
<h4 id="作业-2"><a href="#作业-2" class="headerlink" title="作业"></a>作业</h4><h5 id="1-2"><a href="#1-2" class="headerlink" title="1"></a>1</h5><p>假设任务是将下面8个点聚类成3个簇：A1(2,10), A2(2,5), A3(8,4), B1(5,8), B2(7,5), B3(6,4), C1(1,2), C3(4,9)，距离函数是欧式距离。假设初始选择A1，B1，C1分别作为每个聚类的中心，用Kmeans算法给出计算过程。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125506436.png" alt="image-20250607125506436"></p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125606040.png" alt="image-20250607125606040"></p>
<h5 id="2-2"><a href="#2-2" class="headerlink" title="2"></a>2</h5><p>Kmeans初始类簇中心如何选取？K值如何确定？请简要阐述。</p>
<p><strong>一、初始类簇中心的选取 (如何选好的起始点？)</strong></p>
<p>传统K-means随机选择初始中心点，容易导致结果不稳定（多次运行结果不同）或陷入局部最优（效果差）。改进方法主要有：</p>
<ol>
<li><strong>K-means++ (最常用且推荐)：</strong><ul>
<li><strong>核心思想：</strong> 让初始中心点彼此尽量远离。</li>
<li><strong>步骤：</strong><ol>
<li>随机选择<strong>第一个</strong>中心点。</li>
<li>计算每个数据点到<strong>当前已选中心点</strong>的最短距离（即离最近中心的距离）。</li>
<li>以<strong>与这个最短距离平方成正比</strong>的概率，随机选择下一个中心点（距离越大的点，被选中的概率越大）。</li>
<li>重复步骤2和3，直到选出K个中心点。</li>
</ol>
</li>
<li><strong>优点：</strong> 显著提高聚类质量和稳定性，计算开销增加不大。</li>
</ul>
</li>
<li><strong>多次运行+选取最优：</strong><ul>
<li>独立运行K-means算法多次（每次随机初始化）。</li>
<li>每次运行完成后，计算所有数据点与其所属簇中心的距离平方和（SSE, Sum of Squared Errors）。</li>
<li>选择SSE最小的那次运行结果作为最终结果。</li>
<li><strong>优点：</strong> 简单，增加找到更好解的机会。</li>
<li><strong>缺点：</strong> 计算开销随运行次数增加。</li>
</ul>
</li>
<li><strong>基于样本密度/距离：</strong><ul>
<li>选择数据空间中样本密度高的区域点作为中心。</li>
<li>或选择相互之间距离较远的点作为中心（类似K-means++的思想，但实现方式可能不同）。</li>
</ul>
</li>
</ol>
<p><strong>二、K值（簇数量）的确定 (如何知道分几类？)</strong></p>
<p>K值通常需要预先指定，但没有绝对正确的答案。常用方法基于评估不同K值下聚类结果的“质量”，寻找拐点或最优值：</p>
<ol>
<li><strong>肘部法则：</strong><ul>
<li><strong>核心思想：</strong> 随着K增大，簇内样本聚合更紧密，簇内平方和误差（SSE）会下降，但下降幅度会逐渐变缓。找到SSE下降速率发生显著变化的“肘点”。</li>
<li><strong>做法：</strong> 计算不同K值（如K=1, 2, 3, …, max）对应的SSE。绘制<code>K值 - SSE</code>曲线图。观察曲线，寻找SSE下降幅度突然变得平缓的那个K值（形如手臂的“肘关节”）。</li>
<li><strong>优点：</strong> 直观。</li>
<li><strong>缺点：</strong> “肘点”有时不明显或不存在，需要主观判断。</li>
</ul>
</li>
<li><strong>轮廓系数：</strong><ul>
<li><strong>核心思想：</strong> 综合衡量一个样本与其自身簇的紧密度(<code>a</code>)和与其他簇的分离度(<code>b</code>)。</li>
<li><strong>计算：</strong> 对于每个样本i：<ul>
<li><code>a(i)</code> = i 到同簇内所有其他点的平均距离（簇内不相似度）。</li>
<li><code>b(i)</code> = i 到所有<strong>其他簇</strong>中点的平均距离的最小值（最近邻簇的不相似度）。</li>
<li>样本i的轮廓系数：<code>s(i) = (b(i) - a(i)) / max(a(i), b(i))</code>。值在[-1, 1]之间。</li>
</ul>
</li>
<li><strong>整体评估：</strong> 计算所有样本轮廓系数的平均值，作为该K值下聚类的整体轮廓系数。</li>
<li><strong>选择K：</strong> 尝试不同K值，选择<strong>平均轮廓系数最大</strong>对应的K值。轮廓系数越接近1，表示聚类效果越好（簇内紧凑，簇间分离）。</li>
<li><strong>优点：</strong> 量化评估，结果在[-1, 1]之间有界。</li>
<li><strong>缺点：</strong> 计算量较大，尤其对于大数据集。</li>
</ul>
</li>
</ol>
<h4 id="参考资料-2"><a href="#参考资料-2" class="headerlink" title="参考资料"></a>参考资料</h4><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com.cn/developer/article/1802143">《机器学习》— 第九章 聚类-腾讯云开发者社区-腾讯云</a></p>
<h3 id="降维与度量学习"><a href="#降维与度量学习" class="headerlink" title="降维与度量学习"></a>降维与度量学习</h3><h4 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h4><p>k近邻算法简称<strong>kNN（k-Nearest Neighbor）</strong>，是一种经典的监督学习方法，是数据挖掘十大算法之一。其工作机制十分简单：给定某个测试样本，kNN基于某种<strong>距离度量</strong>在训练集中找出与其距离最近的k个带有真实标记的训练样本，然后基于这k个邻居的真实标记来进行预测，类似于集成学习中的基学习器结合策略：分类任务采用投票法，回归任务则采用平均法。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607150256290.png" alt="image-20250607150256290"></p>
<p><strong>核心思想</strong></p>
<p>1NN 分类器通过将测试样本 $ \boldsymbol{x} $ 分配到其最近邻样本 $ \boldsymbol{z} $ 的类别来完成预测。其错误概率取决于两个关键因素：</p>
<ul>
<li><strong>$ \boldsymbol{x} $ 的真实类别</strong>：$ P(c | \boldsymbol{x}) $，即给定 $ \boldsymbol{x} $ 属于类别 $ c $ 的概率。  </li>
<li><strong>$ \boldsymbol{z} $ 的类别</strong>：$ P(c | \boldsymbol{z}) $，即 $ \boldsymbol{z} $ 属于类别 $ c $ 的概率。</li>
</ul>
<p><strong>错误概率公式</strong></p>
<p>若测试样本 $ \boldsymbol{x} $ 的最近邻为 $ \boldsymbol{z} $，则 1NN 分类器出错的概率为：</p>
<script type="math/tex; mode=display">
P(\text{err}) = 1 - P(\text{correct}) = 1 - \sum_{c \in \mathcal{C}} P(c | \boldsymbol{x}) P(c | \boldsymbol{z})</script><p>其中：</p>
<ul>
<li>$ \mathcal{C} $ 是所有可能的类别集合。  </li>
<li>$ P(c | \boldsymbol{x}) $：$ \boldsymbol{x} $ 属于类别 $ c $ 的条件概率。  </li>
<li>$ P(c | \boldsymbol{z}) $：$ \boldsymbol{z} $ 属于类别 $ c $ 的条件概率。</li>
</ul>
<p>通过证明可以发现一个令人震惊的结论：<strong>最近邻分类器的错误率不超过贝叶斯最优分类器错误率的两倍</strong>。 </p>
<p>对于距离度量，<strong>不同的度量方法得到的k个近邻不尽相同，从而对最终的投票结果产生了影响</strong>，因此选择一个合适的距离度量方法也十分重要。</p>
<p>在上一篇聚类算法中，在度量样本相似性时介绍了常用的几种距离计算方法，包括<strong>闵可夫斯基距离，曼哈顿距离，VDM</strong>等。在实际应用中，<strong>kNN的距离度量函数一般根据样本的特性来选择合适的距离度量，同时应对数据进行去量纲/归一化处理来消除大量纲属性的强权政治影响</strong>。 </p>
<h4 id="低维嵌入"><a href="#低维嵌入" class="headerlink" title="低维嵌入"></a>低维嵌入</h4><p><strong>使用knn的前提是样本空间的密度要一定大，但是这个条件在现实中很难满足，因此引出降维操作</strong></p>
<blockquote>
<p>kNN的重要假设: 任意测试样本  附近任意小的  距离范围内总能找到一个训练样本，即训练样本的采样密度足够大，或称为 <strong>“密采样”( dense sample)</strong> 。然而，这个假设在现实任务中通常很难满足</p>
</blockquote>
<p>样本的<strong>特征数</strong>也称为<strong>维数</strong>（dimensionality），当维数非常大时，也就是通常所说的“<strong>维数灾难</strong>”(curse of dimensionality)，具体表现在：在高维情形下，<strong>数据样本变得十分稀疏</strong>，因为此时要满足训练样本为“<strong>密采样</strong>”的总体样本数目是一个触不可及的天文数字。<strong>训练样本的稀疏使得其代表总体分布的能力大大减弱，从而消减了学习器的泛化能力</strong>；同时当维数很高时，<strong>计算距离也变得十分复杂</strong>，甚至连计算内积都不再容易</p>
<p>缓解维数灾难的一个重要途径就是<strong>降维（dimension reduction），即通过某种数学变换将原始高维空间转变到一个低维的子空间</strong>。在这个子空间中，样本的密度将大幅提高，同时距离计算也变得容易。这</p>
<p>时也许会有疑问，降维之后不是会丢失原始数据的一部分信息吗？</p>
<p>实际上，在很多实际问题中，虽然训练数据是高维的，但是与学习任务相关也许仅仅是其中的一个低维子空间，也称为一个<strong>低维嵌入</strong>，例如：数据属性中存在噪声属性、相似属性或冗余属性等，<strong>对高维数据进行降维能在一定程度上达到提炼低维优质属性或降噪的效果</strong>。</p>
<h4 id="MDS算法"><a href="#MDS算法" class="headerlink" title="MDS算法"></a><strong>MDS算法</strong></h4><p>MDS（Multidimensional Scaling，多维尺度分析）是一种经典的<strong>降维技术</strong>，其核心目标是将高维数据映射到低维空间（如二维或三维），同时<strong>尽可能保留原始数据中样本点之间的距离关系</strong>。以下是其核心原理与应用要点：</p>
<p><strong>1. 核心思想</strong></p>
<ul>
<li><strong>输入</strong>：一个样本点之间的距离矩阵 $ D $（如欧氏距离、余弦距离等）。  </li>
<li><strong>输出</strong>：低维空间中样本点的坐标矩阵 $ Z $，使得低维空间中的距离与原始距离尽可能一致 。  </li>
<li><strong>关键假设</strong>：高维数据的内在结构可通过样本间的距离关系描述，降维后需最小化这种关系的失真。</li>
</ul>
<p><strong>2. 算法步骤</strong></p>
<p>MDS 的核心是通过<strong>矩阵分解</strong>从距离矩阵推导低维坐标：</p>
<ol>
<li><p><strong>构建距离矩阵 $ D $</strong>：<br>对于 $ r $ 个样本，计算两两之间的距离，形成 $ r \times r $ 的矩阵 $ D $，其中 $ D_{ij} $ 表示样本 $ i $ 和 $ j $ 的距离 。</p>
</li>
<li><p><strong>双中心化（Double Centering）</strong>：<br>构造矩阵 $ B = -\frac{1}{2} H D^{(2)} H $，其中 $ D^{(2)} $ 是距离的平方矩阵，$ H = I - \frac{1}{r} \mathbf{1} \mathbf{1}^\top $ 是中心化矩阵 。</p>
</li>
<li><p><strong>特征值分解</strong>：<br>对 $ B $ 进行特征值分解，得到 $ B = V \Lambda V^\top $，其中 $ \Lambda $ 是按降序排列的特征值对角矩阵，$ V $ 是对应的特征向量矩阵 。</p>
</li>
<li><p><strong>构造低维坐标</strong>：<br>选择前 $ d’ $ 个最大特征值（$ d’ $ 为目标维度）和对应的特征向量，计算低维坐标矩阵：  </p>
<script type="math/tex; mode=display">
Z = \Lambda^{1/2} V^\top</script><p>其中 $ \Lambda^{1/2} $ 是特征值矩阵的平方根 。</p>
</li>
</ol>
<p><strong>3. 关键特性</strong></p>
<ul>
<li><strong>保留距离关系</strong>：MDS 直接优化低维空间中的距离与原始距离的一致性，适用于需精确保留样本相似性的场景（如生物信息学中的基因关系分析）。  </li>
<li><strong>非线性适应性</strong>：与 PCA 不同，MDS 不要求数据线性分布，更适合处理非线性结构（如环形、流形数据）。  </li>
<li><strong>灵活性</strong>：支持任意距离度量（如自定义的相似性指标），而 PCA 仅适用于欧氏距离 。</li>
</ul>
<h4 id="线性降维方法"><a href="#线性降维方法" class="headerlink" title="线性降维方法"></a><strong>线性降维方法</strong></h4><p>线性降维通过<strong>线性变换</strong>将高维数据 $ \mathbf{X} \in \mathbb{R}^{d \times m} $ 投影到低维空间 $ \mathbf{Z} \in \mathbb{R}^{d’ \times m} $（$ d’ \leq d $），保留数据的主要信息。其数学表达为：</p>
<script type="math/tex; mode=display">
\mathbf{Z} = \mathbf{W}^\top \mathbf{X}</script><ul>
<li><strong>变换矩阵 $ \mathbf{W} \in \mathbb{R}^{d \times d’} $</strong>：<br>每一列是正交的基向量，构成低维子空间的坐标系。  </li>
<li><p><strong>目标</strong>：选择 $ \mathbf{W} $ 使得低维表示 $ \mathbf{Z} $ 最大化保留原始数据的信息（如方差、距离等）。</p>
</li>
<li><p><strong>MDS</strong>：<br>直接以<strong>保留高维空间中样本点之间的距离关系</strong>为目标。降维后的低维空间需尽可能保持原始样本两两之间的距离（如欧氏距离、自定义相似性距离）。  </p>
<ul>
<li><strong>示例</strong>：在基因数据分析中，MDS可确保基因表达相似的样本在低维空间中仍紧密分布。  </li>
</ul>
</li>
<li><p><strong>其他线性方法（如PCA、LDA）</strong>：  </p>
<ul>
<li><strong>PCA</strong>：最大化数据在低维空间的方差，强调保留全局结构而非具体距离。  </li>
<li><strong>LDA</strong>：在监督学习中最大化类间分离度，忽略类内距离。  </li>
</ul>
</li>
</ul>
<h4 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h4><p>不同于MDS采用距离保持的方法，主成分分析（Principal Component Analysis ,PCA）是一种经典的<strong>无监督降维算法</strong> ，其核心目标是通过线性变换将高维数据映射到低维空间，同时保留数据的<strong>最大方差信息</strong> （即信息损失最小）</p>
<p>直接通过一个<strong>线性变换</strong>，将原始空间中的样本<strong>投影</strong>到新的低维空间中。</p>
<p>简单来理解这一过程便是：<strong>PCA采用一组新的基（向量）来表示样本点，其中每一个基向量都是原始空间基向量的线性组合，通过使用尽可能少的新基向量来表出样本，从而达到降维的目的。</strong></p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607155733314.png" alt="image-20250607155733314"></p>
<p>假设使用d’个新基向量来表示原来样本，实质上是将样本投影到一个由d’个基向量确定的一个<strong>超平面</strong>上（<strong>即舍弃了一些维度</strong>），要用一个超平面对空间中所有高维样本进行恰当的表达，最理想的情形是：<strong>若这些样本点都能在超平面上表出且这些表出在超平面上都能够很好地分散开来</strong>。但是一般使用较原空间低一些维度的超平面来做到这两点十分不容易，因此我们退一步海阔天空，要求这个超平面应具有如下两个性质：</p>
<blockquote>
<p><strong>最近重构性</strong>：样本点到超平面的距离足够近，即尽可能在超平面附近；</p>
<p><strong>最大可分性</strong>：样本点在超平面上的投影尽可能地分散开来，即投影后的坐标具有区分性。</p>
</blockquote>
<p>这里十分神奇的是：<strong>最近重构性与最大可分性虽然从不同的出发点来定义优化问题中的目标函数，但最终这两种特性得到了完全相同的优化问题</strong>：</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607165159235.png" alt="image-20250607165159235"></p>
<h5 id="协方差矩阵与优化求解"><a href="#协方差矩阵与优化求解" class="headerlink" title="协方差矩阵与优化求解"></a><strong>协方差矩阵与优化求解</strong></h5><p>若数据已<strong>中心化</strong>（均值为零），则 $ \mathbf{X} \mathbf{X}^\top $ 是<strong>样本协方差矩阵</strong>的 $ m $ 倍。此时，PCA的优化问题转化为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
& \underset{\mathbf{W}}{\text{maximize}}
& & \text{tr}\left( \mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W} \right) \\
& \text{subject to}
& & \mathbf{W}^\top \mathbf{W} = \mathbf{I}
\end{aligned}</script><p>通过拉格朗日乘数法，该问题的解为 $ \mathbf{X} \mathbf{X}^\top $ 的前 $ d’ $ 个最大特征值对应的特征向量</p>
<h5 id="PCA的数学推导"><a href="#PCA的数学推导" class="headerlink" title="PCA的数学推导"></a><strong>PCA的数学推导</strong></h5><ul>
<li><p><strong>优化目标</strong>：  </p>
<script type="math/tex; mode=display">
\max_{\mathbf{W}} \quad \text{tr}\left( \mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W} \right) \quad \text{s.t.} \quad \mathbf{W}^\top \mathbf{W} = \mathbf{I}</script><p>其中，$ \mathbf{X} \in \mathbb{R}^{d \times m} $ 是中心化后的数据矩阵（均值为零）。</p>
</li>
<li><p><strong>拉格朗日乘数法</strong>：<br>引入拉格朗日乘子 $ \Lambda $，构造拉格朗日函数：</p>
<script type="math/tex; mode=display">
\mathcal{L}(\mathbf{W}, \Lambda) = \text{tr}\left( \mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W} \right) - \text{tr}\left( \Lambda (\mathbf{W}^\top \mathbf{W} - \mathbf{I}) \right)</script><p>对 $ \mathbf{W} $ 求导并令导数为零，得到：</p>
<script type="math/tex; mode=display">
\mathbf{X} \mathbf{X}^\top \mathbf{W} = \Lambda \mathbf{W}</script><p>即 $ \mathbf{X} \mathbf{X}^\top $ 的特征向量 $ \mathbf{w}_i $ 满足：</p>
<script type="math/tex; mode=display">
\mathbf{X} \mathbf{X}^\top \mathbf{w}_i = \lambda_i \mathbf{w}_i</script></li>
</ul>
<h5 id="PCA特征向量选择"><a href="#PCA特征向量选择" class="headerlink" title="PCA特征向量选择"></a>PCA特征向量选择</h5><p><strong>1. 核心问题</strong></p>
<p>在PCA中，我们希望找到一个 $ d’ \times d $ 的变换矩阵 $ \mathbf{W} $，其列向量是协方差矩阵 $ \mathbf{X} \mathbf{X}^\top $ 的特征向量，且满足正交约束 $ \mathbf{W}^\top \mathbf{W} = \mathbf{I} $。关键问题是：<strong>如何从 $ d $ 个特征向量中选择 $ d’ $ 个最优的？</strong></p>
<p><strong>2. 数学推导</strong></p>
<ol>
<li><p><strong>特征值分解</strong>：<br>协方差矩阵 $ \mathbf{X} \mathbf{X}^\top \in \mathbb{R}^{d \times d} $ 可分解为：</p>
<script type="math/tex; mode=display">
\mathbf{X} \mathbf{X}^\top \mathbf{W} = \mathbf{W} \boldsymbol{\Lambda}</script><p>其中，$ \boldsymbol{\Lambda} = \text{diag}(\lambda_1, \lambda_2, \dots, \lambda_d) $ 是特征值对角矩阵，$ \mathbf{W} $ 是特征向量矩阵。</p>
</li>
<li><p><strong>优化目标转化</strong>：<br>PCA的目标是最大化 $ \text{tr}(\mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W}) $。利用特征值分解，可得：</p>
<script type="math/tex; mode=display">
\mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W} = \mathbf{W}^\top (\mathbf{W} \boldsymbol{\Lambda}) = \boldsymbol{\Lambda}</script><p>因此，优化目标变为：</p>
<script type="math/tex; mode=display">
\max_{\mathbf{W}} \quad \text{tr}(\boldsymbol{\Lambda}) = \sum_{i=1}^{d'} \lambda_i</script><p>即选择 $ d’ $ 个最大的特征值 $ \lambda_i $ 对应的特征向量组成 $ \mathbf{W} $。</p>
</li>
</ol>
<p><strong>3. 特征向量选择策略</strong></p>
<ul>
<li><strong>按特征值排序</strong>：<br>特征值 $ \lambda_i $ 表示数据沿特征向量 $ \mathbf{w}_i $ 方向的方差。选择前 $ d’ $ 个最大特征值对应的特征向量，可保留最多信息。  </li>
<li><strong>正交性保证</strong>：<br>特征向量矩阵 $ \mathbf{W} $ 的列自动满足 $ \mathbf{W}^\top \mathbf{W} = \mathbf{I} $，无需额外正交化。</li>
</ul>
<h5 id="PCA算法的整个流程如下图所示："><a href="#PCA算法的整个流程如下图所示：" class="headerlink" title="PCA算法的整个流程如下图所示："></a>PCA算法的整个流程如下图所示：</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607170020467.png" alt="image-20250607170020467"></p>
<h4 id="核化线性降维"><a href="#核化线性降维" class="headerlink" title="核化线性降维"></a><strong>核化线性降维</strong></h4><p>待学习</p>
<h4 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h4><p><strong>流形学习（manifold learning）</strong>是一种借助拓扑流形概念的降维方法，流形是指在<strong>局部与欧式空间同胚的空间</strong>，即在局部与欧式空间具有相同的性质，能用欧氏距离计算样本之间的距离。这样即使高维空间的分布十分复杂，但是在局部上依然满足欧式空间的性质，基于流形学习的降维正是这种 <strong>“邻域保持”</strong> 的思想。其中 <strong>等度量映射（Isomap）试图在降维前后保持邻域内样本之间的距离，而局部线性嵌入（LLE）则是保持邻域内样本之间的线性关系</strong> 。</p>
<h5 id="等度量映射Isomap"><a href="#等度量映射Isomap" class="headerlink" title="等度量映射Isomap"></a>等度量映射Isomap</h5><p>等度量映射的基本出发点是：高维空间中的直线距离具有误导性，因为有时高维空间中的直线距离在低维空间中是不可达的。<strong>因此利用流形在局部上与欧式空间同胚的性质，可以使用近邻距离来逼近测地线距离</strong>，即对于一个样本点，它与近邻内的样本点之间是可达的，且距离使用欧式距离计算，这样整个样本空间就形成了一张近邻图，高维空间中两个样本之间的距离就转为最短路径问题。可采用著名的<strong>Dijkstra算法</strong>或<strong>Floyd算法</strong>计算最短距离，得到高维空间中任意两点之间的距离后便可以使用 MDS 算法来其计算低维空间中的坐标。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171119645.png" alt="image-20250607171119645"></p>
<p>Isomap算法流程如下图：</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171258284.png" alt="image-20250607171258284"></p>
<p>对于近邻图的构建，常用的有两种方法：<strong>一种是指定近邻点个数</strong>，像kNN一样选取k个最近的邻居；<strong>另一种是指定邻域半径</strong>，距离小于该阈值的被认为是它的近邻点。但两种方法均会出现下面的问题：</p>
<blockquote>
<p>若<strong>邻域范围指定过大，则会造成“短路问题”</strong>，即本身距离很远却成了近邻，将距离近的那些样本扼杀在摇篮。</p>
<p>若<strong>邻域范围指定过小，则会造成“断路问题”</strong>，即有些样本点无法可达了，整个世界村被划分为互不可达的小部落。</p>
</blockquote>
<h5 id="局部线性嵌入"><a href="#局部线性嵌入" class="headerlink" title="局部线性嵌入"></a>局部线性嵌入</h5><p>待学习</p>
<h4 id="度量学习"><a href="#度量学习" class="headerlink" title="度量学习"></a>度量学习</h4><p><strong>1. 核心思想</strong></p>
<p>度量学习（Metric Learning）的核心目标是<strong>学习一个合理的距离度量</strong>，使得相似样本距离更近，不相似样本距离更远。传统欧式距离（Euclidean Distance）虽然简单，但其固定权重无法反映不同特征的实际重要性。因此，我们引入<strong>加权欧式距离</strong>，通过可调节的参数（权重）优化距离计算。</p>
<p><strong>2. 欧式距离与加权欧式距离</strong></p>
<ul>
<li><p><strong>标准欧式距离</strong>：  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{ed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) = \|\boldsymbol{x}_i - \boldsymbol{x}_j\|_2^2 = \sum_{k=1}^d (\boldsymbol{x}_{i,k} - \boldsymbol{x}_{j,k})^2</script><p>每个特征维度对距离的贡献相同，未考虑特征的重要性差异。</p>
</li>
<li><p><strong>加权欧式距离</strong>：  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) = (\boldsymbol{x}_i - \boldsymbol{x}_j)^\top \mathbf{W} (\boldsymbol{x}_i - \boldsymbol{x}_j)</script><p>其中，$ \mathbf{W} = \text{diag}(\boldsymbol{w}) $ 是对角权重矩阵，$ w_k \geq 0 $ 表示第 $ k $ 个特征的权重。<br>展开后为：</p>
<script type="math/tex; mode=display">
\text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) = \sum_{k=1}^d w_k (\boldsymbol{x}_{i,k} - \boldsymbol{x}_{j,k})^2</script></li>
</ul>
<p><strong>3. 权重的作用</strong></p>
<ul>
<li><strong>特征重要性调节</strong>：  <ul>
<li>高权重 $ w_k $：强调第 $ k $ 维特征对距离的影响（如图像的颜色通道比位置更重要）。  </li>
<li>低权重 $ w_k $：弱化噪声或冗余特征的影响。  </li>
</ul>
</li>
<li><strong>几何意义</strong>：<br>加权欧式距离相当于在各特征维度上进行缩放，将数据映射到一个新的空间，使得关键特征的差异更显著。</li>
</ul>
<p><strong>4. 度量学习的目标</strong></p>
<p>通过学习最优权重 $ \boldsymbol{w} $，使以下目标成立：</p>
<ul>
<li><strong>相似样本</strong>：加权距离小（$ \text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) \to 0 $）。  </li>
<li><strong>不相似样本</strong>：加权距离大（$ \text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) \to \infty $）。  </li>
</ul>
<p>典型优化问题形式：</p>
<script type="math/tex; mode=display">
\min_{\boldsymbol{w}} \quad \sum_{(\boldsymbol{x}_i, \boldsymbol{x}_j) \in S} \text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) + \lambda \|\boldsymbol{w}\|_2^2</script><p>其中，$ S $ 是相似样本对集合，$ \lambda $ 是正则化项防止过拟合。</p>
<blockquote>
<p>总结来说，</p>
<ul>
<li><strong>降维是将原高维空间嵌入到一个合适的低维子空间中，接着在低维空间中进行学习任务</strong></li>
<li><strong>度量学习则是试图去学习出一个 *距离度量* 来等效降维的效果</strong></li>
</ul>
</blockquote>
<h5 id="LMNN（Large-Margin-Nearest-Neighbors）详解"><a href="#LMNN（Large-Margin-Nearest-Neighbors）详解" class="headerlink" title="LMNN（Large Margin Nearest Neighbors）详解"></a><strong>LMNN（Large Margin Nearest Neighbors）详解</strong></h5><p><strong>1. 核心思想</strong></p>
<p>LMNN 是一种<strong>监督度量学习方法</strong>，其目标是通过学习一个线性变换矩阵 $ \mathbf{M} $，使<strong>同类样本在变换后的空间中更紧密</strong>，<strong>不同类样本被推开</strong>，从而提升KNN等基于距离的算法性能。其核心是引入<strong>最大边距（Large Margin）</strong>的概念，类似于SVM的分类边界。</p>
<p><strong>2. 损失函数</strong></p>
<p>LMNN 的优化目标由两部分组成：</p>
<ul>
<li><p><strong>Pull Loss（拉力损失）</strong>：<br>使同类样本对的距离尽可能小，公式为：</p>
<script type="math/tex; mode=display">
\varepsilon_{\text{pull}}(\mathbf{L}) = \sum_{j \sim i} \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2</script><p>其中，$ j \sim i $ 表示与样本 $ i $ 同类的最近邻样本。</p>
</li>
<li><p><strong>Push Loss（推力损失）</strong>：<br>使不同类样本对的距离至少保持一个固定边距 $ \xi_{ijl} $，公式为：</p>
<script type="math/tex; mode=display">
\varepsilon_{\text{push}}(\mathbf{L}) = \sum_{i,j,l} (1 - y_{il}) \left[1 + \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2 - \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_l)\|^2\right]_+</script><p>其中，$ y<em>{il} = 1 $ 表示样本 $ i $ 和 $ l $ 属于同一类，否则为0；$ [\cdot]</em>+ $ 表示取正值部分。</p>
</li>
<li><p><strong>总损失函数</strong>：  </p>
<script type="math/tex; mode=display">
\varepsilon(\mathbf{L}) = (1 - \mu) \varepsilon_{\text{pull}}(\mathbf{L}) + \mu \varepsilon_{\text{push}}(\mathbf{L})</script><p>参数 $ \mu \in [0, 1] $ 控制两类损失的权重。</p>
</li>
</ul>
<p><strong>3. 优化问题</strong></p>
<p>LMNN 的目标是最小化总损失函数，同时满足以下约束：</p>
<script type="math/tex; mode=display">
\begin{aligned}
& \min_{\mathbf{M}, \boldsymbol{\xi}} \quad (1 - \mu) \sum_{i,j \sim i} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j) + \mu \sum_{i,j \sim i,l} (1 - y_{il}) \xi_{ijl} \\
& \text{s.t.} \quad (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_l)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_l) - (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j) \geq 1 - \xi_{ijl}, \\
& \quad \quad \quad \xi_{ijl} \geq 0, \quad \mathbf{M} \succeq 0.
\end{aligned}</script><ul>
<li><strong>约束（1）</strong>：确保不同类样本对的距离比同类样本对大至少 $ 1 - \xi_{ijl} $。  </li>
<li><strong>约束（2）</strong>：松弛变量 $ \xi_{ijl} \geq 0 $ 允许部分样本对违反约束。  </li>
<li><strong>约束（3）</strong>：$ \mathbf{M} $ 必须是半正定矩阵，保证距离的非负性和三角不等式。</li>
</ul>
<h4 id="作业-3"><a href="#作业-3" class="headerlink" title="作业"></a>作业</h4><h5 id="1-3"><a href="#1-3" class="headerlink" title="1"></a>1</h5><p>数据降维有哪些常用的方法？阐述主成分分析（PCA）算法的计算流程，并讨论PCA 降维之后的维度如何确定？</p>
<p><strong>（1）常用数据降维方法</strong></p>
<ol>
<li><strong>主成分分析（PCA）</strong>：通过线性变换保留最大方差方向，适用于去噪和压缩数据 。  </li>
<li><strong>线性判别分析（LDA）</strong>：在监督学习中最大化类间分离度，适用于分类任务 。  </li>
</ol>
<p><strong>（2）主成分分析（PCA）的计算流程</strong></p>
<ol>
<li><strong>数据标准化</strong>：对原始数据去均值、方差归一化，消除量纲影响 。  </li>
<li><strong>计算协方差矩阵</strong>：  <script type="math/tex; mode=display">
\mathbf{\Sigma} = \frac{1}{m} \mathbf{X} \mathbf{X}^\top</script>其中 $ \mathbf{X} $ 是中心化后的数据矩阵 。  </li>
<li><strong>特征值分解</strong>：对协方差矩阵进行特征值分解，得到特征值 $ \lambda_i $ 和单位正交特征向量 $ \mathbf{w}_i $ 。  </li>
<li><strong>选择主成分</strong>：按特征值大小排序，选择前 $ d’ $ 个最大特征值对应的特征向量构成变换矩阵 $ \mathbf{W} = [\mathbf{w}<em>1, \mathbf{w}_2, \dots, \mathbf{w}</em>{d’}] $。  </li>
<li><strong>降维投影</strong>：计算低维表示 $ \mathbf{Z} = \mathbf{W}^\top \mathbf{X} $，其中 $ \mathbf{Z} \in \mathbb{R}^{d’ \times m} $ 。</li>
</ol>
<p><strong>（3）PCA降维后维度的确定</strong></p>
<ul>
<li><strong>累积方差贡献率</strong>：选择前 $ d’ $ 个主成分，使累计方差占比达到阈值（如95%）。  </li>
<li><strong>肘部法则（Elbow Method）</strong>：绘制特征值随维度变化的曲线，选择“拐点”作为 $ d’ $。  </li>
</ul>
<h5 id="2-3"><a href="#2-3" class="headerlink" title="2"></a>2</h5><p>度量学习的目标是什么？LMNN算法中三元组损失是什么？如何计算？</p>
<p><strong>（1）度量学习的目标</strong></p>
<p>度量学习旨在学习一个合理的距离度量，使得：</p>
<ul>
<li><strong>相似样本</strong>：距离尽可能小（如同类样本）。  </li>
<li><strong>不相似样本</strong>：距离尽可能大（如异类样本）。<br>典型应用包括推荐系统（优化用户-商品相似性）、图像检索（提升匹配精度）和生物识别（增强类间可分性）。</li>
</ul>
<p><strong>（2）LMNN中的三元组损失</strong></p>
<p>LMNN（Large Margin Nearest Neighbor）是一种监督度量学习方法，其核心思想是通过优化距离度量来提升KNN的分类性能。虽然LMNN本身主要使用对比损失（Contrastive Loss），但三元组损失（Triplet Loss）是深度度量学习中常见的损失函数，其计算方式如下：<strong>三元组损失的定义</strong></p>
<p>三元组损失基于锚点（Anchor）、正例（Positive）和负例（Negative）三个样本，目标是使锚点与正例的距离小于锚点与负例的距离，公式为：</p>
<script type="math/tex; mode=display">
\mathcal{L} = \sum_{i,j,l} \max\left(0, \|\mathbf{z}_i - \mathbf{z}_j\|^2 - \|\mathbf{z}_i - \mathbf{z}_l\|^2 + m\right)</script><ul>
<li>$ \mathbf{z}_i $：锚点样本的嵌入表示。  </li>
<li>$ \mathbf{z}_j $：与锚点同类的正例样本。  </li>
<li>$ \mathbf{z}_l $：与锚点不同类的负例样本。  </li>
<li>$ m $：预设的边界值（Margin），控制正负样本距离的最小差距 。</li>
</ul>
<p><strong>LMNN的损失函数</strong></p>
<p>LMNN 的损失函数包含两部分：</p>
<ol>
<li><strong>拉力损失（Pull Loss）</strong>：最小化同类样本对的距离：  <script type="math/tex; mode=display">
\varepsilon_{\text{pull}} = \sum_{i,j \sim i} \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2</script></li>
<li><strong>推力损失（Push Loss）</strong>：最大化异类样本对的距离：  <script type="math/tex; mode=display">
\varepsilon_{\text{push}} = \sum_{i,j \sim i,l} (1 - y_{il}) \left[1 + \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2 - \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_l)\|^2\right]_+</script>其中 $ \mathbf{L} $ 是线性变换矩阵，$ y<em>{il} $ 表示样本对是否同类，$ [\cdot]</em>+ $ 表示取正值部分 。</li>
</ol>
<p><strong>优化目标</strong></p>
<p>LMNN 的总损失为拉力和推力损失的加权和：</p>
<script type="math/tex; mode=display">
\varepsilon(\mathbf{L}) = (1 - \mu) \varepsilon_{\text{pull}} + \mu \varepsilon_{\text{push}}</script><p>参数 $ \mu \in [0, 1] $ 平衡两类损失的权重，最终通过优化 $ \mathbf{L} $ 得到最优距离度量 。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607175825520.png" alt="image-20250607175825520"></p>
<h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>监督学习解决现实问题有哪些难点?<br>1.标记数据获取成本高：在许多领域如医疗，获取标记数据是昂贵且耗时的。<br>2.未标记数据大量存在且易得：相对而言，未标记数据大量存在且容易获取。<br>3.提升模型的泛化能力：通过利用未标记数据，可以增强模型的泛化能力。<br>举例：在医疗领域，获取医生标记的诊断数据非常昂贵，但有大量未标记的病人记录。<br>半监督学习可以帮助利用这些未标记数据，提高疾病预测模型的准确性。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607181345721.png" alt="image-20250607181345721">半监督学习结合了有监督学习和无监督学习，半监督学习使用<strong>少量的标记数据</strong>和<strong>大量的未标记数据</strong>来训练模型，主要目标是提升模型在未标记数据上的表现。</p>
<h5 id="基于生成模型的方法"><a href="#基于生成模型的方法" class="headerlink" title="基于生成模型的方法"></a>基于生成模型的方法</h5><p>假设所有数据（无论是否有标记）都是由一个<strong>潜在的模型</strong>“生成”的。那么无标记的数据可以帮助更准确的估计潜在模型的参数。<br>比如右图中可以看到数据可以由两个高斯分布近似，则无监督的数据可以被用来更好得做高斯分布的参数估计</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183201926.png" alt="image-20250607183201926"></p>
<h5 id="半监督SVM"><a href="#半监督SVM" class="headerlink" title="半监督SVM"></a><strong>半监督SVM</strong></h5><p>监督学习中的SVM试图找到一个划分超平面，使得两侧支持向量之间的间隔最大，即 <strong>最大划分间隔</strong> 思想。对于半监督SVM (Semi-Supervised Support Vector Machine, S3VM) 则考虑超平面在能将两类标记样本分隔的同时，<strong>穿过数据低密度的区域</strong>。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183349866.png" alt="image-20250607183349866"></p>
<h6 id="TSVM-Transductive-Support-Vector-Machine"><a href="#TSVM-Transductive-Support-Vector-Machine" class="headerlink" title="TSVM(Transductive Support Vector Machine)"></a>TSVM(Transductive Support Vector Machine)</h6><p><strong>1. 核心思想</strong></p>
<p>TSVM 是一种<strong>半监督学习方法</strong>，通过结合有标记数据 $ D_l $ 和未标记数据 $ D_u $，利用伪标签（Pseudo-labels）和迭代优化策略，最大化分类超平面的间隔。其损失函数需同时考虑：</p>
<ul>
<li><strong>有标记样本</strong>：最小化分类错误（Hinge Loss）。  </li>
<li><strong>未标记样本</strong>：通过伪标签引入约束，逐步调整超平面。</li>
</ul>
<p><strong>2. 损失函数推导</strong></p>
<p>TSVM 的目标是找到一个超平面 $ \boldsymbol{w}^\top \boldsymbol{x} + b = 0 $，使得：</p>
<ol>
<li><strong>有标记样本</strong>的分类误差最小。  </li>
<li><strong>未标记样本</strong>的伪标签与超平面预测结果一致。  </li>
</ol>
<p><strong>标准SVM的损失函数</strong>为：</p>
<script type="math/tex; mode=display">
\min_{\boldsymbol{w}, b, \xi} \quad \frac{1}{2} \|\boldsymbol{w}\|^2 + C \sum_{i=1}^l \xi_i</script><p>其中，$ \xi_i $ 是松弛变量，表示样本 $ (\boldsymbol{x}_i, y_i) $ 的分类误差。</p>
<p><strong>TSVM的扩展</strong>：<br>引入未标记样本 $ D_u $ 的伪标签 $ \hat{y}_j $（$ j = l+1, \dots, l+u $），并赋予其较小的惩罚系数 $ C_u $（初始阶段 $ C_u \ll C_l $）：</p>
<script type="math/tex; mode=display">
\min_{\boldsymbol{w}, b, \xi} \quad \frac{1}{2} \|\boldsymbol{w}\|^2 + C_l \sum_{i=1}^l \xi_i + C_u \sum_{j=l+1}^{l+u} \xi_j</script><p>其中：</p>
<ul>
<li>$ C_l $：有标记样本的惩罚系数。  </li>
<li>$ C_u $：未标记样本的惩罚系数，初始值很小，逐步增大以增强伪标签的影响。</li>
</ul>
<p><strong>3. 迭代优化流程</strong></p>
<ol>
<li><p><strong>初始化</strong>：  </p>
<ul>
<li>用有标记数据 $ D_l $ 训练初始 SVM，得到 $ \boldsymbol{w}_0, b_0 $。  </li>
<li>对未标记数据 $ D_u $ 预测伪标签 $ \hat{y}_j = \text{sign}(\boldsymbol{w}_0^\top \boldsymbol{x}_j + b_0) $。  </li>
</ul>
</li>
<li><p><strong>伪标签调整</strong>：  </p>
<ul>
<li>若存在冲突（如 $ \hat{y}_i \hat{y}_j &lt; 0 $ 且 $ \xi_i + \xi_j &gt; 2 $），翻转其中一个伪标签（如 $ \hat{y}_i \leftarrow -\hat{y}_i $）。  </li>
<li>重新求解优化问题，更新 $ \boldsymbol{w}, b $。  </li>
</ul>
</li>
<li><p><strong>参数调整</strong>：  </p>
<ul>
<li>逐步增大 $ C_u $（如 $ C_u \leftarrow \min{2C_u, C_l} $），增强未标记样本的影响。  </li>
</ul>
</li>
</ol>
<p><strong>4. 关键数学细节</strong></p>
<ul>
<li><p><strong>Hinge Loss</strong>：<br>对每个样本 $ (\boldsymbol{x}_i, y_i) $，损失为：</p>
<script type="math/tex; mode=display">
\xi_i = \max\left(0, 1 - y_i (\boldsymbol{w}^\top \boldsymbol{x}_i + b)\right)</script><p>未标记样本的伪标签 $ \hat{y}_j $ 同样代入此公式，但惩罚系数为 $ C_u $。  </p>
</li>
<li><p><strong>正则化项</strong>：<br>$ \frac{1}{2} |\boldsymbol{w}|^2 $ 确保超平面的泛化能力，防止过拟合。  </p>
</li>
<li><p><strong>伪标签翻转条件</strong>：<br>当两个未标记样本 $ i, j $ 满足：</p>
<script type="math/tex; mode=display">
\hat{y}_i \hat{y}_j < 0 \quad \text{且} \quad \xi_i > 0, \xi_j > 0, \quad \xi_i + \xi_j > 2</script><p>表示它们被错误分类且距离超平面较近，需翻转其中一个标签以减少冲突。</p>
</li>
</ul>
<h5 id="图半监督学习"><a href="#图半监督学习" class="headerlink" title="图半监督学习"></a><strong>图半监督学习</strong></h5><p>给定一个数据集，我们可将其映射为一个图，数据集中每个样本对应于图结点，若两个样本之间的相似度很高(或相关性很强)，则对应的结点之间存在一条边，边的“强度”(strength) 正比于样本之间的相似度(或相关性)。</p>
<p>可将有标记样本所对应的结点想象为染过色，标记样本所对应的结点尚未染色。半监督学习就对应于“颜色”在图上扩散或传播的过程。由于个图对应了一个矩阵，我们就能基于矩阵运算来进行半监督学习算法的推导与分析。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607184534217.png" alt="image-20250607184534217"></p>
<p><strong>图半监督学习中的能量函数推导详解</strong></p>
<p><strong>1. 图结构与亲和矩阵</strong></p>
<p>给定有标记数据集 $ D<em>l = {(\boldsymbol{x}_1, y_1), (\boldsymbol{x}_2, y_2), \dots, (\boldsymbol{x}_l, y_l)} $ 和未标记数据集 $ D_u = {\boldsymbol{x}</em>{l+1}, \boldsymbol{x}<em>{l+2}, \dots, \boldsymbol{x}</em>{l+u}} $，构建图 $ G = (V, E) $：</p>
<ul>
<li><strong>结点集</strong>：$ V = {\boldsymbol{x}<em>1, \dots, \boldsymbol{x}_l, \boldsymbol{x}</em>{l+1}, \dots, \boldsymbol{x}_{l+u}} $，包含所有样本。  </li>
<li><strong>边集</strong>：通过亲和矩阵 $ \mathbf{W} $ 表示，元素定义为：<script type="math/tex; mode=display">
(\mathbf{W})_{ij} = 
\begin{cases}
\exp\left(-\frac{\|\boldsymbol{x}_i - \boldsymbol{x}_j\|^2}{2\sigma^2}\right), & i \neq j \\
0, & \text{otherwise}
\end{cases}</script>其中，$ \sigma $ 是高斯核的带宽参数，控制邻接关系的敏感性。</li>
</ul>
<p><strong>2. 能量函数的定义与推导</strong></p>
<p>假设分类模型的输出标记为 $ f(\boldsymbol{x}_i) $（取值为类别标签，如 $ \pm 1 $），定义能量函数 $ E(f) $ 为：</p>
<script type="math/tex; mode=display">
E(f) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} (f(\boldsymbol{x}_i) - f(\boldsymbol{x}_j))^2</script><p>其中 $ m = l + u $ 是总样本数。</p>
<p><strong>3. 能量函数的展开与简化</strong></p>
<ol>
<li><strong>展开平方项</strong><script type="math/tex; mode=display">
E(f) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} \left[ f^2(\boldsymbol{x}_i) - 2 f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) + f^2(\boldsymbol{x}_j) \right]</script></li>
<li><strong>利用对称性简化</strong><br>由于 $ \mathbf{W} $ 是对称矩阵（$(\mathbf{W})<em>{ij} = (\mathbf{W})</em>{ji}$），可交换求和顺序：<script type="math/tex; mode=display">
\sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_j) = \sum_{j=1}^m \sum_{i=1}^m (\mathbf{W})_{ji} f^2(\boldsymbol{x}_j) = \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_i)</script>因此，能量函数变为<script type="math/tex; mode=display">
E(f) = \frac{1}{2} \left( 2 \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_i) - 2 \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) \right)</script></li>
<li><strong>引入度矩阵</strong><br>定义度矩阵 $ \mathbf{D} $ 为对角矩阵，其对角线元素为：<script type="math/tex; mode=display">
d_i = \sum_{j=1}^m (\mathbf{W})_{ij}</script>最终能量函数可表示为：<script type="math/tex; mode=display">
E(f) = \sum_{i=1}^m d_i f^2(\boldsymbol{x}_i) - \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) = \boldsymbol{f}^\top (\mathbf{D} - \mathbf{W}) \boldsymbol{f}</script>其中，$ \boldsymbol{f} = [f(\boldsymbol{x}_1), f(\boldsymbol{x}_2), \dots, f(\boldsymbol{x}_m)]^\top $。</li>
</ol>
<p><strong>图半监督学习方法推导详解</strong></p>
<p><strong>1. 分块矩阵表示</strong></p>
<p>将亲和矩阵 $ \mathbf{W} $ 和度矩阵 $ \mathbf{D} $ 按有标记数据（前 $ l $ 行列）和未标记数据（后 $ u $ 行列）分块：</p>
<script type="math/tex; mode=display">
\mathbf{W} = 
\begin{bmatrix}
\mathbf{W}_{ll} & \mathbf{W}_{lu} \\
\mathbf{W}_{ul} & \mathbf{W}_{uu}
\end{bmatrix}, \quad
\mathbf{D} = 
\begin{bmatrix}
\mathbf{D}_{ll} & \mathbf{0}_{lu} \\
\mathbf{0}_{ul} & \mathbf{D}_{uu}
\end{bmatrix}</script><p>其中：</p>
<ul>
<li>$ \mathbf{W}_{ll} $：有标记数据间的亲和度。  </li>
<li>$ \mathbf{W}_{lu} $：有标记与未标记数据间的亲和度。  </li>
<li>$ \mathbf{W}_{uu} $：未标记数据间的亲和度。  </li>
<li>$ \mathbf{D}<em>{ll}, \mathbf{D}</em>{uu} $：对应子图的度矩阵。</li>
</ul>
<p><strong>2. 能量函数的分块展开</strong></p>
<p>能量函数 $ E(f) = \boldsymbol{f}^\top (\mathbf{D} - \mathbf{W}) \boldsymbol{f} $ 可展开为</p>
<p>展开后得到：</p>
<script type="math/tex; mode=display">
E(f) = \boldsymbol{f}_l^\top (\mathbf{D}_{ll} - \mathbf{W}_{ll}) \boldsymbol{f}_l - 2 \boldsymbol{f}_u^\top \mathbf{W}_{ul} \boldsymbol{f}_l + \boldsymbol{f}_u^\top (\mathbf{D}_{uu} - \mathbf{W}_{uu}) \boldsymbol{f}_u</script><p><strong>3. 对未标记数据 $ \boldsymbol{f}_u $ 求偏微分</strong></p>
<p>目标是最小化 $ E(f) $，对 $ \boldsymbol{f}_u $ 求偏导并令其为零：</p>
<script type="math/tex; mode=display">
\frac{\partial E(f)}{\partial \boldsymbol{f}_u} = -2 \mathbf{W}_{ul} \boldsymbol{f}_l + 2 (\mathbf{D}_{uu} - \mathbf{W}_{uu}) \boldsymbol{f}_u = 0</script><p>解得：</p>
<script type="math/tex; mode=display">
\boldsymbol{f}_u = (\mathbf{D}_{uu} - \mathbf{W}_{uu})^{-1} \mathbf{W}_{ul} \boldsymbol{f}_l</script><h4 id="协同训练"><a href="#协同训练" class="headerlink" title="协同训练"></a>协同训练</h4><p>协同训练（Co-training）是一种经典的<strong>半监督学习方法</strong>，由Blum和Mitchell于1998年首次提出，主要用于处理<strong>多视图数据</strong>（Multi-view Data）。其核心思想是通过多个分类器的协作，利用少量标记数据和大量未标记数据提升模型性能。以下是详细解析：</p>
<p><strong>1. 核心思想与假设</strong></p>
<p><strong>（1）多视图数据</strong></p>
<ul>
<li><strong>定义</strong>：每个样本可被划分为多个<strong>充分冗余且条件独立</strong>的视图（View）。  <ul>
<li><strong>充分冗余</strong>：每个视图本身包含足够信息，可独立完成学习任务。  </li>
<li><strong>条件独立性</strong>：在给定类别标签的条件下，不同视图的特征相互独立。<br>例如，网页数据可划分为“文本内容”和“超链接结构”两个视图，它们共同描述网页内容。</li>
</ul>
</li>
</ul>
<p><strong>（2）协作机制</strong></p>
<ul>
<li><strong>双分类器设计</strong>：使用两个分类器 $ h_1 $ 和 $ h_2 $，分别基于视图 $ V_1 $ 和 $ V_2 $ 进行训练。  </li>
<li><strong>伪标签生成</strong>：分类器 $ h_1 $ 对未标记数据的高置信度预测结果会被 $ h_2 $ 使用，反之亦然，形成迭代优化。  </li>
<li><strong>目标</strong>：通过分类器间的互补性，逐步扩展标记数据集，提升模型泛化能力。</li>
</ul>
<p><strong>2. 算法流程</strong></p>
<ol>
<li><strong>初始化阶段</strong>：  <ul>
<li>使用少量标记数据 $ D_l $，分别训练分类器 $ h_1 $（基于视图 $ V_1 $）和 $ h_2 $（基于视图 $ V_2 $）。  </li>
</ul>
</li>
<li><strong>伪标签生成</strong>：  <ul>
<li>对未标记数据 $ D_u $，$ h_1 $ 预测视图 $ V_1 $ 的伪标签，$ h_2 $ 预测视图 $ V_2 $ 的伪标签。  </li>
<li>选择置信度高于阈值的样本加入训练集（如 $ h_1 $ 的预测结果用于更新 $ h_2 $ 的训练数据，反之亦然）。  </li>
</ul>
</li>
<li><strong>迭代优化</strong>：  <ul>
<li>重复伪标签生成和模型训练，直到未标记数据耗尽或模型收敛。</li>
</ul>
</li>
</ol>
<p><strong>3. 核心优势</strong></p>
<ul>
<li><strong>减少对标注数据的依赖</strong>：仅需少量标记数据即可训练高性能模型，尤其适合标注成本高的场景（如医疗影像分析）。  </li>
<li><strong>提升模型鲁棒性</strong>：分类器间的协作可纠正彼此的错误，降低单一模型过拟合风险。  </li>
<li><strong>多视图互补性</strong>：不同视图的信息融合能捕捉更全面的特征（如图像的RGB通道与纹理特征）。</li>
</ul>
<h4 id="作业-4"><a href="#作业-4" class="headerlink" title="作业"></a>作业</h4><h5 id="1-4"><a href="#1-4" class="headerlink" title="1"></a>1</h5><p>什么是半监督学习？请简要描述其基本思想。半监督学习相比于监督学习和无监督学习有什么优势和应用场景？</p>
<p><strong>（1）定义与基本思想</strong>  </p>
<p>半监督学习（Semi-Supervised Learning）是结合<strong>监督学习</strong>（利用标记数据）和<strong>无监督学习</strong>（利用未标记数据）的机器学习方法，其核心思想是通过少量标记数据与大量未标记数据的联合训练，提升模型的泛化能力和鲁棒性。  </p>
<ul>
<li><strong>监督学习</strong>：依赖大量人工标注数据（如分类、回归）。  </li>
<li><strong>无监督学习</strong>：仅利用数据分布规律（如聚类、降维）。  </li>
<li><strong>半监督学习</strong>：在标记数据稀缺时，通过未标记数据挖掘潜在结构，降低标注成本 。</li>
</ul>
<p><strong>（2）优势</strong>  </p>
<ul>
<li><strong>减少标注依赖</strong>：仅需少量标记数据即可训练高性能模型，适用于标注成本高的场景（如医疗影像分析）。  </li>
<li><strong>提升模型性能</strong>：利用未标记数据增强数据多样性，缓解过拟合风险。  </li>
<li><strong>平衡效率与精度</strong>：在资源有限时，兼顾监督学习的准确性与无监督学习的高效性 。</li>
</ul>
<p><strong>（3）应用场景</strong>  </p>
<ul>
<li><strong>医学诊断</strong>：利用少量标注的病理图像和大量未标注数据训练疾病预测模型。  </li>
<li><strong>推荐系统</strong>：结合用户行为（有标记）与商品属性（未标记）优化排序模型。  </li>
<li><strong>自然语言处理</strong>：通过预训练模型（如GPT）的“预训练+微调”框架，减少人工标注需求 。</li>
</ul>
<h5 id="2-4"><a href="#2-4" class="headerlink" title="2"></a>2</h5><p>协同训练算法的作用是什么？请简述算法主要流程和所需条件。</p>
<p><strong>（1）作用与核心思想</strong>  </p>
<p>协同训练是一种典型的半监督学习方法，适用于<strong>多视图数据</strong>（Multi-view Data）。其核心思想是通过多个分类器的协作，利用未标记数据扩展训练集，最终提升模型性能。  </p>
<ul>
<li><strong>多视图条件</strong>：  <ul>
<li><strong>充分冗余</strong>：每个视图本身包含足够信息，可独立完成任务。  </li>
<li><strong>条件独立性</strong>：在给定类别标签的条件下，不同视图的特征相互独立 。</li>
</ul>
</li>
</ul>
<p><strong>（2）算法流程</strong>  </p>
<ol>
<li><strong>初始化阶段</strong>：  <ul>
<li>使用少量标记数据 $ D_l $，分别训练两个分类器 $ h_1 $（基于视图 $ V_1 $）和 $ h_2 $（基于视图 $ V_2 $）。  </li>
</ul>
</li>
<li><strong>伪标签生成</strong>：  <ul>
<li>对未标记数据 $ D_u $，$ h_1 $ 预测 $ V_2 $ 的伪标签，$ h_2 $ 预测 $ V_1 $ 的伪标签。  </li>
<li>选择置信度高于阈值的样本加入训练集（如 $ h_1 $ 的预测结果用于更新 $ h_2 $ 的训练数据，反之亦然）。  </li>
</ul>
</li>
<li><strong>迭代优化</strong>：  <ul>
<li>重复伪标签生成和模型训练，直到未标记数据耗尽或模型收敛 。</li>
</ul>
</li>
</ol>
<p><strong>（3）所需条件</strong>  </p>
<ul>
<li><strong>多视图划分</strong>：数据需满足“充分冗余”和“条件独立性”（如图像的RGB通道与纹理特征）。  </li>
<li><strong>分类器多样性</strong>：选择差异较大的分类器（如SVM + 决策树），增强互补性。  </li>
<li><strong>伪标签可靠性</strong>：初始模型需有一定性能，避免错误伪标签污染训练集 。</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>请我一杯咖啡吧！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.png" alt="张熙浚 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipay.png" alt="张熙浚 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E5%AD%A6/" rel="tag"># 大学</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/06/01/%E5%AD%A6%E4%B9%A0/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/" rel="prev" title="weatherweb开发学习记录">
                  <i class="fa fa-angle-left"></i> weatherweb开发学习记录
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/" rel="next" title="计算机系统基础期末笔记汇总">
                  计算机系统基础期末笔记汇总 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">张熙浚</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="本站访问数 fa fa-user 次"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="本站总访问量 fa fa-eye 次"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="400" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
