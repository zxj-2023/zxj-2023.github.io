<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="前言本教程为langchain官方教程的学习记录 academy.langchain.com&#x2F;enrollments 代码见zxj-2023&#x2F;learn-rag-langchain module-4Parallel node execution 并行节点执行Waiting for nodes to finish 等待节点完成现在，让我们考虑一个案例，其中一个并行路径的步骤比另一个多。 123456">
<meta property="og:type" content="article">
<meta property="og:title" content="LangGraph学习——agent——下">
<meta property="og:url" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/index.html">
<meta property="og:site_name" content="Zhang XiJun">
<meta property="og:description" content="前言本教程为langchain官方教程的学习记录 academy.langchain.com&#x2F;enrollments 代码见zxj-2023&#x2F;learn-rag-langchain module-4Parallel node execution 并行节点执行Waiting for nodes to finish 等待节点完成现在，让我们考虑一个案例，其中一个并行路径的步骤比另一个多。 123456">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722143802652.png">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722153534867.png">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/66dbb1abf89f2d847ee6f1ff_sub-graph1.png">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723094949158.png">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723100648199.png">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723102913524.png">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723112736244.png">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725155616205-1753430177489-3.png">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725161106319.png">
<meta property="og:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250726103516996.png">
<meta property="article:published_time" content="2025-07-21T16:00:00.000Z">
<meta property="article:modified_time" content="2025-07-27T04:14:49.303Z">
<meta property="article:author" content="张熙浚">
<meta property="article:tag" content="langgraph">
<meta property="article:tag" content="fastapi">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722143802652.png">


<link rel="canonical" href="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/","path":"2025/07/22/学习/ai框架/langgraph-agent下/","title":"LangGraph学习——agent——下"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>LangGraph学习——agent——下 | Zhang XiJun</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Zhang XiJun</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">BLOGS</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#module-4"><span class="nav-number">2.</span> <span class="nav-text">module-4</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Parallel-node-execution-%E5%B9%B6%E8%A1%8C%E8%8A%82%E7%82%B9%E6%89%A7%E8%A1%8C"><span class="nav-number">2.1.</span> <span class="nav-text">Parallel node execution 并行节点执行</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Waiting-for-nodes-to-finish-%E7%AD%89%E5%BE%85%E8%8A%82%E7%82%B9%E5%AE%8C%E6%88%90"><span class="nav-number">2.1.1.</span> <span class="nav-text">Waiting for nodes to finish 等待节点完成</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Setting-the-order-of-state-updates-%E8%AE%BE%E7%BD%AE%E7%8A%B6%E6%80%81%E6%9B%B4%E6%96%B0%E7%9A%84%E9%A1%BA%E5%BA%8F"><span class="nav-number">2.1.2.</span> <span class="nav-text">Setting the order of state updates 设置状态更新的顺序</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Working-with-LLMs-%E4%BD%BF%E7%94%A8-LLMs"><span class="nav-number">2.1.3.</span> <span class="nav-text">Working with LLMs  使用 LLMs</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Sub-graphs-%E5%AD%90%E5%9B%BE"><span class="nav-number">2.2.</span> <span class="nav-text">Sub-graphs 子图</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Sub-graphs"><span class="nav-number">2.2.1.</span> <span class="nav-text">Sub graphs</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Adding-sub-graphs-to-our-parent-graph-%E5%90%91%E7%88%B6%E5%9B%BE%E6%B7%BB%E5%8A%A0%E5%AD%90%E5%9B%BE"><span class="nav-number">2.2.2.</span> <span class="nav-text">Adding sub graphs to our parent graph  向父图添加子图</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-reduce"><span class="nav-number">2.3.</span> <span class="nav-text">Map-reduce</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Parallelizing-joke-generation-%E5%B9%B6%E8%A1%8C%E5%8C%96%E7%AC%91%E8%AF%9D%E7%94%9F%E6%88%90"><span class="nav-number">2.3.1.</span> <span class="nav-text">Parallelizing joke generation 并行化笑话生成</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Joke-generation-map-%E7%AC%91%E8%AF%9D%E7%94%9F%E6%88%90"><span class="nav-number">2.3.2.</span> <span class="nav-text">Joke generation (map) 笑话生成</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Best-joke-selection-reduce-%E6%9C%80%E4%BD%B3%E7%AC%91%E8%AF%9D%E9%80%89%E6%8B%A9"><span class="nav-number">2.3.3.</span> <span class="nav-text">Best joke selection (reduce) 最佳笑话选择</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Compile-%E7%BC%96%E8%AF%91"><span class="nav-number">2.3.4.</span> <span class="nav-text">Compile 编译</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#module-5"><span class="nav-number">3.</span> <span class="nav-text">module-5</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Chatbot-with-Memory-%E5%B8%A6%E6%9C%89%E8%AE%B0%E5%BF%86%E5%8A%9F%E8%83%BD%E7%9A%84%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="nav-number">3.1.</span> <span class="nav-text">Chatbot with Memory 带有记忆功能的聊天机器人</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Introduction-to-the-LangGraph-Store-LangGraph-%E5%AD%98%E5%82%A8%E7%AE%80%E4%BB%8B"><span class="nav-number">3.1.1.</span> <span class="nav-text">Introduction to the LangGraph Store LangGraph 存储简介</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Chatbot-with-long-term-memory-%E5%85%B7%E6%9C%89%E9%95%BF%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%9A%84%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="nav-number">3.1.2.</span> <span class="nav-text">Chatbot with long-term memory 具有长期记忆的聊天机器人</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Chatbot-with-Profile-Schema-%E5%B8%A6%E6%9C%89%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="nav-number">3.2.</span> <span class="nav-text">Chatbot with Profile Schema 带有配置文件模式的聊天机器人</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Defining-a-user-profile-schema-%E5%AE%9A%E4%B9%89%E7%94%A8%E6%88%B7%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A8%A1%E5%BC%8F"><span class="nav-number">3.2.1.</span> <span class="nav-text">Defining a user profile schema 定义用户配置文件模式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Saving-a-schema-to-the-store-%E5%B0%86%E6%A8%A1%E5%BC%8F%E4%BF%9D%E5%AD%98%E5%88%B0%E5%AD%98%E5%82%A8%E4%B8%AD"><span class="nav-number">3.2.2.</span> <span class="nav-text">Saving a schema to the store 将模式保存到存储中</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Chatbot-with-profile-schema-%E5%B8%A6%E6%9C%89%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="nav-number">3.2.3.</span> <span class="nav-text">Chatbot with profile schema 带有配置文件模式的聊天机器人</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Trustcall-for-creating-and-updating-profile-schemas-Trustcall-%E7%94%A8%E4%BA%8E%E5%88%9B%E5%BB%BA%E5%92%8C%E6%9B%B4%E6%96%B0%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A8%A1%E5%BC%8F"><span class="nav-number">3.2.4.</span> <span class="nav-text">Trustcall for creating and updating profile schemas Trustcall 用于创建和更新配置文件模式</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Chatbot-with-Collection-Schema-%E5%B8%A6%E9%9B%86%E5%90%88%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="nav-number">3.3.</span> <span class="nav-text">Chatbot with Collection Schema 带集合模式的聊天机器人</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Memory-Agent-%E5%86%85%E5%AD%98%E4%BB%A3%E7%90%86"><span class="nav-number">3.4.</span> <span class="nav-text">Memory Agent 内存代理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Creating-an-agent-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%90%86"><span class="nav-number">3.4.1.</span> <span class="nav-text">Creating an agent 创建一个代理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Graph-definition-%E5%9B%BE%E5%AE%9A%E4%B9%89"><span class="nav-number">3.4.2.</span> <span class="nav-text">Graph definition 图定义</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#module-6"><span class="nav-number">4.</span> <span class="nav-text">module-6</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="张熙浚"
      src="/images/zxjavatar.gif">
  <p class="site-author-name" itemprop="name">张熙浚</p>
  <div class="site-description" itemprop="description">zxj Blogs</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">124</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">45</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zxj-2023" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxj-2023" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=2902065320&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;2902065320&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener me" target="_blank"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zxj-2023.github.io/" title="https:&#x2F;&#x2F;zxj-2023.github.io" rel="noopener" target="_blank">Zhang XiJun</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org" rel="noopener" target="_blank">NexT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="LangGraph学习——agent——下 | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          LangGraph学习——agent——下
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-22T00:00:00+08:00">2025-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-27 12:14:49" itemprop="dateModified" datetime="2025-07-27T12:14:49+08:00">2025-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="本文总阅读量 far fa-eye 次"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本教程为langchain官方教程的学习记录</p>
<p><a target="_blank" rel="noopener" href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a target="_blank" rel="noopener" href="https://github.com/zxj-2023/learn-rag-langchain">zxj-2023/learn-rag-langchain</a></p>
<h3 id="module-4"><a href="#module-4" class="headerlink" title="module-4"></a>module-4</h3><h4 id="Parallel-node-execution-并行节点执行"><a href="#Parallel-node-execution-并行节点执行" class="headerlink" title="Parallel node execution 并行节点执行"></a><strong>Parallel node execution</strong> <strong>并行节点执行</strong></h4><h5 id="Waiting-for-nodes-to-finish-等待节点完成"><a href="#Waiting-for-nodes-to-finish-等待节点完成" class="headerlink" title="Waiting for nodes to finish 等待节点完成"></a><strong>Waiting for nodes to finish</strong> <strong>等待节点完成</strong></h5><p>现在，让我们考虑一个案例，其中一个并行路径的步骤比另一个多。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># Initialize each node with node_secret </span><br><span class="line">builder.add_node(&quot;a&quot;, ReturnNodeValue(&quot;I&#x27;m A&quot;))</span><br><span class="line">builder.add_node(&quot;b&quot;, ReturnNodeValue(&quot;I&#x27;m B&quot;))</span><br><span class="line">builder.add_node(&quot;b2&quot;, ReturnNodeValue(&quot;I&#x27;m B2&quot;))</span><br><span class="line">builder.add_node(&quot;c&quot;, ReturnNodeValue(&quot;I&#x27;m C&quot;))</span><br><span class="line">builder.add_node(&quot;d&quot;, ReturnNodeValue(&quot;I&#x27;m D&quot;))</span><br><span class="line"></span><br><span class="line"># Flow</span><br><span class="line">builder.add_edge(START, &quot;a&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;b&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;c&quot;)</span><br><span class="line">builder.add_edge(&quot;b&quot;, &quot;b2&quot;)</span><br><span class="line">builder.add_edge([&quot;b2&quot;, &quot;c&quot;], &quot;d&quot;)</span><br><span class="line">builder.add_edge(&quot;d&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722143802652.png" alt="image-20250722143802652"></p>
<p>在这种情况下，<code>b</code>、<code>b2</code> 和 <code>c</code> 都是同一个步骤的一部分。图形将在进入 <code>d</code> 步骤之前等待所有这些操作完成。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Adding I&#x27;m A to []</span><br><span class="line">Adding I&#x27;m B to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m C to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m B2 to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;]</span><br><span class="line">Adding I&#x27;m D to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;]</span><br><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Setting-the-order-of-state-updates-设置状态更新的顺序"><a href="#Setting-the-order-of-state-updates-设置状态更新的顺序" class="headerlink" title="Setting the order of state updates 设置状态更新的顺序"></a><strong>Setting the order of state updates</strong> <strong>设置状态更新的顺序</strong></h5><p>然而，在每个步骤中，我们无法对状态更新的顺序进行具体控制！简单来说，它是基于图拓扑结构由 LangGraph 确定的确定性顺序，该顺序为 <strong><em>\</em>我们无法控制**</strong>。</p>
<p>上面，我们看到 <code>c</code> 被添加在 <code>b2</code> 之前</p>
<p>然而，我们可以使用自定义 reducer 来定制此功能，例如，对状态更新进行排序。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def sorting_reducer(left, right):</span><br><span class="line">    &quot;&quot;&quot; 合并并排序列表中的值&quot;&quot;&quot;</span><br><span class="line">    # 如果 left 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(left, list):</span><br><span class="line">        left = [left]</span><br><span class="line"></span><br><span class="line">    # 如果 right 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(right, list):</span><br><span class="line">        right = [right]</span><br><span class="line">    </span><br><span class="line">    # 合并 left 和 right 列表，然后升序排序</span><br><span class="line">    return sorted(left + right, reverse=False)</span><br><span class="line">class State(TypedDict):</span><br><span class="line">    # sorting_reducer 函数将对 state 中的值进行排序</span><br><span class="line">    state: Annotated[list, sorting_reducer]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<p>现在，reducer 对更新的状态值进行排序！<code>sorting_reducer</code> 示例对所有值进行全局排序。我们还可以：</p>
<ol>
<li>在并行步骤期间将输出写入状态中的单独字段  </li>
<li>在并行步骤之后使用“汇”节点来合并和排序这些输出  </li>
<li>合并后清除临时字段</li>
</ol>
<p>请参阅 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/branching/#stable-sorting">docs</a> 以获取更多详细信息。</p>
<h5 id="Working-with-LLMs-使用-LLMs"><a href="#Working-with-LLMs-使用-LLMs" class="headerlink" title="Working with LLMs  使用 LLMs"></a><strong>Working with LLMs</strong>  <strong>使用 LLMs</strong></h5><p>现在，让我们添加一个现实中的例子！我们希望从两个外部来源（Wikipedia 和 Web-Search）收集上下文信息，并让 LLM 回答一个问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br><span class="line">from langchain_community.tools import TavilySearchResults</span><br><span class="line"></span><br><span class="line">def search_web(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">    search_docs = tavily_search.invoke(state[&#x27;question&#x27;])</span><br><span class="line"></span><br><span class="line">     # 将多个搜索文档转换成了一个统一格式的长文本，每个文档都有自己的元数据（如URL），并且文档之间有明确的分隔，便于后续处理或展示。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    - 这是一个 列表推导式 (list comprehension) ，它会遍历 search_docs 列表中的每一个元素（这里我们称之为 doc ）。</span><br><span class="line">    - search_docs 里的每个 doc 应该是一个包含 &#x27;url&#x27; 和 &#x27;content&#x27; 键的字典。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = WikipediaLoader(query=state[&#x27;question&#x27;], </span><br><span class="line">                                  load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def generate_answer(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 用于回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    question = state[&quot;question&quot;]</span><br><span class="line"></span><br><span class="line">    # 模板</span><br><span class="line">    answer_template = &quot;&quot;&quot;使用以下上下文回答问题 &#123;question&#125;: &#123;context&#125;&quot;&quot;&quot;</span><br><span class="line">    answer_instructions = answer_template.format(question=question, </span><br><span class="line">                                                       context=context)    </span><br><span class="line">    </span><br><span class="line">    # 回答</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=answer_instructions)]+[HumanMessage(content=f&quot;回答问题。&quot;)])</span><br><span class="line">      </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;answer&quot;: answer&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点</span><br><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># 初始化每个节点</span><br><span class="line">builder.add_node(&quot;search_web&quot;,search_web)</span><br><span class="line">builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">builder.add_node(&quot;generate_answer&quot;, generate_answer)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">builder.add_edge(START, &quot;search_wikipedia&quot;)</span><br><span class="line">builder.add_edge(START, &quot;search_web&quot;)</span><br><span class="line">builder.add_edge(&quot;search_wikipedia&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;search_web&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;generate_answer&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722153534867.png" alt="image-20250722153534867"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = graph.invoke(&#123;&quot;question&quot;: &quot;英伟达2025年第一季度财报表现如何&quot;&#125;)</span><br><span class="line">result[&#x27;answer&#x27;].content</span><br></pre></td></tr></table></figure>
<h4 id="Sub-graphs-子图"><a href="#Sub-graphs-子图" class="headerlink" title="Sub-graphs 子图"></a><strong>Sub-graphs</strong> 子图</h4><p>子图允许你在图表的不同部分创建和管理不同的状态。这在多智能体系统中尤其有用，尤其是在每个智能体都有各自状态的智能体团队中。</p>
<p>让我们考虑一个简单的例子：</p>
<ul>
<li>我有一个系统，它接收日志。</li>
<li>该系统通过不同的代理执行两个独立的子任务（总结日志，查找故障模式）。</li>
<li>我希望在两个不同的子图中执行这两个操作。</li>
</ul>
<p>最重要的是要理解图表是如何传达信息的！</p>
<p>简而言之，通信是 <strong><em>\</em>通过重叠密钥**</strong> 实现的：</p>
<ul>
<li>子图可以访问父图中的 <code>docs</code>（文档）。</li>
<li>父图可以从子图中访问 <code>summary</code>（摘要）和 <code>failure_report</code>（故障报告）。</li>
</ul>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/66dbb1abf89f2d847ee6f1ff_sub-graph1.png" alt="subgraph.png"></p>
<ol>
<li><strong>Logs (Traces)</strong>:<ul>
<li>这是系统的输入，表示一系列的日志记录。</li>
</ul>
</li>
<li><strong>Entry Graph</strong>:<ul>
<li>这是系统的入口图，它包含了总体状态（Overall State），其中包含：<ul>
<li><code>docs</code>：文档或日志数据。</li>
<li><code>summary report</code>：摘要报告，这是系统执行摘要任务后生成的。</li>
<li><code>failure report</code>：故障报告，这是系统执行故障分析任务后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Call sub-graphs</strong>:<ul>
<li>这是从入口图调用两个子图的过程，分别用于执行摘要和故障分析任务。</li>
</ul>
</li>
<li><strong>Summarization</strong>:<ul>
<li>这个子图负责生成日志的摘要。它的状态（Summary State）包含：<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>summary</code>：摘要内容。</li>
<li><code>summary report</code>：摘要报告，这是摘要任务完成后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Failure Analysis</strong>:<ul>
<li>这个子图负责分析日志中的故障模式。它的状态（Failure Analysis State）包含：<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>failures</code>：故障模式。</li>
<li><code>failure report</code>：故障报告，这是故障分析任务完成后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Finish</strong>:<ul>
<li>这是流程的结束点，表示两个子图的任务都已完成，并且生成了摘要报告和故障报告。</li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from typing import List, Optional, Annotated</span><br><span class="line"></span><br><span class="line">#logs结构</span><br><span class="line">class Log(TypedDict):</span><br><span class="line">    id: str</span><br><span class="line">    question: str</span><br><span class="line">    docs: Optional[List]</span><br><span class="line">    answer: str</span><br><span class="line">    grade: Optional[int]</span><br><span class="line">    grader: Optional[str]</span><br><span class="line">    feedback: Optional[str]</span><br></pre></td></tr></table></figure>
<h5 id="Sub-graphs"><a href="#Sub-graphs" class="headerlink" title="Sub graphs"></a><strong>Sub graphs</strong></h5><p>这里是失败分析子图，它使用了 <code>FailureAnalysisState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line"># 故障分析子图</span><br><span class="line">class FailureAnalysisState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于故障分析的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    failures: List[Log]     # 包含故障的日志列表</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class FailureAnalysisOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;故障分析的输出状态。&quot;&quot;&quot;</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def get_failures(state):</span><br><span class="line">    &quot;&quot;&quot;获取包含故障的日志&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 从清理后的日志中筛选出包含 &quot;grade&quot; 键的日志，这些被视为故障</span><br><span class="line">    failures = [log for log in cleaned_logs if &quot;grade&quot; in log]</span><br><span class="line">    return &#123;&quot;failures&quot;: failures&#125;</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;生成故障摘要&quot;&quot;&quot;</span><br><span class="line">    failures = state[&quot;failures&quot;]</span><br><span class="line">    # 添加功能：fa_summary = summary_generation(qs_summary)</span><br><span class="line">    fa_summary = &quot;Chroma 文档的检索质量不佳。&quot;</span><br><span class="line">    # 为每个故障日志生成一个处理过的日志标识符</span><br><span class="line">    return &#123;&quot;fa_summary&quot;: fa_summary, &quot;processed_logs&quot;: [f&quot;failure-analysis-on-log-&#123;failure[&#x27;id&#x27;]&#125;&quot; for failure in failures]&#125;</span><br><span class="line"></span><br><span class="line">fa_builder = StateGraph(state_schema=FailureAnalysisState,output_schema=FailureAnalysisOutputState)</span><br><span class="line">fa_builder.add_node(&quot;get_failures&quot;, get_failures)</span><br><span class="line">fa_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">fa_builder.add_edge(START, &quot;get_failures&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;get_failures&quot;, &quot;generate_summary&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;generate_summary&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = fa_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723094949158.png" alt="image-20250723094949158"></p>
<p>这里是问题总结子图，它使用了 <code>QuestionSummarizationState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># 摘要生成子图</span><br><span class="line">class QuestionSummarizationState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于问题摘要的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    qs_summary: str         # 问题摘要</span><br><span class="line">    report: str             # 从摘要生成的报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class QuestionSummarizationOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;问题摘要的输出状态。&quot;&quot;&quot;</span><br><span class="line">    report: str             # 最终报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;从日志生成摘要。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 添加功能：summary = summarize(generate_summary)</span><br><span class="line">    summary = &quot;问题集中在 ChatOllama 和 Chroma 向量存储的使用上。&quot;</span><br><span class="line">    # 返回摘要以及已处理的日志ID</span><br><span class="line">    return &#123;&quot;qs_summary&quot;: summary, &quot;processed_logs&quot;: [f&quot;summary-on-log-&#123;log[&#x27;id&#x27;]&#125;&quot; for log in cleaned_logs]&#125;</span><br><span class="line"></span><br><span class="line">def send_to_slack(state):</span><br><span class="line">    &quot;&quot;&quot;模拟发送报告。&quot;&quot;&quot;</span><br><span class="line">    qs_summary = state[&quot;qs_summary&quot;]</span><br><span class="line">    # 添加功能：report = report_generation(qs_summary)</span><br><span class="line">    report = &quot;foo bar baz&quot;</span><br><span class="line">    return &#123;&quot;report&quot;: report&#125;</span><br><span class="line"></span><br><span class="line">qs_builder = StateGraph(QuestionSummarizationState,output_schema=QuestionSummarizationOutputState)</span><br><span class="line">qs_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">qs_builder.add_node(&quot;send_to_slack&quot;, send_to_slack)</span><br><span class="line">qs_builder.add_edge(START, &quot;generate_summary&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;generate_summary&quot;, &quot;send_to_slack&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;send_to_slack&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = qs_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723100648199.png" alt="image-20250723100648199"></p>
<h5 id="Adding-sub-graphs-to-our-parent-graph-向父图添加子图"><a href="#Adding-sub-graphs-to-our-parent-graph-向父图添加子图" class="headerlink" title="Adding sub graphs to our parent graph  向父图添加子图"></a><strong>Adding sub graphs to our parent graph </strong> <strong>向父图添加子图</strong></h5><p>现在，我们可以将所有内容整合在一起。我们使用 <code>EntryGraphState</code> 创建父图。并且我们将我们的子图添加为节点！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 入口图</span><br><span class="line">class EntryGraphState(TypedDict):</span><br><span class="line">    # 原始日志数据列表</span><br><span class="line">    raw_logs: List[Log]</span><br><span class="line">    # 经过清洗处理后的日志数据列表</span><br><span class="line">    cleaned_logs: List[Log]</span><br><span class="line">    fa_summary: str # 这只会在故障分析子图中生成</span><br><span class="line">    report: str # 这只会在问题摘要子图中生成</span><br><span class="line">    processed_logs:  Annotated[List[int], add] # 跟踪哪些日志已经被处理过 ，尤其是在子图之间共享状态时。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def clean_logs(state):</span><br><span class="line">    # 获取日志</span><br><span class="line">    raw_logs = state[&quot;raw_logs&quot;]</span><br><span class="line">    # 数据清洗 raw_logs -&gt; docs</span><br><span class="line">    cleaned_logs = raw_logs</span><br><span class="line">    return &#123;&quot;cleaned_logs&quot;: cleaned_logs&#125;</span><br><span class="line"></span><br><span class="line">entry_builder = StateGraph(EntryGraphState)</span><br><span class="line">entry_builder.add_node(&quot;clean_logs&quot;, clean_logs)</span><br><span class="line">#添加子图</span><br><span class="line">entry_builder.add_node(&quot;question_summarization&quot;, qs_builder.compile())</span><br><span class="line">entry_builder.add_node(&quot;failure_analysis&quot;, fa_builder.compile())</span><br><span class="line"></span><br><span class="line">entry_builder.add_edge(START, &quot;clean_logs&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;failure_analysis&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;question_summarization&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;failure_analysis&quot;, END)</span><br><span class="line">entry_builder.add_edge(&quot;question_summarization&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = entry_builder.compile()</span><br><span class="line"></span><br><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line"># 将 xray 设置为 1 将显示嵌套图的内部结构</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723102913524.png" alt="image-20250723102913524"></p>
<h4 id="Map-reduce"><a href="#Map-reduce" class="headerlink" title="Map-reduce"></a><strong>Map-reduce</strong></h4><p>LangGraph 里的 <strong>Map-Reduce</strong> 是一种<strong>并行处理模式</strong>，用于将一个大任务拆分成多个子任务（Map），再汇总结果（Reduce）。这是 LangGraph 中处理<strong>批量数据或并行节点执行</strong>的核心机制之一。</p>
<p>让我们设计一个系统，该系统将完成两件事情：</p>
<p>(1) <strong>映射（Map）</strong> —— 根据主题生成一组笑话。<br>(2) <strong>归约（Reduce）</strong> —— 从这组笑话中挑出最棒的一条。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"># Prompts we will use</span><br><span class="line">subjects_prompt = &quot;&quot;&quot;生成一个包含3个子主题的列表，这些子主题都与以下总体主题相关：&#123;topic&#125;。&quot;&quot;&quot;</span><br><span class="line">joke_prompt = &quot;&quot;&quot;生成一个关于&#123;subject&#125;的笑话&quot;&quot;&quot;</span><br><span class="line">best_joke_prompt = &quot;&quot;&quot;下面是关于&#123;topic&#125;的一堆笑话。选择最好的一个！返回最好笑话的ID，第一个笑话的ID从0开始。笑话：\n\n  &#123;jokes&#125;&quot;&quot;&quot;</span><br><span class="line"># LLM</span><br><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h5 id="Parallelizing-joke-generation-并行化笑话生成"><a href="#Parallelizing-joke-generation-并行化笑话生成" class="headerlink" title="Parallelizing joke generation 并行化笑话生成"></a><strong>Parallelizing joke generation</strong> <strong>并行化笑话生成</strong></h5><p>首先，让我们定义图的入口点，它将：</p>
<ul>
<li>接收用户输入的主题  </li>
<li>基于该主题生成若干“笑话子主题”  </li>
<li>将每个子主题发送到上面定义的笑话生成节点</li>
</ul>
<p>我们的状态有一个 <code>jokes</code> 键，它将累积来自并行化笑话生成的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Subjects(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示主题列表。&quot;&quot;&quot;</span><br><span class="line">    subjects: list[str] # 主题字符串列表</span><br><span class="line"></span><br><span class="line">class BestJoke(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示最佳笑话的ID。&quot;&quot;&quot;</span><br><span class="line">    id: int # 最佳笑话的索引ID</span><br><span class="line">    </span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;定义整个图的总体状态，使用TypedDict以便于类型提示和状态管理。&quot;&quot;&quot;</span><br><span class="line">    topic: str # 当前讨论的主题</span><br><span class="line">    subjects: list # 生成的子主题列表</span><br><span class="line">    jokes: Annotated[list, operator.add] # 笑话列表，使用operator.add表示列表内容会累加而不是覆盖</span><br><span class="line">    best_selected_joke: str # 最终选出的最佳笑话</span><br></pre></td></tr></table></figure>
<p>生成笑话的主题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#用于生成主题</span><br><span class="line">def generate_topics(state: OverallState):</span><br><span class="line">    #使用 Python 的 format() 方法来构建一个提示字符串（ prompt ）</span><br><span class="line">    prompt = subjects_prompt.format(topic=state[&quot;topic&quot;])</span><br><span class="line">    #.with_structured_output(Subjects) 它指示模型尝试将其输出格式化为 Subjects 类</span><br><span class="line">    response = model.with_structured_output(Subjects).invoke(prompt)</span><br><span class="line">    return &#123;&quot;subjects&quot;: response.subjects&#125;</span><br></pre></td></tr></table></figure>
<p>这就是妙处：我们利用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#send"><code>Send</code></a> 为每个主题并行生成笑话。</p>
<p>非常实用！无论主题数量多少，它都能自动并行处理。</p>
<ul>
<li><code>generate_joke</code>：图中节点的名字  </li>
<li><code>&#123;&quot;subject&quot;: s&#125;</code>：要传递的状态</li>
</ul>
<p><code>Send</code> 允许你向 <code>generate_joke</code> 节点发送<strong>任意</strong>结构的状态，无需与 <code>OverallState</code> 对齐。<br>在这里，<code>generate_joke</code> 使用自己的内部状态，我们通过 <code>Send</code> 按需填充即可。</p>
<blockquote>
<p>在 LangGraph 里，<code>Send</code> 是一个<strong>“动态派发器”</strong>：它让你<strong>在运行时</strong>决定“要把哪个节点运行多少次、每次给它什么数据”，并自动并行执行。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.types import Send</span><br><span class="line">def continue_to_jokes(state: OverallState):</span><br><span class="line">    # 该函数根据当前状态中的主题列表，为每个主题生成一个 Send 对象。</span><br><span class="line">    # 每个 Send 对象都指示图将数据发送到名为 &quot;generate_joke&quot; 的节点，</span><br><span class="line">    # 并将当前主题作为 &quot;subject&quot; 参数传递，从而实现并行生成笑话。</span><br><span class="line">    return [Send(&quot;generate_joke&quot;, &#123;&quot;subject&quot;: s&#125;) for s in state[&quot;subjects&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="Joke-generation-map-笑话生成"><a href="#Joke-generation-map-笑话生成" class="headerlink" title="Joke generation (map) 笑话生成"></a><strong>Joke generation (map)</strong> <strong>笑话生成</strong></h5><p>现在，我们只需定义一个节点来生成笑话，命名为 <code>generate_joke</code>！</p>
<p>生成的笑话会被写回到 <code>OverallState</code> 中的 <code>jokes</code> 字段。<br>该字段配有 reducer，能够自动把多次写入的列表合并成一个大列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 定义 JokeState，用于表示生成笑话任务的输入状态。</span><br><span class="line">class JokeState(TypedDict):</span><br><span class="line">    subject: str#笑话的主题</span><br><span class="line"></span><br><span class="line"># 定义 Joke 模型，用于表示模型生成的笑话的结构。</span><br><span class="line">class Joke(BaseModel):</span><br><span class="line">    joke: str#笑话的文本内容</span><br><span class="line"></span><br><span class="line"># 定义生成笑话的函数。</span><br><span class="line">def generate_joke(state: JokeState):</span><br><span class="line">    # 根据 joke_prompt 模板和当前状态中的主题格式化提示。</span><br><span class="line">    prompt = joke_prompt.format(subject=state[&quot;subject&quot;])</span><br><span class="line">    # 调用语言模型，并指定输出应结构化为 Joke 类型。</span><br><span class="line">    response = model.with_structured_output(Joke).invoke(prompt)</span><br><span class="line">    # 返回一个包含生成的笑话的字典，键为 &quot;jokes&quot;。</span><br><span class="line">    return &#123;&quot;jokes&quot;: [response.joke]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Best-joke-selection-reduce-最佳笑话选择"><a href="#Best-joke-selection-reduce-最佳笑话选择" class="headerlink" title="Best joke selection (reduce) 最佳笑话选择"></a><strong>Best joke selection (reduce)</strong> <strong>最佳笑话选择</strong></h5><p>现在，我们添加逻辑来挑选最好的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def best_joke(state: OverallState):</span><br><span class="line">    # 将状态中所有笑话列表连接成一个字符串，每个笑话之间用两个换行符分隔</span><br><span class="line">    jokes = &quot;\n\n&quot;.join(state[&quot;jokes&quot;])</span><br><span class="line">    # 使用主题和所有笑话格式化最佳笑话提示语</span><br><span class="line">    prompt = best_joke_prompt.format(topic=state[&quot;topic&quot;], jokes=jokes)</span><br><span class="line">    # 调用模型，期望其输出符合 BestJoke 结构（包含最佳笑话的ID）</span><br><span class="line">    response = model.with_structured_output(BestJoke).invoke(prompt)</span><br><span class="line">    # 根据模型返回的ID，从笑话列表中选择最佳笑话，并将其存储在状态的 best_selected_joke 字段中</span><br><span class="line">    return &#123;&quot;best_selected_joke&quot;: state[&quot;jokes&quot;][response.id]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Compile-编译"><a href="#Compile-编译" class="headerlink" title="Compile 编译"></a><strong>Compile</strong> 编译</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image</span><br><span class="line">from langgraph.graph import END, StateGraph, START</span><br><span class="line"></span><br><span class="line"># 构建图：将所有组件组合在一起构建我们的流程图</span><br><span class="line">graph = StateGraph(OverallState)</span><br><span class="line"></span><br><span class="line">graph.add_node(&quot;generate_topics&quot;, generate_topics)</span><br><span class="line">graph.add_node(&quot;generate_joke&quot;, generate_joke)</span><br><span class="line">graph.add_node(&quot;best_joke&quot;, best_joke)</span><br><span class="line"></span><br><span class="line">graph.add_edge(START, &quot;generate_topics&quot;)</span><br><span class="line"># 根据条件决定是否继续生成笑话</span><br><span class="line">graph.add_conditional_edges(&quot;generate_topics&quot;, continue_to_jokes, [&quot;generate_joke&quot;])</span><br><span class="line"># 生成笑话后执行选择最佳笑话</span><br><span class="line">graph.add_edge(&quot;generate_joke&quot;, &quot;best_joke&quot;)</span><br><span class="line"># 选择最佳笑话后流程结束</span><br><span class="line">graph.add_edge(&quot;best_joke&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = graph.compile()</span><br><span class="line">Image(app.get_graph().draw_mermaid_png())</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723112736244.png" alt="image-20250723112736244"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for s in app.stream(&#123;&quot;topic&quot;: &quot;日本广岛原子弹&quot;&#125;):</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;generate_topics&#x27;: &#123;&#x27;subjects&#x27;: [&#x27;原子弹投放的历史背景与决策过程&#x27;, &#x27;广岛原爆对城市与居民的影响&#x27;, &#x27;战后和平运动与核裁军倡议&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;战后和平运动的人开会讨论核裁军，一个人站起来说：‘我们必须彻底销毁所有核武器！’ 另一个人犹豫地举手：‘那……我们保留一个吧，就一个，藏在冰箱后面，以防万一。’&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&quot;杜鲁门宣布要结束战争，顾问问是否要使用原子弹。罗斯福的棺材板突然震动了一下，丘吉尔的雪茄掉在了地上，斯大林则默默拿起了电话：&#x27;同志，我们的计划可能需要再推迟一下。&#x27;&quot;]&#125;&#125;</span><br><span class="line">&#123;&#x27;best_joke&#x27;: &#123;&#x27;best_selected_joke&#x27;: &#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Research Assistant</strong> <strong>研究助理</strong></p>
<p>见另一篇文章</p>
<h3 id="module-5"><a href="#module-5" class="headerlink" title="module-5"></a>module-5</h3><h4 id="Chatbot-with-Memory-带有记忆功能的聊天机器人"><a href="#Chatbot-with-Memory-带有记忆功能的聊天机器人" class="headerlink" title="Chatbot with Memory 带有记忆功能的聊天机器人"></a><strong>Chatbot with Memory</strong> <strong>带有记忆功能的聊天机器人</strong></h4><p>在这里，我们将介绍 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Memory Store</a> 作为一种保存和检索长期记忆的方法。</p>
<blockquote>
<p>LangGraph Memory Store 是 <strong>LangGraph 提供的长期记忆存储接口</strong>，用于在 <strong>不同对话线程之间</strong> 持久化保存和检索用户信息。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>名称</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BaseStore</strong></td>
<td>抽象接口，定义了 <code>put/get/search/delete</code> 等操作方法</td>
</tr>
<tr>
<td><strong>InMemoryStore</strong></td>
<td>内存实现，适合原型验证</td>
</tr>
<tr>
<td><strong>RedisStore / AsyncRedisStore</strong></td>
<td>生产级实现，支持向量搜索、元数据过滤和命名空间管理</td>
</tr>
</tbody>
</table>
</div>
</blockquote>
<p>我们将构建一个使用 <code>short-term (within-thread仅当前对话线程)</code> 和 <code>long-term (across-thread跨所有对话线程    )</code> 内存的聊天机器人。</p>
<p>我们将重点关注长期 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory">semantic memory<strong>（语义记忆）</strong></a>，它将包含关于用户的事实信息。这些长期记忆将被用于创建一个个性化的聊天机器人，它可以记住有关用户的事实。</p>
<p>它将节省内存 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories">“in the hot path”</a>，当用户与之聊天时。</p>
<blockquote>
<p><strong>“in the hot path”</strong> 指的是：<strong>在对话或任务执行的</strong>主流程中<strong>（即用户输入后立即、同步地）</strong>主动调用工具或写入记忆，使信息<strong>实时生效</strong>并可用于下一步决策。</p>
</blockquote>
<h5 id="Introduction-to-the-LangGraph-Store-LangGraph-存储简介"><a href="#Introduction-to-the-LangGraph-Store-LangGraph-存储简介" class="headerlink" title="Introduction to the LangGraph Store LangGraph 存储简介"></a><strong>Introduction to the LangGraph Store</strong> <strong>LangGraph 存储简介</strong></h5><p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Memory Store</a> 提供了一种在 LangGraph 中 <strong>跨线程</strong> 存储和检索信息的方式。这是一个用于持久化 <code>key-value</code> 存储的 <a target="_blank" rel="noopener" href="https://blog.langchain.dev/launching-long-term-memory-support-in-langgraph/">开源基类</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line">in_memory_store = InMemoryStore()</span><br></pre></td></tr></table></figure>
<p>在 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">Store</a> 中存储对象（例如，记忆）时，我们提供：</p>
<p>- 对象的 <code>namespace</code>（类似于目录的元组）</p>
<p>- 对象的 <code>key</code>（类似于文件名）</p>
<p>- 对象的 <code>value</code>（类似于文件内容）</p>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a> 方法通过 <code>namespace</code> 和 <code>key</code> 将对象保存到存储中。</p>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725155616205-1753430177489-3.png" alt="image-20250725155616205"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;  # 用户ID</span><br><span class="line">namespace_for_memory = (user_id, &quot;memories&quot;)  # 记忆命名空间</span><br><span class="line"></span><br><span class="line"># 生成一个唯一的键值</span><br><span class="line">key = str(uuid.uuid4())  # 使用UUID创建唯一标识符作为键</span><br><span class="line"></span><br><span class="line"># 值需要是一个字典格式</span><br><span class="line">value = &#123;&quot;food_preference&quot;: &quot;我喜欢披萨&quot;&#125;  # 存储的食物偏好信息</span><br><span class="line"></span><br><span class="line"># 保存记忆</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)  # 将记忆存储到内存中</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a> 通过 <code>namespace</code> 从存储中检索对象。这将返回一个列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">memories = in_memory_store.search(namespace_for_memory)</span><br><span class="line">type(memories)</span><br><span class="line"></span><br><span class="line"># Metatdata </span><br><span class="line">memories[0].dict()</span><br><span class="line"></span><br><span class="line"># The key, value</span><br><span class="line">print(memories[0].key, memories[0].value)</span><br><span class="line">9e65de8a-f404-4974-b509-0df0566d8fb5 &#123;&#x27;food_preference&#x27;: &#x27;我喜欢披萨&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a> 通过 <code>namespace</code> 和 <code>key</code> 检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Get the memory by namespace and key</span><br><span class="line">memory = in_memory_store.get(namespace_for_memory, key)</span><br><span class="line">memory.dict()</span><br></pre></td></tr></table></figure>
<h5 id="Chatbot-with-long-term-memory-具有长期记忆的聊天机器人"><a href="#Chatbot-with-long-term-memory-具有长期记忆的聊天机器人" class="headerlink" title="Chatbot with long-term memory 具有长期记忆的聊天机器人"></a><strong>Chatbot with long-term memory</strong> <strong>具有长期记忆的聊天机器人</strong></h5><p>我们想要一个聊天机器人，<a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_156">有两种记忆的方式</a>:</p>
<ol>
<li><code>Short-term (within-thread) memory</code>: 聊天机器人可以保留会话历史记录和/或允许在聊天会话中进行中断。  </li>
<li><code>Long-term (cross-thread) memory</code>: 聊天机器人可以记住特定用户在所有聊天会话中的信息 <strong>跨会话</strong>。</li>
</ol>
<p>对于 <code>short-term memory</code>，我们将使用一个 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries">checkpointer</a>。</p>
<ul>
<li>他们在每一步都将图状态写入线程中。</li>
<li>他们在该线程中持久化保存聊天历史记录。</li>
<li>他们允许图在该线程中的任何步骤被中断和/或恢复。</li>
</ul>
<p>对于 <code>long-term memory</code>，我们将使用上面介绍的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的有用助手，能够提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;&quot;你正在收集用户信息以个性化你的回复。</span><br><span class="line"></span><br><span class="line">当前用户信息：</span><br><span class="line">&#123;memory&#125;</span><br><span class="line"></span><br><span class="line">指令：</span><br><span class="line">1. 仔细查看下面的聊天历史</span><br><span class="line">2. 识别有关用户的新信息，例如：</span><br><span class="line">   - 个人详情（姓名、位置）</span><br><span class="line">   - 偏好（喜欢、不喜欢）</span><br><span class="line">   - 兴趣和爱好</span><br><span class="line">   - 过去的经历</span><br><span class="line">   - 目标或未来计划</span><br><span class="line">3. 将任何新信息与现有记忆合并</span><br><span class="line">4. 将记忆格式化为清晰的项目符号列表</span><br><span class="line">5. 如果新信息与现有记忆冲突，请保留最新版本</span><br><span class="line"></span><br><span class="line">记住：只包括用户直接陈述的事实信息。不要做假设或推断。</span><br><span class="line"></span><br><span class="line">基于以下聊天历史，请更新用户信息：&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    existing_memory = store.get(namespace, key)</span><br><span class="line"></span><br><span class="line">    # 如果存在则提取实际的记忆内容并添加前缀</span><br><span class="line">    if existing_memory:</span><br><span class="line">        # 值是一个带有memory键的字典</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)</span><br><span class="line">    </span><br><span class="line">    # 使用记忆以及聊天历史进行回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">        </span><br><span class="line">    # 提取记忆</span><br><span class="line">    if existing_memory:</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)</span><br><span class="line">    new_memory = model.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖存储中的现有记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line"></span><br><span class="line">    # 将值写入为带有memory键的字典</span><br><span class="line">    store.put(namespace, key, &#123;&quot;memory&quot;: new_memory.content&#125;)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于跨线程的长期记忆存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于线程内的短期记忆检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点器和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725161106319.png" alt="image-20250725161106319"></p>
<p>聊天历史将通过检查点工具保存到短期记忆中。聊天机器人将回顾聊天历史。然后，它将创建并保存一个记忆到 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a>。此内存可在未来的聊天会话中访问，以个性化聊天机器人的响应。</p>
<p>当我们与聊天机器人交互时，我们提供两样东西：</p>
<ol>
<li><code>Short-term (within-thread) memory</code>: 一个用于持久化聊天历史的 <code>thread ID</code>。  </li>
<li><code>Long-term (cross-thread) memory</code>: 一个用于将长期记忆命名空间到用户的 <code>user ID</code>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br><span class="line">    </span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，我的名字是Lance</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，Lance！很高兴认识你。有什么我可以帮你的吗？😊</span><br></pre></td></tr></table></figure>
<p>我们正在使用 <code>MemorySaver</code> 检查点来管理线程内内存。这会将聊天历史保存到线程中。我们可以查看保存到线程的聊天历史记录。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">state = graph.get_state(thread).values</span><br><span class="line">for m in state[&quot;messages&quot;]: </span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>回想一下，我们使用存储库编译了该图：<code>across_thread_memory = InMemoryStore()</code>并且，我们向图中添加了一个节点 (<code>write_memory</code>)，该节点反映了聊天历史并保存了一段记忆到存储中。</p>
<p>我们可以查看内存是否已保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.dict()</span><br><span class="line"></span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;memory&#x27;, &#x27;1&#x27;],</span><br><span class="line"> &#x27;key&#x27;: &#x27;user_memory&#x27;,</span><br><span class="line"> &#x27;value&#x27;: &#123;&#x27;memory&#x27;: &#x27;- 姓名：Lance  \n- 位置：旧金山  \n- 兴趣和爱好：骑自行车  \n- 喜欢的活动：在旧金山骑行，可能包括金门大桥和滨海区路线&#x27;&#125;,</span><br><span class="line"> &#x27;created_at&#x27;: &#x27;2025-07-25T08:12:35.877160+00:00&#x27;,</span><br><span class="line"> &#x27;updated_at&#x27;: &#x27;2025-07-25T08:12:35.877161+00:00&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>现在，让我们以 <strong>相同的用户ID</strong>启动一个<strong>新线程</strong>。我们应该看到聊天机器人记住了用户的个人资料，并将其用于个性化响应。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供用户ID用于跨线程记忆以及一个新的线程ID</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好！你推荐我去哪里骑自行车？&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-Profile-Schema-带有配置文件模式的聊天机器人"><a href="#Chatbot-with-Profile-Schema-带有配置文件模式的聊天机器人" class="headerlink" title="Chatbot with Profile Schema 带有配置文件模式的聊天机器人"></a><strong>Chatbot with Profile Schema</strong> <strong>带有配置文件模式的聊天机器人</strong></h4><p>我们的聊天机器人将记忆保存为字符串。在实践中，我们通常希望记忆具有结构化格式。例如，记忆可以是<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">单个、持续更新的模式 </a>。在我们的案例中，我们希望这是一个单一的用户档案。</p>
<p>我们将扩展我们的聊天机器人，将语义记忆保存到单个<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">用户档案 </a>中。我们还将介绍一个库 <a target="_blank" rel="noopener" href="https://github.com/hinthornw/trustcall">Trustcall</a>，用于使用新信息更新此模式。</p>
<h5 id="Defining-a-user-profile-schema-定义用户配置文件模式"><a href="#Defining-a-user-profile-schema-定义用户配置文件模式" class="headerlink" title="Defining a user profile schema 定义用户配置文件模式"></a><strong>Defining a user profile schema</strong> <strong>定义用户配置文件模式</strong></h5><p>Python 有许多不同类型的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition">structured data</a>，例如 TypedDict、字典、JSON 和 <a target="_blank" rel="noopener" href="https://docs.pydantic.dev/latest/">Pydantic</a>。</p>
<p>让我们先使用 TypedDict 来定义一个用户资料模式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from typing import TypedDict, List</span><br><span class="line"></span><br><span class="line">class UserProfile(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;带有类型字段的用户档案模式&quot;&quot;&quot;</span><br><span class="line">    user_name: str  # 用户的首选名称</span><br><span class="line">    interests: List[str]  # 用户兴趣列表</span><br></pre></td></tr></table></figure>
<h5 id="Saving-a-schema-to-the-store-将模式保存到存储中"><a href="#Saving-a-schema-to-the-store-将模式保存到存储中" class="headerlink" title="Saving a schema to the store 将模式保存到存储中"></a><strong>Saving a schema to the store</strong> <strong>将模式保存到存储中</strong></h5><p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a> 接受任何 Python 字典作为 <code>value</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># TypedDict 实例</span><br><span class="line">user_profile: UserProfile = &#123;</span><br><span class="line">    &quot;user_name&quot;: &quot;Lance&quot;,  # 用户名</span><br><span class="line">    &quot;interests&quot;: [&quot;骑行&quot;, &quot;科技&quot;, &quot;咖啡&quot;]  # 兴趣爱好</span><br><span class="line">&#125;</span><br><span class="line">user_profile</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a> 方法将 TypedDict 保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line"></span><br><span class="line"># 初始化内存存储</span><br><span class="line">in_memory_store = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 为要保存的记忆创建命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace_for_memory = (user_id, &quot;memory&quot;)</span><br><span class="line"></span><br><span class="line"># 将记忆以键值对的形式保存到命名空间中</span><br><span class="line">key = &quot;user_profile&quot;</span><br><span class="line">value = user_profile</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a> 按命名空间从存储中检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for m in in_memory_store.search(namespace_for_memory):</span><br><span class="line">    print(m.dict())</span><br><span class="line">    </span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;1&#x27;, &#x27;memory&#x27;], &#x27;key&#x27;: &#x27;user_profile&#x27;, &#x27;value&#x27;: &#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;, &#x27;created_at&#x27;: &#x27;2025-07-25T08:58:06.031770+00:00&#x27;, &#x27;updated_at&#x27;: &#x27;2025-07-25T08:58:06.031775+00:00&#x27;, &#x27;score&#x27;: None&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a> 通过命名空间和键来检索特定对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">profile = in_memory_store.get(namespace_for_memory, &quot;user_profile&quot;)</span><br><span class="line">profile.value</span><br><span class="line"></span><br><span class="line">&#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Chatbot-with-profile-schema-带有配置文件模式的聊天机器人"><a href="#Chatbot-with-profile-schema-带有配置文件模式的聊天机器人" class="headerlink" title="Chatbot with profile schema 带有配置文件模式的聊天机器人"></a><strong>Chatbot with profile schema</strong> <strong>带有配置文件模式的聊天机器人</strong></h5><p>现在我们知道了如何为记忆指定一个模式，并将其保存到存储中。现在，我们如何根据这个特定的模式 <strong>创建</strong> 记忆？</p>
<p>在我们的聊天机器人中，我们 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">想要从一个聊天里创建记忆</a>.这就是 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">structured outputs格式化输出</a> 概念有用的地方。</p>
<p>LangChain 的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/chat_models/">chat model</a> 接口有一个 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">PROTECTED$11$</a> 方法用于强制结构化输出。这在我们需要确保输出符合某个模式时非常有用，而且它会为我们解析输出。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 将模式绑定到模型</span><br><span class="line">model_with_structure = model.with_structured_output(UserProfile)</span><br><span class="line"></span><br><span class="line"># 调用模型生成符合模式的结构化输出</span><br><span class="line">structured_output = model_with_structure.invoke([HumanMessage(&quot;我的名字是Lance，我喜欢骑自行车。&quot;)])</span><br><span class="line">structured_output</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Structured outputs（结构化输出）<br>指让大模型<strong>不再“随意说人话”</strong>，而是<strong>按你事先定义好的格式（JSON / 表格 / 枚举 / 嵌套对象等）精确返回数据</strong>。相当于给模型套了一个“模具”，保证输出可直接被代码解析、入库或传给下游系统，避免再用正则、字符串拼接去“猜”结果。</p>
<p>使用官方的大模型组件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">model=ChatTongyi(</span><br><span class="line">    model=&quot;qwen-plus-2025-07-14&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>现在，让我们在聊天机器人中使用它。这只需要对 <code>write_memory</code> 函数进行轻微修改。我们使用 <code>model_with_structure</code>，如上所述，来生成一个与我们模式匹配的配置文件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage, AIMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的 helpful 助手，可以提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;根据用户的聊天历史创建或更新用户档案记忆。</span><br><span class="line">这将被保存为长期记忆。如果存在现有记忆，只需更新它。</span><br><span class="line">以下是现有记忆（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 使用记忆以及聊天历史来回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line">        </span><br><span class="line">    # 在指令中格式化现有记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 调用模型生成符合模式的结构化输出</span><br><span class="line">    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖现有的用户档案记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    store.put(namespace, key, new_memory)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于长期（跨线程）记忆的存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于短期（线程内）记忆的检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250726103516996.png" alt="image-20250726103516996"></p>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance，我喜欢在旧金山骑自行车和在面包店吃饭。&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>查看记忆</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Namespace for the memory to save</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.value</span><br></pre></td></tr></table></figure>
<h5 id="Trustcall-for-creating-and-updating-profile-schemas-Trustcall-用于创建和更新配置文件模式"><a href="#Trustcall-for-creating-and-updating-profile-schemas-Trustcall-用于创建和更新配置文件模式" class="headerlink" title="Trustcall for creating and updating profile schemas Trustcall 用于创建和更新配置文件模式"></a><strong>Trustcall for creating and updating profile schemas</strong> <strong>Trustcall 用于创建和更新配置文件模式</strong></h5><p>Trustcall 是一个由 LangChain 团队开发的开源 Python 库，旨在<strong>解决大型语言模型（LLM）在生成或修改复杂 JSON 数据结构时效率低、易出错的问题</strong>。</p>
<p>我们使用 <code>create_extractor</code>，传入模型以及我们的模式作为 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/tools/">tool</a>。使用 TrustCall 时，可以以多种方式提供模式。</p>
<p>例如，我们可以传递一个 JSON 对象 / Python 字典或 Pydantic 模型。在底层，TrustCall 使用 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/tool_calling/">tool calling</a> 从输入的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/messages/">messages</a> 列表中生成 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/">structured output</a>。为了强制 Trustcall 生成 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/">structured output</a>，我们可以在 <code>tool_choice</code> 参数中包含模式名称。</p>
<p>我仅做了解了，感觉用处不多，用结果化输出就能达到效果</p>
<h4 id="Chatbot-with-Collection-Schema-带集合模式的聊天机器人"><a href="#Chatbot-with-Collection-Schema-带集合模式的聊天机器人" class="headerlink" title="Chatbot with Collection Schema 带集合模式的聊天机器人"></a><strong>Chatbot with Collection Schema</strong> <strong>带集合模式的聊天机器人</strong></h4><p><strong>“collection”</strong> 指的是一种<strong>将语义记忆组织为多个独立文档（objects）的存储方式</strong>，而不是把所有信息都塞进一个巨大的“用户档案”（single profile）里。</p>
<p>假设你在做一个 AI 助手，用户说：</p>
<blockquote>
<p>“我下周要去东京出差，住在涩谷区的 Sakura Hotel。”<br>“我朋友 Ken 也要来，他喜欢吃拉面。”</p>
</blockquote>
<p>如果用 <strong>collection</strong>，你会存成两条记忆：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trip&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;destination&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Tokyo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2025-08-04&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hotel&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Sakura Hotel, Shibuya&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;friend&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Ken&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;food_preference&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ramen&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<p>每条记忆都是一个独立文档，后续你可以：</p>
<ul>
<li>搜索“trip”类型的记忆，找到用户的出差安排；</li>
<li>搜索“friend”类型的记忆，找到 Ken 的偏好；</li>
<li>更新 Ken 的信息时，<strong>只改一条记录</strong>，不会影响其它记忆。</li>
</ul>
<h4 id="Memory-Agent-内存代理"><a href="#Memory-Agent-内存代理" class="headerlink" title="Memory Agent 内存代理"></a><strong>Memory Agent</strong> <strong>内存代理</strong></h4><p>现在，我们将把学到的内容整合起来，构建一个具有长期记忆的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/">agent</a>。</p>
<p>我们的代理 <code>task_mAIstro</code> 将帮助我们管理待办事项列表！</p>
<p>我们之前构建的聊天机器人 <strong>始终</strong> 会反思对话并保存记忆。<code>task_mAIstro</code> 将决定 <strong>何时</strong> 保存记忆（待办事项列表中的项目）。</p>
<p>我们之前构建的聊天机器人始终保存一种类型的记忆，即个人资料或集合。<code>task_mAIstro</code> 可以决定将数据保存到用户个人资料或 ToDo 事项集合中。</p>
<p>除此之外，<code>task_mAIstro</code> 还将管理程序性记忆。这允许用户更新创建ToDo项的偏好设置。</p>
<h5 id="Creating-an-agent-创建一个代理"><a href="#Creating-an-agent-创建一个代理" class="headerlink" title="Creating an agent 创建一个代理"></a><strong>Creating an agent</strong> <strong>创建一个代理</strong></h5><p>有许多不同的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/high_level/">agent</a> 架构可供选择。在这里，我们将实现一个简单的内容，一个 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation">ReAct</a> 代理。这个代理将成为创建和管理待办事项列表的得力助手。</p>
<p>此代理可以决定更新三种类型的长期记忆：</p>
<p>(a) 创建或更新具有普通用户信息的用户 <code>profile</code></p>
<p>(b) 在ToDo列表中添加或更新项目 <code>collection</code></p>
<p>(c) 更新其自身的 <code>instructions</code> 以了解如何更新待办事项列表中的项目</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from typing import TypedDict, Literal</span><br><span class="line"></span><br><span class="line"># 更新记忆工具</span><br><span class="line">class UpdateMemory(TypedDict):</span><br><span class="line">    &quot;&quot;&quot; 决定更新哪种记忆类型 &quot;&quot;&quot;</span><br><span class="line">    update_type: Literal[&#x27;user&#x27;, &#x27;todo&#x27;, &#x27;instructions&#x27;]</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><code>&#39;user&#39;</code>：用户相关信息</li>
<li><code>&#39;todo&#39;</code>：待办事项</li>
<li><code>&#39;instructions&#39;</code>：指令信息</li>
</ul>
</blockquote>
<h5 id="Graph-definition-图定义"><a href="#Graph-definition-图定义" class="headerlink" title="Graph definition 图定义"></a><strong>Graph definition</strong> <strong>图定义</strong></h5><p>我们添加了一个简单的路由器 <code>route_message</code>，它通过二元决策来节省内存。</p>
<h3 id="module-6"><a href="#module-6" class="headerlink" title="module-6"></a>module-6</h3>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>请我一杯咖啡吧！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.png" alt="张熙浚 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipay.png" alt="张熙浚 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/langgraph/" rel="tag"># langgraph</a>
              <a href="/tags/fastapi/" rel="tag"># fastapi</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/" rel="prev" title="Research Assistant研究助理">
                  <i class="fa fa-angle-left"></i> Research Assistant研究助理
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="next" title="MCP 学习笔记">
                  MCP 学习笔记 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">张熙浚</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="本站访问数 fa fa-user 次"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="本站总访问量 fa fa-eye 次"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="400" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
