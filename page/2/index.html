<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="zxj Blogs">
<meta property="og:type" content="website">
<meta property="og:title" content="Zhang XiJun">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Zhang XiJun">
<meta property="og:description" content="zxj Blogs">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="张熙浚">
<meta property="article:tag" content="zxj">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Zhang XiJun</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhang XiJun</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">BLOGS</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="张熙浚"
      src="/images/zxjavatar.gif">
  <p class="site-author-name" itemprop="name">张熙浚</p>
  <div class="site-description" itemprop="description">zxj Blogs</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">119</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zxj-2023" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxj-2023" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=2902065320&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;2902065320&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener me" target="_blank"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zxj-2023.github.io/" title="https:&#x2F;&#x2F;zxj-2023.github.io" rel="noopener" target="_blank">Zhang XiJun</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org" rel="noopener" target="_blank">NexT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/pgsql%E5%AE%9E%E7%8E%B0%E6%8C%81%E4%B9%85%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/pgsql%E5%AE%9E%E7%8E%B0%E6%8C%81%E4%B9%85%E5%8C%96/" class="post-title-link" itemprop="url">pgsql实现持久化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-28 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-28T00:00:00+08:00">2025-07-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-06 09:50:53" itemprop="dateModified" datetime="2025-08-06T09:50:53+08:00">2025-08-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/agent%E5%AE%9E%E6%88%98/" itemprop="url" rel="index"><span itemprop="name">agent实战</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>常使用pgsql与redis配合langgraph的checkpoint与store进行持久化储存，完成长期记忆与短期记忆的实现</p>
<h3 id="pgsql实现持久化"><a href="#pgsql实现持久化" class="headerlink" title="pgsql实现持久化"></a>pgsql实现持久化</h3><h4 id="什么是pgsql"><a href="#什么是pgsql" class="headerlink" title="什么是pgsql"></a>什么是pgsql</h4><p>PostgreSQL（常简称pgsql或Postgres）是一个功能强大的开源对象-关系型数据库管理系统（ORDBMS），以其稳定性、扩展性和符合SQL标准著称。</p>
<h4 id="docker拉取"><a href="#docker拉取" class="headerlink" title="docker拉取"></a>docker拉取</h4><p>docker-compose</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">version: &#x27;3.8&#x27;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  postgres:</span><br><span class="line">    image: postgres:15        # 指定具体版本</span><br><span class="line">    container_name: postgres_db</span><br><span class="line">    environment:</span><br><span class="line">      POSTGRES_USER: postgres</span><br><span class="line">      POSTGRES_PASSWORD: postgres</span><br><span class="line">      POSTGRES_DB: postgres</span><br><span class="line">      TZ: Asia/Shanghai       # 设置时区</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5432:5432&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - pgdata:/var/lib/postgresql/data</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    healthcheck:             # 健康检查</span><br><span class="line">      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;nange&quot;]</span><br><span class="line">      interval: 10s</span><br><span class="line">      timeout: 5s</span><br><span class="line">      retries: 5</span><br><span class="line">    command: [&quot;postgres&quot;, &quot;-c&quot;, &quot;max_connections=200&quot;]  # 自定义配置</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  pgdata:</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Docker Compose</strong> 是一个 <strong>定义和运行多容器 Docker 应用</strong> 的 <strong>声明式工具</strong>。<br>它通过一个 <strong>YAML 文件（通常叫 <code>docker-compose.yml</code>）</strong> 描述整个应用的服务、网络、存储等配置，然后用一条命令即可 <strong>启动/停止/管理</strong> 所有容器，无需手动逐个 <code>docker run</code>。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#拉取并运行</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>
<h4 id="在pgsqsl安装依赖"><a href="#在pgsqsl安装依赖" class="headerlink" title="在pgsqsl安装依赖"></a>在pgsqsl安装依赖</h4><p>因为LangGraph的PostgresStore需要使用到pgvector，因此需要在容器中按照如下步骤进行操作，直接使用Docker Desktop软件中进行操作 </p>
<blockquote>
<ul>
<li>为什么需要 <code>pgvector</code>？</li>
<li><code>PostgresStore</code> 支持将 <strong>向量嵌入（embedding）</strong> 存储在 PostgreSQL 中，并基于它们进行 <strong>语义搜索</strong>。</li>
<li>该功能依赖 <code>pgvector</code> 扩展提供的 <code>vector</code> 类型和索引机制（如 HNSW）。</li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">安装依赖           </span><br><span class="line">apt update    #刷新本地软件包索引           </span><br><span class="line">apt install -y git build-essential postgresql-server-dev-15                          </span><br></pre></td></tr></table></figure>
<blockquote>
<p>apt install -y git build-essential postgresql-server-dev-15一次性安装 3 类依赖。</p>
<ul>
<li><code>git</code> —— 用来克隆 pgvector 源码。</li>
<li><code>build-essential</code> —— Debian/Ubuntu 的“编译工具链”元包，包含 gcc、make 等。</li>
<li><code>postgresql-server-dev-15</code> —— 与当前 Postgres <strong>主版本一致</strong> 的开发头文件和 <code>pg_config</code>。</li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">编译并安装 pgvector      </span><br><span class="line">#把 pgvector 的 v0.7.0 稳定版 源码克隆到本地目录 ./pgvector。</span><br><span class="line">git clone --branch v0.7.0 https://github.com/pgvector/pgvector.git                </span><br><span class="line">cd pgvector  </span><br><span class="line">#调用 Makefile 根据当前操作系统 + PostgreSQL 版本编译出二进制文件（.so 共享库）。</span><br><span class="line">make          </span><br><span class="line">#把刚刚编好的 .so 文件和 .sql/.control 文件复制到 PostgreSQL 的扩展目录</span><br><span class="line">make install                </span><br><span class="line">验证安装，检查扩展文件是否安装成功                    </span><br><span class="line">ls -l /usr/share/postgresql/15/extension/vector* </span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://github.com/pgvector/pgvector">pgvector/pgvector: Open-source vector similarity search for Postgres</a></p>
<p>接下来，若要在脚本中进行使用，首先在系统环境中需要安装PostgreSQL 的开发库（libpq），因为 psycopg 需要它来编译或运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install libpq-dev postgresql-server-dev-all</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>psycopg（Python 操作 PostgreSQL 的库）</strong> 在 <strong>Linux/macOS</strong> 上运行时，底层依赖于 <strong>PostgreSQL 的 C 语言开发库 libpq</strong>。<br>如果系统里 <strong>没有 libpq</strong>，psycopg 会出现以下两种问题：</p>
<ol>
<li><p><strong>编译安装失败</strong>（源码/旧版本）<br>当 <code>pip install psycopg2</code> 需要现场编译时，会找不到头文件 <code>libpq-fe.h</code> 或动态库 <code>libpq.so</code>，导致报错：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error: libpq-fe.h: No such file or directory</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>运行时崩溃</strong><br>即使通过预编译的 wheel 包安装成功，运行时也可能提示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ImportError: libpq.so.5: cannot open shared object file</span><br></pre></td></tr></table></figure>
</li>
</ol>
</blockquote>
<p>最后，再安装相关依赖包  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install langgraph-checkpoint-postgres                    </span><br><span class="line">pip install psycopg psycopg-pool </span><br></pre></td></tr></table></figure>
<p>psycopg官方 PostgreSQL 驱动，在 <code>psycopg</code> 之上再包一层“<strong>连接池</strong>”，让并发访问更快、更稳定。</p>
<h4 id="连接pgsql"><a href="#连接pgsql" class="headerlink" title="连接pgsql"></a>连接pgsql</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.store.postgres import PostgresStore</span><br><span class="line">from langgraph.checkpoint.postgres import PostgresSaver</span><br><span class="line">from psycopg_pool import ConnectionPool</span><br><span class="line"># 1) 连接字符串（URI 语法）</span><br><span class="line">DB_URI = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line">#   协议://      用户   : 密码   @ 主机:端口 / 数据库名  ? 额外参数</span><br><span class="line"></span><br><span class="line"># 2) 连接级参数</span><br><span class="line">connection_kwargs = &#123;</span><br><span class="line">    &quot;autocommit&quot;: True,     # 每条 SQL 执行完立即提交，无需手动 commit</span><br><span class="line">    &quot;prepare_threshold&quot;: 0, # 禁用服务器端 prepared statement，可减少一次往返</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 3) 创建池</span><br><span class="line">connection_pool = ConnectionPool(</span><br><span class="line">    conninfo=DB_URI,</span><br><span class="line">    max_size=20,            # 最多 20 条物理连接</span><br><span class="line">    kwargs=connection_kwargs,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 4) 显式打开池（psycopg 3 的 ConnectionPool 默认懒启动，调 open() 会立即建 min_size 条连接）</span><br><span class="line">connection_pool.open()</span><br><span class="line">print(&quot;数据库连接池初始化成功&quot;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>正常情况每次 SQL 都新建一条 TCP 连接、做 SSL 握手、验证密码、分配内存，如果不复用连接，这些动作就要 <strong>每次都重新来一遍</strong>，<strong>成本非常高</strong>。</p>
<p>连接池（Connection Pool）是一种 <strong>数据库访问层资源管理组件</strong>，其核心目标是在 <strong>高并发、短事务</strong> 场景下，通过 <strong>复用已建立的数据库物理连接</strong> 来降低系统整体延迟、减少资源消耗，并防止数据库因瞬时连接风暴而崩溃。</p>
</blockquote>
<h4 id="初始化pgsql"><a href="#初始化pgsql" class="headerlink" title="初始化pgsql"></a>初始化pgsql</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 初始化PostgresStore</span><br><span class="line">in_postgres_store = PostgresStore(</span><br><span class="line">    pool,</span><br><span class="line">    index=&#123;</span><br><span class="line">        &quot;dims&quot;: 1536,</span><br><span class="line">        &quot;embed&quot;: embedding</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line">in_postgres_store.setup()</span><br><span class="line"></span><br><span class="line">#初始化checkpoint</span><br><span class="line"># 使用传入的连接池创建 PostgresSaver</span><br><span class="line">checkpointer = PostgresSaver(pool)</span><br><span class="line">checkpointer.setup()</span><br><span class="line"></span><br><span class="line">#最后编译时添加</span><br><span class="line">graph_builder.compile(checkpointer=checkpointer, store=in_postgres_store)</span><br></pre></td></tr></table></figure>
<p><code>in_postgres_store.setup()</code> 的角色一句话就能说清：</p>
<blockquote>
<p><strong>把数据库里所有为了让向量存储正常工作的“一次性基建”全部建好</strong>——只建一次，后面再跑就不会重复执行。</p>
</blockquote>
<p>具体而言，它通常干下面三件事：1.<strong>建表 / 建扩展</strong>；2.<strong>建向量索引</strong>；3.<strong>元数据初始化</strong></p>
<h4 id="fastapi实现生命周期的管理"><a href="#fastapi实现生命周期的管理" class="headerlink" title="fastapi实现生命周期的管理"></a>fastapi实现生命周期的管理</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"># 定义了一个异步函数lifespan，它接收一个FastAPI应用实例app作为参数。这个函数将管理应用的生命周期，包括启动和关闭时的操作</span><br><span class="line"># 函数在应用启动时执行一些初始化操作，如加载上下文数据、以及初始化问题生成器</span><br><span class="line"># 函数在应用关闭时执行一些清理操作</span><br><span class="line"># @asynccontextmanager 装饰器用于创建一个异步上下文管理器，它允许你在 yield 之前和之后执行特定的代码块，分别表示启动和关闭时的操作</span><br><span class="line">@asynccontextmanager</span><br><span class="line">async def lifespan(app: FastAPI):</span><br><span class="line">    # 启动时执行</span><br><span class="line">    # 申明引用全局变量，在函数中被初始化，并在整个应用中使用</span><br><span class="line">    global graph, connection_pool</span><br><span class="line">    # 启动时执行</span><br><span class="line">    try:</span><br><span class="line">        logger.info(&quot;正在初始化模型、定义 Graph...&quot;)</span><br><span class="line">        # 初始化 LLM</span><br><span class="line">        llm, embedding = get_llm(llm_type)</span><br><span class="line">        # 创建数据库连接池</span><br><span class="line">        DB_URI = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line">        connection_kwargs = &#123;</span><br><span class="line">            &quot;autocommit&quot;: True,</span><br><span class="line">            &quot;prepare_threshold&quot;: 0,</span><br><span class="line">        &#125;</span><br><span class="line">        connection_pool = ConnectionPool(</span><br><span class="line">            conninfo=DB_URI,</span><br><span class="line">            max_size=20,</span><br><span class="line">            kwargs=connection_kwargs,</span><br><span class="line">        )</span><br><span class="line">        connection_pool.open()  # 显式打开连接池</span><br><span class="line">        logger.info(&quot;数据库连接池初始化成功&quot;)</span><br><span class="line">        # 短期记忆 初始化checkpointer</span><br><span class="line">        checkpointer = PostgresSaver(connection_pool)</span><br><span class="line">        checkpointer.setup()</span><br><span class="line">        # 长期记忆 初始化PostgresStore</span><br><span class="line">        in_postgres_store = PostgresStore(</span><br><span class="line">            connection_pool,</span><br><span class="line">            index=&#123;</span><br><span class="line">                &quot;dims&quot;: 1536,</span><br><span class="line">                &quot;embed&quot;: embedding</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        in_postgres_store.setup()</span><br><span class="line">        # 定义 Graph</span><br><span class="line">        graph = create_graph(llm, checkpointer, in_postgres_store )</span><br><span class="line">        # 保存 Graph 可视化图</span><br><span class="line">        save_graph_visualization(graph)</span><br><span class="line">        logger.info(&quot;初始化完成&quot;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        logger.error(f&quot;初始化过程中出错: &#123;str(e)&#125;&quot;)</span><br><span class="line">        raise</span><br><span class="line"></span><br><span class="line">    yield  # 应用运行期间</span><br><span class="line"></span><br><span class="line">    # 关闭时执行</span><br><span class="line">    logger.info(&quot;正在关闭...&quot;)</span><br><span class="line">    if connection_pool:</span><br><span class="line">        connection_pool.close()  # 关闭连接池</span><br><span class="line">        logger.info(&quot;数据库连接池已关闭&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># lifespan参数用于在应用程序生命周期的开始和结束时执行一些初始化或清理工作</span><br><span class="line">app = FastAPI(lifespan=lifespan)</span><br></pre></td></tr></table></figure>
<h3 id="pgsql的存储结构"><a href="#pgsql的存储结构" class="headerlink" title="pgsql的存储结构"></a>pgsql的存储结构</h3><h4 id="一、Checkpoints-系列"><a href="#一、Checkpoints-系列" class="headerlink" title="一、Checkpoints 系列"></a>一、Checkpoints 系列</h4><blockquote>
<p>作用：让 <strong>LangGraph Runtime</strong> 能在 <strong>分布式/长流程</strong> 场景下 <strong>断点续跑、重放、并发控制</strong>。</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>表名</th>
<th>存什么</th>
<th>典型字段（示意）</th>
<th>何时写入</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>checkpoints</strong></td>
<td>每个「图实例」的 <strong>最新快照</strong>（state 的完整 JSONB）</td>
<td><code>thread_id</code>, <code>checkpoint_ns</code>, <code>checkpoint_id</code>, <code>parent_checkpoint_id</code>, <code>state</code>, <code>created_at</code></td>
<td>每次节点执行成功后覆盖更新</td>
</tr>
<tr>
<td><strong>checkpoint_blobs</strong></td>
<td>checkpoints 里 <strong>大字段的拆分</strong>（避免行过大）</td>
<td><code>thread_id</code>, <code>checkpoint_ns</code>, <code>channel</code>, <code>type</code>, <code>blob</code></td>
<td>当 state 过大，自动拆分</td>
</tr>
<tr>
<td><strong>checkpoint_migrations</strong></td>
<td>记录 <strong>schema 版本/迁移脚本</strong></td>
<td><code>version</code>, <code>name</code>, <code>applied_at</code></td>
<td>只在 <code>setup()</code> 时写一次</td>
</tr>
<tr>
<td><strong>checkpoint_writes</strong></td>
<td><strong>写放大日志</strong>（每个节点写 state 的增量 diff）</td>
<td><code>thread_id</code>, <code>checkpoint_id</code>, <code>task_id</code>, <code>idx</code>, <code>channel</code>, <code>type</code>, <code>value</code></td>
<td>每次节点完成时追加</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>关系：<br><code>checkpoints</code> = 最新完整快照<br><code>checkpoint_writes</code> = 所有增量历史（用于重放/审计）<br><code>checkpoint_blobs</code> = checkpoints 里超大型 value 的切片</p>
</blockquote>
<h4 id="二、Store-系列"><a href="#二、Store-系列" class="headerlink" title="二、Store 系列"></a>二、Store 系列</h4><blockquote>
<p>作用：给 <strong>业务代码（开发者）</strong> 提供 <strong>持久化 KV / 向量存储</strong>，与图运行状态无关。</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>表名</th>
<th>存什么</th>
<th>典型字段（示意）</th>
<th>何时写入</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>store</strong></td>
<td><strong>任意 KV 文档</strong>（LangChain Document → JSONB）</td>
<td><code>uuid</code>, <code>namespace</code>, <code>key</code>, <code>value</code>, <code>created_at</code>, <code>updated_at</code></td>
<td>你调用 <code>store.amput</code> / <code>amset</code> 等 API</td>
</tr>
<tr>
<td><strong>store_migrations</strong></td>
<td>同 checkpoint_migrations，记录 store schema 版本</td>
<td><code>version</code>, <code>name</code>, <code>applied_at</code></td>
<td>只在第一次 <code>setup()</code></td>
</tr>
<tr>
<td><strong>store_vectors</strong></td>
<td><strong>向量索引表</strong>（embedding → vector 类型）</td>
<td><code>uuid</code>, <code>collection_id</code>, <code>embedding</code>, <code>document</code>, <code>metadata</code></td>
<td>你调用 <code>add_documents(..., embeddings=...)</code></td>
</tr>
<tr>
<td><strong>vector_migrations</strong></td>
<td>记录 pgvector 扩展及索引迁移版本</td>
<td><code>version</code>, <code>applied_at</code></td>
<td><code>setup()</code> 时若第一次装 pgvector</td>
</tr>
</tbody>
</table>
</div>
<h4 id="三、调用链脑图"><a href="#三、调用链脑图" class="headerlink" title="三、调用链脑图"></a>三、调用链脑图</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">┌──────────────┐</span><br><span class="line">│ LangGraph    │ 运行图实例</span><br><span class="line">└────┬─────────┘</span><br><span class="line">     │1. 写 checkpoints</span><br><span class="line">     │2. 写 checkpoint_writes</span><br><span class="line">     │3. 拆大字段到 checkpoint_blobs</span><br><span class="line">     ▼</span><br><span class="line">┌──────────────┐</span><br><span class="line">│ 业务代码     │ 读写 KV/向量</span><br><span class="line">└────┬─────────┘</span><br><span class="line">     │1. 写 store</span><br><span class="line">     │2. 写 store_vectors</span><br><span class="line">     ▼</span><br><span class="line"> PostgreSQL (pgsql)</span><br></pre></td></tr></table></figure>
<h3 id="在linux安装postgresql"><a href="#在linux安装postgresql" class="headerlink" title="在linux安装postgresql"></a>在linux安装postgresql</h3><h4 id="查看linux发行版本"><a href="#查看linux发行版本" class="headerlink" title="查看linux发行版本"></a>查看linux发行版本</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看发行版名称和版本</span><br><span class="line">cat /etc/os-release</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">PRETTY_NAME=&quot;Ubuntu 24.04.2 LTS&quot;</span><br><span class="line">NAME=&quot;Ubuntu&quot;</span><br><span class="line">VERSION_ID=&quot;24.04&quot;</span><br><span class="line">VERSION=&quot;24.04.2 LTS (Noble Numbat)&quot;</span><br><span class="line">VERSION_CODENAME=noble</span><br><span class="line">ID=ubuntu</span><br><span class="line">ID_LIKE=debian</span><br><span class="line">HOME_URL=&quot;https://www.ubuntu.com/&quot;</span><br><span class="line">SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;</span><br><span class="line">PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;</span><br><span class="line">UBUNTU_CODENAME=noble</span><br><span class="line">LOGO=ubuntu-logo</span><br></pre></td></tr></table></figure>
<h4 id="安装postgresql"><a href="#安装postgresql" class="headerlink" title="安装postgresql"></a>安装postgresql</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 更新软件包索引</span><br><span class="line">sudo apt update</span><br><span class="line"></span><br><span class="line"># 安装 PostgreSQL 和常用扩展</span><br><span class="line">sudo apt install -y postgresql postgresql-contrib</span><br><span class="line"></span><br><span class="line"># 检查服务状态</span><br><span class="line">#Linux 容器/子系统（ Docker、WSL 或 LXC）没有使用 systemd ，因此 systemctl 无法工作</span><br><span class="line">sudo systemctl status postgresql</span><br><span class="line"></span><br><span class="line">#确认 PostgreSQL 已安装</span><br><span class="line">which psql            # 应该输出 /usr/bin/psql</span><br><span class="line">pg_ctl --version      # 显示版本号即已安装</span><br></pre></td></tr></table></figure>
<ul>
<li><code>postgresql</code> 是主程序</li>
<li><code>postgresql-contrib</code> 提供额外扩展（如 <code>uuid-ossp</code>、<code>pgcrypto</code> 等）</li>
</ul>
<blockquote>
<p>systemctl一般用于服务器上，完整的linux系统上</p>
<p>Linux 容器/子系统（ Docker、WSL 或 LXC）使用 service</p>
</blockquote>
<p>启动pgsql服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service postgresql start</span><br></pre></td></tr></table></figure>
<p>停止pgsql服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service postgresql stop</span><br></pre></td></tr></table></figure>
<p>查看状态</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service postgresql status</span><br></pre></td></tr></table></figure>
<h3 id="更换apt镜像源"><a href="#更换apt镜像源" class="headerlink" title="更换apt镜像源"></a>更换apt镜像源</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/apt/sources.list &lt;&lt;&#x27;EOF&#x27;</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm-updates main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm-backports main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian-security bookworm-security main contrib non-free</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">apt update</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7470702616906645540">postgresql向量扩展pgvector的安装与入门本文简答的介绍了 rag 的架构，引申出向量数据库的作用，介绍了 - 掘金</a></p>
<p>langchain支持向量存储<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/integrations/vectorstores/">向量存储 | 🦜️🔗 LangChain —- Vector stores | 🦜️🔗 LangChain</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/28/%E5%AD%A6%E4%B9%A0/transfromers/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/28/%E5%AD%A6%E4%B9%A0/transfromers/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" class="post-title-link" itemprop="url">Transformer快速入门</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-07-28 00:00:00 / 修改时间：10:39:27" itemprop="dateCreated datePublished" datetime="2025-07-28T00:00:00+08:00">2025-07-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/transformer/" itemprop="url" rel="index"><span itemprop="name">transformer</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a target="_blank" rel="noopener" href="https://transformers.run/">Hello! · Transformers快速入门</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/jsksxs360/How-to-use-Transformers">jsksxs360/How-to-use-Transformers: Transformers 库快速入门教程</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">MCP 学习笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-27 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-27T00:00:00+08:00">2025-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-01 14:31:13" itemprop="dateModified" datetime="2025-08-01T14:31:13+08:00">2025-08-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/mcp/" itemprop="url" rel="index"><span itemprop="name">mcp</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="什么是-MCP？"><a href="#什么是-MCP？" class="headerlink" title="什么是 MCP？"></a>什么是 MCP？</h3><ul>
<li><strong>全称</strong>：Model Context Protocol</li>
<li><strong>作用</strong>：让 AI 助手（如 Claude、Cline 等）在对话过程中，动态调用外部工具（Tool）完成复杂任务（读写文件、查询数据库、调用 API 等）。</li>
<li><strong>组成</strong>：<ol>
<li><strong>MCP Host</strong>（宿主，如 Cline、Claude Desktop）</li>
<li><strong>MCP Server</strong>（提供 Tool 的后台服务）</li>
<li><strong>Tool</strong>（具体功能单元，如 <code>read_file</code>, <code>exec_command</code> 等）</li>
</ol>
</li>
</ul>
<h3 id="核心概念速记"><a href="#核心概念速记" class="headerlink" title="核心概念速记"></a>核心概念速记</h3><ul>
<li><strong>MCP Server</strong><ul>
<li>一个独立进程，提供 1-N 个 Tool。</li>
<li>可以用任何语言编写，只要暴露标准 MCP 接口。</li>
</ul>
</li>
<li><strong>Tool</strong><ul>
<li>最小执行单元，必须包含：<ul>
<li>name（唯一）</li>
<li>description（让 LLM 理解何时调用）</li>
<li>input schema（参数结构，JSON Schema）</li>
</ul>
</li>
</ul>
</li>
<li><strong>交互流程（重点）</strong><ul>
<li>在启动mcp server时，server将tool信息传送给host</li>
<li>用户在 Host 输入自然语言需求。</li>
<li>Host 将需求 + 可用 Tool 列表发给 LLM。</li>
<li>LLM 判断调用哪个 Tool，并填充参数。</li>
<li>Host 通过 MCP 协议向对应 Server 发送请求。</li>
<li>Server 执行 Tool 并返回结果。</li>
<li>Host 将结果合并上下文，继续对话。</li>
</ul>
</li>
</ul>
<h3 id="安装mcp"><a href="#安装mcp" class="headerlink" title="安装mcp"></a>安装mcp</h3><p>在mcp server市场查找自己想用的mcp服务，如<a target="_blank" rel="noopener" href="https://mcp.so/server/fetch/modelcontextprotocol?tab=content">Fetch MCP Server</a></p>
<p>复制mcp配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;mcpServers&quot;: &#123;</span><br><span class="line">    &quot;fetch&quot;: &#123;</span><br><span class="line">      &quot;command&quot;: &quot;uvx&quot;,</span><br><span class="line">      &quot;args&quot;: [</span><br><span class="line">        &quot;mcp-server-fetch&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在mcp host 中安装，如trae</p>
<p>host会自动完成对mcp的配置</p>
<h3 id="创建一个mcp-server"><a href="#创建一个mcp-server" class="headerlink" title="创建一个mcp server"></a>创建一个mcp server</h3><p>初始化项目</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">uv init weather</span><br><span class="line"></span><br><span class="line">uv sync</span><br><span class="line"></span><br><span class="line">source .venv/bin/activate </span><br><span class="line"></span><br><span class="line">#添加依赖</span><br><span class="line">uv add &quot;mcp[cli]&quot; httpx</span><br></pre></td></tr></table></figure>
<p>创建weather.py</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"># 导入类型提示模块，用于类型注解</span><br><span class="line">from typing import Any</span><br><span class="line"></span><br><span class="line"># 导入httpx库，用于发送HTTP请求</span><br><span class="line">import httpx</span><br><span class="line"></span><br><span class="line"># 从mcp.server.fastmcp模块导入FastMCP类</span><br><span class="line"># FastMCP是一个快速构建MCP（Model Control Protocol）服务器的框架</span><br><span class="line">from mcp.server.fastmcp import FastMCP</span><br><span class="line"></span><br><span class="line"># 创建FastMCP实例，命名为&quot;weather&quot;，日志级别设置为ERROR（只显示错误信息）</span><br><span class="line">mcp = FastMCP(&quot;weather&quot;, log_level=&quot;ERROR&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 常量定义</span><br><span class="line"># NWS（National Weather Service）API的基础URL</span><br><span class="line">NWS_API_BASE = &quot;https://api.weather.gov&quot;</span><br><span class="line"># 用户代理字符串，用于标识应用程序</span><br><span class="line">USER_AGENT = &quot;weather-app/1.0&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">async def make_nws_request(url: str) -&gt; dict[str, Any] | None:</span><br><span class="line">    &quot;&quot;&quot;向NWS API发起请求并处理错误。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        url: 要请求的API URL</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        成功时返回解析后的JSON数据字典，失败时返回None</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 设置请求头信息</span><br><span class="line">    headers = &#123;</span><br><span class="line">        &quot;User-Agent&quot;: USER_AGENT,           # 用户代理标识</span><br><span class="line">        &quot;Accept&quot;: &quot;application/geo+json&quot;    # 接受的数据格式</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    # 创建异步HTTP客户端</span><br><span class="line">    async with httpx.AsyncClient() as client:</span><br><span class="line">        try:</span><br><span class="line">            # 发起GET请求，设置超时时间为30秒</span><br><span class="line">            response = await client.get(url, headers=headers, timeout=30.0)</span><br><span class="line">            # 如果响应状态码不是2xx，抛出异常</span><br><span class="line">            response.raise_for_status()</span><br><span class="line">            # 返回解析后的JSON数据</span><br><span class="line">            return response.json()</span><br><span class="line">        except Exception:</span><br><span class="line">            # 捕获所有异常，返回None表示请求失败</span><br><span class="line">            return None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def format_alert(feature: dict) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;将警报数据格式化为可读的字符串。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        feature: 包含警报信息的字典</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的警报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 获取警报属性</span><br><span class="line">    props = feature[&quot;properties&quot;]</span><br><span class="line">    # 格式化警报信息，使用get方法提供默认值防止键不存在</span><br><span class="line">    return f&quot;&quot;&quot;</span><br><span class="line">事件: &#123;props.get(&#x27;event&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">区域: &#123;props.get(&#x27;areaDesc&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">严重程度: &#123;props.get(&#x27;severity&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">描述: &#123;props.get(&#x27;description&#x27;, &#x27;无描述信息&#x27;)&#125;</span><br><span class="line">指示: &#123;props.get(&#x27;instruction&#x27;, &#x27;无具体指示&#x27;)&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 使用@mcp.tool()装饰器将函数注册为MCP工具</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_alerts(state: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定美国州的天气警报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        state: 两个字母的美国州代码（例如：CA, NY）</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的警报信息字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 构建获取州警报的URL</span><br><span class="line">    url = f&quot;&#123;NWS_API_BASE&#125;/alerts/active/area/&#123;state&#125;&quot;</span><br><span class="line">    # 发起API请求获取数据</span><br><span class="line">    data = await make_nws_request(url)</span><br><span class="line"></span><br><span class="line">    # 检查数据是否有效</span><br><span class="line">    if not data or &quot;features&quot; not in data:</span><br><span class="line">        return &quot;无法获取警报或未找到警报。&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否有警报</span><br><span class="line">    if not data[&quot;features&quot;]:</span><br><span class="line">        return &quot;该州无活动警报。&quot;</span><br><span class="line"></span><br><span class="line">    # 格式化所有警报</span><br><span class="line">    alerts = [format_alert(feature) for feature in data[&quot;features&quot;]]</span><br><span class="line">    # 用分隔符连接所有警报</span><br><span class="line">    return &quot;\n---\n&quot;.join(alerts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 注册为MCP工具的天气预报函数</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_forecast(latitude: float, longitude: float) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定位置的天气预报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        latitude: 位置的纬度</span><br><span class="line">        longitude: 位置的经度</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的天气预报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 首先获取预报网格端点</span><br><span class="line">    points_url = f&quot;&#123;NWS_API_BASE&#125;/points/&#123;latitude&#125;,&#123;longitude&#125;&quot;</span><br><span class="line">    points_data = await make_nws_request(points_url)</span><br><span class="line"></span><br><span class="line">    # 检查点数据是否获取成功</span><br><span class="line">    if not points_data:</span><br><span class="line">        return &quot;无法获取此位置的预报数据。&quot;</span><br><span class="line"></span><br><span class="line">    # 从点响应中获取预报URL</span><br><span class="line">    forecast_url = points_data[&quot;properties&quot;][&quot;forecast&quot;]</span><br><span class="line">    forecast_data = await make_nws_request(forecast_url)</span><br><span class="line"></span><br><span class="line">    # 检查预报数据是否获取成功</span><br><span class="line">    if not forecast_data:</span><br><span class="line">        return &quot;无法获取详细预报。&quot;</span><br><span class="line"></span><br><span class="line">    # 将时间段格式化为可读的预报</span><br><span class="line">    periods = forecast_data[&quot;properties&quot;][&quot;periods&quot;]</span><br><span class="line">    forecasts = []</span><br><span class="line">    # 只显示接下来的5个时间段</span><br><span class="line">    for period in periods[:5]:</span><br><span class="line">        forecast = f&quot;&quot;&quot;</span><br><span class="line">&#123;period[&#x27;name&#x27;]&#125;:</span><br><span class="line">温度: &#123;period[&#x27;temperature&#x27;]&#125;°&#123;period[&#x27;temperatureUnit&#x27;]&#125;</span><br><span class="line">风力: &#123;period[&#x27;windSpeed&#x27;]&#125; &#123;period[&#x27;windDirection&#x27;]&#125;</span><br><span class="line">预报: &#123;period[&#x27;detailedForecast&#x27;]&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">        forecasts.append(forecast)</span><br><span class="line"></span><br><span class="line">    # 用分隔符连接所有预报</span><br><span class="line">    return &quot;\n---\n&quot;.join(forecasts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 初始化并运行服务器，使用stdio传输方式</span><br><span class="line">    mcp.run(transport=&#x27;stdio&#x27;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>@mcp.tool()可以将函数内的字符串，参数类型等信息传给大模型，以供大模型决定何时调用这个tool</p>
<p>mcp.run(transport=’stdio’)说明mcp server和host的传输方式是输入和输出</p>
</blockquote>
<p>mcp server 配置信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&quot;weather&quot;: &#123;</span><br><span class="line">    &quot;disabled&quot;: false,</span><br><span class="line">    &quot;timeout&quot;: 60,</span><br><span class="line">    &quot;command&quot;: &quot;uv&quot;,</span><br><span class="line">    &quot;args&quot;: [</span><br><span class="line">      &quot;--directory&quot;,</span><br><span class="line">      &quot;/Users/joeygreen/PycharmProjects/weather&quot;,</span><br><span class="line">      &quot;run&quot;,</span><br><span class="line">      &quot;weather.py&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;transportType&quot;: &quot;stdio&quot;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>“disabled”: false表示该服务是否被禁用。<code>false</code> 表示该服务是启用状态，可以正常运行。</p>
<p>“timeout”: 60设置该服务的超时时间，单位为秒。</p>
<p>“command”: “uv”指定执行该服务时使用的命令。</p>
<p>“args”出了执行 <code>command</code> 时需要传递的参数。</p>
<p>“transportType”: “stdio”指定服务的通信方式。<code>stdio</code> 表示标准输入输出流（Standard Input Output），通常用于进程间通信。</p>
</blockquote>
<h3 id="解析mcp-server与host的通信"><a href="#解析mcp-server与host的通信" class="headerlink" title="解析mcp server与host的通信"></a>解析mcp server与host的通信</h3><p><img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727154739013.png" alt="image-20250727154739013"></p>
<p>输入为host对server发送，输出为server对host发送，以下将列举几个重要的说明</p>
<p>输入中：<code>method</code>字段为host告诉server接下来要干什么，如<strong>初始化 (Initialization)</strong>，<strong>通知已初始化 (Notification)</strong>，<strong>查询可用工具 (Listing Tools)</strong>，<strong>调用工具 (Calling a Tool)</strong></p>
<p><code>protocolVersion</code>说明了mcp使用的协议版本</p>
<p>以下见server返回的tool信息，其中的一个参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;get_forecast&quot;,</span><br><span class="line">    &quot;description&quot;: &quot;Get weather forecast for a location.\n\nArgs:\n    latitude: Latitude of the location\n    longitude: Longitude of the location\n&quot;,</span><br><span class="line">    &quot;inputSchema&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;latitude&quot;: &#123;</span><br><span class="line">                &quot;title&quot;: &quot;Latitude&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;number&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;longitude&quot;: &#123;</span><br><span class="line">                &quot;title&quot;: &quot;Longitude&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;number&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;required&quot;: [</span><br><span class="line">            &quot;latitude&quot;,</span><br><span class="line">            &quot;longitude&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;title&quot;: &quot;get_forecastArguments&quot;,</span><br><span class="line">        &quot;type&quot;: &quot;object&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以和定义的函数对比学习</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"># 注册为MCP工具的天气预报函数</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_forecast(latitude: float, longitude: float) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定位置的天气预报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        latitude: 位置的纬度</span><br><span class="line">        longitude: 位置的经度</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的天气预报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 首先获取预报网格端点</span><br><span class="line">    points_url = f&quot;&#123;NWS_API_BASE&#125;/points/&#123;latitude&#125;,&#123;longitude&#125;&quot;</span><br><span class="line">    points_data = await make_nws_request(points_url)</span><br><span class="line"></span><br><span class="line">    # 检查点数据是否获取成功</span><br><span class="line">    if not points_data:</span><br><span class="line">        return &quot;无法获取此位置的预报数据。&quot;</span><br><span class="line"></span><br><span class="line">    # 从点响应中获取预报URL</span><br><span class="line">    forecast_url = points_data[&quot;properties&quot;][&quot;forecast&quot;]</span><br><span class="line">    forecast_data = await make_nws_request(forecast_url)</span><br><span class="line"></span><br><span class="line">    # 检查预报数据是否获取成功</span><br><span class="line">    if not forecast_data:</span><br><span class="line">        return &quot;无法获取详细预报。&quot;</span><br><span class="line"></span><br><span class="line">    # 将时间段格式化为可读的预报</span><br><span class="line">    periods = forecast_data[&quot;properties&quot;][&quot;periods&quot;]</span><br><span class="line">    forecasts = []</span><br><span class="line">    # 只显示接下来的5个时间段</span><br><span class="line">    for period in periods[:5]:</span><br><span class="line">        forecast = f&quot;&quot;&quot;</span><br><span class="line">&#123;period[&#x27;name&#x27;]&#125;:</span><br><span class="line">温度: &#123;period[&#x27;temperature&#x27;]&#125;°&#123;period[&#x27;temperatureUnit&#x27;]&#125;</span><br><span class="line">风力: &#123;period[&#x27;windSpeed&#x27;]&#125; &#123;period[&#x27;windDirection&#x27;]&#125;</span><br><span class="line">预报: &#123;period[&#x27;detailedForecast&#x27;]&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">        forecasts.append(forecast)</span><br><span class="line"></span><br><span class="line">    # 用分隔符连接所有预报</span><br><span class="line">    return &quot;\n---\n&quot;.join(forecasts)</span><br></pre></td></tr></table></figure>
<p><code>description</code>内容即为我们在定义这个tool的时候写的<strong>文档字符串</strong>（Documentation String），通常简称为 <strong>docstring</strong></p>
<p><code>inputSchema</code> 是在MCP（Model Control Protocol）中用来<strong>描述工具（tool）所需参数的结构和类型的规范</strong>。它本质上是一个JSON Schema。</p>
<blockquote>
<p>JSON Schema 是一个用于<strong>描述和验证 JSON 数据结构的规范</strong>。你可以把它理解为 JSON 数据的“蓝图”或“模板”。</p>
</blockquote>
<p><code>required</code>指明哪些参数是必需的，哪些是可选的。</p>
<h3 id="理解mcp的本质"><a href="#理解mcp的本质" class="headerlink" title="理解mcp的本质"></a>理解mcp的本质</h3><p>以上内容皆是server与host直接的交互，本质上可以理解成host对server提供的工具进行注册与使用。这其中并不涉及到host与大模型的交互，也就是大模型是如何使用host提供的信息。实际上不同的mcp host与模型的交互协议也不同，如cline使用的是xml格式；cherry studio使用的则是fuction calling</p>
<p>再看mcp的全称Model Context Protocol，模型上下文协议，也就是mcp增加模型的扩展性，使他可以获取更多信息，而server就是为模型提供更多信息的工具</p>
<h3 id="mcp-host与模型的交互"><a href="#mcp-host与模型的交互" class="headerlink" title="mcp host与模型的交互"></a>mcp host与模型的交互</h3><p>使用中转服务器截获日志</p>
<p><img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727163811531-1753605912284-1.png" alt="image-20250727163811531"></p>
<p>以下为cline发送给模型的请求</p>
<p><img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727164527797.png" alt="image-20250727164527797"></p>
<p><code>messages</code>包含了系统提示词与用户输入</p>
<p>先来看系统提示词，cline提供的提示词包括工具使用格式，工具信息，工具使用方法等。这里重点说一下，cline的工具使用格式xml</p>
<p>结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;tool_name&gt;</span><br><span class="line">&lt;parameter1_name&gt;value1&lt;/parameter1_name&gt;</span><br><span class="line">&lt;parameter2_name&gt;value2&lt;/parameter2_name&gt;</span><br><span class="line">...</span><br><span class="line">&lt;/tool_name&gt;</span><br></pre></td></tr></table></figure>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;read_file&gt;</span><br><span class="line">src/main.js</span><br><span class="line">&lt;/read_file&gt;</span><br></pre></td></tr></table></figure>
<p>再举个例子</p>
<p>use_mcp_tool<br>描述：请求使用由连接的 MCP 服务器提供的工具。每个 MCP 服务器可以提供具有不同功能的多个工具。工具有定义的输入模式，用于指定必需和可选参数。<br>参数：</p>
<p>server_name: (必需) 提供该工具的 MCP 服务器的名称<br>tool_name: (必需) 要执行的工具的名称<br>arguments: (必需) 一个 JSON 对象，包含工具的输入参数，遵循工具的输入模式<br>用法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;use_mcp_tool&gt;</span><br><span class="line">&lt;server_name&gt;服务器名称在此&lt;/server_name&gt;</span><br><span class="line">&lt;tool_name&gt;工具名称在此&lt;/tool_name&gt;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">&quot;param1&quot;: &quot;value1&quot;,</span><br><span class="line">&quot;param2&quot;: &quot;value2&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&lt;/use_mcp_tool&gt;</span><br></pre></td></tr></table></figure>
<p>模型返回响应如下</p>
<p><img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727174504506.png" alt="image-20250727174504506"></p>
<p>sse连接，流式输出</p>
<blockquote>
<p>SSE 是一种<strong>基于标准 HTTP</strong>、<strong>只允许服务器向客户端单向推送文本流</strong>的实时通信技术，浏览器原生支持，自动重连，常用于<strong>AI 流式回答</strong>、<strong>实时日志</strong>、<strong>股价/监控推送</strong>等场景。</p>
<p>即客户端发送一次请求，连续接受多次响应直到结束</p>
</blockquote>
<h3 id="mcp的三种传输协议"><a href="#mcp的三种传输协议" class="headerlink" title="mcp的三种传输协议"></a>mcp的三种传输协议</h3><div class="table-container">
<table>
<thead>
<tr>
<th>协议名称</th>
<th>通信方式</th>
<th>适用场景</th>
<th>优势</th>
<th>局限</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Stdio</strong>（标准输入输出）</td>
<td>使用进程的标准输入（stdin）和标准输出（stdout）进行本地通信，基于 JSON-RPC 2.0 格式</td>
<td>本地开发、调试、IDE插件、命令行工具</td>
<td>简单易实现、跨平台、低延迟</td>
<td>仅支持本地通信，无法跨网络，低并发</td>
</tr>
<tr>
<td><strong>SSE</strong>（Server-Sent Events）</td>
<td>客户端通过 HTTP POST 发送请求，服务器通过 SSE 单向推送流式响应</td>
<td>实时监控、新闻推送、远程服务调用</td>
<td>基于 HTTP，浏览器友好，支持流式数据</td>
<td>仅支持单向通信，MCP官方已标记为“即将废弃”</td>
</tr>
<tr>
<td><strong>Streamable HTTP</strong>（新型流式HTTP）</td>
<td>支持双向流式通信的现代 HTTP 协议，替代 SSE，支持会话恢复、OAuth 认证等</td>
<td>分布式系统、高并发、双向实时交互</td>
<td>双向通信、高性能、企业级安全机制</td>
<td>实现较复杂，生态仍在发展中</td>
</tr>
</tbody>
</table>
</div>
<h3 id="ReAct"><a href="#ReAct" class="headerlink" title="ReAct"></a>ReAct</h3><p>ReAct 是一种用于增强大型语言模型（LLMs）推理和行动能力的技术框架，它通过结合“推理”（Reasoning）和“行动”（Acting）来提升模型处理复杂任务的能力。</p>
<p>其工作流程通常包括以下几个步骤：</p>
<ol>
<li><strong>思考（Reasoning）</strong>：模型对当前问题进行分析，思考下一步需要采取的行动。</li>
<li><strong>行动（Acting）</strong>：模型决定调用哪些工具或函数，并提供必要的参数。</li>
<li><strong>观察（Observation）</strong>：工具执行后返回结果，模型对结果进行观察。</li>
<li><strong>响应（Response）</strong>：根据观察结果，模型生成最终的用户响应。</li>
</ol>
<p>实际应用上就是告诉大模型用ReAct这种模式来思考</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1uronYREWR?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">MCP终极指南 - 从原理到实战，带你深入掌握MCP（基础篇）_哔哩哔哩_bilibili</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/" class="post-title-link" itemprop="url">LangGraph学习——agent——下</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-22T00:00:00+08:00">2025-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-27 12:14:49" itemprop="dateModified" datetime="2025-07-27T12:14:49+08:00">2025-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本教程为langchain官方教程的学习记录</p>
<p><a target="_blank" rel="noopener" href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a target="_blank" rel="noopener" href="https://github.com/zxj-2023/learn-rag-langchain">zxj-2023/learn-rag-langchain</a></p>
<h3 id="module-4"><a href="#module-4" class="headerlink" title="module-4"></a>module-4</h3><h4 id="Parallel-node-execution-并行节点执行"><a href="#Parallel-node-execution-并行节点执行" class="headerlink" title="Parallel node execution 并行节点执行"></a><strong>Parallel node execution</strong> <strong>并行节点执行</strong></h4><h5 id="Waiting-for-nodes-to-finish-等待节点完成"><a href="#Waiting-for-nodes-to-finish-等待节点完成" class="headerlink" title="Waiting for nodes to finish 等待节点完成"></a><strong>Waiting for nodes to finish</strong> <strong>等待节点完成</strong></h5><p>现在，让我们考虑一个案例，其中一个并行路径的步骤比另一个多。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># Initialize each node with node_secret </span><br><span class="line">builder.add_node(&quot;a&quot;, ReturnNodeValue(&quot;I&#x27;m A&quot;))</span><br><span class="line">builder.add_node(&quot;b&quot;, ReturnNodeValue(&quot;I&#x27;m B&quot;))</span><br><span class="line">builder.add_node(&quot;b2&quot;, ReturnNodeValue(&quot;I&#x27;m B2&quot;))</span><br><span class="line">builder.add_node(&quot;c&quot;, ReturnNodeValue(&quot;I&#x27;m C&quot;))</span><br><span class="line">builder.add_node(&quot;d&quot;, ReturnNodeValue(&quot;I&#x27;m D&quot;))</span><br><span class="line"></span><br><span class="line"># Flow</span><br><span class="line">builder.add_edge(START, &quot;a&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;b&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;c&quot;)</span><br><span class="line">builder.add_edge(&quot;b&quot;, &quot;b2&quot;)</span><br><span class="line">builder.add_edge([&quot;b2&quot;, &quot;c&quot;], &quot;d&quot;)</span><br><span class="line">builder.add_edge(&quot;d&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722143802652.png" alt="image-20250722143802652"></p>
<p>在这种情况下，<code>b</code>、<code>b2</code> 和 <code>c</code> 都是同一个步骤的一部分。图形将在进入 <code>d</code> 步骤之前等待所有这些操作完成。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Adding I&#x27;m A to []</span><br><span class="line">Adding I&#x27;m B to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m C to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m B2 to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;]</span><br><span class="line">Adding I&#x27;m D to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;]</span><br><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Setting-the-order-of-state-updates-设置状态更新的顺序"><a href="#Setting-the-order-of-state-updates-设置状态更新的顺序" class="headerlink" title="Setting the order of state updates 设置状态更新的顺序"></a><strong>Setting the order of state updates</strong> <strong>设置状态更新的顺序</strong></h5><p>然而，在每个步骤中，我们无法对状态更新的顺序进行具体控制！简单来说，它是基于图拓扑结构由 LangGraph 确定的确定性顺序，该顺序为 <strong><em>\</em>我们无法控制**</strong>。</p>
<p>上面，我们看到 <code>c</code> 被添加在 <code>b2</code> 之前</p>
<p>然而，我们可以使用自定义 reducer 来定制此功能，例如，对状态更新进行排序。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def sorting_reducer(left, right):</span><br><span class="line">    &quot;&quot;&quot; 合并并排序列表中的值&quot;&quot;&quot;</span><br><span class="line">    # 如果 left 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(left, list):</span><br><span class="line">        left = [left]</span><br><span class="line"></span><br><span class="line">    # 如果 right 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(right, list):</span><br><span class="line">        right = [right]</span><br><span class="line">    </span><br><span class="line">    # 合并 left 和 right 列表，然后升序排序</span><br><span class="line">    return sorted(left + right, reverse=False)</span><br><span class="line">class State(TypedDict):</span><br><span class="line">    # sorting_reducer 函数将对 state 中的值进行排序</span><br><span class="line">    state: Annotated[list, sorting_reducer]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<p>现在，reducer 对更新的状态值进行排序！<code>sorting_reducer</code> 示例对所有值进行全局排序。我们还可以：</p>
<ol>
<li>在并行步骤期间将输出写入状态中的单独字段  </li>
<li>在并行步骤之后使用“汇”节点来合并和排序这些输出  </li>
<li>合并后清除临时字段</li>
</ol>
<p>请参阅 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/branching/#stable-sorting">docs</a> 以获取更多详细信息。</p>
<h5 id="Working-with-LLMs-使用-LLMs"><a href="#Working-with-LLMs-使用-LLMs" class="headerlink" title="Working with LLMs  使用 LLMs"></a><strong>Working with LLMs</strong>  <strong>使用 LLMs</strong></h5><p>现在，让我们添加一个现实中的例子！我们希望从两个外部来源（Wikipedia 和 Web-Search）收集上下文信息，并让 LLM 回答一个问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br><span class="line">from langchain_community.tools import TavilySearchResults</span><br><span class="line"></span><br><span class="line">def search_web(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">    search_docs = tavily_search.invoke(state[&#x27;question&#x27;])</span><br><span class="line"></span><br><span class="line">     # 将多个搜索文档转换成了一个统一格式的长文本，每个文档都有自己的元数据（如URL），并且文档之间有明确的分隔，便于后续处理或展示。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    - 这是一个 列表推导式 (list comprehension) ，它会遍历 search_docs 列表中的每一个元素（这里我们称之为 doc ）。</span><br><span class="line">    - search_docs 里的每个 doc 应该是一个包含 &#x27;url&#x27; 和 &#x27;content&#x27; 键的字典。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = WikipediaLoader(query=state[&#x27;question&#x27;], </span><br><span class="line">                                  load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def generate_answer(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 用于回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    question = state[&quot;question&quot;]</span><br><span class="line"></span><br><span class="line">    # 模板</span><br><span class="line">    answer_template = &quot;&quot;&quot;使用以下上下文回答问题 &#123;question&#125;: &#123;context&#125;&quot;&quot;&quot;</span><br><span class="line">    answer_instructions = answer_template.format(question=question, </span><br><span class="line">                                                       context=context)    </span><br><span class="line">    </span><br><span class="line">    # 回答</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=answer_instructions)]+[HumanMessage(content=f&quot;回答问题。&quot;)])</span><br><span class="line">      </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;answer&quot;: answer&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点</span><br><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># 初始化每个节点</span><br><span class="line">builder.add_node(&quot;search_web&quot;,search_web)</span><br><span class="line">builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">builder.add_node(&quot;generate_answer&quot;, generate_answer)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">builder.add_edge(START, &quot;search_wikipedia&quot;)</span><br><span class="line">builder.add_edge(START, &quot;search_web&quot;)</span><br><span class="line">builder.add_edge(&quot;search_wikipedia&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;search_web&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;generate_answer&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722153534867.png" alt="image-20250722153534867"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = graph.invoke(&#123;&quot;question&quot;: &quot;英伟达2025年第一季度财报表现如何&quot;&#125;)</span><br><span class="line">result[&#x27;answer&#x27;].content</span><br></pre></td></tr></table></figure>
<h4 id="Sub-graphs-子图"><a href="#Sub-graphs-子图" class="headerlink" title="Sub-graphs 子图"></a><strong>Sub-graphs</strong> 子图</h4><p>子图允许你在图表的不同部分创建和管理不同的状态。这在多智能体系统中尤其有用，尤其是在每个智能体都有各自状态的智能体团队中。</p>
<p>让我们考虑一个简单的例子：</p>
<ul>
<li>我有一个系统，它接收日志。</li>
<li>该系统通过不同的代理执行两个独立的子任务（总结日志，查找故障模式）。</li>
<li>我希望在两个不同的子图中执行这两个操作。</li>
</ul>
<p>最重要的是要理解图表是如何传达信息的！</p>
<p>简而言之，通信是 <strong><em>\</em>通过重叠密钥**</strong> 实现的：</p>
<ul>
<li>子图可以访问父图中的 <code>docs</code>（文档）。</li>
<li>父图可以从子图中访问 <code>summary</code>（摘要）和 <code>failure_report</code>（故障报告）。</li>
</ul>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/66dbb1abf89f2d847ee6f1ff_sub-graph1.png" alt="subgraph.png"></p>
<ol>
<li><strong>Logs (Traces)</strong>:<ul>
<li>这是系统的输入，表示一系列的日志记录。</li>
</ul>
</li>
<li><strong>Entry Graph</strong>:<ul>
<li>这是系统的入口图，它包含了总体状态（Overall State），其中包含：<ul>
<li><code>docs</code>：文档或日志数据。</li>
<li><code>summary report</code>：摘要报告，这是系统执行摘要任务后生成的。</li>
<li><code>failure report</code>：故障报告，这是系统执行故障分析任务后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Call sub-graphs</strong>:<ul>
<li>这是从入口图调用两个子图的过程，分别用于执行摘要和故障分析任务。</li>
</ul>
</li>
<li><strong>Summarization</strong>:<ul>
<li>这个子图负责生成日志的摘要。它的状态（Summary State）包含：<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>summary</code>：摘要内容。</li>
<li><code>summary report</code>：摘要报告，这是摘要任务完成后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Failure Analysis</strong>:<ul>
<li>这个子图负责分析日志中的故障模式。它的状态（Failure Analysis State）包含：<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>failures</code>：故障模式。</li>
<li><code>failure report</code>：故障报告，这是故障分析任务完成后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Finish</strong>:<ul>
<li>这是流程的结束点，表示两个子图的任务都已完成，并且生成了摘要报告和故障报告。</li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from typing import List, Optional, Annotated</span><br><span class="line"></span><br><span class="line">#logs结构</span><br><span class="line">class Log(TypedDict):</span><br><span class="line">    id: str</span><br><span class="line">    question: str</span><br><span class="line">    docs: Optional[List]</span><br><span class="line">    answer: str</span><br><span class="line">    grade: Optional[int]</span><br><span class="line">    grader: Optional[str]</span><br><span class="line">    feedback: Optional[str]</span><br></pre></td></tr></table></figure>
<h5 id="Sub-graphs"><a href="#Sub-graphs" class="headerlink" title="Sub graphs"></a><strong>Sub graphs</strong></h5><p>这里是失败分析子图，它使用了 <code>FailureAnalysisState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line"># 故障分析子图</span><br><span class="line">class FailureAnalysisState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于故障分析的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    failures: List[Log]     # 包含故障的日志列表</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class FailureAnalysisOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;故障分析的输出状态。&quot;&quot;&quot;</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def get_failures(state):</span><br><span class="line">    &quot;&quot;&quot;获取包含故障的日志&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 从清理后的日志中筛选出包含 &quot;grade&quot; 键的日志，这些被视为故障</span><br><span class="line">    failures = [log for log in cleaned_logs if &quot;grade&quot; in log]</span><br><span class="line">    return &#123;&quot;failures&quot;: failures&#125;</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;生成故障摘要&quot;&quot;&quot;</span><br><span class="line">    failures = state[&quot;failures&quot;]</span><br><span class="line">    # 添加功能：fa_summary = summary_generation(qs_summary)</span><br><span class="line">    fa_summary = &quot;Chroma 文档的检索质量不佳。&quot;</span><br><span class="line">    # 为每个故障日志生成一个处理过的日志标识符</span><br><span class="line">    return &#123;&quot;fa_summary&quot;: fa_summary, &quot;processed_logs&quot;: [f&quot;failure-analysis-on-log-&#123;failure[&#x27;id&#x27;]&#125;&quot; for failure in failures]&#125;</span><br><span class="line"></span><br><span class="line">fa_builder = StateGraph(state_schema=FailureAnalysisState,output_schema=FailureAnalysisOutputState)</span><br><span class="line">fa_builder.add_node(&quot;get_failures&quot;, get_failures)</span><br><span class="line">fa_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">fa_builder.add_edge(START, &quot;get_failures&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;get_failures&quot;, &quot;generate_summary&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;generate_summary&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = fa_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723094949158.png" alt="image-20250723094949158"></p>
<p>这里是问题总结子图，它使用了 <code>QuestionSummarizationState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># 摘要生成子图</span><br><span class="line">class QuestionSummarizationState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于问题摘要的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    qs_summary: str         # 问题摘要</span><br><span class="line">    report: str             # 从摘要生成的报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class QuestionSummarizationOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;问题摘要的输出状态。&quot;&quot;&quot;</span><br><span class="line">    report: str             # 最终报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;从日志生成摘要。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 添加功能：summary = summarize(generate_summary)</span><br><span class="line">    summary = &quot;问题集中在 ChatOllama 和 Chroma 向量存储的使用上。&quot;</span><br><span class="line">    # 返回摘要以及已处理的日志ID</span><br><span class="line">    return &#123;&quot;qs_summary&quot;: summary, &quot;processed_logs&quot;: [f&quot;summary-on-log-&#123;log[&#x27;id&#x27;]&#125;&quot; for log in cleaned_logs]&#125;</span><br><span class="line"></span><br><span class="line">def send_to_slack(state):</span><br><span class="line">    &quot;&quot;&quot;模拟发送报告。&quot;&quot;&quot;</span><br><span class="line">    qs_summary = state[&quot;qs_summary&quot;]</span><br><span class="line">    # 添加功能：report = report_generation(qs_summary)</span><br><span class="line">    report = &quot;foo bar baz&quot;</span><br><span class="line">    return &#123;&quot;report&quot;: report&#125;</span><br><span class="line"></span><br><span class="line">qs_builder = StateGraph(QuestionSummarizationState,output_schema=QuestionSummarizationOutputState)</span><br><span class="line">qs_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">qs_builder.add_node(&quot;send_to_slack&quot;, send_to_slack)</span><br><span class="line">qs_builder.add_edge(START, &quot;generate_summary&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;generate_summary&quot;, &quot;send_to_slack&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;send_to_slack&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = qs_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723100648199.png" alt="image-20250723100648199"></p>
<h5 id="Adding-sub-graphs-to-our-parent-graph-向父图添加子图"><a href="#Adding-sub-graphs-to-our-parent-graph-向父图添加子图" class="headerlink" title="Adding sub graphs to our parent graph  向父图添加子图"></a><strong>Adding sub graphs to our parent graph </strong> <strong>向父图添加子图</strong></h5><p>现在，我们可以将所有内容整合在一起。我们使用 <code>EntryGraphState</code> 创建父图。并且我们将我们的子图添加为节点！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 入口图</span><br><span class="line">class EntryGraphState(TypedDict):</span><br><span class="line">    # 原始日志数据列表</span><br><span class="line">    raw_logs: List[Log]</span><br><span class="line">    # 经过清洗处理后的日志数据列表</span><br><span class="line">    cleaned_logs: List[Log]</span><br><span class="line">    fa_summary: str # 这只会在故障分析子图中生成</span><br><span class="line">    report: str # 这只会在问题摘要子图中生成</span><br><span class="line">    processed_logs:  Annotated[List[int], add] # 跟踪哪些日志已经被处理过 ，尤其是在子图之间共享状态时。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def clean_logs(state):</span><br><span class="line">    # 获取日志</span><br><span class="line">    raw_logs = state[&quot;raw_logs&quot;]</span><br><span class="line">    # 数据清洗 raw_logs -&gt; docs</span><br><span class="line">    cleaned_logs = raw_logs</span><br><span class="line">    return &#123;&quot;cleaned_logs&quot;: cleaned_logs&#125;</span><br><span class="line"></span><br><span class="line">entry_builder = StateGraph(EntryGraphState)</span><br><span class="line">entry_builder.add_node(&quot;clean_logs&quot;, clean_logs)</span><br><span class="line">#添加子图</span><br><span class="line">entry_builder.add_node(&quot;question_summarization&quot;, qs_builder.compile())</span><br><span class="line">entry_builder.add_node(&quot;failure_analysis&quot;, fa_builder.compile())</span><br><span class="line"></span><br><span class="line">entry_builder.add_edge(START, &quot;clean_logs&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;failure_analysis&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;question_summarization&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;failure_analysis&quot;, END)</span><br><span class="line">entry_builder.add_edge(&quot;question_summarization&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = entry_builder.compile()</span><br><span class="line"></span><br><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line"># 将 xray 设置为 1 将显示嵌套图的内部结构</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723102913524.png" alt="image-20250723102913524"></p>
<h4 id="Map-reduce"><a href="#Map-reduce" class="headerlink" title="Map-reduce"></a><strong>Map-reduce</strong></h4><p>LangGraph 里的 <strong>Map-Reduce</strong> 是一种<strong>并行处理模式</strong>，用于将一个大任务拆分成多个子任务（Map），再汇总结果（Reduce）。这是 LangGraph 中处理<strong>批量数据或并行节点执行</strong>的核心机制之一。</p>
<p>让我们设计一个系统，该系统将完成两件事情：</p>
<p>(1) <strong>映射（Map）</strong> —— 根据主题生成一组笑话。<br>(2) <strong>归约（Reduce）</strong> —— 从这组笑话中挑出最棒的一条。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"># Prompts we will use</span><br><span class="line">subjects_prompt = &quot;&quot;&quot;生成一个包含3个子主题的列表，这些子主题都与以下总体主题相关：&#123;topic&#125;。&quot;&quot;&quot;</span><br><span class="line">joke_prompt = &quot;&quot;&quot;生成一个关于&#123;subject&#125;的笑话&quot;&quot;&quot;</span><br><span class="line">best_joke_prompt = &quot;&quot;&quot;下面是关于&#123;topic&#125;的一堆笑话。选择最好的一个！返回最好笑话的ID，第一个笑话的ID从0开始。笑话：\n\n  &#123;jokes&#125;&quot;&quot;&quot;</span><br><span class="line"># LLM</span><br><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h5 id="Parallelizing-joke-generation-并行化笑话生成"><a href="#Parallelizing-joke-generation-并行化笑话生成" class="headerlink" title="Parallelizing joke generation 并行化笑话生成"></a><strong>Parallelizing joke generation</strong> <strong>并行化笑话生成</strong></h5><p>首先，让我们定义图的入口点，它将：</p>
<ul>
<li>接收用户输入的主题  </li>
<li>基于该主题生成若干“笑话子主题”  </li>
<li>将每个子主题发送到上面定义的笑话生成节点</li>
</ul>
<p>我们的状态有一个 <code>jokes</code> 键，它将累积来自并行化笑话生成的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Subjects(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示主题列表。&quot;&quot;&quot;</span><br><span class="line">    subjects: list[str] # 主题字符串列表</span><br><span class="line"></span><br><span class="line">class BestJoke(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示最佳笑话的ID。&quot;&quot;&quot;</span><br><span class="line">    id: int # 最佳笑话的索引ID</span><br><span class="line">    </span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;定义整个图的总体状态，使用TypedDict以便于类型提示和状态管理。&quot;&quot;&quot;</span><br><span class="line">    topic: str # 当前讨论的主题</span><br><span class="line">    subjects: list # 生成的子主题列表</span><br><span class="line">    jokes: Annotated[list, operator.add] # 笑话列表，使用operator.add表示列表内容会累加而不是覆盖</span><br><span class="line">    best_selected_joke: str # 最终选出的最佳笑话</span><br></pre></td></tr></table></figure>
<p>生成笑话的主题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#用于生成主题</span><br><span class="line">def generate_topics(state: OverallState):</span><br><span class="line">    #使用 Python 的 format() 方法来构建一个提示字符串（ prompt ）</span><br><span class="line">    prompt = subjects_prompt.format(topic=state[&quot;topic&quot;])</span><br><span class="line">    #.with_structured_output(Subjects) 它指示模型尝试将其输出格式化为 Subjects 类</span><br><span class="line">    response = model.with_structured_output(Subjects).invoke(prompt)</span><br><span class="line">    return &#123;&quot;subjects&quot;: response.subjects&#125;</span><br></pre></td></tr></table></figure>
<p>这就是妙处：我们利用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#send"><code>Send</code></a> 为每个主题并行生成笑话。</p>
<p>非常实用！无论主题数量多少，它都能自动并行处理。</p>
<ul>
<li><code>generate_joke</code>：图中节点的名字  </li>
<li><code>&#123;&quot;subject&quot;: s&#125;</code>：要传递的状态</li>
</ul>
<p><code>Send</code> 允许你向 <code>generate_joke</code> 节点发送<strong>任意</strong>结构的状态，无需与 <code>OverallState</code> 对齐。<br>在这里，<code>generate_joke</code> 使用自己的内部状态，我们通过 <code>Send</code> 按需填充即可。</p>
<blockquote>
<p>在 LangGraph 里，<code>Send</code> 是一个<strong>“动态派发器”</strong>：它让你<strong>在运行时</strong>决定“要把哪个节点运行多少次、每次给它什么数据”，并自动并行执行。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.types import Send</span><br><span class="line">def continue_to_jokes(state: OverallState):</span><br><span class="line">    # 该函数根据当前状态中的主题列表，为每个主题生成一个 Send 对象。</span><br><span class="line">    # 每个 Send 对象都指示图将数据发送到名为 &quot;generate_joke&quot; 的节点，</span><br><span class="line">    # 并将当前主题作为 &quot;subject&quot; 参数传递，从而实现并行生成笑话。</span><br><span class="line">    return [Send(&quot;generate_joke&quot;, &#123;&quot;subject&quot;: s&#125;) for s in state[&quot;subjects&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="Joke-generation-map-笑话生成"><a href="#Joke-generation-map-笑话生成" class="headerlink" title="Joke generation (map) 笑话生成"></a><strong>Joke generation (map)</strong> <strong>笑话生成</strong></h5><p>现在，我们只需定义一个节点来生成笑话，命名为 <code>generate_joke</code>！</p>
<p>生成的笑话会被写回到 <code>OverallState</code> 中的 <code>jokes</code> 字段。<br>该字段配有 reducer，能够自动把多次写入的列表合并成一个大列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 定义 JokeState，用于表示生成笑话任务的输入状态。</span><br><span class="line">class JokeState(TypedDict):</span><br><span class="line">    subject: str#笑话的主题</span><br><span class="line"></span><br><span class="line"># 定义 Joke 模型，用于表示模型生成的笑话的结构。</span><br><span class="line">class Joke(BaseModel):</span><br><span class="line">    joke: str#笑话的文本内容</span><br><span class="line"></span><br><span class="line"># 定义生成笑话的函数。</span><br><span class="line">def generate_joke(state: JokeState):</span><br><span class="line">    # 根据 joke_prompt 模板和当前状态中的主题格式化提示。</span><br><span class="line">    prompt = joke_prompt.format(subject=state[&quot;subject&quot;])</span><br><span class="line">    # 调用语言模型，并指定输出应结构化为 Joke 类型。</span><br><span class="line">    response = model.with_structured_output(Joke).invoke(prompt)</span><br><span class="line">    # 返回一个包含生成的笑话的字典，键为 &quot;jokes&quot;。</span><br><span class="line">    return &#123;&quot;jokes&quot;: [response.joke]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Best-joke-selection-reduce-最佳笑话选择"><a href="#Best-joke-selection-reduce-最佳笑话选择" class="headerlink" title="Best joke selection (reduce) 最佳笑话选择"></a><strong>Best joke selection (reduce)</strong> <strong>最佳笑话选择</strong></h5><p>现在，我们添加逻辑来挑选最好的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def best_joke(state: OverallState):</span><br><span class="line">    # 将状态中所有笑话列表连接成一个字符串，每个笑话之间用两个换行符分隔</span><br><span class="line">    jokes = &quot;\n\n&quot;.join(state[&quot;jokes&quot;])</span><br><span class="line">    # 使用主题和所有笑话格式化最佳笑话提示语</span><br><span class="line">    prompt = best_joke_prompt.format(topic=state[&quot;topic&quot;], jokes=jokes)</span><br><span class="line">    # 调用模型，期望其输出符合 BestJoke 结构（包含最佳笑话的ID）</span><br><span class="line">    response = model.with_structured_output(BestJoke).invoke(prompt)</span><br><span class="line">    # 根据模型返回的ID，从笑话列表中选择最佳笑话，并将其存储在状态的 best_selected_joke 字段中</span><br><span class="line">    return &#123;&quot;best_selected_joke&quot;: state[&quot;jokes&quot;][response.id]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Compile-编译"><a href="#Compile-编译" class="headerlink" title="Compile 编译"></a><strong>Compile</strong> 编译</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image</span><br><span class="line">from langgraph.graph import END, StateGraph, START</span><br><span class="line"></span><br><span class="line"># 构建图：将所有组件组合在一起构建我们的流程图</span><br><span class="line">graph = StateGraph(OverallState)</span><br><span class="line"></span><br><span class="line">graph.add_node(&quot;generate_topics&quot;, generate_topics)</span><br><span class="line">graph.add_node(&quot;generate_joke&quot;, generate_joke)</span><br><span class="line">graph.add_node(&quot;best_joke&quot;, best_joke)</span><br><span class="line"></span><br><span class="line">graph.add_edge(START, &quot;generate_topics&quot;)</span><br><span class="line"># 根据条件决定是否继续生成笑话</span><br><span class="line">graph.add_conditional_edges(&quot;generate_topics&quot;, continue_to_jokes, [&quot;generate_joke&quot;])</span><br><span class="line"># 生成笑话后执行选择最佳笑话</span><br><span class="line">graph.add_edge(&quot;generate_joke&quot;, &quot;best_joke&quot;)</span><br><span class="line"># 选择最佳笑话后流程结束</span><br><span class="line">graph.add_edge(&quot;best_joke&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = graph.compile()</span><br><span class="line">Image(app.get_graph().draw_mermaid_png())</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723112736244.png" alt="image-20250723112736244"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for s in app.stream(&#123;&quot;topic&quot;: &quot;日本广岛原子弹&quot;&#125;):</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;generate_topics&#x27;: &#123;&#x27;subjects&#x27;: [&#x27;原子弹投放的历史背景与决策过程&#x27;, &#x27;广岛原爆对城市与居民的影响&#x27;, &#x27;战后和平运动与核裁军倡议&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;战后和平运动的人开会讨论核裁军，一个人站起来说：‘我们必须彻底销毁所有核武器！’ 另一个人犹豫地举手：‘那……我们保留一个吧，就一个，藏在冰箱后面，以防万一。’&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&quot;杜鲁门宣布要结束战争，顾问问是否要使用原子弹。罗斯福的棺材板突然震动了一下，丘吉尔的雪茄掉在了地上，斯大林则默默拿起了电话：&#x27;同志，我们的计划可能需要再推迟一下。&#x27;&quot;]&#125;&#125;</span><br><span class="line">&#123;&#x27;best_joke&#x27;: &#123;&#x27;best_selected_joke&#x27;: &#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Research Assistant</strong> <strong>研究助理</strong></p>
<p>见另一篇文章</p>
<h3 id="module-5"><a href="#module-5" class="headerlink" title="module-5"></a>module-5</h3><h4 id="Chatbot-with-Memory-带有记忆功能的聊天机器人"><a href="#Chatbot-with-Memory-带有记忆功能的聊天机器人" class="headerlink" title="Chatbot with Memory 带有记忆功能的聊天机器人"></a><strong>Chatbot with Memory</strong> <strong>带有记忆功能的聊天机器人</strong></h4><p>在这里，我们将介绍 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Memory Store</a> 作为一种保存和检索长期记忆的方法。</p>
<blockquote>
<p>LangGraph Memory Store 是 <strong>LangGraph 提供的长期记忆存储接口</strong>，用于在 <strong>不同对话线程之间</strong> 持久化保存和检索用户信息。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>名称</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BaseStore</strong></td>
<td>抽象接口，定义了 <code>put/get/search/delete</code> 等操作方法</td>
</tr>
<tr>
<td><strong>InMemoryStore</strong></td>
<td>内存实现，适合原型验证</td>
</tr>
<tr>
<td><strong>RedisStore / AsyncRedisStore</strong></td>
<td>生产级实现，支持向量搜索、元数据过滤和命名空间管理</td>
</tr>
</tbody>
</table>
</div>
</blockquote>
<p>我们将构建一个使用 <code>short-term (within-thread仅当前对话线程)</code> 和 <code>long-term (across-thread跨所有对话线程    )</code> 内存的聊天机器人。</p>
<p>我们将重点关注长期 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory">semantic memory<strong>（语义记忆）</strong></a>，它将包含关于用户的事实信息。这些长期记忆将被用于创建一个个性化的聊天机器人，它可以记住有关用户的事实。</p>
<p>它将节省内存 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories">“in the hot path”</a>，当用户与之聊天时。</p>
<blockquote>
<p><strong>“in the hot path”</strong> 指的是：<strong>在对话或任务执行的</strong>主流程中<strong>（即用户输入后立即、同步地）</strong>主动调用工具或写入记忆，使信息<strong>实时生效</strong>并可用于下一步决策。</p>
</blockquote>
<h5 id="Introduction-to-the-LangGraph-Store-LangGraph-存储简介"><a href="#Introduction-to-the-LangGraph-Store-LangGraph-存储简介" class="headerlink" title="Introduction to the LangGraph Store LangGraph 存储简介"></a><strong>Introduction to the LangGraph Store</strong> <strong>LangGraph 存储简介</strong></h5><p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Memory Store</a> 提供了一种在 LangGraph 中 <strong>跨线程</strong> 存储和检索信息的方式。这是一个用于持久化 <code>key-value</code> 存储的 <a target="_blank" rel="noopener" href="https://blog.langchain.dev/launching-long-term-memory-support-in-langgraph/">开源基类</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line">in_memory_store = InMemoryStore()</span><br></pre></td></tr></table></figure>
<p>在 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">Store</a> 中存储对象（例如，记忆）时，我们提供：</p>
<p>- 对象的 <code>namespace</code>（类似于目录的元组）</p>
<p>- 对象的 <code>key</code>（类似于文件名）</p>
<p>- 对象的 <code>value</code>（类似于文件内容）</p>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a> 方法通过 <code>namespace</code> 和 <code>key</code> 将对象保存到存储中。</p>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725155616205-1753430177489-3.png" alt="image-20250725155616205"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;  # 用户ID</span><br><span class="line">namespace_for_memory = (user_id, &quot;memories&quot;)  # 记忆命名空间</span><br><span class="line"></span><br><span class="line"># 生成一个唯一的键值</span><br><span class="line">key = str(uuid.uuid4())  # 使用UUID创建唯一标识符作为键</span><br><span class="line"></span><br><span class="line"># 值需要是一个字典格式</span><br><span class="line">value = &#123;&quot;food_preference&quot;: &quot;我喜欢披萨&quot;&#125;  # 存储的食物偏好信息</span><br><span class="line"></span><br><span class="line"># 保存记忆</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)  # 将记忆存储到内存中</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a> 通过 <code>namespace</code> 从存储中检索对象。这将返回一个列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">memories = in_memory_store.search(namespace_for_memory)</span><br><span class="line">type(memories)</span><br><span class="line"></span><br><span class="line"># Metatdata </span><br><span class="line">memories[0].dict()</span><br><span class="line"></span><br><span class="line"># The key, value</span><br><span class="line">print(memories[0].key, memories[0].value)</span><br><span class="line">9e65de8a-f404-4974-b509-0df0566d8fb5 &#123;&#x27;food_preference&#x27;: &#x27;我喜欢披萨&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a> 通过 <code>namespace</code> 和 <code>key</code> 检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Get the memory by namespace and key</span><br><span class="line">memory = in_memory_store.get(namespace_for_memory, key)</span><br><span class="line">memory.dict()</span><br></pre></td></tr></table></figure>
<h5 id="Chatbot-with-long-term-memory-具有长期记忆的聊天机器人"><a href="#Chatbot-with-long-term-memory-具有长期记忆的聊天机器人" class="headerlink" title="Chatbot with long-term memory 具有长期记忆的聊天机器人"></a><strong>Chatbot with long-term memory</strong> <strong>具有长期记忆的聊天机器人</strong></h5><p>我们想要一个聊天机器人，<a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_156">有两种记忆的方式</a>:</p>
<ol>
<li><code>Short-term (within-thread) memory</code>: 聊天机器人可以保留会话历史记录和/或允许在聊天会话中进行中断。  </li>
<li><code>Long-term (cross-thread) memory</code>: 聊天机器人可以记住特定用户在所有聊天会话中的信息 <strong>跨会话</strong>。</li>
</ol>
<p>对于 <code>short-term memory</code>，我们将使用一个 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries">checkpointer</a>。</p>
<ul>
<li>他们在每一步都将图状态写入线程中。</li>
<li>他们在该线程中持久化保存聊天历史记录。</li>
<li>他们允许图在该线程中的任何步骤被中断和/或恢复。</li>
</ul>
<p>对于 <code>long-term memory</code>，我们将使用上面介绍的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的有用助手，能够提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;&quot;你正在收集用户信息以个性化你的回复。</span><br><span class="line"></span><br><span class="line">当前用户信息：</span><br><span class="line">&#123;memory&#125;</span><br><span class="line"></span><br><span class="line">指令：</span><br><span class="line">1. 仔细查看下面的聊天历史</span><br><span class="line">2. 识别有关用户的新信息，例如：</span><br><span class="line">   - 个人详情（姓名、位置）</span><br><span class="line">   - 偏好（喜欢、不喜欢）</span><br><span class="line">   - 兴趣和爱好</span><br><span class="line">   - 过去的经历</span><br><span class="line">   - 目标或未来计划</span><br><span class="line">3. 将任何新信息与现有记忆合并</span><br><span class="line">4. 将记忆格式化为清晰的项目符号列表</span><br><span class="line">5. 如果新信息与现有记忆冲突，请保留最新版本</span><br><span class="line"></span><br><span class="line">记住：只包括用户直接陈述的事实信息。不要做假设或推断。</span><br><span class="line"></span><br><span class="line">基于以下聊天历史，请更新用户信息：&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    existing_memory = store.get(namespace, key)</span><br><span class="line"></span><br><span class="line">    # 如果存在则提取实际的记忆内容并添加前缀</span><br><span class="line">    if existing_memory:</span><br><span class="line">        # 值是一个带有memory键的字典</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)</span><br><span class="line">    </span><br><span class="line">    # 使用记忆以及聊天历史进行回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">        </span><br><span class="line">    # 提取记忆</span><br><span class="line">    if existing_memory:</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)</span><br><span class="line">    new_memory = model.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖存储中的现有记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line"></span><br><span class="line">    # 将值写入为带有memory键的字典</span><br><span class="line">    store.put(namespace, key, &#123;&quot;memory&quot;: new_memory.content&#125;)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于跨线程的长期记忆存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于线程内的短期记忆检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点器和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725161106319.png" alt="image-20250725161106319"></p>
<p>聊天历史将通过检查点工具保存到短期记忆中。聊天机器人将回顾聊天历史。然后，它将创建并保存一个记忆到 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a>。此内存可在未来的聊天会话中访问，以个性化聊天机器人的响应。</p>
<p>当我们与聊天机器人交互时，我们提供两样东西：</p>
<ol>
<li><code>Short-term (within-thread) memory</code>: 一个用于持久化聊天历史的 <code>thread ID</code>。  </li>
<li><code>Long-term (cross-thread) memory</code>: 一个用于将长期记忆命名空间到用户的 <code>user ID</code>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br><span class="line">    </span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，我的名字是Lance</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，Lance！很高兴认识你。有什么我可以帮你的吗？😊</span><br></pre></td></tr></table></figure>
<p>我们正在使用 <code>MemorySaver</code> 检查点来管理线程内内存。这会将聊天历史保存到线程中。我们可以查看保存到线程的聊天历史记录。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">state = graph.get_state(thread).values</span><br><span class="line">for m in state[&quot;messages&quot;]: </span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>回想一下，我们使用存储库编译了该图：<code>across_thread_memory = InMemoryStore()</code>并且，我们向图中添加了一个节点 (<code>write_memory</code>)，该节点反映了聊天历史并保存了一段记忆到存储中。</p>
<p>我们可以查看内存是否已保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.dict()</span><br><span class="line"></span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;memory&#x27;, &#x27;1&#x27;],</span><br><span class="line"> &#x27;key&#x27;: &#x27;user_memory&#x27;,</span><br><span class="line"> &#x27;value&#x27;: &#123;&#x27;memory&#x27;: &#x27;- 姓名：Lance  \n- 位置：旧金山  \n- 兴趣和爱好：骑自行车  \n- 喜欢的活动：在旧金山骑行，可能包括金门大桥和滨海区路线&#x27;&#125;,</span><br><span class="line"> &#x27;created_at&#x27;: &#x27;2025-07-25T08:12:35.877160+00:00&#x27;,</span><br><span class="line"> &#x27;updated_at&#x27;: &#x27;2025-07-25T08:12:35.877161+00:00&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>现在，让我们以 <strong>相同的用户ID</strong>启动一个<strong>新线程</strong>。我们应该看到聊天机器人记住了用户的个人资料，并将其用于个性化响应。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供用户ID用于跨线程记忆以及一个新的线程ID</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好！你推荐我去哪里骑自行车？&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-Profile-Schema-带有配置文件模式的聊天机器人"><a href="#Chatbot-with-Profile-Schema-带有配置文件模式的聊天机器人" class="headerlink" title="Chatbot with Profile Schema 带有配置文件模式的聊天机器人"></a><strong>Chatbot with Profile Schema</strong> <strong>带有配置文件模式的聊天机器人</strong></h4><p>我们的聊天机器人将记忆保存为字符串。在实践中，我们通常希望记忆具有结构化格式。例如，记忆可以是<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">单个、持续更新的模式 </a>。在我们的案例中，我们希望这是一个单一的用户档案。</p>
<p>我们将扩展我们的聊天机器人，将语义记忆保存到单个<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">用户档案 </a>中。我们还将介绍一个库 <a target="_blank" rel="noopener" href="https://github.com/hinthornw/trustcall">Trustcall</a>，用于使用新信息更新此模式。</p>
<h5 id="Defining-a-user-profile-schema-定义用户配置文件模式"><a href="#Defining-a-user-profile-schema-定义用户配置文件模式" class="headerlink" title="Defining a user profile schema 定义用户配置文件模式"></a><strong>Defining a user profile schema</strong> <strong>定义用户配置文件模式</strong></h5><p>Python 有许多不同类型的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition">structured data</a>，例如 TypedDict、字典、JSON 和 <a target="_blank" rel="noopener" href="https://docs.pydantic.dev/latest/">Pydantic</a>。</p>
<p>让我们先使用 TypedDict 来定义一个用户资料模式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from typing import TypedDict, List</span><br><span class="line"></span><br><span class="line">class UserProfile(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;带有类型字段的用户档案模式&quot;&quot;&quot;</span><br><span class="line">    user_name: str  # 用户的首选名称</span><br><span class="line">    interests: List[str]  # 用户兴趣列表</span><br></pre></td></tr></table></figure>
<h5 id="Saving-a-schema-to-the-store-将模式保存到存储中"><a href="#Saving-a-schema-to-the-store-将模式保存到存储中" class="headerlink" title="Saving a schema to the store 将模式保存到存储中"></a><strong>Saving a schema to the store</strong> <strong>将模式保存到存储中</strong></h5><p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a> 接受任何 Python 字典作为 <code>value</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># TypedDict 实例</span><br><span class="line">user_profile: UserProfile = &#123;</span><br><span class="line">    &quot;user_name&quot;: &quot;Lance&quot;,  # 用户名</span><br><span class="line">    &quot;interests&quot;: [&quot;骑行&quot;, &quot;科技&quot;, &quot;咖啡&quot;]  # 兴趣爱好</span><br><span class="line">&#125;</span><br><span class="line">user_profile</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a> 方法将 TypedDict 保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line"></span><br><span class="line"># 初始化内存存储</span><br><span class="line">in_memory_store = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 为要保存的记忆创建命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace_for_memory = (user_id, &quot;memory&quot;)</span><br><span class="line"></span><br><span class="line"># 将记忆以键值对的形式保存到命名空间中</span><br><span class="line">key = &quot;user_profile&quot;</span><br><span class="line">value = user_profile</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a> 按命名空间从存储中检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for m in in_memory_store.search(namespace_for_memory):</span><br><span class="line">    print(m.dict())</span><br><span class="line">    </span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;1&#x27;, &#x27;memory&#x27;], &#x27;key&#x27;: &#x27;user_profile&#x27;, &#x27;value&#x27;: &#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;, &#x27;created_at&#x27;: &#x27;2025-07-25T08:58:06.031770+00:00&#x27;, &#x27;updated_at&#x27;: &#x27;2025-07-25T08:58:06.031775+00:00&#x27;, &#x27;score&#x27;: None&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a> 通过命名空间和键来检索特定对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">profile = in_memory_store.get(namespace_for_memory, &quot;user_profile&quot;)</span><br><span class="line">profile.value</span><br><span class="line"></span><br><span class="line">&#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Chatbot-with-profile-schema-带有配置文件模式的聊天机器人"><a href="#Chatbot-with-profile-schema-带有配置文件模式的聊天机器人" class="headerlink" title="Chatbot with profile schema 带有配置文件模式的聊天机器人"></a><strong>Chatbot with profile schema</strong> <strong>带有配置文件模式的聊天机器人</strong></h5><p>现在我们知道了如何为记忆指定一个模式，并将其保存到存储中。现在，我们如何根据这个特定的模式 <strong>创建</strong> 记忆？</p>
<p>在我们的聊天机器人中，我们 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">想要从一个聊天里创建记忆</a>.这就是 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">structured outputs格式化输出</a> 概念有用的地方。</p>
<p>LangChain 的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/chat_models/">chat model</a> 接口有一个 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">PROTECTED$11$</a> 方法用于强制结构化输出。这在我们需要确保输出符合某个模式时非常有用，而且它会为我们解析输出。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 将模式绑定到模型</span><br><span class="line">model_with_structure = model.with_structured_output(UserProfile)</span><br><span class="line"></span><br><span class="line"># 调用模型生成符合模式的结构化输出</span><br><span class="line">structured_output = model_with_structure.invoke([HumanMessage(&quot;我的名字是Lance，我喜欢骑自行车。&quot;)])</span><br><span class="line">structured_output</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Structured outputs（结构化输出）<br>指让大模型<strong>不再“随意说人话”</strong>，而是<strong>按你事先定义好的格式（JSON / 表格 / 枚举 / 嵌套对象等）精确返回数据</strong>。相当于给模型套了一个“模具”，保证输出可直接被代码解析、入库或传给下游系统，避免再用正则、字符串拼接去“猜”结果。</p>
<p>使用官方的大模型组件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">model=ChatTongyi(</span><br><span class="line">    model=&quot;qwen-plus-2025-07-14&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>现在，让我们在聊天机器人中使用它。这只需要对 <code>write_memory</code> 函数进行轻微修改。我们使用 <code>model_with_structure</code>，如上所述，来生成一个与我们模式匹配的配置文件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage, AIMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的 helpful 助手，可以提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;根据用户的聊天历史创建或更新用户档案记忆。</span><br><span class="line">这将被保存为长期记忆。如果存在现有记忆，只需更新它。</span><br><span class="line">以下是现有记忆（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 使用记忆以及聊天历史来回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line">        </span><br><span class="line">    # 在指令中格式化现有记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 调用模型生成符合模式的结构化输出</span><br><span class="line">    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖现有的用户档案记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    store.put(namespace, key, new_memory)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于长期（跨线程）记忆的存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于短期（线程内）记忆的检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250726103516996.png" alt="image-20250726103516996"></p>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance，我喜欢在旧金山骑自行车和在面包店吃饭。&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>查看记忆</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Namespace for the memory to save</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.value</span><br></pre></td></tr></table></figure>
<h5 id="Trustcall-for-creating-and-updating-profile-schemas-Trustcall-用于创建和更新配置文件模式"><a href="#Trustcall-for-creating-and-updating-profile-schemas-Trustcall-用于创建和更新配置文件模式" class="headerlink" title="Trustcall for creating and updating profile schemas Trustcall 用于创建和更新配置文件模式"></a><strong>Trustcall for creating and updating profile schemas</strong> <strong>Trustcall 用于创建和更新配置文件模式</strong></h5><p>Trustcall 是一个由 LangChain 团队开发的开源 Python 库，旨在<strong>解决大型语言模型（LLM）在生成或修改复杂 JSON 数据结构时效率低、易出错的问题</strong>。</p>
<p>我们使用 <code>create_extractor</code>，传入模型以及我们的模式作为 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/tools/">tool</a>。使用 TrustCall 时，可以以多种方式提供模式。</p>
<p>例如，我们可以传递一个 JSON 对象 / Python 字典或 Pydantic 模型。在底层，TrustCall 使用 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/tool_calling/">tool calling</a> 从输入的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/messages/">messages</a> 列表中生成 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/">structured output</a>。为了强制 Trustcall 生成 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/">structured output</a>，我们可以在 <code>tool_choice</code> 参数中包含模式名称。</p>
<p>我仅做了解了，感觉用处不多，用结果化输出就能达到效果</p>
<h4 id="Chatbot-with-Collection-Schema-带集合模式的聊天机器人"><a href="#Chatbot-with-Collection-Schema-带集合模式的聊天机器人" class="headerlink" title="Chatbot with Collection Schema 带集合模式的聊天机器人"></a><strong>Chatbot with Collection Schema</strong> <strong>带集合模式的聊天机器人</strong></h4><p><strong>“collection”</strong> 指的是一种<strong>将语义记忆组织为多个独立文档（objects）的存储方式</strong>，而不是把所有信息都塞进一个巨大的“用户档案”（single profile）里。</p>
<p>假设你在做一个 AI 助手，用户说：</p>
<blockquote>
<p>“我下周要去东京出差，住在涩谷区的 Sakura Hotel。”<br>“我朋友 Ken 也要来，他喜欢吃拉面。”</p>
</blockquote>
<p>如果用 <strong>collection</strong>，你会存成两条记忆：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trip&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;destination&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Tokyo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2025-08-04&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hotel&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Sakura Hotel, Shibuya&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;friend&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Ken&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;food_preference&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ramen&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<p>每条记忆都是一个独立文档，后续你可以：</p>
<ul>
<li>搜索“trip”类型的记忆，找到用户的出差安排；</li>
<li>搜索“friend”类型的记忆，找到 Ken 的偏好；</li>
<li>更新 Ken 的信息时，<strong>只改一条记录</strong>，不会影响其它记忆。</li>
</ul>
<h4 id="Memory-Agent-内存代理"><a href="#Memory-Agent-内存代理" class="headerlink" title="Memory Agent 内存代理"></a><strong>Memory Agent</strong> <strong>内存代理</strong></h4><p>现在，我们将把学到的内容整合起来，构建一个具有长期记忆的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/">agent</a>。</p>
<p>我们的代理 <code>task_mAIstro</code> 将帮助我们管理待办事项列表！</p>
<p>我们之前构建的聊天机器人 <strong>始终</strong> 会反思对话并保存记忆。<code>task_mAIstro</code> 将决定 <strong>何时</strong> 保存记忆（待办事项列表中的项目）。</p>
<p>我们之前构建的聊天机器人始终保存一种类型的记忆，即个人资料或集合。<code>task_mAIstro</code> 可以决定将数据保存到用户个人资料或 ToDo 事项集合中。</p>
<p>除此之外，<code>task_mAIstro</code> 还将管理程序性记忆。这允许用户更新创建ToDo项的偏好设置。</p>
<h5 id="Creating-an-agent-创建一个代理"><a href="#Creating-an-agent-创建一个代理" class="headerlink" title="Creating an agent 创建一个代理"></a><strong>Creating an agent</strong> <strong>创建一个代理</strong></h5><p>有许多不同的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/high_level/">agent</a> 架构可供选择。在这里，我们将实现一个简单的内容，一个 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation">ReAct</a> 代理。这个代理将成为创建和管理待办事项列表的得力助手。</p>
<p>此代理可以决定更新三种类型的长期记忆：</p>
<p>(a) 创建或更新具有普通用户信息的用户 <code>profile</code></p>
<p>(b) 在ToDo列表中添加或更新项目 <code>collection</code></p>
<p>(c) 更新其自身的 <code>instructions</code> 以了解如何更新待办事项列表中的项目</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from typing import TypedDict, Literal</span><br><span class="line"></span><br><span class="line"># 更新记忆工具</span><br><span class="line">class UpdateMemory(TypedDict):</span><br><span class="line">    &quot;&quot;&quot; 决定更新哪种记忆类型 &quot;&quot;&quot;</span><br><span class="line">    update_type: Literal[&#x27;user&#x27;, &#x27;todo&#x27;, &#x27;instructions&#x27;]</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><code>&#39;user&#39;</code>：用户相关信息</li>
<li><code>&#39;todo&#39;</code>：待办事项</li>
<li><code>&#39;instructions&#39;</code>：指令信息</li>
</ul>
</blockquote>
<h5 id="Graph-definition-图定义"><a href="#Graph-definition-图定义" class="headerlink" title="Graph definition 图定义"></a><strong>Graph definition</strong> <strong>图定义</strong></h5><p>我们添加了一个简单的路由器 <code>route_message</code>，它通过二元决策来节省内存。</p>
<h3 id="module-6"><a href="#module-6" class="headerlink" title="module-6"></a>module-6</h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/21/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/Retrieval/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/21/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/Retrieval/" class="post-title-link" itemprop="url">Retrieval</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-21 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-21T00:00:00+08:00">2025-07-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-05 10:41:56" itemprop="dateModified" datetime="2025-08-05T10:41:56+08:00">2025-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">实习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/" itemprop="url" rel="index"><span itemprop="name">晨晟智控</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="elastic-search"><a href="#elastic-search" class="headerlink" title="elastic search"></a>elastic search</h3><p>Elasticsearch 是当今最流行的 <strong>开源分布式搜索与分析引擎</strong>，用 Java 开发，基于 <strong>Apache Lucene</strong> 构建。它把<strong>全文检索、实时分析、时序数据、地理空间查询</strong>和<strong>向量检索</strong>统一到一个平台，被广泛用于日志、指标、安全、企业搜索以及 AI/RAG 场景。</p>
<p> RAG 系统中，<strong>Elasticsearch 不仅是向量数据库，更是语义检索引擎和上下文构建器</strong>，更准确地说，是<strong>向量数据库 + 全文检索引擎</strong>的混合角色。</p>
<h4 id="查找语句"><a href="#查找语句" class="headerlink" title="查找语句"></a>查找语句</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">GET /test_full_v1/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;高压旁路管道磁粉检测使用的是哪种磁化方法和磁悬液浓度？&quot;,</span><br><span class="line">      &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;,&quot;report_url&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices?v#查看所有的所有</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_count#查看文件数</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_mapping#查看映射</span><br><span class="line"></span><br><span class="line">GET test_full_v1#查看索引内容</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_search#查看索引内容</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 3,</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices/zxj_test#查看索引是否存在</span><br></pre></td></tr></table></figure>
<p>可视化平台kibana的内网路径：</p>
<ul>
<li><code>http://10.117.128.50:5601</code></li>
<li><a target="_blank" rel="noopener" href="http://10.117.128.50:5601/app/dev_tools#/console/shell">http://10.117.128.50:5601/app/dev_tools#/console/shell</a> 开发者工具</li>
</ul>
<h4 id="es支持的几种检索函数"><a href="#es支持的几种检索函数" class="headerlink" title="es支持的几种检索函数"></a>es支持的几种检索函数</h4><h5 id="向量搜索"><a href="#向量搜索" class="headerlink" title="向量搜索"></a>向量搜索</h5><p>这里的向量搜索也就是稠密向量检索，过程为<strong>“把文本/图像等非结构化数据映射成高维向量 → 在向量空间里做近似最近邻（ANN）搜索 → 按相似度排序返回结果”</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def vector_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建Elasticsearch KNN查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;knn&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: dense_vector_field,      # 指定存储向量的字段名</span><br><span class="line">            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">            &quot;k&quot;: 5,                          # 返回最相似的5个结果</span><br><span class="line">            &quot;num_candidates&quot;: 10,            # 在10个候选中选择最优的5个（提高搜索效率和准确性）</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="bm25"><a href="#bm25" class="headerlink" title="bm25"></a>bm25</h5><p>BM25（<strong>Best Matching 25</strong>）也就是全文关键词搜索，或者叫传统关键词搜索，他的核心思想为<strong>“词频越高、文档越短、词越稀有，则相关性越高”</strong>，在 TF-IDF 的基础上引入词频饱和、文档长度归一化两项修正。</p>
<blockquote>
<p>TF-IDF（<strong>Term Frequency–Inverse Document Frequency，词频-逆文档频率</strong>）是一种经典的 <strong>文本特征权重计算方法</strong>，用于衡量 <strong>一个词对一篇文档的重要性</strong>。</p>
</blockquote>
<p>项目中的bm25检索采取多字段匹配的方式，还有几个参数需要了解，如下</p>
<ol>
<li><p><strong>‘type’</strong> :决定了<strong>如何把多个字段的 BM25 打分合并成最终得分</strong>,常用的参数有以下三种</p>
<p>| type                    | 中文含义     | 打分逻辑                                                     |<br>| :——————————— | :—————- | :—————————————————————————————- |<br>| <strong>best_fields</strong>（默认） | 最佳字段优先 | 取 <strong>得分最高的那个字段</strong> 做最终分（可用 <code>tie_breaker</code> 让次佳字段再贡献一点点）。 |<br>| <strong>most_fields</strong>         | 最多字段优先 | 把所有命中字段的得分 <strong>直接相加</strong>（类似 OR 逻辑），字段越多分越高。 |<br>| <strong>cross_fields</strong>        | 跨字段合并   | 把多个字段视为 <strong>一个虚拟大字段</strong>，统一计算 TF 和 IDF，解决“关键词分散在不同字段”问题。 |</p>
</li>
<li><p><strong><code>&#39;tie_breaker&#39;</code></strong>：当多个字段都匹配时，<strong>“最佳字段”得分 + 其余字段得分×tie_breaker</strong> 作为最终得分。</p>
</li>
<li><strong><code>&#39;operator&#39;</code></strong>:控制<strong>单个字段内</strong>的多个词项是“AND”还是“OR”关系。<ul>
<li><strong><code>&quot;AND&quot;</code></strong><br>要求<strong>同一个字段</strong>必须同时包含所有查询词，减少噪音，提高精准度。适合地址、姓名等跨字段严格匹配。</li>
<li><strong><code>&quot;OR&quot;</code></strong><br>只要字段里出现任意一个词就匹配，召回量大，但可能引入不相关结果。</li>
</ul>
</li>
</ol>
<p>最后，每个字段还可以人工设置权重，如<code>&quot;fields&quot;: [&quot;title^3&quot;, &quot;content&quot;, &quot;tags^2&quot;]</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def bm25_query(search_query: str):</span><br><span class="line">    # 使用BM25算法进行传统关键词匹配</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            &quot;multi_match&quot;: &#123;  # 多字段匹配查询</span><br><span class="line">                &quot;query&quot;: search_query,</span><br><span class="line">                &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;size&quot;: 8,  # 返回最多8个结果</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="混合检索"><a href="#混合检索" class="headerlink" title="混合检索"></a>混合检索</h5><p>混合检索也就是 <a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html">Reciprocal Rank Fusion</a>（RRF），通过结合向量搜索和 BM25 搜索的结果综合判断。</p>
<p>但由于es中混合检索需要付费使用，后续检索效果评估时不做测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">def hybrid_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建混合搜索查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;retriever&quot;: &#123;</span><br><span class="line">            # 使用RRF (Reciprocal Rank Fusion) 算法融合多个检索器的结果</span><br><span class="line">            &quot;rrf&quot;: &#123;</span><br><span class="line">                # 定义多个检索器列表</span><br><span class="line">                &quot;retrievers&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第一个检索器：多字段BM25关键词搜索</span><br><span class="line">                        &quot;standard&quot;: &#123;</span><br><span class="line">                            &quot;query&quot;: &#123;</span><br><span class="line">                                # 使用multi_match在多个字段上进行BM25搜索</span><br><span class="line">                                &quot;multi_match&quot;: &#123;</span><br><span class="line">                                    &quot;query&quot;: search_query,</span><br><span class="line">                                    &quot;type&quot;: &quot;best_fields&quot;,      # 选择最佳匹配字段</span><br><span class="line">                                    &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第二个检索器：KNN向量近似搜索</span><br><span class="line">                        &quot;knn&quot;: &#123;</span><br><span class="line">                            &quot;field&quot;: dense_vector_field,      # 向量字段名（使用定义的变量）</span><br><span class="line">                            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">                            &quot;k&quot;: 5,                          # 返回5个最相似的向量结果</span><br><span class="line">                            &quot;num_candidates&quot;: 10,            # 候选向量数量，用于提高搜索准确性</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="模糊检索"><a href="#模糊检索" class="headerlink" title="模糊检索"></a>模糊检索</h5><p>无论是在网页搜索、文件检索，还是数据库查询中，我们时常会因为拼写错误或信息不完整而无法找到需要的结果。<strong>模糊搜索</strong>（Fuzzy Search）应运而生，它通过识别与查询相似的词语来帮助我们获得更加灵活的搜索结果。</p>
<p>这里是将bm25与模糊搜索结合起来</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">def fuzzy_query(search_query: str):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    创建模糊搜索查询函数，支持拼写错误和近似匹配</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        search_query (str): 用户输入的搜索查询文本</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        Dict: Elasticsearch模糊搜索查询体</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            # 使用match查询进行文本匹配</span><br><span class="line">            &quot;match&quot;: &#123;</span><br><span class="line">                # 在指定的文本字段中进行搜索</span><br><span class="line">                text_field: &#123;</span><br><span class="line">                    &quot;query&quot;: search_query,        # 用户的搜索查询文本</span><br><span class="line">                    &quot;fuzziness&quot;: &quot;AUTO&quot;,          # 自动模糊匹配设置</span><br><span class="line">                    # fuzziness参数说明：</span><br><span class="line">                    # - &quot;AUTO&quot;：根据词长度自动调整模糊度</span><br><span class="line">                    #   - 0-2个字符：不允许错误</span><br><span class="line">                    #   - 3-5个字符：允许1个编辑距离错误</span><br><span class="line">                    #   - 5个以上字符：允许2个编辑距离错误</span><br><span class="line">                    # - 也可以设置具体数值：0, 1, 2</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><code>AUTO</code> 规则：<strong>0~2 字符</strong>不允许错；<strong>3~5 字符</strong>最多1错；<strong>&gt;5 字符</strong>最多2错。</li>
<li>对 <strong>text 字段</strong>先分词，再对每个 token 做模糊 → 召回 <code>Elasticsearch</code>。</li>
</ul>
<h4 id="elasticsearch的连接"><a href="#elasticsearch的连接" class="headerlink" title="elasticsearch的连接"></a>elasticsearch的连接</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from langchain_elasticsearch import ElasticsearchRetriever</span><br><span class="line">from embeddings_model import select_embeddings_model</span><br><span class="line"># 根据模型名称选择嵌入模型</span><br><span class="line">embedding_model_name=&#x27;bge&#x27;</span><br><span class="line">embeddings = select_embeddings_model(embedding_model_name)</span><br><span class="line">dense_vector_field=&#x27;vector&#x27;</span><br><span class="line">text_field=&#x27;text&#x27;</span><br><span class="line">search_func=fuzzy_query</span><br><span class="line"># 创建Elasticsearch检索器</span><br><span class="line">retriever = ElasticsearchRetriever.from_es_params(</span><br><span class="line">    index_name=&quot;zxj_test&quot;,  # 指定索引名称</span><br><span class="line">    body_func=fuzzy_query,  # 查询函数</span><br><span class="line">    content_field=&quot;text&quot;,  # 内容字段名</span><br><span class="line">    url=&#x27;http://elasticsearch:9200/&#x27;# Elasticsearch服务器地址</span><br><span class="line">)</span><br><span class="line">print(&quot;连接成功&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="elasticsearch的入库"><a href="#elasticsearch的入库" class="headerlink" title="elasticsearch的入库"></a>elasticsearch的入库</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">document = []</span><br><span class="line">id_list = []</span><br><span class="line"></span><br><span class="line"># 遍历文件夹中的所有.md文件</span><br><span class="line">for filename in os.listdir(folder_path):</span><br><span class="line">    if filename.endswith(&quot;.md&quot;):</span><br><span class="line">        file_path = os.path.join(folder_path, filename)</span><br><span class="line"></span><br><span class="line">        # 从文件名中提取chunk_id（去除.md扩展名）</span><br><span class="line">        chunk_id = filename.replace(&quot;.md&quot;, &quot;&quot;)</span><br><span class="line"></span><br><span class="line">        # 读取MD文件内容</span><br><span class="line">        with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as file:</span><br><span class="line">            text_content = file.read()</span><br><span class="line">  </span><br><span class="line">        # 查找对应的URL（根据文件名匹配）</span><br><span class="line">        report_url = &quot;&quot;</span><br><span class="line">        # 从folder_name中提取核心文档名（最后一个^后面的部分）</span><br><span class="line">        core_folder_name = folder_name.split(&#x27;^&#x27;)[-1]  # 提取核心文档名</span><br><span class="line"></span><br><span class="line">        # 根据core_folder_name查找对应的URL</span><br><span class="line">        report_url = find_url_by_name_from_list(docs_data, core_folder_name)</span><br><span class="line"></span><br><span class="line">        # 构建document结构</span><br><span class="line">        doc = Document(</span><br><span class="line">            page_content=text_content,</span><br><span class="line">            metadata=&#123;</span><br><span class="line">                &quot;report_name&quot;: folder_name,</span><br><span class="line">                &quot;report_url&quot;: report_url,</span><br><span class="line">                &quot;chunk_id&quot;: chunk_id</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        document.append(doc)</span><br><span class="line">        id_list.append(folder_name + &quot;_&quot; + chunk_id)</span><br><span class="line"></span><br><span class="line"># 批量添加到向量库</span><br><span class="line">es_vector_store.add_documents(documents=document, ids=id_list)</span><br><span class="line">print(f&quot;    文件夹 &#123;folder_name&#125; 已成功入库，共 &#123;len(document)&#125; 个文档块&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h4><p><a target="_blank" rel="noopener" href="https://python.langchain.ac.cn/docs/integrations/retrievers/elasticsearch_retriever/#bm25">Elasticsearch检索器 | 🦜️🔗 LangChain 框架</a></p>
<h3 id="主流的检索策略"><a href="#主流的检索策略" class="headerlink" title="主流的检索策略"></a>主流的检索策略</h3><h4 id="BM25-全文关键词检索"><a href="#BM25-全文关键词检索" class="headerlink" title="BM25 全文关键词检索"></a>BM25 全文关键词检索</h4><p>BM25（Best Matching 25）是一种久经考验的排序算法，广泛应用于传统搜索引擎中。它基于“词袋模型”，核心思想是通过关键词匹配程度来衡量文档与查询的相关性。</p>
<p>核心原理概览：</p>
<p>词频 (Term Frequency, TF)：一个词在文档中出现的次数越多，通常意味着这篇文档与该词相关性越高。但BM25会进行“饱和度”处理，避免某些超高频词过度影响结果。可以想象成，一篇文章提到“苹果”10次，比提到1次更相关，但提到100次和提到50次，在“苹果”这个主题上的相关性增加可能就没那么显著了。<br>逆文档频率 (Inverse Document Frequency, IDF)：如果一个词在整个文档集合中都很罕见（只在少数文档中出现），那么它对于区分文档主题就更重要，IDF值就高。比如“量子纠缠”这个词远比“的”、“是”这类词更能锁定专业文档。<br>文档长度归一化：用于平衡长短文档的得分，避免长文档仅仅因为内容多而获得不公平的高分。<br>工作方式举例：当用户搜索“深度学习入门教程”时，BM25会倾向于找出那些更频繁出现“深度学习”、“入门”、“教程”这些词，且这些词相对不那么常见的文档。</p>
<p><strong>1. 公式整体结构</strong></p>
<script type="math/tex; mode=display">
\text{score}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \underbrace{\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot \left(1 - b + b \cdot \frac{|D|}{\text{avgdl}}\right)}}_{\text{词频归一化项（TF）}}</script><ul>
<li><strong>IDF 部分</strong>：衡量词项 $ q_i $ 的区分能力（逆文档频率）。</li>
<li><strong>TF 部分</strong>：衡量词项 $ q_i $ 在文档 $ D $ 中的匹配程度（词频归一化）。</li>
<li><strong>求和</strong>：对查询中的所有词项 $ q_i $ 的得分求和，得到最终相关性分数。</li>
</ul>
<p><strong>2. IDF 部分</strong></p>
<script type="math/tex; mode=display">
\text{IDF}(q_i) = \ln\left(\frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}\right)</script><ul>
<li><strong>意义</strong>：IDF 值越高，词项 $ q_i $ 越能区分文档（常见于少数文档中的词）。</li>
<li><strong>平滑处理</strong>：分子和分母均加 0.5，避免极端值（如 $ n(q_i) = 0 $ 时 ID 无限大）。</li>
<li><strong>参数</strong>：<ul>
<li>$ N $：文档总数。</li>
<li>$ n(q_i) $：包含 $ q_i $ 的文档数。</li>
</ul>
</li>
</ul>
<p><strong>3. 词频归一化项（TF）</strong></p>
<script type="math/tex; mode=display">
\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot \left(1 - b + b \cdot \frac{|D|}{\text{avgdl}}\right)}</script><ul>
<li><strong>非线性饱和</strong>：分子和分母均包含 $ f(q_i, D) $，使词频增长带来的增益逐渐减小（避免长文档中重复词项的过度影响）。</li>
<li><strong>文档长度归一化</strong>：<ul>
<li>$ |D| $：文档 $ D $ 的长度（词数）。</li>
<li>$ \text{avgdl} $：整个文档集合的平均文档长度。</li>
<li>$ b $：控制文档长度对得分的影响（$ b=1 $ 时完全归一化，$ b=0 $ 时忽略长度）。</li>
</ul>
</li>
<li><strong>参数</strong>：<ul>
<li>$ k_1 $：控制词频饱和的系数（通常 $ k_1 \in [1.2, 2.0] $，默认 $ k_1 = 1.5 $）。</li>
<li>$ b $：默认 $ b = 0.75 $。</li>
</ul>
</li>
</ul>
<p>这个公式虽然看起来有些复杂，但它精妙地平衡了词频、词的稀有度以及文档长度这几个核心因素，是BM25算法效果出色的关键。</p>
<h6 id="BM25、全文搜索与倒排索引：它们是如何协同工作的？"><a href="#BM25、全文搜索与倒排索引：它们是如何协同工作的？" class="headerlink" title="BM25、全文搜索与倒排索引：它们是如何协同工作的？"></a>BM25、全文搜索与倒排索引：它们是如何协同工作的？</h6><p><strong>这三者是构建搜索系统的关键组件：</strong></p>
<ul>
<li><p>全文搜索 (Full-Text Search)：这是我们希望达成的目标——在大量文本中找到包含特定信息的文档。</p>
</li>
<li><p>倒排索引 (Inverted Index)：这是实现高效全文搜索的数据结构基础。它像一本书末尾的详细“关键词索引”，记录了每个词出现在哪些文档中以及相关位置信息。当用户查询时，系统可以通过倒排索引快速定位到包含查询词的候选文档。</p>
</li>
<li>BM25：在通过倒排索引找到候选文档后，BM25算法登场，为每个文档计算一个相关性得分，然后按分排序，将最相关的结果呈现给用户。</li>
</ul>
<p><strong>把它们比作在图书馆找特定主题的书籍：</strong></p>
<ul>
<li>你告诉图书管理员你要找关于“天体物理学”的书（用户查询）。</li>
<li>管理员查阅一个总卡片索引（倒排索引），迅速告诉你哪些书架（文档ID）上有包含“天体物理学”这个词的书。</li>
<li>你走到这些书架，快速翻阅这些书（BM25评分过程），根据目录、摘要和提及“天体物理学”的频繁程度及重要性，判断哪几本最符合你的需求，并把它们按相关性高低排好。</li>
</ul>
<h4 id="Dense-Vector-kNN-向量语义检索"><a href="#Dense-Vector-kNN-向量语义检索" class="headerlink" title="Dense Vector / kNN 向量语义检索"></a>Dense Vector / kNN 向量语义检索</h4><p>向量语义检索（Dense Vector / k-Nearest Neighbor，简称 kNN）是一种<strong>基于高维稠密向量表示的语义检索技术</strong>，与传统关键词倒排索引不同，它通过<strong>自然语言的上下文含义</strong>而非字面匹配来寻找最相关的文档或实体。</p>
<ol>
<li><p><strong>Embedding</strong>：使用预训练语言模型（如 BERT、Sentence-Transformers）把文本映射为<strong>固定维度的稠密向量</strong>（通常 128–1024 维）。</p>
</li>
<li><p><strong>kNN 搜索</strong>：给定查询向量，<strong>在向量空间中找距离最近的 k 个文档向量</strong>。距离度量常见：</p>
<ul>
<li>余弦相似度（cosine）</li>
<li>内积 / dot-product</li>
<li>L2 欧氏距离</li>
</ul>
</li>
</ol>
<h4 id="Hybrid-Retrieval-混合检索"><a href="#Hybrid-Retrieval-混合检索" class="headerlink" title="Hybrid Retrieval 混合检索"></a>Hybrid Retrieval 混合检索</h4><p>既然不同的检索策略各有千秋（例如，BM25擅长关键词精确匹配，Embedding擅长语义理解），那么将它们结合起来，是不是能达到“1+1&gt;2”的效果呢？答案是肯定的，这就是混合检索的核心思想。</p>
<p>常见做法：同时使用BM25（或其他稀疏检索方法）和一种或多种Embedding检索方法，然后将它们各自的检索结果进行融合排序。</p>
<p>融合策略举例：</p>
<p>RRF (Reciprocal Rank Fusion, 倒数排序融合)：一种简单但鲁棒的融合方法。它不关心不同检索系统输出的原始得分，只关心每个文档在各自结果列表中的排名。一个文档 doc 的RRF得分计算如下：</p>
<script type="math/tex; mode=display">
Score_RRF(doc) = Σ_{s ∈ Systems} (1 / (k + rank_s(doc)))</script><p>其中：</p>
<ul>
<li>Systems 是所有参与融合的检索系统的集合。</li>
<li>rank_s(doc) 是文档 doc 在检索系统 s 给出的结果列表中的排名（例如，第一名是1，第二名是2）。</li>
<li>k 是一个小常数（例如，常设置为60），用于平滑得分，避免排名靠后的文档得分过小或排名第一的文档得分占比过高。</li>
</ul>
<h4 id="Reranker-重排序器"><a href="#Reranker-重排序器" class="headerlink" title="Reranker  重排序器"></a>Reranker  重排序器</h4><p>经过上述一种或多种检索策略的“粗筛”（召回阶段），我们通常会得到一个包含较多候选文档的列表（比如几百个）。为了进一步提升最终喂给LLM的文档质量，Reranker（重排序器）应运而生。它相当于一位“精炼师”或“质量品鉴官”，对初步召回的结果进行更细致、更精准的二次排序。</p>
<ol>
<li>召回<br>倒排 / 向量 / 混合先给 <strong>Top-N</strong>（N≈100~1 k）。</li>
<li>拼特征<br>把 <code>(query, doc)</code> 拼成一条输入：<br><code>[CLS] 用户问题 [SEP] 标题+正文 [SEP]</code>。</li>
<li>打分<br>扔给 Cross-Encoder 或 ColBERT → 输出<strong>一个相关性分数</strong>。</li>
<li>重排<br>按分数从高到低重新排序，只留 <strong>Top-K</strong>（K≈10~20）。</li>
<li>返回<br>重排后的短列表交给前端或 LLM，完成一次“精读”。</li>
</ol>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_59614665/article/details/149066780">大模型RAG | 深入了解几种主流的检索策略（BM25、Embedding、混合检索、Reranker）-CSDN博客</a></p>
<h3 id="项目关于elasticsearch代码阅读记录"><a href="#项目关于elasticsearch代码阅读记录" class="headerlink" title="项目关于elasticsearch代码阅读记录"></a>项目关于elasticsearch代码阅读记录</h3><p>阅读elasticsearch代码相关记录:</p>
<ol>
<li><strong>embedding_model</strong>.select_embeddings_model:根据指定的模型名称加载</li>
<li><strong>make_es_vector_store</strong>：<ol>
<li>docs_url = pd.read_excel(‘docs_new.xlsx’)，从excel加载url并进行数据处理，保存筛选后的ur</li>
<li>完成文件加载测试：xizhang/retrival/docfile_test/test.py；</li>
<li>初始化es，使用elastic_search.load_es_index加载存储索引</li>
<li>完成测试elasticsearch连接与索引构建（索引名zxj_test）：/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_es_connect.py，/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_add_es.py</li>
<li>顺序批量处理文件：共16000多份，每十份为一批进行处理，使用download_pdf.py进行文件下载，使用，使用vector_base.rewrite_file对文件进行处理，这里可以修改代码，增加对mineru处理pdf的markdown文件的处理，返回Document对象列表；</li>
</ol>
</li>
<li><strong>elastic_search</strong></li>
</ol>
<p>重写了检索策略的函数，包括BM25，KNN，混合搜索</p>
<ol>
<li><p>elastic_retriever创建Elasticsearch检索器：根据搜索类型选择对应的查询函数，创建Elasticsearch检索器ElasticsearchRetriever.from_es_params</p>
</li>
<li><p><strong>retrievers</strong></p>
<ol>
<li>定义函数select_retriever，根据指定的名称选择并返回相应的检索器，目前只有bm25</li>
</ol>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/" class="post-title-link" itemprop="url">LangGraph学习——agent——上</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-18T00:00:00+08:00">2025-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-27 12:14:37" itemprop="dateModified" datetime="2025-07-27T12:14:37+08:00">2025-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本教程为langchain官方教程的学习记录</p>
<p><a target="_blank" rel="noopener" href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a target="_blank" rel="noopener" href="https://github.com/zxj-2023/learn-rag-langchain">zxj-2023/learn-rag-langchain</a></p>
<h3 id="module-1"><a href="#module-1" class="headerlink" title="module-1"></a>module-1</h3><h4 id="route路由"><a href="#route路由" class="headerlink" title="route路由"></a>route路由</h4><p>在 LangGraph 中，<strong>route（路由）\</strong>的核心作用是*<em>根据当前状态动态决定“下一步应该执行哪个节点”*</em></p>
<h5 id="定义工具"><a href="#定义工具" class="headerlink" title="定义工具"></a>定义工具</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def multiply(a: int, b: int) -&gt; int:</span><br><span class="line">    &quot;&quot;&quot;Multiply a and b.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: first int</span><br><span class="line">        b: second int</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line">    </span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">llm_with_tools = llm.bind_tools([multiply])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>三引号字符串叫 <strong>docstring</strong>，它会被 LangChain 拿来做两件事：</p>
<ol>
<li><strong>生成工具的 description（给大模型看的“说明书”）</strong><br>没有它时，LangChain 只能退而求其次，把函数名 <code>multiply</code> 拼成一句 “multiply tool” 之类的默认描述。大模型拿到的工具列表里，这个工具就只有一个干巴巴的名字和参数列表，它可能猜不到这个工具到底是干什么的</li>
<li><strong>给人类开发者自己看</strong><br>IDE、文档生成器、静态检查工具都会读取这段文字，方便后期维护。</li>
</ol>
</blockquote>
<h5 id="构建条件边"><a href="#构建条件边" class="headerlink" title="构建条件边"></a>构建条件边</h5><p><code>tool_calling_llm</code> 是一个<strong>普通的计算节点</strong>（node），负责把当前对话状态交给大模型，让大模型决定要不要调用工具；</p>
<p>真正完成“路由”动作的是 <strong><code>tools_condition</code></strong> 这个函数——它才是 LangGraph 里的 <strong>route（条件边）</strong>。</p>
<p><code>tools_condition</code> 是 作为<strong>LangGraph 预置的“默认路由函数”</strong>，功能就是，如果大模型的最新回复中包含工具调用，就调用工具</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># Node</span><br><span class="line">def tool_calling_llm(state: MessagesState):</span><br><span class="line">	#调用大模型后将最新的消息返回</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm_with_tools.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">#MessagesState 是 LangGraph 官方预置 的一种 状态（State）定义</span><br><span class="line">#这个状态维护了一个消息list，有新的消息就加进这个消息list</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;tool_calling_llm&quot;, tool_calling_llm)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode([multiply]))</span><br><span class="line">builder.add_edge(START, &quot;tool_calling_llm&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;tool_calling_llm&quot;,</span><br><span class="line">    # 如果助手（结果）的最新消息是工具调用 -&gt; tools_condition 路由到工具</span><br><span class="line">    # 如果助手（结果）的最新消息不是工具调用 -&gt; tools_condition 路由到 END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719142543838.png" alt="image-20250719142543838"></p>
<h5 id="调用"><a href="#调用" class="headerlink" title="调用"></a>调用</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage</span><br><span class="line">messages = [HumanMessage(content=&quot;你好，2乘2是多少&quot;)]</span><br><span class="line">messages = graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，2乘2是多少</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_e026ceb409e247748786ad)</span><br><span class="line"> Call ID: call_e026ceb409e247748786ad</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">4</span><br></pre></td></tr></table></figure>
<h4 id="agent代理"><a href="#agent代理" class="headerlink" title="agent代理"></a>agent代理</h4><p>在 LangGraph 中，<strong>代理（Agent）</strong> 被明确定义为<strong>“一个由大语言模型（LLM）驱动的、能够循环决策并调用外部工具来完成任务的节点或子图”</strong>。</p>
<p><strong>Agent = LLM + 工具集合 + 提示模板</strong>，三者在 LangGraph 的状态化图结构里循环运行，直到满足停止条件。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.03629">ReAct</a> 是一种流行的通用智能体架构，它结合了这些扩展，并整合了三个核心概念。</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#tool-calling">工具调用</a>：允许LLM根据需要选择和使用各种工具。</li>
<li><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#memory">记忆</a>：使智能体能够保留和使用之前步骤的信息。</li>
<li><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#planning">规划</a>：使LLM能够创建并遵循多步计划以实现目标。</li>
</ol>
<p>即</p>
<p><code>act</code>- 让模型调用特定工具</p>
<p><code>observe</code> - 将工具输出传递回模型  </p>
<p> <code>reason</code> - 让模型对工具输出进行推理，以决定下一步操作（例如，调用另一个工具或直接响应）</p>
</blockquote>
<h5 id="定义工具-1"><a href="#定义工具-1" class="headerlink" title="定义工具"></a>定义工具</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tools = [add, multiply, divide]#工具函数具体内容省略</span><br><span class="line">llm = ChatOpenAI()</span><br><span class="line"></span><br><span class="line"># 在这个 ipynb 文件中，我们将并行工具调用（parallel tool calling）设置为 false，因为数学计算通常是按顺序执行的，并且这次我们有3个可以进行数学计算的工具。</span><br><span class="line"># OpenAI 模型为了效率，默认进行并行工具调用，详情请参阅 `https://python.langchain.com/docs/how_to/tool_calling_parallel/`</span><br><span class="line"># 不妨尝试一下，看看模型在处理数学方程式时的表现！</span><br><span class="line">llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)</span><br></pre></td></tr></table></figure>
<h5 id="创建代理"><a href="#创建代理" class="headerlink" title="创建代理"></a>创建代理</h5><p>定义节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line"># System message</span><br><span class="line">sys_msg = SystemMessage(content=&quot;你是一个乐于助人的助手，负责对一组输入执行算术运算。&quot;)</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def assistant(state: MessagesState):</span><br><span class="line">   return &#123;&quot;messages&quot;: [llm_with_tools.invoke([sys_msg] + state[&quot;messages&quot;])]&#125;</span><br></pre></td></tr></table></figure>
<p>这一步相当于定义了系统提示词，然后在 assistant 这个节点里，通过 [sys_msg] + state[“messages”] 这部分代码，这个系统提示词被添加到了整个对话历史的最前面，然后一起发送给模型。这样一来，模型在生成回复时就会遵循这个系统提示词的指示。</p>
<p>与上一个不同的是，我们将 <code>Tools</code> 节点 <strong>回环</strong> 连接到 <code>Assistant</code>，从而形成一个回路。</p>
<p>在 assistant节点执行后，<code>tools_condition</code>检查模型的输出是否为工具调用。</p>
<p>如果是工具调用，则流程被导向至 <code>tools</code> 节点。  </p>
<p><code>tools</code>节点重新连接到<code>assistant</code><strong>。</strong> 只要模型决定调用工具，此循环就会继续。  </p>
<p>如果模型的响应不是工具调用，则流程被导向至结束，终止该过程。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line"></span><br><span class="line"># Define nodes: these do the work</span><br><span class="line">builder.add_node(&quot;assistant&quot;, assistant)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode(tools))</span><br><span class="line"></span><br><span class="line"># Define edges: these determine how the control flow moves</span><br><span class="line">builder.add_edge(START, &quot;assistant&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;assistant&quot;,</span><br><span class="line">    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools</span><br><span class="line">    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, &quot;assistant&quot;)</span><br><span class="line">react_graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># Show</span><br><span class="line">display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719145948088.png" alt="image-20250719145948088"></p>
<h5 id="调用-1"><a href="#调用-1" class="headerlink" title="调用"></a>调用</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">messages = [HumanMessage(content=&quot;将3和4相加。将结果乘以2。再将结果除以5。&quot;)]</span><br><span class="line">messages = react_graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line"></span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=False的输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_6c69898dba0342bfbb889e)</span><br><span class="line"> Call ID: call_6c69898dba0342bfbb889e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_9940e7603ecf4a13a5f2fb)</span><br><span class="line"> Call ID: call_9940e7603ecf4a13a5f2fb</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  divide (call_d48fbbe205a14dfbaa3500)</span><br><span class="line"> Call ID: call_d48fbbe205a14dfbaa3500</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是2.8。</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=True的输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_e0c7d8e65f2c49e8aecd3e)</span><br><span class="line"> Call ID: call_e0c7d8e65f2c49e8aecd3e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">  multiply (call_5bf824058e64489aaace91)</span><br><span class="line"> Call ID: call_5bf824058e64489aaace91</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">  divide (call_36c34f69f6574028b28847)</span><br><span class="line"> Call ID: call_36c34f69f6574028b28847</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是 **2.8**。</span><br></pre></td></tr></table></figure>
<h4 id="Agent-memory代理记忆"><a href="#Agent-memory代理记忆" class="headerlink" title="Agent memory代理记忆"></a>Agent memory代理记忆</h4><p>使用chekpointer检查点的功能，最简单的检查点之一是 <code>MemorySaver</code>，这是一个用于图形状态的内存键值存储。</p>
<p>这个检查点就相当于把<strong>图的每一次“状态快照”持久化到外部存储</strong>的机制。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">react_graph_memory = builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p>我们可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/persistence/">记忆功能</a> 来解决这个问题！LangGraph 可以使用检查点工具在每一步之后自动保存图的状态。这一内置的持久化层为我们提供了内存功能，使 LangGraph 能够从最后一次状态更新处继续。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Specify a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Specify an input</span><br><span class="line">messages = [HumanMessage(content=&quot;Add 3 and 4.&quot;)]</span><br><span class="line"></span><br><span class="line"># Run</span><br><span class="line">messages = react_graph_memory.invoke(&#123;&quot;messages&quot;: messages&#125;,config)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当我们使用内存时，我们需要指定一个 <code>thread_id</code>。这 <code>thread_id</code> 将存储我们的图形状态集合。</p>
<p>如下图，检查点在图的每一步写入状态，这些检查点保存在一个线程中 ，我们可以使用 <code>thread_id</code> 在未来访问该线程</p>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66e0e9f526b41a4ed9e2d28b_agent-memory2.png" alt="state.jpg"></p>
<h3 id="module-2"><a href="#module-2" class="headerlink" title="module-2"></a>module-2</h3><h4 id="state-scheme状态模式"><a href="#state-scheme状态模式" class="headerlink" title="state-scheme状态模式"></a>state-scheme状态模式</h4><p>LangGraph 的 <strong>state-scheme（状态模式）</strong> 就是“一张<strong>蓝图</strong>”，它告诉框架：“在整个图的生命周期里，状态对象应该长什么样、每个字段怎样被更新、以及节点之间如何共享或隔离数据。”</p>
<p>state-scheme 用 <strong>TypedDict</strong> 或 <strong>Pydantic BaseModel</strong> 来声明，定义了：</p>
<ul>
<li>状态里有哪些字段（key）</li>
<li>每个字段的 Python 类型</li>
<li><strong>可选</strong> 该字段的 <strong>reducer</strong>（更新规则）</li>
</ul>
<h5 id="TypedDict"><a href="#TypedDict" class="headerlink" title="TypedDict"></a><strong>TypedDict</strong></h5><p><strong>基本定义</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    foo: str</span><br><span class="line">    bar: str</span><br></pre></td></tr></table></figure>
<p><strong>可增加像 <code>Literal</code> 这样的类型提示，使其更有价值</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from typing import Literal</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p>在这里，<code>mood</code> 只能是 “happy” 或 “sad”。</p>
<p><strong>加 reducer：让更新“可追加”而不覆盖</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class MathState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line">    scratchpad: Annotated[list[str], add_message]  # 新元素自动追加</span><br><span class="line">    answer: int</span><br></pre></td></tr></table></figure>
<p><code>Annotated[list[str], add]</code> 告诉 LangGraph：当节点返回 <code>&#123;&quot;scratchpad&quot;: [&quot;新步骤&quot;]&#125;</code> 时，<strong>追加</strong>到现有列表，而不是替换</p>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">#定义节点</span><br><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state[&#x27;name&#x27;] + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state):</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;happy&quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_3(state):</span><br><span class="line">    print(&quot;---Node 3---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;sad&quot;&#125;</span><br><span class="line">#路由函数</span><br><span class="line">def decide_mood(state) -&gt; Literal[&quot;node_2&quot;, &quot;node_3&quot;]:</span><br><span class="line">        </span><br><span class="line">    # Here, let&#x27;s just do a 50 / 50 split between nodes 2, 3</span><br><span class="line">    if random.random() &lt; 0.5:</span><br><span class="line"></span><br><span class="line">        # 50% of the time, we return Node 2</span><br><span class="line">        return &quot;node_2&quot;</span><br><span class="line">    </span><br><span class="line">    # 50% of the time, we return Node 3</span><br><span class="line">    return &quot;node_3&quot;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(TypedDictState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719154439415.png" alt="image-20250719154439415"></p>
<p>因为我们的状态是一个字典，我们只需用一个字典调用图，以设置状态中 <code>name</code> 键的初始值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;name&quot;:&quot;Lance&quot;&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="Dataclass数据类"><a href="#Dataclass数据类" class="headerlink" title="Dataclass数据类"></a><strong>Dataclass数据类</strong></h5><p>python的dataclasses库提供了一种简洁的语法，用于创建主要用于存储数据的类。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line"></span><br><span class="line">@dataclass</span><br><span class="line">class DataclassState:</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state.name + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(DataclassState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>要访问 <code>dataclass</code> 的键，我们只需修改在 <code>node_1</code> 中使用的下标即可：</p>
<p>我们使用 <code>state.name</code> 来表示 <code>dataclass</code> 状态，而不是使用 <code>state[&quot;name&quot;]</code> 来表示上面的 <code>TypedDict</code>。</p>
<p>你会注意到一个有点奇怪的地方：在每个节点中，我们仍然返回一个字典来执行状态更新。</p>
<p><strong>Dataclass 只是“描述”状态的形状，而真正在 LangGraph 的节点之间流动的依旧是「字典」</strong>，这是框架设计层面的约定</p>
<p>在这种情况下，<code>dataclass</code> 拥有键 <code>name</code>，因此我们可以通过从节点传递一个字典来更新它，就像在状态为 <code>TypedDict</code> 时所做的那样。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(DataclassState(name=&quot;Lance&quot;,mood=&quot;sad&quot;))</span><br></pre></td></tr></table></figure>
<p>我们通过 <code>dataclass</code> 来设置状态中每个键/通道的初始值！</p>
<h4 id="State-Reducers状态更新函数"><a href="#State-Reducers状态更新函数" class="headerlink" title="State Reducers状态更新函数"></a><strong>State Reducers</strong>状态更新函数</h4><p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers">Reducers</a> 为我们指定了如何执行更新。它接收 <strong>旧状态</strong> 与 <strong>一次变更指令（action / 增量字段）</strong>，<strong>返回全新的状态对象</strong>，整个过程中<strong>不能修改原有数据</strong>。</p>
<p>我们可以使用 <code>Annotated</code> 类型来指定一个 reducer 函数。在这种情况下，让我们将每个节点返回的值附加到结果中，而不是覆盖它们。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing import Annotated</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br></pre></td></tr></table></figure>
<p>我们只需要一个可以执行此操作的缩减器：<code>operator.add</code> 是 Python 内置 operator 模块中的一个函数。当 <code>operator.add</code> 应用于列表时，它执行列表连接。</p>
<h5 id="Custom-Reducers-自定义-Reducers"><a href="#Custom-Reducers-自定义-Reducers" class="headerlink" title="Custom Reducers 自定义 Reducers"></a><strong>Custom Reducers 自定义 Reducers</strong></h5><p>我们同样可以自定义reducers函数，解决一些特殊情况，比如，如下可以解决传入参数为none的情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def reduce_list(left: list | None, right: list | None) -&gt; list:</span><br><span class="line">    &quot;&quot;&quot;安全地合并两个列表，处理其中一个或两个输入可能为 None 的情况。</span><br><span class="line"></span><br><span class="line">    参数：</span><br><span class="line">        left (list | None): 要合并的第一个列表，或 None。</span><br><span class="line">        right (list | None): 要合并的第二个列表，或 None。</span><br><span class="line"></span><br><span class="line">    返回：</span><br><span class="line">        list: 一个包含两个输入列表所有元素的新列表。</span><br><span class="line">               如果输入为 None，则将其视为空列表。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if not left:</span><br><span class="line">        left = []</span><br><span class="line">    if not right:</span><br><span class="line">        right = []</span><br><span class="line">    return left + right</span><br><span class="line"></span><br><span class="line">class DefaultState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br><span class="line"></span><br><span class="line">class CustomReducerState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], reduce_list]</span><br></pre></td></tr></table></figure>
<h5 id="MessagesState"><a href="#MessagesState" class="headerlink" title="MessagesState"></a>MessagesState</h5><p>我可以使用内置的 reducer <code>add_messages</code> 来处理状态中的消息</p>
<p>而<em><code>MessagesState</code></em> <em>内置了一个</em> <em><code>messages</code></em> 键 它还为该键内置了一个 <code>add_messages</code> 合并器，这两个是等价的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from typing import Annotated</span><br><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import AnyMessage</span><br><span class="line">from langgraph.graph.message import add_messages</span><br><span class="line"></span><br><span class="line"># 定义一个自定义的 TypedDict，其中包含一个带有 add_messages reducer 的消息列表。</span><br><span class="line">class CustomMessagesState(TypedDict):</span><br><span class="line">    messages: Annotated[list[AnyMessage], add_messages]</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br><span class="line"></span><br><span class="line"># 使用 MessagesState ，它包含带有 add_messages reducer 的 messages 键。</span><br><span class="line">class ExtendedMessagesState(MessagesState):</span><br><span class="line">    # 添加除 messages 之外所需的任何键， messages 是预构建的。</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br></pre></td></tr></table></figure>
<p>在使用 <code>add_messages</code> reducer 时，让我们展示一些有用的技巧。</p>
<p><strong>重写（Re-writing）</strong></p>
<p>如果我们传递的消息与 <code>messages</code> 列表中已有的消息具有相同的 ID，则该消息将被覆盖！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Initial state</span><br><span class="line">initial_messages = [AIMessage(content=&quot;Hello! How can I assist you?&quot;, name=&quot;Model&quot;, id=&quot;1&quot;),</span><br><span class="line">                    HumanMessage(content=&quot;I&#x27;m looking for information on marine biology.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line">                   ]</span><br><span class="line"></span><br><span class="line"># New message to add</span><br><span class="line">new_message = HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line"></span><br><span class="line"># Test</span><br><span class="line">add_messages(initial_messages , new_message)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[AIMessage(content=&#x27;Hello! How can I assist you?&#x27;, name=&#x27;Model&#x27;, id=&#x27;1&#x27;),</span><br><span class="line"> HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&#x27;Lance&#x27;, id=&#x27;2&#x27;)]</span><br></pre></td></tr></table></figure>
<p><strong>删除（Removal）</strong></p>
<p><code>add_messages</code> 也 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/">同样支持删除</a>。为此，我们简单地使用 <a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/messages/langchain_core.messages.modifier.RemoveMessage.html">RemoveMessage</a> 来自 <code>langchain_core</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Message list</span><br><span class="line">messages = [AIMessage(&quot;Hi.&quot;, name=&quot;Bot&quot;, id=&quot;1&quot;)]</span><br><span class="line">messages.append(HumanMessage(&quot;Hi.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;))</span><br><span class="line">messages.append(AIMessage(&quot;So you said you were researching ocean mammals?&quot;, name=&quot;Bot&quot;, id=&quot;3&quot;))</span><br><span class="line">messages.append(HumanMessage(&quot;Yes, I know about whales. But what others should I learn about?&quot;, name=&quot;Lance&quot;, id=&quot;4&quot;))</span><br><span class="line"></span><br><span class="line"># Isolate messages to delete</span><br><span class="line">delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]</span><br><span class="line">print(delete_messages)</span><br></pre></td></tr></table></figure>
<h4 id="Multiple-Schemas-多种状态"><a href="#Multiple-Schemas-多种状态" class="headerlink" title="Multiple Schemas 多种状态"></a><strong>Multiple Schemas</strong> 多种状态</h4><h5 id="Private-State-私有状态"><a href="#Private-State-私有状态" class="headerlink" title="Private State 私有状态"></a><strong>Private State</strong> 私有状态</h5><p>首先，让我们讨论在节点之间传递 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/pass_private_state/">private state</a> 的情况。这对于图的中间计算逻辑中需要的任何内容都很有用，但与图的整体输入或输出无关。</p>
<p>示例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    foo: int</span><br><span class="line"></span><br><span class="line">class PrivateState(TypedDict):</span><br><span class="line">    baz: int</span><br><span class="line"></span><br><span class="line">def node_1(state: OverallState) -&gt; PrivateState:</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;baz&quot;: state[&#x27;foo&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state: PrivateState) -&gt; OverallState:</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;foo&quot;: state[&#x27;baz&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(OverallState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_edge(&quot;node_1&quot;, &quot;node_2&quot;)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719171509917.png" alt="image-20250719171509917"></p>
<p>我们将定义一个 <code>OverallState</code> 和一个 <code>PrivateState</code>。<code>node_2</code> 使用 <code>PrivateState</code> 作为输入，但输出写入到 <code>OverallState</code>。</p>
<p><code>baz</code> 仅包含在 <code>PrivateState</code> 中。因此，我们可以看到 <code>baz</code> 被排除在图形输出之外，因为它不在 <code>OverallState</code> 中。</p>
<h5 id="Input-Output-Schema-输入-输出模式"><a href="#Input-Output-Schema-输入-输出模式" class="headerlink" title="Input / Output Schema 输入/输出模式"></a><strong>Input / Output Schema </strong>输入/输出模式</h5><p>在 LangGraph 中，<strong>Input / Output Schema</strong> 就是“<strong>图的对外接口协议</strong>”：<strong>调用者只能按 Input Schema 传参；图运行完后，只吐出 Output Schema 规定的字段。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"># 定义输入的模式</span><br><span class="line">class InputState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line"></span><br><span class="line"># 定义输出的模式</span><br><span class="line">class OutputState(TypedDict):</span><br><span class="line">    answer: str</span><br><span class="line"></span><br><span class="line"># 定义整体模式，结合输入和输出</span><br><span class="line">class OverallState(InputState, OutputState):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"># 定义处理输入并生成答案的节点</span><br><span class="line">def answer_node(state: InputState):</span><br><span class="line">    # 示例答案和额外键</span><br><span class="line">    return &#123;&quot;answer&quot;: &quot;bye&quot;, &quot;question&quot;: state[&quot;question&quot;]&#125;</span><br><span class="line"></span><br><span class="line"># 构建图，并指定输入和输出模式</span><br><span class="line">builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)</span><br><span class="line">builder.add_node(answer_node)  # 添加答案节点</span><br><span class="line">builder.add_edge(START, &quot;answer_node&quot;)  # 定义起始边</span><br><span class="line">builder.add_edge(&quot;answer_node&quot;, END)  # 定义结束边</span><br><span class="line">graph = builder.compile()  # 编译图</span><br><span class="line"></span><br><span class="line"># 使用输入调用图并打印结果</span><br><span class="line">print(graph.invoke(&#123;&quot;question&quot;: &quot;hi&quot;&#125;))</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;answer&#x27;: &#x27;bye Lance&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，<code>input</code> / <code>output</code> 模式对图的输入和输出上允许的键进行 <strong>过滤</strong>。可以看到 <code>output</code> 模式将输出限制为仅包含 <code>answer</code> 键。</p>
<h4 id="Filtering-and-trimming-messages筛选和精简消息"><a href="#Filtering-and-trimming-messages筛选和精简消息" class="headerlink" title="Filtering and trimming messages筛选和精简消息"></a><strong>Filtering and trimming messages</strong>筛选和精简消息</h4><p>如果我们在处理长时间对话时不够小心，会导致高令牌使用量和延迟，因为我们传递给模型的是一系列不断增加的消息。所以要进行筛选和精简消息。</p>
<h5 id="简化器（Reducer）"><a href="#简化器（Reducer）" class="headerlink" title="简化器（Reducer）"></a><strong>简化器（Reducer）</strong></h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Nodes</span><br><span class="line">def filter_messages(state: MessagesState):</span><br><span class="line">    # 删除除最近两条消息外的所有消息</span><br><span class="line">    delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]]</span><br><span class="line">    return &#123;&quot;messages&quot;: delete_messages&#125;</span><br><span class="line"></span><br><span class="line">def chat_model_node(state: MessagesState):    </span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;filter&quot;, filter_messages)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;filter&quot;)</span><br><span class="line">builder.add_edge(&quot;filter&quot;, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719203204234.png" alt="image-20250719203204234"></p>
<h5 id="筛选消息（Filtering-messages）"><a href="#筛选消息（Filtering-messages）" class="headerlink" title="筛选消息（Filtering messages）"></a><strong>筛选消息（Filtering messages）</strong></h5><p>如果你不需要或不希望修改图状态，可以直接过滤传递给聊天模型的消息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;][-1:])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>例如，只需传递一个过滤后的列表：<code>llm.invoke(messages[-1:])</code> 给模型。</p>
<p>状态包含了所有消息。但这里模型调用仅使用最后一条消息</p>
<h5 id="裁剪消息（Trim-messages）"><a href="#裁剪消息（Trim-messages）" class="headerlink" title="裁剪消息（Trim messages）"></a><strong>裁剪消息（Trim messages）</strong></h5><p>另一种方法是根据设定一定数量的tokens进行 <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/trim_messages/#getting-the-last-max_tokens-tokens">trim messages</a>。在把对话历史发给大模型之前，按 <strong>token 预算</strong> 把超长消息列表“剪”到合适长度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import trim_messages</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    # 使用 trim_messages 函数修剪消息列表</span><br><span class="line">    # max_tokens: 限制消息的最大令牌数</span><br><span class="line">    # strategy: 修剪策略，这里是“last”，表示保留最新的消息</span><br><span class="line">    # token_counter: 用于计算令牌数的模型实例</span><br><span class="line">    # allow_partial: 是否允许部分修剪</span><br><span class="line">    messages = trim_messages(</span><br><span class="line">            state[&quot;messages&quot;],</span><br><span class="line">            max_tokens=100,</span><br><span class="line">            strategy=&quot;last&quot;,</span><br><span class="line">            token_counter= ChatOpenAI(</span><br><span class="line">                model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">                api_key=&quot;sk-&quot;,</span><br><span class="line">                base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;),</span><br><span class="line">            allow_partial=False,</span><br><span class="line">        )</span><br><span class="line">    # 调用语言模型（llm）处理修剪后的消息，并返回结果</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(messages)]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-message-summarization带有消息总结功能的聊天机器人"><a href="#Chatbot-with-message-summarization带有消息总结功能的聊天机器人" class="headerlink" title="Chatbot with message summarization带有消息总结功能的聊天机器人"></a><strong>Chatbot with message summarization</strong>带有消息总结功能的聊天机器人</h4><p>与其仅仅修剪或过滤消息，我们将展示如何使用大型语言模型（LLMs）来生成对话的实时摘要。</p>
<p>这使我们能够保留整个对话的压缩表示，而不仅仅是通过修剪或过滤将其移除。</p>
<p>我们将为该聊天机器人配备记忆功能，支持长时间对话，同时不会产生高昂的 token 成本或延迟。</p>
<h5 id="定义总结状态"><a href="#定义总结状态" class="headerlink" title="定义总结状态"></a>定义总结状态</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">class State(MessagesState):</span><br><span class="line">    summary: str</span><br></pre></td></tr></table></figure>
<p>除了内置的 <code>messages</code> 键之外，我们现在还将包含一个自定义键（<code>summary</code>）。</p>
<h5 id="定义LLM节点"><a href="#定义LLM节点" class="headerlink" title="定义LLM节点"></a>定义LLM节点</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage </span><br><span class="line"> </span><br><span class="line"> # 定义调用模型的逻辑</span><br><span class="line">def call_model(state: State): </span><br><span class="line">     </span><br><span class="line">     # 获取摘要（如果存在） </span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 如果有摘要，则添加它</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 将摘要添加到系统消息中</span><br><span class="line">         system_message = f&quot;先前对话的摘要：&#123;summary&#125;&quot; </span><br><span class="line"> </span><br><span class="line">         # 将摘要附加到任何较新的消息中</span><br><span class="line">         messages = [SystemMessage(content=system_message)] + state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     else: </span><br><span class="line">         messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     return &#123;&quot;messages&quot;: response&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>调用我们的LLM</strong>，如果存在摘要，则将其纳入提示中。</p>
<blockquote>
<p>当 call_model 函数返回 {“messages”: response} 时，它是在告诉 langgraph ：“请用 response （即模型的新输出）来更新 State 对象中 messages 键对应的值。” langgraph 会将这个新消息追加到 messages 列表中，从而保持了对话历史的连续性</p>
</blockquote>
<h5 id="定义摘要节点"><a href="#定义摘要节点" class="headerlink" title="定义摘要节点"></a>定义摘要节点</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def summarize_conversation(state: State): </span><br><span class="line">     </span><br><span class="line">     # 首先，我们获取任何现有的摘要</span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 创建我们的摘要提示</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 摘要已存在</span><br><span class="line">         summary_message = ( </span><br><span class="line">             f&quot;这是迄今为止对话的摘要：&#123;summary&#125;\n\n&quot; </span><br><span class="line">             &quot;请结合以上新消息扩展摘要：&quot; </span><br><span class="line">         ) </span><br><span class="line">         </span><br><span class="line">     else: </span><br><span class="line">         summary_message = &quot;创建以上对话的摘要：&quot; </span><br><span class="line"> </span><br><span class="line">     # 将提示添加到我们的历史记录中</span><br><span class="line">     messages = state[&quot;messages&quot;] + [HumanMessage(content=summary_message)] </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     </span><br><span class="line">     # 删除除最近2条消息外的所有消息</span><br><span class="line">     delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]] </span><br><span class="line">     return &#123;&quot;summary&quot;: response.content, &quot;messages&quot;: delete_messages&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>生成摘要</strong>。请注意，这里我们将使用 <code>RemoveMessage</code> 在生成摘要后过滤我们的状态。</p>
<h5 id="定义路由函数"><a href="#定义路由函数" class="headerlink" title="定义路由函数"></a>定义路由函数</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import END </span><br><span class="line"> # 决定是结束对话还是总结对话</span><br><span class="line">def should_continue(state: State): </span><br><span class="line">     </span><br><span class="line">     &quot;&quot;&quot;返回要执行的下一个节点。&quot;&quot;&quot; </span><br><span class="line">     </span><br><span class="line">     messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     # 如果消息超过六条，那么我们总结对话</span><br><span class="line">     if len(messages) &gt; 6: </span><br><span class="line">         return &quot;summarize_conversation&quot; </span><br><span class="line">     </span><br><span class="line">     # 否则我们就可以结束了</span><br><span class="line">     return END </span><br></pre></td></tr></table></figure>
<p>我们将添加一个条件边，以根据对话长度确定是否生成摘要。</p>
<blockquote>
<p>在 langgraph 中， Command 是一个特殊的类型，用于指导图形（graph）决定接下来应该执行哪个节点。 您可以把它看作是给图形下达的一个“命令”。</p>
</blockquote>
<h5 id="添加内存并编译图"><a href="#添加内存并编译图" class="headerlink" title="添加内存并编译图"></a>添加内存并编译图</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, START</span><br><span class="line"></span><br><span class="line"># Define a new graph</span><br><span class="line">workflow = StateGraph(State)</span><br><span class="line">workflow.add_node(&quot;conversation&quot;, call_model)</span><br><span class="line">workflow.add_node(&quot;summarize_conversation&quot;,summarize_conversation)</span><br><span class="line"></span><br><span class="line"># Set the entrypoint as conversation</span><br><span class="line">workflow.add_edge(START, &quot;conversation&quot;)</span><br><span class="line">workflow.add_conditional_edges(&quot;conversation&quot;, should_continue)</span><br><span class="line">workflow.add_edge(&quot;summarize_conversation&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Compile</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph = workflow.compile(checkpointer=memory)</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h5 id="使用线程调用"><a href="#使用线程调用" class="headerlink" title="使用线程调用"></a>使用线程调用</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">input_message = HumanMessage(content=&quot;我喜欢玩lol，你知道这个游戏吗&quot;)</span><br><span class="line">output = graph.invoke(&#123;&quot;messages&quot;: [input_message]&#125;, config) </span><br><span class="line">for m in output[&#x27;messages&#x27;][-1:]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当对话大于6，可生成概要</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.get_state(config).values.get(&quot;summary&quot;,&quot;&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-message-summarization-amp-external-DB-memory具有消息总结和外部数据库记忆的聊天机器人"><a href="#Chatbot-with-message-summarization-amp-external-DB-memory具有消息总结和外部数据库记忆的聊天机器人" class="headerlink" title="Chatbot with message summarization &amp; external DB memory具有消息总结和外部数据库记忆的聊天机器人"></a><strong>Chatbot with message summarization &amp; external DB memory</strong>具有消息总结和外部数据库记忆的聊天机器人</h4><h5 id="使用数据库"><a href="#使用数据库" class="headerlink" title="使用数据库"></a>使用数据库</h5><p><code>SqliteSaver</code> 是 LangGraph 提供的一个 <strong>轻量级状态持久化工具</strong>，它将图的运行状态（即 checkpoint）保存到本地的 SQLite 数据库中，使得你可以在程序中断或重启后<strong>恢复执行上下文</strong>，特别适合本地开发、实验性项目或中小规模应用。</p>
<p>如果我们提供 “:memory:” ，它将创建一个内存中的 SQLite 数据库。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import sqlite3</span><br><span class="line"># In memory</span><br><span class="line">conn = sqlite3.connect(&quot;:memory:&quot;, check_same_thread = False)</span><br></pre></td></tr></table></figure>
<p>如果我们提供一个 db 路径，那么它将为我们创建一个数据库！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#在本地创建一个目录 state_db，并尝试从 GitHub 下载一个名为 example.db 的 SQLite 数据库文件</span><br><span class="line">!mkdir -p state_db &amp;&amp; [ ! -f state_db/example.db ] &amp;&amp; wget -P state_db https://github.com/langchain-ai/langchain-academy/raw/main/module-2/state_db/example.db</span><br><span class="line"></span><br><span class="line">db_path = &quot;state_db/example.db&quot;</span><br><span class="line">conn = sqlite3.connect(db_path, check_same_thread=False)</span><br></pre></td></tr></table></figure>
<p>定义checkpoint</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.checkpoint.sqlite import SqliteSaver</span><br><span class="line">memory = SqliteSaver(conn)</span><br></pre></td></tr></table></figure>
<p>像上一个形式编译图</p>
<p>让我们确认一下我们的状态是否已保存到本地。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">graph_state = graph.get_state(config)</span><br><span class="line">graph_state</span><br></pre></td></tr></table></figure>
<p>使用像 Sqlite 这样的数据库意味着状态会被持久化！</p>
<h3 id="module-3"><a href="#module-3" class="headerlink" title="module-3"></a>module-3</h3><h4 id="Streaming-流式传输"><a href="#Streaming-流式传输" class="headerlink" title="Streaming 流式传输"></a><strong>Streaming</strong> 流式传输</h4><p>现在，让我们来谈谈 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming">流式传输我们的图状态</a> 的方法。<code>.stream</code> 和 <code>.astream</code> 是用于流式返回结果的同步和异步方法。</p>
<p><code>values</code>：这将在每个节点被调用后流式传输图的完整状态。 <code>updates</code>：这将在每个节点被调用后流式传输图的状态更新。</p>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbaf892d24625a201744e5_streaming1.png" alt="values_vs_updates.png"></p>
<h5 id="stream-mode-”updates”"><a href="#stream-mode-”updates”" class="headerlink" title="stream_mode=”updates”"></a>stream_mode=”updates”</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Create a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    print(chunk)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;conversation&#x27;: &#123;&#x27;messages&#x27;: AIMessage(content=&#x27;你好，zxj！很高兴认识你～有什么我可以帮你的吗？😊&#x27;, additional_kwargs=&#123;&#x27;refusal&#x27;: None&#125;, response_metadata=&#123;&#x27;token_usage&#x27;: &#123;&#x27;completion_tokens&#x27;: 16, &#x27;prompt_tokens&#x27;: 576, &#x27;total_tokens&#x27;: 592, &#x27;completion_tokens_details&#x27;: None, &#x27;prompt_tokens_details&#x27;: None&#125;, &#x27;model_name&#x27;: &#x27;qwen-plus-2025-04-28&#x27;, &#x27;system_fingerprint&#x27;: None, &#x27;id&#x27;: &#x27;chatcmpl-891471ae-2fe8-9b3d-b5f7-f4fcd55a4e16&#x27;, &#x27;service_tier&#x27;: None, &#x27;finish_reason&#x27;: &#x27;stop&#x27;, &#x27;logprobs&#x27;: None&#125;, id=&#x27;run--f36409f3-af43-4e9b-8a46-39646ad7c106-0&#x27;, usage_metadata=&#123;&#x27;input_tokens&#x27;: 576, &#x27;output_tokens&#x27;: 16, &#x27;total_tokens&#x27;: 592, &#x27;input_token_details&#x27;: &#123;&#125;, &#x27;output_token_details&#x27;: &#123;&#125;&#125;)&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>让我们来看一下 <code>stream_mode=&quot;updates&quot;</code>。</p>
<p>因为我们使用 <code>updates</code> 进行流式传输，所以只有在图中的节点运行后，我们才能看到状态的更新。每个 <code>chunk</code> 是一个字典，以 <code>node_name</code> 为键，更新后的状态为值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    chunk[&#x27;conversation&#x27;][&quot;messages&quot;].pretty_print()</span><br></pre></td></tr></table></figure>
<p>现在我们直接打印状态更新。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好呀，zxj！再次见到你真高兴～😊 有什么我可以帮忙的吗？</span><br></pre></td></tr></table></figure>
<h5 id="stream-mode-”values”"><a href="#stream-mode-”values”" class="headerlink" title="stream_mode=”values”"></a>stream_mode=”values”</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Start conversation, again</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">input_message = HumanMessage(content=&quot;你好我是zxj&quot;)</span><br><span class="line">for event in graph.stream(&#123;&quot;messages&quot;: [input_message]&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    for m in event[&#x27;messages&#x27;]:</span><br><span class="line">        m.pretty_print()</span><br><span class="line">    print(&quot;---&quot;*25)</span><br></pre></td></tr></table></figure>
<p>现在，我们可以看到 <code>stream_mode=&quot;values&quot;</code>.这是在 <code>conversation</code> 节点被调用后，图的整个状态。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，zxj！有什么我可以帮你的吗？😊</span><br><span class="line">---------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h5 id="Streaming-tokens-流式传输令牌"><a href="#Streaming-tokens-流式传输令牌" class="headerlink" title="Streaming tokens 流式传输令牌"></a><strong>Streaming tokens</strong> <strong>流式传输令牌</strong></h5><p>在 LangGraph 中，“流式传输令牌（Streaming tokens）”指的是<strong>在节点内部的大模型（LLM）生成过程中，逐 token 地将中间结果实时推送到客户端</strong>的能力。实现这一能力的核心方法是 <code>astream_events</code>，它会以事件流的形式暴露整个执行过程中的所有细节，包括每一次 LLM 调用产生的 token。</p>
<p>每个事件是一个包含几个键的字典：</p>
<p><code>event</code>：这是正在发出的事件的类型。</p>
<p> <code>name</code>：这是事件的名称。</p>
<p><code>data</code>：这是与事件相关联的数据。</p>
<p> <code>metadata</code>：包含 <code>langgraph_node</code>，即发出事件的节点。</p>
<p>要点是，图表中聊天模型的令牌具有 <code>on_chat_model_stream</code> 类型。我们可以使用 <code>event[&#39;metadata&#39;][&#39;langgraph_node&#39;]</code> 来选择要流式的节点。并且我们可以使用 <code>event[&#39;data&#39;]</code> 来获取每个事件的实际数据，而在这种情况下，数据是一个 <code>AIMessageChunk</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">node_to_stream = &#x27;conversation&#x27;#定义流式传输的节点</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;5&quot;&#125;&#125;</span><br><span class="line">input_message = HumanMessage(content=&quot;为我介绍lol&quot;)</span><br><span class="line">async for event in graph.astream_events(&#123;&quot;messages&quot;: [input_message]&#125;, config, version=&quot;v2&quot;):</span><br><span class="line">    # 从特定节点获取聊天模型生成的 Token</span><br><span class="line">    #事件类型必须是 逐 token 流式输出（on_chat_model_stream）。</span><br><span class="line">    if event[&quot;event&quot;] == &quot;on_chat_model_stream&quot; and event[&#x27;metadata&#x27;].get(&#x27;langgraph_node&#x27;,&#x27;&#x27;) == node_to_stream:</span><br><span class="line">        data = event[&quot;data&quot;]</span><br><span class="line">        print(data[&quot;chunk&quot;].content, end=&quot;|&quot;)</span><br></pre></td></tr></table></figure>
<p>event的常见类型</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事件类型 (<code>event</code>)</th>
<th>触发时机与说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>on_chain_start</code></td>
<td>任意 Runnable（节点、子图或整个图）开始执行</td>
</tr>
<tr>
<td><code>on_chain_stream</code></td>
<td>节点/图在运行过程中 <strong>增量输出</strong> chunk</td>
</tr>
<tr>
<td><code>on_chain_end</code></td>
<td>任意 Runnable 执行完成</td>
</tr>
<tr>
<td><code>on_chat_model_start</code></td>
<td><strong>ChatModel</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_chat_model_stream</code></td>
<td><strong>ChatModel</strong> 逐 token 返回内容（打字机效果）</td>
</tr>
<tr>
<td><code>on_chat_model_end</code></td>
<td><strong>ChatModel</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_tool_start</code></td>
<td><strong>Tool</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_tool_end</code></td>
<td><strong>Tool</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_retriever_start</code></td>
<td><strong>Retriever</strong> 开始检索</td>
</tr>
<tr>
<td><code>on_retriever_end</code></td>
<td><strong>Retriever</strong> 检索结束</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Breakpoints-断点"><a href="#Breakpoints-断点" class="headerlink" title="Breakpoints 断点"></a><strong>Breakpoints 断点</strong></h4><p><code>human-in-the-loop</code>（人工介入/人在回路）的三大动机：</p>
<p>1️⃣ Approval（审批）我们可以中断智能体，将当前状态呈现给用户，并让用户决定是否执行该操作。</p>
<p>2️⃣ Debugging（调试/回放）我们可以回退图形以重现或避免问题</p>
<p>3️⃣ Editing（编辑）AI 产出的中间结果不符合预期，但不想重跑整图，可以直接修改状态</p>
<p>我们将介绍 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/#simple-usage">breakpoints</a>，它提供了一种在特定步骤停止图的简单方法。</p>
<h5 id="Breakpoints-for-human-approval用于人类审批的断点"><a href="#Breakpoints-for-human-approval用于人类审批的断点" class="headerlink" title="Breakpoints for human approval用于人类审批的断点"></a><strong>Breakpoints for human approval</strong>用于人类审批的断点</h5><p>假设我们关注工具的使用：我们希望批准代理使用其任何工具。</p>
<p>我们所需要做的就是简单地用 <code>interrupt_before=[&quot;tools&quot;]</code> 编译图形，其中 <code>tools</code> 是我们的工具节点。</p>
<p>这意味着在执行工具调用的节点 <code>tools</code> 之前，执行将被中断。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;tools&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720225640772.png" alt="image-20250720225640772"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: HumanMessage(content=&quot;2乘3&quot;)&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br></pre></td></tr></table></figure>
<p>我们可以获取状态并查看要调用的下一个节点。这是一种很好的方法，可以发现图已被中断。</p>
<p>现在，我们将介绍一个很好的技巧。当我们使用 <code>None</code> 调用图时，它将直接从最后一个状态检查点继续！</p>
<p><img src="https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png" alt="breakpoints.jpg"></p>
<p>状态快照（StateSnapshot）</p>
<ul>
<li>类型：专门用来存 <strong>一个时刻</strong> 的完整状态</li>
<li>获取方式：<ul>
<li><code>Graph.get_state()</code> → <strong>最新的</strong> 快照</li>
<li><code>Graph.get_state_history()</code> → <strong>所有</strong> 快照列表</li>
</ul>
</li>
</ul>
<p>继续/重跑图</p>
<ul>
<li><code>Graph.stream(None, &#123;&quot;thread_id&quot;: &quot;xxx&quot;&#125;)</code><ul>
<li>不传新输入 <code>None</code> 表示 <strong>从当前最新状态继续跑</strong></li>
<li>也可回退到历史快照，再重跑（调试/回放）</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">6</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">2乘3的结果是6。</span><br></pre></td></tr></table></figure>
<h4 id="Editing-graph-state-编辑图状态"><a href="#Editing-graph-state-编辑图状态" class="headerlink" title="Editing graph state 编辑图状态"></a><strong>Editing graph state </strong>编辑图状态</h4><p>断点也是<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/">修改图状态的机会</a>让我们在 <code>assistant</code> 节点之前为代理设置断点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;assistant&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720230924672.png" alt="image-20250720230924672"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: &quot;2乘3&quot;&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br></pre></td></tr></table></figure>
<p>当状态中断时，我们可以直接应用状态更新</p>
<p>记住，对 <code>messages</code> 键的更新将使用 <code>add_messages</code> reducer：</p>
<p><strong>如果我们想覆盖现有的消息，可以提供带有<em> </em><code>id</code><em> </em>的消息。</strong> 如果我们只想将消息添加到消息列表中，则可以传递未指定 <code>id</code> 的消息，如下所示。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&quot;不要，实际上要3乘3!&quot;)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">new_state = graph.get_state(thread).values</span><br><span class="line">for m in new_state[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">不要，实际上要3乘3!</span><br></pre></td></tr></table></figure>
<p>现在，让我们继续进行我们的代理操作，只需传递 <code>None</code> 并允许其从当前状态继续执行。我们输出当前内容，然后继续执行剩余的节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="Dynamic-breakpoints-动态断点"><a href="#Dynamic-breakpoints-动态断点" class="headerlink" title="Dynamic breakpoints 动态断点"></a><strong>Dynamic breakpoints </strong>动态断点</h4><p>你可以根据条件来实现它（从节点内部基于开发人员定义的逻辑）。您可以向用户说明其中断原因（通过将您想传递的内容发送到 <code>NodeInterrupt</code>）。</p>
<p>让我们创建一个图表，其中根据输入的长度会抛出一个 <code>NodeInterrupt</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.errors import NodeInterrupt</span><br><span class="line">from langgraph.graph import START, END, StateGraph</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    input: str</span><br><span class="line"></span><br><span class="line">def step_1(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 1---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_2(state: State) -&gt; State:</span><br><span class="line">    # 如果输入字符串长度超过5个字符，我们可以选择抛出NodeInterrupt异常</span><br><span class="line">    if len(state[&#x27;input&#x27;]) &gt; 5:</span><br><span class="line">        raise NodeInterrupt(f&quot;收到长度超过5个字符的输入: &#123;state[&#x27;input&#x27;]&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    print(&quot;---Step 2---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_3(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 3---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">builder = StateGraph(State)</span><br><span class="line">builder.add_node(&quot;step_1&quot;, step_1)</span><br><span class="line">builder.add_node(&quot;step_2&quot;, step_2)</span><br><span class="line">builder.add_node(&quot;step_3&quot;, step_3)</span><br><span class="line">builder.add_edge(START, &quot;step_1&quot;)</span><br><span class="line">builder.add_edge(&quot;step_1&quot;, &quot;step_2&quot;)</span><br><span class="line">builder.add_edge(&quot;step_2&quot;, &quot;step_3&quot;)</span><br><span class="line">builder.add_edge(&quot;step_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Set up memory</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># Compile the graph with memory</span><br><span class="line">graph = builder.compile(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250721222709712.png" alt="image-20250721222709712"></p>
<p>让我们运行一个输入超过5个字符的图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">initial_input = &#123;&quot;input&quot;: &quot;hello world&quot;&#125;</span><br><span class="line">thread_config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread_config, stream_mode=&quot;values&quot;):</span><br><span class="line">    print(event)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br><span class="line">---Step 1---</span><br><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以尝试从断点恢复图。但是，这只会重新运行相同的节点！除非状态发生变化，否则我们将一直卡在这里。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread_config,</span><br><span class="line">    &#123;&quot;input&quot;: &quot;hi&quot;&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>使用update_state更新状态</p>
<h4 id="Time-travel-时间旅行"><a href="#Time-travel-时间旅行" class="headerlink" title="Time travel 时间旅行"></a><strong>Time travel</strong> 时间旅行</h4><p>现在，让我们通过查看、重播，甚至从过去的状态叉出，来展示 LangGraph <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/">支持debug</a> 的功能。</p>
<h5 id="Browsing-History-浏览历史"><a href="#Browsing-History-浏览历史" class="headerlink" title="Browsing History 浏览历史"></a><strong>Browsing History</strong> <strong>浏览历史</strong></h5><p>我们可以使用 <code>get_state</code> 来查看给定 <code>thread_id</code> 的图的 当前 状态！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.get_state(&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;&#125;&#125;)</span><br></pre></td></tr></table></figure>
<p>我们还可以浏览代理的状态历史。<code>get_state_history</code> 让我们能够获取所有先前步骤的状态。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_states = [s for s in graph.get_state_history(thread)]</span><br><span class="line">len(all_states)</span><br><span class="line">print(all_states)</span><br></pre></td></tr></table></figure>
<h5 id="Replaying-回放"><a href="#Replaying-回放" class="headerlink" title="Replaying 回放"></a><strong>Replaying</strong> <strong>回放</strong></h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">to_replay = all_states[-2]</span><br><span class="line">to_replay.values</span><br><span class="line">&#123;&#x27;messages&#x27;: [HumanMessage(content=&#x27;2乘3&#x27;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#x27;0676d9b5-cd59-4630-924d-b5c8d950e8d8&#x27;)]&#125;</span><br><span class="line">to_replay.next</span><br><span class="line">(&#x27;assistant&#x27;,)</span><br></pre></td></tr></table></figure>
<p>我们还获取了配置，它告诉了我们 <code>checkpoint_id</code> 以及 <code>thread_id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">to_replay.config</span><br><span class="line">&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;,</span><br><span class="line">  &#x27;checkpoint_ns&#x27;: &#x27;&#x27;,</span><br><span class="line">  &#x27;checkpoint_id&#x27;: &#x27;1f066c0e-2ee2-66d5-8000-5dde78194aae&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>要从这里重播，我们只需将配置传回给代理！图知道这个检查点已经执行过了。它只是从这个检查点重新播放！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, to_replay.config, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h5 id="Forking-分叉"><a href="#Forking-分叉" class="headerlink" title="Forking 分叉"></a><strong>Forking</strong> 分叉</h5><p>如果我们想从相同的步骤运行，但使用不同的输入，该怎么办呢？这是分叉。</p>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbb038f89f2d847ee5c336_time-travel3.png" alt="fig3.jpg"></p>
<p>让我们修改此检查点的状态。我们可以直接使用提供的 <code>checkpoint_id</code> 来运行 <code>update_state</code>。</p>
<p>请记住我们对 <code>messages</code> 的 reducer 是如何工作的：</p>
<ul>
<li>它会追加消息，除非我们提供了一个消息 ID。</li>
<li>我们提供消息 ID 是为了覆盖消息，而不是将消息追加到状态中！</li>
</ul>
<p>因此，要覆盖消息，我们只需提供消息 ID，而我们已有 <code>to_fork.values[&quot;messages&quot;].id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fork_config = graph.update_state(</span><br><span class="line">    to_fork.config,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&#x27;5乘3&#x27;, </span><br><span class="line">                               id=to_fork.values[&quot;messages&quot;][0].id)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><h4 id="message"><a href="#message" class="headerlink" title="message"></a>message</h4><p>LangChain 中的 HumanMessage 、 AIMessage 、 SystemMessage 和 ToolMessage 。这些消息类型是构建与语言模型（LLM）交互的核心组件，它们共同构成了一个完整的对话历史，帮助模型理解上下文并做出恰当的回应。</p>
<ol>
<li>SystemMessage</li>
</ol>
<p>SystemMessage 的结构最简单，它只包含内容和类型。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 消息的具体内容，即给 AI 的指令。</li>
<li>type (str): 固定为字符串 ‘system’ 。</li>
</ul>
<ol>
<li>HumanMessage</li>
</ol>
<p>HumanMessage 的结构也同样简单，代表用户的输入。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 用户输入的文本。</li>
<li>type (str): 固定为字符串 ‘human’ 。</li>
</ul>
<ol>
<li>AIMessage</li>
</ol>
<p>AIMessage 的结构相对复杂，因为它不仅可以包含文本响应，还可以包含对工具的调用请求。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): AI 生成的文本响应。如果 AI 的回复是发起工具调用，此字段可以为空字符串。</li>
<li>tool_calls (list[dict], 可选): 一个字典列表，每个字典代表一个工具调用请求。这是支持“Function Calling”或“Tool Calling”功能的核心。其结构通常包含：<ul>
<li>name (str): 要调用的工具名称。</li>
<li>args (dict): 调用工具时需要传入的参数。</li>
<li>id (str): 此次工具调用的唯一标识符，用于后续 ToolMessage 的关联。</li>
</ul>
</li>
<li>type (str): 固定为字符串 ‘ai’ 。</li>
</ul>
<ol>
<li>ToolMessage</li>
</ol>
<p>ToolMessage 用于承载工具执行后的返回结果。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 工具执行返回的结果。通常是一个字符串，比如 JSON 格式的字符串。</li>
<li>tool_call_id (str): 此次工具调用的唯一标识符， 必须 与之前 AIMessage 中 tool_calls 里的 id 相对应。这使得模型能够准确地将结果与请求匹配起来。</li>
<li>type (str): 固定为字符串 ‘tool’ 。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/" class="post-title-link" itemprop="url">Libreoffice</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-18T00:00:00+08:00">2025-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-30 15:26:37" itemprop="dateModified" datetime="2025-07-30T15:26:37+08:00">2025-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">实习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/" itemprop="url" rel="index"><span itemprop="name">晨晟智控</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="libreoffice部署"><a href="#libreoffice部署" class="headerlink" title="libreoffice部署"></a>libreoffice部署</h3><h4 id="查看Linux发行版"><a href="#查看Linux发行版" class="headerlink" title="查看Linux发行版"></a>查看Linux发行版</h4><p><img src="/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/image-20250718095931232.png" alt="image-20250718095931232"></p>
<p>系统是 <strong>银河麒麟高级服务器操作系统 V10（Kylin Linux Advanced Server V10）</strong>，属于 <strong>中国国产、兼容 CentOS/RHEL 生态</strong> 的 Linux 发行版。</p>
<p>因此它使用 <strong>RPM 包管理</strong>（<code>dnf</code>/<code>yum</code>），而不是 <code>.deb</code>。</p>
<h4 id="查看CPU-处理器架构"><a href="#查看CPU-处理器架构" class="headerlink" title="查看CPU 处理器架构"></a>查看<strong>CPU 处理器架构</strong></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -m</span><br></pre></td></tr></table></figure>
<p>是<strong>x86_64</strong></p>
<h4 id="不用部署了，镜像里有，直接用了"><a href="#不用部署了，镜像里有，直接用了" class="headerlink" title="不用部署了，镜像里有，直接用了"></a>不用部署了，镜像里有，直接用了</h4><h4 id="使用libreoffice处理doc文件，转成pdf"><a href="#使用libreoffice处理doc文件，转成pdf" class="headerlink" title="使用libreoffice处理doc文件，转成pdf"></a>使用libreoffice处理doc文件，转成pdf</h4><p>将当前目录下所有 <code>.doc</code> 和 <code>.docx</code> 转为 PDF：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">libreoffice --headless --convert-to pdf *.doc *.docx --outdir ./pdf_output/</span><br><span class="line"></span><br><span class="line"># 检查是否有残留进程</span><br><span class="line">ps aux | grep libreoffice</span><br><span class="line"></span><br><span class="line"># 如果有残留进程，杀死它们</span><br><span class="line">killall soffice.bin 2&gt;/dev/null</span><br></pre></td></tr></table></figure>
<h4 id="python"><a href="#python" class="headerlink" title="python"></a>python</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import subprocess</span><br><span class="line">import argparse</span><br><span class="line">import glob</span><br><span class="line">from pathlib import Path</span><br><span class="line">def batch_convert_documents(input_path, output_dir):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    批量转换文档的函数版本</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        input_path (str): 输入路径（文件、目录或通配符）</span><br><span class="line">        output_dir (str): 输出目录</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">        bool: 转换是否成功</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 确保输出目录存在</span><br><span class="line">    Path(output_dir).mkdir(parents=True, exist_ok=True)</span><br><span class="line">    </span><br><span class="line">    # 收集所有要转换的文件</span><br><span class="line">    files_to_convert = []</span><br><span class="line">    </span><br><span class="line">    if os.path.isfile(input_path):</span><br><span class="line">        # 单个文件</span><br><span class="line">        if input_path.lower().endswith((&#x27;.doc&#x27;, &#x27;.docx&#x27;)):</span><br><span class="line">            files_to_convert.append(input_path)</span><br><span class="line">    elif os.path.isdir(input_path):</span><br><span class="line">        # 目录中的所有doc/docx文件</span><br><span class="line">        for pattern in [&#x27;*.doc&#x27;, &#x27;*.docx&#x27;]:</span><br><span class="line">            files_to_convert.extend(glob.glob(os.path.join(input_path, pattern)))</span><br><span class="line">    else:</span><br><span class="line">        # 通配符模式</span><br><span class="line">        files_to_convert = glob.glob(input_path)</span><br><span class="line">        # 过滤出doc和docx文件</span><br><span class="line">        files_to_convert = [f for f in files_to_convert if f.lower().endswith((&#x27;.doc&#x27;, &#x27;.docx&#x27;))]</span><br><span class="line">    </span><br><span class="line">    if not files_to_convert:</span><br><span class="line">        print(&quot;未找到要转换的文档文件&quot;)</span><br><span class="line">        return False</span><br><span class="line">    </span><br><span class="line">    print(f&quot;找到 &#123;len(files_to_convert)&#125; 个文件需要转换&quot;)</span><br><span class="line">    </span><br><span class="line">    # 构建命令</span><br><span class="line">    cmd = [</span><br><span class="line">        &#x27;libreoffice&#x27;,</span><br><span class="line">        &#x27;--headless&#x27;,</span><br><span class="line">        &#x27;--convert-to&#x27;, &#x27;pdf&#x27;,</span><br><span class="line">        &#x27;--outdir&#x27;, output_dir</span><br><span class="line">    ] + files_to_convert</span><br><span class="line">    </span><br><span class="line">    try:</span><br><span class="line">        print(&quot;正在转换文件...&quot;)</span><br><span class="line">        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)</span><br><span class="line">        </span><br><span class="line">        if result.returncode == 0:</span><br><span class="line">            print(f&quot;成功转换 &#123;len(files_to_convert)&#125; 个文件&quot;)</span><br><span class="line">            return True</span><br><span class="line">        else:</span><br><span class="line">            print(f&quot;转换失败: &#123;result.stderr&#125;&quot;)</span><br><span class="line">            return False</span><br><span class="line">            </span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;转换过程中发生错误: &#123;e&#125;&quot;)</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    success = batch_convert_documents(&quot;./docs&quot;, &quot;./pdf_output&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="Linux扫盲"><a href="#Linux扫盲" class="headerlink" title="Linux扫盲"></a>Linux扫盲</h3><h4 id="发行版"><a href="#发行版" class="headerlink" title="发行版"></a>发行版</h4><p>像Ubuntu，CentOS都属于Linux的发行版，就像Windows11属于Windows的关系</p>
<p>常见发行版分类：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>系列</th>
<th>代表发行版</th>
<th>包格式</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Debian 系</strong></td>
<td>Debian、Ubuntu、Kali、Linux Mint</td>
<td><code>.deb</code></td>
<td>包多、社区大、教程多</td>
</tr>
<tr>
<td><strong>Red Hat 系</strong></td>
<td>CentOS、RHEL、Rocky、Alma、Fedora</td>
<td><code>.rpm</code></td>
<td>企业级稳定、官方支持长</td>
</tr>
<tr>
<td><strong>SUSE 系</strong></td>
<td>openSUSE Leap / Tumbleweed</td>
<td><code>.rpm</code></td>
<td>YaST 管理工具、欧洲流行</td>
</tr>
<tr>
<td><strong>Arch 系</strong></td>
<td>Arch Linux、Manjaro</td>
<td><code>.pkg.tar.zst</code></td>
<td>滚动更新、极客向</td>
</tr>
<tr>
<td><strong>轻量/最小</strong></td>
<td>Alpine、Debian netinst、CentOS Stream Minimal</td>
<td>任意</td>
<td>镜像小、资源占用低</td>
</tr>
</tbody>
</table>
</div>
<p>如何查看Linux发行版</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/os-release</span><br></pre></td></tr></table></figure>
<h4 id="deb和rpm"><a href="#deb和rpm" class="headerlink" title="deb和rpm"></a>deb和rpm</h4><p> <code>.deb</code> 和 <code>.rpm</code> 想象成 <strong>“Linux 世界里的安装程序”</strong>，就像 Windows 的 <code>.exe</code> / <code>.msi</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>格式</th>
<th>适用系统</th>
<th>安装命令</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>.deb</code></strong></td>
<td>Debian、Ubuntu、Linux Mint、Kali 等</td>
<td><code>sudo dpkg -i xxx.deb</code> 或 <code>sudo apt install ./xxx.deb</code></td>
</tr>
<tr>
<td><strong><code>.rpm</code></strong></td>
<td>CentOS、RHEL、Fedora、openSUSE、Rocky、Alma 等</td>
<td><code>sudo rpm -ivh xxx.rpm</code> 或 <code>sudo dnf/yum install xxx.rpm</code></td>
</tr>
</tbody>
</table>
</div>
<h4 id="cpu处理器架构"><a href="#cpu处理器架构" class="headerlink" title="cpu处理器架构"></a>cpu处理器架构</h4><div class="table-container">
<table>
<thead>
<tr>
<th>目录名</th>
<th>代表架构</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>x86_64</strong></td>
<td><strong>Intel/AMD 64 位</strong></td>
<td>绝大多数台式机、服务器（如 Xeon、EPYC、Core、Ryzen）</td>
</tr>
<tr>
<td><strong>aarch64</strong></td>
<td><strong>ARM 64 位</strong></td>
<td>树莓派 4/5、苹果 M 系列（Asahi Linux）、鲲鹏、飞腾、Ampere ARM 服务器等</td>
</tr>
</tbody>
</table>
</div>
<p>查看处理器架构：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -m</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E5%AE%9E%E6%88%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E5%AE%9E%E6%88%98/" class="post-title-link" itemprop="url">实战</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-18T00:00:00+08:00">2025-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-30 09:15:18" itemprop="dateModified" datetime="2025-07-30T09:15:18+08:00">2025-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">实习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/" itemprop="url" rel="index"><span itemprop="name">晨晟智控</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>部署日志见实习日志那篇文章</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>查看mineru提取的markdown文档后，发现mineru暂时无法提取多级标题，所以可以舍弃根据markdown文档结构的分块策略</p>
<p>UnstructuredMarkdownLoader会丢失表格格式，不能使用</p>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>将 <code>Markdown</code> 文档加载到 LangChain <a target="_blank" rel="noopener" href="https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document">文档</a> 对象中，以便我们可以在后续使用</p>
<h4 id="使用UnstructuredMarkdownLoader-对象"><a href="#使用UnstructuredMarkdownLoader-对象" class="headerlink" title="使用UnstructuredMarkdownLoader 对象"></a>使用<a target="_blank" rel="noopener" href="https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html">UnstructuredMarkdownLoader</a> 对象</h4><p>UnstructuredMarkdownLoader 是 LangChain 中的一个 文档加载器（Document Loader） ，专门用于加载和解析 Markdown ( .md ) 文件。它的特别之处在于，它底层依赖于一个强大的开源库 unstructured 。</p>
<p><strong>UnstructuredMarkdownLoader 的核心功能</strong></p>
<p>传统的文本加载器可能会将整个 Markdown 文件作为一个大字符串读入。而 UnstructuredMarkdownLoader 凭借 unstructured 库的能力，可以 智能地识别 Markdown 文件内部的结构 。</p>
<p>它能够将文档分解成多个有意义的<strong>“元素” (Elements)</strong>，例如：</p>
<ul>
<li>标题 (Titles)</li>
<li>叙述性文本 (Narrative Text / Paragraphs)</li>
<li>列表项 (List Items)</li>
<li>代码块 (Code Blocks)<br>这种智能分区对于后续的 RAG (Retrieval-Augmented Generation) 应用非常重要，因为它能让您以更小的、逻辑上连贯的块来处理文本，从而提高检索的准确性。</li>
</ul>
<p><strong>重要的 mode 参数</strong></p>
<p>UnstructuredMarkdownLoader 的构造函数中有一个非常重要的 mode 参数，它决定了文档的加载方式：</p>
<ol>
<li><p>mode=”single” (默认值)</p>
<ul>
<li>将整个 Markdown 文件的所有内容加载成 一个单独的 Document 对象 。</li>
<li>page_content 包含文件的全部文本。</li>
</ul>
</li>
<li><p>mode=”elements”</p>
<ul>
<li>这是它最强大的模式。它会将文件解析成多个 Document 对象， 每个对象对应一个识别出的元素 （如一个标题、一个段落）。</li>
<li>这对于创建精细的文本块以进行向量嵌入和检索非常有用。</li>
</ul>
</li>
</ol>
<h4 id="使用libreoffice处理doc文件，转成pdf"><a href="#使用libreoffice处理doc文件，转成pdf" class="headerlink" title="使用libreoffice处理doc文件，转成pdf"></a>使用libreoffice处理doc文件，转成pdf</h4><p>将当前目录下所有 <code>.doc</code> 和 <code>.docx</code> 转为 PDF：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">libreoffice --headless --convert-to pdf *.doc *.docx --outdir ./pdf_output/</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">LangChain学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-15 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-15T00:00:00+08:00">2025-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-02 15:52:08" itemprop="dateModified" datetime="2025-08-02T15:52:08+08:00">2025-08-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langchain/" itemprop="url" rel="index"><span itemprop="name">langchain</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="实战demo"><a href="#实战demo" class="headerlink" title="实战demo"></a>实战demo</h3><h4 id="agent实战"><a href="#agent实战" class="headerlink" title="agent实战"></a>agent实战</h4><p>langchain的agent与langgraph的agent主要差异点在create_openai_functions_agent, AgentExecutor这两个函数</p>
<p>前者的作用类似<strong>构建 Runnable 链</strong>，返回一个<code>RunnablePassthrough.assign(...)|prompt|llm_with_tools|ToolsAgentOutputParser()</code>，但其invoke仅能完成单步的调用，而<code>AgentExecutor</code> 会自动完成3 步循环（调用工具→拼回结果→再次调用 LLM），直到任务结束。</p>
<blockquote>
<p>以下为ai的解释</p>
<p><strong>直接使用 <code>agent</code> (Runnable) 的局限性:</strong></p>
<ol>
<li><strong>单步执行</strong>: 你直接调用 <code>agent.invoke()</code> 或 <code>agent.ainvoke()</code> 时，它通常只执行<strong>一步</strong>。对于像 <code>create_tool_calling_agent</code> 生成的 <code>agent</code> 来说，这一步就是：<ul>
<li>接收输入（包括历史消息和 <code>agent_scratchpad</code>）。</li>
<li>让 LLM 决定是给出最终答案 (<code>AgentFinish</code>) 还是调用工具 (<code>AgentAction</code>)。</li>
<li>返回这个决定。</li>
</ul>
</li>
<li><strong>工具调用需要手动处理</strong>: 如果 LLM 决定调用工具（返回 <code>AgentAction</code>），<strong>你</strong>需要负责：<ul>
<li>从返回的 <code>AgentAction</code> 中找出工具名称和输入参数。</li>
<li>在你的工具列表中找到对应的工具。</li>
<li>执行这个工具。</li>
<li>获取工具的输出（Observation）。</li>
<li><strong>再次手动调用 <code>agent.invoke(...)</code></strong>，把工具的输出（通常需要格式化成 <code>ToolMessage</code>）放回 <code>agent_scratchpad</code> 或 <code>intermediate_steps</code> 中。</li>
<li>重复这个过程，直到 <code>agent</code> 最终返回 <code>AgentFinish</code>。</li>
</ul>
</li>
</ol>
<p><strong>使用 <code>AgentExecutor</code> 的优势:</strong></p>
<p><code>AgentExecutor</code> 就是为了解决上述问题而设计的。它本质上是一个<strong>自动化的执行引擎</strong>，为你管理整个 Agent 的思考-行动-观察循环。</p>
<ol>
<li><strong>自动化循环</strong>: <code>AgentExecutor</code> 内部会自动运行那个循环：<ul>
<li>调用 <code>agent</code> (Runnable)。</li>
<li>检查返回的是 <code>AgentAction</code> 还是 <code>AgentFinish</code>。</li>
<li>如果是 <code>AgentAction</code>，它会自动根据你提供的 <code>tools</code> 列表找到并执行对应的工具。</li>
<li>它会自动将工具的输出（Observation）记录下来，并作为下一步的输入（放入 <code>agent_scratchpad</code>）再次调用 <code>agent</code>。</li>
<li>这个过程会一直重复。</li>
</ul>
</li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">from langchain.agents import create_openai_functions_agent, AgentExecutor</span><br><span class="line">from langchain.tools import tool</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line"># 1. 定义工具</span><br><span class="line">class WeatherInput(BaseModel):</span><br><span class="line">    location: str = Field(description=&quot;城市名称&quot;)</span><br><span class="line"></span><br><span class="line">@tool(&quot;get_weather&quot;, args_schema=WeatherInput)</span><br><span class="line">def get_weather(location: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;查询城市天气&quot;&quot;&quot;</span><br><span class="line">    return f&quot;&#123;location&#125; 今天是晴天，25°C&quot;</span><br><span class="line"></span><br><span class="line"># 2. 创建Agent</span><br><span class="line">llm = ChatOpenAI(model=&quot;gpt-4&quot;)</span><br><span class="line">tools = [get_weather]</span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (&quot;system&quot;, &quot;你是一个助手，可以调用工具&quot;),</span><br><span class="line">    (&quot;human&quot;, &quot;&#123;input&#125;&quot;)</span><br><span class="line">])</span><br><span class="line">agent = create_openai_functions_agent(llm, tools, prompt)</span><br><span class="line">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)</span><br><span class="line"></span><br><span class="line"># 3. 执行</span><br><span class="line">result = agent_executor.invoke(&#123;&quot;input&quot;: &quot;北京天气如何？&quot;&#125;)</span><br><span class="line">print(result[&quot;output&quot;])</span><br></pre></td></tr></table></figure>
<h4 id="工具调用"><a href="#工具调用" class="headerlink" title="工具调用"></a>工具调用</h4><p>利用bind_tools绑定工具，当大模型需要调用工具的时候，会返回工具信息，tool_calls，如下</p>
<p>[{‘name’: ‘add_numbers’, ‘args’: {‘a’: 15, ‘b’: 27}, ‘id’: ‘4e7b261cce6d4e3da09134086c704c3c’, ‘type’: ‘tool_call’}]</p>
<blockquote>
<p><code>llm_with_tools.invoke(...)</code> 只是一个<strong>单步调用</strong>，LLM 返回的是<strong>“我想调用哪个工具、传什么参数”</strong>（即 <code>tool_calls</code>）。<br><strong>但 LLM 并不会自动执行工具</strong>，所以你必须：</p>
<ol>
<li><strong>手动执行工具</strong>（或让 AgentExecutor 帮你执行）。</li>
<li><strong>把执行结果拼回对话</strong>（作为 <code>ToolMessage</code>）。</li>
<li><strong>再次调用 LLM</strong>，让它基于工具返回的结果生成最终答案。</li>
</ol>
</blockquote>
<p>这里展示的是手动拼接，并传给大模型，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 将工具的输出发送回LLM，让LLM基于结果生成最终回答</span><br><span class="line">            # 这是一个关键步骤，通常在Agent中自动处理。这里手动演示。</span><br><span class="line">            final_response = llm_with_tools.invoke([</span><br><span class="line">                HumanMessage(content=&quot;What is 15 + 27?&quot;),</span><br><span class="line">                AIMessage(content=&quot;&quot;, tool_calls=[tool_call]), # 告知LLM它之前建议的工具调用</span><br><span class="line">                ToolMessage(content=str(result), tool_call_id=tool_call[&#x27;id&#x27;]) # 告知LLM工具的执行结果</span><br><span class="line">            ])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.tools import tool</span><br><span class="line">from typing import Literal</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">from langchain_core.messages import HumanMessage, AIMessage, ToolMessage</span><br><span class="line"></span><br><span class="line"># 定义一个加法工具</span><br><span class="line">@tool</span><br><span class="line">def add_numbers(a: float, b: float) -&gt; float:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Adds two numbers together.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: The first number.</span><br><span class="line">        b: The second number.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a + b</span><br><span class="line"></span><br><span class="line"># 我们可以定义更多的工具，例如一个乘法工具</span><br><span class="line">@tool</span><br><span class="line">def multiply_numbers(a: float, b: float) -&gt; float:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Multiplies two numbers together.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: The first number.</span><br><span class="line">        b: The second number.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line"></span><br><span class="line"># 将我们定义的工具放在一个列表中</span><br><span class="line">tools = [add_numbers, multiply_numbers]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 初始化LLM</span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    temperature=0.5,</span><br><span class="line">    model_name=&quot;deepseek-v3-0324&quot;, # 聊天模型通常使用&quot;gpt-3.5-turbo&quot;或&quot;gpt-4&quot;</span><br><span class="line">    openai_api_base=&quot;https://api.qnaigc.com/v1&quot;, # 例如，您可以指定base_url</span><br><span class="line">    openai_api_key=&quot;sk-&quot; # 直接在此处设置API密钥，或者通过环境变量设置</span><br><span class="line">)</span><br><span class="line"># 将工具绑定到LLM</span><br><span class="line"># LLM现在知道了add_numbers和multiply_numbers这两个工具及其功能</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 场景一：LLM直接回答，不需要工具</span><br><span class="line">print(&quot;--- 场景一：LLM直接回答 ---&quot;)</span><br><span class="line">response1 = llm_with_tools.invoke([HumanMessage(content=&quot;Hello, what&#x27;s your name?&quot;)])</span><br><span class="line">print(response1.content) # LLM直接生成文本回复</span><br><span class="line"></span><br><span class="line">print(&quot;\n--- 场景二：LLM决定调用工具 ---&quot;)</span><br><span class="line"># 场景二：LLM决定调用工具</span><br><span class="line"># 当LLM的响应中包含tool_calls时，意味着它想要调用一个或多个工具</span><br><span class="line">response2 = llm_with_tools.invoke([HumanMessage(content=&quot;What is 15 + 27?&quot;)])</span><br><span class="line">print(response2.tool_calls) # 打印LLM决定调用的工具信息</span><br><span class="line"></span><br><span class="line"># 检查并执行LLM建议的工具调用</span><br><span class="line">if response2.tool_calls:</span><br><span class="line">    for tool_call in response2.tool_calls:</span><br><span class="line">        if tool_call[&#x27;name&#x27;] == &quot;add_numbers&quot;:</span><br><span class="line">            # 提取LLM为工具调用生成的参数</span><br><span class="line">            args = tool_call[&#x27;args&#x27;]</span><br><span class="line">            result = add_numbers.invoke(args) # 执行工具</span><br><span class="line">            print(f&quot;Tool call: add_numbers(&#123;args[&#x27;a&#x27;]&#125;, &#123;args[&#x27;b&#x27;]&#125;) = &#123;result&#125;&quot;)</span><br><span class="line"></span><br><span class="line">            # 将工具的输出发送回LLM，让LLM基于结果生成最终回答</span><br><span class="line">            # 这是一个关键步骤，通常在Agent中自动处理。这里手动演示。</span><br><span class="line">            final_response = llm_with_tools.invoke([</span><br><span class="line">                HumanMessage(content=&quot;What is 15 + 27?&quot;),</span><br><span class="line">                AIMessage(content=&quot;&quot;, tool_calls=[tool_call]), # 告知LLM它之前建议的工具调用</span><br><span class="line">                ToolMessage(content=str(result), tool_call_id=tool_call[&#x27;id&#x27;]) # 告知LLM工具的执行结果</span><br><span class="line">            ])</span><br><span class="line">            print(&quot;Final LLM response based on tool output:&quot;)</span><br><span class="line">            print(final_response.content)</span><br></pre></td></tr></table></figure>
<h3 id="概念扫盲"><a href="#概念扫盲" class="headerlink" title="概念扫盲"></a>概念扫盲</h3><h4 id="Document-对象"><a href="#Document-对象" class="headerlink" title="Document 对象"></a>Document 对象</h4><p>Document 对象是 LangChain 用来封装和处理文本数据的基本单位。无论您是从 PDF、Markdown 文件、网站还是数据库加载数据，LangChain 都会将这些数据转换成一个或多个 Document 对象，以便在后续的流程中使用。</p>
<p>一个 Document 对象主要包含两个部分：</p>
<ol>
<li><p>page_content (字符串)</p>
<ul>
<li>这是文档对象的核心，存储了原始的文本内容。例如，如果加载一个 Markdown 文件， page_content 就会包含该文件的所有文本。</li>
</ul>
</li>
<li><p>metadata (字典)</p>
<ul>
<li>这是一个字典，用于存储关于文档的“元数据”或附加信息。这些信息对于过滤、追踪或增强文档处理流程非常有用。常见的元数据包括：<ul>
<li>source ：文档的来源，比如文件名、URL等。</li>
<li>page ：如果文档来自多页文件（如PDF），这里可以存储页码。</li>
<li>其他自定义信息：您可以添加任何有助于您应用的信息，如作者、创建日期等。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>除了通过文档加载器（Loaders）自动创建，您也可以手动创建一个 Document 对象。这在测试或处理简单文本时非常方便。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个简单的 Document 对象</span><br><span class="line">doc = Document(</span><br><span class="line">    page_content=&quot;这是文档的主要内容。LangChain 真酷！&quot;,</span><br><span class="line">    metadata=&#123;</span><br><span class="line">        &#x27;source&#x27;: &#x27;my_notebook.ipynb&#x27;,</span><br><span class="line">        &#x27;author&#x27;: &#x27;AI Assistant&#x27;,</span><br><span class="line">        &#x27;chapter&#x27;: 2</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="Runnable协议"><a href="#Runnable协议" class="headerlink" title="Runnable协议"></a>Runnable协议</h4><p><a target="_blank" rel="noopener" href="https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable">“Runnable”</a>协议</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV12TLAzuEni/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">2025最新版！langchain入门到精通实战教程！结合实战案例，干货拉满！99%的人不知道的暴利玩法，学完敢谷歌工程师叫板！_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.langchain.com.cn/docs/introduction/">introduction | LangChain中文网</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1XudVYzEcW?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">跟着官网学langchain2025(version 0.3)_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.langchain.com/langgraph-platform">LangGraph Platform - Docs by LangChain</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langsmith/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langsmith/" class="post-title-link" itemprop="url">Langsmith</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-07-15 00:00:00 / 修改时间：17:55:00" itemprop="dateCreated datePublished" datetime="2025-07-15T00:00:00+08:00">2025-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langsmith/" itemprop="url" rel="index"><span itemprop="name">langsmith</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="配置langsmith">配置langsmith</h3>
<h4 id="安装langsmith-sdk">安装LangSmith SDK</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install langsmith</span><br></pre></td></tr></table></figure>
<h4 id="环境变量">环境变量</h4>
<p>获取api<a target="_blank" rel="noopener" href="https://smith.langchain.com/o/56031c2a-c402-41d4-83ed-ed15d0693548/settings/apikeys">LangSmith</a></p>
<p>设置相应的环境变量。这将把跟踪记录到<code>default</code>项目（尽管您可以轻松更改）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export LANGSMITH_TRACING=true</span><br><span class="line">export LANGSMITH_API_KEY=</span><br><span class="line">export LANGSMITH_PROJECT=default</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">LANGSMITH_TRACING=true</span><br><span class="line">LANGSMITH_ENDPOINT=&quot;https://api.smith.langchain.com&quot;</span><br><span class="line">LANGSMITH_API_KEY=&quot;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&quot;</span><br><span class="line">LANGSMITH_PROJECT=&quot;langgraph&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="资源">资源</h3>
<p>官网<a target="_blank" rel="noopener" href="https://smith.langchain.com/o/56031c2a-c402-41d4-83ed-ed15d0693548/">《LangSmith》
— LangSmith</a></p>
<p>参考文档<a target="_blank" rel="noopener" href="https://langsmith.langchain.ac.cn/">LangSmith 入门 |
🦜️🛠️ LangSmith 文档</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.smith.langchain.com/">Get started with
LangSmith | 🦜️🛠️ LangSmith</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">张熙浚</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="本站访问数 fa fa-user 次"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="本站总访问量 fa fa-eye 次"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="400" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
