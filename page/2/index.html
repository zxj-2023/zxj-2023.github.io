<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="zxj Blogs">
<meta property="og:type" content="website">
<meta property="og:title" content="Zhang XiJun">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Zhang XiJun">
<meta property="og:description" content="zxj Blogs">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="张熙浚">
<meta property="article:tag" content="zxj">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Zhang XiJun</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhang XiJun</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">BLOGS</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="张熙浚"
      src="/images/zxjavatar.gif">
  <p class="site-author-name" itemprop="name">张熙浚</p>
  <div class="site-description" itemprop="description">zxj Blogs</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">132</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">56</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zxj-2023" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxj-2023" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=2902065320&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;2902065320&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener me" target="_blank"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zxj-2023.github.io/" title="https:&#x2F;&#x2F;zxj-2023.github.io" rel="noopener" target="_blank">Zhang XiJun</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org" rel="noopener" target="_blank">NexT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/" class="post-title-link" itemprop="url">模型微调——LoRA</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-08-11 00:00:00" itemprop="dateCreated datePublished" datetime="2025-08-11T00:00:00+08:00">2025-08-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-12 19:15:14" itemprop="dateModified" datetime="2025-08-12T19:15:14+08:00">2025-08-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="index"><span itemprop="name">模型</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E8%B0%83/" itemprop="url" rel="index"><span itemprop="name">微调</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="为什么要微调">为什么要微调</h3>
<p>预训练大模型在海量通用语料上学到的知识，在垂直场景（医疗、法律、零售客服等）里往往“泛而浅”。</p>
<p>从零训练一个同等规模的大模型成本极高（千卡周级别），而微调只需在已有权重上做小步调整，算力/数据量都指数级下降。</p>
<h3 id="什么是全量微调">什么是全量微调</h3>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811104846104.png" alt="image-20250811104846104">
<figcaption aria-hidden="true">image-20250811104846104</figcaption>
</figure>
<p>全量微调（full
fine-tuning）通俗来说，对于参数的每一个权重，都要学习一个新的值（或者偏移量），更新所有
Transformer 层里的权重矩阵（包括
embedding、attention、FFN），这样的开销是很大的。</p>
<h3 id="什么是lora">什么是LoRA</h3>
<p>LoRA（Low-Rank
Adaptation，低秩适配）是一种<strong>参数高效微调（PEFT）</strong>技术，核心目的：
<strong>“冻结大模型 99 %
以上原始权重，只额外训练极少量低秩矩阵，就能让模型在下游任务上达到近似全量微调的效果。”</strong></p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811105145633.png" alt="image-20250811105145633">
<figcaption aria-hidden="true">image-20250811105145633</figcaption>
</figure>
<p>通俗来说，通过学习两个低秩的矩阵，来近似于完整的矩阵，如图，W=A*B，矩阵相乘</p>
<p>在实际应用中，<strong>LoRA可以直接和transformer的FFN层（线性层）对齐</strong></p>
<p>Transformer 模型的核心是注意力机制，其中涉及到 Query, Key, Value
的计算，这些都是线性变换。</p>
<p>在标准的注意力机制中，计算公式为：</p>
<p><span class="math display">$$
\text{Attention}(Q, K, V) =
\text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$</span></p>
<p>其中 <span class="math inline"><em>Q</em></span>, <span class="math inline"><em>K</em></span>, <span class="math inline"><em>V</em></span> 的计算为：</p>
<p><span class="math display"><em>Q</em> = <em>X</em><sub><em>Q</em></sub><em>W</em><sub><em>Q</em></sub>,  <em>K</em> = <em>X</em><sub><em>K</em></sub><em>W</em><sub><em>K</em></sub>,  <em>V</em> = <em>X</em><sub><em>V</em></sub><em>W</em><sub><em>V</em></sub></span></p>
<p><span class="math inline"><em>X</em><sub><em>Q</em></sub></span>,
<span class="math inline"><em>X</em><sub><em>K</em></sub></span>, <span class="math inline"><em>X</em><sub><em>V</em></sub></span>
的输入可以相同，也可以不同。例如，在 Cross-Attention
中，解码器的隐藏状态作为 <span class="math inline"><em>X</em><sub><em>Q</em></sub></span>，编码器的输出作为
<span class="math inline"><em>X</em><sub><em>K</em></sub></span> 和
<span class="math inline"><em>X</em><sub><em>V</em></sub></span>。</p>
<p><strong>LoRA 可以应用到 <span class="math inline"><em>W</em><sub><em>Q</em></sub></span>, <span class="math inline"><em>W</em><sub><em>K</em></sub></span>, <span class="math inline"><em>W</em><sub><em>V</em></sub></span>
上，采用与线性层类似的方式</strong>。</p>
<h3 id="为什么要用lora">为什么要用lora</h3>
<p>首先要理解低秩：秩可以理解成一个矩阵所代表的信息，低秩矩阵，便是带有少量信息的矩阵，当然这样的矩阵计算效率是更高的，</p>
<p>在全量微调中，由于训练一个完整的矩阵开销是非常大的；在lora中就通过训练低秩矩阵，来近似<strong>模型权重更新</strong>的效果</p>
<blockquote>
<p>若模型参数比较小，使用冻结部分参数或全量微调的方式，往往更好</p>
</blockquote>
<p>初学者不禁会思考，这样难道不会损失信息导致大模型的性能变差吗？但是，实验下来效果还是不错的，通过牺牲一点性能，来换取开销的大幅度减少</p>
<blockquote>
<p>LoRA 原文实验 在 GPT-3 175 B 上，仅用 rank 4 的 LoRA 就能在全量微调
99 % 参数量的情况下，保持 97 % 的下游指标。</p>
</blockquote>
<h3 id="什么是qlora">什么是QLoRA</h3>
<p>QLoRA（Quantized Low-Rank Adaptation，量化低秩适应）是 <strong>LoRA
的“极致省内存”版本</strong>。它把 LoRA
的“低秩增量”思路再往前推一步：<strong>先把整个底座模型权重压到
4-bit，再在上面做 LoRA 微调</strong>。</p>
<p>QLoRA 是另一个热门术语，它与 LoRA
之间的唯一区别在于首字母“Q”，代表“量化（quantized）”。“量化”一词指的是用来减少存储神经元权重的比特数。</p>
<p>例如，神经网络的权重通常以浮点数表示，每个权重需要 32
位。量化的思想是将神经网络的权重压缩为更低的精度，而不会显著损失模型性能或产生重大影响。因此，不再使用
32 位，而是可以舍弃部分比特，例如只用 16 位。</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811142432782.png" alt="image-20250811142432782">
<figcaption aria-hidden="true">image-20250811142432782</figcaption>
</figure>
<h3 id="微调工具的介绍">微调工具的介绍</h3>
<h4 id="unsloth">unsloth</h4>
<p><a target="_blank" rel="noopener" href="https://github.com/unslothai/unsloth?tab=readme-ov-file">unslothai/unsloth:
Fine-tuning &amp; Reinforcement Learning for LLMs. 🦥 Train OpenAI
gpt-oss, Qwen3, Llama 4, DeepSeek-R1, Gemma 3, TTS 2x faster with 70%
less VRAM.</a></p>
<p>unsloth是一个专为大型语言模型（LLM）设计的动态量化与微调框架，旨在提高微调效率并减少显存占用，因此主要用于单机单卡的模型微调。</p>
<p>值得一提的是，Unsloth动态量化模型：https://unsloth.ai/blog/dynamic-v2</p>
<p>Unsloth的动态量化方法，特别是其最新的Dynamic
2.0版本，旨在在尽量减少性能损失的同时显著压缩大型语言模型（LLMs）的体积。对于Qwen3模型，尤其是4-bit动态量化版本，现有的评测显示其性能下降非常有限，甚至在某些任务上与原始模型相当。</p>
<blockquote>
<p>Unsloth 的「动态量化」可以一句话概括为：
<strong>“按层、按敏感度自动决定每块权重到底用 2.5 / 3.5 / 4 / 6 / 8 / 32
bit 的精细化量化策略，而不是一股脑全量化到 4 bit。”</strong></p>
</blockquote>
<p>这也使得Unsloth的动态量化模型成为<strong>个人配置</strong>下的最佳微调工具。</p>
<p>不过需要注意的是，动态量化由利也有弊，其<strong>好处在于可以极大程度压缩模型运行所需占用的显存大小，同时几乎不损失性能</strong>，但问题在于动态量化的模型，无论是推理还是微调，<strong>只能单卡运行</strong>，这就使得其吞吐量有限，无法在一台物理机上实现多GPU并行从而扩大吞吐量。</p>
<h4 id="llama-factory"><strong>LLaMA Factory</strong></h4>
<p><a target="_blank" rel="noopener" href="https://github.com/hiyouga/LLaMA-Factory/tree/main">hiyouga/LLaMA-Factory:
Unified Efficient Fine-Tuning of 100+ LLMs &amp; VLMs (ACL 2024)</a></p>
<p>LLaMA Factory
是一个简单易用且高效的大型语言模型训练与微调平台。通过它，用户可以在无需编写任何代码的前提下，在本地完成上百种预训练模型的微调。</p>
<p>LLaMA Factory 提供了API Server 和一站式 WebUI
Board，方便企业进行模型的管理和部署。适合不会写代码或代码基础比较弱的同学快速上手进行微调。</p>
<h4 id="其他">其他</h4>
<p>ms-SWIFT GitHub项目主页：https://github.com/modelscope/swift</p>
<p>ColossalAI
GitHub项目主页：https://github.com/hpcaitech/ColossalAI</p>
<p>除此之外，也可以借助更加底层的库，如peft、LoRA、transformer等实现高效微调。</p>
<h3 id="模型性能评估框架">模型性能评估框架</h3>
<h4 id="evalscope">EvalScope</h4>
<p>项目地址： https://github.com/modelscope/evalscope</p>
<p>EvalScope
是由阿里巴巴魔搭社区（ModelScope）推出的一款开源模型评估框架，旨在为大语言
模型（LLM）和多模态模型提供统一、系统化的性能评估方案。该框架具备高度的自动化和可扩展性，
适用于研究机构、工业界以及模型开发者在模型验证与性能对比场景中的广泛需求。</p>
<h3 id="可视化框架">可视化框架</h3>
<h4 id="wandb">wandb</h4>
<p><strong>Weights &amp; Biases（简称 wandb）</strong>
是一个专为机器学习 / 深度学习设计的
<strong>云端实验管理、可视化与协作平台</strong>。它帮你把“训练过程中发生了什么”全部自动化地记录下来，并以网页仪表盘的形式实时展示，省去你手动保存日志、画图、整理表格的麻烦。</p>
<p>wandb官网： https://wandb.ai/site</p>
<h4 id="swanlab">swanlab</h4>
<p>SwanLab 是一款<strong>开源、轻量</strong>的 AI
模型训练跟踪与可视化工具，提供了一个<strong>跟踪、记录、比较、和协作实验</strong>的平台。</p>
<p>SwanLab 面向人工智能研究者，设计了友好的Python API
和漂亮的UI界面，并提供<strong>训练可视化、自动日志记录、超参数记录、实验对比、多人协同等功能</strong>。在SwanLab上，研究者能基于直观的可视化图表发现训练问题，对比多个实验找到研究灵感，并通过<strong>在线网页</strong>的分享与基于组织的<strong>多人协同训练</strong>，打破团队沟通的壁垒，提高组织训练效率。</p>
<p><a target="_blank" rel="noopener" href="https://docs.swanlab.cn/">SwanLab官方文档 |
先进的AI团队协作与模型创新引擎</a></p>
<h3 id="构造微调数据集">构造微调数据集</h3>
<h4 id="为什么要构造微调数据集">为什么要构造微调数据集</h4>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811162229104.png" alt="image-20250811162229104">
<figcaption aria-hidden="true">image-20250811162229104</figcaption>
</figure>
<p>其中 &lt;∣im_start∣&gt;
代表文本开始,而user则代表消息身份,用于构建多轮对话,而<lim_end>则代表文本结束,即用户输入结束,而<lim_start>代表新一段文本开始,assistant代表接下来由模型创建消息,而<lim_end>同样代表模型创建消息的结束。</lim_end></lim_start></lim_end></p>
<p>而模型其实是通过这样一组<strong>特殊字符标记</strong>来规范自己的行为,<strong>判断当前消息类型,以及通过输出特殊标记来确定停止时间</strong>。对于绝大多数模型,我们可以在模型的<strong>tokenizer_config.json中看到完整的特殊标记符</strong>(以及系统提示词模板):</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811163120092.png" alt="image-20250811163120092">
<figcaption aria-hidden="true">image-20250811163120092</figcaption>
</figure>
<p>而在实际微调过程中,我们都知道需要<strong>有监督的数据集</strong>、也就是需要输入QA对来进行微调。以著名的<strong>alpaca_zh中文微调数据集</strong>来说,其基本格式如下:</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811163232521.png" alt="image-20250811163232521">
<figcaption aria-hidden="true">image-20250811163232521</figcaption>
</figure>
<p>就可以表示为下列json格式数据集:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json&#123;  &quot;instruction&quot;: &quot;&quot;,  &quot;input&quot;: &quot;输入:你好。&quot;,  &quot;output&quot;: &quot;输出:你好,有什么可以帮到你的?&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>而在真实的微调过程中,如果是针对Qwen3进行微调,微调脚本会将这条数据集(无论什么格式)转化为如下格式:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xml&lt;im_start|&gt;user\n你好&lt;im_end|&gt;\n&lt;im_start|&gt;assistant\n你好,有什么可以帮到你的?&lt;im_end|&gt;</span><br></pre></td></tr></table></figure>
<p>而在实际训练过程中,模型就会根据assistant前的内容,学习assistant后面的输出内容。</p>
<p><strong>因此我们要在下载数据集后，进行微调前，对数据集进行预处理</strong>，接下来引出构造数据集的几种场景</p>
<h4 id="带有系统提示微调数据集格式">带有系统提示微调数据集格式</h4>
<p>在很多场景下,我们还会发现一些<strong>带有instruction字段的微调数据集</strong>,那instruction字段是如何带入到微调过程中的呢?</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811163232521.png" alt="image-20250811163232521">
<figcaption aria-hidden="true">image-20250811163232521</figcaption>
</figure>
<p>答案非常简单,还是依靠特殊字符。例如有一个对话内容如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 系统提示词(instruction):你是一名助人为乐的助手。</span><br><span class="line">- 用户输入(input):你好,好久不见。</span><br><span class="line">- 助手回复(output):是的呀,好久不见,最近有什么有趣的事情要和我分享么?</span><br></pre></td></tr></table></figure>
<p>此时模型的输入和输出如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;lim_start|&gt;system你是一名助人为乐的助手。&lt;/im_end&gt;</span><br><span class="line">&lt;lim_start|&gt;user 你好,好久不见。&lt;/lim_end&gt;</span><br><span class="line">&lt;lim_start|&gt;assistant 是的呀,好久不见,最近有什么有趣的事情要和我分享么?&lt;/lim_end&gt;</span><br></pre></td></tr></table></figure>
<p>即会通过&lt;lim_start|&gt;system…&lt;lim_end|&gt;来标记系统提示词。实际进行微调时,模型会根据assistant为界,学习assistant之前的文本输入情况下应该如何输出。</p>
<h4 id="带function-calling微调数据集格式">带Function
calling微调数据集格式</h4>
<p>更进一步的,如果对话过程中带入了<strong>Function
calling</strong>,此时首先模型会读取提前准备好的tool
schema(也可能是自动生成的,例如MCP即可自动创建tool schema):</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;tool_schema&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;get_weather&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;查询指定城市的天气信息&quot;,</span><br><span class="line">      &quot;parameters&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;object&quot;,</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">          &quot;location&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">            &quot;description&quot;: &quot;要查询天气的城市名称&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;required&quot;: [&quot;location&quot;]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而假设我们的对话内容如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 系统提示词(instruction):你是一名助人为乐的助手。当用户查询天气的时候,请调用get_weather函数进行天气信息查询。</span><br><span class="line">- 用户输入(input):你好,请帮我查询下北京天气。</span><br><span class="line">- 助手回复(output):&#123;&quot;name&quot;: &quot;get_weather&quot;, &quot;arguments&quot;: &#123;&quot;location&quot;: &quot;北京&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>此时回复内容就是一条Function call message</p>
</blockquote>
<p>而此时模型真实的输入和输出内容如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;|im_start|&gt;system</span><br><span class="line">你是天气助手，当用户查询天气时请调用 get_weather 函数。</span><br><span class="line"># Tools</span><br><span class="line">You may call one or more functions to assist with the user query.</span><br><span class="line">You are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:</span><br><span class="line">&lt;tools&gt;</span><br><span class="line">[&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;description&quot;:&quot;查询指定城市的天气信息&quot;,&quot;parameters&quot;:&#123;&quot;type&quot;:&quot;object&quot;,&quot;properties&quot;:&#123;&quot;location&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;description&quot;:&quot;要查询天气的城市名称&quot;&#125;&#125;,&quot;required&quot;:[&quot;location&quot;]&#125;&#125;]</span><br><span class="line">&lt;/tools&gt;</span><br><span class="line">&lt;tool_call&gt;</span><br><span class="line"> &#123;&quot;name&quot;: &lt;function-name&gt;, &quot;arguments&quot;: &lt;args-json-object&gt;&#125;</span><br><span class="line">&lt;/tool_call&gt;.</span><br><span class="line">&lt;|im_end|&gt;</span><br><span class="line">&lt;|im_start|&gt;user</span><br><span class="line">北京天气如何？</span><br><span class="line">&lt;|im_end|&gt;</span><br><span class="line">&lt;|im_start|&gt;assistant</span><br><span class="line">&lt;tool_call&gt;&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;arguments&quot;:&#123;&quot;location&quot;:&quot;北京&quot;&#125;&#125;&lt;/tool_call&gt;</span><br><span class="line">&lt;|im_end|&gt;</span><br></pre></td></tr></table></figure>
<p>接下来在进行训练时,模型同样根据assistant前的内容,学习assistant后面的输出内容。不过需要注意的是,由于高效微调调整的参数量较少,因此只能优化模型的Function
calling能力,并不能从无到有让模型学会Function calling。</p>
<h4 id="带有思考过程的微调数据集结构">带有思考过程的微调数据集结构</h4>
<p>而如果是带有思考链,则一个简单的问答数据如下:</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811165802090.png" alt="image-20250811165802090">
<figcaption aria-hidden="true">image-20250811165802090</figcaption>
</figure>
<ul>
<li>系统提示词(instruction):你是一名助人为乐的助手。</li>
<li>用户输入(input):你好,好久不见。</li>
<li>助手回复(output):好的,用户发来“你好,好久不见!”,我需要回应。首先,用户可能希望得到亲切的回应,所以应该用友好的语气。/n是的呀,好久不见,最近有什么有趣的事情要和我分享么?</li>
</ul>
<p>此时模型真实的内部输入和输出结果如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;lim_start|&gt;system</span><br><span class="line">你是一名助人为乐的助手。&lt;lim_end|&gt;</span><br><span class="line">&lt;lim_start|&gt;user</span><br><span class="line">你好,好久不见。&lt;lim_end|&gt;</span><br><span class="line">&lt;lim_start|&gt;assistant</span><br><span class="line"></span><br><span class="line">&lt;think&gt;  好的,用户发来“你好,好久不见!”,我需要回应。首先,用户可能希望得到亲切的回应,所以应该用友好的语气。&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">是的呀,好久不见,最近有什么有趣的事情要和我分享么?&lt;/lim_end|&gt;</span><br></pre></td></tr></table></figure>
<p>模型同样根据assistant前的内容,学习assistant后面的输出内容。也就是说,所谓的思考过程,本质上其实是一种文本响应格式,通过模型训练而来。</p>
<h4 id="混合推理模型构造微调数据集基本方法">混合推理模型构造微调数据集基本方法</h4>
<p>在了解了微调数据集结构背后的基本原理后,接下来的问题是应该如何构造微调数据集呢?</p>
<p>一般来说我们可以在huggingface、ModelScope或llama-
factory中挑选合适的数据集,并根据实际情况进行组装。</p>
<p>例如围绕Qwen3模型的高效微调,为了确保其仍然<strong>保留混合推理能力,</strong>我们可以考虑在微调数据集中加入如普<strong>通对话数据集</strong><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/mlabonne/FineTome-100k">FineTome</a>,以及<strong>带有推理字段的数学类数据集</strong><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/nvidia/OpenMathReasoning">OpenMathReasoning</a>,<strong>并围绕这两个数据集进行拼接</strong>,从而在确保能提升模型的数学能力的同时,保留非推理的功能。</p>
<p>同时还需要在持续微调训练过程中<strong>不断调整COT数学数据集和普通文本问答数据集之间的配比</strong>,以确保模型能够在提升数学能力的同时,保留混合推理的性能。</p>
<blockquote>
<p>Qwen3 的「混合推理能力」=
<strong>在同一个模型里内置两套“大脑”</strong>： •
<strong>快思考（非思考模式）</strong>：轻量算力、秒级响应，适合简单问答；
•
<strong>慢思考（思考模式）</strong>：多步链式推理、深度推敲，适合复杂逻辑、数学、代码。
系统会自动或按用户指令在两种模式之间 <strong>动态切换</strong>，从而
<strong>既省算力又保证难题精度</strong>。</p>
</blockquote>
<h3 id="微调的基本流程">微调的基本流程</h3>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250812105535330.png" alt="image-20250812105535330">
<figcaption aria-hidden="true">image-20250812105535330</figcaption>
</figure>
<h3 id="环境配置">环境配置</h3>
<p><strong>安装Unsloth</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo</span><br></pre></td></tr></table></figure>
<p><strong>安装Qwen3-8B-unsloth-bnb-4bit</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modelscope download --model unsloth/Qwen3-8B-unsloth-bnb-4bit --local_dir /workspace/qwen3-8b</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#模型下载</span><br><span class="line">from modelscope import snapshot_download</span><br><span class="line">model_dir = snapshot_download(&#x27;unsloth/Qwen3-8B-unsloth-bnb-4bit&#x27;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>unsloth/Qwen3-8B-unsloth-bnb-4bit</strong> 这个模型它是
<strong>专门为Unsloth微调框架优化过的4bit量化版本</strong></p>
<p>原始 Qwen3-8B（FP16）需要约 <strong>22GB 显存</strong>，而 4bit
量化后仅需 <strong>6GB 左右</strong></p>
<p><strong>只要显存允许，原始 FP16/BF16 模型也可以用 Unsloth 做 4-bit
LoRA（即 QLoRA）微调；官方预量化 4-bit
模型只是帮你把“量化”这一步提前做完了，二者本质相同。</strong></p>
<p><strong>Unsloth 的两种用法示例</strong></p>
<table>
<colgroup>
<col style="width: 30%">
<col style="width: 42%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">场景</th>
<th style="text-align: left;">代码片段</th>
<th style="text-align: left;">备注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">A. 用官方已量化好的 4-bit 权重</td>
<td style="text-align: left;"><code>model_name="unsloth/Qwen3-8B-bnb-4bit"</code></td>
<td style="text-align: left;">显卡 6 GB 就能跑，省去自己量化</td>
</tr>
<tr class="even">
<td style="text-align: left;">B. 用原始 FP16 权重并现场 4-bit 量化</td>
<td style="text-align: left;"><code>model_name="Qwen/Qwen3-8B"</code> +
<code>load_in_4bit=True</code></td>
<td style="text-align: left;">显卡仍需 6 GB，显存占用与 A 相同</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两种写法效果等价</span></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name=<span class="string">&quot;Qwen/Qwen3-8B&quot;</span>,   <span class="comment"># 原始权重</span></span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,            <span class="comment"># 现场量化到 4-bit</span></span><br><span class="line">    max_seq_length=<span class="number">2048</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>安装EvalScope</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">pip install evalscope                </span><br><span class="line"># 安装 Native backend (默认)</span><br><span class="line"> # 额外选项</span><br><span class="line">pip install &#x27;evalscope[opencompass]&#x27;   # 安装 OpenCompass backend</span><br><span class="line"> pip install &#x27;evalscope[vlmeval]&#x27;       </span><br><span class="line"># 安装 VLMEvalKit backend</span><br><span class="line"> pip install &#x27;evalscope[rag]&#x27;           </span><br><span class="line">pip install &#x27;evalscope[perf]&#x27;          </span><br><span class="line">pip install &#x27;evalscope[app]&#x27;           </span><br><span class="line"># 或可以直接输入all，安装全部模块</span><br><span class="line"># pip install &#x27;evalscope[all]&#x27;           </span><br><span class="line"># 安装 RAGEval backend</span><br><span class="line"> # 安装 模型压测模块 依赖</span><br><span class="line"># 安装 可视化 相关依赖</span><br><span class="line"># 安装所有 backends (Native, OpenCompass, </span><br><span class="line">VLMEvalKit, RAGEval)</span><br></pre></td></tr></table></figure>
<p><strong>安装wandb</strong></p>
<p>wandb官网： https://wandb.ai/site</p>
<p>安装wandb：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install wandb</span><br></pre></td></tr></table></figure>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/SwanHubX/SwanLab?tab=readme-ov-file#-快速开始">SwanHubX/SwanLab:
⚡️SwanLab - an open-source, modern-design AI training tracking and
visualization tool. Supports Cloud / Self-hosted use. Integrated with
PyTorch / Transformers / LLaMA Factory / veRL/ Swift / Ultralytics /
MMEngine / Keras etc.</a></p>
<p>与其类似，一个开源、现代化设计的深度学习训练跟踪与可视化工具</p>
</blockquote>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV13BKozLEXE/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">DIY你的AI梦中情人？Qwen3微调手把手教你！_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1tthPeFEWb/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">通俗易懂理解全量微调和LoRA微调_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1DT421r7Et?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">通俗易懂理解大模型预训练和微调_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1YLE1zyEvX?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=3">3.四大微调框架及微调硬件环境介绍_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1s2AUe2EBq/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">如何把你的
DeePseek-R1 微调为某个领域的专家？（实战篇）_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/javatiange/article/details/149964743?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=149964743&amp;sharerefer=PC&amp;sharesource=2501_91530961&amp;sharefrom=from_link">一文详解：8种常见的大模型微调方法，看这篇就够了！-CSDN博客</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/" class="post-title-link" itemprop="url">大模型训练流程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-08-11 00:00:00 / 修改时间：09:55:54" itemprop="dateCreated datePublished" datetime="2025-08-11T00:00:00+08:00">2025-08-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="index"><span itemprop="name">模型</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E8%B0%83/" itemprop="url" rel="index"><span itemprop="name">微调</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="什么是大模型">什么是大模型</h3>
<p>随着2022年底 ChatGPT 再一次刷新 NLP
的能力上限，大<strong>语言模型（Large Language
Model，LLM）开始接替传统的预训练语言模型（Pre-trained Language
Model，PLM）</strong> 成为 NLP 的主流方向，基于 LLM
的全新研究范式也正在刷新被 BERT
发扬光大的<strong>预训练-微调范式</strong>，NLP
由此迎来又一次翻天覆地的变化。</p>
<p>LLM，即 Large Language
Model，中文名为大语言模型或大型语言模型，是一种相<strong>较传统语言模型参数量更多、在更大规模语料上进行预训练的语言模型</strong>。</p>
<p>一般来说，LLM
指包含<strong>数百亿（或更多）参数的语言模型</strong>，它们往往在<strong>数
T token
语料上</strong>通过多卡分布式集群进行预训练，具备远超出传统预训练模型的文本理解与生成能力。不过，随着
LLM 研究的不断深入，多种参数尺寸的 LLM 逐渐丰富，广义的 LLM
一般覆盖了从<strong>十亿参数</strong>（如
Qwen-1.5B）到<strong>千亿参数</strong>（如
Grok-314B）的所有大型语言模型。只要模型展现出<strong>涌现能力</strong>，即在一系列复杂任务上表现出远超传统预训练模型（如
BERT、T5）的能力与潜力，都可以称之为 LLM。</p>
<p>一般认为，GPT-3（1750亿参数）是 LLM 的开端，基于 GPT-3 通过
<strong>预训练（Pretraining）、监督微调（Supervised
Fine-Tuning，SFT）、强化学习与人类反馈（Reinforcement Learning with
Human Feedback，RLHF）</strong>三阶段训练得到的 ChatGPT 更是主导了 LLM
时代的到来。</p>
<blockquote>
<p>区分 LLM 与传统 PLM 最显著的特征即是 LLM 具备 <code>涌现能力</code>
。涌现能力是指同样的模型架构与预训练任务下，某些能力在小型模型中不明显，但在大型模型中特别突出。</p>
</blockquote>
<h3 id="训练流程">训练流程</h3>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/image-20250811092459843.png" alt="image-20250811092459843">
<figcaption aria-hidden="true">image-20250811092459843</figcaption>
</figure>
<p>一般而言，训练一个完整的 LLM 需要经过图1中的三个阶段——Pretrain、SFT
和 RLHF。</p>
<h3 id="pretrain">Pretrain</h3>
<p>Pretrain，即预训练，是训练 LLM 最核心也是工程量最大的第一步。</p>
<h4 id="参数">参数</h4>
<table style="width:100%;">
<colgroup>
<col style="width: 16%">
<col style="width: 21%">
<col style="width: 18%">
<col style="width: 8%">
<col style="width: 16%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>模型</th>
<th>hidden_layers</th>
<th>hidden_size</th>
<th>heads</th>
<th>整体参数量</th>
<th>预训练数据量</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>BERT-base</td>
<td>12</td>
<td>768</td>
<td>12</td>
<td>0.1B</td>
<td>3B</td>
</tr>
<tr class="even">
<td>BERT-large</td>
<td>24</td>
<td>1024</td>
<td>16</td>
<td>0.3B</td>
<td>3B</td>
</tr>
<tr class="odd">
<td>Qwen-1.8B</td>
<td>24</td>
<td>2048</td>
<td>16</td>
<td>1.8B</td>
<td>2.2T</td>
</tr>
<tr class="even">
<td>LLaMA-7B</td>
<td>32</td>
<td>4096</td>
<td>32</td>
<td>7B</td>
<td>1T</td>
</tr>
<tr class="odd">
<td>GPT-3</td>
<td>96</td>
<td>12288</td>
<td>96</td>
<td>175B</td>
<td>300B</td>
</tr>
</tbody>
</table>
<p>根据定义，LLM
的核心特点即在于其具有<strong>远超传统预训练模型的参数量</strong>，<strong>同时在更海量的语料上进行预训练</strong>。传统预训练模型如
BERT，有 base 和 large 两个版本。BERT-base 模型由 12个 Encoder
层组成，其 hidden_size 为 768，使用 12个头作为多头注意力层，整体参数量为
1亿（110M）；而 BERT-large 模型由 24个 Encoder 层组成，hidden_size 为
1024，有 16个头，整体参数量为 3亿（340M）。同时，BERT 预训练使用了
33亿（3B）token 的语料，在 64块 TPU 上训练了
4天。事实上，相对于传统的深度学习模型，3亿参数量、33亿训练数据的 BERT
已经是一个能力超群、资源消耗巨大的庞然大物。</p>
<p>但是，前面我们提到，<strong>一般而言的 LLM
通常具有数百亿甚至上千亿参数</strong>，即使是广义上最小的
LLM，一般也有十亿（1B）以上的参数量。例如以开山之作 GPT-3 为例，其有
96个 Decoder 层，12288 的 hidden_size 和 96个头，<strong>共有
1750亿（175B）参数，比 BERT 大出快
3个数量级</strong>。即使是目前流行的小型 LLM 如 Qwen-1.8B，其也有 24个
Decoder 层、2048的 hidden_size 和 16个注意力头，整体参数量达到
18亿（1.8B）。</p>
<h4 id="分布式训练">分布式训练</h4>
<p>也正因如此，<strong>分布式训练框架也成为 LLM
训练必不可少的组成部分</strong>。分布式训练框架的核心思路是<strong>数据并行和模型并行</strong>。所谓数据并行，是指训练模型的尺寸可以被单个
GPU 内存容纳，但是由于增大训练的 batch_size
会增大显存开销，无法使用较大的 batch_size
进行训练；同时，训练数据量非常大，使用单张 GPU 训练时长难以接受。</p>
<h4 id="数据集">数据集</h4>
<p><strong>训练数据本身也是预训练 LLM 的一个重大挑战</strong>。训练一个
LLM，至少需要数百 B 甚至上 T 的预训练语料。根据研究，LLM
所掌握的知识绝大部分都是在预训练过程中学会的，因此，为了使训练出的 LLM
能够覆盖尽可能广的知识面，预训练语料需要组织多种来源的数据，并以一定比例进行混合。目前，主要的开源预训练语料包括
CommonCrawl、C4、Github、Wikipedia 等。<strong>不同的 LLM
往往会在开源预训练语料基础上，加入部分私有高质量语料，再基于自己实验得到的最佳配比来构造预训练数据集</strong>。事实上，<strong>数据配比</strong>向来是预训练
LLM
的“核心秘籍”，不同的配比往往会相当大程度影响最终模型训练出来的性能。</p>
<p>训练一个中文
LLM，训练数据的难度会更大。目前，高质量语料还是大部分集中在英文范畴，例如上表的
Wikipedia、Arxiv 等，均是英文数据集；而 C4
等多语言数据集中，英文语料也占据主要地位。目前开源的中文 LLM 如
ChatGLM、Baichuan
等模型均未开放其预训练数据集，开源的中文预训练数据集目前仅有昆仑天工开源的<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/Skywork/SkyPile-150B">SkyPile</a>（150B）、中科闻歌开源的<a target="_blank" rel="noopener" href="https://huggingface.co/datasets/wenge-research/yayi2_pretrain_data">yayi2</a>（100B）等，相较于英文开源数据集有明显差距。</p>
<h4 id="数据清洗">数据清洗</h4>
<p><strong>预训练数据的处理与清洗</strong>也是 LLM
预训练的一个重要环节。诸多研究证明，预训练数据的质量往往比体量更加重要。预训练数据处理一般包括以下流程：</p>
<ol type="1">
<li>文档准备。由于海量预训练语料往往是从互联网上获得，一般需要从爬取的网站来获得自然语言文档。文档准备主要包括
URL 过滤（根据网页 URL 过滤掉有害内容）、文档提取（从 HTML
中提取纯文本）、语言选择（确定提取的文本的语种）等。</li>
<li>语料过滤。语料过滤的核心目的是去除低质量、无意义、有毒有害的内容，例如乱码、广告等。语料过滤一般有两种方法：基于模型的方法，即通过高质量语料库训练一个文本分类器进行过滤；基于启发式的方法，一般通过人工定义
web 内容的质量指标，计算语料的指标值来进行过滤。</li>
<li>语料去重。实验表示，大量重复文本会显著影响模型的泛化能力，因此，语料去重即删除训练语料中相似度非常高的文档，也是必不可少的一个步骤。去重一般基于
hash
算法计算数据集内部或跨数据集的文档相似性，将相似性大于指定阈值的文档去除；也可以基于子串在序列级进行精确匹配去重。</li>
</ol>
<h3 id="sft-指令微调">SFT 指令微调</h3>
<p>预训练赋予了 LLM 能力，却还需要第二步将其激发出来。经过预训练的 LLM
好像一个博览群书但又不求甚解的书生，对什么样的偏怪问题，都可以流畅地接出下文，但他偏偏又<strong>不知道问题本身的含义</strong>，只会“死板背书”。这一现象的本质是因为，LLM
的预训练任务就是经典的
<strong>CLM</strong>，也就是训<strong>练其预测下一个 token
的能力</strong>，在没有进一步微调之前，其无法与其他下游任务或是用户指令适配。</p>
<p>因此，我们还需要第二步来教这个博览群书的学生如何去使用它的知识，也就是
<strong>SFT（Supervised Fine-Tuning，有监督微调）</strong>。</p>
<p>面对能力强大的
LLM，我们往往不再是在指定下游任务上构造有监督数据进行微调，而是选择训练模型的“通用指令遵循能力”，也就是一般<strong>通过<code>指令微调</code>的方式来进行
SFT</strong>。</p>
<p>所谓指令微调，即我们训练的输入是各种类型的用户指令，而需要模型拟合的输出则是我们希望模型在收到该指令后做出的回复。例如，我们的一条训练样本可以是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input:告诉我今天的天气预报？</span><br><span class="line">output:根据天气预报，今天天气是晴转多云，最高温度26摄氏度，最低温度9摄氏度，昼夜温差大，请注意保暖哦</span><br></pre></td></tr></table></figure>
<p>也就是说，SFT
的主要目标是让模型从多种类型、多种风格的指令中获得泛化的指令遵循能力，也就是能够理解并回复用户的指令。</p>
<h3 id="rlhf">RLHF</h3>
<p>RLHF，全称是 <strong>Reinforcement Learning from Human
Feedback，即人类反馈强化学习</strong>，是利用强化学习来训练 LLM
的关键步骤。相较于在 GPT-3 就已经初见雏形的 SFT，RLHF 往往被认为是
ChatGPT 相较于 GPT-3 的最核心突破。事实上，从功能上出发，我们可以将 LLM
的训练过程分成<strong>预训练与对齐（alignment）两个阶段</strong>。预训练的核心作用是赋予模型海量的知识，而所谓对齐，其实就是让模型与人类价值观一致，从而输出人类希望其输出的内容。在这个过程中，SFT
是让 LLM 和人类的指令对齐，从而具有指令遵循能力；而 RLHF
则是从更深层次令 LLM
和人类价值观对齐，令其达到安全、有用、无害的核心标准。</p>
<p>RLHF 分为两个步骤：<strong>训练 RM 和 PPO 训练</strong>。</p>
<p><strong>RM，Reward Model，即奖励模型</strong>。RM
是用于拟合人类偏好，来给 LLM 做出反馈的。在强化学习的训练中，对于 LLM
的每一个回复，RM
会进行打分，这个打分反映了生成回复符合人类偏好的程度。然后 LLM
会根据强化学习的原理，基于 RM 的打分来进行优化训练。</p>
<p>在完成 RM 训练之后，就可以使用 PPO
算法来进行强化学习训练。<strong>PPO，Proximal Policy
Optimization，近端策略优化算法</strong>，是一种经典的 RL
算法。事实上，强化学习训练时也可以使用其他的强化学习算法，但目前 PPO
算法因为成熟、成本较低，还是最适合 RLHF 的算法。</p>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/happy-llm/#/./chapter4/第四章%20大语言模型">第四章
大语言模型</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/" class="post-title-link" itemprop="url">tokenizer</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-08-08 00:00:00 / 修改时间：16:21:18" itemprop="dateCreated datePublished" datetime="2025-08-08T00:00:00+08:00">2025-08-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">大模型算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/" itemprop="url" rel="index"><span itemprop="name">tokenizer</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="什么是-tokenizer">什么是 Tokenizer？</h3>
<p><strong>Tokenizer</strong>（分词器）可以将原始文本（raw
text）转换为模型能够理解的数字序列，在模型输入和输出的两个主要阶段中发挥重要作用：</p>
<h4 id="模型输入编码-encode阶段">模型输入（编码 Encode）阶段</h4>
<ol type="1">
<li><p><strong>分词（Tokenize）</strong></p>
<p>将文本拆分为词元（Token），常见的分词方式包括字级、词级、子词级（如
BPE、WordPiece）、空格分词等。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: &quot;你好&quot;</span><br><span class="line">分词: [&quot;你&quot;, &quot;好&quot;]</span><br></pre></td></tr></table></figure></li>
<li><p><strong>映射（Mapping）</strong></p>
<p>将每个词元映射为词汇表中的唯一 ID，生成的数字序列即为模型的输入。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">分词: [&quot;你&quot;, &quot;好&quot;]</span><br><span class="line">映射: [<span class="number">1001</span>, <span class="number">1002</span>]</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="模型输出解码-decode阶段">模型输出（解码 Decode）阶段</h4>
<ol type="1">
<li><p><strong>反映射（De-mapping）</strong></p>
<p>模型输出的数字序列通过词汇表映射回对应的词元，二者是一一对应的关系。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输出: [<span class="number">1001</span>, <span class="number">1002</span>]</span><br><span class="line">反映射: [&quot;你&quot;, &quot;好&quot;]</span><br></pre></td></tr></table></figure></li>
<li><p><strong>文本重组</strong></p>
<p>将解码后的词元以某种规则重新拼接为完整文本。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">反映射: [&quot;你&quot;, &quot;好&quot;]</span><br><span class="line">重组: &quot;你好&quot;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="直观感受">直观感受</h4>
<p>访问 <a target="_blank" rel="noopener" href="https://tiktokenizer.vercel.app">Tiktokenizer</a>，通过右上角选取不同的
Tokenizer 进行尝试</p>
<h3 id="词汇表">词汇表</h3>
<p>两种常见的构建词汇表的方法：</p>
<ul>
<li><strong>BPE（Byte-Pair Encoding）</strong>：用于
GPT、GPT-2、RoBERTa、BART 和 DeBERTa 等模型。</li>
<li><strong>WordPiece</strong>：用于 DistilBERT、MobileBERT、Funnel
Transformers 和 MPNET 等模型。</li>
</ul>
<h4 id="bpe">BPE</h4>
<p>BPE（Byte Pair Encoding，字节对编码）在 NLP
里是一种<strong>贪心式的子词（subword）分词算法</strong>。
理解：从“字符”开始，反复把<strong>出现次数最多的相邻字符对</strong>合并成新的符号，并加入词汇表，直到达到预设的词汇表大小。</p>
<blockquote>
<p>为什么可以处理 OOV（Out-Of-Vocabulary）情况</p>
<p>因为所有词汇都是由字符或词根组成的，通过对单个字符的学习，可以组成oov的词汇</p>
<p>为什么需要词汇表</p>
<p>编码时，从文本到模型：需要将文本分词为 Tokens，再通过词汇表将 Tokens
转换为 Token IDs，再传给transformer</p>
<p>解码时，从模型到文本：需要通过词汇表Token IDs 转换为
Tokens，再把Tokens 拼接为文本</p>
</blockquote>
<h5 id="步骤">步骤</h5>
<ol type="1">
<li><strong>初始化词汇表 <span class="math inline"><em>V</em></span></strong>：
<ul>
<li><span class="math inline"><em>V</em></span>
包含语料库中的所有唯一字符，即单词字符的集合。</li>
</ul></li>
<li><strong>统计字符对的频次</strong>：
<ul>
<li>对于每个单词的字符序列，统计相邻字符对的出现频次。</li>
</ul></li>
<li><strong>找到频次（Score）最高的字符对并合并</strong>：
<ul>
<li>选择出现频率最高的字符对 <span class="math inline">(<em>x</em>,<em>y</em>)</span>，将其合并为新符号
<span class="math inline"><em>x</em><em>y</em></span>。</li>
</ul></li>
<li><strong>更新词汇表并重复步骤 2 到 4</strong>：
<ul>
<li>将新符号添加到词汇表 <span class="math inline"><em>V</em> = <em>V</em> ∪ {<em>x</em><em>y</em>}</span>。</li>
<li>更新语料库中的单词表示，重复统计和合并过程，直到满足停止条件（例如，词汇表达到预定大小）。</li>
</ul></li>
</ol>
<p><strong>示例</strong></p>
<p>我们需要将语料库（corpus）的文本拆分为单词，假设当前语料库包含的单词和对应频次如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(&quot;low&quot;, 5), (&quot;lower&quot;, 2), (&quot;newest&quot;, 6), (&quot;widest&quot;, 3)</span><br></pre></td></tr></table></figure>
<p><strong>步骤 1：初始化词汇表</strong></p>
<p><strong>将单词拆分为字符序列</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;), 5  </span><br><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;, &quot;e&quot;, &quot;r&quot;), 2  </span><br><span class="line">(&quot;n&quot;, &quot;e&quot;, &quot;w&quot;, &quot;e&quot;, &quot;s&quot;, &quot;t&quot;), 6  </span><br><span class="line">(&quot;w&quot;, &quot;i&quot;, &quot;d&quot;, &quot;e&quot;, &quot;s&quot;, &quot;t&quot;), 3</span><br></pre></td></tr></table></figure>
<p><strong>词汇表 V</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;l&#x27;, &#x27;o&#x27;, &#x27;w&#x27;, &#x27;e&#x27;, &#x27;r&#x27;, &#x27;n&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, &#x27;i&#x27;, &#x27;d&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>步骤 2：统计字符对的频次</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">字符对频次统计结果:</span><br><span class="line">(&#x27;l&#x27;, &#x27;o&#x27;): 7        # 5 (low) + 2 (lower)</span><br><span class="line">(&#x27;o&#x27;, &#x27;w&#x27;): 7        # 5 (low) + 2 (lower)</span><br><span class="line">(&#x27;w&#x27;, &#x27;e&#x27;): 8        # 2 (lower) + 6 (newest)</span><br><span class="line">(&#x27;e&#x27;, &#x27;r&#x27;): 2</span><br><span class="line">(&#x27;n&#x27;, &#x27;e&#x27;): 6</span><br><span class="line">(&#x27;e&#x27;, &#x27;w&#x27;): 6</span><br><span class="line">(&#x27;e&#x27;, &#x27;s&#x27;): 9        # 6 (newest) + 3 (widest)</span><br><span class="line">(&#x27;s&#x27;, &#x27;t&#x27;): 9        # 6 (newest) + 3 (widest)</span><br><span class="line">(&#x27;w&#x27;, &#x27;i&#x27;): 3</span><br><span class="line">(&#x27;i&#x27;, &#x27;d&#x27;): 3</span><br><span class="line">(&#x27;d&#x27;, &#x27;e&#x27;): 3</span><br></pre></td></tr></table></figure>
<p><strong>步骤 3：找到频次最高的字符对并合并</strong></p>
<p><strong>选择频次最高的字符对</strong>：</p>
<ul>
<li><code>("e", "s")</code> 和 <code>("s", "t")</code>，频次均为
9。可以任选其一进行合并，假设选择排序第一的：
<code>("e", "s")</code>。</li>
</ul>
<p><strong>合并 <code>("e", "s")</code> 为新符号
<code>es</code></strong>。</p>
<p><strong>记录合并操作</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Merge 1: (&quot;e&quot;, &quot;s&quot;) -&gt; &quot;es&quot;</span><br></pre></td></tr></table></figure>
<p><strong>步骤 4：更新词汇表并重复</strong></p>
<p><strong>更新单词序列</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;), 5  </span><br><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;, &quot;e&quot;, &quot;r&quot;), 2  </span><br><span class="line">(&quot;n&quot;, &quot;e&quot;, &quot;w&quot;, &quot;es&quot;, &quot;t&quot;), 6  </span><br><span class="line">(&quot;w&quot;, &quot;i&quot;, &quot;d&quot;, &quot;es&quot;, &quot;t&quot;), 3</span><br></pre></td></tr></table></figure>
<p><strong>更新词汇表 V</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;l&#x27;, &#x27;o&#x27;, &#x27;w&#x27;, &#x27;e&#x27;, &#x27;r&#x27;, &#x27;n&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, &#x27;i&#x27;, &#x27;d&#x27;, &#x27;es&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>重复步骤 2 到 4，直到达到预定的词汇表大小</strong>。</p>
<h4 id="wordpiece">WordPiece</h4>
<p>WordPiece 是 Google 在 2016 年为语音识别与 BERT
提出的<strong>子词（subword）分词算法</strong>，可看作 BPE
的“似然改进版”。理解：“<strong>用概率贪心而不是频次贪心，从字符开始逐步合并子词</strong>。”</p>
<p>与 BPE 不同，WordPiece 的 Score
由字符对频次与其组成部分频次的比值决定，定义 Score：</p>
<p><span class="math display">$$
\text{Score}_{\text{WordPiece}}(x, y) =
\frac{\text{freq}(xy)}{\text{freq}(x) \times \text{freq}(y)}
$$</span></p>
<p>其中, <span class="math inline">freq(<em>x</em>)</span>, <span class="math inline">freq(<em>y</em>)</span> 和 <span class="math inline">freq(<em>x</em><em>y</em>)</span> 分别表示符号 <span class="math inline"><em>x</em></span>, <span class="math inline"><em>y</em></span> 和它们合并后的符号 <span class="math inline"><em>x</em><em>y</em></span> 的频次。</p>
<h5 id="步骤-1">步骤</h5>
<ol type="1">
<li><strong>初始化词汇表 <span class="math inline"><em>V</em></span></strong>：
<ul>
<li>与 BPE 相同, <span class="math inline"><em>V</em></span>
包含语料库中的所有唯一字符，但处理方式略有不同：<strong>对于每个单词，除了首个字符外，其他字符前都加上
<code>##</code> 前缀。</strong></li>
</ul></li>
<li><strong>统计字符对的频次及 Score</strong>：
<ul>
<li>对于每个可能的字符对 <span class="math inline">(<em>x</em>,<em>y</em>)</span>，计算 <span class="math inline">freq(<em>x</em>)</span>, <span class="math inline">freq(<em>y</em>)</span>, <span class="math inline">freq(<em>x</em><em>y</em>)</span>，并计算
Score。</li>
</ul></li>
<li><strong>找到 Score 最高的字符对并合并</strong>：
<ul>
<li>选择 Score 最高的字符对 <span class="math inline">(<em>x</em>,<em>y</em>)</span>，将其合并为新符号
<span class="math inline"><em>x</em><em>y</em></span>，注意：
<ul>
<li>如果第二个符号以 <code>##</code> 开头，合并时去掉 <code>##</code>
前缀再进行连接。</li>
<li>新符号是否以 <code>##</code> 开头，取决于第一个符号是否以
<code>##</code> 开头。</li>
</ul></li>
</ul></li>
<li><strong>更新词汇表并重复步骤 2 到 4</strong>：
<ul>
<li>将新符号添加到词汇表 <span class="math inline"><em>V</em> = <em>V</em> ∪ {<em>x</em><em>y</em>}</span>。</li>
<li>更新语料库中的单词表示，重复统计和合并过程，直到满足停止条件。</li>
</ul></li>
</ol>
<h3 id="映射mapping">映射（Mapping）</h3>
<p>以 BPE 为例，最终词汇表 <span class="math inline"><em>V</em></span>
中的 Token 和对应的频次分别为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vocab = &#123;</span><br><span class="line">    &#x27;lo&#x27;: 7,</span><br><span class="line">    &#x27;w&#x27;: 16,</span><br><span class="line">    &#x27;e&#x27;: 8,</span><br><span class="line">    &#x27;r&#x27;: 2,</span><br><span class="line">    &#x27;n&#x27;: 6,</span><br><span class="line">    &#x27;est&#x27;: 9,</span><br><span class="line">    &#x27;i&#x27;: 3,</span><br><span class="line">    &#x27;d&#x27;: 3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Token to ID: &#123;&#x27;lo&#x27;: 0, &#x27;w&#x27;: 1, &#x27;e&#x27;: 2, &#x27;r&#x27;: 3, &#x27;n&#x27;: 4, &#x27;est&#x27;: 5, &#x27;i&#x27;: 6, &#x27;d&#x27;: 7&#125;</span><br><span class="line">ID to Token: &#123;0: &#x27;lo&#x27;, 1: &#x27;w&#x27;, 2: &#x27;e&#x27;, 3: &#x27;r&#x27;, 4: &#x27;n&#x27;, 5: &#x27;est&#x27;, 6: &#x27;i&#x27;, 7: &#x27;d&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>当然，也可以根据频次或者其他规则进行特殊处理。</p>
<p>以上是编码部分的概述，实际上在文本预处理的时候还会增加特殊标记，但这些以及后续的解码部分大多是一些文本处理的规则，这里就不过多赘述了，Tokenizer
之间的核心差异在于使用的分割方法和词汇表的构建策略。</p>
<h3 id="transformer中的分词">transformer中的分词</h3>
<p>在 Transformers 中，<strong>分词（tokenization）</strong>
实际上包含以下几个步骤：</p>
<ol type="1">
<li><strong>标准化（Normalization）</strong>：对文本进行必要的清理操作，例如删除多余空格或重音符号、进行
Unicode 标准化等。</li>
<li><strong>预分词（Pre-tokenization）</strong>：将输入拆分为单词。</li>
<li><strong>通过模型处理输入（Running the input through the
model）</strong>：使用预分词后的单词生成一系列词元（tokens）。</li>
<li><strong>后处理（Post-processing）</strong>：添加分词器的特殊标记，生成注意力掩码（attention
mask）和词元类型 ID（token type IDs）。</li>
</ol>
<p>流程图如下</p>
<figure>
<img src="/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/image-20250808100051423.png" alt="image-20250808100051423">
<figcaption aria-hidden="true">image-20250808100051423</figcaption>
</figure>
<h4 id="注意力掩码attention-mask和词元类型-id-token-type-ids是什么">注意力掩码（Attention
Mask）和词元类型 ID （Token Type IDs）是什么？</h4>
<figure>
<img src="/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/image-20250808100813881.png" alt="image-20250808100813881">
<figcaption aria-hidden="true">image-20250808100813881</figcaption>
</figure>
<p>1️⃣ 注意力掩码（Attention Mask） •
目的：告诉模型“哪些位置可以被看到”，其余位置直接屏蔽。 • 典型场景： –
<strong>自注意力里做 padding 掩码</strong>：把 <code>&lt;pad&gt;</code>
对应的位置设为 −∞，softmax 后权重=0。 –
<strong>解码器自回归掩码</strong>：生成任务用下三角掩码，避免第 i 个
token 看到未来 token。</p>
<p>2️⃣ 词元类型 ID（Token Type IDs，也叫 Segment IDs） •
目的：区分<strong>同一次输入里不同句子或段落</strong>，让模型知道“这段属于
A，那段属于 B”。 • 典型场景： – BERT
做句子对分类（NSP）：<code>[CLS] 句子A [SEP] 句子B [SEP]</code> → TypeID
= 0 0 0 0 1 1 1。 – RoBERTa、GPT 等单句模型则<strong>不需要</strong>
Token Type IDs。</p>
<p><strong>注意力掩码</strong>确保模型只关注实际的词元，忽略填充部分，从而避免无效的计算：</p>
<ul>
<li><strong>1</strong>：表示模型应关注的词元（Tokens）</li>
<li><strong>0</strong>：表示模型应忽略的词元（通常是填充
<code>padding</code> 的部分）。</li>
</ul>
<p><strong>词元类型 ID</strong> 用于区分输入中的不同句子或段落：</p>
<ul>
<li><strong>0</strong>：表示第一个句子的词元。</li>
<li><strong>1</strong>：表示第二个句子的词元。</li>
</ul>
<blockquote>
<p>CLS，SEP，PAD都是什么意思</p>
<p><code>[CLS]</code>（Classification），作用：对应位置的隐藏状态被当作<strong>整句/句对的“整体表示”</strong>，用来接分类头做句子级任务（情感分类、NLI
等）。</p>
<p><code>[SEP]</code>（Separator），作用：让模型知道<strong>分段 /
句子边界</strong>，配合 Token Type IDs 区分句子 A 和句子 B。</p>
<p><code>[PAD]</code>（padding token）的作用是
<strong>批量训练时把不同长度的序列补齐到同一长度</strong>，让张量可以堆叠成规整的矩阵；模型在计算注意力时通过
Attention Mask 把 <code>[PAD]</code> 对应的位置屏蔽掉，不让它们影响有效
token 的表示。</p>
</blockquote>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/blob/master/Guide/21.%20BPE%20vs%20WordPiece：理解%20Tokenizer%20的工作原理与子词分割方法.md">AI-Guide-and-Demos-zh_CN/Guide/21.
BPE vs WordPiece：理解 Tokenizer 的工作原理与子词分割方法.md at master ·
Hoper-J/AI-Guide-and-Demos-zh_CN</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/07/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/07/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-08-07 10:55:13 / 修改时间：10:58:21" itemprop="dateCreated datePublished" datetime="2025-08-07T10:55:13+08:00">2025-08-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a target="_blank" rel="noopener" href="https://zh.d2l.ai/index.html">《动手学深度学习》 —
动手学深度学习 2.0.0 documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://courses.d2l.ai/zh-v2/">课程安排 -
动手学深度学习课程</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/" class="post-title-link" itemprop="url">redis存储状态</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-08-06 00:00:00" itemprop="dateCreated datePublished" datetime="2025-08-06T00:00:00+08:00">2025-08-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-10 00:00:41" itemprop="dateModified" datetime="2025-08-10T00:00:41+08:00">2025-08-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/agent%E5%AE%9E%E6%88%98/" itemprop="url" rel="index"><span itemprop="name">agent实战</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="为什么用redis">为什么用redis</h3>
<p>Redis通过 RedisSessionManager 类来管理用户会话，存储结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">session:&#123;user_id&#125; -&gt; &#123;</span><br><span class="line">  &quot;session_id&quot;: &quot;会话ID&quot;,</span><br><span class="line">  &quot;status&quot;: &quot;idle|running|interrupted|completed|error&quot;,</span><br><span class="line">  &quot;last_response&quot;: &quot;上次智能体响应&quot;,</span><br><span class="line">  &quot;last_query&quot;: &quot;用户上次查询&quot;,</span><br><span class="line">  &quot;last_updated&quot;: &quot;最后更新时间戳&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/image-20250809232853613.png" alt="image-20250809232853613">
<figcaption aria-hidden="true">image-20250809232853613</figcaption>
</figure>
<p>主要功能</p>
<ul>
<li>会话创建与维护 ：为每个用户创建唯一会话，支持会话超时自动清理</li>
<li>状态跟踪
：实时跟踪智能体执行状态（空闲、运行中、中断、完成、错误）</li>
<li>中断恢复支持
：当智能体需要人工干预时，Redis保存中断状态，支持后续恢复执行</li>
<li>用户管理 ：统计活跃用户数量，管理多用户并发访问</li>
</ul>
<p>与PostgreSQL的分工</p>
<ul>
<li>Redis ：负责临时会话状态和实时数据（快速读写）</li>
<li>PostgreSQL
：负责智能体的长期记忆存储（通过LangGraph的checkpointer）</li>
</ul>
<blockquote>
<p>为什么不使用pgsql完成对状态的存储</p>
<p>频繁读写
：会话状态需要频繁更新（每次请求都要更新状态），PostgreSQL的磁盘I/O比Redis内存操作慢很多4</p>
<p>短期记忆（PostgreSQL + LangGraph Checkpointer）</p>
<p>临时状态记忆（Redis）</p>
</blockquote>
<h3 id="redis实现状态存储业务逻辑总览图">redis实现状态存储业务逻辑总览图</h3>
<figure>
<img src="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/image-20250806164348663.png" alt="image-20250806164348663">
<figcaption aria-hidden="true">image-20250806164348663</figcaption>
</figure>
<p>使用redis的根本逻辑：存储对话的状态，当出现由工具调用或者客户端崩溃导致的中断时，可以存储状态在redis，在开始对话时，通过session_id获取redis的状态，并根据状态判断是要恢复中断还是正常对话</p>
<p>存储的redis（调用invoke_agent接口）：开始（创建）对话时要根据会话user_id获取或创建redis；再调用agent后，根据响应是否存在<strong>status</strong>字段是否是”<strong>interrupt</strong>”，判断是否有终端，最后更新redis状态</p>
<p>恢复的redis（调用resume_agent接口）：获取redis状态，并根据请求的恢复内容，使用Command命令恢复agent，最后更新redis</p>
<figure>
<img src="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/image-20250809233037563.png" alt="image-20250809233037563">
<figcaption aria-hidden="true">image-20250809233037563</figcaption>
</figure>
<h3 id="redis类">redis类</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 初始化异步 Redis 连接和会话配置</span><br><span class="line">def __init__(self, redis_host, redis_port, redis_db, session_timeout):</span><br><span class="line">    self.redis_client = redis.Redis(</span><br><span class="line">        host=redis_host,</span><br><span class="line">        port=redis_port,</span><br><span class="line">        db=redis_db,</span><br><span class="line">        decode_responses=True</span><br><span class="line">    )</span><br><span class="line">    self.session_timeout = session_timeout  # 会话过期时间（秒）</span><br><span class="line"></span><br><span class="line"># 关闭 Redis 连接</span><br><span class="line">async def close(self):</span><br><span class="line">    await self.redis_client.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 16%">
<col style="width: 27%">
<col style="width: 19%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>方法名</th>
<th>作用</th>
<th>输入参数</th>
<th>返回值</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>__init__</code></td>
<td>建立与 Redis 的异步连接并设置会话超时</td>
<td><code>redis_host</code>, <code>redis_port</code>,
<code>redis_db</code>, <code>session_timeout</code></td>
<td>-</td>
<td><code>decode_responses=True</code> 使 Redis 返回字符串而非字节</td>
</tr>
<tr class="even">
<td><code>close</code></td>
<td>优雅关闭 Redis 连接</td>
<td>-</td>
<td>-</td>
<td>异步方法，需 <code>await</code></td>
</tr>
<tr class="odd">
<td><code>create_session</code></td>
<td>为指定用户新建（或覆盖）会话记录</td>
<td><code>user_id</code>, 可选 <code>session_id</code>,
<code>status</code>, <code>last_query</code>,
<code>last_response</code>, <code>last_updated</code></td>
<td><code>str</code>：生成的 <code>session_id</code></td>
<td>会话键格式：<code>session:&#123;user_id&#125;</code>；过期时间为
<code>session_timeout</code></td>
</tr>
<tr class="even">
<td><code>get_session</code></td>
<td>读取指定用户的完整会话字典</td>
<td><code>user_id</code></td>
<td><code>dict</code> 或 <code>None</code></td>
<td>自动将 JSON 里的 <code>last_response</code> 反序列化为
<code>AgentResponse</code> 对象</td>
</tr>
<tr class="odd">
<td><code>update_session</code></td>
<td>增量更新已有会话的字段</td>
<td><code>user_id</code>, 可选 <code>status</code>,
<code>last_query</code>, <code>last_response</code>,
<code>last_updated</code></td>
<td><code>bool</code>：<code>True</code> 更新成功，<code>False</code>
用户不存在</td>
<td>更新后刷新过期时间</td>
</tr>
<tr class="even">
<td><code>delete_session</code></td>
<td>删除单个用户的会话</td>
<td><code>user_id</code></td>
<td><code>bool</code>：<code>True</code> 删除成功</td>
<td>直接删除 <code>session:&#123;user_id&#125;</code></td>
</tr>
<tr class="odd">
<td><code>get_session_count</code></td>
<td>计算当前活跃会话总数</td>
<td>-</td>
<td><code>int</code></td>
<td>使用异步扫描 <code>session:*</code> 键空间</td>
</tr>
<tr class="even">
<td><code>get_all_user_ids</code></td>
<td>取出所有已创建会话的 <code>user_id</code></td>
<td>-</td>
<td><code>List[str]</code></td>
<td>同样基于 <code>session:*</code> 扫描</td>
</tr>
<tr class="odd">
<td><code>user_id_exists</code></td>
<td>快速判断某用户是否已有会话</td>
<td><code>user_id</code></td>
<td><code>bool</code></td>
<td>利用 <code>EXISTS</code> 命令</td>
</tr>
</tbody>
</table>
<h3 id="安装redis">安装redis</h3>
<h4 id="linux系统">linux系统</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y redis-server</span><br><span class="line"># 启动 Redis 服务</span><br><span class="line">sudo service redis-server start</span><br><span class="line"># 检查 Redis 服务状态</span><br><span class="line">sudo service redis-server status</span><br></pre></td></tr></table></figure>
<h4 id="docker">docker</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># Docker Compose 配置文件，用于启动 Redis 服务</span><br><span class="line"># 该配置为 FastAPI 应用提供 Redis 后端，支持分布式会话管理</span><br><span class="line">version: &#x27;3.8&#x27;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  redis:</span><br><span class="line">    # 使用官方 Redis 镜像</span><br><span class="line">    image: redis:latest</span><br><span class="line">    # 服务名称</span><br><span class="line">    container_name: redis</span><br><span class="line">    # 映射 Redis 默认端口到主机</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;6379:6379&quot;</span><br><span class="line">    # 持久化存储配置（可选）</span><br><span class="line">    volumes:</span><br><span class="line">      - redis-data:/data</span><br><span class="line">    # 确保容器在重启时自动启动</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    # 健康检查：验证 Redis 服务是否正常运行</span><br><span class="line">    healthcheck:</span><br><span class="line">      test: [&quot;CMD&quot;, &quot;redis-cli&quot;, &quot;ping&quot;]</span><br><span class="line">      interval: 30s</span><br><span class="line">      timeout: 10s</span><br><span class="line">      retries: 3</span><br><span class="line">      start_period: 10s</span><br><span class="line">    # 网络配置</span><br><span class="line">    networks:</span><br><span class="line">      - app-network</span><br><span class="line"></span><br><span class="line"># 定义持久化存储卷</span><br><span class="line">volumes:</span><br><span class="line">  redis-data:</span><br><span class="line">    name: redis-data</span><br><span class="line"></span><br><span class="line"># 定义网络</span><br><span class="line">networks:</span><br><span class="line">  app-network:</span><br><span class="line">    driver: bridge</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/05/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/%E4%B8%83%E6%9C%88%E5%A4%8D%E7%9B%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/05/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/%E4%B8%83%E6%9C%88%E5%A4%8D%E7%9B%98/" class="post-title-link" itemprop="url">实习七月复盘</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-08-05 00:00:00 / 修改时间：15:46:49" itemprop="dateCreated datePublished" datetime="2025-08-05T00:00:00+08:00">2025-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">实习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/" itemprop="url" rel="index"><span itemprop="name">晨晟智控</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="文件处理阶段">文件处理阶段</h3>
<ol type="1">
<li>使用libreoffice将doc，docx文件处理成pdf文件，方便后续使用mineru进行提取</li>
<li>完成mineru的docker本地部署；搭建fastapi服务，与项目容器构建自定义网络，方便后续服务调用；使用locust完成对mineru的并发性能测试，和吞吐量测试</li>
<li>对mineru提取的html格式的表格进行预处理工作，将其转化成md格式，方便后续分块，节省tokens</li>
</ol>
<h4 id="部分技术细节">部分技术细节</h4>
<p><strong>mineru提取效果说明</strong></p>
<p>可以完整提取表格与图片，将图片以相对链接形式储存在images文件夹下；可以完成pdf与扫描件的提取，可以实现对图片中文字的识别；输出符合人类阅读顺序的文本，适用于单栏、多栏及复杂排版；删除页眉、页脚、脚注、页码等元素，确保语义连贯</p>
<p>目前问题：仍无法实现对多级标题的识别</p>
<p><strong>mineru的fastapi启动指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3 mineru-api --host 0.0.0.0 --port 30000 --dp-size 3 --enable-torch-compile</span><br></pre></td></tr></table></figure>
<blockquote>
<p>MinerU支持通过sglang的多GPU并行模式来提升推理速度。</p>
<ul>
<li>如果您有超过多张显卡，可以使用sglang的多卡并行模式来增加吞吐量：<code>--dp-size 2</code></li>
<li>同时您可以启用<code>torch.compile</code>来将推理速度加速约15%：<code>--enable-torch-compile</code></li>
</ul>
</blockquote>
<blockquote>
<p>注意设置环境变量<code>MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3</code>保证模型本地加载与调用指定gpu</p>
</blockquote>
<p><strong>mineru容器启动指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host -v /aisys/:/aisys/ --network network_test mineru-sglang:latest tail -f /dev/null</span><br><span class="line">docker start mineru-server</span><br></pre></td></tr></table></figure>
<p><strong>mineru三种后端模式测试</strong></p>
<p>pipeline (默认后端) ，vlm-sglang-engine，vlm-sglang-client</p>
<p>项目中使用的是vlm-sglang-engine，原因如下，pipeline应用场景更多是仅能cpu推理，解析速度大大落后与vlm模式，而我们gpu资源充足，自然不考虑；vlm-sglang-client应用场景更多是有SGLang服务器，这样客户端既可以不用安装sglang，同样不符合我们的条件</p>
<p><strong>mineru并发与吞吐量测试</strong></p>
<p><strong>测试场景</strong>：10页的pdf，50用户并发</p>
<p><strong>工具</strong>：locust</p>
<p><strong>测试结果</strong></p>
<p>对于推理模型的吞吐量，在3个gpu开启数据并行的情况下，平均每秒单个gpu处理tokens为1500左右</p>
<p>gpu状态如上:<strong>显存几乎打满 85–87 %</strong>,<strong>GPU 利用率
59–63 %</strong>,<strong>功耗 170–188 W / 350 W</strong></p>
<p>压测结果如下，选取部分指标</p>
<table>
<colgroup>
<col style="width: 18%">
<col style="width: 28%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th>指标</th>
<th>数值</th>
<th>通俗解释</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>平均响应时间</strong></td>
<td><strong>241 秒</strong> ≈ <strong>4 分钟</strong></td>
<td>上传一个 PDF → 拿到解析结果，平均要等 4 分钟。</td>
</tr>
<tr class="even">
<td><strong>中位数</strong></td>
<td><strong>215 秒</strong> ≈ <strong>3.6 分钟</strong></td>
<td>一半请求在 3.6 分钟内完成。</td>
</tr>
<tr class="odd">
<td><strong>95% 用户</strong></td>
<td><strong>361 秒</strong> ≈ <strong>6 分钟</strong></td>
<td>最慢的 5% 要等 6 分钟以上。</td>
</tr>
<tr class="even">
<td><strong>吞吐量</strong></td>
<td><strong>0.18 req/s</strong></td>
<td>这台 MinerU <strong>每分钟只能处理约11 个 PDF</strong>。</td>
</tr>
</tbody>
</table>
<h3 id="分块阶段">分块阶段</h3>
<p>当前主流的分块方式共五种：固定长度分块，语义分块，递归分块，文档结构分块，llm分块。</p>
<p>最后项目我选择了递归分块，原因如下：</p>
<ol type="1">
<li>mineru无法正确提取md文档结构，因此我舍弃了文档结构分块</li>
<li>测试了agentic
chunk（其主要思想是，先进行初步分段，按照长度或递归，然后让大模型生成这一段的概要，将段与段合并生成块），但是测试下来，我们这个一个文档的内容同质化很严重，基本上都分到一块里了，我猜测语义分块也是这种效果，因此舍弃</li>
<li>我们的文档中存在大量表格，我在预处理阶段增加了对表格的首尾标记，使用递归分块可以更好的保留这些结构</li>
</ol>
<h3 id="检索阶段">检索阶段</h3>
<p>基于langchain_elasticsearch完成了向量搜索，bm25，混合检索，模糊检索的检索函数的编写。</p>
<p>结果如下：</p>
<ol type="1">
<li>混合检索elasticsearch需要付费使用</li>
<li>bm25的多字段搜索有三种模式且字段的权重可以调整，后续评估时调整进行测试</li>
<li>检索的效果需要后续进行rag评估时判定</li>
</ol>
<h3 id="elasticsearch相关">elasticsearch相关</h3>
<p>完成对项目es模块的熟悉阅读；实现对elasticsearch的连接与字段的构建与存入。</p>
<p>关于字段的存储，我选取了report_name，report_url，page_content</p>
<h4 id="相关细节">相关细节</h4>
<h5 id="阅读elasticsearch代码相关记录"><strong>阅读elasticsearch代码相关记录:</strong></h5>
<ol type="1">
<li><strong>embedding_model</strong>.select_embeddings_model:根据指定的模型名称加载</li>
<li><strong>make_es_vector_store</strong>：
<ol type="1">
<li>docs_url =
pd.read_excel(‘docs_new.xlsx’)，从excel加载url并进行数据处理，保存筛选后的ur</li>
<li>完成文件加载测试：xizhang/retrival/docfile_test/test.py；</li>
<li>初始化es，使用elastic_search.load_es_index加载存储索引</li>
<li>完成测试elasticsearch连接与索引构建（索引名zxj_test）：/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_es_connect.py，/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_add_es.py</li>
<li>顺序批量处理文件：共16000多份，每十份为一批进行处理，使用download_pdf.py进行文件下载，使用，使用vector_base.rewrite_file对文件进行处理，这里可以修改代码，增加对mineru处理pdf的markdown文件的处理，返回Document对象列表；</li>
</ol></li>
<li><strong>elastic_search</strong></li>
</ol>
<p>重写了检索策略的函数，包括BM25，KNN，混合搜索</p>
<ol type="1">
<li><p>elastic_retriever创建Elasticsearch检索器：根据搜索类型选择对应的查询函数，创建Elasticsearch检索器ElasticsearchRetriever.from_es_params</p></li>
<li><p><strong>retrievers</strong></p>
<ol type="1">
<li>定义函数select_retriever，根据指定的名称选择并返回相应的检索器，目前只有bm25</li>
</ol></li>
</ol>
<h5 id="文档结构">文档结构</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">doc = Document(</span><br><span class="line">            page_content=text_content,</span><br><span class="line">            metadata=&#123;</span><br><span class="line">                &quot;report_name&quot;: folder_name,</span><br><span class="line">                &quot;report_url&quot;: report_url,</span><br><span class="line">                &quot;chunk_id&quot;: chunk_id</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h3 id="rag评估">rag评估</h3>
<p>待补充</p>
<h3 id="后续优化思考">后续优化思考</h3>
<ol type="1">
<li>重排序部分我没有做过，不知道怎么做，也不知道效果会怎样（我感觉在我们这个场景应该提升有限，听你说也是这样）</li>
<li>如何存入数据库的部分，可能也是优化的点，比如可以尝试agentic
rag这种，在存入数据库前再进行一步处理</li>
<li>还有一个点我比较好奇，我们项目在召回后是如何处理的，就是上下文拼接吗</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/02/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/python-logging%E6%A8%A1%E5%9D%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/02/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/python-logging%E6%A8%A1%E5%9D%97/" class="post-title-link" itemprop="url">python-logging模块</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-08-02 00:00:00" itemprop="dateCreated datePublished" datetime="2025-08-02T00:00:00+08:00">2025-08-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-03 18:50:57" itemprop="dateModified" datetime="2025-08-03T18:50:57+08:00">2025-08-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/" itemprop="url" rel="index"><span itemprop="name">杂项</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="日志级别">日志级别</h3>
<table>
<thead>
<tr class="header">
<th>级别</th>
<th>方法</th>
<th>用途</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DEBUG</td>
<td><code>logging.debug()</code></td>
<td>调试信息</td>
</tr>
<tr class="even">
<td>INFO</td>
<td><code>logging.info()</code></td>
<td>普通信息</td>
</tr>
<tr class="odd">
<td>WARNING</td>
<td><code>logging.warning()</code></td>
<td>警告信息</td>
</tr>
<tr class="even">
<td>ERROR</td>
<td><code>logging.error()</code></td>
<td>错误信息</td>
</tr>
<tr class="odd">
<td>CRITICAL</td>
<td><code>logging.critical()</code></td>
<td>严重错误</td>
</tr>
</tbody>
</table>
<p>python默认只会打印warning以上级别的日志，可通过<code>basicConfig</code>进行设置，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 基础配置</span><br><span class="line">logging.basicConfig(level=logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># 记录不同级别的日志</span><br><span class="line">logging.debug(&quot;这是一个DEBUG级别的日志&quot;)</span><br><span class="line">logging.info(&quot;这是一个INFO级别的日志&quot;)</span><br><span class="line">logging.warning(&quot;这是一个WARNING级别的日志&quot;)</span><br><span class="line">logging.error(&quot;这是一个ERROR级别的日志&quot;)</span><br><span class="line">logging.critical(&quot;这是一个CRITICAL级别的日志&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="格式化log并输出">格式化log并输出</h3>
<p>我们可以使用全局配置，完成log的格式化和输出成文件，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logging.basicConfig(level=logging.DEBUG,format=&#x27;%(asctime)s - %(levelname)s - %(message)s&#x27;,filename=&#x27;basic.log&#x27;,filemode=&#x27;w&#x27;)</span><br></pre></td></tr></table></figure>
<p>同样，我们可以自定义logger</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># 创建自定义logger</span><br><span class="line">logger = logging.getLogger(&#x27;my_app&#x27;)</span><br><span class="line">logger.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># 清除之前的处理器</span><br><span class="line">logger.handlers.clear()</span><br><span class="line"></span><br><span class="line"># 创建文件处理器</span><br><span class="line">file_handler = logging.FileHandler(&#x27;logs/my_app.log&#x27;, encoding=&#x27;utf-8&#x27;)</span><br><span class="line">file_handler.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># 创建控制台处理器</span><br><span class="line">console_handler = logging.StreamHandler()</span><br><span class="line">console_handler.setLevel(logging.WARNING)</span><br><span class="line"></span><br><span class="line"># 创建不同的格式器</span><br><span class="line">file_formatter = logging.Formatter(</span><br><span class="line">    &#x27;%(asctime)s | %(name)s | %(levelname)s | %(funcName)s:%(lineno)d | %(message)s&#x27;</span><br><span class="line">)</span><br><span class="line">console_formatter = logging.Formatter(</span><br><span class="line">    &#x27;🚨 %(levelname)s: %(message)s&#x27;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">file_handler.setFormatter(file_formatter)</span><br><span class="line">console_handler.setFormatter(console_formatter)</span><br><span class="line"></span><br><span class="line"># 添加处理器</span><br><span class="line">logger.addHandler(file_handler)</span><br><span class="line">logger.addHandler(console_handler)</span><br><span class="line"></span><br><span class="line"># 测试不同级别的日志</span><br><span class="line">logger.debug(&quot;调试信息 - 只写入文件&quot;)</span><br><span class="line">logger.info(&quot;普通信息 - 只写入文件&quot;)</span><br><span class="line">logger.warning(&quot;警告信息 - 控制台和文件都有&quot;)</span><br><span class="line">logger.error(&quot;错误信息 - 控制台和文件都有&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="异常捕获">异常捕获</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    result = divide(10, 0)</span><br><span class="line">except ZeroDivisionError as exc:</span><br><span class="line">    # 方式 1：记录异常对象</span><br><span class="line">    logger.error(&quot;除零异常发生: &#123;&#125;&quot;, exc)</span><br><span class="line"></span><br><span class="line">    # 方式 2：记录完整 traceback（推荐）</span><br><span class="line">    logger.exception(&quot;捕获到异常，详情如下&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="loguru的常用使用方法">loguru的常用使用方法</h3>
<p>基础用法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from loguru import logger</span><br><span class="line"></span><br><span class="line">logger.debug(&quot;这是 debug&quot;)</span><br><span class="line">logger.info(&quot;这是 info&quot;)</span><br><span class="line">logger.warning(&quot;这是 warning&quot;)</span><br><span class="line">logger.error(&quot;这是 error&quot;)</span><br><span class="line">logger.critical(&quot;这是 critical&quot;)</span><br></pre></td></tr></table></figure>
<p>输出到文件 logger.add(“app.log”)</p>
<p>过滤级别 logger.add(“app.log”, level=“WARNING”)</p>
<p>移除默认控制台输出 logger.remove()</p>
<h3 id="参考资料">参考资料</h3>
<p>[<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1rJv8eNE1x?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Python]
logging模块怎么用_哔哩哔哩_bilibili</a></p>
<p>[<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1VnW7edEq7?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Python]
打印log神器 —— loguru_哔哩哔哩_bilibili</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/02/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/python-uv%E5%8C%85%E7%AE%A1%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/02/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/python-uv%E5%8C%85%E7%AE%A1%E7%90%86/" class="post-title-link" itemprop="url">python-uv包管理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-08-02 00:00:00" itemprop="dateCreated datePublished" datetime="2025-08-02T00:00:00+08:00">2025-08-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-04 16:20:46" itemprop="dateModified" datetime="2025-08-04T16:20:46+08:00">2025-08-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/" itemprop="url" rel="index"><span itemprop="name">杂项</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="什么是uv">什么是uv</h3>
<p><code>uv</code> 是由 <strong>Astral</strong>
团队开发的一个<strong>超高速 Python 包管理器</strong>，用
<strong>Rust</strong> 编写，目标是替代
<code>pip</code>、<code>venv</code>、<code>pip-tools</code>、<code>poetry</code>
等多个工具。</p>
<h3 id="uv常用命令">uv常用命令</h3>
<p>uv init myproj 创建新项目</p>
<p>source .venv/bin/activate（Linux/macOS）激活虚拟环境</p>
<p>uv add requests 安装依赖并写入 pyproject.toml</p>
<p>uv remove requests 移除依赖</p>
<p>uv sync 同步依赖到虚拟环境</p>
<p>uv export 导出 lock 文件为 requirements.txt 等格式</p>
<p>uv build 构建源码包和 wheel</p>
<p>uv publish 发布到 PyPI</p>
<h3 id="uvx是什么">uvx是什么</h3>
<p><strong><code>uvx</code></strong> 是：</p>
<blockquote>
<p><strong>uv tool run</strong>
的<strong>快捷别名</strong>（alias），用于<strong>无需安装即可运行
Python 包提供的命令行工具</strong>。</p>
</blockquote>
<p><code>uvx</code> 就像 Python 世界的 <strong><code>npx</code></strong>
或 <strong><code>pipx run</code></strong> ——
<strong>临时拉取、构建隔离环境、运行工具，用完即走，不留痕迹</strong>。</p>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ajJ7zPEa5/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【uv】Python迄今最好的项目管理+环境管理工具（吧？）_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV13WGHz8EEz?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">从pip到uv：一口气梳理现代Python项目管理全流程！_哔哩哔哩_bilibili</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/" class="post-title-link" itemprop="url">MCP 客户端实战</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-08-01 00:00:00 / 修改时间：17:03:37" itemprop="dateCreated datePublished" datetime="2025-08-01T00:00:00+08:00">2025-08-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/mcp/" itemprop="url" rel="index"><span itemprop="name">mcp</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="配置环境">配置环境</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 创建项目目录</span><br><span class="line">uv init mcp-client</span><br><span class="line">cd mcp-client</span><br><span class="line"></span><br><span class="line"># 创建虚拟环境</span><br><span class="line">uv venv</span><br><span class="line"></span><br><span class="line"># 激活虚拟环境</span><br><span class="line"># 在 Windows 上:</span><br><span class="line">.venv\Scripts\activate</span><br><span class="line"># 在 Unix 或 MacOS 上:</span><br><span class="line">source .venv/bin/activate</span><br><span class="line"></span><br><span class="line"># 安装所需包</span><br><span class="line">uv add mcp anthropic python-dotenv</span><br><span class="line">#使用镜像源安装</span><br><span class="line">uv add mcp anthropic python-dotenv --index-url https://pypi.tuna.tsinghua.edu.cn/simple/</span><br><span class="line"></span><br><span class="line"># 删除样板文件</span><br><span class="line"># 在 Windows 上:</span><br><span class="line">del main.py</span><br><span class="line"># 在 Unix 或 MacOS 上:</span><br><span class="line">rm main.py</span><br><span class="line"></span><br><span class="line"># 创建我们的主文件</span><br><span class="line">touch client.py</span><br></pre></td></tr></table></figure>
<h3 id="设置-api-密钥">设置 API 密钥</h3>
<p>创建一个 <code>.env</code> 文件来存储它：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Create .env file</span><br><span class="line">touch .env</span><br></pre></td></tr></table></figure>
<p>将您的密钥添加到 <code>.env</code> 文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ANTHROPIC_API_KEY=&lt;your key here&gt;</span><br></pre></td></tr></table></figure>
<p>将 <code>.env</code> 添加到您的 <code>.gitignore</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;.env&quot; &gt;&gt; .gitignore</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将 <code>.env</code> 文件名添加到 <code>.gitignore</code>
文件中，这样 Git 就会忽略 <code>.env</code>
文件，不会将其纳入版本控制。</p>
</blockquote>
<h3 id="创建客户端">创建客户端</h3>
<h4 id="基本客户端结构">基本客户端结构</h4>
<p>首先，让我们设置我们的导入并创建基本的客户端类：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">from typing import Optional</span><br><span class="line">from contextlib import AsyncExitStack</span><br><span class="line"></span><br><span class="line">from mcp import ClientSession, StdioServerParameters</span><br><span class="line">from mcp.client.stdio import stdio_client</span><br><span class="line"></span><br><span class="line">from anthropic import Anthropic</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line"></span><br><span class="line">load_dotenv()  # 从 .env 文件加载环境变量</span><br><span class="line"></span><br><span class="line">class MCPClient:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        # 初始化会话和客户端对象</span><br><span class="line">        self.session: Optional[ClientSession] = None  # MCP客户端会话</span><br><span class="line">        self.exit_stack = AsyncExitStack()  # 异步上下文管理器堆栈，用于资源清理</span><br><span class="line">        self.anthropic = Anthropic()  # Anthropic AI 客户端</span><br><span class="line">        </span><br><span class="line">    # 后续方法将在这里定义</span><br></pre></td></tr></table></figure>
<h4 id="服务器连接管理">服务器连接管理</h4>
<p>接下来，我们将实现连接到 MCP 服务器的功能：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">async def connect_to_server(self, server_script_path: str):</span><br><span class="line">    &quot;&quot;&quot;连接到MCP服务器</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        server_script_path: 服务器脚本路径 (.py 或 .js 文件)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 检查是否为Python文件</span><br><span class="line">    is_python = server_script_path.endswith(&#x27;.py&#x27;)</span><br><span class="line">    # 检查是否为JavaScript文件</span><br><span class="line">    is_js = server_script_path.endswith(&#x27;.js&#x27;)</span><br><span class="line">    </span><br><span class="line">    # 如果不是Python或JavaScript文件，则抛出错误</span><br><span class="line">    if not (is_python or is_js):</span><br><span class="line">        raise ValueError(&quot;服务器脚本必须是 .py 或 .js 文件&quot;)</span><br><span class="line"></span><br><span class="line">    # 根据文件类型确定执行命令</span><br><span class="line">    command = &quot;python&quot; if is_python else &quot;node&quot;</span><br><span class="line">    </span><br><span class="line">    # 创建服务器参数对象</span><br><span class="line">    server_params = StdioServerParameters(</span><br><span class="line">        command=command,           # 执行命令</span><br><span class="line">        args=[server_script_path], # 脚本路径作为参数</span><br><span class="line">        env=None                   # 环境变量（使用默认环境）</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 建立stdio客户端连接并将其添加到异步上下文管理器中</span><br><span class="line">    stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))</span><br><span class="line">    self.stdio, self.write = stdio_transport</span><br><span class="line">    </span><br><span class="line">    # 创建客户端会话并将其添加到异步上下文管理器中</span><br><span class="line">    self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))</span><br><span class="line"></span><br><span class="line">    # 初始化会话</span><br><span class="line">    await self.session.initialize()</span><br><span class="line"></span><br><span class="line">    # 列出可用的工具</span><br><span class="line">    response = await self.session.list_tools()</span><br><span class="line">    tools = response.tools</span><br><span class="line">    </span><br><span class="line">    # 打印连接的服务器提供的工具列表</span><br><span class="line">    print(&quot;\n已连接到服务器，可用工具:&quot;, [tool.name for tool in tools])</span><br></pre></td></tr></table></figure>
<h4 id="查询处理逻辑">查询处理逻辑</h4>
<p>现在让我们添加处理查询和调用工具的核心功能：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">async def process_query(self, query: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;使用Claude和可用工具处理查询&quot;&quot;&quot;</span><br><span class="line">    # 构建消息列表</span><br><span class="line">    messages = [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;role&quot;: &quot;user&quot;,      # 用户角色</span><br><span class="line">            &quot;content&quot;: query     # 用户查询内容</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    # 获取可用工具列表</span><br><span class="line">    response = await self.session.list_tools()</span><br><span class="line">    available_tools = [&#123;</span><br><span class="line">        &quot;name&quot;: tool.name,           # 工具名称</span><br><span class="line">        &quot;description&quot;: tool.description,  # 工具描述</span><br><span class="line">        &quot;input_schema&quot;: tool.inputSchema  # 工具输入模式</span><br><span class="line">    &#125; for tool in response.tools]</span><br><span class="line"></span><br><span class="line">    # 初始Claude API调用</span><br><span class="line">    response = self.anthropic.messages.create(</span><br><span class="line">        model=&quot;qwen3-235b-a22b&quot;,  # 使用的模型</span><br><span class="line">        max_tokens=1000,                     # 最大返回令牌数</span><br><span class="line">        messages=messages,                   # 消息历史</span><br><span class="line">        tools=available_tools               # 可用工具</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 处理响应并处理工具调用</span><br><span class="line">    final_text = []  # 存储最终文本结果</span><br><span class="line"></span><br><span class="line">    assistant_message_content = []  # 存储助手消息内容</span><br><span class="line">    for content in response.content:  # 遍历响应内容</span><br><span class="line">        if content.type == &#x27;text&#x27;:  # 如果是文本内容</span><br><span class="line">            final_text.append(content.text)  # 添加到最终结果</span><br><span class="line">            assistant_message_content.append(content)  # 添加到助手消息</span><br><span class="line">        elif content.type == &#x27;tool_use&#x27;:  # 如果是工具调用</span><br><span class="line">            tool_name = content.name    # 工具名称</span><br><span class="line">            tool_args = content.input   # 工具参数</span><br><span class="line"></span><br><span class="line">            # 执行工具调用</span><br><span class="line">            result = await self.session.call_tool(tool_name, tool_args)</span><br><span class="line">            final_text.append(f&quot;[调用工具 &#123;tool_name&#125;，参数 &#123;tool_args&#125;]&quot;)</span><br><span class="line"></span><br><span class="line">            assistant_message_content.append(content)</span><br><span class="line">            # 添加助手消息到历史</span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                &quot;content&quot;: assistant_message_content</span><br><span class="line">            &#125;)</span><br><span class="line">            # 添加工具执行结果到历史</span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;tool_result&quot;,      # 工具结果类型</span><br><span class="line">                        &quot;tool_use_id&quot;: content.id,  # 工具使用ID</span><br><span class="line">                        &quot;content&quot;: result.content   # 工具执行结果</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">            # 获取Claude的下一个响应</span><br><span class="line">            response = self.anthropic.messages.create(</span><br><span class="line">                model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">                max_tokens=1000,</span><br><span class="line">                messages=messages,</span><br><span class="line">                tools=available_tools</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            # 添加响应文本到最终结果</span><br><span class="line">            final_text.append(response.content[0].text)</span><br><span class="line"></span><br><span class="line">    # 返回连接后的最终文本结果</span><br><span class="line">    return &quot;\n&quot;.join(final_text)</span><br></pre></td></tr></table></figure>
<h4 id="交互式聊天界面">交互式聊天界面</h4>
<p>现在我们将添加聊天循环和清理功能：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">async def chat_loop(self):</span><br><span class="line">    &quot;&quot;&quot;运行交互式聊天循环&quot;&quot;&quot;</span><br><span class="line">    print(&quot;\nMCP客户端已启动!&quot;)</span><br><span class="line">    print(&quot;输入您的问题或输入&#x27;quit&#x27;退出。&quot;)</span><br><span class="line"></span><br><span class="line">    while True:  # 无限循环，持续接收用户输入</span><br><span class="line">        try:</span><br><span class="line">            query = input(&quot;\n问题: &quot;).strip()  # 获取用户输入并去除首尾空格</span><br><span class="line"></span><br><span class="line">            if query.lower() == &#x27;quit&#x27;:  # 如果用户输入&#x27;quit&#x27;（不区分大小写）</span><br><span class="line">                break  # 退出循环</span><br><span class="line"></span><br><span class="line">            # 处理用户查询并获取响应</span><br><span class="line">            response = await self.process_query(query)</span><br><span class="line">            print(&quot;\n&quot; + response)  # 打印AI响应结果</span><br><span class="line"></span><br><span class="line">        except Exception as e:  # 捕获所有异常</span><br><span class="line">            print(f&quot;\n错误: &#123;str(e)&#125;&quot;)  # 打印错误信息</span><br><span class="line"></span><br><span class="line">async def cleanup(self):</span><br><span class="line">    &quot;&quot;&quot;清理资源&quot;&quot;&quot;</span><br><span class="line">    await self.exit_stack.aclose()  # 异步关闭所有在exit_stack中管理的资源</span><br></pre></td></tr></table></figure>
<h4 id="主入口点">主入口点</h4>
<p>最后，我们将添加主要的执行逻辑：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">async def main():</span><br><span class="line">    # 检查命令行参数数量，如果少于2个则显示使用说明</span><br><span class="line">    if len(sys.argv) &lt; 2:</span><br><span class="line">        print(&quot;用法: python client.py &lt;服务器脚本路径&gt;&quot;)</span><br><span class="line">        sys.exit(1)  # 退出程序，返回错误码1</span><br><span class="line"></span><br><span class="line">    # 创建MCP客户端实例</span><br><span class="line">    client = MCPClient()</span><br><span class="line">    try:</span><br><span class="line">        # 连接到服务器，sys.argv[1]是第一个命令行参数（服务器脚本路径）</span><br><span class="line">        await client.connect_to_server(sys.argv[1])</span><br><span class="line">        # 启动交互式聊天循环</span><br><span class="line">        await client.chat_loop()</span><br><span class="line">    finally:</span><br><span class="line">        # 确保程序结束时清理资源</span><br><span class="line">        await client.cleanup()</span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    import sys  # 导入sys模块用于处理命令行参数</span><br><span class="line">    # 运行异步主函数</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/QQ20250801-164738.png" alt="QQ20250801-164738">
<figcaption aria-hidden="true">QQ20250801-164738</figcaption>
</figure>
<h3 id="运行客户端">运行客户端</h3>
<p>要使您的客户端与任何 MCP 服务器运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uv run client.py path/to/server.py # python server</span><br><span class="line">uv run client.py path/to/build/index.js # node server</span><br></pre></td></tr></table></figure>
<p>客户端将：</p>
<ol type="1">
<li>连接到指定服务器</li>
<li>列出可用工具</li>
<li>开始一个交互式聊天会话，您可以在其中：
<ul>
<li>输入查询</li>
<li>查看工具执行情况</li>
<li>从 Claude 获取响应</li>
</ul></li>
</ol>
<h3 id="运作流程">运作流程</h3>
<p>当你提交查询时：</p>
<ol type="1">
<li>客户端从服务器获取可用工具列表</li>
<li>你的查询连同工具描述一起发送给 Claude</li>
<li>Claude 决定使用哪些工具（如果有的话）</li>
<li>客户端通过服务器执行任何请求的工具调用</li>
<li>结果会发送回 Claude</li>
<li>Claude 提供自然语言响应</li>
<li>响应显示给您</li>
</ol>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://modelcontextprotocol.io/quickstart/client#main-entry-point">Build
an MCP Client - Model Context Protocol</a></p>
<h3 id="适配openai版本">适配openai版本</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import json</span><br><span class="line">import sys</span><br><span class="line">from typing import Optional</span><br><span class="line">from contextlib import AsyncExitStack</span><br><span class="line"></span><br><span class="line">from mcp import ClientSession, StdioServerParameters</span><br><span class="line">from mcp.client.stdio import stdio_client</span><br><span class="line"></span><br><span class="line">from openai import OpenAI</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">load_dotenv()  # 从 .env 文件加载环境变量</span><br><span class="line"></span><br><span class="line">class MCPClient:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        # 初始化会话和客户端对象</span><br><span class="line">        self.session: Optional[ClientSession] = None  # MCP客户端会话</span><br><span class="line">        self.exit_stack = AsyncExitStack()  # 异步上下文管理器堆栈，用于资源清理</span><br><span class="line">        self.anthropic = OpenAI(</span><br><span class="line">            api_key=os.getenv(&quot;DASHSCOPE_API_KEY&quot;),</span><br><span class="line">            base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">        )  # 使用OpenAI兼容模式连接通义千问</span><br><span class="line">        </span><br><span class="line">    async def connect_to_server(self, server_script_path: str):</span><br><span class="line">        &quot;&quot;&quot;连接到MCP服务器</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            server_script_path (str): 服务器脚本路径，支持.py或.js文件</span><br><span class="line">        </span><br><span class="line">        Raises:</span><br><span class="line">            ValueError: 当脚本文件不是.py或.js格式时抛出</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 检查是否为Python文件</span><br><span class="line">        is_python = server_script_path.endswith(&#x27;.py&#x27;)</span><br><span class="line">        # 检查是否为JavaScript文件</span><br><span class="line">        is_js = server_script_path.endswith(&#x27;.js&#x27;)</span><br><span class="line">        </span><br><span class="line">        # 如果不是Python或JavaScript文件，则抛出错误</span><br><span class="line">        if not (is_python or is_js):</span><br><span class="line">            raise ValueError(&quot;服务器脚本必须是 .py 或 .js 文件&quot;)</span><br><span class="line"></span><br><span class="line">        # 根据文件类型确定执行命令</span><br><span class="line">        command = &quot;python&quot; if is_python else &quot;node&quot;</span><br><span class="line">        </span><br><span class="line">        # 创建服务器参数对象</span><br><span class="line">        server_params = StdioServerParameters(</span><br><span class="line">            command=command,           # 执行命令</span><br><span class="line">            args=[server_script_path], # 脚本路径作为参数</span><br><span class="line">            env=None                   # 环境变量（使用默认环境）</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 建立stdio客户端连接并将其添加到异步上下文管理器中</span><br><span class="line">        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))</span><br><span class="line">        self.stdio, self.write = stdio_transport</span><br><span class="line">        </span><br><span class="line">        # 创建客户端会话并将其添加到异步上下文管理器中</span><br><span class="line">        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))</span><br><span class="line"></span><br><span class="line">        # 初始化会话</span><br><span class="line">        await self.session.initialize()</span><br><span class="line"></span><br><span class="line">        # 列出可用的工具</span><br><span class="line">        response = await self.session.list_tools()</span><br><span class="line">        tools = response.tools</span><br><span class="line">        </span><br><span class="line">        # 打印连接的服务器提供的工具列表</span><br><span class="line">        print(&quot;\n已连接到服务器，可用工具:&quot;, [tool.name for tool in tools])</span><br><span class="line"></span><br><span class="line">    async def process_query(self, query: str) -&gt; str:</span><br><span class="line">        &quot;&quot;&quot;使用Qwen和可用工具处理查询&quot;&quot;&quot;</span><br><span class="line">        # 构建消息列表</span><br><span class="line">        messages = [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: query</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        # 获取可用工具列表并转换为OpenAI格式</span><br><span class="line">        response = await self.session.list_tools()</span><br><span class="line">        available_tools = []</span><br><span class="line">        for tool in response.tools:</span><br><span class="line">            schema = tool.inputSchema</span><br><span class="line">            if isinstance(schema, str):</span><br><span class="line">                schema = json.loads(schema)</span><br><span class="line">            if isinstance(schema, dict) and &quot;properties&quot; in schema:</span><br><span class="line">                schema = &#123;&quot;type&quot;: &quot;object&quot;, **schema&#125;</span><br><span class="line"></span><br><span class="line">            available_tools.append(&#123;</span><br><span class="line">                &quot;type&quot;: &quot;function&quot;,</span><br><span class="line">                &quot;function&quot;: &#123;</span><br><span class="line">                    &quot;name&quot;: tool.name,</span><br><span class="line">                    &quot;description&quot;: tool.description,</span><br><span class="line">                    &quot;parameters&quot;: schema</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">        # 第一次调用模型</span><br><span class="line">        response = self.anthropic.chat.completions.create(</span><br><span class="line">            model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">            max_tokens=1000,</span><br><span class="line">            messages=messages,</span><br><span class="line">            tools=available_tools,</span><br><span class="line">            extra_body=&#123;&quot;enable_thinking&quot;: False&#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        final_text = []</span><br><span class="line">        message = response.choices[0].message</span><br><span class="line"></span><br><span class="line">        # 处理文本内容</span><br><span class="line">        if message.content:</span><br><span class="line">            final_text.append(message.content)</span><br><span class="line"></span><br><span class="line">        # 处理工具调用</span><br><span class="line">        if message.tool_calls:</span><br><span class="line">            for tool_call in message.tool_calls:</span><br><span class="line">                tool_name = tool_call.function.name</span><br><span class="line">                tool_args = json.loads(tool_call.function.arguments)</span><br><span class="line">                </span><br><span class="line">                # 执行工具调用</span><br><span class="line">                result = await self.session.call_tool(tool_name, tool_args)</span><br><span class="line">                final_text.append(f&quot;[调用工具 &#123;tool_name&#125;，参数 &#123;tool_args&#125;]&quot;)</span><br><span class="line">                </span><br><span class="line">                # 处理工具结果</span><br><span class="line">                tool_result_content = &quot;&quot;</span><br><span class="line">                if result.content:</span><br><span class="line">                    for item in result.content:</span><br><span class="line">                        if hasattr(item, &#x27;type&#x27;) and item.type == &#x27;text&#x27;:</span><br><span class="line">                            tool_result_content += item.text</span><br><span class="line">                        else:</span><br><span class="line">                            tool_result_content += str(item)</span><br><span class="line"></span><br><span class="line">                # 添加助手消息到历史</span><br><span class="line">                messages.append(&#123;</span><br><span class="line">                    &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                    &quot;content&quot;: None,</span><br><span class="line">                    &quot;tool_calls&quot;: [tool_call]</span><br><span class="line">                &#125;)</span><br><span class="line">                </span><br><span class="line">                # 添加工具执行结果到历史</span><br><span class="line">                messages.append(&#123;</span><br><span class="line">                    &quot;role&quot;: &quot;tool&quot;,</span><br><span class="line">                    &quot;tool_call_id&quot;: tool_call.id,</span><br><span class="line">                    &quot;content&quot;: tool_result_content</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">                # 再次调用模型</span><br><span class="line">                response = self.anthropic.chat.completions.create(</span><br><span class="line">                    model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">                    max_tokens=1000,</span><br><span class="line">                    messages=messages,</span><br><span class="line">                    tools=available_tools,</span><br><span class="line">                    extra_body=&#123;&quot;enable_thinking&quot;: False&#125;</span><br><span class="line">                )</span><br><span class="line">                </span><br><span class="line">                # 处理最终响应</span><br><span class="line">                if response.choices and response.choices[0].message.content:</span><br><span class="line">                    final_text.append(response.choices[0].message.content)</span><br><span class="line"></span><br><span class="line">        return &quot;\n&quot;.join(final_text)</span><br><span class="line"></span><br><span class="line">    async def chat_loop(self):</span><br><span class="line">        &quot;&quot;&quot;运行交互式聊天循环&quot;&quot;&quot;</span><br><span class="line">        print(&quot;\nMCP客户端已启动!&quot;)</span><br><span class="line">        print(&quot;输入您的问题或输入&#x27;quit&#x27;退出。&quot;)</span><br><span class="line"></span><br><span class="line">        while True:  # 无限循环，持续接收用户输入</span><br><span class="line">            try:</span><br><span class="line">                query = input(&quot;\n问题: &quot;).strip()  # 获取用户输入并去除首尾空格</span><br><span class="line"></span><br><span class="line">                if query.lower() == &#x27;quit&#x27;:  # 如果用户输入&#x27;quit&#x27;（不区分大小写）</span><br><span class="line">                    break  # 退出循环</span><br><span class="line"></span><br><span class="line">                # 处理用户查询并获取响应</span><br><span class="line">                response = await self.process_query(query)</span><br><span class="line">                print(&quot;\n&quot; + response)  # 打印AI响应结果</span><br><span class="line"></span><br><span class="line">            except Exception as e:  # 捕获所有异常</span><br><span class="line">                print(f&quot;\n错误: &#123;str(e)&#125;&quot;)  # 打印错误信息</span><br><span class="line">                import traceback</span><br><span class="line">                traceback.print_exc()  # 打印详细错误信息</span><br><span class="line"></span><br><span class="line">    async def cleanup(self):</span><br><span class="line">        &quot;&quot;&quot;清理资源&quot;&quot;&quot;</span><br><span class="line">        await self.exit_stack.aclose()  # 异步关闭所有在exit_stack中管理的资源</span><br><span class="line"></span><br><span class="line">async def main():</span><br><span class="line">    # 检查命令行参数数量，如果少于2个则显示使用说明</span><br><span class="line">    if len(sys.argv) &lt; 2:</span><br><span class="line">        print(&quot;用法: python client.py &lt;服务器脚本路径&gt;&quot;)</span><br><span class="line">        sys.exit(1)  # 退出程序，返回错误码1</span><br><span class="line"></span><br><span class="line">    # 创建MCP客户端实例</span><br><span class="line">    client = MCPClient()</span><br><span class="line">    try:</span><br><span class="line">        # 连接到服务器，sys.argv[1]是第一个命令行参数（服务器脚本路径）</span><br><span class="line">        await client.connect_to_server(sys.argv[1])</span><br><span class="line">        # 启动交互式聊天循环</span><br><span class="line">        await client.chat_loop()</span><br><span class="line">    finally:</span><br><span class="line">        # 确保程序结束时清理资源</span><br><span class="line">        await client.cleanup()</span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 运行异步主函数</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>
<h3 id="openai和claude在工具调用的差异">openai和claude在工具调用的差异</h3>
<ol type="1">
<li><strong>工具格式转换修复</strong></li>
</ol>
<p><strong>问题</strong>：MCP工具格式与OpenAI API不兼容
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原错误格式</span></span><br><span class="line">available_tools = [&#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">    <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">    <span class="string">&quot;input_schema&quot;</span>: tool.inputSchema</span><br><span class="line">&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后格式（符合OpenAI规范）</span></span><br><span class="line">available_tools = [&#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">    <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">        <span class="string">&quot;parameters&quot;</span>: schema  <span class="comment"># 正确的JSON Schema格式</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure></p>
<ol start="2" type="1">
<li><strong>API响应处理修复</strong></li>
</ol>
<p><strong>问题</strong>：错误访问了OpenAI响应对象的属性
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原错误代码</span></span><br><span class="line"><span class="keyword">for</span> content <span class="keyword">in</span> response.content:  <span class="comment"># ❌ response没有content属性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后代码</span></span><br><span class="line">message = response.choices[<span class="number">0</span>].message  <span class="comment"># ✅ 正确的访问路径</span></span><br><span class="line"><span class="keyword">if</span> message.content:</span><br><span class="line">    final_text.append(message.content)</span><br><span class="line"><span class="keyword">if</span> message.tool_calls:</span><br><span class="line">    <span class="keyword">for</span> tool_call <span class="keyword">in</span> message.tool_calls:</span><br><span class="line">        <span class="comment"># 处理工具调用</span></span><br></pre></td></tr></table></figure></p>
<ol start="3" type="1">
<li><strong>工具调用结果处理修复</strong></li>
</ol>
<p><strong>问题</strong>：错误处理MCP工具调用返回的结果结构
<strong>修复</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原错误代码</span></span><br><span class="line"><span class="string">&quot;content&quot;</span>: result.content  <span class="comment"># ❌ 可能包含复杂对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后代码</span></span><br><span class="line">tool_result_content = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> result.content:</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> result.content:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(item, <span class="string">&#x27;type&#x27;</span>) <span class="keyword">and</span> item.<span class="built_in">type</span> == <span class="string">&#x27;text&#x27;</span>:</span><br><span class="line">            tool_result_content += item.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tool_result_content += <span class="built_in">str</span>(item)</span><br></pre></td></tr></table></figure>
<ol start="4" type="1">
<li><strong>消息历史构建修复</strong></li>
</ol>
<p><strong>问题</strong>：工具调用后消息历史格式不正确
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正确的消息历史格式</span></span><br><span class="line">messages.append(&#123;</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>,</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: <span class="literal">None</span>,</span><br><span class="line">    <span class="string">&quot;tool_calls&quot;</span>: [tool_call]</span><br><span class="line">&#125;)</span><br><span class="line">messages.append(&#123;</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">    <span class="string">&quot;tool_call_id&quot;</span>: tool_call.<span class="built_in">id</span>,</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: tool_result_content</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p>
<ol start="5" type="1">
<li><strong>JSON Schema兼容性处理</strong></li>
</ol>
<p><strong>问题</strong>：MCP返回的schema可能缺少必要的根类型定义
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">schema = tool.inputSchema</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(schema, <span class="built_in">str</span>):</span><br><span class="line">    schema = json.loads(schema)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(schema, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&quot;properties&quot;</span> <span class="keyword">in</span> schema:</span><br><span class="line">    schema = &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>, **schema&#125;  <span class="comment"># 确保有根类型</span></span><br></pre></td></tr></table></figure></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/langgraph%E5%AE%9E%E6%88%98mcp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/langgraph%E5%AE%9E%E6%88%98mcp/" class="post-title-link" itemprop="url">langgraph实战mcp</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-08-01 00:00:00" itemprop="dateCreated datePublished" datetime="2025-08-01T00:00:00+08:00">2025-08-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-02 11:47:14" itemprop="dateModified" datetime="2025-08-02T11:47:14+08:00">2025-08-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/mcp/" itemprop="url" rel="index"><span itemprop="name">mcp</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="环境配置">环境配置</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install langchain-mcp-adapters</span><br></pre></td></tr></table></figure>
<h3 id="使用langgraph调用mcp">使用langgraph调用mcp</h3>
<p>要点主要是利用MultiServerMCPClient构建服务，获取tool</p>
<p>利用预设的create_react_agent构建ReAct架构的智能体并调用工具</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">import asyncio # 需要导入 asyncio 来运行异步函数</span><br><span class="line"># 从langchain_mcp_adapters.client模块导入MultiServerMCPClient类</span><br><span class="line"># 从langgraph.prebuilt模块导入create_react_agent函数</span><br><span class="line">from langchain_mcp_adapters.client import MultiServerMCPClient</span><br><span class="line">from langgraph.prebuilt import create_react_agent</span><br><span class="line"></span><br><span class="line"># 导入 LLM 相关库</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"># 将主要逻辑封装在一个异步函数中</span><br><span class="line">async def main():</span><br><span class="line">    # 创建MultiServerMCPClient实例，配置两个不同的服务</span><br><span class="line">    client = MultiServerMCPClient(</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;math&quot;: &#123;  # 数学计算服务</span><br><span class="line">                &quot;command&quot;: &quot;python&quot;,  # 使用python命令启动</span><br><span class="line">                # 替换为你的math_server.py文件的绝对路径</span><br><span class="line">                &quot;args&quot;: [&quot;/workspace/langgraph-mcp/math_server.py&quot;],</span><br><span class="line">                &quot;transport&quot;: &quot;stdio&quot;,  # 使用标准输入输出传输</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;weather&quot;: &#123;  # 天气服务</span><br><span class="line">                # 确保你的天气服务器在8000端口运行</span><br><span class="line">                # *** 确保这个 URL 是正确的，并且服务器正在运行 ***</span><br><span class="line">                &quot;url&quot;: &quot;http://localhost:8000/mcp&quot;,</span><br><span class="line">                &quot;transport&quot;: &quot;streamable_http&quot;,  # 使用可流式HTTP传输</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tools = []</span><br><span class="line">    try:</span><br><span class="line">        # 在异步函数内部正确使用 await</span><br><span class="line">        tools = await client.get_tools()</span><br><span class="line">        print(f&quot;成功获取到 &#123;len(tools)&#125; 个MCP工具。&quot;)</span><br><span class="line">        for tool_item in tools:</span><br><span class="line">            print(f&quot;  - &#123;tool_item.name&#125;: &#123;tool_item.description&#125;&quot;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;获取MCP工具失败: &#123;e&#125;&quot;)</span><br><span class="line">        print(&quot;请确保MCP服务URL有效且可访问，或者您已正确配置了认证信息。&quot;)</span><br><span class="line">        # 在函数内部，如果出错可以选择返回或继续处理</span><br><span class="line">        # return # 这里可以 return，但会结束 main 函数</span><br><span class="line"></span><br><span class="line">    if not tools:</span><br><span class="line">        print(&quot;没有获取到工具，无法创建代理。&quot;)</span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    # 创建ReAct代理</span><br><span class="line">    llm = ChatOpenAI(</span><br><span class="line">        model=&quot;qwen3-235b-a22b-thinking-2507&quot;,</span><br><span class="line">        api_key=&quot;sk-a8ef27c47ea84224ac6eed6d4bba1bab&quot;,</span><br><span class="line">        base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot; # 修正了末尾多余的空格</span><br><span class="line">    )</span><br><span class="line">    agent = create_react_agent(llm, tools)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    # 异步调用代理来解决数学问题</span><br><span class="line">    # 确保在异步函数内部使用 await</span><br><span class="line">    math_response = await agent.ainvoke(</span><br><span class="line">        &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what&#x27;s (3 + 5) x 12?&quot;&#125;]&#125;</span><br><span class="line">    )</span><br><span class="line">    print(&quot;\n--- 数学问题回答 ---&quot;)</span><br><span class="line">    print(math_response[&quot;messages&quot;][-1].content) # 打印最后一条消息（LLM的回答）</span><br><span class="line"></span><br><span class="line">    # 异步调用代理来查询天气</span><br><span class="line">    weather_response = await agent.ainvoke(</span><br><span class="line">        &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is the weather in nyc?&quot;&#125;]&#125;</span><br><span class="line">    )</span><br><span class="line">    print(&quot;\n--- 天气问题回答 ---&quot;)</span><br><span class="line">    print(weather_response[&quot;messages&quot;][-1].content) # 打印最后一条消息（LLM的回答）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># --- 这是脚本的入口点 ---</span><br><span class="line"># 使用 asyncio.run() 来运行你的主异步函数</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    asyncio.run(main())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/agents/mcp/">使用
MCP - LangChain 框架</a></p>
<h3 id="框架流程">框架流程</h3>
<figure>
<img src="/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/langgraph%E5%AE%9E%E6%88%98mcp/image-20250801164905578.png" alt="image-20250801164905578">
<figcaption aria-hidden="true">image-20250801164905578</figcaption>
</figure>
<p>✅ 三个角色（系统组件）</p>
<table>
<colgroup>
<col style="width: 28%">
<col style="width: 72%">
</colgroup>
<thead>
<tr class="header">
<th>角色</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Client</strong></td>
<td>前端或用户界面，发起请求</td>
</tr>
<tr class="even">
<td><strong>Auth Provider</strong></td>
<td>认证服务（如 OAuth、JWT 提供者），负责登录和签发 token</td>
</tr>
<tr class="odd">
<td><strong>LangGraph Backend</strong></td>
<td>应用的后端服务，处理业务逻辑</td>
</tr>
<tr class="even">
<td><strong>Secret Store</strong></td>
<td>存放用户敏感信息（如 token、密钥等）</td>
</tr>
<tr class="odd">
<td><strong>MCP Server</strong></td>
<td>后端工具服务，提供具体的工具或资源接口</td>
</tr>
</tbody>
</table>
<p>✅ 流程详解（12步）</p>
<p>🔐 阶段一：用户登录 &amp; 获取 Token（1~6）</p>
<ol type="1">
<li><p><strong>用户登录</strong><br>
Client 提交用户名和密码给 Auth Provider。</p></li>
<li><p><strong>返回 Token</strong><br>
Auth Provider 验证成功后，返回一个访问令牌（token）。</p></li>
<li><p><strong>携带 Token 请求</strong><br>
Client 将 token 附加在请求头中，发给 LangGraph Backend。</p></li>
<li><p><strong>验证 Token</strong><br>
LangGraph Backend 使用 <code>@auth.authenticate</code> 中间件验证 token
是否有效。</p></li>
<li><p><strong>获取用户信息</strong><br>
验证通过后，LangGraph Backend 从 Auth Provider
拉取用户详细信息。</p></li>
<li><p><strong>确认有效性</strong><br>
后端确认用户信息无误，流程继续。</p></li>
</ol>
<p>🔑 阶段二：获取用户权限 Token（6a~6b）</p>
<p>6a. <strong>拉取用户权限 Token</strong><br>
LangGraph Backend 从 Secret Store 获取该用户对应的权限 token（可能是 MCP
所需的访问凭证）。</p>
<p>6b. <strong>返回权限 Token</strong><br>
Secret Store 返回该 token。</p>
<p>🛠️ 阶段三：调用工具 &amp; 返回结果（7~12）</p>
<ol start="7" type="1">
<li><p><strong>权限控制检查</strong><br>
LangGraph Backend 使用 <code>@auth.on.*</code>
权限控制逻辑，确认用户是否有权调用该工具。</p></li>
<li><p><strong>构建 MCP Client</strong><br>
后端用用户的权限 token 构建一个 MCP 客户端。</p></li>
<li><p><strong>调用 MCP 工具</strong><br>
MCP Client 发起请求，调用某个具体工具，携带
token（通常放在请求头中）。</p></li>
<li><p><strong>MCP 验证并执行</strong><br>
MCP Server 验证 token 是否有效，确认无误后执行工具逻辑。</p></li>
<li><p><strong>工具返回结果</strong><br>
MCP Server 返回工具执行结果或资源数据。</p></li>
<li><p><strong>返回给前端</strong><br>
LangGraph Backend 将结果返回给 Client，完成整个链路。</p></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">张熙浚</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="本站访问数 fa fa-user 次"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="本站总访问量 fa fa-eye 次"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="400" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
