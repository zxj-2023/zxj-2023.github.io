<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="zxj Blogs">
<meta property="og:type" content="website">
<meta property="og:title" content="Zhang XiJun">
<meta property="og:url" content="http://example.com/page/3/index.html">
<meta property="og:site_name" content="Zhang XiJun">
<meta property="og:description" content="zxj Blogs">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="张熙浚">
<meta property="article:tag" content="zxj">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Zhang XiJun</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhang XiJun</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">BLOGS</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="张熙浚"
      src="/images/zxjavatar.gif">
  <p class="site-author-name" itemprop="name">张熙浚</p>
  <div class="site-description" itemprop="description">zxj Blogs</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">127</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">47</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zxj-2023" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxj-2023" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=2902065320&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;2902065320&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener me" target="_blank"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zxj-2023.github.io/" title="https:&#x2F;&#x2F;zxj-2023.github.io" rel="noopener" target="_blank">Zhang XiJun</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org" rel="noopener" target="_blank">NexT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/" class="post-title-link" itemprop="url">LangGraph学习——agent——下</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-22T00:00:00+08:00">2025-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-13 09:25:37" itemprop="dateModified" datetime="2025-08-13T09:25:37+08:00">2025-08-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本教程为langchain官方教程的学习记录</p>
<p><a target="_blank" rel="noopener" href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a target="_blank" rel="noopener" href="https://github.com/zxj-2023/learn-rag-langchain"><a target="_blank" rel="noopener" href="https://github.com/zxj-2023/learn-rag-langchain/tree/main/academy-langgraph">learn-rag-langchain/academy-langgraph at main · zxj-2023/learn-rag-langchain</a></a></p>
<h3 id="module-4"><a href="#module-4" class="headerlink" title="module-4"></a>module-4</h3><h4 id="Parallel-node-execution-并行节点执行"><a href="#Parallel-node-execution-并行节点执行" class="headerlink" title="Parallel node execution 并行节点执行"></a><strong>Parallel node execution</strong> <strong>并行节点执行</strong></h4><h5 id="Waiting-for-nodes-to-finish-等待节点完成"><a href="#Waiting-for-nodes-to-finish-等待节点完成" class="headerlink" title="Waiting for nodes to finish 等待节点完成"></a><strong>Waiting for nodes to finish</strong> <strong>等待节点完成</strong></h5><p>现在，让我们考虑一个案例，其中一个并行路径的步骤比另一个多。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># Initialize each node with node_secret </span><br><span class="line">builder.add_node(&quot;a&quot;, ReturnNodeValue(&quot;I&#x27;m A&quot;))</span><br><span class="line">builder.add_node(&quot;b&quot;, ReturnNodeValue(&quot;I&#x27;m B&quot;))</span><br><span class="line">builder.add_node(&quot;b2&quot;, ReturnNodeValue(&quot;I&#x27;m B2&quot;))</span><br><span class="line">builder.add_node(&quot;c&quot;, ReturnNodeValue(&quot;I&#x27;m C&quot;))</span><br><span class="line">builder.add_node(&quot;d&quot;, ReturnNodeValue(&quot;I&#x27;m D&quot;))</span><br><span class="line"></span><br><span class="line"># Flow</span><br><span class="line">builder.add_edge(START, &quot;a&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;b&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;c&quot;)</span><br><span class="line">builder.add_edge(&quot;b&quot;, &quot;b2&quot;)</span><br><span class="line">builder.add_edge([&quot;b2&quot;, &quot;c&quot;], &quot;d&quot;)</span><br><span class="line">builder.add_edge(&quot;d&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722143802652.png" alt="image-20250722143802652"></p>
<p>在这种情况下，<code>b</code>、<code>b2</code> 和 <code>c</code> 都是同一个步骤的一部分。图形将在进入 <code>d</code> 步骤之前等待所有这些操作完成。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Adding I&#x27;m A to []</span><br><span class="line">Adding I&#x27;m B to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m C to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m B2 to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;]</span><br><span class="line">Adding I&#x27;m D to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;]</span><br><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Setting-the-order-of-state-updates-设置状态更新的顺序"><a href="#Setting-the-order-of-state-updates-设置状态更新的顺序" class="headerlink" title="Setting the order of state updates 设置状态更新的顺序"></a><strong>Setting the order of state updates</strong> <strong>设置状态更新的顺序</strong></h5><p>然而，在每个步骤中，我们无法对状态更新的顺序进行具体控制！简单来说，它是基于图拓扑结构由 LangGraph 确定的确定性顺序，该顺序为 <strong><em>\</em>我们无法控制**</strong>。</p>
<p>上面，我们看到 <code>c</code> 被添加在 <code>b2</code> 之前</p>
<p>然而，我们可以使用自定义 reducer 来定制此功能，例如，对状态更新进行排序。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def sorting_reducer(left, right):</span><br><span class="line">    &quot;&quot;&quot; 合并并排序列表中的值&quot;&quot;&quot;</span><br><span class="line">    # 如果 left 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(left, list):</span><br><span class="line">        left = [left]</span><br><span class="line"></span><br><span class="line">    # 如果 right 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(right, list):</span><br><span class="line">        right = [right]</span><br><span class="line">    </span><br><span class="line">    # 合并 left 和 right 列表，然后升序排序</span><br><span class="line">    return sorted(left + right, reverse=False)</span><br><span class="line">class State(TypedDict):</span><br><span class="line">    # sorting_reducer 函数将对 state 中的值进行排序</span><br><span class="line">    state: Annotated[list, sorting_reducer]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<p>现在，reducer 对更新的状态值进行排序！<code>sorting_reducer</code> 示例对所有值进行全局排序。我们还可以：</p>
<ol>
<li>在并行步骤期间将输出写入状态中的单独字段  </li>
<li>在并行步骤之后使用“汇”节点来合并和排序这些输出  </li>
<li>合并后清除临时字段</li>
</ol>
<p>请参阅 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/branching/#stable-sorting">docs</a> 以获取更多详细信息。</p>
<h5 id="Working-with-LLMs-使用-LLMs"><a href="#Working-with-LLMs-使用-LLMs" class="headerlink" title="Working with LLMs  使用 LLMs"></a><strong>Working with LLMs</strong>  <strong>使用 LLMs</strong></h5><p>现在，让我们添加一个现实中的例子！我们希望从两个外部来源（Wikipedia 和 Web-Search）收集上下文信息，并让 LLM 回答一个问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br><span class="line">from langchain_community.tools import TavilySearchResults</span><br><span class="line"></span><br><span class="line">def search_web(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">    search_docs = tavily_search.invoke(state[&#x27;question&#x27;])</span><br><span class="line"></span><br><span class="line">     # 将多个搜索文档转换成了一个统一格式的长文本，每个文档都有自己的元数据（如URL），并且文档之间有明确的分隔，便于后续处理或展示。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    - 这是一个 列表推导式 (list comprehension) ，它会遍历 search_docs 列表中的每一个元素（这里我们称之为 doc ）。</span><br><span class="line">    - search_docs 里的每个 doc 应该是一个包含 &#x27;url&#x27; 和 &#x27;content&#x27; 键的字典。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = WikipediaLoader(query=state[&#x27;question&#x27;], </span><br><span class="line">                                  load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def generate_answer(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 用于回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    question = state[&quot;question&quot;]</span><br><span class="line"></span><br><span class="line">    # 模板</span><br><span class="line">    answer_template = &quot;&quot;&quot;使用以下上下文回答问题 &#123;question&#125;: &#123;context&#125;&quot;&quot;&quot;</span><br><span class="line">    answer_instructions = answer_template.format(question=question, </span><br><span class="line">                                                       context=context)    </span><br><span class="line">    </span><br><span class="line">    # 回答</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=answer_instructions)]+[HumanMessage(content=f&quot;回答问题。&quot;)])</span><br><span class="line">      </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;answer&quot;: answer&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点</span><br><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># 初始化每个节点</span><br><span class="line">builder.add_node(&quot;search_web&quot;,search_web)</span><br><span class="line">builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">builder.add_node(&quot;generate_answer&quot;, generate_answer)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">builder.add_edge(START, &quot;search_wikipedia&quot;)</span><br><span class="line">builder.add_edge(START, &quot;search_web&quot;)</span><br><span class="line">builder.add_edge(&quot;search_wikipedia&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;search_web&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;generate_answer&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722153534867.png" alt="image-20250722153534867"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = graph.invoke(&#123;&quot;question&quot;: &quot;英伟达2025年第一季度财报表现如何&quot;&#125;)</span><br><span class="line">result[&#x27;answer&#x27;].content</span><br></pre></td></tr></table></figure>
<h4 id="Sub-graphs-子图"><a href="#Sub-graphs-子图" class="headerlink" title="Sub-graphs 子图"></a><strong>Sub-graphs</strong> 子图</h4><p>子图允许你在图表的不同部分创建和管理不同的状态。这在多智能体系统中尤其有用，尤其是在每个智能体都有各自状态的智能体团队中。</p>
<p>让我们考虑一个简单的例子：</p>
<ul>
<li>我有一个系统，它接收日志。</li>
<li>该系统通过不同的代理执行两个独立的子任务（总结日志，查找故障模式）。</li>
<li>我希望在两个不同的子图中执行这两个操作。</li>
</ul>
<p>最重要的是要理解图表是如何传达信息的！</p>
<p>简而言之，通信是 <strong><em>\</em>通过重叠密钥**</strong> 实现的：</p>
<ul>
<li>子图可以访问父图中的 <code>docs</code>（文档）。</li>
<li>父图可以从子图中访问 <code>summary</code>（摘要）和 <code>failure_report</code>（故障报告）。</li>
</ul>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/66dbb1abf89f2d847ee6f1ff_sub-graph1.png" alt="subgraph.png"></p>
<ol>
<li><strong>Logs (Traces)</strong>:<ul>
<li>这是系统的输入，表示一系列的日志记录。</li>
</ul>
</li>
<li><strong>Entry Graph</strong>:<ul>
<li>这是系统的入口图，它包含了总体状态（Overall State），其中包含：<ul>
<li><code>docs</code>：文档或日志数据。</li>
<li><code>summary report</code>：摘要报告，这是系统执行摘要任务后生成的。</li>
<li><code>failure report</code>：故障报告，这是系统执行故障分析任务后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Call sub-graphs</strong>:<ul>
<li>这是从入口图调用两个子图的过程，分别用于执行摘要和故障分析任务。</li>
</ul>
</li>
<li><strong>Summarization</strong>:<ul>
<li>这个子图负责生成日志的摘要。它的状态（Summary State）包含：<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>summary</code>：摘要内容。</li>
<li><code>summary report</code>：摘要报告，这是摘要任务完成后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Failure Analysis</strong>:<ul>
<li>这个子图负责分析日志中的故障模式。它的状态（Failure Analysis State）包含：<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>failures</code>：故障模式。</li>
<li><code>failure report</code>：故障报告，这是故障分析任务完成后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Finish</strong>:<ul>
<li>这是流程的结束点，表示两个子图的任务都已完成，并且生成了摘要报告和故障报告。</li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from typing import List, Optional, Annotated</span><br><span class="line"></span><br><span class="line">#logs结构</span><br><span class="line">class Log(TypedDict):</span><br><span class="line">    id: str</span><br><span class="line">    question: str</span><br><span class="line">    docs: Optional[List]</span><br><span class="line">    answer: str</span><br><span class="line">    grade: Optional[int]</span><br><span class="line">    grader: Optional[str]</span><br><span class="line">    feedback: Optional[str]</span><br></pre></td></tr></table></figure>
<h5 id="Sub-graphs"><a href="#Sub-graphs" class="headerlink" title="Sub graphs"></a><strong>Sub graphs</strong></h5><p>这里是失败分析子图，它使用了 <code>FailureAnalysisState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line"># 故障分析子图</span><br><span class="line">class FailureAnalysisState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于故障分析的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    failures: List[Log]     # 包含故障的日志列表</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class FailureAnalysisOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;故障分析的输出状态。&quot;&quot;&quot;</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def get_failures(state):</span><br><span class="line">    &quot;&quot;&quot;获取包含故障的日志&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 从清理后的日志中筛选出包含 &quot;grade&quot; 键的日志，这些被视为故障</span><br><span class="line">    failures = [log for log in cleaned_logs if &quot;grade&quot; in log]</span><br><span class="line">    return &#123;&quot;failures&quot;: failures&#125;</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;生成故障摘要&quot;&quot;&quot;</span><br><span class="line">    failures = state[&quot;failures&quot;]</span><br><span class="line">    # 添加功能：fa_summary = summary_generation(qs_summary)</span><br><span class="line">    fa_summary = &quot;Chroma 文档的检索质量不佳。&quot;</span><br><span class="line">    # 为每个故障日志生成一个处理过的日志标识符</span><br><span class="line">    return &#123;&quot;fa_summary&quot;: fa_summary, &quot;processed_logs&quot;: [f&quot;failure-analysis-on-log-&#123;failure[&#x27;id&#x27;]&#125;&quot; for failure in failures]&#125;</span><br><span class="line"></span><br><span class="line">fa_builder = StateGraph(state_schema=FailureAnalysisState,output_schema=FailureAnalysisOutputState)</span><br><span class="line">fa_builder.add_node(&quot;get_failures&quot;, get_failures)</span><br><span class="line">fa_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">fa_builder.add_edge(START, &quot;get_failures&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;get_failures&quot;, &quot;generate_summary&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;generate_summary&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = fa_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723094949158.png" alt="image-20250723094949158"></p>
<p>这里是问题总结子图，它使用了 <code>QuestionSummarizationState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># 摘要生成子图</span><br><span class="line">class QuestionSummarizationState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于问题摘要的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    qs_summary: str         # 问题摘要</span><br><span class="line">    report: str             # 从摘要生成的报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class QuestionSummarizationOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;问题摘要的输出状态。&quot;&quot;&quot;</span><br><span class="line">    report: str             # 最终报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;从日志生成摘要。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 添加功能：summary = summarize(generate_summary)</span><br><span class="line">    summary = &quot;问题集中在 ChatOllama 和 Chroma 向量存储的使用上。&quot;</span><br><span class="line">    # 返回摘要以及已处理的日志ID</span><br><span class="line">    return &#123;&quot;qs_summary&quot;: summary, &quot;processed_logs&quot;: [f&quot;summary-on-log-&#123;log[&#x27;id&#x27;]&#125;&quot; for log in cleaned_logs]&#125;</span><br><span class="line"></span><br><span class="line">def send_to_slack(state):</span><br><span class="line">    &quot;&quot;&quot;模拟发送报告。&quot;&quot;&quot;</span><br><span class="line">    qs_summary = state[&quot;qs_summary&quot;]</span><br><span class="line">    # 添加功能：report = report_generation(qs_summary)</span><br><span class="line">    report = &quot;foo bar baz&quot;</span><br><span class="line">    return &#123;&quot;report&quot;: report&#125;</span><br><span class="line"></span><br><span class="line">qs_builder = StateGraph(QuestionSummarizationState,output_schema=QuestionSummarizationOutputState)</span><br><span class="line">qs_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">qs_builder.add_node(&quot;send_to_slack&quot;, send_to_slack)</span><br><span class="line">qs_builder.add_edge(START, &quot;generate_summary&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;generate_summary&quot;, &quot;send_to_slack&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;send_to_slack&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = qs_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723100648199.png" alt="image-20250723100648199"></p>
<h5 id="Adding-sub-graphs-to-our-parent-graph-向父图添加子图"><a href="#Adding-sub-graphs-to-our-parent-graph-向父图添加子图" class="headerlink" title="Adding sub graphs to our parent graph  向父图添加子图"></a><strong>Adding sub graphs to our parent graph </strong> <strong>向父图添加子图</strong></h5><p>现在，我们可以将所有内容整合在一起。我们使用 <code>EntryGraphState</code> 创建父图。并且我们将我们的子图添加为节点！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 入口图</span><br><span class="line">class EntryGraphState(TypedDict):</span><br><span class="line">    # 原始日志数据列表</span><br><span class="line">    raw_logs: List[Log]</span><br><span class="line">    # 经过清洗处理后的日志数据列表</span><br><span class="line">    cleaned_logs: List[Log]</span><br><span class="line">    fa_summary: str # 这只会在故障分析子图中生成</span><br><span class="line">    report: str # 这只会在问题摘要子图中生成</span><br><span class="line">    processed_logs:  Annotated[List[int], add] # 跟踪哪些日志已经被处理过 ，尤其是在子图之间共享状态时。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def clean_logs(state):</span><br><span class="line">    # 获取日志</span><br><span class="line">    raw_logs = state[&quot;raw_logs&quot;]</span><br><span class="line">    # 数据清洗 raw_logs -&gt; docs</span><br><span class="line">    cleaned_logs = raw_logs</span><br><span class="line">    return &#123;&quot;cleaned_logs&quot;: cleaned_logs&#125;</span><br><span class="line"></span><br><span class="line">entry_builder = StateGraph(EntryGraphState)</span><br><span class="line">entry_builder.add_node(&quot;clean_logs&quot;, clean_logs)</span><br><span class="line">#添加子图</span><br><span class="line">entry_builder.add_node(&quot;question_summarization&quot;, qs_builder.compile())</span><br><span class="line">entry_builder.add_node(&quot;failure_analysis&quot;, fa_builder.compile())</span><br><span class="line"></span><br><span class="line">entry_builder.add_edge(START, &quot;clean_logs&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;failure_analysis&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;question_summarization&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;failure_analysis&quot;, END)</span><br><span class="line">entry_builder.add_edge(&quot;question_summarization&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = entry_builder.compile()</span><br><span class="line"></span><br><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line"># 将 xray 设置为 1 将显示嵌套图的内部结构</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723102913524.png" alt="image-20250723102913524"></p>
<h4 id="Map-reduce"><a href="#Map-reduce" class="headerlink" title="Map-reduce"></a><strong>Map-reduce</strong></h4><p>LangGraph 里的 <strong>Map-Reduce</strong> 是一种<strong>并行处理模式</strong>，用于将一个大任务拆分成多个子任务（Map），再汇总结果（Reduce）。这是 LangGraph 中处理<strong>批量数据或并行节点执行</strong>的核心机制之一。</p>
<p>让我们设计一个系统，该系统将完成两件事情：</p>
<p>(1) <strong>映射（Map）</strong> —— 根据主题生成一组笑话。<br>(2) <strong>归约（Reduce）</strong> —— 从这组笑话中挑出最棒的一条。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"># Prompts we will use</span><br><span class="line">subjects_prompt = &quot;&quot;&quot;生成一个包含3个子主题的列表，这些子主题都与以下总体主题相关：&#123;topic&#125;。&quot;&quot;&quot;</span><br><span class="line">joke_prompt = &quot;&quot;&quot;生成一个关于&#123;subject&#125;的笑话&quot;&quot;&quot;</span><br><span class="line">best_joke_prompt = &quot;&quot;&quot;下面是关于&#123;topic&#125;的一堆笑话。选择最好的一个！返回最好笑话的ID，第一个笑话的ID从0开始。笑话：\n\n  &#123;jokes&#125;&quot;&quot;&quot;</span><br><span class="line"># LLM</span><br><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h5 id="Parallelizing-joke-generation-并行化笑话生成"><a href="#Parallelizing-joke-generation-并行化笑话生成" class="headerlink" title="Parallelizing joke generation 并行化笑话生成"></a><strong>Parallelizing joke generation</strong> <strong>并行化笑话生成</strong></h5><p>首先，让我们定义图的入口点，它将：</p>
<ul>
<li>接收用户输入的主题  </li>
<li>基于该主题生成若干“笑话子主题”  </li>
<li>将每个子主题发送到上面定义的笑话生成节点</li>
</ul>
<p>我们的状态有一个 <code>jokes</code> 键，它将累积来自并行化笑话生成的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Subjects(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示主题列表。&quot;&quot;&quot;</span><br><span class="line">    subjects: list[str] # 主题字符串列表</span><br><span class="line"></span><br><span class="line">class BestJoke(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示最佳笑话的ID。&quot;&quot;&quot;</span><br><span class="line">    id: int # 最佳笑话的索引ID</span><br><span class="line">    </span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;定义整个图的总体状态，使用TypedDict以便于类型提示和状态管理。&quot;&quot;&quot;</span><br><span class="line">    topic: str # 当前讨论的主题</span><br><span class="line">    subjects: list # 生成的子主题列表</span><br><span class="line">    jokes: Annotated[list, operator.add] # 笑话列表，使用operator.add表示列表内容会累加而不是覆盖</span><br><span class="line">    best_selected_joke: str # 最终选出的最佳笑话</span><br></pre></td></tr></table></figure>
<p>生成笑话的主题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#用于生成主题</span><br><span class="line">def generate_topics(state: OverallState):</span><br><span class="line">    #使用 Python 的 format() 方法来构建一个提示字符串（ prompt ）</span><br><span class="line">    prompt = subjects_prompt.format(topic=state[&quot;topic&quot;])</span><br><span class="line">    #.with_structured_output(Subjects) 它指示模型尝试将其输出格式化为 Subjects 类</span><br><span class="line">    response = model.with_structured_output(Subjects).invoke(prompt)</span><br><span class="line">    return &#123;&quot;subjects&quot;: response.subjects&#125;</span><br></pre></td></tr></table></figure>
<p>这就是妙处：我们利用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#send"><code>Send</code></a> 为每个主题并行生成笑话。</p>
<p>非常实用！无论主题数量多少，它都能自动并行处理。</p>
<ul>
<li><code>generate_joke</code>：图中节点的名字  </li>
<li><code>&#123;&quot;subject&quot;: s&#125;</code>：要传递的状态</li>
</ul>
<p><code>Send</code> 允许你向 <code>generate_joke</code> 节点发送<strong>任意</strong>结构的状态，无需与 <code>OverallState</code> 对齐。<br>在这里，<code>generate_joke</code> 使用自己的内部状态，我们通过 <code>Send</code> 按需填充即可。</p>
<blockquote>
<p>在 LangGraph 里，<code>Send</code> 是一个<strong>“动态派发器”</strong>：它让你<strong>在运行时</strong>决定“要把哪个节点运行多少次、每次给它什么数据”，并自动并行执行。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.types import Send</span><br><span class="line">def continue_to_jokes(state: OverallState):</span><br><span class="line">    # 该函数根据当前状态中的主题列表，为每个主题生成一个 Send 对象。</span><br><span class="line">    # 每个 Send 对象都指示图将数据发送到名为 &quot;generate_joke&quot; 的节点，</span><br><span class="line">    # 并将当前主题作为 &quot;subject&quot; 参数传递，从而实现并行生成笑话。</span><br><span class="line">    return [Send(&quot;generate_joke&quot;, &#123;&quot;subject&quot;: s&#125;) for s in state[&quot;subjects&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="Joke-generation-map-笑话生成"><a href="#Joke-generation-map-笑话生成" class="headerlink" title="Joke generation (map) 笑话生成"></a><strong>Joke generation (map)</strong> <strong>笑话生成</strong></h5><p>现在，我们只需定义一个节点来生成笑话，命名为 <code>generate_joke</code>！</p>
<p>生成的笑话会被写回到 <code>OverallState</code> 中的 <code>jokes</code> 字段。<br>该字段配有 reducer，能够自动把多次写入的列表合并成一个大列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 定义 JokeState，用于表示生成笑话任务的输入状态。</span><br><span class="line">class JokeState(TypedDict):</span><br><span class="line">    subject: str#笑话的主题</span><br><span class="line"></span><br><span class="line"># 定义 Joke 模型，用于表示模型生成的笑话的结构。</span><br><span class="line">class Joke(BaseModel):</span><br><span class="line">    joke: str#笑话的文本内容</span><br><span class="line"></span><br><span class="line"># 定义生成笑话的函数。</span><br><span class="line">def generate_joke(state: JokeState):</span><br><span class="line">    # 根据 joke_prompt 模板和当前状态中的主题格式化提示。</span><br><span class="line">    prompt = joke_prompt.format(subject=state[&quot;subject&quot;])</span><br><span class="line">    # 调用语言模型，并指定输出应结构化为 Joke 类型。</span><br><span class="line">    response = model.with_structured_output(Joke).invoke(prompt)</span><br><span class="line">    # 返回一个包含生成的笑话的字典，键为 &quot;jokes&quot;。</span><br><span class="line">    return &#123;&quot;jokes&quot;: [response.joke]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Best-joke-selection-reduce-最佳笑话选择"><a href="#Best-joke-selection-reduce-最佳笑话选择" class="headerlink" title="Best joke selection (reduce) 最佳笑话选择"></a><strong>Best joke selection (reduce)</strong> <strong>最佳笑话选择</strong></h5><p>现在，我们添加逻辑来挑选最好的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def best_joke(state: OverallState):</span><br><span class="line">    # 将状态中所有笑话列表连接成一个字符串，每个笑话之间用两个换行符分隔</span><br><span class="line">    jokes = &quot;\n\n&quot;.join(state[&quot;jokes&quot;])</span><br><span class="line">    # 使用主题和所有笑话格式化最佳笑话提示语</span><br><span class="line">    prompt = best_joke_prompt.format(topic=state[&quot;topic&quot;], jokes=jokes)</span><br><span class="line">    # 调用模型，期望其输出符合 BestJoke 结构（包含最佳笑话的ID）</span><br><span class="line">    response = model.with_structured_output(BestJoke).invoke(prompt)</span><br><span class="line">    # 根据模型返回的ID，从笑话列表中选择最佳笑话，并将其存储在状态的 best_selected_joke 字段中</span><br><span class="line">    return &#123;&quot;best_selected_joke&quot;: state[&quot;jokes&quot;][response.id]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Compile-编译"><a href="#Compile-编译" class="headerlink" title="Compile 编译"></a><strong>Compile</strong> 编译</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image</span><br><span class="line">from langgraph.graph import END, StateGraph, START</span><br><span class="line"></span><br><span class="line"># 构建图：将所有组件组合在一起构建我们的流程图</span><br><span class="line">graph = StateGraph(OverallState)</span><br><span class="line"></span><br><span class="line">graph.add_node(&quot;generate_topics&quot;, generate_topics)</span><br><span class="line">graph.add_node(&quot;generate_joke&quot;, generate_joke)</span><br><span class="line">graph.add_node(&quot;best_joke&quot;, best_joke)</span><br><span class="line"></span><br><span class="line">graph.add_edge(START, &quot;generate_topics&quot;)</span><br><span class="line"># 根据条件决定是否继续生成笑话</span><br><span class="line">graph.add_conditional_edges(&quot;generate_topics&quot;, continue_to_jokes, [&quot;generate_joke&quot;])</span><br><span class="line"># 生成笑话后执行选择最佳笑话</span><br><span class="line">graph.add_edge(&quot;generate_joke&quot;, &quot;best_joke&quot;)</span><br><span class="line"># 选择最佳笑话后流程结束</span><br><span class="line">graph.add_edge(&quot;best_joke&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = graph.compile()</span><br><span class="line">Image(app.get_graph().draw_mermaid_png())</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723112736244.png" alt="image-20250723112736244"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for s in app.stream(&#123;&quot;topic&quot;: &quot;日本广岛原子弹&quot;&#125;):</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;generate_topics&#x27;: &#123;&#x27;subjects&#x27;: [&#x27;原子弹投放的历史背景与决策过程&#x27;, &#x27;广岛原爆对城市与居民的影响&#x27;, &#x27;战后和平运动与核裁军倡议&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;战后和平运动的人开会讨论核裁军，一个人站起来说：‘我们必须彻底销毁所有核武器！’ 另一个人犹豫地举手：‘那……我们保留一个吧，就一个，藏在冰箱后面，以防万一。’&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&quot;杜鲁门宣布要结束战争，顾问问是否要使用原子弹。罗斯福的棺材板突然震动了一下，丘吉尔的雪茄掉在了地上，斯大林则默默拿起了电话：&#x27;同志，我们的计划可能需要再推迟一下。&#x27;&quot;]&#125;&#125;</span><br><span class="line">&#123;&#x27;best_joke&#x27;: &#123;&#x27;best_selected_joke&#x27;: &#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Research Assistant</strong> <strong>研究助理</strong></p>
<p>见另一篇文章</p>
<h3 id="module-5"><a href="#module-5" class="headerlink" title="module-5"></a>module-5</h3><h4 id="Chatbot-with-Memory-带有记忆功能的聊天机器人"><a href="#Chatbot-with-Memory-带有记忆功能的聊天机器人" class="headerlink" title="Chatbot with Memory 带有记忆功能的聊天机器人"></a><strong>Chatbot with Memory</strong> <strong>带有记忆功能的聊天机器人</strong></h4><p>在这里，我们将介绍 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Memory Store</a> 作为一种保存和检索长期记忆的方法。</p>
<blockquote>
<p>LangGraph Memory Store 是 <strong>LangGraph 提供的长期记忆存储接口</strong>，用于在 <strong>不同对话线程之间</strong> 持久化保存和检索用户信息。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>名称</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BaseStore</strong></td>
<td>抽象接口，定义了 <code>put/get/search/delete</code> 等操作方法</td>
</tr>
<tr>
<td><strong>InMemoryStore</strong></td>
<td>内存实现，适合原型验证</td>
</tr>
<tr>
<td><strong>RedisStore / AsyncRedisStore</strong></td>
<td>生产级实现，支持向量搜索、元数据过滤和命名空间管理</td>
</tr>
</tbody>
</table>
</div>
</blockquote>
<p>我们将构建一个使用 <code>short-term (within-thread仅当前对话线程)</code> 和 <code>long-term (across-thread跨所有对话线程    )</code> 内存的聊天机器人。</p>
<p>我们将重点关注长期 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory">semantic memory<strong>（语义记忆）</strong></a>，它将包含关于用户的事实信息。这些长期记忆将被用于创建一个个性化的聊天机器人，它可以记住有关用户的事实。</p>
<p>它将节省内存 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories">“in the hot path”</a>，当用户与之聊天时。</p>
<blockquote>
<p><strong>“in the hot path”</strong> 指的是：<strong>在对话或任务执行的</strong>主流程中<strong>（即用户输入后立即、同步地）</strong>主动调用工具或写入记忆，使信息<strong>实时生效</strong>并可用于下一步决策。</p>
</blockquote>
<h5 id="Introduction-to-the-LangGraph-Store-LangGraph-存储简介"><a href="#Introduction-to-the-LangGraph-Store-LangGraph-存储简介" class="headerlink" title="Introduction to the LangGraph Store LangGraph 存储简介"></a><strong>Introduction to the LangGraph Store</strong> <strong>LangGraph 存储简介</strong></h5><p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Memory Store</a> 提供了一种在 LangGraph 中 <strong>跨线程</strong> 存储和检索信息的方式。这是一个用于持久化 <code>key-value</code> 存储的 <a target="_blank" rel="noopener" href="https://blog.langchain.dev/launching-long-term-memory-support-in-langgraph/">开源基类</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line">in_memory_store = InMemoryStore()</span><br></pre></td></tr></table></figure>
<p>在 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">Store</a> 中存储对象（例如，记忆）时，我们提供：</p>
<p>- 对象的 <code>namespace</code>（类似于目录的元组）</p>
<p>- 对象的 <code>key</code>（类似于文件名）</p>
<p>- 对象的 <code>value</code>（类似于文件内容）</p>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a> 方法通过 <code>namespace</code> 和 <code>key</code> 将对象保存到存储中。</p>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725155616205-1753430177489-3.png" alt="image-20250725155616205"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;  # 用户ID</span><br><span class="line">namespace_for_memory = (user_id, &quot;memories&quot;)  # 记忆命名空间</span><br><span class="line"></span><br><span class="line"># 生成一个唯一的键值</span><br><span class="line">key = str(uuid.uuid4())  # 使用UUID创建唯一标识符作为键</span><br><span class="line"></span><br><span class="line"># 值需要是一个字典格式</span><br><span class="line">value = &#123;&quot;food_preference&quot;: &quot;我喜欢披萨&quot;&#125;  # 存储的食物偏好信息</span><br><span class="line"></span><br><span class="line"># 保存记忆</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)  # 将记忆存储到内存中</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a> 通过 <code>namespace</code> 从存储中检索对象。这将返回一个列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">memories = in_memory_store.search(namespace_for_memory)</span><br><span class="line">type(memories)</span><br><span class="line"></span><br><span class="line"># Metatdata </span><br><span class="line">memories[0].dict()</span><br><span class="line"></span><br><span class="line"># The key, value</span><br><span class="line">print(memories[0].key, memories[0].value)</span><br><span class="line">9e65de8a-f404-4974-b509-0df0566d8fb5 &#123;&#x27;food_preference&#x27;: &#x27;我喜欢披萨&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a> 通过 <code>namespace</code> 和 <code>key</code> 检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Get the memory by namespace and key</span><br><span class="line">memory = in_memory_store.get(namespace_for_memory, key)</span><br><span class="line">memory.dict()</span><br></pre></td></tr></table></figure>
<h5 id="Chatbot-with-long-term-memory-具有长期记忆的聊天机器人"><a href="#Chatbot-with-long-term-memory-具有长期记忆的聊天机器人" class="headerlink" title="Chatbot with long-term memory 具有长期记忆的聊天机器人"></a><strong>Chatbot with long-term memory</strong> <strong>具有长期记忆的聊天机器人</strong></h5><p>我们想要一个聊天机器人，<a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_156">有两种记忆的方式</a>:</p>
<ol>
<li><code>Short-term (within-thread) memory</code>: 聊天机器人可以保留会话历史记录和/或允许在聊天会话中进行中断。  </li>
<li><code>Long-term (cross-thread) memory</code>: 聊天机器人可以记住特定用户在所有聊天会话中的信息 <strong>跨会话</strong>。</li>
</ol>
<p>对于 <code>short-term memory</code>，我们将使用一个 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries">checkpointer</a>。</p>
<ul>
<li>他们在每一步都将图状态写入线程中。</li>
<li>他们在该线程中持久化保存聊天历史记录。</li>
<li>他们允许图在该线程中的任何步骤被中断和/或恢复。</li>
</ul>
<p>对于 <code>long-term memory</code>，我们将使用上面介绍的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的有用助手，能够提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;&quot;你正在收集用户信息以个性化你的回复。</span><br><span class="line"></span><br><span class="line">当前用户信息：</span><br><span class="line">&#123;memory&#125;</span><br><span class="line"></span><br><span class="line">指令：</span><br><span class="line">1. 仔细查看下面的聊天历史</span><br><span class="line">2. 识别有关用户的新信息，例如：</span><br><span class="line">   - 个人详情（姓名、位置）</span><br><span class="line">   - 偏好（喜欢、不喜欢）</span><br><span class="line">   - 兴趣和爱好</span><br><span class="line">   - 过去的经历</span><br><span class="line">   - 目标或未来计划</span><br><span class="line">3. 将任何新信息与现有记忆合并</span><br><span class="line">4. 将记忆格式化为清晰的项目符号列表</span><br><span class="line">5. 如果新信息与现有记忆冲突，请保留最新版本</span><br><span class="line"></span><br><span class="line">记住：只包括用户直接陈述的事实信息。不要做假设或推断。</span><br><span class="line"></span><br><span class="line">基于以下聊天历史，请更新用户信息：&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    existing_memory = store.get(namespace, key)</span><br><span class="line"></span><br><span class="line">    # 如果存在则提取实际的记忆内容并添加前缀</span><br><span class="line">    if existing_memory:</span><br><span class="line">        # 值是一个带有memory键的字典</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)</span><br><span class="line">    </span><br><span class="line">    # 使用记忆以及聊天历史进行回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">        </span><br><span class="line">    # 提取记忆</span><br><span class="line">    if existing_memory:</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)</span><br><span class="line">    new_memory = model.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖存储中的现有记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line"></span><br><span class="line">    # 将值写入为带有memory键的字典</span><br><span class="line">    store.put(namespace, key, &#123;&quot;memory&quot;: new_memory.content&#125;)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于跨线程的长期记忆存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于线程内的短期记忆检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点器和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725161106319.png" alt="image-20250725161106319"></p>
<p>聊天历史将通过检查点工具保存到短期记忆中。聊天机器人将回顾聊天历史。然后，它将创建并保存一个记忆到 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a>。此内存可在未来的聊天会话中访问，以个性化聊天机器人的响应。</p>
<p>当我们与聊天机器人交互时，我们提供两样东西：</p>
<ol>
<li><code>Short-term (within-thread) memory</code>: 一个用于持久化聊天历史的 <code>thread ID</code>。  </li>
<li><code>Long-term (cross-thread) memory</code>: 一个用于将长期记忆命名空间到用户的 <code>user ID</code>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br><span class="line">    </span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，我的名字是Lance</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，Lance！很高兴认识你。有什么我可以帮你的吗？😊</span><br></pre></td></tr></table></figure>
<p>我们正在使用 <code>MemorySaver</code> 检查点来管理线程内内存。这会将聊天历史保存到线程中。我们可以查看保存到线程的聊天历史记录。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">state = graph.get_state(thread).values</span><br><span class="line">for m in state[&quot;messages&quot;]: </span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>回想一下，我们使用存储库编译了该图：<code>across_thread_memory = InMemoryStore()</code>并且，我们向图中添加了一个节点 (<code>write_memory</code>)，该节点反映了聊天历史并保存了一段记忆到存储中。</p>
<p>我们可以查看内存是否已保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.dict()</span><br><span class="line"></span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;memory&#x27;, &#x27;1&#x27;],</span><br><span class="line"> &#x27;key&#x27;: &#x27;user_memory&#x27;,</span><br><span class="line"> &#x27;value&#x27;: &#123;&#x27;memory&#x27;: &#x27;- 姓名：Lance  \n- 位置：旧金山  \n- 兴趣和爱好：骑自行车  \n- 喜欢的活动：在旧金山骑行，可能包括金门大桥和滨海区路线&#x27;&#125;,</span><br><span class="line"> &#x27;created_at&#x27;: &#x27;2025-07-25T08:12:35.877160+00:00&#x27;,</span><br><span class="line"> &#x27;updated_at&#x27;: &#x27;2025-07-25T08:12:35.877161+00:00&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>现在，让我们以 <strong>相同的用户ID</strong>启动一个<strong>新线程</strong>。我们应该看到聊天机器人记住了用户的个人资料，并将其用于个性化响应。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供用户ID用于跨线程记忆以及一个新的线程ID</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好！你推荐我去哪里骑自行车？&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-Profile-Schema-带有配置文件模式的聊天机器人"><a href="#Chatbot-with-Profile-Schema-带有配置文件模式的聊天机器人" class="headerlink" title="Chatbot with Profile Schema 带有配置文件模式的聊天机器人"></a><strong>Chatbot with Profile Schema</strong> <strong>带有配置文件模式的聊天机器人</strong></h4><p>我们的聊天机器人将记忆保存为字符串。在实践中，我们通常希望记忆具有结构化格式。例如，记忆可以是<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">单个、持续更新的模式 </a>。在我们的案例中，我们希望这是一个单一的用户档案。</p>
<p>我们将扩展我们的聊天机器人，将语义记忆保存到单个<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">用户档案 </a>中。我们还将介绍一个库 <a target="_blank" rel="noopener" href="https://github.com/hinthornw/trustcall">Trustcall</a>，用于使用新信息更新此模式。</p>
<h5 id="Defining-a-user-profile-schema-定义用户配置文件模式"><a href="#Defining-a-user-profile-schema-定义用户配置文件模式" class="headerlink" title="Defining a user profile schema 定义用户配置文件模式"></a><strong>Defining a user profile schema</strong> <strong>定义用户配置文件模式</strong></h5><p>Python 有许多不同类型的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition">structured data</a>，例如 TypedDict、字典、JSON 和 <a target="_blank" rel="noopener" href="https://docs.pydantic.dev/latest/">Pydantic</a>。</p>
<p>让我们先使用 TypedDict 来定义一个用户资料模式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from typing import TypedDict, List</span><br><span class="line"></span><br><span class="line">class UserProfile(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;带有类型字段的用户档案模式&quot;&quot;&quot;</span><br><span class="line">    user_name: str  # 用户的首选名称</span><br><span class="line">    interests: List[str]  # 用户兴趣列表</span><br></pre></td></tr></table></figure>
<h5 id="Saving-a-schema-to-the-store-将模式保存到存储中"><a href="#Saving-a-schema-to-the-store-将模式保存到存储中" class="headerlink" title="Saving a schema to the store 将模式保存到存储中"></a><strong>Saving a schema to the store</strong> <strong>将模式保存到存储中</strong></h5><p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a> 接受任何 Python 字典作为 <code>value</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># TypedDict 实例</span><br><span class="line">user_profile: UserProfile = &#123;</span><br><span class="line">    &quot;user_name&quot;: &quot;Lance&quot;,  # 用户名</span><br><span class="line">    &quot;interests&quot;: [&quot;骑行&quot;, &quot;科技&quot;, &quot;咖啡&quot;]  # 兴趣爱好</span><br><span class="line">&#125;</span><br><span class="line">user_profile</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a> 方法将 TypedDict 保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line"></span><br><span class="line"># 初始化内存存储</span><br><span class="line">in_memory_store = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 为要保存的记忆创建命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace_for_memory = (user_id, &quot;memory&quot;)</span><br><span class="line"></span><br><span class="line"># 将记忆以键值对的形式保存到命名空间中</span><br><span class="line">key = &quot;user_profile&quot;</span><br><span class="line">value = user_profile</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a> 按命名空间从存储中检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for m in in_memory_store.search(namespace_for_memory):</span><br><span class="line">    print(m.dict())</span><br><span class="line">    </span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;1&#x27;, &#x27;memory&#x27;], &#x27;key&#x27;: &#x27;user_profile&#x27;, &#x27;value&#x27;: &#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;, &#x27;created_at&#x27;: &#x27;2025-07-25T08:58:06.031770+00:00&#x27;, &#x27;updated_at&#x27;: &#x27;2025-07-25T08:58:06.031775+00:00&#x27;, &#x27;score&#x27;: None&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a> 通过命名空间和键来检索特定对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">profile = in_memory_store.get(namespace_for_memory, &quot;user_profile&quot;)</span><br><span class="line">profile.value</span><br><span class="line"></span><br><span class="line">&#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Chatbot-with-profile-schema-带有配置文件模式的聊天机器人"><a href="#Chatbot-with-profile-schema-带有配置文件模式的聊天机器人" class="headerlink" title="Chatbot with profile schema 带有配置文件模式的聊天机器人"></a><strong>Chatbot with profile schema</strong> <strong>带有配置文件模式的聊天机器人</strong></h5><p>现在我们知道了如何为记忆指定一个模式，并将其保存到存储中。现在，我们如何根据这个特定的模式 <strong>创建</strong> 记忆？</p>
<p>在我们的聊天机器人中，我们 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">想要从一个聊天里创建记忆</a>.这就是 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">structured outputs格式化输出</a> 概念有用的地方。</p>
<p>LangChain 的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/chat_models/">chat model</a> 接口有一个 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">PROTECTED$11$</a> 方法用于强制结构化输出。这在我们需要确保输出符合某个模式时非常有用，而且它会为我们解析输出。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 将模式绑定到模型</span><br><span class="line">model_with_structure = model.with_structured_output(UserProfile)</span><br><span class="line"></span><br><span class="line"># 调用模型生成符合模式的结构化输出</span><br><span class="line">structured_output = model_with_structure.invoke([HumanMessage(&quot;我的名字是Lance，我喜欢骑自行车。&quot;)])</span><br><span class="line">structured_output</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Structured outputs（结构化输出）<br>指让大模型<strong>不再“随意说人话”</strong>，而是<strong>按你事先定义好的格式（JSON / 表格 / 枚举 / 嵌套对象等）精确返回数据</strong>。相当于给模型套了一个“模具”，保证输出可直接被代码解析、入库或传给下游系统，避免再用正则、字符串拼接去“猜”结果。</p>
<p>使用官方的大模型组件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">model=ChatTongyi(</span><br><span class="line">    model=&quot;qwen-plus-2025-07-14&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>现在，让我们在聊天机器人中使用它。这只需要对 <code>write_memory</code> 函数进行轻微修改。我们使用 <code>model_with_structure</code>，如上所述，来生成一个与我们模式匹配的配置文件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage, AIMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的 helpful 助手，可以提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;根据用户的聊天历史创建或更新用户档案记忆。</span><br><span class="line">这将被保存为长期记忆。如果存在现有记忆，只需更新它。</span><br><span class="line">以下是现有记忆（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 使用记忆以及聊天历史来回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line">        </span><br><span class="line">    # 在指令中格式化现有记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 调用模型生成符合模式的结构化输出</span><br><span class="line">    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖现有的用户档案记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    store.put(namespace, key, new_memory)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于长期（跨线程）记忆的存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于短期（线程内）记忆的检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250726103516996.png" alt="image-20250726103516996"></p>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance，我喜欢在旧金山骑自行车和在面包店吃饭。&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>查看记忆</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Namespace for the memory to save</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.value</span><br></pre></td></tr></table></figure>
<h5 id="Trustcall-for-creating-and-updating-profile-schemas-Trustcall-用于创建和更新配置文件模式"><a href="#Trustcall-for-creating-and-updating-profile-schemas-Trustcall-用于创建和更新配置文件模式" class="headerlink" title="Trustcall for creating and updating profile schemas Trustcall 用于创建和更新配置文件模式"></a><strong>Trustcall for creating and updating profile schemas</strong> <strong>Trustcall 用于创建和更新配置文件模式</strong></h5><p>Trustcall 是一个由 LangChain 团队开发的开源 Python 库，旨在<strong>解决大型语言模型（LLM）在生成或修改复杂 JSON 数据结构时效率低、易出错的问题</strong>。</p>
<p>我们使用 <code>create_extractor</code>，传入模型以及我们的模式作为 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/tools/">tool</a>。使用 TrustCall 时，可以以多种方式提供模式。</p>
<p>例如，我们可以传递一个 JSON 对象 / Python 字典或 Pydantic 模型。在底层，TrustCall 使用 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/tool_calling/">tool calling</a> 从输入的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/messages/">messages</a> 列表中生成 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/">structured output</a>。为了强制 Trustcall 生成 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/">structured output</a>，我们可以在 <code>tool_choice</code> 参数中包含模式名称。</p>
<p>我仅做了解了，感觉用处不多，用结果化输出就能达到效果</p>
<h4 id="Chatbot-with-Collection-Schema-带集合模式的聊天机器人"><a href="#Chatbot-with-Collection-Schema-带集合模式的聊天机器人" class="headerlink" title="Chatbot with Collection Schema 带集合模式的聊天机器人"></a><strong>Chatbot with Collection Schema</strong> <strong>带集合模式的聊天机器人</strong></h4><p><strong>“collection”</strong> 指的是一种<strong>将语义记忆组织为多个独立文档（objects）的存储方式</strong>，而不是把所有信息都塞进一个巨大的“用户档案”（single profile）里。</p>
<p>假设你在做一个 AI 助手，用户说：</p>
<blockquote>
<p>“我下周要去东京出差，住在涩谷区的 Sakura Hotel。”<br>“我朋友 Ken 也要来，他喜欢吃拉面。”</p>
</blockquote>
<p>如果用 <strong>collection</strong>，你会存成两条记忆：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trip&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;destination&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Tokyo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2025-08-04&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hotel&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Sakura Hotel, Shibuya&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;friend&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Ken&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;food_preference&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ramen&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<p>每条记忆都是一个独立文档，后续你可以：</p>
<ul>
<li>搜索“trip”类型的记忆，找到用户的出差安排；</li>
<li>搜索“friend”类型的记忆，找到 Ken 的偏好；</li>
<li>更新 Ken 的信息时，<strong>只改一条记录</strong>，不会影响其它记忆。</li>
</ul>
<h4 id="Memory-Agent-内存代理"><a href="#Memory-Agent-内存代理" class="headerlink" title="Memory Agent 内存代理"></a><strong>Memory Agent</strong> <strong>内存代理</strong></h4><p>现在，我们将把学到的内容整合起来，构建一个具有长期记忆的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/">agent</a>。</p>
<p>我们的代理 <code>task_mAIstro</code> 将帮助我们管理待办事项列表！</p>
<p>我们之前构建的聊天机器人 <strong>始终</strong> 会反思对话并保存记忆。<code>task_mAIstro</code> 将决定 <strong>何时</strong> 保存记忆（待办事项列表中的项目）。</p>
<p>我们之前构建的聊天机器人始终保存一种类型的记忆，即个人资料或集合。<code>task_mAIstro</code> 可以决定将数据保存到用户个人资料或 ToDo 事项集合中。</p>
<p>除此之外，<code>task_mAIstro</code> 还将管理程序性记忆。这允许用户更新创建ToDo项的偏好设置。</p>
<h5 id="Creating-an-agent-创建一个代理"><a href="#Creating-an-agent-创建一个代理" class="headerlink" title="Creating an agent 创建一个代理"></a><strong>Creating an agent</strong> <strong>创建一个代理</strong></h5><p>有许多不同的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/high_level/">agent</a> 架构可供选择。在这里，我们将实现一个简单的内容，一个 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation">ReAct</a> 代理。这个代理将成为创建和管理待办事项列表的得力助手。</p>
<p>此代理可以决定更新三种类型的长期记忆：</p>
<p>(a) 创建或更新具有普通用户信息的用户 <code>profile</code></p>
<p>(b) 在ToDo列表中添加或更新项目 <code>collection</code></p>
<p>(c) 更新其自身的 <code>instructions</code> 以了解如何更新待办事项列表中的项目</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from typing import TypedDict, Literal</span><br><span class="line"></span><br><span class="line"># 更新记忆工具</span><br><span class="line">class UpdateMemory(TypedDict):</span><br><span class="line">    &quot;&quot;&quot; 决定更新哪种记忆类型 &quot;&quot;&quot;</span><br><span class="line">    update_type: Literal[&#x27;user&#x27;, &#x27;todo&#x27;, &#x27;instructions&#x27;]</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><code>&#39;user&#39;</code>：用户相关信息</li>
<li><code>&#39;todo&#39;</code>：待办事项</li>
<li><code>&#39;instructions&#39;</code>：指令信息</li>
</ul>
</blockquote>
<h5 id="Graph-definition-图定义"><a href="#Graph-definition-图定义" class="headerlink" title="Graph definition 图定义"></a><strong>Graph definition</strong> <strong>图定义</strong></h5><p>我们添加了一个简单的路由器 <code>route_message</code>，它通过二元决策来节省内存。</p>
<h3 id="module-6"><a href="#module-6" class="headerlink" title="module-6"></a>module-6</h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/" class="post-title-link" itemprop="url">Research Assistant研究助理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-22T00:00:00+08:00">2025-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-08 21:50:20" itemprop="dateModified" datetime="2025-08-08T21:50:20+08:00">2025-08-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="Research-Assistant-研究助理"><a href="#Research-Assistant-研究助理" class="headerlink" title="Research Assistant 研究助理"></a><strong>Research Assistant</strong> <strong>研究助理</strong></h4><p>我们的目标是围绕聊天模型构建一个轻量级、多智能体系统，以定制研究过程。</p>
<p>Source Selection</p>
<ul>
<li>用户可为研究自行选择任意输入源。</li>
</ul>
<p>Planning</p>
<ul>
<li>用户提供主题后，系统生成一组 AI 分析师，每位分析师聚焦一个子主题。</li>
<li>在研究开始前，采用 <strong>人机协同</strong> 方式对子主题进行精调。</li>
</ul>
<p>LLM Utilization</p>
<ul>
<li>每位分析师基于所选源，与专家 AI 开展深度访谈。</li>
<li>访谈采用多轮对话形式，以 STORM 论文所示方式提取详尽洞见。</li>
<li>访谈过程将以“<strong>子图</strong>”形式记录，并保存各自内部状态。</li>
</ul>
<p>Research Process</p>
<ul>
<li>专家 AI 并行收集信息，实时回答分析师提问。</li>
<li>所有访谈通过 <strong>map-reduce</strong> 架构同时展开。</li>
</ul>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/66dbb164d61c93d48e604091_research-assistant1.png" alt="Screenshot 2024-08-26 at 7.26.33 PM.png"></p>
<h5 id="Generate-Analysts-Human-In-The-Loop-生成分析师"><a href="#Generate-Analysts-Human-In-The-Loop-生成分析师" class="headerlink" title="Generate Analysts: Human-In-The-Loop 生成分析师"></a><strong>Generate Analysts: Human-In-The-Loop</strong> <strong>生成分析师</strong></h5><p>创建分析师并使用人工循环（human-in-the-loop）来审查他们。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line">class Analyst(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    分析师模型类</span><br><span class="line">    用于定义单个分析师的基本信息和属性</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    affiliation: str = Field(</span><br><span class="line">        description=&quot;分析师的主要隶属机构。&quot;,</span><br><span class="line">    )</span><br><span class="line">    name: str = Field(</span><br><span class="line">        description=&quot;分析师的姓名&quot;</span><br><span class="line">    )</span><br><span class="line">    role: str = Field(</span><br><span class="line">        description=&quot;分析师在该主题背景下的角色。&quot;,</span><br><span class="line">    )</span><br><span class="line">    description: str = Field(</span><br><span class="line">        description=&quot;分析师的关注点、担忧和动机的描述。&quot;,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    @property#@property 装饰器的作用是将一个方法转换为只读属性 ，让方法可以像访问属性一样使用，而不需要加括号调用。</span><br><span class="line">    def persona(self) -&gt; str:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        生成分析师的人设信息</span><br><span class="line">        返回格式化的字符串包含分析师的所有关键信息</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        return f&quot;姓名: &#123;self.name&#125;\n角色: &#123;self.role&#125;\n隶属机构: &#123;self.affiliation&#125;\n描述: &#123;self.description&#125;\n&quot;</span><br><span class="line"></span><br><span class="line">class Perspectives(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    视角模型类</span><br><span class="line">    用于管理多个分析师的集合</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    analysts: List[Analyst] = Field(</span><br><span class="line">        description=&quot;包含角色和隶属机构的分析师综合列表。&quot;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">class GenerateAnalystsState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    生成分析师状态类型定义</span><br><span class="line">    用于类型提示，定义在生成分析师过程中需要的状态信息</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    topic: str # 研究主题 - 用户输入的研究话题</span><br><span class="line">    max_analysts: int # 分析师数量 - 需要生成的分析师最大数量</span><br><span class="line">    human_analyst_feedback: str # 人类反馈 - 来自用户的反馈信息，用于调整分析师生成</span><br><span class="line">    analysts: List[Analyst] # 提出问题的分析师 - 已生成的分析师列表</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>Field</code> 是 Pydantic 提供的一个函数，主要用于为模型字段添加额外的元数据和配置。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import START, END, StateGraph</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langchain_core.messages import AIMessage, HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line"># 分析师指令模板</span><br><span class="line">analyst_instructions=&quot;&quot;&quot;您需要创建一组AI分析师角色。请仔细遵循以下指令：</span><br><span class="line"></span><br><span class="line">1. 首先，查看研究主题：</span><br><span class="line">&#123;topic&#125;</span><br><span class="line">        </span><br><span class="line">2. 检查任何可选的编辑反馈，这些反馈用于指导分析师的创建： </span><br><span class="line">        </span><br><span class="line">&#123;human_analyst_feedback&#125;</span><br><span class="line">    </span><br><span class="line">3. 根据上述文档和/或反馈确定最有趣的主题。</span><br><span class="line">                    </span><br><span class="line">4. 选择前 &#123;max_analysts&#125; 个主题。</span><br><span class="line"></span><br><span class="line">5. 为每个主题分配一个分析师。</span><br><span class="line"></span><br><span class="line">6. 重要：请以JSON格式返回您的响应，结构如下：</span><br><span class="line">   &#123;&#123;</span><br><span class="line">     &quot;analysts&quot;: [</span><br><span class="line">       &#123;&#123;</span><br><span class="line">         &quot;name&quot;: &quot;分析师姓名&quot;,</span><br><span class="line">         &quot;affiliation&quot;: &quot;所属机构&quot;,</span><br><span class="line">         &quot;role&quot;: &quot;角色描述&quot;,</span><br><span class="line">         &quot;description&quot;: &quot;详细描述&quot;</span><br><span class="line">       &#125;&#125;</span><br><span class="line">     ]</span><br><span class="line">   &#125;&#125;</span><br><span class="line"></span><br><span class="line">7. 请确保响应中包含&#x27;json&#x27;这个词，这是必需的。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def create_analysts(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 创建分析师 &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    topic=state[&#x27;topic&#x27;]</span><br><span class="line">    max_analysts=state[&#x27;max_analysts&#x27;]</span><br><span class="line">    human_analyst_feedback=state.get(&#x27;human_analyst_feedback&#x27;, &#x27;&#x27;)#防止为空</span><br><span class="line">        </span><br><span class="line">    # 强制结构化输出</span><br><span class="line">    structured_llm = llm.with_structured_output(Perspectives)</span><br><span class="line"></span><br><span class="line">    # 系统消息</span><br><span class="line">    system_message = analyst_instructions.format(topic=topic,human_analyst_feedback=human_analyst_feedback, max_analysts=max_analysts)</span><br><span class="line"></span><br><span class="line">    # 生成分析师</span><br><span class="line">    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=&quot;生成分析师集合。&quot;)])</span><br><span class="line">    </span><br><span class="line">    # 将分析师列表写入状态</span><br><span class="line">    return &#123;&quot;analysts&quot;: analysts.analysts&#125;</span><br><span class="line"></span><br><span class="line">def human_feedback(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 无操作节点，应该在此处中断 &quot;&quot;&quot;</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">def should_continue(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 返回下一个要执行的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否有用户反馈</span><br><span class="line">    human_analyst_feedback=state.get(&#x27;human_analyst_feedback&#x27;, None)</span><br><span class="line">    if human_analyst_feedback:</span><br><span class="line">        return &quot;create_analysts&quot;</span><br><span class="line">    </span><br><span class="line">    # 否则结束</span><br><span class="line">    return END</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">builder = StateGraph(GenerateAnalystsState)</span><br><span class="line">builder.add_node(&quot;create_analysts&quot;, create_analysts)  # 添加创建分析师节点</span><br><span class="line">builder.add_node(&quot;human_feedback&quot;, human_feedback)   # 添加用户反馈节点</span><br><span class="line">builder.add_edge(START, &quot;create_analysts&quot;)           # 从开始到创建分析师</span><br><span class="line">builder.add_edge(&quot;create_analysts&quot;, &quot;human_feedback&quot;) # 从创建分析师到用户反馈</span><br><span class="line">builder.add_conditional_edges(&quot;human_feedback&quot;, should_continue, [&quot;create_analysts&quot;, END]) # 条件边</span><br><span class="line"></span><br><span class="line"># 编译图</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph = builder.compile(interrupt_before=[&#x27;human_feedback&#x27;], checkpointer=memory)  # 在用户反馈前中断</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))  # 显示流程图</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250723171742889.png" alt="image-20250723171742889"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 输入</span><br><span class="line">max_analysts = 3  # 最大分析师数量</span><br><span class="line">topic = &quot;采用LangGraph作为代理框架的好处&quot;  # 研究主题</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;  # 线程配置，用于会话跟踪</span><br><span class="line"></span><br><span class="line"># 运行图直到第一次中断</span><br><span class="line">for event in graph.stream(&#123;&quot;topic&quot;:topic,&quot;max_analysts&quot;:max_analysts,&#125;, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    # 审查结果</span><br><span class="line">    analysts = event.get(&#x27;analysts&#x27;, &#x27;&#x27;)  # 获取分析师列表</span><br><span class="line">    if analysts:</span><br><span class="line">        for analyst in analysts:</span><br><span class="line">            print(f&quot;姓名: &#123;analyst.name&#125;&quot;)        # 打印分析师姓名</span><br><span class="line">            print(f&quot;隶属机构: &#123;analyst.affiliation&#125;&quot;)  # 打印隶属机构</span><br><span class="line">            print(f&quot;角色: &#123;analyst.role&#125;&quot;)        # 打印角色</span><br><span class="line">            print(f&quot;描述: &#123;analyst.description&#125;&quot;)  # 打印描述</span><br><span class="line">            print(&quot;-&quot; * 50)  # 打印分隔线</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">姓名: 艾琳·史密斯</span><br><span class="line">隶属机构: 人工智能与代理系统研究所</span><br><span class="line">角色: LangGraph架构专家</span><br><span class="line">描述: 专注于研究基于图结构的AI代理框架，尤其是LangGraph在复杂决策流程中的模块化与可扩展性优势。</span><br><span class="line">--------------------------------------------------</span><br><span class="line">姓名: 拉胡尔·梅赫塔</span><br><span class="line">隶属机构: 分布式系统与AI实验室</span><br><span class="line">角色: 代理框架性能分析师</span><br><span class="line">描述: 研究LangGraph在多代理协作中的效率提升，以及其在异步通信、状态管理和错误恢复方面的优势。</span><br><span class="line">--------------------------------------------------</span><br><span class="line">姓名: 艾米丽·陈</span><br><span class="line">隶属机构: 人机交互与智能系统中心</span><br><span class="line">角色: 代理框架用户体验研究员</span><br><span class="line">描述: 分析LangGraph如何支持开发者构建更具交互性和可解释性的AI代理系统，特别是在可视化流程设计和调试方面的优势。</span><br><span class="line">--------------------------------------------------</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 我们现在像 human_feedback 节点一样更新状态</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            &quot;添加一个来自初创公司的人，以增加企业家视角&quot;&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 继续图的执行</span><br><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    # 审查结果</span><br><span class="line">    analysts = event.get(&#x27;analysts&#x27;, &#x27;&#x27;)  # 获取分析师列表</span><br><span class="line">    if analysts:</span><br><span class="line">        for analyst in analysts:</span><br><span class="line">            print(f&quot;姓名: &#123;analyst.name&#125;&quot;)        # 打印分析师姓名</span><br><span class="line">            print(f&quot;隶属机构: &#123;analyst.affiliation&#125;&quot;)  # 打印隶属机构</span><br><span class="line">            print(f&quot;角色: &#123;analyst.role&#125;&quot;)        # 打印角色</span><br><span class="line">            print(f&quot;描述: &#123;analyst.description&#125;&quot;)  # 打印描述</span><br><span class="line">            print(&quot;-&quot; * 50)  # 打印分隔线</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 如果我们满意，那么就不提供任何反馈</span><br><span class="line">further_feedback = None #如果满意就返回none，如果不满意就进行反馈</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            further_feedback&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<h5 id="Conduct-Interview-进行面试"><a href="#Conduct-Interview-进行面试" class="headerlink" title="Conduct Interview 进行面试"></a><strong>Conduct Interview</strong> <strong>进行面试</strong></h5><p><strong>生成问题</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import  Annotated</span><br><span class="line">from langgraph.graph import MessagesState</span><br><span class="line"></span><br><span class="line">class InterviewState(MessagesState):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    访谈状态类</span><br><span class="line">    继承自MessagesState，用于管理访谈过程中的各种状态信息</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    max_num_turns: int # 对话轮数上限</span><br><span class="line">    context: Annotated[list, operator.add] # 源文档，使用operator.add进行合并</span><br><span class="line">    analyst: Analyst # 提问的分析师</span><br><span class="line">    interview: str # 访谈记录（文字记录）</span><br><span class="line">    sections: list # 最终章节，我们在外部状态中重复此字段以用于Send() API</span><br><span class="line"></span><br><span class="line">class SearchQuery(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    搜索查询模型</span><br><span class="line">    用于定义搜索查询的结构</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    search_query: str = Field(None, description=&quot;用于检索的搜索查询。&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 问题生成指令</span><br><span class="line">question_instructions = &quot;&quot;&quot;你是一名分析师，任务是采访专家以了解特定主题。</span><br><span class="line"></span><br><span class="line">你的目标是提炼出与你主题相关的有趣且具体的见解。</span><br><span class="line"></span><br><span class="line">1. 有趣的：人们会感到惊讶或不明显的见解。</span><br><span class="line">        </span><br><span class="line">2. 具体的：避免泛泛而谈的见解，包含来自专家的具体例子。</span><br><span class="line"></span><br><span class="line">这是你的关注主题和目标集合：&#123;goals&#125;</span><br><span class="line">        </span><br><span class="line">首先使用符合你人设的名字介绍自己，然后提出你的问题。</span><br><span class="line"></span><br><span class="line">继续提问以深入挖掘和细化你对该主题的理解。</span><br><span class="line">        </span><br><span class="line">当你对理解满意时，用&quot;非常感谢您的帮助！&quot;来结束采访。</span><br><span class="line"></span><br><span class="line">记住在整个回复中保持角色特征，体现提供给你的人设和目标。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def generate_question(state: InterviewState):</span><br><span class="line">    &quot;&quot;&quot; 生成问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    analyst = state[&quot;analyst&quot;]      # 当前分析师</span><br><span class="line">    messages = state[&quot;messages&quot;]    # 对话历史</span><br><span class="line"></span><br><span class="line">    # 生成问题</span><br><span class="line">    system_message = question_instructions.format(goals=analyst.persona)  # 格式化系统消息</span><br><span class="line">    question = llm.invoke([SystemMessage(content=system_message)]+messages)  # 调用LLM生成问题</span><br><span class="line">        </span><br><span class="line">    # 将消息写入状态</span><br><span class="line">    return &#123;&quot;messages&quot;: [question]&#125;  # 返回新生成的问题</span><br></pre></td></tr></table></figure>
<p><strong>生成问题的并行处理</strong></p>
<p>专家将并行从多个来源收集信息以回答问题。</p>
<ul>
<li>特定网站：例如通过 <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/document_loaders/web_base/">WebBaseLoader</a>  </li>
<li>已索引文档：例如通过 <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/tutorials/rag/">RAG</a>  </li>
<li>网页搜索  </li>
<li>维基百科搜索</li>
</ul>
<p>你可以尝试不同的网络搜索工具，比如 <a target="_blank" rel="noopener" href="https://tavily.com/">Tavily</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Web search tool</span><br><span class="line">from langchain_community.tools.tavily_search import TavilySearchResults</span><br><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line">#tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">tavily_search=TavilySearch(max_result=3)</span><br><span class="line"></span><br><span class="line"># Wikipedia search tool</span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br></pre></td></tr></table></figure>
<p>现在，我们创建节点以搜索网络和维基百科。</p>
<p>我们还将创建一个节点来回答分析师的问题。最后，我们将创建节点以保存完整的采访内容，并撰写采访的摘要（“部分”）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import get_buffer_string</span><br><span class="line"></span><br><span class="line"># 搜索查询编写</span><br><span class="line">search_instructions = SystemMessage(content=f&quot;&quot;&quot;你将获得分析师和专家之间的对话。</span><br><span class="line"></span><br><span class="line">你的目标是生成一个结构化的 JSON 对象，该对象包含一个用于网络搜索的查询字符串。</span><br><span class="line"></span><br><span class="line">请严格按照以下步骤操作：</span><br><span class="line"></span><br><span class="line">1.  仔细分析整个对话。</span><br><span class="line">2.  特别关注分析师提出的最后一个问题。</span><br><span class="line">3.  根据该问题，生成一个清晰、简洁、有效的搜索查询字符串。</span><br><span class="line">4.  **你的最终输出必须是一个严格的 JSON 对象，格式如下，不要包含任何其他文字或解释：**</span><br><span class="line">    &#123;&#123;&quot;search_query&quot;: &quot;你的查询字符串放在这里&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">**示例：**</span><br><span class="line">如果最后一个问题涉及 &quot;LangGraph 与其他代理框架（如 AutoGen）相比的优势&quot;，</span><br><span class="line">你的输出必须严格是：</span><br><span class="line">&#123;&#123;&quot;search_query&quot;: &quot;LangGraph vs AutoGen agent framework advantages&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">分析师的最后一个问题才是关键，请基于它生成查询。</span><br><span class="line"></span><br><span class="line">**你的输出：**&quot;&quot;&quot;)</span><br><span class="line"></span><br><span class="line">def search_web(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索查询</span><br><span class="line">    structured_llm = llm.with_structured_output(SearchQuery)</span><br><span class="line">    search_query = structured_llm.invoke([search_instructions]+state[&#x27;messages&#x27;])</span><br><span class="line">    </span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = tavily_search.invoke(search_query.search_query)</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;/&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # # 搜索查询</span><br><span class="line">    # structured_llm = llm.with_structured_output(SearchQuery)</span><br><span class="line">    # search_query = structured_llm.invoke([search_instructions]+state[&#x27;messages&#x27;])</span><br><span class="line">    </span><br><span class="line">    # # 搜索</span><br><span class="line">    # search_docs = WikipediaLoader(query=search_query.search_query, </span><br><span class="line">    #                               load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">    #  # 格式化</span><br><span class="line">    # formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">    #     [</span><br><span class="line">    #         f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;/&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">    #         for doc in search_docs</span><br><span class="line">    #     ]</span><br><span class="line">    # )</span><br><span class="line"></span><br><span class="line">    # return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line">    return &#123;&quot;context&quot;: [&quot;&quot;]&#125;</span><br><span class="line"></span><br><span class="line">answer_instructions = &quot;&quot;&quot;你是一位正在接受分析师采访的专家。</span><br><span class="line"></span><br><span class="line">这是分析师的关注领域：&#123;goals&#125;。</span><br><span class="line">        </span><br><span class="line">你的目标是回答面试官提出的问题。</span><br><span class="line"></span><br><span class="line">要回答问题，请使用此上下文：</span><br><span class="line">        </span><br><span class="line">&#123;context&#125;</span><br><span class="line"></span><br><span class="line">回答问题时，请遵循以下准则：</span><br><span class="line">        </span><br><span class="line">1. 仅使用上下文中提供的信息。</span><br><span class="line">        </span><br><span class="line">2. 不要引入外部信息或在上下文中明确说明之外进行假设。</span><br><span class="line"></span><br><span class="line">3. 上下文包含每个独立文档主题的来源。</span><br><span class="line"></span><br><span class="line">4. 在任何相关陈述旁边包含这些来源。例如，对于来源 # 1 使用 [1]。</span><br><span class="line"></span><br><span class="line">5. 在答案底部按顺序列出你的来源。 [1] 来源 1，[2] 来源 2，等等</span><br><span class="line">        </span><br><span class="line">6. 如果来源是：&lt;Document source=&quot;assistant/docs/llama3_1.pdf&quot; page=&quot;7&quot;/&gt;&#x27; 那么只需列出：</span><br><span class="line">        </span><br><span class="line">[1] assistant/docs/llama3_1.pdf, page 7 </span><br><span class="line">        </span><br><span class="line">并跳过括号的添加以及引用中的 Document source 前言。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def generate_answer(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    analyst = state[&quot;analyst&quot;]</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line"></span><br><span class="line">    # 回答问题</span><br><span class="line">    system_message = answer_instructions.format(goals=analyst.persona, context=context)</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=system_message)]+messages)</span><br><span class="line">            </span><br><span class="line">    # 将消息命名为来自专家</span><br><span class="line">    answer.name = &quot;expert&quot;</span><br><span class="line">    </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;messages&quot;: [answer]&#125;</span><br><span class="line"></span><br><span class="line">def save_interview(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 保存采访 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取消息</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    </span><br><span class="line">    # 将采访转换为字符串</span><br><span class="line">    interview = get_buffer_string(messages)</span><br><span class="line">    </span><br><span class="line">    # 保存到 interviews 键</span><br><span class="line">    return &#123;&quot;interview&quot;: interview&#125;</span><br><span class="line"></span><br><span class="line">def route_messages(state: InterviewState, </span><br><span class="line">                   name: str = &quot;expert&quot;):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 在问题和答案之间路由 &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 获取消息</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    max_num_turns = state.get(&#x27;max_num_turns&#x27;,2)</span><br><span class="line"></span><br><span class="line">    # 检查专家答案的数量</span><br><span class="line">    #isinstance(m, AIMessage) ：检查当前消息 m 是否是 AIMessage 类的实例。这通常用于识别由 AI 模型生成的消息。</span><br><span class="line">    num_responses = len(</span><br><span class="line">        [m for m in messages if isinstance(m, AIMessage) and m.name == name]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 如果专家回答的次数超过最大轮数，则结束</span><br><span class="line">    if num_responses &gt;= max_num_turns:</span><br><span class="line">        return &#x27;save_interview&#x27;</span><br><span class="line"></span><br><span class="line">    # 获取提出的最后一个问题，以检查它是否表示讨论结束</span><br><span class="line">    #messages[-2] ：分析师提出的 最后一个问题 。</span><br><span class="line">    #messages[-1] ：专家对这个问题的 最新回答 。</span><br><span class="line">    last_question = messages[-2]</span><br><span class="line">    </span><br><span class="line">    if &quot;非常感谢你的帮助&quot; in last_question.content:</span><br><span class="line">        return &#x27;save_interview&#x27;</span><br><span class="line">    return &quot;ask_question&quot;</span><br><span class="line"></span><br><span class="line">section_writer_instructions = &quot;&quot;&quot;你是一位专业的科技作家。</span><br><span class="line">            </span><br><span class="line">你的任务是根据一组源文档创建一份简短、易于理解的报告部分。</span><br><span class="line"></span><br><span class="line">1. 分析源文档的内容：</span><br><span class="line">- 每个源文档的名称都在文档开头，带有 &lt;Document 标签。</span><br><span class="line">        </span><br><span class="line">2. 使用 markdown 格式创建报告结构：</span><br><span class="line">- 使用 ## 作为章节标题</span><br><span class="line">- 使用 ### 作为小节标题</span><br><span class="line">        </span><br><span class="line">3. 按照此结构编写报告：</span><br><span class="line">a. 标题 (## header)</span><br><span class="line">b. 摘要 (### header)</span><br><span class="line">c. 来源 (### header)</span><br><span class="line"></span><br><span class="line">4. 根据分析师的关注领域，使你的标题引人入胜：</span><br><span class="line">&#123;focus&#125;</span><br><span class="line"></span><br><span class="line">5. 对于摘要部分：</span><br><span class="line">- 设置与分析师关注领域相关的通用背景/上下文的摘要</span><br><span class="line">- 强调从采访中收集到的新颖、有趣或令人惊讶的见解</span><br><span class="line">- 创建一个使用过的源文档的编号列表</span><br><span class="line">- 不要提及面试官或专家的姓名</span><br><span class="line">- 目标是最多约 400 字</span><br><span class="line">- 根据源文档中的信息，在报告中使用编号来源（例如，[1]、[2]）</span><br><span class="line">        </span><br><span class="line">6. 在来源部分：</span><br><span class="line">- 包含报告中使用的所有来源</span><br><span class="line">- 提供相关网站或特定文档路径的完整链接</span><br><span class="line">- 每个来源用换行符分隔。在每行末尾使用两个空格以在 Markdown 中创建换行符。</span><br><span class="line">- 它看起来像：</span><br><span class="line"></span><br><span class="line">### 来源</span><br><span class="line">[1] 链接或文档名称</span><br><span class="line">[2] 链接或文档名称</span><br><span class="line"></span><br><span class="line">7. 务必合并来源。例如，这不正确：</span><br><span class="line"></span><br><span class="line">[3] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line">[4] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line"></span><br><span class="line">不应有冗余来源。它应该只是：</span><br><span class="line"></span><br><span class="line">[3] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line">        </span><br><span class="line">8. 最终审查：</span><br><span class="line">- 确保报告遵循所需的结构</span><br><span class="line">- 在报告标题之前不包含任何前言</span><br><span class="line">- 检查所有准则是否已遵循&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_section(state: InterviewState):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 编写章节的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    interview = state[&quot;interview&quot;]</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    analyst = state[&quot;analyst&quot;]</span><br><span class="line">   </span><br><span class="line">    # 使用从采访（上下文）或采访本身（interview）收集的源文档编写章节</span><br><span class="line">    system_message = section_writer_instructions.format(focus=analyst.description)</span><br><span class="line">    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f&quot;Use this source to write your section: &#123;context&#125;&quot;)]) </span><br><span class="line">                </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;sections&quot;: [section.content]&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">interview_builder = StateGraph(InterviewState)</span><br><span class="line">interview_builder.add_node(&quot;ask_question&quot;, generate_question)</span><br><span class="line">interview_builder.add_node(&quot;search_web&quot;, search_web)</span><br><span class="line">interview_builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">interview_builder.add_node(&quot;answer_question&quot;, generate_answer)</span><br><span class="line">interview_builder.add_node(&quot;save_interview&quot;, save_interview)</span><br><span class="line">interview_builder.add_node(&quot;write_section&quot;, write_section)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">interview_builder.add_edge(START, &quot;ask_question&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;ask_question&quot;, &quot;search_web&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;ask_question&quot;, &quot;search_wikipedia&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;search_web&quot;, &quot;answer_question&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;search_wikipedia&quot;, &quot;answer_question&quot;)</span><br><span class="line">interview_builder.add_conditional_edges(&quot;answer_question&quot;, route_messages,[&#x27;ask_question&#x27;,&#x27;save_interview&#x27;])</span><br><span class="line">interview_builder.add_edge(&quot;save_interview&quot;, &quot;write_section&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;write_section&quot;, END)</span><br><span class="line"></span><br><span class="line"># 采访</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=&quot;Conduct Interviews&quot;)</span><br><span class="line"></span><br><span class="line"># 视图</span><br><span class="line">display(Image(interview_graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725101725158.png" alt="image-20250725101725158"></p>
<h5 id="Map-Reduce（Parallelze-interviews-Map-Reduce）-并行化访谈"><a href="#Map-Reduce（Parallelze-interviews-Map-Reduce）-并行化访谈" class="headerlink" title="Map-Reduce（Parallelze interviews: Map-Reduce） 并行化访谈"></a><strong>Map-Reduce（Parallelze interviews: Map-Reduce）</strong> <strong>并行化访谈</strong></h5><p>我们通过 <code>Send()</code> API 并行化处理访谈，这是一个映射步骤。我们将它们在 reduce 步骤中组合成报告正文。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import List, Annotated</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line">class ResearchGraphState(TypedDict):</span><br><span class="line">    topic: str                           # 研究主题 (字符串类型)</span><br><span class="line">    max_analysts: int                   # 分析师数量 (整数类型)</span><br><span class="line">    human_analyst_feedback: str         # 人类分析师的反馈 (字符串类型)</span><br><span class="line">    analysts: List[Analyst]             # 提问的分析师列表 (Analyst 对象的列表)</span><br><span class="line">    sections: Annotated[list, operator.add] # 报告章节列表 (使用 operator.add 作为 Send() API 的键，意味着列表可以通过相加来合并)</span><br><span class="line">    introduction: str                   # 最终报告的引言部分 (字符串类型)</span><br><span class="line">    content: str                        # 最终报告的内容主体部分 (字符串类型)</span><br><span class="line">    conclusion: str                     # 最终报告的结论部分 (字符串类型)</span><br><span class="line">    final_report: str                   # 最终完整的报告 (字符串类型)</span><br><span class="line"></span><br><span class="line"># 从 langgraph.constants 导入 Send 类</span><br><span class="line">from langgraph.constants import Send</span><br><span class="line">def initiate_all_interviews(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 这是“map”（映射）步骤，我们使用 Send API 并行运行每个采访子图 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否存在人类反馈</span><br><span class="line">    human_analyst_feedback = state.get(&#x27;human_analyst_feedback&#x27;)</span><br><span class="line">    if human_analyst_feedback:</span><br><span class="line">        # 如果有反馈，则返回到 &quot;create_analysts&quot; 节点进行调整</span><br><span class="line">        return &quot;create_analysts&quot;</span><br><span class="line"></span><br><span class="line">    # 否则，通过 Send() API 并行启动所有采访</span><br><span class="line">    else:</span><br><span class="line">        topic = state[&quot;topic&quot;]</span><br><span class="line">        # 为每个分析师创建一个 Send 对象</span><br><span class="line">        # 目标是 &quot;conduct_interview&quot; 节点</span><br><span class="line">        # 传递的参数包括该分析师对象和一条初始消息</span><br><span class="line">        return [Send(&quot;conduct_interview&quot;, &#123;&quot;analyst&quot;: analyst,</span><br><span class="line">                                           &quot;messages&quot;: [HumanMessage(</span><br><span class="line">                                               content=f&quot;所以你说你正在写一篇关于 &#123;topic&#125; 的文章？&quot;</span><br><span class="line">                                           )</span><br><span class="line">                                                       ]&#125;) for analyst in state[&quot;analysts&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="Finalize-最终确定"><a href="#Finalize-最终确定" class="headerlink" title="Finalize 最终确定"></a><strong>Finalize</strong> <strong>最终确定</strong></h5><p>我们添加最后一个步骤，为最终报告撰写引言和结论。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import List, Annotated</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"># 定义用于撰写最终报告的指令模板</span><br><span class="line">report_writer_instructions = &quot;&quot;&quot;你是一位正在撰写关于以下主题报告的技术作家：</span><br><span class="line"></span><br><span class="line">&#123;topic&#125;</span><br><span class="line">    </span><br><span class="line">你有一个分析师团队。每个分析师做了两件事：</span><br><span class="line"></span><br><span class="line">1. 他们就一个特定的子主题与专家进行了采访。</span><br><span class="line">2. 他们将他们的发现写成了一份备忘录。</span><br><span class="line"></span><br><span class="line">你的任务：</span><br><span class="line"></span><br><span class="line">1. 你将得到一份来自你所有分析师的备忘录集合。</span><br><span class="line">2. 仔细思考每份备忘录中的见解。</span><br><span class="line">3. 将这些见解整合成一个清晰的整体摘要，把所有备忘录中的核心思想联系起来。</span><br><span class="line">4. 将每份备忘录中的要点总结成一个连贯的单一叙述。</span><br><span class="line"></span><br><span class="line">报告格式要求：</span><br><span class="line"> </span><br><span class="line">1. 使用 Markdown 格式。</span><br><span class="line">2. 报告开头不要有前言。</span><br><span class="line">3. 不要使用子标题。</span><br><span class="line">4. 报告开头使用一个一级标题：## Insights （## 见解）</span><br><span class="line">5. 在报告中不要提及任何分析师的名字。</span><br><span class="line">6. 保留备忘录中的所有引用，这些引用会用方括号标注，例如 [1] 或 [2]。</span><br><span class="line">7. 创建一个最终的、合并的来源列表，并添加到以 `## Sources` 为标题的部分。</span><br><span class="line">8. 按顺序列出你的来源，不要重复。</span><br><span class="line"></span><br><span class="line">[1] 来源 1</span><br><span class="line">[2] 来源 2</span><br><span class="line"></span><br><span class="line">以下是你的分析师提供的备忘录，你需要根据它们来撰写报告：</span><br><span class="line"></span><br><span class="line">&#123;context&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_report(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告主体内容的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节（备忘录）</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节（备忘录）连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和备忘录内容，调用 LLM 生成最终报告</span><br><span class="line">    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)    </span><br><span class="line">    report = llm.invoke([SystemMessage(content=system_message)] + [HumanMessage(content=&quot;根据这些备忘录写一份报告。&quot;)]) </span><br><span class="line">    # 返回报告内容</span><br><span class="line">    return &#123;&quot;content&quot;: report.content&#125;</span><br><span class="line"></span><br><span class="line"># 定义用于撰写引言和结论的指令模板</span><br><span class="line">intro_conclusion_instructions = &quot;&quot;&quot;你是一位正在完成关于 &#123;topic&#125; 报告的技术作家。</span><br><span class="line"></span><br><span class="line">你将得到报告的所有章节。</span><br><span class="line"></span><br><span class="line">你的工作是撰写一个清晰且有说服力的引言或结论部分。</span><br><span class="line"></span><br><span class="line">用户会指示你是写引言还是结论。</span><br><span class="line"></span><br><span class="line">两个部分都不要有前言。</span><br><span class="line"></span><br><span class="line">目标大约 100 个词，简洁地预览（对于引言）或回顾（对于结论）报告的所有章节。</span><br><span class="line"></span><br><span class="line">使用 Markdown 格式。</span><br><span class="line"></span><br><span class="line">对于你的引言，创建一个引人注目的标题，并使用 # 标题级别。</span><br><span class="line">对于你的引言，使用 ## Introduction （## 引言） 作为部分标题。</span><br><span class="line"></span><br><span class="line">对于你的结论，使用 ## Conclusion （## 结论） 作为部分标题。</span><br><span class="line"></span><br><span class="line">以下是供你参考以撰写相应部分的章节：&#123;formatted_str_sections&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_introduction(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告引言的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和章节内容，调用 LLM 生成引言</span><br><span class="line">    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    </span><br><span class="line">    intro = llm.invoke([instructions] + [HumanMessage(content=&quot;写报告的引言&quot;)]) </span><br><span class="line">    # 返回引言内容</span><br><span class="line">    return &#123;&quot;introduction&quot;: intro.content&#125;</span><br><span class="line"></span><br><span class="line">def write_conclusion(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告结论的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和章节内容，调用 LLM 生成结论</span><br><span class="line">    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    </span><br><span class="line">    conclusion = llm.invoke([instructions] + [HumanMessage(content=&quot;写报告的结论&quot;)]) </span><br><span class="line">    # 返回结论内容</span><br><span class="line">    return &#123;&quot;conclusion&quot;: conclusion.content&#125;</span><br><span class="line"></span><br><span class="line">def finalize_report(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 这是“reduce”（归约）步骤，我们收集所有部分，将它们组合起来，并进行反思以写出引言/结论 &quot;&quot;&quot;</span><br><span class="line">    &quot;&quot;&quot; 最终整合报告的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取报告主体内容</span><br><span class="line">    content = state[&quot;content&quot;]</span><br><span class="line">    # 如果内容以 &quot;## Insights&quot; 开头，则移除这个标题</span><br><span class="line">    if content.startswith(&quot;## Insights&quot;):</span><br><span class="line">        content = content.strip(&quot;## Insights&quot;)</span><br><span class="line">    # 尝试分离报告主体和来源部分</span><br><span class="line">    if &quot;## Sources&quot; in content:</span><br><span class="line">        try:</span><br><span class="line">            content, sources = content.split(&quot;\n## Sources\n&quot;)</span><br><span class="line">        except:</span><br><span class="line">            sources = None # 如果分离失败，则来源部分为空</span><br><span class="line">    else:</span><br><span class="line">        sources = None</span><br><span class="line"></span><br><span class="line">    # 将引言、主体内容和结论连接起来形成最终报告</span><br><span class="line">    final_report = state[&quot;introduction&quot;] + &quot;\n\n---\n\n&quot; + content + &quot;\n\n---\n\n&quot; + state[&quot;conclusion&quot;]</span><br><span class="line">    # 如果存在来源部分，则将其附加到最终报告末尾</span><br><span class="line">    if sources is not None:</span><br><span class="line">        final_report += &quot;\n\n## Sources\n&quot; + sources</span><br><span class="line">    # 返回最终报告</span><br><span class="line">    return &#123;&quot;final_report&quot;: final_report&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">builder = StateGraph(ResearchGraphState)</span><br><span class="line">builder.add_node(&quot;create_analysts&quot;, create_analysts)</span><br><span class="line">builder.add_node(&quot;human_feedback&quot;, human_feedback)</span><br><span class="line">builder.add_node(&quot;conduct_interview&quot;, interview_builder.compile()) # 将之前定义的采访图编译后作为一个节点</span><br><span class="line">builder.add_node(&quot;write_report&quot;, write_report)</span><br><span class="line">builder.add_node(&quot;write_introduction&quot;, write_introduction)</span><br><span class="line">builder.add_node(&quot;write_conclusion&quot;, write_conclusion)</span><br><span class="line">builder.add_node(&quot;finalize_report&quot;, finalize_report)</span><br><span class="line"></span><br><span class="line"># 定义工作流逻辑</span><br><span class="line">builder.add_edge(START, &quot;create_analysts&quot;) # 从开始到创建分析师</span><br><span class="line">builder.add_edge(&quot;create_analysts&quot;, &quot;human_feedback&quot;) # 创建分析师后进入人类反馈环节</span><br><span class="line"># 条件边：根据 human_feedback 节点的输出，决定是回到创建分析师还是开始采访</span><br><span class="line">builder.add_conditional_edges(&quot;human_feedback&quot;, initiate_all_interviews, [&quot;create_analysts&quot;, &quot;conduct_interview&quot;]) </span><br><span class="line"># 采访完成后，并行执行撰写报告、引言和结论</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_report&quot;)</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_introduction&quot;)</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_conclusion&quot;)</span><br><span class="line"># 撰写完报告的三个部分后，汇聚到最终整合步骤</span><br><span class="line">builder.add_edge([&quot;write_conclusion&quot;, &quot;write_report&quot;, &quot;write_introduction&quot;], &quot;finalize_report&quot;)</span><br><span class="line">builder.add_edge(&quot;finalize_report&quot;, END) # 最终整合后结束</span><br><span class="line"></span><br><span class="line"># 编译图</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"># 编译图，并设置在 &#x27;human_feedback&#x27; 节点前中断，以及使用检查点保存器</span><br><span class="line">graph = builder.compile(interrupt_before=[&#x27;human_feedback&#x27;], checkpointer=memory)</span><br><span class="line"># 显示图的可视化表示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725102148881.png" alt="image-20250725102148881"></p>
<h5 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h5><p>让我们提出一个关于 LangGraph 的开放式问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">max_analysts = 3 </span><br><span class="line">topic = &quot;采用 LangGraph 作为代理框架的好处&quot;</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 使用 stream 但不执行打印逻辑</span><br><span class="line">for event in graph.stream(&#123;</span><br><span class="line">    &quot;topic&quot;: topic,</span><br><span class="line">    &quot;max_analysts&quot;: max_analysts</span><br><span class="line">&#125;, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    pass  # 不执行任何操作</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#人工更新节点</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                                &quot;请加入这家原生生成式 AI 创业公司的首席执行官。&quot;&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 确认我们已经满意，返回none</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            None&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 继续执行</span><br><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;updates&quot;):</span><br><span class="line">    print(&quot;--Node--&quot;)</span><br><span class="line">    node_name = next(iter(event.keys()))</span><br><span class="line">    print(node_name)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725103159942.png" alt="image-20250725103159942"></p>
<p><a target="_blank" rel="noopener" href="https://smith.langchain.com/public/6504cafd-d314-48d1-8640-57dc3f472e61/r">https://smith.langchain.com/public/6504cafd-d314-48d1-8640-57dc3f472e61/r</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/21/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/Retrieval/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/21/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/Retrieval/" class="post-title-link" itemprop="url">Retrieval</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-21 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-21T00:00:00+08:00">2025-07-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-05 10:41:56" itemprop="dateModified" datetime="2025-08-05T10:41:56+08:00">2025-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">实习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/" itemprop="url" rel="index"><span itemprop="name">晨晟智控</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="elastic-search"><a href="#elastic-search" class="headerlink" title="elastic search"></a>elastic search</h3><p>Elasticsearch 是当今最流行的 <strong>开源分布式搜索与分析引擎</strong>，用 Java 开发，基于 <strong>Apache Lucene</strong> 构建。它把<strong>全文检索、实时分析、时序数据、地理空间查询</strong>和<strong>向量检索</strong>统一到一个平台，被广泛用于日志、指标、安全、企业搜索以及 AI/RAG 场景。</p>
<p> RAG 系统中，<strong>Elasticsearch 不仅是向量数据库，更是语义检索引擎和上下文构建器</strong>，更准确地说，是<strong>向量数据库 + 全文检索引擎</strong>的混合角色。</p>
<h4 id="查找语句"><a href="#查找语句" class="headerlink" title="查找语句"></a>查找语句</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">GET /test_full_v1/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;高压旁路管道磁粉检测使用的是哪种磁化方法和磁悬液浓度？&quot;,</span><br><span class="line">      &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;,&quot;report_url&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices?v#查看所有的所有</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_count#查看文件数</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_mapping#查看映射</span><br><span class="line"></span><br><span class="line">GET test_full_v1#查看索引内容</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_search#查看索引内容</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 3,</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices/zxj_test#查看索引是否存在</span><br></pre></td></tr></table></figure>
<p>可视化平台kibana的内网路径：</p>
<ul>
<li><code>http://10.117.128.50:5601</code></li>
<li><a target="_blank" rel="noopener" href="http://10.117.128.50:5601/app/dev_tools#/console/shell">http://10.117.128.50:5601/app/dev_tools#/console/shell</a> 开发者工具</li>
</ul>
<h4 id="es支持的几种检索函数"><a href="#es支持的几种检索函数" class="headerlink" title="es支持的几种检索函数"></a>es支持的几种检索函数</h4><h5 id="向量搜索"><a href="#向量搜索" class="headerlink" title="向量搜索"></a>向量搜索</h5><p>这里的向量搜索也就是稠密向量检索，过程为<strong>“把文本/图像等非结构化数据映射成高维向量 → 在向量空间里做近似最近邻（ANN）搜索 → 按相似度排序返回结果”</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def vector_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建Elasticsearch KNN查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;knn&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: dense_vector_field,      # 指定存储向量的字段名</span><br><span class="line">            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">            &quot;k&quot;: 5,                          # 返回最相似的5个结果</span><br><span class="line">            &quot;num_candidates&quot;: 10,            # 在10个候选中选择最优的5个（提高搜索效率和准确性）</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="bm25"><a href="#bm25" class="headerlink" title="bm25"></a>bm25</h5><p>BM25（<strong>Best Matching 25</strong>）也就是全文关键词搜索，或者叫传统关键词搜索，他的核心思想为<strong>“词频越高、文档越短、词越稀有，则相关性越高”</strong>，在 TF-IDF 的基础上引入词频饱和、文档长度归一化两项修正。</p>
<blockquote>
<p>TF-IDF（<strong>Term Frequency–Inverse Document Frequency，词频-逆文档频率</strong>）是一种经典的 <strong>文本特征权重计算方法</strong>，用于衡量 <strong>一个词对一篇文档的重要性</strong>。</p>
</blockquote>
<p>项目中的bm25检索采取多字段匹配的方式，还有几个参数需要了解，如下</p>
<ol>
<li><p><strong>‘type’</strong> :决定了<strong>如何把多个字段的 BM25 打分合并成最终得分</strong>,常用的参数有以下三种</p>
<p>| type                    | 中文含义     | 打分逻辑                                                     |<br>| :——————————— | :—————- | :—————————————————————————————- |<br>| <strong>best_fields</strong>（默认） | 最佳字段优先 | 取 <strong>得分最高的那个字段</strong> 做最终分（可用 <code>tie_breaker</code> 让次佳字段再贡献一点点）。 |<br>| <strong>most_fields</strong>         | 最多字段优先 | 把所有命中字段的得分 <strong>直接相加</strong>（类似 OR 逻辑），字段越多分越高。 |<br>| <strong>cross_fields</strong>        | 跨字段合并   | 把多个字段视为 <strong>一个虚拟大字段</strong>，统一计算 TF 和 IDF，解决“关键词分散在不同字段”问题。 |</p>
</li>
<li><p><strong><code>&#39;tie_breaker&#39;</code></strong>：当多个字段都匹配时，<strong>“最佳字段”得分 + 其余字段得分×tie_breaker</strong> 作为最终得分。</p>
</li>
<li><strong><code>&#39;operator&#39;</code></strong>:控制<strong>单个字段内</strong>的多个词项是“AND”还是“OR”关系。<ul>
<li><strong><code>&quot;AND&quot;</code></strong><br>要求<strong>同一个字段</strong>必须同时包含所有查询词，减少噪音，提高精准度。适合地址、姓名等跨字段严格匹配。</li>
<li><strong><code>&quot;OR&quot;</code></strong><br>只要字段里出现任意一个词就匹配，召回量大，但可能引入不相关结果。</li>
</ul>
</li>
</ol>
<p>最后，每个字段还可以人工设置权重，如<code>&quot;fields&quot;: [&quot;title^3&quot;, &quot;content&quot;, &quot;tags^2&quot;]</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def bm25_query(search_query: str):</span><br><span class="line">    # 使用BM25算法进行传统关键词匹配</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            &quot;multi_match&quot;: &#123;  # 多字段匹配查询</span><br><span class="line">                &quot;query&quot;: search_query,</span><br><span class="line">                &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;size&quot;: 8,  # 返回最多8个结果</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="混合检索"><a href="#混合检索" class="headerlink" title="混合检索"></a>混合检索</h5><p>混合检索也就是 <a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html">Reciprocal Rank Fusion</a>（RRF），通过结合向量搜索和 BM25 搜索的结果综合判断。</p>
<p>但由于es中混合检索需要付费使用，后续检索效果评估时不做测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">def hybrid_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建混合搜索查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;retriever&quot;: &#123;</span><br><span class="line">            # 使用RRF (Reciprocal Rank Fusion) 算法融合多个检索器的结果</span><br><span class="line">            &quot;rrf&quot;: &#123;</span><br><span class="line">                # 定义多个检索器列表</span><br><span class="line">                &quot;retrievers&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第一个检索器：多字段BM25关键词搜索</span><br><span class="line">                        &quot;standard&quot;: &#123;</span><br><span class="line">                            &quot;query&quot;: &#123;</span><br><span class="line">                                # 使用multi_match在多个字段上进行BM25搜索</span><br><span class="line">                                &quot;multi_match&quot;: &#123;</span><br><span class="line">                                    &quot;query&quot;: search_query,</span><br><span class="line">                                    &quot;type&quot;: &quot;best_fields&quot;,      # 选择最佳匹配字段</span><br><span class="line">                                    &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第二个检索器：KNN向量近似搜索</span><br><span class="line">                        &quot;knn&quot;: &#123;</span><br><span class="line">                            &quot;field&quot;: dense_vector_field,      # 向量字段名（使用定义的变量）</span><br><span class="line">                            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">                            &quot;k&quot;: 5,                          # 返回5个最相似的向量结果</span><br><span class="line">                            &quot;num_candidates&quot;: 10,            # 候选向量数量，用于提高搜索准确性</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="模糊检索"><a href="#模糊检索" class="headerlink" title="模糊检索"></a>模糊检索</h5><p>无论是在网页搜索、文件检索，还是数据库查询中，我们时常会因为拼写错误或信息不完整而无法找到需要的结果。<strong>模糊搜索</strong>（Fuzzy Search）应运而生，它通过识别与查询相似的词语来帮助我们获得更加灵活的搜索结果。</p>
<p>这里是将bm25与模糊搜索结合起来</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">def fuzzy_query(search_query: str):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    创建模糊搜索查询函数，支持拼写错误和近似匹配</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        search_query (str): 用户输入的搜索查询文本</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        Dict: Elasticsearch模糊搜索查询体</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            # 使用match查询进行文本匹配</span><br><span class="line">            &quot;match&quot;: &#123;</span><br><span class="line">                # 在指定的文本字段中进行搜索</span><br><span class="line">                text_field: &#123;</span><br><span class="line">                    &quot;query&quot;: search_query,        # 用户的搜索查询文本</span><br><span class="line">                    &quot;fuzziness&quot;: &quot;AUTO&quot;,          # 自动模糊匹配设置</span><br><span class="line">                    # fuzziness参数说明：</span><br><span class="line">                    # - &quot;AUTO&quot;：根据词长度自动调整模糊度</span><br><span class="line">                    #   - 0-2个字符：不允许错误</span><br><span class="line">                    #   - 3-5个字符：允许1个编辑距离错误</span><br><span class="line">                    #   - 5个以上字符：允许2个编辑距离错误</span><br><span class="line">                    # - 也可以设置具体数值：0, 1, 2</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><code>AUTO</code> 规则：<strong>0~2 字符</strong>不允许错；<strong>3~5 字符</strong>最多1错；<strong>&gt;5 字符</strong>最多2错。</li>
<li>对 <strong>text 字段</strong>先分词，再对每个 token 做模糊 → 召回 <code>Elasticsearch</code>。</li>
</ul>
<h4 id="elasticsearch的连接"><a href="#elasticsearch的连接" class="headerlink" title="elasticsearch的连接"></a>elasticsearch的连接</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from langchain_elasticsearch import ElasticsearchRetriever</span><br><span class="line">from embeddings_model import select_embeddings_model</span><br><span class="line"># 根据模型名称选择嵌入模型</span><br><span class="line">embedding_model_name=&#x27;bge&#x27;</span><br><span class="line">embeddings = select_embeddings_model(embedding_model_name)</span><br><span class="line">dense_vector_field=&#x27;vector&#x27;</span><br><span class="line">text_field=&#x27;text&#x27;</span><br><span class="line">search_func=fuzzy_query</span><br><span class="line"># 创建Elasticsearch检索器</span><br><span class="line">retriever = ElasticsearchRetriever.from_es_params(</span><br><span class="line">    index_name=&quot;zxj_test&quot;,  # 指定索引名称</span><br><span class="line">    body_func=fuzzy_query,  # 查询函数</span><br><span class="line">    content_field=&quot;text&quot;,  # 内容字段名</span><br><span class="line">    url=&#x27;http://elasticsearch:9200/&#x27;# Elasticsearch服务器地址</span><br><span class="line">)</span><br><span class="line">print(&quot;连接成功&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="elasticsearch的入库"><a href="#elasticsearch的入库" class="headerlink" title="elasticsearch的入库"></a>elasticsearch的入库</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">document = []</span><br><span class="line">id_list = []</span><br><span class="line"></span><br><span class="line"># 遍历文件夹中的所有.md文件</span><br><span class="line">for filename in os.listdir(folder_path):</span><br><span class="line">    if filename.endswith(&quot;.md&quot;):</span><br><span class="line">        file_path = os.path.join(folder_path, filename)</span><br><span class="line"></span><br><span class="line">        # 从文件名中提取chunk_id（去除.md扩展名）</span><br><span class="line">        chunk_id = filename.replace(&quot;.md&quot;, &quot;&quot;)</span><br><span class="line"></span><br><span class="line">        # 读取MD文件内容</span><br><span class="line">        with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as file:</span><br><span class="line">            text_content = file.read()</span><br><span class="line">  </span><br><span class="line">        # 查找对应的URL（根据文件名匹配）</span><br><span class="line">        report_url = &quot;&quot;</span><br><span class="line">        # 从folder_name中提取核心文档名（最后一个^后面的部分）</span><br><span class="line">        core_folder_name = folder_name.split(&#x27;^&#x27;)[-1]  # 提取核心文档名</span><br><span class="line"></span><br><span class="line">        # 根据core_folder_name查找对应的URL</span><br><span class="line">        report_url = find_url_by_name_from_list(docs_data, core_folder_name)</span><br><span class="line"></span><br><span class="line">        # 构建document结构</span><br><span class="line">        doc = Document(</span><br><span class="line">            page_content=text_content,</span><br><span class="line">            metadata=&#123;</span><br><span class="line">                &quot;report_name&quot;: folder_name,</span><br><span class="line">                &quot;report_url&quot;: report_url,</span><br><span class="line">                &quot;chunk_id&quot;: chunk_id</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        document.append(doc)</span><br><span class="line">        id_list.append(folder_name + &quot;_&quot; + chunk_id)</span><br><span class="line"></span><br><span class="line"># 批量添加到向量库</span><br><span class="line">es_vector_store.add_documents(documents=document, ids=id_list)</span><br><span class="line">print(f&quot;    文件夹 &#123;folder_name&#125; 已成功入库，共 &#123;len(document)&#125; 个文档块&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h4><p><a target="_blank" rel="noopener" href="https://python.langchain.ac.cn/docs/integrations/retrievers/elasticsearch_retriever/#bm25">Elasticsearch检索器 | 🦜️🔗 LangChain 框架</a></p>
<h3 id="主流的检索策略"><a href="#主流的检索策略" class="headerlink" title="主流的检索策略"></a>主流的检索策略</h3><h4 id="BM25-全文关键词检索"><a href="#BM25-全文关键词检索" class="headerlink" title="BM25 全文关键词检索"></a>BM25 全文关键词检索</h4><p>BM25（Best Matching 25）是一种久经考验的排序算法，广泛应用于传统搜索引擎中。它基于“词袋模型”，核心思想是通过关键词匹配程度来衡量文档与查询的相关性。</p>
<p>核心原理概览：</p>
<p>词频 (Term Frequency, TF)：一个词在文档中出现的次数越多，通常意味着这篇文档与该词相关性越高。但BM25会进行“饱和度”处理，避免某些超高频词过度影响结果。可以想象成，一篇文章提到“苹果”10次，比提到1次更相关，但提到100次和提到50次，在“苹果”这个主题上的相关性增加可能就没那么显著了。<br>逆文档频率 (Inverse Document Frequency, IDF)：如果一个词在整个文档集合中都很罕见（只在少数文档中出现），那么它对于区分文档主题就更重要，IDF值就高。比如“量子纠缠”这个词远比“的”、“是”这类词更能锁定专业文档。<br>文档长度归一化：用于平衡长短文档的得分，避免长文档仅仅因为内容多而获得不公平的高分。<br>工作方式举例：当用户搜索“深度学习入门教程”时，BM25会倾向于找出那些更频繁出现“深度学习”、“入门”、“教程”这些词，且这些词相对不那么常见的文档。</p>
<p><strong>1. 公式整体结构</strong></p>
<script type="math/tex; mode=display">
\text{score}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \underbrace{\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot \left(1 - b + b \cdot \frac{|D|}{\text{avgdl}}\right)}}_{\text{词频归一化项（TF）}}</script><ul>
<li><strong>IDF 部分</strong>：衡量词项 $ q_i $ 的区分能力（逆文档频率）。</li>
<li><strong>TF 部分</strong>：衡量词项 $ q_i $ 在文档 $ D $ 中的匹配程度（词频归一化）。</li>
<li><strong>求和</strong>：对查询中的所有词项 $ q_i $ 的得分求和，得到最终相关性分数。</li>
</ul>
<p><strong>2. IDF 部分</strong></p>
<script type="math/tex; mode=display">
\text{IDF}(q_i) = \ln\left(\frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}\right)</script><ul>
<li><strong>意义</strong>：IDF 值越高，词项 $ q_i $ 越能区分文档（常见于少数文档中的词）。</li>
<li><strong>平滑处理</strong>：分子和分母均加 0.5，避免极端值（如 $ n(q_i) = 0 $ 时 ID 无限大）。</li>
<li><strong>参数</strong>：<ul>
<li>$ N $：文档总数。</li>
<li>$ n(q_i) $：包含 $ q_i $ 的文档数。</li>
</ul>
</li>
</ul>
<p><strong>3. 词频归一化项（TF）</strong></p>
<script type="math/tex; mode=display">
\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot \left(1 - b + b \cdot \frac{|D|}{\text{avgdl}}\right)}</script><ul>
<li><strong>非线性饱和</strong>：分子和分母均包含 $ f(q_i, D) $，使词频增长带来的增益逐渐减小（避免长文档中重复词项的过度影响）。</li>
<li><strong>文档长度归一化</strong>：<ul>
<li>$ |D| $：文档 $ D $ 的长度（词数）。</li>
<li>$ \text{avgdl} $：整个文档集合的平均文档长度。</li>
<li>$ b $：控制文档长度对得分的影响（$ b=1 $ 时完全归一化，$ b=0 $ 时忽略长度）。</li>
</ul>
</li>
<li><strong>参数</strong>：<ul>
<li>$ k_1 $：控制词频饱和的系数（通常 $ k_1 \in [1.2, 2.0] $，默认 $ k_1 = 1.5 $）。</li>
<li>$ b $：默认 $ b = 0.75 $。</li>
</ul>
</li>
</ul>
<p>这个公式虽然看起来有些复杂，但它精妙地平衡了词频、词的稀有度以及文档长度这几个核心因素，是BM25算法效果出色的关键。</p>
<h6 id="BM25、全文搜索与倒排索引：它们是如何协同工作的？"><a href="#BM25、全文搜索与倒排索引：它们是如何协同工作的？" class="headerlink" title="BM25、全文搜索与倒排索引：它们是如何协同工作的？"></a>BM25、全文搜索与倒排索引：它们是如何协同工作的？</h6><p><strong>这三者是构建搜索系统的关键组件：</strong></p>
<ul>
<li><p>全文搜索 (Full-Text Search)：这是我们希望达成的目标——在大量文本中找到包含特定信息的文档。</p>
</li>
<li><p>倒排索引 (Inverted Index)：这是实现高效全文搜索的数据结构基础。它像一本书末尾的详细“关键词索引”，记录了每个词出现在哪些文档中以及相关位置信息。当用户查询时，系统可以通过倒排索引快速定位到包含查询词的候选文档。</p>
</li>
<li>BM25：在通过倒排索引找到候选文档后，BM25算法登场，为每个文档计算一个相关性得分，然后按分排序，将最相关的结果呈现给用户。</li>
</ul>
<p><strong>把它们比作在图书馆找特定主题的书籍：</strong></p>
<ul>
<li>你告诉图书管理员你要找关于“天体物理学”的书（用户查询）。</li>
<li>管理员查阅一个总卡片索引（倒排索引），迅速告诉你哪些书架（文档ID）上有包含“天体物理学”这个词的书。</li>
<li>你走到这些书架，快速翻阅这些书（BM25评分过程），根据目录、摘要和提及“天体物理学”的频繁程度及重要性，判断哪几本最符合你的需求，并把它们按相关性高低排好。</li>
</ul>
<h4 id="Dense-Vector-kNN-向量语义检索"><a href="#Dense-Vector-kNN-向量语义检索" class="headerlink" title="Dense Vector / kNN 向量语义检索"></a>Dense Vector / kNN 向量语义检索</h4><p>向量语义检索（Dense Vector / k-Nearest Neighbor，简称 kNN）是一种<strong>基于高维稠密向量表示的语义检索技术</strong>，与传统关键词倒排索引不同，它通过<strong>自然语言的上下文含义</strong>而非字面匹配来寻找最相关的文档或实体。</p>
<ol>
<li><p><strong>Embedding</strong>：使用预训练语言模型（如 BERT、Sentence-Transformers）把文本映射为<strong>固定维度的稠密向量</strong>（通常 128–1024 维）。</p>
</li>
<li><p><strong>kNN 搜索</strong>：给定查询向量，<strong>在向量空间中找距离最近的 k 个文档向量</strong>。距离度量常见：</p>
<ul>
<li>余弦相似度（cosine）</li>
<li>内积 / dot-product</li>
<li>L2 欧氏距离</li>
</ul>
</li>
</ol>
<h4 id="Hybrid-Retrieval-混合检索"><a href="#Hybrid-Retrieval-混合检索" class="headerlink" title="Hybrid Retrieval 混合检索"></a>Hybrid Retrieval 混合检索</h4><p>既然不同的检索策略各有千秋（例如，BM25擅长关键词精确匹配，Embedding擅长语义理解），那么将它们结合起来，是不是能达到“1+1&gt;2”的效果呢？答案是肯定的，这就是混合检索的核心思想。</p>
<p>常见做法：同时使用BM25（或其他稀疏检索方法）和一种或多种Embedding检索方法，然后将它们各自的检索结果进行融合排序。</p>
<p>融合策略举例：</p>
<p>RRF (Reciprocal Rank Fusion, 倒数排序融合)：一种简单但鲁棒的融合方法。它不关心不同检索系统输出的原始得分，只关心每个文档在各自结果列表中的排名。一个文档 doc 的RRF得分计算如下：</p>
<script type="math/tex; mode=display">
Score_RRF(doc) = Σ_{s ∈ Systems} (1 / (k + rank_s(doc)))</script><p>其中：</p>
<ul>
<li>Systems 是所有参与融合的检索系统的集合。</li>
<li>rank_s(doc) 是文档 doc 在检索系统 s 给出的结果列表中的排名（例如，第一名是1，第二名是2）。</li>
<li>k 是一个小常数（例如，常设置为60），用于平滑得分，避免排名靠后的文档得分过小或排名第一的文档得分占比过高。</li>
</ul>
<h4 id="Reranker-重排序器"><a href="#Reranker-重排序器" class="headerlink" title="Reranker  重排序器"></a>Reranker  重排序器</h4><p>经过上述一种或多种检索策略的“粗筛”（召回阶段），我们通常会得到一个包含较多候选文档的列表（比如几百个）。为了进一步提升最终喂给LLM的文档质量，Reranker（重排序器）应运而生。它相当于一位“精炼师”或“质量品鉴官”，对初步召回的结果进行更细致、更精准的二次排序。</p>
<ol>
<li>召回<br>倒排 / 向量 / 混合先给 <strong>Top-N</strong>（N≈100~1 k）。</li>
<li>拼特征<br>把 <code>(query, doc)</code> 拼成一条输入：<br><code>[CLS] 用户问题 [SEP] 标题+正文 [SEP]</code>。</li>
<li>打分<br>扔给 Cross-Encoder 或 ColBERT → 输出<strong>一个相关性分数</strong>。</li>
<li>重排<br>按分数从高到低重新排序，只留 <strong>Top-K</strong>（K≈10~20）。</li>
<li>返回<br>重排后的短列表交给前端或 LLM，完成一次“精读”。</li>
</ol>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_59614665/article/details/149066780">大模型RAG | 深入了解几种主流的检索策略（BM25、Embedding、混合检索、Reranker）-CSDN博客</a></p>
<h3 id="项目关于elasticsearch代码阅读记录"><a href="#项目关于elasticsearch代码阅读记录" class="headerlink" title="项目关于elasticsearch代码阅读记录"></a>项目关于elasticsearch代码阅读记录</h3><p>阅读elasticsearch代码相关记录:</p>
<ol>
<li><strong>embedding_model</strong>.select_embeddings_model:根据指定的模型名称加载</li>
<li><strong>make_es_vector_store</strong>：<ol>
<li>docs_url = pd.read_excel(‘docs_new.xlsx’)，从excel加载url并进行数据处理，保存筛选后的ur</li>
<li>完成文件加载测试：xizhang/retrival/docfile_test/test.py；</li>
<li>初始化es，使用elastic_search.load_es_index加载存储索引</li>
<li>完成测试elasticsearch连接与索引构建（索引名zxj_test）：/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_es_connect.py，/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_add_es.py</li>
<li>顺序批量处理文件：共16000多份，每十份为一批进行处理，使用download_pdf.py进行文件下载，使用，使用vector_base.rewrite_file对文件进行处理，这里可以修改代码，增加对mineru处理pdf的markdown文件的处理，返回Document对象列表；</li>
</ol>
</li>
<li><strong>elastic_search</strong></li>
</ol>
<p>重写了检索策略的函数，包括BM25，KNN，混合搜索</p>
<ol>
<li><p>elastic_retriever创建Elasticsearch检索器：根据搜索类型选择对应的查询函数，创建Elasticsearch检索器ElasticsearchRetriever.from_es_params</p>
</li>
<li><p><strong>retrievers</strong></p>
<ol>
<li>定义函数select_retriever，根据指定的名称选择并返回相应的检索器，目前只有bm25</li>
</ol>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/" class="post-title-link" itemprop="url">LangGraph学习——agent——上</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-18T00:00:00+08:00">2025-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-13 09:25:21" itemprop="dateModified" datetime="2025-08-13T09:25:21+08:00">2025-08-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本教程为langchain官方教程的学习记录</p>
<p><a target="_blank" rel="noopener" href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a target="_blank" rel="noopener" href="https://github.com/zxj-2023/learn-rag-langchain"><a target="_blank" rel="noopener" href="https://github.com/zxj-2023/learn-rag-langchain/tree/main/academy-langgraph">learn-rag-langchain/academy-langgraph at main · zxj-2023/learn-rag-langchain</a></a></p>
<h3 id="module-1"><a href="#module-1" class="headerlink" title="module-1"></a>module-1</h3><h4 id="route路由"><a href="#route路由" class="headerlink" title="route路由"></a>route路由</h4><p>在 LangGraph 中，<strong>route（路由）\</strong>的核心作用是*<em>根据当前状态动态决定“下一步应该执行哪个节点”*</em></p>
<h5 id="定义工具"><a href="#定义工具" class="headerlink" title="定义工具"></a>定义工具</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def multiply(a: int, b: int) -&gt; int:</span><br><span class="line">    &quot;&quot;&quot;Multiply a and b.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: first int</span><br><span class="line">        b: second int</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line">    </span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">llm_with_tools = llm.bind_tools([multiply])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>三引号字符串叫 <strong>docstring</strong>，它会被 LangChain 拿来做两件事：</p>
<ol>
<li><strong>生成工具的 description（给大模型看的“说明书”）</strong><br>没有它时，LangChain 只能退而求其次，把函数名 <code>multiply</code> 拼成一句 “multiply tool” 之类的默认描述。大模型拿到的工具列表里，这个工具就只有一个干巴巴的名字和参数列表，它可能猜不到这个工具到底是干什么的</li>
<li><strong>给人类开发者自己看</strong><br>IDE、文档生成器、静态检查工具都会读取这段文字，方便后期维护。</li>
</ol>
</blockquote>
<h5 id="构建条件边"><a href="#构建条件边" class="headerlink" title="构建条件边"></a>构建条件边</h5><p><code>tool_calling_llm</code> 是一个<strong>普通的计算节点</strong>（node），负责把当前对话状态交给大模型，让大模型决定要不要调用工具；</p>
<p>真正完成“路由”动作的是 <strong><code>tools_condition</code></strong> 这个函数——它才是 LangGraph 里的 <strong>route（条件边）</strong>。</p>
<p><code>tools_condition</code> 是 作为<strong>LangGraph 预置的“默认路由函数”</strong>，功能就是，如果大模型的最新回复中包含工具调用，就调用工具</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># Node</span><br><span class="line">def tool_calling_llm(state: MessagesState):</span><br><span class="line">	#调用大模型后将最新的消息返回</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm_with_tools.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">#MessagesState 是 LangGraph 官方预置 的一种 状态（State）定义</span><br><span class="line">#这个状态维护了一个消息list，有新的消息就加进这个消息list</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;tool_calling_llm&quot;, tool_calling_llm)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode([multiply]))</span><br><span class="line">builder.add_edge(START, &quot;tool_calling_llm&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;tool_calling_llm&quot;,</span><br><span class="line">    # 如果助手（结果）的最新消息是工具调用 -&gt; tools_condition 路由到工具</span><br><span class="line">    # 如果助手（结果）的最新消息不是工具调用 -&gt; tools_condition 路由到 END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719142543838.png" alt="image-20250719142543838"></p>
<h5 id="调用"><a href="#调用" class="headerlink" title="调用"></a>调用</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage</span><br><span class="line">messages = [HumanMessage(content=&quot;你好，2乘2是多少&quot;)]</span><br><span class="line">messages = graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，2乘2是多少</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_e026ceb409e247748786ad)</span><br><span class="line"> Call ID: call_e026ceb409e247748786ad</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">4</span><br></pre></td></tr></table></figure>
<h4 id="agent代理"><a href="#agent代理" class="headerlink" title="agent代理"></a>agent代理</h4><p>在 LangGraph 中，<strong>代理（Agent）</strong> 被明确定义为<strong>“一个由大语言模型（LLM）驱动的、能够循环决策并调用外部工具来完成任务的节点或子图”</strong>。</p>
<p><strong>Agent = LLM + 工具集合 + 提示模板</strong>，三者在 LangGraph 的状态化图结构里循环运行，直到满足停止条件。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.03629">ReAct</a> 是一种流行的通用智能体架构，它结合了这些扩展，并整合了三个核心概念。</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#tool-calling">工具调用</a>：允许LLM根据需要选择和使用各种工具。</li>
<li><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#memory">记忆</a>：使智能体能够保留和使用之前步骤的信息。</li>
<li><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#planning">规划</a>：使LLM能够创建并遵循多步计划以实现目标。</li>
</ol>
<p>即</p>
<p><code>act</code>- 让模型调用特定工具</p>
<p><code>observe</code> - 将工具输出传递回模型  </p>
<p> <code>reason</code> - 让模型对工具输出进行推理，以决定下一步操作（例如，调用另一个工具或直接响应）</p>
</blockquote>
<h5 id="定义工具-1"><a href="#定义工具-1" class="headerlink" title="定义工具"></a>定义工具</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tools = [add, multiply, divide]#工具函数具体内容省略</span><br><span class="line">llm = ChatOpenAI()</span><br><span class="line"></span><br><span class="line"># 在这个 ipynb 文件中，我们将并行工具调用（parallel tool calling）设置为 false，因为数学计算通常是按顺序执行的，并且这次我们有3个可以进行数学计算的工具。</span><br><span class="line"># OpenAI 模型为了效率，默认进行并行工具调用，详情请参阅 `https://python.langchain.com/docs/how_to/tool_calling_parallel/`</span><br><span class="line"># 不妨尝试一下，看看模型在处理数学方程式时的表现！</span><br><span class="line">llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)</span><br></pre></td></tr></table></figure>
<h5 id="创建代理"><a href="#创建代理" class="headerlink" title="创建代理"></a>创建代理</h5><p>定义节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line"># System message</span><br><span class="line">sys_msg = SystemMessage(content=&quot;你是一个乐于助人的助手，负责对一组输入执行算术运算。&quot;)</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def assistant(state: MessagesState):</span><br><span class="line">   return &#123;&quot;messages&quot;: [llm_with_tools.invoke([sys_msg] + state[&quot;messages&quot;])]&#125;</span><br></pre></td></tr></table></figure>
<p>这一步相当于定义了系统提示词，然后在 assistant 这个节点里，通过 [sys_msg] + state[“messages”] 这部分代码，这个系统提示词被添加到了整个对话历史的最前面，然后一起发送给模型。这样一来，模型在生成回复时就会遵循这个系统提示词的指示。</p>
<p>与上一个不同的是，我们将 <code>Tools</code> 节点 <strong>回环</strong> 连接到 <code>Assistant</code>，从而形成一个回路。</p>
<p>在 assistant节点执行后，<code>tools_condition</code>检查模型的输出是否为工具调用。</p>
<p>如果是工具调用，则流程被导向至 <code>tools</code> 节点。  </p>
<p><code>tools</code>节点重新连接到<code>assistant</code><strong>。</strong> 只要模型决定调用工具，此循环就会继续。  </p>
<p>如果模型的响应不是工具调用，则流程被导向至结束，终止该过程。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line"></span><br><span class="line"># Define nodes: these do the work</span><br><span class="line">builder.add_node(&quot;assistant&quot;, assistant)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode(tools))</span><br><span class="line"></span><br><span class="line"># Define edges: these determine how the control flow moves</span><br><span class="line">builder.add_edge(START, &quot;assistant&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;assistant&quot;,</span><br><span class="line">    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools</span><br><span class="line">    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, &quot;assistant&quot;)</span><br><span class="line">react_graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># Show</span><br><span class="line">display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719145948088.png" alt="image-20250719145948088"></p>
<h5 id="调用-1"><a href="#调用-1" class="headerlink" title="调用"></a>调用</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">messages = [HumanMessage(content=&quot;将3和4相加。将结果乘以2。再将结果除以5。&quot;)]</span><br><span class="line">messages = react_graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line"></span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=False的输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_6c69898dba0342bfbb889e)</span><br><span class="line"> Call ID: call_6c69898dba0342bfbb889e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_9940e7603ecf4a13a5f2fb)</span><br><span class="line"> Call ID: call_9940e7603ecf4a13a5f2fb</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  divide (call_d48fbbe205a14dfbaa3500)</span><br><span class="line"> Call ID: call_d48fbbe205a14dfbaa3500</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是2.8。</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=True的输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_e0c7d8e65f2c49e8aecd3e)</span><br><span class="line"> Call ID: call_e0c7d8e65f2c49e8aecd3e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">  multiply (call_5bf824058e64489aaace91)</span><br><span class="line"> Call ID: call_5bf824058e64489aaace91</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">  divide (call_36c34f69f6574028b28847)</span><br><span class="line"> Call ID: call_36c34f69f6574028b28847</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是 **2.8**。</span><br></pre></td></tr></table></figure>
<h4 id="Agent-memory代理记忆"><a href="#Agent-memory代理记忆" class="headerlink" title="Agent memory代理记忆"></a>Agent memory代理记忆</h4><p>使用chekpointer检查点的功能，最简单的检查点之一是 <code>MemorySaver</code>，这是一个用于图形状态的内存键值存储。</p>
<p>这个检查点就相当于把<strong>图的每一次“状态快照”持久化到外部存储</strong>的机制。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">react_graph_memory = builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p>我们可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/persistence/">记忆功能</a> 来解决这个问题！LangGraph 可以使用检查点工具在每一步之后自动保存图的状态。这一内置的持久化层为我们提供了内存功能，使 LangGraph 能够从最后一次状态更新处继续。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Specify a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Specify an input</span><br><span class="line">messages = [HumanMessage(content=&quot;Add 3 and 4.&quot;)]</span><br><span class="line"></span><br><span class="line"># Run</span><br><span class="line">messages = react_graph_memory.invoke(&#123;&quot;messages&quot;: messages&#125;,config)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当我们使用内存时，我们需要指定一个 <code>thread_id</code>。这 <code>thread_id</code> 将存储我们的图形状态集合。</p>
<p>如下图，检查点在图的每一步写入状态，这些检查点保存在一个线程中 ，我们可以使用 <code>thread_id</code> 在未来访问该线程</p>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66e0e9f526b41a4ed9e2d28b_agent-memory2.png" alt="state.jpg"></p>
<h3 id="module-2"><a href="#module-2" class="headerlink" title="module-2"></a>module-2</h3><h4 id="state-scheme状态模式"><a href="#state-scheme状态模式" class="headerlink" title="state-scheme状态模式"></a>state-scheme状态模式</h4><p>LangGraph 的 <strong>state-scheme（状态模式）</strong> 就是“一张<strong>蓝图</strong>”，它告诉框架：“在整个图的生命周期里，状态对象应该长什么样、每个字段怎样被更新、以及节点之间如何共享或隔离数据。”</p>
<p>state-scheme 用 <strong>TypedDict</strong> 或 <strong>Pydantic BaseModel</strong> 来声明，定义了：</p>
<ul>
<li>状态里有哪些字段（key）</li>
<li>每个字段的 Python 类型</li>
<li><strong>可选</strong> 该字段的 <strong>reducer</strong>（更新规则）</li>
</ul>
<h5 id="TypedDict"><a href="#TypedDict" class="headerlink" title="TypedDict"></a><strong>TypedDict</strong></h5><p><strong>基本定义</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    foo: str</span><br><span class="line">    bar: str</span><br></pre></td></tr></table></figure>
<p><strong>可增加像 <code>Literal</code> 这样的类型提示，使其更有价值</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from typing import Literal</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p>在这里，<code>mood</code> 只能是 “happy” 或 “sad”。</p>
<p><strong>加 reducer：让更新“可追加”而不覆盖</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class MathState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line">    scratchpad: Annotated[list[str], add_message]  # 新元素自动追加</span><br><span class="line">    answer: int</span><br></pre></td></tr></table></figure>
<p><code>Annotated[list[str], add]</code> 告诉 LangGraph：当节点返回 <code>&#123;&quot;scratchpad&quot;: [&quot;新步骤&quot;]&#125;</code> 时，<strong>追加</strong>到现有列表，而不是替换</p>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">#定义节点</span><br><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state[&#x27;name&#x27;] + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state):</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;happy&quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_3(state):</span><br><span class="line">    print(&quot;---Node 3---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;sad&quot;&#125;</span><br><span class="line">#路由函数</span><br><span class="line">def decide_mood(state) -&gt; Literal[&quot;node_2&quot;, &quot;node_3&quot;]:</span><br><span class="line">        </span><br><span class="line">    # Here, let&#x27;s just do a 50 / 50 split between nodes 2, 3</span><br><span class="line">    if random.random() &lt; 0.5:</span><br><span class="line"></span><br><span class="line">        # 50% of the time, we return Node 2</span><br><span class="line">        return &quot;node_2&quot;</span><br><span class="line">    </span><br><span class="line">    # 50% of the time, we return Node 3</span><br><span class="line">    return &quot;node_3&quot;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(TypedDictState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719154439415.png" alt="image-20250719154439415"></p>
<p>因为我们的状态是一个字典，我们只需用一个字典调用图，以设置状态中 <code>name</code> 键的初始值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;name&quot;:&quot;Lance&quot;&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="Dataclass数据类"><a href="#Dataclass数据类" class="headerlink" title="Dataclass数据类"></a><strong>Dataclass数据类</strong></h5><p>python的dataclasses库提供了一种简洁的语法，用于创建主要用于存储数据的类。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line"></span><br><span class="line">@dataclass</span><br><span class="line">class DataclassState:</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state.name + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(DataclassState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>要访问 <code>dataclass</code> 的键，我们只需修改在 <code>node_1</code> 中使用的下标即可：</p>
<p>我们使用 <code>state.name</code> 来表示 <code>dataclass</code> 状态，而不是使用 <code>state[&quot;name&quot;]</code> 来表示上面的 <code>TypedDict</code>。</p>
<p>你会注意到一个有点奇怪的地方：在每个节点中，我们仍然返回一个字典来执行状态更新。</p>
<p><strong>Dataclass 只是“描述”状态的形状，而真正在 LangGraph 的节点之间流动的依旧是「字典」</strong>，这是框架设计层面的约定</p>
<p>在这种情况下，<code>dataclass</code> 拥有键 <code>name</code>，因此我们可以通过从节点传递一个字典来更新它，就像在状态为 <code>TypedDict</code> 时所做的那样。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(DataclassState(name=&quot;Lance&quot;,mood=&quot;sad&quot;))</span><br></pre></td></tr></table></figure>
<p>我们通过 <code>dataclass</code> 来设置状态中每个键/通道的初始值！</p>
<h4 id="State-Reducers状态更新函数"><a href="#State-Reducers状态更新函数" class="headerlink" title="State Reducers状态更新函数"></a><strong>State Reducers</strong>状态更新函数</h4><p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers">Reducers</a> 为我们指定了如何执行更新。它接收 <strong>旧状态</strong> 与 <strong>一次变更指令（action / 增量字段）</strong>，<strong>返回全新的状态对象</strong>，整个过程中<strong>不能修改原有数据</strong>。</p>
<p>我们可以使用 <code>Annotated</code> 类型来指定一个 reducer 函数。在这种情况下，让我们将每个节点返回的值附加到结果中，而不是覆盖它们。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing import Annotated</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br></pre></td></tr></table></figure>
<p>我们只需要一个可以执行此操作的缩减器：<code>operator.add</code> 是 Python 内置 operator 模块中的一个函数。当 <code>operator.add</code> 应用于列表时，它执行列表连接。</p>
<h5 id="Custom-Reducers-自定义-Reducers"><a href="#Custom-Reducers-自定义-Reducers" class="headerlink" title="Custom Reducers 自定义 Reducers"></a><strong>Custom Reducers 自定义 Reducers</strong></h5><p>我们同样可以自定义reducers函数，解决一些特殊情况，比如，如下可以解决传入参数为none的情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def reduce_list(left: list | None, right: list | None) -&gt; list:</span><br><span class="line">    &quot;&quot;&quot;安全地合并两个列表，处理其中一个或两个输入可能为 None 的情况。</span><br><span class="line"></span><br><span class="line">    参数：</span><br><span class="line">        left (list | None): 要合并的第一个列表，或 None。</span><br><span class="line">        right (list | None): 要合并的第二个列表，或 None。</span><br><span class="line"></span><br><span class="line">    返回：</span><br><span class="line">        list: 一个包含两个输入列表所有元素的新列表。</span><br><span class="line">               如果输入为 None，则将其视为空列表。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if not left:</span><br><span class="line">        left = []</span><br><span class="line">    if not right:</span><br><span class="line">        right = []</span><br><span class="line">    return left + right</span><br><span class="line"></span><br><span class="line">class DefaultState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br><span class="line"></span><br><span class="line">class CustomReducerState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], reduce_list]</span><br></pre></td></tr></table></figure>
<h5 id="MessagesState"><a href="#MessagesState" class="headerlink" title="MessagesState"></a>MessagesState</h5><p>我可以使用内置的 reducer <code>add_messages</code> 来处理状态中的消息</p>
<p>而<em><code>MessagesState</code></em> <em>内置了一个</em> <em><code>messages</code></em> 键 它还为该键内置了一个 <code>add_messages</code> 合并器，这两个是等价的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from typing import Annotated</span><br><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import AnyMessage</span><br><span class="line">from langgraph.graph.message import add_messages</span><br><span class="line"></span><br><span class="line"># 定义一个自定义的 TypedDict，其中包含一个带有 add_messages reducer 的消息列表。</span><br><span class="line">class CustomMessagesState(TypedDict):</span><br><span class="line">    messages: Annotated[list[AnyMessage], add_messages]</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br><span class="line"></span><br><span class="line"># 使用 MessagesState ，它包含带有 add_messages reducer 的 messages 键。</span><br><span class="line">class ExtendedMessagesState(MessagesState):</span><br><span class="line">    # 添加除 messages 之外所需的任何键， messages 是预构建的。</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br></pre></td></tr></table></figure>
<p>在使用 <code>add_messages</code> reducer 时，让我们展示一些有用的技巧。</p>
<p><strong>重写（Re-writing）</strong></p>
<p>如果我们传递的消息与 <code>messages</code> 列表中已有的消息具有相同的 ID，则该消息将被覆盖！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Initial state</span><br><span class="line">initial_messages = [AIMessage(content=&quot;Hello! How can I assist you?&quot;, name=&quot;Model&quot;, id=&quot;1&quot;),</span><br><span class="line">                    HumanMessage(content=&quot;I&#x27;m looking for information on marine biology.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line">                   ]</span><br><span class="line"></span><br><span class="line"># New message to add</span><br><span class="line">new_message = HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line"></span><br><span class="line"># Test</span><br><span class="line">add_messages(initial_messages , new_message)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[AIMessage(content=&#x27;Hello! How can I assist you?&#x27;, name=&#x27;Model&#x27;, id=&#x27;1&#x27;),</span><br><span class="line"> HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&#x27;Lance&#x27;, id=&#x27;2&#x27;)]</span><br></pre></td></tr></table></figure>
<p><strong>删除（Removal）</strong></p>
<p><code>add_messages</code> 也 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/">同样支持删除</a>。为此，我们简单地使用 <a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/messages/langchain_core.messages.modifier.RemoveMessage.html">RemoveMessage</a> 来自 <code>langchain_core</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Message list</span><br><span class="line">messages = [AIMessage(&quot;Hi.&quot;, name=&quot;Bot&quot;, id=&quot;1&quot;)]</span><br><span class="line">messages.append(HumanMessage(&quot;Hi.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;))</span><br><span class="line">messages.append(AIMessage(&quot;So you said you were researching ocean mammals?&quot;, name=&quot;Bot&quot;, id=&quot;3&quot;))</span><br><span class="line">messages.append(HumanMessage(&quot;Yes, I know about whales. But what others should I learn about?&quot;, name=&quot;Lance&quot;, id=&quot;4&quot;))</span><br><span class="line"></span><br><span class="line"># Isolate messages to delete</span><br><span class="line">delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]</span><br><span class="line">print(delete_messages)</span><br></pre></td></tr></table></figure>
<h4 id="Multiple-Schemas-多种状态"><a href="#Multiple-Schemas-多种状态" class="headerlink" title="Multiple Schemas 多种状态"></a><strong>Multiple Schemas</strong> 多种状态</h4><h5 id="Private-State-私有状态"><a href="#Private-State-私有状态" class="headerlink" title="Private State 私有状态"></a><strong>Private State</strong> 私有状态</h5><p>首先，让我们讨论在节点之间传递 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/pass_private_state/">private state</a> 的情况。这对于图的中间计算逻辑中需要的任何内容都很有用，但与图的整体输入或输出无关。</p>
<p>示例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    foo: int</span><br><span class="line"></span><br><span class="line">class PrivateState(TypedDict):</span><br><span class="line">    baz: int</span><br><span class="line"></span><br><span class="line">def node_1(state: OverallState) -&gt; PrivateState:</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;baz&quot;: state[&#x27;foo&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state: PrivateState) -&gt; OverallState:</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;foo&quot;: state[&#x27;baz&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(OverallState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_edge(&quot;node_1&quot;, &quot;node_2&quot;)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719171509917.png" alt="image-20250719171509917"></p>
<p>我们将定义一个 <code>OverallState</code> 和一个 <code>PrivateState</code>。<code>node_2</code> 使用 <code>PrivateState</code> 作为输入，但输出写入到 <code>OverallState</code>。</p>
<p><code>baz</code> 仅包含在 <code>PrivateState</code> 中。因此，我们可以看到 <code>baz</code> 被排除在图形输出之外，因为它不在 <code>OverallState</code> 中。</p>
<h5 id="Input-Output-Schema-输入-输出模式"><a href="#Input-Output-Schema-输入-输出模式" class="headerlink" title="Input / Output Schema 输入/输出模式"></a><strong>Input / Output Schema </strong>输入/输出模式</h5><p>在 LangGraph 中，<strong>Input / Output Schema</strong> 就是“<strong>图的对外接口协议</strong>”：<strong>调用者只能按 Input Schema 传参；图运行完后，只吐出 Output Schema 规定的字段。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"># 定义输入的模式</span><br><span class="line">class InputState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line"></span><br><span class="line"># 定义输出的模式</span><br><span class="line">class OutputState(TypedDict):</span><br><span class="line">    answer: str</span><br><span class="line"></span><br><span class="line"># 定义整体模式，结合输入和输出</span><br><span class="line">class OverallState(InputState, OutputState):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"># 定义处理输入并生成答案的节点</span><br><span class="line">def answer_node(state: InputState):</span><br><span class="line">    # 示例答案和额外键</span><br><span class="line">    return &#123;&quot;answer&quot;: &quot;bye&quot;, &quot;question&quot;: state[&quot;question&quot;]&#125;</span><br><span class="line"></span><br><span class="line"># 构建图，并指定输入和输出模式</span><br><span class="line">builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)</span><br><span class="line">builder.add_node(answer_node)  # 添加答案节点</span><br><span class="line">builder.add_edge(START, &quot;answer_node&quot;)  # 定义起始边</span><br><span class="line">builder.add_edge(&quot;answer_node&quot;, END)  # 定义结束边</span><br><span class="line">graph = builder.compile()  # 编译图</span><br><span class="line"></span><br><span class="line"># 使用输入调用图并打印结果</span><br><span class="line">print(graph.invoke(&#123;&quot;question&quot;: &quot;hi&quot;&#125;))</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;answer&#x27;: &#x27;bye Lance&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，<code>input</code> / <code>output</code> 模式对图的输入和输出上允许的键进行 <strong>过滤</strong>。可以看到 <code>output</code> 模式将输出限制为仅包含 <code>answer</code> 键。</p>
<h4 id="Filtering-and-trimming-messages筛选和精简消息"><a href="#Filtering-and-trimming-messages筛选和精简消息" class="headerlink" title="Filtering and trimming messages筛选和精简消息"></a><strong>Filtering and trimming messages</strong>筛选和精简消息</h4><p>如果我们在处理长时间对话时不够小心，会导致高令牌使用量和延迟，因为我们传递给模型的是一系列不断增加的消息。所以要进行筛选和精简消息。</p>
<h5 id="简化器（Reducer）"><a href="#简化器（Reducer）" class="headerlink" title="简化器（Reducer）"></a><strong>简化器（Reducer）</strong></h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Nodes</span><br><span class="line">def filter_messages(state: MessagesState):</span><br><span class="line">    # 删除除最近两条消息外的所有消息</span><br><span class="line">    delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]]</span><br><span class="line">    return &#123;&quot;messages&quot;: delete_messages&#125;</span><br><span class="line"></span><br><span class="line">def chat_model_node(state: MessagesState):    </span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;filter&quot;, filter_messages)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;filter&quot;)</span><br><span class="line">builder.add_edge(&quot;filter&quot;, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719203204234.png" alt="image-20250719203204234"></p>
<h5 id="筛选消息（Filtering-messages）"><a href="#筛选消息（Filtering-messages）" class="headerlink" title="筛选消息（Filtering messages）"></a><strong>筛选消息（Filtering messages）</strong></h5><p>如果你不需要或不希望修改图状态，可以直接过滤传递给聊天模型的消息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;][-1:])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>例如，只需传递一个过滤后的列表：<code>llm.invoke(messages[-1:])</code> 给模型。</p>
<p>状态包含了所有消息。但这里模型调用仅使用最后一条消息</p>
<h5 id="裁剪消息（Trim-messages）"><a href="#裁剪消息（Trim-messages）" class="headerlink" title="裁剪消息（Trim messages）"></a><strong>裁剪消息（Trim messages）</strong></h5><p>另一种方法是根据设定一定数量的tokens进行 <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/trim_messages/#getting-the-last-max_tokens-tokens">trim messages</a>。在把对话历史发给大模型之前，按 <strong>token 预算</strong> 把超长消息列表“剪”到合适长度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import trim_messages</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    # 使用 trim_messages 函数修剪消息列表</span><br><span class="line">    # max_tokens: 限制消息的最大令牌数</span><br><span class="line">    # strategy: 修剪策略，这里是“last”，表示保留最新的消息</span><br><span class="line">    # token_counter: 用于计算令牌数的模型实例</span><br><span class="line">    # allow_partial: 是否允许部分修剪</span><br><span class="line">    messages = trim_messages(</span><br><span class="line">            state[&quot;messages&quot;],</span><br><span class="line">            max_tokens=100,</span><br><span class="line">            strategy=&quot;last&quot;,</span><br><span class="line">            token_counter= ChatOpenAI(</span><br><span class="line">                model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">                api_key=&quot;sk-&quot;,</span><br><span class="line">                base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;),</span><br><span class="line">            allow_partial=False,</span><br><span class="line">        )</span><br><span class="line">    # 调用语言模型（llm）处理修剪后的消息，并返回结果</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(messages)]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-message-summarization带有消息总结功能的聊天机器人"><a href="#Chatbot-with-message-summarization带有消息总结功能的聊天机器人" class="headerlink" title="Chatbot with message summarization带有消息总结功能的聊天机器人"></a><strong>Chatbot with message summarization</strong>带有消息总结功能的聊天机器人</h4><p>与其仅仅修剪或过滤消息，我们将展示如何使用大型语言模型（LLMs）来生成对话的实时摘要。</p>
<p>这使我们能够保留整个对话的压缩表示，而不仅仅是通过修剪或过滤将其移除。</p>
<p>我们将为该聊天机器人配备记忆功能，支持长时间对话，同时不会产生高昂的 token 成本或延迟。</p>
<h5 id="定义总结状态"><a href="#定义总结状态" class="headerlink" title="定义总结状态"></a>定义总结状态</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">class State(MessagesState):</span><br><span class="line">    summary: str</span><br></pre></td></tr></table></figure>
<p>除了内置的 <code>messages</code> 键之外，我们现在还将包含一个自定义键（<code>summary</code>）。</p>
<h5 id="定义LLM节点"><a href="#定义LLM节点" class="headerlink" title="定义LLM节点"></a>定义LLM节点</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage </span><br><span class="line"> </span><br><span class="line"> # 定义调用模型的逻辑</span><br><span class="line">def call_model(state: State): </span><br><span class="line">     </span><br><span class="line">     # 获取摘要（如果存在） </span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 如果有摘要，则添加它</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 将摘要添加到系统消息中</span><br><span class="line">         system_message = f&quot;先前对话的摘要：&#123;summary&#125;&quot; </span><br><span class="line"> </span><br><span class="line">         # 将摘要附加到任何较新的消息中</span><br><span class="line">         messages = [SystemMessage(content=system_message)] + state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     else: </span><br><span class="line">         messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     return &#123;&quot;messages&quot;: response&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>调用我们的LLM</strong>，如果存在摘要，则将其纳入提示中。</p>
<blockquote>
<p>当 call_model 函数返回 {“messages”: response} 时，它是在告诉 langgraph ：“请用 response （即模型的新输出）来更新 State 对象中 messages 键对应的值。” langgraph 会将这个新消息追加到 messages 列表中，从而保持了对话历史的连续性</p>
</blockquote>
<h5 id="定义摘要节点"><a href="#定义摘要节点" class="headerlink" title="定义摘要节点"></a>定义摘要节点</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def summarize_conversation(state: State): </span><br><span class="line">     </span><br><span class="line">     # 首先，我们获取任何现有的摘要</span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 创建我们的摘要提示</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 摘要已存在</span><br><span class="line">         summary_message = ( </span><br><span class="line">             f&quot;这是迄今为止对话的摘要：&#123;summary&#125;\n\n&quot; </span><br><span class="line">             &quot;请结合以上新消息扩展摘要：&quot; </span><br><span class="line">         ) </span><br><span class="line">         </span><br><span class="line">     else: </span><br><span class="line">         summary_message = &quot;创建以上对话的摘要：&quot; </span><br><span class="line"> </span><br><span class="line">     # 将提示添加到我们的历史记录中</span><br><span class="line">     messages = state[&quot;messages&quot;] + [HumanMessage(content=summary_message)] </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     </span><br><span class="line">     # 删除除最近2条消息外的所有消息</span><br><span class="line">     delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]] </span><br><span class="line">     return &#123;&quot;summary&quot;: response.content, &quot;messages&quot;: delete_messages&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>生成摘要</strong>。请注意，这里我们将使用 <code>RemoveMessage</code> 在生成摘要后过滤我们的状态。</p>
<h5 id="定义路由函数"><a href="#定义路由函数" class="headerlink" title="定义路由函数"></a>定义路由函数</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import END </span><br><span class="line"> # 决定是结束对话还是总结对话</span><br><span class="line">def should_continue(state: State): </span><br><span class="line">     </span><br><span class="line">     &quot;&quot;&quot;返回要执行的下一个节点。&quot;&quot;&quot; </span><br><span class="line">     </span><br><span class="line">     messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     # 如果消息超过六条，那么我们总结对话</span><br><span class="line">     if len(messages) &gt; 6: </span><br><span class="line">         return &quot;summarize_conversation&quot; </span><br><span class="line">     </span><br><span class="line">     # 否则我们就可以结束了</span><br><span class="line">     return END </span><br></pre></td></tr></table></figure>
<p>我们将添加一个条件边，以根据对话长度确定是否生成摘要。</p>
<blockquote>
<p>在 langgraph 中， Command 是一个特殊的类型，用于指导图形（graph）决定接下来应该执行哪个节点。 您可以把它看作是给图形下达的一个“命令”。</p>
</blockquote>
<h5 id="添加内存并编译图"><a href="#添加内存并编译图" class="headerlink" title="添加内存并编译图"></a>添加内存并编译图</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, START</span><br><span class="line"></span><br><span class="line"># Define a new graph</span><br><span class="line">workflow = StateGraph(State)</span><br><span class="line">workflow.add_node(&quot;conversation&quot;, call_model)</span><br><span class="line">workflow.add_node(&quot;summarize_conversation&quot;,summarize_conversation)</span><br><span class="line"></span><br><span class="line"># Set the entrypoint as conversation</span><br><span class="line">workflow.add_edge(START, &quot;conversation&quot;)</span><br><span class="line">workflow.add_conditional_edges(&quot;conversation&quot;, should_continue)</span><br><span class="line">workflow.add_edge(&quot;summarize_conversation&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Compile</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph = workflow.compile(checkpointer=memory)</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h5 id="使用线程调用"><a href="#使用线程调用" class="headerlink" title="使用线程调用"></a>使用线程调用</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">input_message = HumanMessage(content=&quot;我喜欢玩lol，你知道这个游戏吗&quot;)</span><br><span class="line">output = graph.invoke(&#123;&quot;messages&quot;: [input_message]&#125;, config) </span><br><span class="line">for m in output[&#x27;messages&#x27;][-1:]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当对话大于6，可生成概要</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.get_state(config).values.get(&quot;summary&quot;,&quot;&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-message-summarization-amp-external-DB-memory具有消息总结和外部数据库记忆的聊天机器人"><a href="#Chatbot-with-message-summarization-amp-external-DB-memory具有消息总结和外部数据库记忆的聊天机器人" class="headerlink" title="Chatbot with message summarization &amp; external DB memory具有消息总结和外部数据库记忆的聊天机器人"></a><strong>Chatbot with message summarization &amp; external DB memory</strong>具有消息总结和外部数据库记忆的聊天机器人</h4><h5 id="使用数据库"><a href="#使用数据库" class="headerlink" title="使用数据库"></a>使用数据库</h5><p><code>SqliteSaver</code> 是 LangGraph 提供的一个 <strong>轻量级状态持久化工具</strong>，它将图的运行状态（即 checkpoint）保存到本地的 SQLite 数据库中，使得你可以在程序中断或重启后<strong>恢复执行上下文</strong>，特别适合本地开发、实验性项目或中小规模应用。</p>
<p>如果我们提供 “:memory:” ，它将创建一个内存中的 SQLite 数据库。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import sqlite3</span><br><span class="line"># In memory</span><br><span class="line">conn = sqlite3.connect(&quot;:memory:&quot;, check_same_thread = False)</span><br></pre></td></tr></table></figure>
<p>如果我们提供一个 db 路径，那么它将为我们创建一个数据库！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#在本地创建一个目录 state_db，并尝试从 GitHub 下载一个名为 example.db 的 SQLite 数据库文件</span><br><span class="line">!mkdir -p state_db &amp;&amp; [ ! -f state_db/example.db ] &amp;&amp; wget -P state_db https://github.com/langchain-ai/langchain-academy/raw/main/module-2/state_db/example.db</span><br><span class="line"></span><br><span class="line">db_path = &quot;state_db/example.db&quot;</span><br><span class="line">conn = sqlite3.connect(db_path, check_same_thread=False)</span><br></pre></td></tr></table></figure>
<p>定义checkpoint</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.checkpoint.sqlite import SqliteSaver</span><br><span class="line">memory = SqliteSaver(conn)</span><br></pre></td></tr></table></figure>
<p>像上一个形式编译图</p>
<p>让我们确认一下我们的状态是否已保存到本地。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">graph_state = graph.get_state(config)</span><br><span class="line">graph_state</span><br></pre></td></tr></table></figure>
<p>使用像 Sqlite 这样的数据库意味着状态会被持久化！</p>
<h3 id="module-3"><a href="#module-3" class="headerlink" title="module-3"></a>module-3</h3><h4 id="Streaming-流式传输"><a href="#Streaming-流式传输" class="headerlink" title="Streaming 流式传输"></a><strong>Streaming</strong> 流式传输</h4><p>现在，让我们来谈谈 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming">流式传输我们的图状态</a> 的方法。<code>.stream</code> 和 <code>.astream</code> 是用于流式返回结果的同步和异步方法。</p>
<p><code>values</code>：这将在每个节点被调用后流式传输图的完整状态。 <code>updates</code>：这将在每个节点被调用后流式传输图的状态更新。</p>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbaf892d24625a201744e5_streaming1.png" alt="values_vs_updates.png"></p>
<h5 id="stream-mode-”updates”"><a href="#stream-mode-”updates”" class="headerlink" title="stream_mode=”updates”"></a>stream_mode=”updates”</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Create a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    print(chunk)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;conversation&#x27;: &#123;&#x27;messages&#x27;: AIMessage(content=&#x27;你好，zxj！很高兴认识你～有什么我可以帮你的吗？😊&#x27;, additional_kwargs=&#123;&#x27;refusal&#x27;: None&#125;, response_metadata=&#123;&#x27;token_usage&#x27;: &#123;&#x27;completion_tokens&#x27;: 16, &#x27;prompt_tokens&#x27;: 576, &#x27;total_tokens&#x27;: 592, &#x27;completion_tokens_details&#x27;: None, &#x27;prompt_tokens_details&#x27;: None&#125;, &#x27;model_name&#x27;: &#x27;qwen-plus-2025-04-28&#x27;, &#x27;system_fingerprint&#x27;: None, &#x27;id&#x27;: &#x27;chatcmpl-891471ae-2fe8-9b3d-b5f7-f4fcd55a4e16&#x27;, &#x27;service_tier&#x27;: None, &#x27;finish_reason&#x27;: &#x27;stop&#x27;, &#x27;logprobs&#x27;: None&#125;, id=&#x27;run--f36409f3-af43-4e9b-8a46-39646ad7c106-0&#x27;, usage_metadata=&#123;&#x27;input_tokens&#x27;: 576, &#x27;output_tokens&#x27;: 16, &#x27;total_tokens&#x27;: 592, &#x27;input_token_details&#x27;: &#123;&#125;, &#x27;output_token_details&#x27;: &#123;&#125;&#125;)&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>让我们来看一下 <code>stream_mode=&quot;updates&quot;</code>。</p>
<p>因为我们使用 <code>updates</code> 进行流式传输，所以只有在图中的节点运行后，我们才能看到状态的更新。每个 <code>chunk</code> 是一个字典，以 <code>node_name</code> 为键，更新后的状态为值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    chunk[&#x27;conversation&#x27;][&quot;messages&quot;].pretty_print()</span><br></pre></td></tr></table></figure>
<p>现在我们直接打印状态更新。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好呀，zxj！再次见到你真高兴～😊 有什么我可以帮忙的吗？</span><br></pre></td></tr></table></figure>
<h5 id="stream-mode-”values”"><a href="#stream-mode-”values”" class="headerlink" title="stream_mode=”values”"></a>stream_mode=”values”</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Start conversation, again</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">input_message = HumanMessage(content=&quot;你好我是zxj&quot;)</span><br><span class="line">for event in graph.stream(&#123;&quot;messages&quot;: [input_message]&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    for m in event[&#x27;messages&#x27;]:</span><br><span class="line">        m.pretty_print()</span><br><span class="line">    print(&quot;---&quot;*25)</span><br></pre></td></tr></table></figure>
<p>现在，我们可以看到 <code>stream_mode=&quot;values&quot;</code>.这是在 <code>conversation</code> 节点被调用后，图的整个状态。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，zxj！有什么我可以帮你的吗？😊</span><br><span class="line">---------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h5 id="Streaming-tokens-流式传输令牌"><a href="#Streaming-tokens-流式传输令牌" class="headerlink" title="Streaming tokens 流式传输令牌"></a><strong>Streaming tokens</strong> <strong>流式传输令牌</strong></h5><p>在 LangGraph 中，“流式传输令牌（Streaming tokens）”指的是<strong>在节点内部的大模型（LLM）生成过程中，逐 token 地将中间结果实时推送到客户端</strong>的能力。实现这一能力的核心方法是 <code>astream_events</code>，它会以事件流的形式暴露整个执行过程中的所有细节，包括每一次 LLM 调用产生的 token。</p>
<p>每个事件是一个包含几个键的字典：</p>
<p><code>event</code>：这是正在发出的事件的类型。</p>
<p> <code>name</code>：这是事件的名称。</p>
<p><code>data</code>：这是与事件相关联的数据。</p>
<p> <code>metadata</code>：包含 <code>langgraph_node</code>，即发出事件的节点。</p>
<p>要点是，图表中聊天模型的令牌具有 <code>on_chat_model_stream</code> 类型。我们可以使用 <code>event[&#39;metadata&#39;][&#39;langgraph_node&#39;]</code> 来选择要流式的节点。并且我们可以使用 <code>event[&#39;data&#39;]</code> 来获取每个事件的实际数据，而在这种情况下，数据是一个 <code>AIMessageChunk</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">node_to_stream = &#x27;conversation&#x27;#定义流式传输的节点</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;5&quot;&#125;&#125;</span><br><span class="line">input_message = HumanMessage(content=&quot;为我介绍lol&quot;)</span><br><span class="line">async for event in graph.astream_events(&#123;&quot;messages&quot;: [input_message]&#125;, config, version=&quot;v2&quot;):</span><br><span class="line">    # 从特定节点获取聊天模型生成的 Token</span><br><span class="line">    #事件类型必须是 逐 token 流式输出（on_chat_model_stream）。</span><br><span class="line">    if event[&quot;event&quot;] == &quot;on_chat_model_stream&quot; and event[&#x27;metadata&#x27;].get(&#x27;langgraph_node&#x27;,&#x27;&#x27;) == node_to_stream:</span><br><span class="line">        data = event[&quot;data&quot;]</span><br><span class="line">        print(data[&quot;chunk&quot;].content, end=&quot;|&quot;)</span><br></pre></td></tr></table></figure>
<p>event的常见类型</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事件类型 (<code>event</code>)</th>
<th>触发时机与说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>on_chain_start</code></td>
<td>任意 Runnable（节点、子图或整个图）开始执行</td>
</tr>
<tr>
<td><code>on_chain_stream</code></td>
<td>节点/图在运行过程中 <strong>增量输出</strong> chunk</td>
</tr>
<tr>
<td><code>on_chain_end</code></td>
<td>任意 Runnable 执行完成</td>
</tr>
<tr>
<td><code>on_chat_model_start</code></td>
<td><strong>ChatModel</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_chat_model_stream</code></td>
<td><strong>ChatModel</strong> 逐 token 返回内容（打字机效果）</td>
</tr>
<tr>
<td><code>on_chat_model_end</code></td>
<td><strong>ChatModel</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_tool_start</code></td>
<td><strong>Tool</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_tool_end</code></td>
<td><strong>Tool</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_retriever_start</code></td>
<td><strong>Retriever</strong> 开始检索</td>
</tr>
<tr>
<td><code>on_retriever_end</code></td>
<td><strong>Retriever</strong> 检索结束</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Breakpoints-断点"><a href="#Breakpoints-断点" class="headerlink" title="Breakpoints 断点"></a><strong>Breakpoints 断点</strong></h4><p><code>human-in-the-loop</code>（人工介入/人在回路）的三大动机：</p>
<p>1️⃣ Approval（审批）我们可以中断智能体，将当前状态呈现给用户，并让用户决定是否执行该操作。</p>
<p>2️⃣ Debugging（调试/回放）我们可以回退图形以重现或避免问题</p>
<p>3️⃣ Editing（编辑）AI 产出的中间结果不符合预期，但不想重跑整图，可以直接修改状态</p>
<p>我们将介绍 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/#simple-usage">breakpoints</a>，它提供了一种在特定步骤停止图的简单方法。</p>
<h5 id="Breakpoints-for-human-approval用于人类审批的断点"><a href="#Breakpoints-for-human-approval用于人类审批的断点" class="headerlink" title="Breakpoints for human approval用于人类审批的断点"></a><strong>Breakpoints for human approval</strong>用于人类审批的断点</h5><p>假设我们关注工具的使用：我们希望批准代理使用其任何工具。</p>
<p>我们所需要做的就是简单地用 <code>interrupt_before=[&quot;tools&quot;]</code> 编译图形，其中 <code>tools</code> 是我们的工具节点。</p>
<p>这意味着在执行工具调用的节点 <code>tools</code> 之前，执行将被中断。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;tools&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720225640772.png" alt="image-20250720225640772"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: HumanMessage(content=&quot;2乘3&quot;)&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br></pre></td></tr></table></figure>
<p>我们可以获取状态并查看要调用的下一个节点。这是一种很好的方法，可以发现图已被中断。</p>
<p>现在，我们将介绍一个很好的技巧。当我们使用 <code>None</code> 调用图时，它将直接从最后一个状态检查点继续！</p>
<p><img src="https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png" alt="breakpoints.jpg"></p>
<p>状态快照（StateSnapshot）</p>
<ul>
<li>类型：专门用来存 <strong>一个时刻</strong> 的完整状态</li>
<li>获取方式：<ul>
<li><code>Graph.get_state()</code> → <strong>最新的</strong> 快照</li>
<li><code>Graph.get_state_history()</code> → <strong>所有</strong> 快照列表</li>
</ul>
</li>
</ul>
<p>继续/重跑图</p>
<ul>
<li><code>Graph.stream(None, &#123;&quot;thread_id&quot;: &quot;xxx&quot;&#125;)</code><ul>
<li>不传新输入 <code>None</code> 表示 <strong>从当前最新状态继续跑</strong></li>
<li>也可回退到历史快照，再重跑（调试/回放）</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">6</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">2乘3的结果是6。</span><br></pre></td></tr></table></figure>
<h4 id="Editing-graph-state-编辑图状态"><a href="#Editing-graph-state-编辑图状态" class="headerlink" title="Editing graph state 编辑图状态"></a><strong>Editing graph state </strong>编辑图状态</h4><p>断点也是<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/">修改图状态的机会</a>让我们在 <code>assistant</code> 节点之前为代理设置断点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;assistant&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720230924672.png" alt="image-20250720230924672"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: &quot;2乘3&quot;&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br></pre></td></tr></table></figure>
<p>当状态中断时，我们可以直接应用状态更新</p>
<p>记住，对 <code>messages</code> 键的更新将使用 <code>add_messages</code> reducer：</p>
<p><strong>如果我们想覆盖现有的消息，可以提供带有<em> </em><code>id</code><em> </em>的消息。</strong> 如果我们只想将消息添加到消息列表中，则可以传递未指定 <code>id</code> 的消息，如下所示。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&quot;不要，实际上要3乘3!&quot;)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">new_state = graph.get_state(thread).values</span><br><span class="line">for m in new_state[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">不要，实际上要3乘3!</span><br></pre></td></tr></table></figure>
<p>现在，让我们继续进行我们的代理操作，只需传递 <code>None</code> 并允许其从当前状态继续执行。我们输出当前内容，然后继续执行剩余的节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="Dynamic-breakpoints-动态断点"><a href="#Dynamic-breakpoints-动态断点" class="headerlink" title="Dynamic breakpoints 动态断点"></a><strong>Dynamic breakpoints </strong>动态断点</h4><p>你可以根据条件来实现它（从节点内部基于开发人员定义的逻辑）。您可以向用户说明其中断原因（通过将您想传递的内容发送到 <code>NodeInterrupt</code>）。</p>
<p>让我们创建一个图表，其中根据输入的长度会抛出一个 <code>NodeInterrupt</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.errors import NodeInterrupt</span><br><span class="line">from langgraph.graph import START, END, StateGraph</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    input: str</span><br><span class="line"></span><br><span class="line">def step_1(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 1---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_2(state: State) -&gt; State:</span><br><span class="line">    # 如果输入字符串长度超过5个字符，我们可以选择抛出NodeInterrupt异常</span><br><span class="line">    if len(state[&#x27;input&#x27;]) &gt; 5:</span><br><span class="line">        raise NodeInterrupt(f&quot;收到长度超过5个字符的输入: &#123;state[&#x27;input&#x27;]&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    print(&quot;---Step 2---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_3(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 3---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">builder = StateGraph(State)</span><br><span class="line">builder.add_node(&quot;step_1&quot;, step_1)</span><br><span class="line">builder.add_node(&quot;step_2&quot;, step_2)</span><br><span class="line">builder.add_node(&quot;step_3&quot;, step_3)</span><br><span class="line">builder.add_edge(START, &quot;step_1&quot;)</span><br><span class="line">builder.add_edge(&quot;step_1&quot;, &quot;step_2&quot;)</span><br><span class="line">builder.add_edge(&quot;step_2&quot;, &quot;step_3&quot;)</span><br><span class="line">builder.add_edge(&quot;step_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Set up memory</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># Compile the graph with memory</span><br><span class="line">graph = builder.compile(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250721222709712.png" alt="image-20250721222709712"></p>
<p>让我们运行一个输入超过5个字符的图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">initial_input = &#123;&quot;input&quot;: &quot;hello world&quot;&#125;</span><br><span class="line">thread_config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread_config, stream_mode=&quot;values&quot;):</span><br><span class="line">    print(event)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br><span class="line">---Step 1---</span><br><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以尝试从断点恢复图。但是，这只会重新运行相同的节点！除非状态发生变化，否则我们将一直卡在这里。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread_config,</span><br><span class="line">    &#123;&quot;input&quot;: &quot;hi&quot;&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>使用update_state更新状态</p>
<h4 id="Time-travel-时间旅行"><a href="#Time-travel-时间旅行" class="headerlink" title="Time travel 时间旅行"></a><strong>Time travel</strong> 时间旅行</h4><p>现在，让我们通过查看、重播，甚至从过去的状态叉出，来展示 LangGraph <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/">支持debug</a> 的功能。</p>
<h5 id="Browsing-History-浏览历史"><a href="#Browsing-History-浏览历史" class="headerlink" title="Browsing History 浏览历史"></a><strong>Browsing History</strong> <strong>浏览历史</strong></h5><p>我们可以使用 <code>get_state</code> 来查看给定 <code>thread_id</code> 的图的 当前 状态！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.get_state(&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;&#125;&#125;)</span><br></pre></td></tr></table></figure>
<p>我们还可以浏览代理的状态历史。<code>get_state_history</code> 让我们能够获取所有先前步骤的状态。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_states = [s for s in graph.get_state_history(thread)]</span><br><span class="line">len(all_states)</span><br><span class="line">print(all_states)</span><br></pre></td></tr></table></figure>
<h5 id="Replaying-回放"><a href="#Replaying-回放" class="headerlink" title="Replaying 回放"></a><strong>Replaying</strong> <strong>回放</strong></h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">to_replay = all_states[-2]</span><br><span class="line">to_replay.values</span><br><span class="line">&#123;&#x27;messages&#x27;: [HumanMessage(content=&#x27;2乘3&#x27;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#x27;0676d9b5-cd59-4630-924d-b5c8d950e8d8&#x27;)]&#125;</span><br><span class="line">to_replay.next</span><br><span class="line">(&#x27;assistant&#x27;,)</span><br></pre></td></tr></table></figure>
<p>我们还获取了配置，它告诉了我们 <code>checkpoint_id</code> 以及 <code>thread_id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">to_replay.config</span><br><span class="line">&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;,</span><br><span class="line">  &#x27;checkpoint_ns&#x27;: &#x27;&#x27;,</span><br><span class="line">  &#x27;checkpoint_id&#x27;: &#x27;1f066c0e-2ee2-66d5-8000-5dde78194aae&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>要从这里重播，我们只需将配置传回给代理！图知道这个检查点已经执行过了。它只是从这个检查点重新播放！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, to_replay.config, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h5 id="Forking-分叉"><a href="#Forking-分叉" class="headerlink" title="Forking 分叉"></a><strong>Forking</strong> 分叉</h5><p>如果我们想从相同的步骤运行，但使用不同的输入，该怎么办呢？这是分叉。</p>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbb038f89f2d847ee5c336_time-travel3.png" alt="fig3.jpg"></p>
<p>让我们修改此检查点的状态。我们可以直接使用提供的 <code>checkpoint_id</code> 来运行 <code>update_state</code>。</p>
<p>请记住我们对 <code>messages</code> 的 reducer 是如何工作的：</p>
<ul>
<li>它会追加消息，除非我们提供了一个消息 ID。</li>
<li>我们提供消息 ID 是为了覆盖消息，而不是将消息追加到状态中！</li>
</ul>
<p>因此，要覆盖消息，我们只需提供消息 ID，而我们已有 <code>to_fork.values[&quot;messages&quot;].id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fork_config = graph.update_state(</span><br><span class="line">    to_fork.config,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&#x27;5乘3&#x27;, </span><br><span class="line">                               id=to_fork.values[&quot;messages&quot;][0].id)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><h4 id="message"><a href="#message" class="headerlink" title="message"></a>message</h4><p>LangChain 中的 HumanMessage 、 AIMessage 、 SystemMessage 和 ToolMessage 。这些消息类型是构建与语言模型（LLM）交互的核心组件，它们共同构成了一个完整的对话历史，帮助模型理解上下文并做出恰当的回应。</p>
<ol>
<li>SystemMessage</li>
</ol>
<p>SystemMessage 的结构最简单，它只包含内容和类型。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 消息的具体内容，即给 AI 的指令。</li>
<li>type (str): 固定为字符串 ‘system’ 。</li>
</ul>
<ol>
<li>HumanMessage</li>
</ol>
<p>HumanMessage 的结构也同样简单，代表用户的输入。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 用户输入的文本。</li>
<li>type (str): 固定为字符串 ‘human’ 。</li>
</ul>
<ol>
<li>AIMessage</li>
</ol>
<p>AIMessage 的结构相对复杂，因为它不仅可以包含文本响应，还可以包含对工具的调用请求。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): AI 生成的文本响应。如果 AI 的回复是发起工具调用，此字段可以为空字符串。</li>
<li>tool_calls (list[dict], 可选): 一个字典列表，每个字典代表一个工具调用请求。这是支持“Function Calling”或“Tool Calling”功能的核心。其结构通常包含：<ul>
<li>name (str): 要调用的工具名称。</li>
<li>args (dict): 调用工具时需要传入的参数。</li>
<li>id (str): 此次工具调用的唯一标识符，用于后续 ToolMessage 的关联。</li>
</ul>
</li>
<li>type (str): 固定为字符串 ‘ai’ 。</li>
</ul>
<ol>
<li>ToolMessage</li>
</ol>
<p>ToolMessage 用于承载工具执行后的返回结果。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 工具执行返回的结果。通常是一个字符串，比如 JSON 格式的字符串。</li>
<li>tool_call_id (str): 此次工具调用的唯一标识符， 必须 与之前 AIMessage 中 tool_calls 里的 id 相对应。这使得模型能够准确地将结果与请求匹配起来。</li>
<li>type (str): 固定为字符串 ‘tool’ 。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/" class="post-title-link" itemprop="url">Libreoffice</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-18T00:00:00+08:00">2025-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-30 15:26:37" itemprop="dateModified" datetime="2025-07-30T15:26:37+08:00">2025-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">实习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/" itemprop="url" rel="index"><span itemprop="name">晨晟智控</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="libreoffice部署"><a href="#libreoffice部署" class="headerlink" title="libreoffice部署"></a>libreoffice部署</h3><h4 id="查看Linux发行版"><a href="#查看Linux发行版" class="headerlink" title="查看Linux发行版"></a>查看Linux发行版</h4><p><img src="/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/image-20250718095931232.png" alt="image-20250718095931232"></p>
<p>系统是 <strong>银河麒麟高级服务器操作系统 V10（Kylin Linux Advanced Server V10）</strong>，属于 <strong>中国国产、兼容 CentOS/RHEL 生态</strong> 的 Linux 发行版。</p>
<p>因此它使用 <strong>RPM 包管理</strong>（<code>dnf</code>/<code>yum</code>），而不是 <code>.deb</code>。</p>
<h4 id="查看CPU-处理器架构"><a href="#查看CPU-处理器架构" class="headerlink" title="查看CPU 处理器架构"></a>查看<strong>CPU 处理器架构</strong></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -m</span><br></pre></td></tr></table></figure>
<p>是<strong>x86_64</strong></p>
<h4 id="不用部署了，镜像里有，直接用了"><a href="#不用部署了，镜像里有，直接用了" class="headerlink" title="不用部署了，镜像里有，直接用了"></a>不用部署了，镜像里有，直接用了</h4><h4 id="使用libreoffice处理doc文件，转成pdf"><a href="#使用libreoffice处理doc文件，转成pdf" class="headerlink" title="使用libreoffice处理doc文件，转成pdf"></a>使用libreoffice处理doc文件，转成pdf</h4><p>将当前目录下所有 <code>.doc</code> 和 <code>.docx</code> 转为 PDF：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">libreoffice --headless --convert-to pdf *.doc *.docx --outdir ./pdf_output/</span><br><span class="line"></span><br><span class="line"># 检查是否有残留进程</span><br><span class="line">ps aux | grep libreoffice</span><br><span class="line"></span><br><span class="line"># 如果有残留进程，杀死它们</span><br><span class="line">killall soffice.bin 2&gt;/dev/null</span><br></pre></td></tr></table></figure>
<h4 id="python"><a href="#python" class="headerlink" title="python"></a>python</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import subprocess</span><br><span class="line">import argparse</span><br><span class="line">import glob</span><br><span class="line">from pathlib import Path</span><br><span class="line">def batch_convert_documents(input_path, output_dir):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    批量转换文档的函数版本</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        input_path (str): 输入路径（文件、目录或通配符）</span><br><span class="line">        output_dir (str): 输出目录</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">        bool: 转换是否成功</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 确保输出目录存在</span><br><span class="line">    Path(output_dir).mkdir(parents=True, exist_ok=True)</span><br><span class="line">    </span><br><span class="line">    # 收集所有要转换的文件</span><br><span class="line">    files_to_convert = []</span><br><span class="line">    </span><br><span class="line">    if os.path.isfile(input_path):</span><br><span class="line">        # 单个文件</span><br><span class="line">        if input_path.lower().endswith((&#x27;.doc&#x27;, &#x27;.docx&#x27;)):</span><br><span class="line">            files_to_convert.append(input_path)</span><br><span class="line">    elif os.path.isdir(input_path):</span><br><span class="line">        # 目录中的所有doc/docx文件</span><br><span class="line">        for pattern in [&#x27;*.doc&#x27;, &#x27;*.docx&#x27;]:</span><br><span class="line">            files_to_convert.extend(glob.glob(os.path.join(input_path, pattern)))</span><br><span class="line">    else:</span><br><span class="line">        # 通配符模式</span><br><span class="line">        files_to_convert = glob.glob(input_path)</span><br><span class="line">        # 过滤出doc和docx文件</span><br><span class="line">        files_to_convert = [f for f in files_to_convert if f.lower().endswith((&#x27;.doc&#x27;, &#x27;.docx&#x27;))]</span><br><span class="line">    </span><br><span class="line">    if not files_to_convert:</span><br><span class="line">        print(&quot;未找到要转换的文档文件&quot;)</span><br><span class="line">        return False</span><br><span class="line">    </span><br><span class="line">    print(f&quot;找到 &#123;len(files_to_convert)&#125; 个文件需要转换&quot;)</span><br><span class="line">    </span><br><span class="line">    # 构建命令</span><br><span class="line">    cmd = [</span><br><span class="line">        &#x27;libreoffice&#x27;,</span><br><span class="line">        &#x27;--headless&#x27;,</span><br><span class="line">        &#x27;--convert-to&#x27;, &#x27;pdf&#x27;,</span><br><span class="line">        &#x27;--outdir&#x27;, output_dir</span><br><span class="line">    ] + files_to_convert</span><br><span class="line">    </span><br><span class="line">    try:</span><br><span class="line">        print(&quot;正在转换文件...&quot;)</span><br><span class="line">        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)</span><br><span class="line">        </span><br><span class="line">        if result.returncode == 0:</span><br><span class="line">            print(f&quot;成功转换 &#123;len(files_to_convert)&#125; 个文件&quot;)</span><br><span class="line">            return True</span><br><span class="line">        else:</span><br><span class="line">            print(f&quot;转换失败: &#123;result.stderr&#125;&quot;)</span><br><span class="line">            return False</span><br><span class="line">            </span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;转换过程中发生错误: &#123;e&#125;&quot;)</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    success = batch_convert_documents(&quot;./docs&quot;, &quot;./pdf_output&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="Linux扫盲"><a href="#Linux扫盲" class="headerlink" title="Linux扫盲"></a>Linux扫盲</h3><h4 id="发行版"><a href="#发行版" class="headerlink" title="发行版"></a>发行版</h4><p>像Ubuntu，CentOS都属于Linux的发行版，就像Windows11属于Windows的关系</p>
<p>常见发行版分类：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>系列</th>
<th>代表发行版</th>
<th>包格式</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Debian 系</strong></td>
<td>Debian、Ubuntu、Kali、Linux Mint</td>
<td><code>.deb</code></td>
<td>包多、社区大、教程多</td>
</tr>
<tr>
<td><strong>Red Hat 系</strong></td>
<td>CentOS、RHEL、Rocky、Alma、Fedora</td>
<td><code>.rpm</code></td>
<td>企业级稳定、官方支持长</td>
</tr>
<tr>
<td><strong>SUSE 系</strong></td>
<td>openSUSE Leap / Tumbleweed</td>
<td><code>.rpm</code></td>
<td>YaST 管理工具、欧洲流行</td>
</tr>
<tr>
<td><strong>Arch 系</strong></td>
<td>Arch Linux、Manjaro</td>
<td><code>.pkg.tar.zst</code></td>
<td>滚动更新、极客向</td>
</tr>
<tr>
<td><strong>轻量/最小</strong></td>
<td>Alpine、Debian netinst、CentOS Stream Minimal</td>
<td>任意</td>
<td>镜像小、资源占用低</td>
</tr>
</tbody>
</table>
</div>
<p>如何查看Linux发行版</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/os-release</span><br></pre></td></tr></table></figure>
<h4 id="deb和rpm"><a href="#deb和rpm" class="headerlink" title="deb和rpm"></a>deb和rpm</h4><p> <code>.deb</code> 和 <code>.rpm</code> 想象成 <strong>“Linux 世界里的安装程序”</strong>，就像 Windows 的 <code>.exe</code> / <code>.msi</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>格式</th>
<th>适用系统</th>
<th>安装命令</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>.deb</code></strong></td>
<td>Debian、Ubuntu、Linux Mint、Kali 等</td>
<td><code>sudo dpkg -i xxx.deb</code> 或 <code>sudo apt install ./xxx.deb</code></td>
</tr>
<tr>
<td><strong><code>.rpm</code></strong></td>
<td>CentOS、RHEL、Fedora、openSUSE、Rocky、Alma 等</td>
<td><code>sudo rpm -ivh xxx.rpm</code> 或 <code>sudo dnf/yum install xxx.rpm</code></td>
</tr>
</tbody>
</table>
</div>
<h4 id="cpu处理器架构"><a href="#cpu处理器架构" class="headerlink" title="cpu处理器架构"></a>cpu处理器架构</h4><div class="table-container">
<table>
<thead>
<tr>
<th>目录名</th>
<th>代表架构</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>x86_64</strong></td>
<td><strong>Intel/AMD 64 位</strong></td>
<td>绝大多数台式机、服务器（如 Xeon、EPYC、Core、Ryzen）</td>
</tr>
<tr>
<td><strong>aarch64</strong></td>
<td><strong>ARM 64 位</strong></td>
<td>树莓派 4/5、苹果 M 系列（Asahi Linux）、鲲鹏、飞腾、Ampere ARM 服务器等</td>
</tr>
</tbody>
</table>
</div>
<p>查看处理器架构：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -m</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E5%AE%9E%E6%88%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E5%AE%9E%E6%88%98/" class="post-title-link" itemprop="url">实战</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-18T00:00:00+08:00">2025-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-30 09:15:18" itemprop="dateModified" datetime="2025-07-30T09:15:18+08:00">2025-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">实习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/" itemprop="url" rel="index"><span itemprop="name">晨晟智控</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>部署日志见实习日志那篇文章</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>查看mineru提取的markdown文档后，发现mineru暂时无法提取多级标题，所以可以舍弃根据markdown文档结构的分块策略</p>
<p>UnstructuredMarkdownLoader会丢失表格格式，不能使用</p>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>将 <code>Markdown</code> 文档加载到 LangChain <a target="_blank" rel="noopener" href="https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document">文档</a> 对象中，以便我们可以在后续使用</p>
<h4 id="使用UnstructuredMarkdownLoader-对象"><a href="#使用UnstructuredMarkdownLoader-对象" class="headerlink" title="使用UnstructuredMarkdownLoader 对象"></a>使用<a target="_blank" rel="noopener" href="https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html">UnstructuredMarkdownLoader</a> 对象</h4><p>UnstructuredMarkdownLoader 是 LangChain 中的一个 文档加载器（Document Loader） ，专门用于加载和解析 Markdown ( .md ) 文件。它的特别之处在于，它底层依赖于一个强大的开源库 unstructured 。</p>
<p><strong>UnstructuredMarkdownLoader 的核心功能</strong></p>
<p>传统的文本加载器可能会将整个 Markdown 文件作为一个大字符串读入。而 UnstructuredMarkdownLoader 凭借 unstructured 库的能力，可以 智能地识别 Markdown 文件内部的结构 。</p>
<p>它能够将文档分解成多个有意义的<strong>“元素” (Elements)</strong>，例如：</p>
<ul>
<li>标题 (Titles)</li>
<li>叙述性文本 (Narrative Text / Paragraphs)</li>
<li>列表项 (List Items)</li>
<li>代码块 (Code Blocks)<br>这种智能分区对于后续的 RAG (Retrieval-Augmented Generation) 应用非常重要，因为它能让您以更小的、逻辑上连贯的块来处理文本，从而提高检索的准确性。</li>
</ul>
<p><strong>重要的 mode 参数</strong></p>
<p>UnstructuredMarkdownLoader 的构造函数中有一个非常重要的 mode 参数，它决定了文档的加载方式：</p>
<ol>
<li><p>mode=”single” (默认值)</p>
<ul>
<li>将整个 Markdown 文件的所有内容加载成 一个单独的 Document 对象 。</li>
<li>page_content 包含文件的全部文本。</li>
</ul>
</li>
<li><p>mode=”elements”</p>
<ul>
<li>这是它最强大的模式。它会将文件解析成多个 Document 对象， 每个对象对应一个识别出的元素 （如一个标题、一个段落）。</li>
<li>这对于创建精细的文本块以进行向量嵌入和检索非常有用。</li>
</ul>
</li>
</ol>
<h4 id="使用libreoffice处理doc文件，转成pdf"><a href="#使用libreoffice处理doc文件，转成pdf" class="headerlink" title="使用libreoffice处理doc文件，转成pdf"></a>使用libreoffice处理doc文件，转成pdf</h4><p>将当前目录下所有 <code>.doc</code> 和 <code>.docx</code> 转为 PDF：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">libreoffice --headless --convert-to pdf *.doc *.docx --outdir ./pdf_output/</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">LangChain学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-15 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-15T00:00:00+08:00">2025-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-02 15:52:08" itemprop="dateModified" datetime="2025-08-02T15:52:08+08:00">2025-08-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langchain/" itemprop="url" rel="index"><span itemprop="name">langchain</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="实战demo"><a href="#实战demo" class="headerlink" title="实战demo"></a>实战demo</h3><h4 id="agent实战"><a href="#agent实战" class="headerlink" title="agent实战"></a>agent实战</h4><p>langchain的agent与langgraph的agent主要差异点在create_openai_functions_agent, AgentExecutor这两个函数</p>
<p>前者的作用类似<strong>构建 Runnable 链</strong>，返回一个<code>RunnablePassthrough.assign(...)|prompt|llm_with_tools|ToolsAgentOutputParser()</code>，但其invoke仅能完成单步的调用，而<code>AgentExecutor</code> 会自动完成3 步循环（调用工具→拼回结果→再次调用 LLM），直到任务结束。</p>
<blockquote>
<p>以下为ai的解释</p>
<p><strong>直接使用 <code>agent</code> (Runnable) 的局限性:</strong></p>
<ol>
<li><strong>单步执行</strong>: 你直接调用 <code>agent.invoke()</code> 或 <code>agent.ainvoke()</code> 时，它通常只执行<strong>一步</strong>。对于像 <code>create_tool_calling_agent</code> 生成的 <code>agent</code> 来说，这一步就是：<ul>
<li>接收输入（包括历史消息和 <code>agent_scratchpad</code>）。</li>
<li>让 LLM 决定是给出最终答案 (<code>AgentFinish</code>) 还是调用工具 (<code>AgentAction</code>)。</li>
<li>返回这个决定。</li>
</ul>
</li>
<li><strong>工具调用需要手动处理</strong>: 如果 LLM 决定调用工具（返回 <code>AgentAction</code>），<strong>你</strong>需要负责：<ul>
<li>从返回的 <code>AgentAction</code> 中找出工具名称和输入参数。</li>
<li>在你的工具列表中找到对应的工具。</li>
<li>执行这个工具。</li>
<li>获取工具的输出（Observation）。</li>
<li><strong>再次手动调用 <code>agent.invoke(...)</code></strong>，把工具的输出（通常需要格式化成 <code>ToolMessage</code>）放回 <code>agent_scratchpad</code> 或 <code>intermediate_steps</code> 中。</li>
<li>重复这个过程，直到 <code>agent</code> 最终返回 <code>AgentFinish</code>。</li>
</ul>
</li>
</ol>
<p><strong>使用 <code>AgentExecutor</code> 的优势:</strong></p>
<p><code>AgentExecutor</code> 就是为了解决上述问题而设计的。它本质上是一个<strong>自动化的执行引擎</strong>，为你管理整个 Agent 的思考-行动-观察循环。</p>
<ol>
<li><strong>自动化循环</strong>: <code>AgentExecutor</code> 内部会自动运行那个循环：<ul>
<li>调用 <code>agent</code> (Runnable)。</li>
<li>检查返回的是 <code>AgentAction</code> 还是 <code>AgentFinish</code>。</li>
<li>如果是 <code>AgentAction</code>，它会自动根据你提供的 <code>tools</code> 列表找到并执行对应的工具。</li>
<li>它会自动将工具的输出（Observation）记录下来，并作为下一步的输入（放入 <code>agent_scratchpad</code>）再次调用 <code>agent</code>。</li>
<li>这个过程会一直重复。</li>
</ul>
</li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">from langchain.agents import create_openai_functions_agent, AgentExecutor</span><br><span class="line">from langchain.tools import tool</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line"># 1. 定义工具</span><br><span class="line">class WeatherInput(BaseModel):</span><br><span class="line">    location: str = Field(description=&quot;城市名称&quot;)</span><br><span class="line"></span><br><span class="line">@tool(&quot;get_weather&quot;, args_schema=WeatherInput)</span><br><span class="line">def get_weather(location: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;查询城市天气&quot;&quot;&quot;</span><br><span class="line">    return f&quot;&#123;location&#125; 今天是晴天，25°C&quot;</span><br><span class="line"></span><br><span class="line"># 2. 创建Agent</span><br><span class="line">llm = ChatOpenAI(model=&quot;gpt-4&quot;)</span><br><span class="line">tools = [get_weather]</span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (&quot;system&quot;, &quot;你是一个助手，可以调用工具&quot;),</span><br><span class="line">    (&quot;human&quot;, &quot;&#123;input&#125;&quot;)</span><br><span class="line">])</span><br><span class="line">agent = create_openai_functions_agent(llm, tools, prompt)</span><br><span class="line">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)</span><br><span class="line"></span><br><span class="line"># 3. 执行</span><br><span class="line">result = agent_executor.invoke(&#123;&quot;input&quot;: &quot;北京天气如何？&quot;&#125;)</span><br><span class="line">print(result[&quot;output&quot;])</span><br></pre></td></tr></table></figure>
<h4 id="工具调用"><a href="#工具调用" class="headerlink" title="工具调用"></a>工具调用</h4><p>利用bind_tools绑定工具，当大模型需要调用工具的时候，会返回工具信息，tool_calls，如下</p>
<p>[{‘name’: ‘add_numbers’, ‘args’: {‘a’: 15, ‘b’: 27}, ‘id’: ‘4e7b261cce6d4e3da09134086c704c3c’, ‘type’: ‘tool_call’}]</p>
<blockquote>
<p><code>llm_with_tools.invoke(...)</code> 只是一个<strong>单步调用</strong>，LLM 返回的是<strong>“我想调用哪个工具、传什么参数”</strong>（即 <code>tool_calls</code>）。<br><strong>但 LLM 并不会自动执行工具</strong>，所以你必须：</p>
<ol>
<li><strong>手动执行工具</strong>（或让 AgentExecutor 帮你执行）。</li>
<li><strong>把执行结果拼回对话</strong>（作为 <code>ToolMessage</code>）。</li>
<li><strong>再次调用 LLM</strong>，让它基于工具返回的结果生成最终答案。</li>
</ol>
</blockquote>
<p>这里展示的是手动拼接，并传给大模型，如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 将工具的输出发送回LLM，让LLM基于结果生成最终回答</span><br><span class="line">            # 这是一个关键步骤，通常在Agent中自动处理。这里手动演示。</span><br><span class="line">            final_response = llm_with_tools.invoke([</span><br><span class="line">                HumanMessage(content=&quot;What is 15 + 27?&quot;),</span><br><span class="line">                AIMessage(content=&quot;&quot;, tool_calls=[tool_call]), # 告知LLM它之前建议的工具调用</span><br><span class="line">                ToolMessage(content=str(result), tool_call_id=tool_call[&#x27;id&#x27;]) # 告知LLM工具的执行结果</span><br><span class="line">            ])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.tools import tool</span><br><span class="line">from typing import Literal</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">from langchain_core.messages import HumanMessage, AIMessage, ToolMessage</span><br><span class="line"></span><br><span class="line"># 定义一个加法工具</span><br><span class="line">@tool</span><br><span class="line">def add_numbers(a: float, b: float) -&gt; float:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Adds two numbers together.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: The first number.</span><br><span class="line">        b: The second number.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a + b</span><br><span class="line"></span><br><span class="line"># 我们可以定义更多的工具，例如一个乘法工具</span><br><span class="line">@tool</span><br><span class="line">def multiply_numbers(a: float, b: float) -&gt; float:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Multiplies two numbers together.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: The first number.</span><br><span class="line">        b: The second number.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line"></span><br><span class="line"># 将我们定义的工具放在一个列表中</span><br><span class="line">tools = [add_numbers, multiply_numbers]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 初始化LLM</span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    temperature=0.5,</span><br><span class="line">    model_name=&quot;deepseek-v3-0324&quot;, # 聊天模型通常使用&quot;gpt-3.5-turbo&quot;或&quot;gpt-4&quot;</span><br><span class="line">    openai_api_base=&quot;https://api.qnaigc.com/v1&quot;, # 例如，您可以指定base_url</span><br><span class="line">    openai_api_key=&quot;sk-&quot; # 直接在此处设置API密钥，或者通过环境变量设置</span><br><span class="line">)</span><br><span class="line"># 将工具绑定到LLM</span><br><span class="line"># LLM现在知道了add_numbers和multiply_numbers这两个工具及其功能</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 场景一：LLM直接回答，不需要工具</span><br><span class="line">print(&quot;--- 场景一：LLM直接回答 ---&quot;)</span><br><span class="line">response1 = llm_with_tools.invoke([HumanMessage(content=&quot;Hello, what&#x27;s your name?&quot;)])</span><br><span class="line">print(response1.content) # LLM直接生成文本回复</span><br><span class="line"></span><br><span class="line">print(&quot;\n--- 场景二：LLM决定调用工具 ---&quot;)</span><br><span class="line"># 场景二：LLM决定调用工具</span><br><span class="line"># 当LLM的响应中包含tool_calls时，意味着它想要调用一个或多个工具</span><br><span class="line">response2 = llm_with_tools.invoke([HumanMessage(content=&quot;What is 15 + 27?&quot;)])</span><br><span class="line">print(response2.tool_calls) # 打印LLM决定调用的工具信息</span><br><span class="line"></span><br><span class="line"># 检查并执行LLM建议的工具调用</span><br><span class="line">if response2.tool_calls:</span><br><span class="line">    for tool_call in response2.tool_calls:</span><br><span class="line">        if tool_call[&#x27;name&#x27;] == &quot;add_numbers&quot;:</span><br><span class="line">            # 提取LLM为工具调用生成的参数</span><br><span class="line">            args = tool_call[&#x27;args&#x27;]</span><br><span class="line">            result = add_numbers.invoke(args) # 执行工具</span><br><span class="line">            print(f&quot;Tool call: add_numbers(&#123;args[&#x27;a&#x27;]&#125;, &#123;args[&#x27;b&#x27;]&#125;) = &#123;result&#125;&quot;)</span><br><span class="line"></span><br><span class="line">            # 将工具的输出发送回LLM，让LLM基于结果生成最终回答</span><br><span class="line">            # 这是一个关键步骤，通常在Agent中自动处理。这里手动演示。</span><br><span class="line">            final_response = llm_with_tools.invoke([</span><br><span class="line">                HumanMessage(content=&quot;What is 15 + 27?&quot;),</span><br><span class="line">                AIMessage(content=&quot;&quot;, tool_calls=[tool_call]), # 告知LLM它之前建议的工具调用</span><br><span class="line">                ToolMessage(content=str(result), tool_call_id=tool_call[&#x27;id&#x27;]) # 告知LLM工具的执行结果</span><br><span class="line">            ])</span><br><span class="line">            print(&quot;Final LLM response based on tool output:&quot;)</span><br><span class="line">            print(final_response.content)</span><br></pre></td></tr></table></figure>
<h3 id="概念扫盲"><a href="#概念扫盲" class="headerlink" title="概念扫盲"></a>概念扫盲</h3><h4 id="Document-对象"><a href="#Document-对象" class="headerlink" title="Document 对象"></a>Document 对象</h4><p>Document 对象是 LangChain 用来封装和处理文本数据的基本单位。无论您是从 PDF、Markdown 文件、网站还是数据库加载数据，LangChain 都会将这些数据转换成一个或多个 Document 对象，以便在后续的流程中使用。</p>
<p>一个 Document 对象主要包含两个部分：</p>
<ol>
<li><p>page_content (字符串)</p>
<ul>
<li>这是文档对象的核心，存储了原始的文本内容。例如，如果加载一个 Markdown 文件， page_content 就会包含该文件的所有文本。</li>
</ul>
</li>
<li><p>metadata (字典)</p>
<ul>
<li>这是一个字典，用于存储关于文档的“元数据”或附加信息。这些信息对于过滤、追踪或增强文档处理流程非常有用。常见的元数据包括：<ul>
<li>source ：文档的来源，比如文件名、URL等。</li>
<li>page ：如果文档来自多页文件（如PDF），这里可以存储页码。</li>
<li>其他自定义信息：您可以添加任何有助于您应用的信息，如作者、创建日期等。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>除了通过文档加载器（Loaders）自动创建，您也可以手动创建一个 Document 对象。这在测试或处理简单文本时非常方便。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个简单的 Document 对象</span><br><span class="line">doc = Document(</span><br><span class="line">    page_content=&quot;这是文档的主要内容。LangChain 真酷！&quot;,</span><br><span class="line">    metadata=&#123;</span><br><span class="line">        &#x27;source&#x27;: &#x27;my_notebook.ipynb&#x27;,</span><br><span class="line">        &#x27;author&#x27;: &#x27;AI Assistant&#x27;,</span><br><span class="line">        &#x27;chapter&#x27;: 2</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="Runnable协议"><a href="#Runnable协议" class="headerlink" title="Runnable协议"></a>Runnable协议</h4><p><a target="_blank" rel="noopener" href="https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable">“Runnable”</a>协议</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV12TLAzuEni/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">2025最新版！langchain入门到精通实战教程！结合实战案例，干货拉满！99%的人不知道的暴利玩法，学完敢谷歌工程师叫板！_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.langchain.com.cn/docs/introduction/">introduction | LangChain中文网</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1XudVYzEcW?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">跟着官网学langchain2025(version 0.3)_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.langchain.com/langgraph-platform">LangGraph Platform - Docs by LangChain</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">LangGraph学习——快速入门</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-15 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-15T00:00:00+08:00">2025-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-05 17:31:03" itemprop="dateModified" datetime="2025-08-05T17:31:03+08:00">2025-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="构建langgraph聊天机器人的基本流程"><a href="#构建langgraph聊天机器人的基本流程" class="headerlink" title="构建langgraph聊天机器人的基本流程"></a>构建langgraph聊天机器人的基本流程</h3><h4 id="创建一个-StateGraph"><a href="#创建一个-StateGraph" class="headerlink" title="创建一个 StateGraph"></a>创建一个 <code>StateGraph</code></h4><p>首先创建一个 <code>StateGraph</code>。一个 <code>StateGraph</code> 对象将我们的聊天机器人结构定义为“状态机”。我们将添加 <code>节点</code> 来表示 LLM 和聊天机器人可以调用的函数，并添加 <code>边</code> 来指定机器人应如何在这些函数之间进行转换。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义状态</span></span><br><span class="line">graph_builder = StateGraph(State)</span><br></pre></td></tr></table></figure>
<p>在 langgraph 中，状态会在图的各个节点之间传递。当一个节点产生新的消息时，它会更新 State 中的 messages 字段。</p>
<p>我们的图现在可以处理两个关键任务</p>
<ol>
<li>每个 <code>节点</code> 都可以接收当前 <code>状态</code> 作为输入，并输出状态的更新。</li>
<li>对 <code>消息</code> 的更新将追加到现有列表而不是覆盖它，这得益于与 <code>Annotated</code> 语法一起使用的预构建 <a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/reference/graphs/?h=add+messages#add_messages"><code>add_messages</code></a> 函数。</li>
</ol>
<blockquote>
<p>langgraph中每个消息对象通常包含以下关键属性：</p>
<ul>
<li>role : 一个字符串，标识消息的发送者（例如 ‘human’ , ‘ai’ , ‘system’ ）。</li>
<li>content : 消息的具体内容，通常是字符串，但也可以是更复杂的结构（例如，用于多模态输入）。</li>
<li>id : 一个可选的唯一标识符。</li>
</ul>
<p>Annotated 的作用 : 通过使用 Annotated[list, add_messages] ，你改变了这个默认行为。 add_messages 函数（由 langgraph 提供或由你自定义）的逻辑是 追加 而不是覆盖。所以，当一个新节点返回消息时， langgraph 会调用 add_messages 函数，将新消息 追加 到现有 messages 列表的末尾。</p>
</blockquote>
<h4 id="定义一个聊天模型"><a href="#定义一个聊天模型" class="headerlink" title="定义一个聊天模型"></a>定义一个聊天模型</h4><p>两种方法：</p>
<p>1.使用 <code>init_chat_model</code>(通用高层封装)<br>这是一个通用的辅助函数，旨在提供一个统一的接口来初始化来自 不同提供商 的聊天模型。</p>
<p><a target="_blank" rel="noopener" href="https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html">init_chat_model — 🦜🔗 LangChain 文档 —- init_chat_model — 🦜🔗 LangChain documentation</a></p>
<p>2.使用如ChatOpenAI (特定于提供商的类)<br>这是一个专门为 OpenAI API 设计的类，提供了对 OpenAI 模型所有功能的完全访问。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from langchain.chat_models import init_chat_model</span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;sk-&quot;</span><br><span class="line">#使用‘&#123;model_provider&#125;:&#123;model&#125;’格式在单个参数中指定模型和模型提供者，例如“openai:o1”</span><br><span class="line">llm = init_chat_model(&quot;openai:qwen-plus-2025-04-28&quot;,</span><br><span class="line">                      base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">                      )</span><br></pre></td></tr></table></figure>
<h4 id="添加一个节点"><a href="#添加一个节点" class="headerlink" title="添加一个节点"></a>添加一个节点</h4><p>现在我们可以将聊天模型集成到一个简单的节点中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#定义节点chatbot</span><br><span class="line">def chatbot(state: State):</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line">graph_builder.add_node(&quot;chatbot&quot;, chatbot)</span><br></pre></td></tr></table></figure>
<p> <code>chatbot</code> 节点函数如何将当前 <code>状态</code> 作为输入，并返回一个包含更新的 <code>消息</code> 列表的字典，键为“messages”。这是所有 LangGraph 节点函数的基本模式。</p>
<p>我们 <code>状态</code> 中的 <code>add_messages</code> 函数会将 LLM 的响应消息追加到状态中已有的消息之后。</p>
<h4 id="添加一个-入口-点"><a href="#添加一个-入口-点" class="headerlink" title="添加一个 入口 点"></a>添加一个 <code>入口</code> 点</h4><p>添加一个 <code>入口</code> 点，以告诉图每次运行时<strong>从何处开始工作</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph_builder.add_edge(START, &quot;chatbot&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="编译图"><a href="#编译图" class="headerlink" title="编译图"></a>编译图</h4><p>在运行图之前，我们需要对其进行编译。我们可以通过在图构建器上调用 <code>compile()</code> 来完成。这将创建一个 <code>CompiledGraph</code>，我们可以在我们的状态上调用它。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph = graph_builder.compile()</span><br></pre></td></tr></table></figure>
<h4 id="可视化图"><a href="#可视化图" class="headerlink" title="可视化图"></a>可视化图</h4><p>您可以使用 <code>get_graph</code> 方法和其中一个“绘图”方法（例如 <code>draw_ascii</code> 或 <code>draw_png</code>）来可视化图。这些 <code>draw</code> 方法都需要额外的依赖项。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    display(Image(graph.get_graph().draw_mermaid_png()))</span><br><span class="line">except Exception:</span><br><span class="line">    # This requires some extra dependencies and is optional</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure>
<h4 id="运行聊天机器人"><a href="#运行聊天机器人" class="headerlink" title="运行聊天机器人"></a>运行聊天机器人</h4><p>运行聊天机器人</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;]&#125;):</span><br><span class="line">        <span class="built_in">print</span>(event)</span><br><span class="line">        <span class="comment">#stream 返回的每个 event 通常是一个字典，键是图中节点的名称，值是该节点完成后的状态更新。</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">            <span class="comment">#消息列表中的最后一条消息的文本内容</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="comment">#退出</span></span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment">#调用</span></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>graph.stream() 是 LangGraph 的核心功能之一。它会执行整个图（Graph），但不是一次性返回最终结果，而是像视频流一样，一步一步地返回中间过程的更新。这使得您可以实时看到模型生成内容的每一个部分。</p>
</blockquote>
<h3 id="添加网页搜索工具"><a href="#添加网页搜索工具" class="headerlink" title="添加网页搜索工具"></a>添加网页搜索工具</h3><h4 id="获取Tavily-api"><a href="#获取Tavily-api" class="headerlink" title="获取Tavily api"></a>获取Tavily api</h4><p><a target="_blank" rel="noopener" href="https://tavily.com/">Tavily 的搜索 API</a> 是一款专为 AI 代理 (LLM) 构建的搜索引擎，能够快速提供实时、准确和基于事实的结果。</p>
<p>每月 1,000 次免费搜索</p>
<p><a target="_blank" rel="noopener" href="https://python.langchain.ac.cn/docs/integrations/tools/tavily_search/">Tavily Search | 🦜️🔗 LangChain 框架</a></p>
<p>获取api<a target="_blank" rel="noopener" href="https://app.tavily.com/home">Tavily AI —- Tavily AI</a></p>
<h4 id="添加工具"><a href="#添加工具" class="headerlink" title="添加工具"></a>添加工具</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line"></span><br><span class="line">tool = TavilySearch(</span><br><span class="line">    tavily_api_key=&quot;tvly-dev-&quot;,</span><br><span class="line">    max_results=2)</span><br><span class="line">tools = [tool]</span><br><span class="line">tool.invoke(&quot;李超是谁?&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="定义图"><a href="#定义图" class="headerlink" title="定义图"></a>定义图</h4><p>在LLM上添加<code>bind_tools</code>。这让LLM知道如果它想使用搜索引擎，应使用正确的JSON格式。</p>
<p>定义聊天模型llm（代码同上）</p>
<p>将tools整合到<code>StateGraph</code>中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将一个或多个**工具（tools） 绑定到一个 大型语言模型（LLM）**上，从而创建一个新的、具备工具调用能力的 LLM 实例</span></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br></pre></td></tr></table></figure>
<h4 id="创建一个运行工具的函数"><a href="#创建一个运行工具的函数" class="headerlink" title="创建一个运行工具的函数"></a>创建一个运行工具的函数</h4><p>现在，创建一个函数来运行被调用的工具。通过将工具添加到一个名为<code>BasicToolNode</code>的新节点来完成，该节点检查状态中的最新消息，如果消息包含<code>tool_calls</code>，则调用工具。它依赖于LLM的<code>tool_calling</code>支持，该支持在Anthropic、OpenAI、Google Gemini以及许多其他LLM提供商中可用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 __call__ 方法，让这个类的实例可以像函数一样被调用</span></span><br><span class="line"><span class="comment"># inputs 是 langgraph 传进来的当前状态，是一个字典</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, inputs: <span class="built_in">dict</span></span>):</span><br><span class="line">    <span class="comment"># 1. 从状态中获取最新的消息</span></span><br><span class="line">    <span class="comment"># 使用了“海象操作符” :=，先从 inputs 中获取 &#x27;messages&#x27; 列表，如果不存在则返回空列表 []</span></span><br><span class="line">    <span class="comment"># 然后检查列表是否为空。如果不为空，则取出最后一条消息。</span></span><br><span class="line">    <span class="keyword">if</span> messages := inputs.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">        message = messages[-<span class="number">1</span>]  <span class="comment"># 通常，最后一条消息是 AI 发出的，其中包含工具调用请求</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果没有消息，就报错，因为这个节点不知道该做什么</span></span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;No message found in input&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 准备一个列表，用来存放所有工具的执行结果</span></span><br><span class="line">    outputs = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 遍历 AI 消息中请求的所有工具调用</span></span><br><span class="line">    <span class="keyword">for</span> tool_call <span class="keyword">in</span> message.tool_calls:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 执行工具</span></span><br><span class="line">        <span class="comment"># a. tool_call[&quot;name&quot;] 获取工具名称 (例如 &#x27;tavily_search_results_json&#x27;)</span></span><br><span class="line">        <span class="comment"># b. self.tools_by_name[...] 从预存的工具字典中找到对应的工具对象</span></span><br><span class="line">        <span class="comment"># c. .invoke(tool_call[&quot;args&quot;]) 使用 LLM 提供的参数来调用该工具</span></span><br><span class="line">        tool_result = <span class="variable language_">self</span>.tools_by_name[tool_call[<span class="string">&quot;name&quot;</span>]].invoke(</span><br><span class="line">            tool_call[<span class="string">&quot;args&quot;</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. 将工具执行结果打包成 ToolMessage</span></span><br><span class="line">        <span class="comment"># 这是 langgraph/langchain 的标准格式，用于告诉 LLM 工具执行的结果是什么</span></span><br><span class="line">        outputs.append(</span><br><span class="line">            ToolMessage(</span><br><span class="line">                content=json.dumps(tool_result),  <span class="comment"># 工具结果必须是字符串，所以用 json.dumps 序列化</span></span><br><span class="line">                name=tool_call[<span class="string">&quot;name&quot;</span>],  <span class="comment"># 告诉 LLM 这是哪个工具的结果</span></span><br><span class="line">                tool_call_id=tool_call[<span class="string">&quot;id&quot;</span>],  <span class="comment"># 必须提供原始请求的 ID，以便 LLM 知道这个结果对应哪个请求</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 6. 返回结果，更新图的状态</span></span><br><span class="line">    <span class="comment"># 返回一个字典，其中 &#x27;messages&#x27; 键对应着包含所有 ToolMessage 的列表</span></span><br><span class="line">    <span class="comment"># langgraph 会将这个列表中的消息追加到主状态的 &#x27;messages&#x27; 列表中</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: outputs&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>call</strong> 是 Python 中一个非常特殊的“魔术方法”（magic method）。它的作用是 让一个类的实例（对象）能够像函数一样被调用 。</p>
<p>这在 langgraph 中是一种常见且核心的设计模式。它的含义是：</p>
<ol>
<li>节点即函数 ： BasicToolNode 的实例（比如 tool_node ）本身就代表了图中的一个可执行节点。</li>
<li>执行逻辑 ：当 langgraph 的状态机运行到这个 tool_node 节点时，它会直接“调用”这个节点对象，并把当前的状态（ inputs 字典）传递给它</li>
</ol>
</blockquote>
<p>可以使用LangGraph预构建的<a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/reference/agents/#langgraph.prebuilt.tool_node.ToolNode">ToolNode</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br></pre></td></tr></table></figure>
<h4 id="定义conditional-edges"><a href="#定义conditional-edges" class="headerlink" title="定义conditional_edges"></a>定义<code>conditional_edges</code></h4><p>添加了工具节点后，现在您可以定义<code>conditional_edges</code>。</p>
<p><strong>边（Edges）</strong>将控制流从一个节点路由到下一个节点。<strong>条件边（Conditional edges）</strong>从单个节点开始，通常包含“if”语句，根据当前图状态路由到不同的节点。这些函数接收当前的图<code>state</code>并返回一个字符串或字符串列表，指示接下来要调用哪个（或哪些）节点。</p>
<p>接下来，定义一个名为<code>route_tools</code>的路由函数，它检查聊天机器人输出中的<code>tool_calls</code>。通过调用<code>add_conditional_edges</code>将此函数提供给图，这会告诉图，无论何时<code>chatbot</code>节点完成，都要检查此函数以确定下一步去哪里。</p>
<p>如果存在工具调用，条件将路由到<code>tools</code>；如果不存在，则路由到<code>END</code>。由于条件可以返回<code>END</code>，因此这次您不需要明确设置<code>finish_point</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">route_tools</span>(<span class="params"></span></span><br><span class="line"><span class="params">     state: State,</span></span><br><span class="line"><span class="params"> </span>):</span><br><span class="line">     <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">     用于 conditional_edge 的路由函数：</span></span><br><span class="line"><span class="string">     - 如果最后一条消息包含工具调用，则路由到 ToolNode</span></span><br><span class="line"><span class="string">     - 否则路由到结束节点</span></span><br><span class="line"><span class="string">     &quot;&quot;&quot;</span></span><br><span class="line">     <span class="comment"># 处理 state 为列表的情况（可能是消息列表）</span></span><br><span class="line">     <span class="keyword">if</span> <span class="built_in">isinstance</span>(state, <span class="built_in">list</span>):</span><br><span class="line">         ai_message = state[-<span class="number">1</span>]  <span class="comment"># 获取最后一条消息</span></span><br><span class="line">     <span class="comment"># 处理 state 为字典的情况（包含 messages 字段）</span></span><br><span class="line">     <span class="keyword">elif</span> messages := state.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">         ai_message = messages[-<span class="number">1</span>]  <span class="comment"># 获取最后一条消息</span></span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">         <span class="keyword">raise</span> ValueError(<span class="string">f&quot;输入状态中没有找到消息: <span class="subst">&#123;state&#125;</span>&quot;</span>)</span><br><span class="line">     </span><br><span class="line">     <span class="comment"># 检查消息是否有工具调用</span></span><br><span class="line">     <span class="keyword">if</span> <span class="built_in">hasattr</span>(ai_message, <span class="string">&quot;tool_calls&quot;</span>) <span class="keyword">and</span> <span class="built_in">len</span>(ai_message.tool_calls) &gt; <span class="number">0</span>:</span><br><span class="line">         <span class="keyword">return</span> <span class="string">&quot;tools&quot;</span>  <span class="comment"># 有工具调用，返回 &quot;tools&quot; 路由到工具节点</span></span><br><span class="line">     <span class="keyword">return</span> END  <span class="comment"># 没有工具调用，返回 END 结束流程</span></span><br></pre></td></tr></table></figure>
<p>可以使用预构建的<a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/reference/prebuilt/#tools_condition">tools_condition</a>代替route_tools以使其更简洁。</p>
<blockquote>
<p><code>tools_condition</code> 函数在聊天机器人需要使用工具时返回 “tools”，如果可以不使用响应则返回 “END”。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> tools_condition</span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">    &#123;<span class="string">&quot;tools&quot;</span>: <span class="string">&quot;tools&quot;</span>, END: END&#125;,</span><br><span class="line">)</span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br></pre></td></tr></table></figure>
<h4 id="可视化图-1"><a href="#可视化图-1" class="headerlink" title="可视化图"></a>可视化图</h4><p>如上</p>
<h4 id="向机器人提问"><a href="#向机器人提问" class="headerlink" title="向机器人提问"></a>向机器人提问</h4><p>现在您可以向聊天机器人提出超出其训练数据范围的问题。</p>
<p>如上</p>
<h3 id="添加记忆功能"><a href="#添加记忆功能" class="headerlink" title="添加记忆功能"></a>添加记忆功能</h3><p>LangGraph 通过<strong>持久性检查点</strong>解决了这个问题。如果您在编译图时提供一个<code>checkpointer</code>，并在调用图时提供一个<code>thread_id</code>，LangGraph 会在每一步之后自动保存状态。当您使用相同的<code>thread_id</code>再次调用图时，图会加载其保存的状态，允许聊天机器人从上次中断的地方继续。</p>
<p>我们稍后会看到，<strong>检查点</strong>比简单的聊天记忆功能<em>强大得多</em>——它允许您随时保存和恢复复杂状态，用于错误恢复、人工干预工作流、时间旅行交互等。但首先，让我们添加检查点以实现多轮对话。</p>
<h4 id="创建-MemorySaver-检查点"><a href="#创建-MemorySaver-检查点" class="headerlink" title="创建 MemorySaver 检查点"></a>创建 <code>MemorySaver</code> 检查点</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br></pre></td></tr></table></figure>
<p>这是一个内存中的检查点，方便本教程使用。然而，在生产应用程序中，您可能会将其更改为使用 <code>SqliteSaver</code> 或 <code>PostgresSaver</code> 并连接数据库。</p>
<h4 id="编译图-1"><a href="#编译图-1" class="headerlink" title="编译图"></a>编译图</h4><p>使用提供的检查点编译图，图在遍历每个节点时将对 <code>State</code> 进行检查点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph = graph_builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<h4 id="与您的聊天机器人互动"><a href="#与您的聊天机器人互动" class="headerlink" title="与您的聊天机器人互动"></a>与您的聊天机器人互动</h4><ol>
<li><p>选择一个线程作为此对话的键。</p>
<p>thread_id决定对话窗口</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>调用您的聊天机器人</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">user_input = &quot;我是谁&quot;</span><br><span class="line"></span><br><span class="line"># The config is the **second positional argument** to stream() or invoke()!</span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">)</span><br><span class="line">for event in events:</span><br><span class="line">    event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="添加人工干预"><a href="#添加人工干预" class="headerlink" title="添加人工干预"></a>添加人工干预</h3><p>代理可能不可靠，并且可能需要人工输入才能成功完成任务。同样，对于某些操作，您可能需要在运行前要求人工批准，以确保一切按预期运行。</p>
<p>LangGraph 的<a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/persistence/">持久化</a>层支持<strong>人工干预</strong>工作流，允许根据用户反馈暂停和恢复执行。此功能的主要接口是<a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/how-tos/human_in_the_loop/add-human-in-the-loop/"><code>interrupt</code></a>函数。在节点内调用<code>interrupt</code>将暂停执行。通过传入<a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/low_level/#command">Command</a>，可以恢复执行并接收来自人工的新输入。<code>interrupt</code>在功能上类似于 Python 的内置<code>input()</code>，<a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/how-tos/human_in_the_loop/add-human-in-the-loop/">但有一些注意事项</a>。</p>
<h4 id="添加human-assistance工具"><a href="#添加human-assistance工具" class="headerlink" title="添加human_assistance工具"></a>添加<code>human_assistance</code>工具</h4><p>将<code>human_assistance</code>工具添加到聊天机器人。此工具使用<code>interrupt</code>从人工接收信息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 添加人工干预功能</span><br><span class="line"># 导入LangGraph的中断机制和命令类型</span><br><span class="line">from langgraph.types import Command, interrupt</span><br><span class="line"># 导入LangChain的工具装饰器</span><br><span class="line">from langchain_core.tools import tool</span><br><span class="line"></span><br><span class="line"># 使用@tool装饰器将函数标记为可被LLM调用的工具</span><br><span class="line">@tool</span><br><span class="line">def human_assistance(query: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;请求人工协助的工具函数。</span><br><span class="line">    当LLM遇到需要人工判断或帮助的情况时，会调用此工具。</span><br><span class="line">    该函数会暂停图的执行，等待人工操作员提供响应。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # interrupt()函数会暂停图的执行，等待人工输入</span><br><span class="line">    # 传入的字典包含查询信息，人工操作员会看到这个查询</span><br><span class="line">    human_response = interrupt(&#123;&quot;query&quot;: query&#125;)</span><br><span class="line">    </span><br><span class="line">    # 从人工响应中提取数据并返回给LLM</span><br><span class="line">    # human_response是一个字典，&quot;data&quot;字段包含人工提供的实际响应</span><br><span class="line">    return human_response[&quot;data&quot;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>简单来说， <strong>调用哪个工具，以及何时调用，完全是由大语言模型（LLM）根据你给它的指令（Prompt）来决定的。</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tool = TavilySearch(max_results=2)</span><br><span class="line">tools = [tool, human_assistance]</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br></pre></td></tr></table></figure>
<h4 id="定义chatbot"><a href="#定义chatbot" class="headerlink" title="定义chatbot"></a>定义chatbot</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def chatbot(state: State):</span><br><span class="line">    # 调用绑定了工具的LLM（llm_with_tools），传入当前的消息历史</span><br><span class="line">    # LLM会根据最新的消息决定是生成文本回复，还是调用一个或多个工具</span><br><span class="line">    message = llm_with_tools.invoke(state[&quot;messages&quot;])</span><br><span class="line">    </span><br><span class="line">    # --- 关键断言逻辑 ---</span><br><span class="line">    assert len(message.tool_calls) &lt;= 1</span><br><span class="line">    </span><br><span class="line">    # 将LLM生成的新消息（可能是文本回复，也可能是工具调用请求）返回</span><br><span class="line">    # 这个返回值会以字典的形式更新到状态（State）对象中</span><br><span class="line">    return &#123;&quot;messages&quot;: [message]&#125;</span><br><span class="line"></span><br><span class="line"># 将 chatbot 函数作为名为 &quot;chatbot&quot; 的节点添加到图构建器中</span><br><span class="line">graph_builder.add_node(&quot;chatbot&quot;, chatbot)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>中断安全性的断言 ( assert ) : assert len(message.tool_calls) &lt;= 1 是在实现人工干预时一个非常重要的 安全措施 。</p>
<ul>
<li>问题 : 现代 LLM 支持并行工具调用（一次请求执行多个工具）。但如果其中一个工具是 human_assistance 并触发了中断，整个图会暂停。当人工操作完成后，图会从中断点恢复。此时，如果不对工具调用数量做限制，LangGraph 可能会重新尝试执行所有在中断前请求的工具，导致已经执行过的工具被再次调用。</li>
<li>解决方案 : 这个断言强制要求 LLM 在每一步最多只能请求调用一个工具。这样就保证了当中断发生并恢复后，不会有重复执行工具的风险，确保了流程的稳定性和可预测性。</li>
</ul>
</blockquote>
<h4 id="编译图-2"><a href="#编译图-2" class="headerlink" title="编译图"></a>编译图</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line">graph = graph_builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<h4 id="调用聊天机器人并中断"><a href="#调用聊天机器人并中断" class="headerlink" title="调用聊天机器人并中断"></a>调用聊天机器人并中断</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">user_input = &quot;我需要一些关于构建 AI 代理的专家指导。你能帮我请求协助吗？&quot;</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    #它的作用是指定在进行流式处理时，你希望接收到的数据是以 完整的、累积的值 的形式返回，而不是以增量的、片段的形式返回。</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>聊天机器人生成了一个工具调用，但随后执行被中断。如果您检查图状态，您会看到它停止在工具节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">snapshot = graph.get_state(config)</span><br><span class="line">snapshot.next</span><br></pre></td></tr></table></figure>
<h4 id="恢复执行"><a href="#恢复执行" class="headerlink" title="恢复执行"></a>恢复执行</h4><p>要恢复执行，请传入一个包含工具所需数据的<a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/low_level/#command"><code>Command</code></a>对象。此数据的格式可以根据需要进行自定义。对于本示例，请使用一个带有键<code>&quot;data&quot;</code>的字典（由human_assistance决定）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">human_response = (</span><br><span class="line">&quot;我们专家在此为您提供帮助！我们建议您查看 LangGraph 来构建您的代理。它比简单的自主代理更可靠、更具可扩展性。&quot;</span><br><span class="line">)   </span><br><span class="line">#从暂停状态恢复执行</span><br><span class="line">human_command = Command(resume=&#123;&quot;data&quot;: human_response&#125;)</span><br><span class="line"></span><br><span class="line">events = graph.stream(human_command, config, stream_mode=&quot;values&quot;)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>1.工具的定义 ( human_assistance function):</p>
<ul>
<li>当 LLM 调用 human_assistance 工具时，这个函数被执行。</li>
<li>函数内部， interrupt() 被调用，导致图暂停，并等待人工输入。</li>
<li>在图恢复后， interrupt() 函数会返回一个值，这个值就是您通过 Command(resume=…) 注入的内容，也就是 {“data”: human_response} 。</li>
<li>因此， human_assistance 函数中的 human_response 变量实际上就等于 {“data”: human_response} 。</li>
<li>最后， return human_response[“data”] 从这个字典中提取出 “data” 键对应的值 ，并将其作为 human_assistance 工具的最终返回结果。</li>
</ul>
<p>2.恢复指令 ( Command(resume=…) ):</p>
<ul>
<li>当您构建 Command(resume={“data”: human_response}) 时，您正在创建一个符合 human_assistance 函数期望的结构。</li>
<li>您将人工回复包装在一个字典里，并使用 “data” 作为键。</li>
<li>这个结构被传递回 interrupt() ，然后被 human_assistance 函数接收和解析。</li>
</ul>
<p>因为 human_assistance 函数的 return 语句期望从返回的字典中访问 “data” 键，所以我们在恢复执行时必须提供一个具有相同结构的字典。这是为了确保数据能够正确地在中断和恢复的过程中传递。</p>
</blockquote>
<p>在 LangGraph 中，<code>Command</code> 是一个用于<strong>控制图执行流程、更新状态、实现人机交互</strong>的核心类。它支持以下四个参数：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">参数名</th>
<th style="text-align:left">类型</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>update</code></td>
<td style="text-align:left"><code>dict</code></td>
<td style="text-align:left">用于更新图的状态（state）。例如：<code>Command(update=&#123;&quot;foo&quot;: &quot;bar&quot;&#125;)</code>。</td>
</tr>
<tr>
<td style="text-align:left"><code>resume</code></td>
<td style="text-align:left"><code>Any</code></td>
<td style="text-align:left">与 <code>interrupt()</code> 配合使用，用于恢复被中断的图执行，并传递用户输入。</td>
</tr>
<tr>
<td style="text-align:left"><code>goto</code></td>
<td style="text-align:left"><code>str</code> 或 <code>Send</code> 或 `List[str</td>
<td style="text-align:left">Send]`</td>
<td>控制下一步要执行的节点，支持跳转到指定节点、多个节点序列，或使用 <code>Send</code> 对象。</td>
</tr>
<tr>
<td style="text-align:left"><code>graph</code></td>
<td style="text-align:left"><code>str</code></td>
<td style="text-align:left">可选，指定命令作用的图。默认是当前图，也可以设为 <code>Command.PARENT</code> 表示父图。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="自定义状态"><a href="#自定义状态" class="headerlink" title="自定义状态"></a>自定义状态</h3><p>在本教程中，您将向状态添加额外字段，以定义复杂行为，而无需依赖消息列表。聊天机器人将使用其搜索工具查找特定信息，并将其转发给人工进行审查。</p>
<h4 id="向状态添加键"><a href="#向状态添加键" class="headerlink" title="向状态添加键"></a>向状态添加键</h4><p>通过向状态添加 <code>name</code> 和 <code>birthday</code> 键，更新聊天机器人以研究实体的生日</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class State(TypedDict):</span><br><span class="line">    messages: Annotated[list, add_messages]</span><br><span class="line">    name: str</span><br><span class="line">    birthday: str</span><br></pre></td></tr></table></figure>
<p>将此信息添加到状态中，可以使其轻松被其他图节点（例如存储或处理信息的下游节点）以及图的持久层访问。</p>
<h4 id="在工具内部更新状态"><a href="#在工具内部更新状态" class="headerlink" title="在工具内部更新状态"></a>在工具内部更新状态</h4><p>现在，在 <code>human_assistance</code> 工具内部填充状态键。这允许人工在信息存储到状态之前对其进行审查。使用 <a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/low_level/#using-inside-tools"><code>Command</code></a> 从<strong>工具内部</strong>发出状态更新。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"># 从 langchain_core.messages 导入 ToolMessage，用于创建工具调用的响应消息</span><br><span class="line">from langchain_core.messages import ToolMessage </span><br><span class="line"># 从 langchain_core.tools 导入 InjectedToolCallId（用于自动注入工具调用ID）和 tool（工具装饰器）</span><br><span class="line">from langchain_core.tools import InjectedToolCallId, tool </span><br><span class="line"></span><br><span class="line"># 从 langgraph.types 导入 Command（用于向图发送指令）和 interrupt（用于中断图的执行）</span><br><span class="line">from langgraph.types import Command, interrupt </span><br><span class="line">from typing import Annotated</span><br><span class="line"># @tool 装饰器将这个函数声明为一个可供 LLM 调用的工具</span><br><span class="line">@tool </span><br><span class="line">def human_assistance(</span><br><span class="line">    name: str, </span><br><span class="line">    birthday: str, </span><br><span class="line">    # tool_call_id 这个参数非常特殊。Annotated[...] 和 InjectedToolCallId 告诉 LangGraph：</span><br><span class="line">    # 1. 这个参数不应暴露给 LLM，LLM 在调用此工具时不需要提供它。</span><br><span class="line">    # 2. LangGraph 在执行时，会自动将触发此工具的那个工具调用的 ID 注入到这个参数中。</span><br><span class="line">    # 这个 ID 对于创建与原始请求相关联的 ToolMessage 至关重要。</span><br><span class="line">    tool_call_id: Annotated[str, InjectedToolCallId]</span><br><span class="line">) -&gt; str: </span><br><span class="line">    &quot;&quot;&quot;当需要人工确认或更正信息时，请求人类协助。&quot;&quot;&quot; </span><br><span class="line">    # 调用 interrupt() 来暂停图的执行，并向人类审核者呈现一个包含问题和待确认数据的字典。</span><br><span class="line">    # 图会在此处暂停，直到人类通过 resume 指令提供了响应。</span><br><span class="line">    human_response = interrupt( </span><br><span class="line">        &#123; </span><br><span class="line">            &quot;question&quot;: &quot;Is this correct?&quot;, </span><br><span class="line">            &quot;name&quot;: name, </span><br><span class="line">            &quot;birthday&quot;: birthday, </span><br><span class="line">        &#125;,</span><br><span class="line">    ) </span><br><span class="line">    # 检查人类的响应。如果响应中 &#x27;correct&#x27; 键的值是 &#x27;yes&#x27; 或 &#x27;y&#x27; 开头，</span><br><span class="line">    # 则认为信息是正确的。</span><br><span class="line">    if human_response.get(&quot;correct&quot;, &quot;&quot;).lower().startswith(&quot;y&quot;): </span><br><span class="line">        # 如果信息正确，直接使用从 LLM 获取的原始信息。</span><br><span class="line">        verified_name = name </span><br><span class="line">        verified_birthday = birthday </span><br><span class="line">        response = &quot;Correct&quot; </span><br><span class="line">    # 否则，认为人类审核者提供了更正后的信息。</span><br><span class="line">    else: </span><br><span class="line">        # 从人类的响应中获取更正后的姓名和生日。</span><br><span class="line">        # 如果人类没有提供新的值，则使用 .get() 的默认值，即原始值。</span><br><span class="line">        verified_name = human_response.get(&quot;name&quot;, name) </span><br><span class="line">        verified_birthday = human_response.get(&quot;birthday&quot;, birthday) </span><br><span class="line">        response = f&quot;Made a correction: &#123;human_response&#125;&quot; </span><br><span class="line"></span><br><span class="line">    # 在工具内部直接构造一个用于更新图状态的字典。</span><br><span class="line">    state_update = &#123; </span><br><span class="line">        &quot;name&quot;: verified_name, # 更新状态中的 &#x27;name&#x27; 字段</span><br><span class="line">        &quot;birthday&quot;: verified_birthday, # 更新状态中的 &#x27;birthday&#x27; 字段</span><br><span class="line">        # 创建一个 ToolMessage，将其添加到状态的 &#x27;messages&#x27; 列表中。</span><br><span class="line">        # 这个消息将作为此工具调用的正式“答复”出现在对话历史中。</span><br><span class="line">        # tool_call_id 是必需的，用于将此答复与 LLM 的原始工具调用请求关联起来。</span><br><span class="line">        &quot;messages&quot;: [ToolMessage(response, tool_call_id=tool_call_id)], </span><br><span class="line">    &#125; </span><br><span class="line">    # 这个工具不返回一个简单的字符串或数字，而是返回一个 Command 对象。</span><br><span class="line">    # Command(update=...) 是一个明确的指令，告诉 LangGraph 执行器：</span><br><span class="line">    # “请不要将我的返回值当作普通工具输出，而是用 state_update 字典里的内容来直接更新当前的图状态。”</span><br><span class="line">    return Command(update=state_update) </span><br></pre></td></tr></table></figure>
<p>图的其余部分保持不变。</p>
<h4 id="提示聊天机器人调用人工审查"><a href="#提示聊天机器人调用人工审查" class="headerlink" title="提示聊天机器人调用人工审查"></a>提示聊天机器人调用人工审查</h4><p>提示聊天机器人查找 LangGraph 库的“生日”，并在其获取所需信息后，指示聊天机器人使用 <code>human_assistance</code> 工具。通过在工具参数中设置 <code>name</code> 和 <code>birthday</code>，您将强制聊天机器人为这些字段生成提议。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">user_input = (</span><br><span class="line">    &quot;你能查一下 LangGraph 是什么时候发布的吗？ &quot;</span><br><span class="line">    &quot;当你有了答案后，使用 human_assistance 工具进行审查。&quot;</span><br><span class="line">)</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>我们再次在 <code>human_assistance</code> 工具中触发了 <code>interrupt</code>。</p>
<h4 id="添加人工协助"><a href="#添加人工协助" class="headerlink" title="添加人工协助"></a>添加人工协助</h4><p>聊天机器人未能识别正确的日期，因此为其提供信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">human_command = Command(</span><br><span class="line">    resume=&#123;</span><br><span class="line">        &quot;name&quot;: &quot;LangGraph&quot;,</span><br><span class="line">        &quot;birthday&quot;: &quot;Jan 17, 2024&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">events = graph.stream(human_command, config, stream_mode=&quot;values&quot;)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>请注意，这些字段现在已反映在状态中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">snapshot = graph.get_state(config)</span><br><span class="line"></span><br><span class="line">&#123;k: v for k, v in snapshot.values.items() if k in (&quot;name&quot;, &quot;birthday&quot;)&#125;</span><br></pre></td></tr></table></figure>
<p>这使得下游节点（例如，进一步处理或存储信息的节点）可以轻松访问它们。</p>
<h3 id="时间功能（从之前的某个状态开始）"><a href="#时间功能（从之前的某个状态开始）" class="headerlink" title="时间功能（从之前的某个状态开始）"></a>时间功能（从之前的某个状态开始）</h3><p>在典型的聊天机器人工作流程中，用户与机器人进行一次或多次交互以完成任务。<a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/tutorials/get-started/3-add-memory/">记忆</a>和<a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/tutorials/get-started/4-human-in-the-loop/">人工干预</a>功能可以为图状态启用检查点并控制未来的响应。</p>
<p>如果您希望用户能够从之前的响应开始并探索不同的结果，该怎么办？或者，如果您希望用户能够回溯聊天机器人的工作以纠正错误或尝试不同的策略，这在自主软件工程师等应用程序中很常见，那又该怎么办？</p>
<p>您可以使用 LangGraph 内置的<strong>时光旅行</strong>功能创建这些类型的体验。</p>
<h4 id="回溯您的图"><a href="#回溯您的图" class="headerlink" title="回溯您的图"></a>回溯您的图</h4><p>通过使用图的<code>get_state_history</code>方法获取检查点来回溯您的图。然后，您可以从之前的这个时间点恢复执行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 初始化一个变量 to_replay 为 None，它将用于存储我们想要“时间旅行”回去的特定状态。</span><br><span class="line"># to_replay 将在循环中被赋值为我们感兴趣的那个历史状态快照。</span><br><span class="line">to_replay = None</span><br><span class="line"></span><br><span class="line"># 遍历 `graph` 在给定 `config` 下的所有历史状态。</span><br><span class="line"># `graph.get_state_history(config)` 会返回一个迭代器，其中包含了从开始到当前的所有状态快照。</span><br><span class="line">for state in graph.get_state_history(config):</span><br><span class="line">    # 打印当前状态快照中的一些信息，以便我们观察和选择。</span><br><span class="line">    # `len(state.values[&quot;messages&quot;])` 显示了到该状态为止，对话历史中的消息总数。</span><br><span class="line">    # `state.next` 显示了在该状态之后，图将要执行的下一个节点或步骤的名称。</span><br><span class="line">    print(&quot;Num Messages: &quot;, len(state.values[&quot;messages&quot;]), &quot;Next: &quot;, state.next)</span><br><span class="line">    </span><br><span class="line">    # 打印一条分隔线，使输出更易读。</span><br><span class="line">    print(&quot;-&quot; * 80)</span><br><span class="line">    </span><br><span class="line">    # 这里是选择“时间旅行”目标点的关键逻辑。</span><br><span class="line">    # 我们设定一个条件：当对话历史中的消息数量正好等于4时，我们就找到了想要回到的那个点。</span><br><span class="line">    # 这是一个为了演示而设定的任意条件，在实际应用中，您可以根据需要设置更复杂的选择逻辑。</span><br><span class="line">    if len(state.values[&quot;messages&quot;]) == 4:</span><br><span class="line">        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.</span><br><span class="line">        # 将当前这个符合条件的状态（state）保存到 to_replay 变量中。</span><br><span class="line">        # 循环结束后，to_replay 变量将持有我们选中的那个历史时刻的完整状态，</span><br><span class="line">        # 之后我们就可以用它来恢复或修改执行流程。</span><br><span class="line">        to_replay = state</span><br></pre></td></tr></table></figure>
<p>图的每一步都会保存检查点。这<strong>跨越了调用</strong>，因此您可以回溯整个线程的历史。</p>
<h4 id="从特定时间点加载状态"><a href="#从特定时间点加载状态" class="headerlink" title="从特定时间点加载状态"></a>从特定时间点加载状态</h4><p>从<code>to_replay</code>状态恢复。从这一点恢复将接下来调用<strong>action</strong>节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(to_replay.next)</span><br><span class="line">print(to_replay.config)</span><br></pre></td></tr></table></figure>
<p>检查点的<code>to_replay.config</code>包含一个<code>checkpoint_id</code>时间戳。提供此<code>checkpoint_id</code>值会告诉 LangGraph 的检查点器从该时间点<strong>加载</strong>状态。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, to_replay.config, stream_mode=&quot;values&quot;):</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h3 id="运行本地服务器"><a href="#运行本地服务器" class="headerlink" title="运行本地服务器"></a>运行本地服务器</h3><h4 id="安装-LangGraph-CLI"><a href="#安装-LangGraph-CLI" class="headerlink" title="安装 LangGraph CLI"></a>安装 LangGraph CLI</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Python &gt;= 3.11 is required.</span><br><span class="line"></span><br><span class="line">pip install --upgrade &quot;langgraph-cli[inmem]&quot;</span><br></pre></td></tr></table></figure>
<h4 id="创建-LangGraph-应用-🌱"><a href="#创建-LangGraph-应用-🌱" class="headerlink" title="创建 LangGraph 应用 🌱"></a>创建 LangGraph 应用 🌱</h4><p>从 <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/new-langgraph-project"><code>new-langgraph-project-python</code> 模板</a> 或 <a target="_blank" rel="noopener" href="https://github.com/langchain-ai/new-langgraphjs-project"><code>new-langgraph-project-js</code> 模板</a> 创建一个新应用。此模板展示了一个单节点应用程序，您可以根据自己的逻辑进行扩展。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">langgraph new . --template new-langgraph-project-python</span><br></pre></td></tr></table></figure>
<blockquote>
<p>使用 <code>langgraph new</code> 而不指定模板，系统将显示一个交互式菜单，您可以从中选择可用的模板列表。</p>
</blockquote>
<h4 id="使用uv安装依赖项"><a href="#使用uv安装依赖项" class="headerlink" title="使用uv安装依赖项"></a>使用uv安装依赖项</h4><p>uv 是一个用 Rust 编写的极速 Python 包和项目管理器 。它旨在解决传统 Python 包管理工具（如 pip 、 poetry 等）在速度和效率方面的痛点，提供更快的安装、依赖解析和环境管理。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install uv#安装uv</span><br></pre></td></tr></table></figure>
<p>运行<code>uv sync</code>会根据 <code>pyproject.toml</code>的依赖创建虚拟环境并安装依赖</p>
<blockquote>
<p><code>pyproject.toml</code> 文件是 Python 项目中用于统一配置项目元数据、构建系统、依赖管理和各种工具设置的标准化文件。它通常用于替代旧的 requirements.txt 文件，提供更现代和集中的项目配置方式。</p>
</blockquote>
<h4 id="创建一个-env-文件"><a href="#创建一个-env-文件" class="headerlink" title="创建一个 .env 文件"></a>创建一个 <code>.env</code> 文件</h4><p>您将在新 LangGraph 应用的根目录下找到一个 <code>.env.example</code> 文件。在新 LangGraph 应用的根目录下创建一个 <code>.env</code> 文件，并将 <code>.env.example</code> 文件的内容复制到其中，填入所需的 API 密钥。</p>
<p>添加环境变量如LANGSMITH_API_KEY，OPENAI_API_KEY等</p>
<h4 id="启动-LangGraph-服务器"><a href="#启动-LangGraph-服务器" class="headerlink" title="启动 LangGraph 服务器"></a>启动 LangGraph 服务器</h4><p>在本地启动 LangGraph API 服务器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">langgraph dev</span><br></pre></td></tr></table></figure>
<p>示例输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;    Ready!</span><br><span class="line">&gt;</span><br><span class="line">&gt;    - API: [https://:2024](https://:2024/)</span><br><span class="line">&gt;</span><br><span class="line">&gt;    - Docs: https://:2024/docs</span><br><span class="line">&gt;</span><br><span class="line">&gt;    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024</span><br></pre></td></tr></table></figure>
<p>LangGraph 服务器（如您通过 langgraph dev 命令启动的服务器）的主要作用是提供一个运行环境和接口，用于开发、测试、部署和管理基于 LangGraph 构建的 AI 代理和应用程序。具体来说，它有以下几个主要用途：</p>
<ol>
<li>API 接口暴露 ：它将您用 LangGraph 定义的复杂代理逻辑（即图结构）通过标准的 RESTful API 接口暴露出来。这意味着其他应用程序、前端界面或者其他服务可以通过 HTTP 请求与您的 LangGraph 代理进行交互，而无需直接集成 LangGraph 的 Python 代码。</li>
<li>简化部署 ：通过将 LangGraph 应用程序打包成一个可运行的服务，您可以更容易地将其部署到云服务器、容器（如 Docker）或其他生产环境中。这使得 LangGraph 代理可以作为一个独立的微服务运行，方便扩展和管理。</li>
<li><p>开发和调试便利 ：</p>
<ul>
<li>实时预览和调试 ：服务器通常会提供一个 Studio UI（如您在 <a target="_blank" rel="noopener" href="http://127.0.0.1:2024/studio">http://127.0.0.1:2024/studio</a> 看到的），让开发者能够可视化地查看代理的图结构、执行流程、状态变化和中间步骤，这对于理解和调试复杂的代理行为至关重要。</li>
<li>API 文档 ：自动生成的 API 文档（如 <a target="_blank" rel="noopener" href="http://127.0.0.1:2024/docs">http://127.0.0.1:2024/docs</a> ）提供了所有可用接口的详细说明和交互式测试功能，极大地加速了开发和集成过程。</li>
</ul>
</li>
<li>状态管理和持久化 ：LangGraph 代理通常涉及复杂的状态管理。服务器可以负责处理这些状态的持久化，确保代理在多次交互之间能够记住上下文和历史信息。</li>
</ol>
<h4 id="在-LangGraph-Studio-中测试您的应用程序"><a href="#在-LangGraph-Studio-中测试您的应用程序" class="headerlink" title="在 LangGraph Studio 中测试您的应用程序"></a>在 LangGraph Studio 中测试您的应用程序</h4><p><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/langgraph_studio/">LangGraph Studio</a> 是一个专门的 UI，您可以连接到 LangGraph API 服务器，以便在本地可视化、交互和调试您的应用程序。通过访问 <code>langgraph dev</code> 命令输出中提供的 URL，在 LangGraph Studio 中测试您的图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/tutorials/get-started/1-build-basic-chatbot/#1-install-packages">构建一个基本聊天机器人 - LangChain 框架</a></p>
<p>官方教程，但是英文<a target="_blank" rel="noopener" href="https://academy.langchain.com/collections">https://academy.langchain.com/collections</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1AY4aeRETY/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">3.5 小时出证！LangGraph 官方课程 🆓 重磅上线🔥🔥🔥_哔哩哔哩_bilibili</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/" class="post-title-link" itemprop="url">langgraph查漏补缺</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-15 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-15T00:00:00+08:00">2025-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-04 17:13:58" itemprop="dateModified" datetime="2025-08-04T17:13:58+08:00">2025-08-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="注入上下文"><a href="#注入上下文" class="headerlink" title="注入上下文"></a>注入上下文</h3><p>“注入上下文”就是<strong>在运行过程中节点/大模型</strong> 可能需要、但<strong>不会</strong>（也不应该）去改变的<strong>只读信息</strong>的集合。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>场景</th>
<th>注入上下文里可能放什么</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>权限控制</strong></td>
<td><code>user_id</code>, <code>tenant_id</code>（决定能访问哪些数据）</td>
</tr>
<tr>
<td><strong>外部依赖</strong></td>
<td><code>db_connection</code>, <code>api_key</code>, <code>s3_bucket</code>（节点里要用）</td>
</tr>
<tr>
<td><strong>个性化参数</strong></td>
<td><code>language</code>, <code>timezone</code>, <code>model_temperature</code></td>
</tr>
<tr>
<td><strong>会话元信息</strong></td>
<td><code>session_id</code>, <code>channel</code>（Slack / 微信 / Web）</td>
</tr>
</tbody>
</table>
</div>
<h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line"></span><br><span class="line">from langgraph.graph import StateGraph</span><br><span class="line">from langgraph.runtime import Runtime</span><br><span class="line"></span><br><span class="line">@dataclass</span><br><span class="line">class Context:</span><br><span class="line">    &quot;&quot;&quot;Context schema defined by the developer.&quot;&quot;&quot;    </span><br><span class="line">    user_id: str    </span><br><span class="line">    db_connection: str</span><br><span class="line">    </span><br><span class="line">def node(state: State, runtime: Runtime[Context]):</span><br><span class="line">    # type safe access to context attributes    </span><br><span class="line">    user_id = runtime.context.user_id</span><br><span class="line">    db_conn = runtime.context.db_connection</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">builder = StateGraph(state_schema=State, context_schema=Context)</span><br><span class="line"></span><br><span class="line"># add nodes, edges, compile the graph...</span><br><span class="line"></span><br><span class="line"># top level context arg is typed as Context for autocomplete and type checking</span><br><span class="line">result = graph.invoke(</span><br><span class="line">    &#123;&#x27;input&#x27;: &#x27;abc&#x27;&#125;,</span><br><span class="line">    context=Context(user_id=&#x27;123&#x27;, db_conn=&#x27;conn_mock&#x27;)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/runtime/#runtime"><code>Runtime</code></a> 类提供了一个单一接口，用于访问信息，例如：</p>
<ul>
<li>上下文：在运行开始时传递的静态数据</li>
<li>存储：长期记忆的存储机制</li>
<li>流写入器：用于向图输出流写入的自定义函数</li>
<li>对于功能 API 用户，<code>previous</code> 也可用：给定线程的前一个返回值</li>
</ul>
<p>现在，开发者不再需要将上述所有内容作为单独的参数注入到节点函数中，<br>而是可以通过一个 <code>runtime</code> 参数来访问它们。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langsmith/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langsmith/" class="post-title-link" itemprop="url">Langsmith</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-07-15 00:00:00 / 修改时间：17:55:00" itemprop="dateCreated datePublished" datetime="2025-07-15T00:00:00+08:00">2025-07-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langsmith/" itemprop="url" rel="index"><span itemprop="name">langsmith</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="配置langsmith"><a href="#配置langsmith" class="headerlink" title="配置langsmith"></a>配置langsmith</h3><h4 id="安装LangSmith-SDK"><a href="#安装LangSmith-SDK" class="headerlink" title="安装LangSmith SDK"></a>安装LangSmith SDK</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install langsmith</span><br></pre></td></tr></table></figure>
<h4 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h4><p>获取api<a target="_blank" rel="noopener" href="https://smith.langchain.com/o/56031c2a-c402-41d4-83ed-ed15d0693548/settings/apikeys">LangSmith</a></p>
<p>设置相应的环境变量。这将把跟踪记录到<code>default</code>项目（尽管您可以轻松更改）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export LANGSMITH_TRACING=true</span><br><span class="line">export LANGSMITH_API_KEY=</span><br><span class="line">export LANGSMITH_PROJECT=default</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">LANGSMITH_TRACING=true</span><br><span class="line">LANGSMITH_ENDPOINT=&quot;https://api.smith.langchain.com&quot;</span><br><span class="line">LANGSMITH_API_KEY=&quot;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&quot;</span><br><span class="line">LANGSMITH_PROJECT=&quot;langgraph&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h3><p>官网<a target="_blank" rel="noopener" href="https://smith.langchain.com/o/56031c2a-c402-41d4-83ed-ed15d0693548/">《LangSmith》 —- LangSmith</a></p>
<p>参考文档<a target="_blank" rel="noopener" href="https://langsmith.langchain.ac.cn/">LangSmith 入门 | 🦜️🛠️ LangSmith 文档</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.smith.langchain.com/">Get started with LangSmith | 🦜️🛠️ LangSmith</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">张熙浚</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="本站访问数 fa fa-user 次"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="本站总访问量 fa fa-eye 次"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="400" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
