<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="zxj Blogs">
<meta property="og:type" content="website">
<meta property="og:title" content="Zhang XiJun">
<meta property="og:url" content="http://example.com/page/6/index.html">
<meta property="og:site_name" content="Zhang XiJun">
<meta property="og:description" content="zxj Blogs">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="张熙浚">
<meta property="article:tag" content="zxj">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/6/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/6/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Zhang XiJun</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhang XiJun</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">BLOGS</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="张熙浚"
      src="/images/zxjavatar.gif">
  <p class="site-author-name" itemprop="name">张熙浚</p>
  <div class="site-description" itemprop="description">zxj Blogs</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">164</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">60</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">61</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zxj-2023" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxj-2023" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=2902065320&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;2902065320&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener me" target="_blank"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zxj-2023.github.io/" title="https:&#x2F;&#x2F;zxj-2023.github.io" rel="noopener" target="_blank">Zhang XiJun</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org" rel="noopener" target="_blank">NexT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/08/01/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/08/01/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/" class="post-title-link" itemprop="url">MCP 客户端实战</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-08-01 00:00:00 / 修改时间：17:03:38" itemprop="dateCreated datePublished" datetime="2025-08-01T00:00:00+08:00">2025-08-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/mcp/" itemprop="url" rel="index"><span itemprop="name">mcp</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="配置环境">配置环境</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 创建项目目录</span><br><span class="line">uv init mcp-client</span><br><span class="line">cd mcp-client</span><br><span class="line"></span><br><span class="line"># 创建虚拟环境</span><br><span class="line">uv venv</span><br><span class="line"></span><br><span class="line"># 激活虚拟环境</span><br><span class="line"># 在 Windows 上:</span><br><span class="line">.venv\Scripts\activate</span><br><span class="line"># 在 Unix 或 MacOS 上:</span><br><span class="line">source .venv/bin/activate</span><br><span class="line"></span><br><span class="line"># 安装所需包</span><br><span class="line">uv add mcp anthropic python-dotenv</span><br><span class="line">#使用镜像源安装</span><br><span class="line">uv add mcp anthropic python-dotenv --index-url https://pypi.tuna.tsinghua.edu.cn/simple/</span><br><span class="line"></span><br><span class="line"># 删除样板文件</span><br><span class="line"># 在 Windows 上:</span><br><span class="line">del main.py</span><br><span class="line"># 在 Unix 或 MacOS 上:</span><br><span class="line">rm main.py</span><br><span class="line"></span><br><span class="line"># 创建我们的主文件</span><br><span class="line">touch client.py</span><br></pre></td></tr></table></figure>
<h3 id="设置-api-密钥">设置 API 密钥</h3>
<p>创建一个 <code>.env</code> 文件来存储它：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Create .env file</span><br><span class="line">touch .env</span><br></pre></td></tr></table></figure>
<p>将您的密钥添加到 <code>.env</code> 文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ANTHROPIC_API_KEY=&lt;your key here&gt;</span><br></pre></td></tr></table></figure>
<p>将 <code>.env</code> 添加到您的 <code>.gitignore</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;.env&quot; &gt;&gt; .gitignore</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将 <code>.env</code> 文件名添加到 <code>.gitignore</code>
文件中，这样 Git 就会忽略 <code>.env</code>
文件，不会将其纳入版本控制。</p>
</blockquote>
<h3 id="创建客户端">创建客户端</h3>
<h4 id="基本客户端结构">基本客户端结构</h4>
<p>首先，让我们设置我们的导入并创建基本的客户端类：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">from typing import Optional</span><br><span class="line">from contextlib import AsyncExitStack</span><br><span class="line"></span><br><span class="line">from mcp import ClientSession, StdioServerParameters</span><br><span class="line">from mcp.client.stdio import stdio_client</span><br><span class="line"></span><br><span class="line">from anthropic import Anthropic</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line"></span><br><span class="line">load_dotenv()  # 从 .env 文件加载环境变量</span><br><span class="line"></span><br><span class="line">class MCPClient:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        # 初始化会话和客户端对象</span><br><span class="line">        self.session: Optional[ClientSession] = None  # MCP客户端会话</span><br><span class="line">        self.exit_stack = AsyncExitStack()  # 异步上下文管理器堆栈，用于资源清理</span><br><span class="line">        self.anthropic = Anthropic()  # Anthropic AI 客户端</span><br><span class="line">        </span><br><span class="line">    # 后续方法将在这里定义</span><br></pre></td></tr></table></figure>
<h4 id="服务器连接管理">服务器连接管理</h4>
<p>接下来，我们将实现连接到 MCP 服务器的功能：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">async def connect_to_server(self, server_script_path: str):</span><br><span class="line">    &quot;&quot;&quot;连接到MCP服务器</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        server_script_path: 服务器脚本路径 (.py 或 .js 文件)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 检查是否为Python文件</span><br><span class="line">    is_python = server_script_path.endswith(&#x27;.py&#x27;)</span><br><span class="line">    # 检查是否为JavaScript文件</span><br><span class="line">    is_js = server_script_path.endswith(&#x27;.js&#x27;)</span><br><span class="line">    </span><br><span class="line">    # 如果不是Python或JavaScript文件，则抛出错误</span><br><span class="line">    if not (is_python or is_js):</span><br><span class="line">        raise ValueError(&quot;服务器脚本必须是 .py 或 .js 文件&quot;)</span><br><span class="line"></span><br><span class="line">    # 根据文件类型确定执行命令</span><br><span class="line">    command = &quot;python&quot; if is_python else &quot;node&quot;</span><br><span class="line">    </span><br><span class="line">    # 创建服务器参数对象</span><br><span class="line">    server_params = StdioServerParameters(</span><br><span class="line">        command=command,           # 执行命令</span><br><span class="line">        args=[server_script_path], # 脚本路径作为参数</span><br><span class="line">        env=None                   # 环境变量（使用默认环境）</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 建立stdio客户端连接并将其添加到异步上下文管理器中</span><br><span class="line">    stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))</span><br><span class="line">    self.stdio, self.write = stdio_transport</span><br><span class="line">    </span><br><span class="line">    # 创建客户端会话并将其添加到异步上下文管理器中</span><br><span class="line">    self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))</span><br><span class="line"></span><br><span class="line">    # 初始化会话</span><br><span class="line">    await self.session.initialize()</span><br><span class="line"></span><br><span class="line">    # 列出可用的工具</span><br><span class="line">    response = await self.session.list_tools()</span><br><span class="line">    tools = response.tools</span><br><span class="line">    </span><br><span class="line">    # 打印连接的服务器提供的工具列表</span><br><span class="line">    print(&quot;\n已连接到服务器，可用工具:&quot;, [tool.name for tool in tools])</span><br></pre></td></tr></table></figure>
<h4 id="查询处理逻辑">查询处理逻辑</h4>
<p>现在让我们添加处理查询和调用工具的核心功能：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">async def process_query(self, query: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;使用Claude和可用工具处理查询&quot;&quot;&quot;</span><br><span class="line">    # 构建消息列表</span><br><span class="line">    messages = [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;role&quot;: &quot;user&quot;,      # 用户角色</span><br><span class="line">            &quot;content&quot;: query     # 用户查询内容</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    # 获取可用工具列表</span><br><span class="line">    response = await self.session.list_tools()</span><br><span class="line">    available_tools = [&#123;</span><br><span class="line">        &quot;name&quot;: tool.name,           # 工具名称</span><br><span class="line">        &quot;description&quot;: tool.description,  # 工具描述</span><br><span class="line">        &quot;input_schema&quot;: tool.inputSchema  # 工具输入模式</span><br><span class="line">    &#125; for tool in response.tools]</span><br><span class="line"></span><br><span class="line">    # 初始Claude API调用</span><br><span class="line">    response = self.anthropic.messages.create(</span><br><span class="line">        model=&quot;qwen3-235b-a22b&quot;,  # 使用的模型</span><br><span class="line">        max_tokens=1000,                     # 最大返回令牌数</span><br><span class="line">        messages=messages,                   # 消息历史</span><br><span class="line">        tools=available_tools               # 可用工具</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 处理响应并处理工具调用</span><br><span class="line">    final_text = []  # 存储最终文本结果</span><br><span class="line"></span><br><span class="line">    assistant_message_content = []  # 存储助手消息内容</span><br><span class="line">    for content in response.content:  # 遍历响应内容</span><br><span class="line">        if content.type == &#x27;text&#x27;:  # 如果是文本内容</span><br><span class="line">            final_text.append(content.text)  # 添加到最终结果</span><br><span class="line">            assistant_message_content.append(content)  # 添加到助手消息</span><br><span class="line">        elif content.type == &#x27;tool_use&#x27;:  # 如果是工具调用</span><br><span class="line">            tool_name = content.name    # 工具名称</span><br><span class="line">            tool_args = content.input   # 工具参数</span><br><span class="line"></span><br><span class="line">            # 执行工具调用</span><br><span class="line">            result = await self.session.call_tool(tool_name, tool_args)</span><br><span class="line">            final_text.append(f&quot;[调用工具 &#123;tool_name&#125;，参数 &#123;tool_args&#125;]&quot;)</span><br><span class="line"></span><br><span class="line">            assistant_message_content.append(content)</span><br><span class="line">            # 添加助手消息到历史</span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                &quot;content&quot;: assistant_message_content</span><br><span class="line">            &#125;)</span><br><span class="line">            # 添加工具执行结果到历史</span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;tool_result&quot;,      # 工具结果类型</span><br><span class="line">                        &quot;tool_use_id&quot;: content.id,  # 工具使用ID</span><br><span class="line">                        &quot;content&quot;: result.content   # 工具执行结果</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">            # 获取Claude的下一个响应</span><br><span class="line">            response = self.anthropic.messages.create(</span><br><span class="line">                model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">                max_tokens=1000,</span><br><span class="line">                messages=messages,</span><br><span class="line">                tools=available_tools</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            # 添加响应文本到最终结果</span><br><span class="line">            final_text.append(response.content[0].text)</span><br><span class="line"></span><br><span class="line">    # 返回连接后的最终文本结果</span><br><span class="line">    return &quot;\n&quot;.join(final_text)</span><br></pre></td></tr></table></figure>
<h4 id="交互式聊天界面">交互式聊天界面</h4>
<p>现在我们将添加聊天循环和清理功能：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">async def chat_loop(self):</span><br><span class="line">    &quot;&quot;&quot;运行交互式聊天循环&quot;&quot;&quot;</span><br><span class="line">    print(&quot;\nMCP客户端已启动!&quot;)</span><br><span class="line">    print(&quot;输入您的问题或输入&#x27;quit&#x27;退出。&quot;)</span><br><span class="line"></span><br><span class="line">    while True:  # 无限循环，持续接收用户输入</span><br><span class="line">        try:</span><br><span class="line">            query = input(&quot;\n问题: &quot;).strip()  # 获取用户输入并去除首尾空格</span><br><span class="line"></span><br><span class="line">            if query.lower() == &#x27;quit&#x27;:  # 如果用户输入&#x27;quit&#x27;（不区分大小写）</span><br><span class="line">                break  # 退出循环</span><br><span class="line"></span><br><span class="line">            # 处理用户查询并获取响应</span><br><span class="line">            response = await self.process_query(query)</span><br><span class="line">            print(&quot;\n&quot; + response)  # 打印AI响应结果</span><br><span class="line"></span><br><span class="line">        except Exception as e:  # 捕获所有异常</span><br><span class="line">            print(f&quot;\n错误: &#123;str(e)&#125;&quot;)  # 打印错误信息</span><br><span class="line"></span><br><span class="line">async def cleanup(self):</span><br><span class="line">    &quot;&quot;&quot;清理资源&quot;&quot;&quot;</span><br><span class="line">    await self.exit_stack.aclose()  # 异步关闭所有在exit_stack中管理的资源</span><br></pre></td></tr></table></figure>
<h4 id="主入口点">主入口点</h4>
<p>最后，我们将添加主要的执行逻辑：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">async def main():</span><br><span class="line">    # 检查命令行参数数量，如果少于2个则显示使用说明</span><br><span class="line">    if len(sys.argv) &lt; 2:</span><br><span class="line">        print(&quot;用法: python client.py &lt;服务器脚本路径&gt;&quot;)</span><br><span class="line">        sys.exit(1)  # 退出程序，返回错误码1</span><br><span class="line"></span><br><span class="line">    # 创建MCP客户端实例</span><br><span class="line">    client = MCPClient()</span><br><span class="line">    try:</span><br><span class="line">        # 连接到服务器，sys.argv[1]是第一个命令行参数（服务器脚本路径）</span><br><span class="line">        await client.connect_to_server(sys.argv[1])</span><br><span class="line">        # 启动交互式聊天循环</span><br><span class="line">        await client.chat_loop()</span><br><span class="line">    finally:</span><br><span class="line">        # 确保程序结束时清理资源</span><br><span class="line">        await client.cleanup()</span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    import sys  # 导入sys模块用于处理命令行参数</span><br><span class="line">    # 运行异步主函数</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/08/01/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/QQ20250801-164738.png" alt="QQ20250801-164738">
<figcaption aria-hidden="true">QQ20250801-164738</figcaption>
</figure>
<h3 id="运行客户端">运行客户端</h3>
<p>要使您的客户端与任何 MCP 服务器运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">uv run client.py path/to/server.py # python server</span><br><span class="line">uv run client.py path/to/build/index.js # node server</span><br></pre></td></tr></table></figure>
<p>客户端将：</p>
<ol type="1">
<li>连接到指定服务器</li>
<li>列出可用工具</li>
<li>开始一个交互式聊天会话，您可以在其中：
<ul>
<li>输入查询</li>
<li>查看工具执行情况</li>
<li>从 Claude 获取响应</li>
</ul></li>
</ol>
<h3 id="运作流程">运作流程</h3>
<p>当你提交查询时：</p>
<ol type="1">
<li>客户端从服务器获取可用工具列表</li>
<li>你的查询连同工具描述一起发送给 Claude</li>
<li>Claude 决定使用哪些工具（如果有的话）</li>
<li>客户端通过服务器执行任何请求的工具调用</li>
<li>结果会发送回 Claude</li>
<li>Claude 提供自然语言响应</li>
<li>响应显示给您</li>
</ol>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://modelcontextprotocol.io/quickstart/client#main-entry-point">Build
an MCP Client - Model Context Protocol</a></p>
<h3 id="适配openai版本">适配openai版本</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import json</span><br><span class="line">import sys</span><br><span class="line">from typing import Optional</span><br><span class="line">from contextlib import AsyncExitStack</span><br><span class="line"></span><br><span class="line">from mcp import ClientSession, StdioServerParameters</span><br><span class="line">from mcp.client.stdio import stdio_client</span><br><span class="line"></span><br><span class="line">from openai import OpenAI</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">load_dotenv()  # 从 .env 文件加载环境变量</span><br><span class="line"></span><br><span class="line">class MCPClient:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        # 初始化会话和客户端对象</span><br><span class="line">        self.session: Optional[ClientSession] = None  # MCP客户端会话</span><br><span class="line">        self.exit_stack = AsyncExitStack()  # 异步上下文管理器堆栈，用于资源清理</span><br><span class="line">        self.anthropic = OpenAI(</span><br><span class="line">            api_key=os.getenv(&quot;DASHSCOPE_API_KEY&quot;),</span><br><span class="line">            base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">        )  # 使用OpenAI兼容模式连接通义千问</span><br><span class="line">        </span><br><span class="line">    async def connect_to_server(self, server_script_path: str):</span><br><span class="line">        &quot;&quot;&quot;连接到MCP服务器</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            server_script_path (str): 服务器脚本路径，支持.py或.js文件</span><br><span class="line">        </span><br><span class="line">        Raises:</span><br><span class="line">            ValueError: 当脚本文件不是.py或.js格式时抛出</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 检查是否为Python文件</span><br><span class="line">        is_python = server_script_path.endswith(&#x27;.py&#x27;)</span><br><span class="line">        # 检查是否为JavaScript文件</span><br><span class="line">        is_js = server_script_path.endswith(&#x27;.js&#x27;)</span><br><span class="line">        </span><br><span class="line">        # 如果不是Python或JavaScript文件，则抛出错误</span><br><span class="line">        if not (is_python or is_js):</span><br><span class="line">            raise ValueError(&quot;服务器脚本必须是 .py 或 .js 文件&quot;)</span><br><span class="line"></span><br><span class="line">        # 根据文件类型确定执行命令</span><br><span class="line">        command = &quot;python&quot; if is_python else &quot;node&quot;</span><br><span class="line">        </span><br><span class="line">        # 创建服务器参数对象</span><br><span class="line">        server_params = StdioServerParameters(</span><br><span class="line">            command=command,           # 执行命令</span><br><span class="line">            args=[server_script_path], # 脚本路径作为参数</span><br><span class="line">            env=None                   # 环境变量（使用默认环境）</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 建立stdio客户端连接并将其添加到异步上下文管理器中</span><br><span class="line">        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))</span><br><span class="line">        self.stdio, self.write = stdio_transport</span><br><span class="line">        </span><br><span class="line">        # 创建客户端会话并将其添加到异步上下文管理器中</span><br><span class="line">        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))</span><br><span class="line"></span><br><span class="line">        # 初始化会话</span><br><span class="line">        await self.session.initialize()</span><br><span class="line"></span><br><span class="line">        # 列出可用的工具</span><br><span class="line">        response = await self.session.list_tools()</span><br><span class="line">        tools = response.tools</span><br><span class="line">        </span><br><span class="line">        # 打印连接的服务器提供的工具列表</span><br><span class="line">        print(&quot;\n已连接到服务器，可用工具:&quot;, [tool.name for tool in tools])</span><br><span class="line"></span><br><span class="line">    async def process_query(self, query: str) -&gt; str:</span><br><span class="line">        &quot;&quot;&quot;使用Qwen和可用工具处理查询&quot;&quot;&quot;</span><br><span class="line">        # 构建消息列表</span><br><span class="line">        messages = [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: query</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        # 获取可用工具列表并转换为OpenAI格式</span><br><span class="line">        response = await self.session.list_tools()</span><br><span class="line">        available_tools = []</span><br><span class="line">        for tool in response.tools:</span><br><span class="line">            schema = tool.inputSchema</span><br><span class="line">            if isinstance(schema, str):</span><br><span class="line">                schema = json.loads(schema)</span><br><span class="line">            if isinstance(schema, dict) and &quot;properties&quot; in schema:</span><br><span class="line">                schema = &#123;&quot;type&quot;: &quot;object&quot;, **schema&#125;</span><br><span class="line"></span><br><span class="line">            available_tools.append(&#123;</span><br><span class="line">                &quot;type&quot;: &quot;function&quot;,</span><br><span class="line">                &quot;function&quot;: &#123;</span><br><span class="line">                    &quot;name&quot;: tool.name,</span><br><span class="line">                    &quot;description&quot;: tool.description,</span><br><span class="line">                    &quot;parameters&quot;: schema</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">        # 第一次调用模型</span><br><span class="line">        response = self.anthropic.chat.completions.create(</span><br><span class="line">            model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">            max_tokens=1000,</span><br><span class="line">            messages=messages,</span><br><span class="line">            tools=available_tools,</span><br><span class="line">            extra_body=&#123;&quot;enable_thinking&quot;: False&#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        final_text = []</span><br><span class="line">        message = response.choices[0].message</span><br><span class="line"></span><br><span class="line">        # 处理文本内容</span><br><span class="line">        if message.content:</span><br><span class="line">            final_text.append(message.content)</span><br><span class="line"></span><br><span class="line">        # 处理工具调用</span><br><span class="line">        if message.tool_calls:</span><br><span class="line">            for tool_call in message.tool_calls:</span><br><span class="line">                tool_name = tool_call.function.name</span><br><span class="line">                tool_args = json.loads(tool_call.function.arguments)</span><br><span class="line">                </span><br><span class="line">                # 执行工具调用</span><br><span class="line">                result = await self.session.call_tool(tool_name, tool_args)</span><br><span class="line">                final_text.append(f&quot;[调用工具 &#123;tool_name&#125;，参数 &#123;tool_args&#125;]&quot;)</span><br><span class="line">                </span><br><span class="line">                # 处理工具结果</span><br><span class="line">                tool_result_content = &quot;&quot;</span><br><span class="line">                if result.content:</span><br><span class="line">                    for item in result.content:</span><br><span class="line">                        if hasattr(item, &#x27;type&#x27;) and item.type == &#x27;text&#x27;:</span><br><span class="line">                            tool_result_content += item.text</span><br><span class="line">                        else:</span><br><span class="line">                            tool_result_content += str(item)</span><br><span class="line"></span><br><span class="line">                # 添加助手消息到历史</span><br><span class="line">                messages.append(&#123;</span><br><span class="line">                    &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                    &quot;content&quot;: None,</span><br><span class="line">                    &quot;tool_calls&quot;: [tool_call]</span><br><span class="line">                &#125;)</span><br><span class="line">                </span><br><span class="line">                # 添加工具执行结果到历史</span><br><span class="line">                messages.append(&#123;</span><br><span class="line">                    &quot;role&quot;: &quot;tool&quot;,</span><br><span class="line">                    &quot;tool_call_id&quot;: tool_call.id,</span><br><span class="line">                    &quot;content&quot;: tool_result_content</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">                # 再次调用模型</span><br><span class="line">                response = self.anthropic.chat.completions.create(</span><br><span class="line">                    model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">                    max_tokens=1000,</span><br><span class="line">                    messages=messages,</span><br><span class="line">                    tools=available_tools,</span><br><span class="line">                    extra_body=&#123;&quot;enable_thinking&quot;: False&#125;</span><br><span class="line">                )</span><br><span class="line">                </span><br><span class="line">                # 处理最终响应</span><br><span class="line">                if response.choices and response.choices[0].message.content:</span><br><span class="line">                    final_text.append(response.choices[0].message.content)</span><br><span class="line"></span><br><span class="line">        return &quot;\n&quot;.join(final_text)</span><br><span class="line"></span><br><span class="line">    async def chat_loop(self):</span><br><span class="line">        &quot;&quot;&quot;运行交互式聊天循环&quot;&quot;&quot;</span><br><span class="line">        print(&quot;\nMCP客户端已启动!&quot;)</span><br><span class="line">        print(&quot;输入您的问题或输入&#x27;quit&#x27;退出。&quot;)</span><br><span class="line"></span><br><span class="line">        while True:  # 无限循环，持续接收用户输入</span><br><span class="line">            try:</span><br><span class="line">                query = input(&quot;\n问题: &quot;).strip()  # 获取用户输入并去除首尾空格</span><br><span class="line"></span><br><span class="line">                if query.lower() == &#x27;quit&#x27;:  # 如果用户输入&#x27;quit&#x27;（不区分大小写）</span><br><span class="line">                    break  # 退出循环</span><br><span class="line"></span><br><span class="line">                # 处理用户查询并获取响应</span><br><span class="line">                response = await self.process_query(query)</span><br><span class="line">                print(&quot;\n&quot; + response)  # 打印AI响应结果</span><br><span class="line"></span><br><span class="line">            except Exception as e:  # 捕获所有异常</span><br><span class="line">                print(f&quot;\n错误: &#123;str(e)&#125;&quot;)  # 打印错误信息</span><br><span class="line">                import traceback</span><br><span class="line">                traceback.print_exc()  # 打印详细错误信息</span><br><span class="line"></span><br><span class="line">    async def cleanup(self):</span><br><span class="line">        &quot;&quot;&quot;清理资源&quot;&quot;&quot;</span><br><span class="line">        await self.exit_stack.aclose()  # 异步关闭所有在exit_stack中管理的资源</span><br><span class="line"></span><br><span class="line">async def main():</span><br><span class="line">    # 检查命令行参数数量，如果少于2个则显示使用说明</span><br><span class="line">    if len(sys.argv) &lt; 2:</span><br><span class="line">        print(&quot;用法: python client.py &lt;服务器脚本路径&gt;&quot;)</span><br><span class="line">        sys.exit(1)  # 退出程序，返回错误码1</span><br><span class="line"></span><br><span class="line">    # 创建MCP客户端实例</span><br><span class="line">    client = MCPClient()</span><br><span class="line">    try:</span><br><span class="line">        # 连接到服务器，sys.argv[1]是第一个命令行参数（服务器脚本路径）</span><br><span class="line">        await client.connect_to_server(sys.argv[1])</span><br><span class="line">        # 启动交互式聊天循环</span><br><span class="line">        await client.chat_loop()</span><br><span class="line">    finally:</span><br><span class="line">        # 确保程序结束时清理资源</span><br><span class="line">        await client.cleanup()</span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 运行异步主函数</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>
<h3 id="openai和claude在工具调用的差异">openai和claude在工具调用的差异</h3>
<ol type="1">
<li><strong>工具格式转换修复</strong></li>
</ol>
<p><strong>问题</strong>：MCP工具格式与OpenAI API不兼容
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原错误格式</span></span><br><span class="line">available_tools = [&#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">    <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">    <span class="string">&quot;input_schema&quot;</span>: tool.inputSchema</span><br><span class="line">&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后格式（符合OpenAI规范）</span></span><br><span class="line">available_tools = [&#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">    <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">        <span class="string">&quot;parameters&quot;</span>: schema  <span class="comment"># 正确的JSON Schema格式</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure></p>
<ol start="2" type="1">
<li><strong>API响应处理修复</strong></li>
</ol>
<p><strong>问题</strong>：错误访问了OpenAI响应对象的属性
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原错误代码</span></span><br><span class="line"><span class="keyword">for</span> content <span class="keyword">in</span> response.content:  <span class="comment"># ❌ response没有content属性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后代码</span></span><br><span class="line">message = response.choices[<span class="number">0</span>].message  <span class="comment"># ✅ 正确的访问路径</span></span><br><span class="line"><span class="keyword">if</span> message.content:</span><br><span class="line">    final_text.append(message.content)</span><br><span class="line"><span class="keyword">if</span> message.tool_calls:</span><br><span class="line">    <span class="keyword">for</span> tool_call <span class="keyword">in</span> message.tool_calls:</span><br><span class="line">        <span class="comment"># 处理工具调用</span></span><br></pre></td></tr></table></figure></p>
<ol start="3" type="1">
<li><strong>工具调用结果处理修复</strong></li>
</ol>
<p><strong>问题</strong>：错误处理MCP工具调用返回的结果结构
<strong>修复</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原错误代码</span></span><br><span class="line"><span class="string">&quot;content&quot;</span>: result.content  <span class="comment"># ❌ 可能包含复杂对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后代码</span></span><br><span class="line">tool_result_content = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> result.content:</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> result.content:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(item, <span class="string">&#x27;type&#x27;</span>) <span class="keyword">and</span> item.<span class="built_in">type</span> == <span class="string">&#x27;text&#x27;</span>:</span><br><span class="line">            tool_result_content += item.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tool_result_content += <span class="built_in">str</span>(item)</span><br></pre></td></tr></table></figure>
<ol start="4" type="1">
<li><strong>消息历史构建修复</strong></li>
</ol>
<p><strong>问题</strong>：工具调用后消息历史格式不正确
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 正确的消息历史格式</span></span><br><span class="line">messages.append(&#123;</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>,</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: <span class="literal">None</span>,</span><br><span class="line">    <span class="string">&quot;tool_calls&quot;</span>: [tool_call]</span><br><span class="line">&#125;)</span><br><span class="line">messages.append(&#123;</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">    <span class="string">&quot;tool_call_id&quot;</span>: tool_call.<span class="built_in">id</span>,</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: tool_result_content</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p>
<ol start="5" type="1">
<li><strong>JSON Schema兼容性处理</strong></li>
</ol>
<p><strong>问题</strong>：MCP返回的schema可能缺少必要的根类型定义
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">schema = tool.inputSchema</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(schema, <span class="built_in">str</span>):</span><br><span class="line">    schema = json.loads(schema)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(schema, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&quot;properties&quot;</span> <span class="keyword">in</span> schema:</span><br><span class="line">    schema = &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>, **schema&#125;  <span class="comment"># 确保有根类型</span></span><br></pre></td></tr></table></figure></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/31/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/%E5%82%A8%E5%AD%98%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93Chroma/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/31/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/%E5%82%A8%E5%AD%98%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93Chroma/" class="post-title-link" itemprop="url">储存向量数据库Chroma</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-31 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-31T00:00:00+08:00">2025-07-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-19 17:16:04" itemprop="dateModified" datetime="2025-08-19T17:16:04+08:00">2025-08-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/agent%E5%AE%9E%E6%88%98/" itemprop="url" rel="index"><span itemprop="name">agent实战</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="chroma是什么">Chroma是什么</h3>
<p>Chroma（通常指 <strong>ChromaDB</strong>）是一款 <strong>开源、AI
原生的向量数据库</strong>，专为存储和检索 <strong>高维嵌入向量</strong>
而设计，目标是让开发者 <strong>5 分钟内在本地跑起一个语义搜索或 RAG
系统</strong>。</p>
<p><strong>极简安装</strong>：<code>pip install chromadb</code></p>
<p><strong>双运行模式</strong>：</p>
<ul>
<li><strong>内存模式</strong>：调试/原型随意重启；</li>
<li><strong>持久化模式</strong>：指定 <code>persist_directory</code>
即可落盘，生产也不怕丢数据。</li>
</ul>
<p><strong>HNSW 索引</strong>：百万级向量也能 <strong>毫秒级</strong>
响应。</p>
<h3 id="使用chroma存储">使用chroma存储</h3>
<h4 id="文档分块">文档分块</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from langchain.document_loaders import PyPDFLoader</span><br><span class="line">from langchain.text_splitter import RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">loader = PyPDFLoader(&quot;input/健康档案.pdf&quot;)</span><br><span class="line">docs = loader.load()</span><br><span class="line">#递归分块</span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_siz</span><br></pre></td></tr></table></figure>
<h4 id="定义embedding模型与chroma">定义embedding模型与chroma</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from langchain.vectorstores import Chroma</span><br><span class="line">from langchain_openai import OpenAIEmbeddings</span><br><span class="line">embedding = OpenAIEmbeddings(</span><br><span class="line">api_key=&quot;sk-&quot;, </span><br><span class="line">base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">model=&quot;text-embedding-v4&quot;,</span><br><span class="line">check_embedding_ctx_length = False,</span><br><span class="line">dimensions=1536</span><br><span class="line">)</span><br><span class="line"># 使用 Chroma 向量数据库存储文档 chunks</span><br><span class="line">vectorstore = Chroma.from_documents(</span><br><span class="line">    documents=chunks,           # 要存储的文档chunks列表（已处理好的文本片段）</span><br><span class="line">    embedding=embedding,        </span><br><span class="line">    persist_directory=&quot;chromaDB&quot;,  # 向量数据库的持久化存储目录路径</span><br><span class="line">    collection_name=&quot;demo001&quot;   # 集合名称，用于区分不同的文档集合</span><br><span class="line">)</span><br><span class="line">vectorstore.persist()</span><br></pre></td></tr></table></figure>
<h4 id="检索">检索</h4>
<p>这里采取直接检索进行测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">results = vectorstore.similarity_search(</span><br><span class="line">    &quot;张三九的基本信息是什么&quot;,</span><br><span class="line">    k=2,</span><br><span class="line">    collection_name=&quot;demo001&quot;  # 指定检索的集合</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="重新加载">重新加载</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 重新加载已存在的 Chroma 数据库</span><br><span class="line">vectorstore = Chroma(</span><br><span class="line">    persist_directory=&quot;./chroma_db&quot;,</span><br><span class="line">    embedding_function=embedding</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">retriever = vectorstore.as_retriever()</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/integrations/vectorstores/chroma/#add-items-to-vector-store">Chroma
| 🦜️🔗 LangChain — Chroma | 🦜️🔗 LangChain</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Plan-and-Execute%E6%A8%A1%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Plan-and-Execute%E6%A8%A1%E5%BC%8F/" class="post-title-link" itemprop="url">Plan-and-Execute模式</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-28 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-28T00:00:00+08:00">2025-07-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-27 10:01:58" itemprop="dateModified" datetime="2025-08-27T10:01:58+08:00">2025-08-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/agent%E5%AE%9E%E6%88%98/" itemprop="url" rel="index"><span itemprop="name">agent实战</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="什么是plan-and-execute模式">什么是Plan-and-Execute模式</h3>
<p>Plan-and-Execute架构流程：先指定计划，后交给执行agent，执行后交给replan节点，判断是否需要更新计划，若要更新计划返回返回更新后的机会，否则返回response，然后路由判断是执行agent还是response</p>
<p>与ReAct模式不同的是，ReAct只做一次规划，而Plan-and-Execute模式核心思想是首先制定一个多步骤计划，然后逐项执行该计划。完成特定任务后，可以重新审视计划并进行适当修改。</p>
<p>举个例子，用户在问一个问题后，agent产生一份任务清单，选取第一份任务开始执行，执行后的结果结合任务清单，执行replan，结合新的信息，更改任务清单的内容，让后续大模型更好地执行，并去除已经完成的任务</p>
<p>实际生产中，应该在planner之前再进行一次判断，如果问题过于简单，不需要进行Plan-and-Execute模式</p>
<h3 id="实战">实战</h3>
<h4 id="安装包">安装包</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --quiet -U langgraph langchain-community langchain-openai tavily-python</span><br></pre></td></tr></table></figure>
<h4 id="定义网络搜索工具与执行agent">定义网络搜索工具与执行agent</h4>
<p>在产生plan后，要有一个agent对任务清单进行执行，这里以一个ReAct的网络搜索agent为例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#定义工具</span><br><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line">tools = [TavilySearch(max_results=3)]</span><br><span class="line"></span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line">from langgraph.prebuilt import create_react_agent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=&quot;qwen3-235b-a22b-thinking-2507&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br><span class="line">prompt = &quot;You are a helpful assistant.&quot;</span><br><span class="line">agent_executor = create_react_agent(llm, tools, prompt=prompt)</span><br></pre></td></tr></table></figure>
<p>测试功能</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">agent_executor.invoke(&#123;&quot;messages&quot;: [(&quot;user&quot;, &quot;今天是几月几日&quot;)]&#125;)</span><br></pre></td></tr></table></figure>
<p>定义执行节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from typing import Literal</span><br><span class="line">from langgraph.graph import END</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">async def execute_step(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;执行计划中的步骤&quot;&quot;&quot;</span><br><span class="line">    plan = state[&quot;plan&quot;]</span><br><span class="line">    # 将计划格式化为带编号的字符串</span><br><span class="line">    plan_str = &quot;\n&quot;.join(f&quot;&#123;i + 1&#125;. &#123;step&#125;&quot; for i, step in enumerate(plan))</span><br><span class="line">    task = plan[0]  # 获取第一个待执行的任务</span><br><span class="line">    task_formatted = f&quot;&quot;&quot;对于以下计划:</span><br><span class="line">&#123;plan_str&#125;\n\n你被分配执行第 &#123;1&#125; 步, &#123;task&#125;。&quot;&quot;&quot;</span><br><span class="line">    # 调用代理执行器来执行任务</span><br><span class="line">    agent_response = await agent_executor.ainvoke(</span><br><span class="line">        &#123;&quot;messages&quot;: [(&quot;user&quot;, task_formatted)]&#125;</span><br><span class="line">    )</span><br><span class="line">    # 返回执行结果，添加到历史步骤中</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;past_steps&quot;: [(task, agent_response[&quot;messages&quot;][-1].content)],</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>create_react_agent 是 LangGraph 提供的一个预构建函数，位于
langgraph.prebuilt 模块中，用于快速创建一个基于 ReAct（Reasoning +
Acting）架构的智能代理。</p>
</blockquote>
<blockquote>
<p>langgraph预设的其他常用组件如下</p>
<p><strong>ToolNode</strong></p>
<p>功能：把 LangChain 工具（BaseTool）封装成一个图节点，负责：</p>
<ul>
<li><p>接收 LLM 生成的工具调用请求</p></li>
<li><p>真正执行工具</p></li>
<li><p>把结果返回给图</p></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.prebuilt import ToolNode</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[search, calculator])</span><br></pre></td></tr></table></figure>
<p><strong>tools_condition</strong></p>
<p>功能：判断 LLM 是否要继续调用工具的“路由函数”。</p>
<p>在 ReAct 图里通常放在节点之间的 条件边：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.prebuilt import tools_condition</span><br><span class="line"></span><br><span class="line">graph.add_conditional_edges(&quot;agent&quot;, tools_condition, &#123;</span><br><span class="line"></span><br><span class="line">  &quot;tools&quot;: &quot;tool_node&quot;,    # 需要工具 → 去 ToolNode</span><br><span class="line"></span><br><span class="line">  &quot;**__end__**&quot;: END       # 不需要 → 结束</span><br><span class="line"></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="定义状态">定义状态</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import Annotated, List, Tuple</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class PlanExecute(TypedDict):</span><br><span class="line">    input: str</span><br><span class="line">    plan: List[str]</span><br><span class="line">    past_steps: Annotated[List[Tuple], operator.add]</span><br><span class="line">    response: str</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Plan(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;未来要遵循的计划&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    steps: List[str] = Field(</span><br><span class="line">        description=&quot;需要遵循的不同步骤，应该按排序顺序排列&quot;</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<h4 id="定义模型">定义模型</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">model=ChatTongyi(</span><br><span class="line"> model=&quot;qwen-plus-2025-07-14&quot;,</span><br><span class="line"> api_key=&quot;sk-&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="定义初始计划节点">定义初始计划节点</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.prompts import ChatPromptTemplate</span><br><span class="line"></span><br><span class="line">planner_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (</span><br><span class="line">            &quot;system&quot;,</span><br><span class="line">            &quot;&quot;&quot;对于给定的目标，制定一个简单的逐步计划。\</span><br><span class="line">这个计划应该包含独立的任务，如果正确执行这些任务将得到正确的答案。不要添加任何多余的步骤。\</span><br><span class="line">最后一步的结果应该是最终答案。确保每个步骤都包含所需的所有信息——不要跳过任何步骤。&quot;&quot;&quot;,</span><br><span class="line">        ),</span><br><span class="line">        (&quot;placeholder&quot;, &quot;&#123;messages&#125;&quot;),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">planner = planner_prompt | model.with_structured_output(Plan)</span><br><span class="line"></span><br><span class="line">async def plan_step(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;制定初始计划步骤&quot;&quot;&quot;</span><br><span class="line">    # 使用规划器为用户输入制定计划</span><br><span class="line">    plan = await planner.ainvoke(&#123;&quot;messages&quot;: [(&quot;user&quot;, state[&quot;input&quot;])]&#125;)</span><br><span class="line">    </span><br><span class="line">    return &#123;&quot;plan&quot;: plan.steps&#125;</span><br></pre></td></tr></table></figure>
<h4 id="定义再计划节点">定义再计划节点</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">from typing import Union</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Response(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;对用户的响应&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    response: str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Act(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;要执行的动作&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    action: Union[Response, Plan] = Field(</span><br><span class="line">        description=&quot;要执行的动作。如果你想响应用户，使用 Response。&quot;</span><br><span class="line">        &quot;如果你需要进一步使用工具来获取答案，使用 Plan。&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">replanner_prompt = ChatPromptTemplate.from_template(</span><br><span class="line">    &quot;&quot;&quot;对于给定的目标，制定一个简单的逐步计划。\</span><br><span class="line">这个    计划应该包含独立的任务，如果正确执行这些任务将得到正确的答案。不要添加任何多余的步骤。\</span><br><span class="line">最后一步的结果应该是最终答案。确保每个步骤都包含所需的所有信息——不要跳过任何步骤。</span><br><span class="line"></span><br><span class="line">你的目标是：</span><br><span class="line">&#123;input&#125;</span><br><span class="line"></span><br><span class="line">你的原始计划是：</span><br><span class="line">&#123;plan&#125;</span><br><span class="line"></span><br><span class="line">你目前已经完成了以下步骤：</span><br><span class="line">&#123;past_steps&#125;</span><br><span class="line"></span><br><span class="line">相应地更新你的计划。如果不需要更多步骤并且可以返回给用户，则直接响应。否则，填写计划。只添加仍需要完成的步骤到计划中。不要将已经完成的步骤作为计划的一部分返回。&quot;&quot;&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">replanner = replanner_prompt | model.with_structured_output(Act)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">async def replan_step(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;重新规划步骤&quot;&quot;&quot;</span><br><span class="line">    # 使用重新规划器根据当前状态更新计划</span><br><span class="line">    output = await replanner.ainvoke(state)</span><br><span class="line">    if isinstance(output.action, Response):</span><br><span class="line">        # 如果动作是响应，返回最终响应</span><br><span class="line">        return &#123;&quot;response&quot;: output.action.response&#125;</span><br><span class="line">    else:</span><br><span class="line">        # 如果动作是计划，返回新的计划步骤</span><br><span class="line">        return &#123;&quot;plan&quot;: output.action.steps&#125;</span><br></pre></td></tr></table></figure>
<h4 id="定义路由">定义路由</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def should_end(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;判断是否结束执行流程&quot;&quot;&quot;</span><br><span class="line">    if &quot;response&quot; in state and state[&quot;response&quot;]:</span><br><span class="line">        # 如果存在响应内容，结束流程</span><br><span class="line">        return END</span><br><span class="line">    else:</span><br><span class="line">        # 否则继续执行代理步骤</span><br><span class="line">        return &quot;agent&quot;</span><br></pre></td></tr></table></figure>
<h4 id="编译图">编译图</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import StateGraph, START</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line"></span><br><span class="line"># 创建内存检查点保存器</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 创建工作流图，使用 PlanExecute 状态类型</span><br><span class="line">workflow = StateGraph(PlanExecute)</span><br><span class="line"></span><br><span class="line"># 添加计划节点</span><br><span class="line">workflow.add_node(&quot;planner&quot;, plan_step)</span><br><span class="line"></span><br><span class="line"># 添加执行步骤节点</span><br><span class="line">workflow.add_node(&quot;agent&quot;, execute_step)</span><br><span class="line"></span><br><span class="line"># 添加重新规划节点</span><br><span class="line">workflow.add_node(&quot;replan&quot;, replan_step)</span><br><span class="line"></span><br><span class="line"># 从开始节点连接到计划节点</span><br><span class="line">workflow.add_edge(START, &quot;planner&quot;)</span><br><span class="line"></span><br><span class="line"># 从计划节点连接到代理执行节点</span><br><span class="line">workflow.add_edge(&quot;planner&quot;, &quot;agent&quot;)</span><br><span class="line"></span><br><span class="line"># 从代理执行节点连接到重新规划节点</span><br><span class="line">workflow.add_edge(&quot;agent&quot;, &quot;replan&quot;)</span><br><span class="line"></span><br><span class="line"># 添加条件边 - 从重新规划节点根据条件决定下一步</span><br><span class="line">workflow.add_conditional_edges(</span><br><span class="line">    &quot;replan&quot;,</span><br><span class="line">    # 传入决定下一个调用节点的函数</span><br><span class="line">    should_end,</span><br><span class="line">    [&quot;agent&quot;, END],  # 可能的下一个节点：代理节点或结束</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 最后，编译工作流并添加检查点功能！</span><br><span class="line"># 这将其编译为 LangChain Runnable，</span><br><span class="line"># 意味着你可以像使用其他任何 runnable 一样使用它</span><br><span class="line">app = workflow.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Plan-and-Execute%E6%A8%A1%E5%BC%8F/image-20250729092408872.png" alt="image-20250729092408872">
<figcaption aria-hidden="true">image-20250729092408872</figcaption>
</figure>
<h4 id="调用">调用</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 配置递归限制，防止无限循环</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;</span><br><span class="line">        &quot;thread_id&quot;: &quot;1&quot;,  # 必需：线程ID</span><br><span class="line">    &#125;,&quot;recursion_limit&quot;: 50&#125;</span><br><span class="line"></span><br><span class="line"># 输入问题：2024年澳大利亚网球公开赛男单冠军的家乡是哪里？</span><br><span class="line">inputs = &#123;&quot;input&quot;: &quot;2024年澳大利亚网球公开赛男单冠军的家乡是哪里？&quot;&#125;</span><br><span class="line"></span><br><span class="line"># 异步流式执行应用</span><br><span class="line">async for event in app.astream(inputs, config=config):</span><br><span class="line">    # 遍历每个事件</span><br><span class="line">    for k, v in event.items():</span><br><span class="line">        # 排除结束标记，打印其他所有事件内容</span><br><span class="line">        if k != &quot;__end__&quot;:</span><br><span class="line">            print(v)</span><br></pre></td></tr></table></figure>
<h3 id="资源">资源</h3>
<p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute/">计划与执行
— Plan-and-Execute</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/pgsql%E5%AE%9E%E7%8E%B0%E6%8C%81%E4%B9%85%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/pgsql%E5%AE%9E%E7%8E%B0%E6%8C%81%E4%B9%85%E5%8C%96/" class="post-title-link" itemprop="url">pgsql实现持久化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-28 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-28T00:00:00+08:00">2025-07-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-06 15:00:36" itemprop="dateModified" datetime="2025-08-06T15:00:36+08:00">2025-08-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/agent%E5%AE%9E%E6%88%98/" itemprop="url" rel="index"><span itemprop="name">agent实战</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言">前言</h3>
<p>常使用pgsql与redis配合langgraph的checkpoint与store进行持久化储存，完成长期记忆与短期记忆的实现</p>
<h3 id="pgsql实现持久化">pgsql实现持久化</h3>
<h4 id="什么是pgsql">什么是pgsql</h4>
<p>PostgreSQL（常简称pgsql或Postgres）是一个功能强大的开源对象-关系型数据库管理系统（ORDBMS），以其稳定性、扩展性和符合SQL标准著称。</p>
<h4 id="docker拉取">docker拉取</h4>
<p>docker-compose</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">version: &#x27;3.8&#x27;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  postgres:</span><br><span class="line">    image: postgres:15        # 指定具体版本</span><br><span class="line">    container_name: postgres_db</span><br><span class="line">    environment:</span><br><span class="line">      POSTGRES_USER: postgres</span><br><span class="line">      POSTGRES_PASSWORD: postgres</span><br><span class="line">      POSTGRES_DB: postgres</span><br><span class="line">      TZ: Asia/Shanghai       # 设置时区</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5432:5432&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - pgdata:/var/lib/postgresql/data</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    healthcheck:             # 健康检查</span><br><span class="line">      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;nange&quot;]</span><br><span class="line">      interval: 10s</span><br><span class="line">      timeout: 5s</span><br><span class="line">      retries: 5</span><br><span class="line">    command: [&quot;postgres&quot;, &quot;-c&quot;, &quot;max_connections=200&quot;]  # 自定义配置</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  pgdata:</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Docker Compose</strong> 是一个 <strong>定义和运行多容器
Docker 应用</strong> 的 <strong>声明式工具</strong>。 它通过一个
<strong>YAML 文件（通常叫 <code>docker-compose.yml</code>）</strong>
描述整个应用的服务、网络、存储等配置，然后用一条命令即可
<strong>启动/停止/管理</strong> 所有容器，无需手动逐个
<code>docker run</code>。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#拉取并运行</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>
<h4 id="在pgsqsl安装依赖">在pgsqsl安装依赖</h4>
<p>因为LangGraph的PostgresStore需要使用到pgvector，因此需要在容器中按照如下步骤进行操作，直接使用Docker
Desktop软件中进行操作</p>
<blockquote>
<ul>
<li>为什么需要 <code>pgvector</code>？</li>
<li><code>PostgresStore</code> 支持将
<strong>向量嵌入（embedding）</strong> 存储在 PostgreSQL
中，并基于它们进行 <strong>语义搜索</strong>。</li>
<li>该功能依赖 <code>pgvector</code> 扩展提供的 <code>vector</code>
类型和索引机制（如 HNSW）。</li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">安装依赖           </span><br><span class="line">apt update    #刷新本地软件包索引           </span><br><span class="line">apt install -y git build-essential postgresql-server-dev-15                          </span><br></pre></td></tr></table></figure>
<blockquote>
<p>apt install -y git build-essential postgresql-server-dev-15一次性安装
3 类依赖。</p>
<ul>
<li><code>git</code> —— 用来克隆 pgvector 源码。</li>
<li><code>build-essential</code> —— Debian/Ubuntu
的“编译工具链”元包，包含 gcc、make 等。</li>
<li><code>postgresql-server-dev-15</code> —— 与当前 Postgres
<strong>主版本一致</strong> 的开发头文件和 <code>pg_config</code>。</li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">编译并安装 pgvector      </span><br><span class="line">#把 pgvector 的 v0.7.0 稳定版 源码克隆到本地目录 ./pgvector。</span><br><span class="line">git clone --branch v0.7.0 https://github.com/pgvector/pgvector.git                </span><br><span class="line">cd pgvector  </span><br><span class="line">#调用 Makefile 根据当前操作系统 + PostgreSQL 版本编译出二进制文件（.so 共享库）。</span><br><span class="line">make          </span><br><span class="line">#把刚刚编好的 .so 文件和 .sql/.control 文件复制到 PostgreSQL 的扩展目录</span><br><span class="line">make install                </span><br><span class="line">验证安装，检查扩展文件是否安装成功                    </span><br><span class="line">ls -l /usr/share/postgresql/15/extension/vector* </span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://github.com/pgvector/pgvector">pgvector/pgvector:
Open-source vector similarity search for Postgres</a></p>
<p>接下来，若要在脚本中进行使用，首先在系统环境中需要安装PostgreSQL
的开发库（libpq），因为 psycopg 需要它来编译或运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install libpq-dev postgresql-server-dev-all</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>psycopg（Python 操作 PostgreSQL 的库）</strong> 在
<strong>Linux/macOS</strong> 上运行时，底层依赖于 <strong>PostgreSQL 的
C 语言开发库 libpq</strong>。 如果系统里 <strong>没有
libpq</strong>，psycopg 会出现以下两种问题：</p>
<ol type="1">
<li><p><strong>编译安装失败</strong>（源码/旧版本） 当
<code>pip install psycopg2</code> 需要现场编译时，会找不到头文件
<code>libpq-fe.h</code> 或动态库 <code>libpq.so</code>，导致报错：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error: libpq-fe.h: No such file or directory</span><br></pre></td></tr></table></figure></li>
<li><p><strong>运行时崩溃</strong> 即使通过预编译的 wheel
包安装成功，运行时也可能提示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ImportError: libpq.so.5: cannot open shared object file</span><br></pre></td></tr></table></figure></li>
</ol>
</blockquote>
<p>最后，再安装相关依赖包</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install langgraph-checkpoint-postgres                    </span><br><span class="line">pip install psycopg psycopg-pool </span><br></pre></td></tr></table></figure>
<p>psycopg官方 PostgreSQL 驱动，在 <code>psycopg</code>
之上再包一层“<strong>连接池</strong>”，让并发访问更快、更稳定。</p>
<h4 id="连接pgsql">连接pgsql</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.store.postgres import PostgresStore</span><br><span class="line">from langgraph.checkpoint.postgres import PostgresSaver</span><br><span class="line">from psycopg_pool import ConnectionPool</span><br><span class="line"># 1) 连接字符串（URI 语法）</span><br><span class="line">DB_URI = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line">#   协议://      用户   : 密码   @ 主机:端口 / 数据库名  ? 额外参数</span><br><span class="line"></span><br><span class="line"># 2) 连接级参数</span><br><span class="line">connection_kwargs = &#123;</span><br><span class="line">    &quot;autocommit&quot;: True,     # 每条 SQL 执行完立即提交，无需手动 commit</span><br><span class="line">    &quot;prepare_threshold&quot;: 0, # 禁用服务器端 prepared statement，可减少一次往返</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 3) 创建池</span><br><span class="line">connection_pool = ConnectionPool(</span><br><span class="line">    conninfo=DB_URI,</span><br><span class="line">    max_size=20,            # 最多 20 条物理连接</span><br><span class="line">    kwargs=connection_kwargs,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 4) 显式打开池（psycopg 3 的 ConnectionPool 默认懒启动，调 open() 会立即建 min_size 条连接）</span><br><span class="line">connection_pool.open()</span><br><span class="line">print(&quot;数据库连接池初始化成功&quot;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>正常情况每次 SQL 都新建一条 TCP 连接、做 SSL
握手、验证密码、分配内存，如果不复用连接，这些动作就要
<strong>每次都重新来一遍</strong>，<strong>成本非常高</strong>。</p>
<p>连接池（Connection Pool）是一种
<strong>数据库访问层资源管理组件</strong>，其核心目标是在
<strong>高并发、短事务</strong> 场景下，通过
<strong>复用已建立的数据库物理连接</strong>
来降低系统整体延迟、减少资源消耗，并防止数据库因瞬时连接风暴而崩溃。</p>
</blockquote>
<h4 id="初始化pgsql">初始化pgsql</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 初始化PostgresStore</span><br><span class="line">in_postgres_store = PostgresStore(</span><br><span class="line">    pool,</span><br><span class="line">    index=&#123;</span><br><span class="line">        &quot;dims&quot;: 1536,</span><br><span class="line">        &quot;embed&quot;: embedding</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line">in_postgres_store.setup()</span><br><span class="line"></span><br><span class="line">#初始化checkpoint</span><br><span class="line"># 使用传入的连接池创建 PostgresSaver</span><br><span class="line">checkpointer = PostgresSaver(pool)</span><br><span class="line">checkpointer.setup()</span><br><span class="line"></span><br><span class="line">#最后编译时添加</span><br><span class="line">graph_builder.compile(checkpointer=checkpointer, store=in_postgres_store)</span><br></pre></td></tr></table></figure>
<p><code>in_postgres_store.setup()</code> 的角色一句话就能说清：</p>
<blockquote>
<p><strong>把数据库里所有为了让向量存储正常工作的“一次性基建”全部建好</strong>——只建一次，后面再跑就不会重复执行。</p>
</blockquote>
<p>具体而言，它通常干下面三件事：1.<strong>建表 /
建扩展</strong>；2.<strong>建向量索引</strong>；3.<strong>元数据初始化</strong></p>
<h4 id="fastapi实现生命周期的管理">fastapi实现生命周期的管理</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"># 定义了一个异步函数lifespan，它接收一个FastAPI应用实例app作为参数。这个函数将管理应用的生命周期，包括启动和关闭时的操作</span><br><span class="line"># 函数在应用启动时执行一些初始化操作，如加载上下文数据、以及初始化问题生成器</span><br><span class="line"># 函数在应用关闭时执行一些清理操作</span><br><span class="line"># @asynccontextmanager 装饰器用于创建一个异步上下文管理器，它允许你在 yield 之前和之后执行特定的代码块，分别表示启动和关闭时的操作</span><br><span class="line">@asynccontextmanager</span><br><span class="line">async def lifespan(app: FastAPI):</span><br><span class="line">    # 启动时执行</span><br><span class="line">    # 申明引用全局变量，在函数中被初始化，并在整个应用中使用</span><br><span class="line">    global graph, connection_pool</span><br><span class="line">    # 启动时执行</span><br><span class="line">    try:</span><br><span class="line">        logger.info(&quot;正在初始化模型、定义 Graph...&quot;)</span><br><span class="line">        # 初始化 LLM</span><br><span class="line">        llm, embedding = get_llm(llm_type)</span><br><span class="line">        # 创建数据库连接池</span><br><span class="line">        DB_URI = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line">        connection_kwargs = &#123;</span><br><span class="line">            &quot;autocommit&quot;: True,</span><br><span class="line">            &quot;prepare_threshold&quot;: 0,</span><br><span class="line">        &#125;</span><br><span class="line">        connection_pool = ConnectionPool(</span><br><span class="line">            conninfo=DB_URI,</span><br><span class="line">            max_size=20,</span><br><span class="line">            kwargs=connection_kwargs,</span><br><span class="line">        )</span><br><span class="line">        connection_pool.open()  # 显式打开连接池</span><br><span class="line">        logger.info(&quot;数据库连接池初始化成功&quot;)</span><br><span class="line">        # 短期记忆 初始化checkpointer</span><br><span class="line">        checkpointer = PostgresSaver(connection_pool)</span><br><span class="line">        checkpointer.setup()</span><br><span class="line">        # 长期记忆 初始化PostgresStore</span><br><span class="line">        in_postgres_store = PostgresStore(</span><br><span class="line">            connection_pool,</span><br><span class="line">            index=&#123;</span><br><span class="line">                &quot;dims&quot;: 1536,</span><br><span class="line">                &quot;embed&quot;: embedding</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        in_postgres_store.setup()</span><br><span class="line">        # 定义 Graph</span><br><span class="line">        graph = create_graph(llm, checkpointer, in_postgres_store )</span><br><span class="line">        # 保存 Graph 可视化图</span><br><span class="line">        save_graph_visualization(graph)</span><br><span class="line">        logger.info(&quot;初始化完成&quot;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        logger.error(f&quot;初始化过程中出错: &#123;str(e)&#125;&quot;)</span><br><span class="line">        raise</span><br><span class="line"></span><br><span class="line">    yield  # 应用运行期间</span><br><span class="line"></span><br><span class="line">    # 关闭时执行</span><br><span class="line">    logger.info(&quot;正在关闭...&quot;)</span><br><span class="line">    if connection_pool:</span><br><span class="line">        connection_pool.close()  # 关闭连接池</span><br><span class="line">        logger.info(&quot;数据库连接池已关闭&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># lifespan参数用于在应用程序生命周期的开始和结束时执行一些初始化或清理工作</span><br><span class="line">app = FastAPI(lifespan=lifespan)</span><br></pre></td></tr></table></figure>
<h3 id="pgsql的存储结构">pgsql的存储结构</h3>
<h4 id="一checkpoints-系列">一、Checkpoints 系列</h4>
<blockquote>
<p>作用：让 <strong>LangGraph Runtime</strong> 能在
<strong>分布式/长流程</strong> 场景下
<strong>断点续跑、重放、并发控制</strong>。</p>
</blockquote>
<table>
<colgroup>
<col style="width: 15%">
<col style="width: 31%">
<col style="width: 37%">
<col style="width: 16%">
</colgroup>
<thead>
<tr>
<th>表名</th>
<th>存什么</th>
<th>典型字段（示意）</th>
<th>何时写入</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>checkpoints</strong></td>
<td>每个「图实例」的 <strong>最新快照</strong>（state 的完整
JSONB）</td>
<td><code>thread_id</code>, <code>checkpoint_ns</code>,
<code>checkpoint_id</code>, <code>parent_checkpoint_id</code>,
<code>state</code>, <code>created_at</code></td>
<td>每次节点执行成功后覆盖更新</td>
</tr>
<tr>
<td><strong>checkpoint_blobs</strong></td>
<td>checkpoints 里 <strong>大字段的拆分</strong>（避免行过大）</td>
<td><code>thread_id</code>, <code>checkpoint_ns</code>,
<code>channel</code>, <code>type</code>, <code>blob</code></td>
<td>当 state 过大，自动拆分</td>
</tr>
<tr>
<td><strong>checkpoint_migrations</strong></td>
<td>记录 <strong>schema 版本/迁移脚本</strong></td>
<td><code>version</code>, <code>name</code>,
<code>applied_at</code></td>
<td>只在 <code>setup()</code> 时写一次</td>
</tr>
<tr>
<td><strong>checkpoint_writes</strong></td>
<td><strong>写放大日志</strong>（每个节点写 state 的增量 diff）</td>
<td><code>thread_id</code>, <code>checkpoint_id</code>,
<code>task_id</code>, <code>idx</code>, <code>channel</code>,
<code>type</code>, <code>value</code></td>
<td>每次节点完成时追加</td>
</tr>
</tbody>
</table>
<blockquote>
<p>关系：<br>
<code>checkpoints</code> = 最新完整快照<br>
<code>checkpoint_writes</code> = 所有增量历史（用于重放/审计）<br>
<code>checkpoint_blobs</code> = checkpoints 里超大型 value 的切片</p>
</blockquote>
<h4 id="二store-系列">二、Store 系列</h4>
<blockquote>
<p>作用：给 <strong>业务代码（开发者）</strong> 提供 <strong>持久化 KV /
向量存储</strong>，与图运行状态无关。</p>
</blockquote>
<table>
<colgroup>
<col style="width: 12%">
<col style="width: 27%">
<col style="width: 34%">
<col style="width: 25%">
</colgroup>
<thead>
<tr>
<th>表名</th>
<th>存什么</th>
<th>典型字段（示意）</th>
<th>何时写入</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>store</strong></td>
<td><strong>任意 KV 文档</strong>（LangChain Document → JSONB）</td>
<td><code>uuid</code>, <code>namespace</code>, <code>key</code>,
<code>value</code>, <code>created_at</code>,
<code>updated_at</code></td>
<td>你调用 <code>store.amput</code> / <code>amset</code> 等 API</td>
</tr>
<tr>
<td><strong>store_migrations</strong></td>
<td>同 checkpoint_migrations，记录 store schema 版本</td>
<td><code>version</code>, <code>name</code>,
<code>applied_at</code></td>
<td>只在第一次 <code>setup()</code></td>
</tr>
<tr>
<td><strong>store_vectors</strong></td>
<td><strong>向量索引表</strong>（embedding → vector 类型）</td>
<td><code>uuid</code>, <code>collection_id</code>,
<code>embedding</code>, <code>document</code>,
<code>metadata</code></td>
<td>你调用 <code>add_documents(..., embeddings=...)</code></td>
</tr>
<tr>
<td><strong>vector_migrations</strong></td>
<td>记录 pgvector 扩展及索引迁移版本</td>
<td><code>version</code>, <code>applied_at</code></td>
<td><code>setup()</code> 时若第一次装 pgvector</td>
</tr>
</tbody>
</table>
<h4 id="三调用链脑图">三、调用链脑图</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">┌──────────────┐</span><br><span class="line">│ LangGraph    │ 运行图实例</span><br><span class="line">└────┬─────────┘</span><br><span class="line">     │1. 写 checkpoints</span><br><span class="line">     │2. 写 checkpoint_writes</span><br><span class="line">     │3. 拆大字段到 checkpoint_blobs</span><br><span class="line">     ▼</span><br><span class="line">┌──────────────┐</span><br><span class="line">│ 业务代码     │ 读写 KV/向量</span><br><span class="line">└────┬─────────┘</span><br><span class="line">     │1. 写 store</span><br><span class="line">     │2. 写 store_vectors</span><br><span class="line">     ▼</span><br><span class="line"> PostgreSQL (pgsql)</span><br></pre></td></tr></table></figure>
<h3 id="在linux安装postgresql">在linux安装postgresql</h3>
<h4 id="查看linux发行版本">查看linux发行版本</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看发行版名称和版本</span><br><span class="line">cat /etc/os-release</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">PRETTY_NAME=&quot;Ubuntu 24.04.2 LTS&quot;</span><br><span class="line">NAME=&quot;Ubuntu&quot;</span><br><span class="line">VERSION_ID=&quot;24.04&quot;</span><br><span class="line">VERSION=&quot;24.04.2 LTS (Noble Numbat)&quot;</span><br><span class="line">VERSION_CODENAME=noble</span><br><span class="line">ID=ubuntu</span><br><span class="line">ID_LIKE=debian</span><br><span class="line">HOME_URL=&quot;https://www.ubuntu.com/&quot;</span><br><span class="line">SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;</span><br><span class="line">PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;</span><br><span class="line">UBUNTU_CODENAME=noble</span><br><span class="line">LOGO=ubuntu-logo</span><br></pre></td></tr></table></figure>
<h4 id="安装postgresql">安装postgresql</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 更新软件包索引</span><br><span class="line">sudo apt update</span><br><span class="line"></span><br><span class="line"># 安装 PostgreSQL 和常用扩展</span><br><span class="line">sudo apt install -y postgresql postgresql-contrib</span><br><span class="line"></span><br><span class="line"># 检查服务状态</span><br><span class="line">#Linux 容器/子系统（ Docker、WSL 或 LXC）没有使用 systemd ，因此 systemctl 无法工作</span><br><span class="line">sudo systemctl status postgresql</span><br><span class="line"></span><br><span class="line">#确认 PostgreSQL 已安装</span><br><span class="line">which psql            # 应该输出 /usr/bin/psql</span><br><span class="line">pg_ctl --version      # 显示版本号即已安装</span><br></pre></td></tr></table></figure>
<ul>
<li><code>postgresql</code> 是主程序</li>
<li><code>postgresql-contrib</code> 提供额外扩展（如
<code>uuid-ossp</code>、<code>pgcrypto</code> 等）</li>
</ul>
<blockquote>
<p>systemctl一般用于服务器上，完整的linux系统上</p>
<p>Linux 容器/子系统（ Docker、WSL 或 LXC）使用 service</p>
</blockquote>
<h4 id="pgsql常用指令">pgsql常用指令</h4>
<p>启动pgsql服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service postgresql start</span><br></pre></td></tr></table></figure>
<p>停止pgsql服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service postgresql stop</span><br></pre></td></tr></table></figure>
<p>查看状态</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service postgresql status</span><br></pre></td></tr></table></figure>
<p>连接PostgreSQL 默认的系统用户，可以执行pgsql的相关指令</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u postgres psql</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>psql</strong>为PostgreSQL
的终端客户端，默认会连接与当前操作系统用户名同名的数据库用户和数据库。</p>
<p><strong>postgres</strong>为PostgreSQL
自带的系统数据库，<code>postgres</code> 默认
<strong>数据库密码为空</strong>，可以通过以下指令进行设置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 设置postgres用户密码</span><br><span class="line">ALTER USER postgres PASSWORD &#x27;postgres&#x27;;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>数据库关于user的作用</p>
<p>数据库里的“用户”是 PostgreSQL
<strong>内部用来做“访问控制”的一把钥匙</strong>。一句话：<strong>“谁能连哪个库、谁能读哪张表、谁能改哪些行”——全靠这些数据库用户（角色）来判定。</strong></p>
<table>
<colgroup>
<col style="width: 32%">
<col style="width: 67%">
</colgroup>
<thead>
<tr>
<th>作用</th>
<th>举例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1. 认证</strong>（Authentication）</td>
<td>告诉 PostgreSQL “我连库时提供的用户名+密码是否合法”。</td>
</tr>
<tr>
<td><strong>2. 授权</strong>（Authorization）</td>
<td>决定
“这个用户连进来后，对哪些库、哪些表、哪些行有何种权限（SELECT/INSERT/UPDATE/DELETE…）”。</td>
</tr>
<tr>
<td><strong>3. 资源隔离</strong>（Isolation）</td>
<td>不同业务/团队用不同用户，方便审计、限流、回收权限，互不干扰。</td>
</tr>
</tbody>
</table>
<p>pgsql通用 URL 模板</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">postgresql://&lt;用户名&gt;:&lt;密码&gt;@127.0.0.1:5432/&lt;数据库名&gt;[?参数=值&amp;...]</span><br></pre></td></tr></table></figure>
<h4 id="连接pgsql-1">连接pgsql</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 基于数据库持久化存储的short-term</span><br><span class="line">db_uri = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line"></span><br><span class="line"># short-term短期记忆 实例化PostgresSaver对象 并初始化checkpointer</span><br><span class="line"># long-term长期记忆 实例化PostgresStore对象 并初始化store</span><br><span class="line">async with (</span><br><span class="line">    AsyncPostgresSaver.from_conn_string(db_uri) as checkpointer,</span><br><span class="line">    AsyncPostgresStore.from_conn_string(db_uri) as store</span><br><span class="line"></span><br><span class="line">):</span><br><span class="line">    await store.setup()</span><br><span class="line">    await checkpointer.setup()</span><br></pre></td></tr></table></figure>
<h3 id="更换apt镜像源">更换apt镜像源</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/apt/sources.list &lt;&lt;&#x27;EOF&#x27;</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm-updates main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm-backports main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian-security bookworm-security main contrib non-free</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">apt update</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7470702616906645540">postgresql向量扩展pgvector的安装与入门本文简答的介绍了
rag 的架构，引申出向量数据库的作用，介绍了 - 掘金</a></p>
<p>langchain支持向量存储<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/integrations/vectorstores/">向量存储
| 🦜️🔗 LangChain — Vector stores | 🦜️🔗 LangChain</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" class="post-title-link" itemprop="url">Transformer学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-28 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-28T00:00:00+08:00">2025-07-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-11 15:40:12" itemprop="dateModified" datetime="2025-08-11T15:40:12+08:00">2025-08-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">大模型算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/transformer/" itemprop="url" rel="index"><span itemprop="name">transformer</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言">前言</h3>
<p>本文基于<a target="_blank" rel="noopener" href="https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/blob/master/PaperNotes/Transformer%20论文精读.md#前言">AI-Guide-and-Demos-zh_CN/PaperNotes/Transformer
论文精读.md at master · Hoper-J/AI-Guide-and-Demos-zh_CN</a>与<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Transformer论文逐段精读【论文精读】_哔哩哔哩_bilibili</a>阅读学习</p>
<h3 id="transformer贡献">transformer贡献</h3>
<p>实际在这一阶段的工作中，<strong>注意力机制</strong>就已经在<strong>编码器-解码器架构</strong>中被广泛应用（与
RNN 一起使用），但 Transformer
彻底颠覆了默认采取的逻辑：<strong>直接放弃 RNN
的递归结构，只使用注意力机制来编码和解码序列信息</strong>。</p>
<p>Transformer 的主要贡献如下：</p>
<ul>
<li><p><strong>取消递归结构，实现并行计算</strong></p>
<p>通过采用<strong>自注意力机制（Self-Attention）</strong>，Transformer
可以同时处理多个输入序列，极大提高了计算的并行度和训练速度。</p></li>
<li><p><strong>引入位置编码（Positional Encoding）并结合 Attention
机制巧妙地捕捉位置信息</strong></p>
<p>在不依赖 RNN
结构的情况下，通过位置编码为序列中的每个元素嵌入位置信息，从而使模型能够感知输入的顺序。</p></li>
</ul>
<h3 id="transformer架构">transformer架构</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807135151542.png" alt="image-20250807135151542">
<figcaption aria-hidden="true">image-20250807135151542</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807145354145.png" alt="image-20250807145354145">
<figcaption aria-hidden="true">image-20250807145354145</figcaption>
</figure>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1MY41137AK?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Transformer模型】曼妙动画轻松学，形象比喻贼好记_哔哩哔哩_bilibili</a></p>
<p>Transformer 模型基于<strong>编码器</strong>（左）-
<strong>解码器</strong>（右）架构</p>
<p><strong>Transformer编码器</strong>同样由 <strong>N
个完全相同的层</strong>（原始论文中
N=6）堆叠而成，每层只有两个子层，而解码器有三个。</p>
<ol type="1">
<li>多头自注意力（Multi-Head Self-Attention）
让输入序列中的每个位置都能关注序列内所有位置，直接建模全局依赖。</li>
<li>前馈全连接网络（Position-wise Feed-Forward Network）
对每个位置独立地做一次两层的全连接变换（通常先升维再降维）。</li>
</ol>
<p>同样，每个子层后都有</p>
<ul>
<li>残差连接（Residual Connection）</li>
<li>层归一化（Layer Normalization）</li>
</ul>
<p>另外，编码器在输入端还会用到</p>
<ul>
<li>位置编码（Positional
Encoding）——给模型提供序列位置信息，因为注意力本身不包含顺序信息。</li>
</ul>
<p><strong>Transformer解码器</strong>由多个相同的层堆叠而成，每一层包含三个核心子层：</p>
<ol type="1">
<li><strong>掩蔽多头自注意力机制</strong>（Masked Multi-Head Attention）
用于处理目标序列，通过掩码防止当前位置关注未来位置，确保生成过程的自回归特性。</li>
<li><strong>编码器-解码器注意力机制</strong>（Encoder-Decoder
Attention）
使解码器能够关注编码器输出的上下文信息，建立输入与输出序列之间的关联。</li>
<li><strong>前馈神经网络</strong>（Feed-Forward Neural Network）
对注意力机制的输出进行非线性变换，增强模型的表达能力。</li>
</ol>
<p>此外，每个子层后均包含<strong>残差连接</strong>（Residual
Connection）和<strong>层归一化</strong>（Layer
Normalization），以稳定训练过程并加速收敛。最终，解码器的输出通过线性层和Softmax层映射为词汇表上的概率分布。</p>
<h3 id="嵌入embeddings">嵌入（Embeddings）</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808103256344.png" alt="image-20250808103256344">
<figcaption aria-hidden="true">image-20250808103256344</figcaption>
</figure>
<p>在 Transformer 模型中，<strong>嵌入层</strong>（Embedding Layer）
是处理输入和输出数据的关键步骤，因为模型实际操作的是<strong>张量</strong>（tensor），而非<strong>字符串</strong>（string）。在将输入文本传递给模型之前，首先需要进行<strong>分词</strong>（tokenization），即将文本拆解为多个
<strong>token</strong>，随后这些 token 会被映射为对应的 <strong>token
ID</strong>，从而转换为模型可理解的数值形式。此时，数据的形状为
<code>(seq_len,)</code>，其中 <code>seq_len</code>
表示输入序列的长度。</p>
<p>目的：为了让模型捕捉到 token 背后复杂的语义（Semantic
meaning）关系，我们需要将离散的 token ID
映射到一个高维的连续向量空间（Continuous, dense）。这意味着每个 token ID
会被转换为一个<strong>嵌入向量</strong>（embedding
vector），期望通过这种方式让语义相近的词汇在向量空间中距离更近，使模型能更好地捕捉词汇之间的关系。</p>
<p>流程：（前面要进行分词，后面要进行位置编码）</p>
<p>初始化一个可学习的矩阵 <code>E ∈ ℝ^(|V| × d_model)</code>
<code>|V|</code> = 词表大小（比如 32 k、50 k），<code>d_model</code> =
512/768/1024…</p>
<p>把 token id 作为行号，直接取对应行： <code>x_i = E[token_id_i]</code>
得到 <code>[batch, seq_len, d_model]</code> 的浮点张量。</p>
<h3 id="位置编码positional-encoding">位置编码（Positional
Encoding）</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808103418150.png" alt="image-20250808103418150">
<figcaption aria-hidden="true">image-20250808103418150</figcaption>
</figure>
<p>Transformer
的自注意力机制（Self-Attention）是<strong>位置无关（position-agnostic）</strong>的。也就是说，如果不做任何处理，模型无法区分“我爱你”和“你爱我”这两个句子的差异，因为自注意力机制只关注
token 之间的相关性，而不考虑它们在序列中的顺序。</p>
<p>为了让模型感知到 token 的位置信息，Transformer
引入了<strong>位置编码</strong>。</p>
<p>在原始论文中，Transformer 使用的是固定位置编码（Positional
Encoding），其公式如下：</p>
<p><span class="math display">$$
\begin{aligned}
PE_{(pos, 2i)} &amp;=
\sin\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right), \\
PE_{(pos, 2i+1)} &amp;=
\cos\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right).
\end{aligned}
$$</span></p>
<p>其中：</p>
<ul>
<li><span class="math inline"><em>p</em><em>o</em><em>s</em></span>
表示位置索引（Position）。</li>
<li><span class="math inline"><em>i</em></span> 表示维度索引。</li>
<li><span class="math inline"><em>d</em><sub>model</sub></span>
是嵌入向量的维度。</li>
</ul>
<p>流程：输入的是一个<strong>整数索引</strong>（位置序号
0,1,2,…）。位置编码模块先把这些整数映射成与词向量同维度的向量（例如 512
维），再把结果加到词向量上。</p>
<h3 id="softmax">Softmax</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808111823715.png" alt="image-20250808111823715">
<figcaption aria-hidden="true">image-20250808111823715</figcaption>
</figure>
<p>在 Transformer 模型中，<strong>Softmax</strong>
函数不仅在计算<strong>注意力权重</strong>时用到，在预测阶段的输出处理环节也会用到，因为预测
token 的过程可以看成是<strong>多分类问题</strong>。</p>
<p><strong>Softmax</strong>
函数是一种常用的激活函数，能够将任意实数向量转换为<strong>概率分布</strong>，确保每个元素的取值范围在
[0, 1] 之间，并且所有元素的和为 1。其数学定义如下：</p>
<p><span class="math display">$$
\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}
$$</span></p>
<p>其中：</p>
<ul>
<li><span class="math inline"><em>x</em><sub><em>i</em></sub></span>
表示输入向量中的第 <span class="math inline"><em>i</em></span>
个元素。</li>
<li><span class="math inline">Softmax(<em>x</em><sub><em>i</em></sub>)</span>
表示输入 <span class="math inline"><em>x</em><sub><em>i</em></sub></span>
转换后的概率。</li>
</ul>
<p>我们可以把 Softmax
看作一种<strong>归一化的指数变换</strong>。相比于简单的比例归一化 <span class="math inline">$\frac{x_i}{\sum_j x_j}$</span>, <strong>Softmax
通过指数变换放大数值间的差异，让较大的值对应更高的概率，同时避免了负值和数值过小的问题，让模型聚焦于权重最高的位置</strong>，同时保留全局信息（低权重仍非零）。</p>
<h3 id="注意力机制">注意力机制</h3>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1xS4y1k7tn?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Attention
注意力机制】激情告白transformer、Bert、GNN的精髓_哔哩哔哩_bilibili</a></p>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808135811744.png" alt="image-20250808135811744">
<figcaption aria-hidden="true">image-20250808135811744</figcaption>
</figure>
<h4 id="缩放点积注意力机制scaled-dot-product-attention"><strong>缩放点积注意力机制（Scaled
Dot-Product Attention）</strong></h4>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808140834132.png" alt="image-20250808140834132">
<figcaption aria-hidden="true">image-20250808140834132</figcaption>
</figure>
<p>Transformer 的核心是<strong>多头注意力机制（Multi-Head
Attention）</strong>，它能够捕捉输入序列中不同位置之间的依赖关系，并从多个角度对信息进行建模。模块将自底向上的进行讲解：在深入理解注意力机制前，首先需要理解论文使用的<strong>缩放点积注意力机制（Scaled
Dot-Product Attention）</strong>。</p>
<p>给定查询矩阵 <span class="math inline"><em>Q</em></span>、键矩阵
<span class="math inline"><em>K</em></span> 和值矩阵 <span class="math inline"><em>V</em></span>,
其注意力输出的数学表达式如下：</p>
<p><span class="math display">$$
\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{Q
K^\top}{\sqrt{d_k}}\right) V
$$</span></p>
<ul>
<li><strong><span class="math inline"><em>Q</em></span>（Query）</strong>:
用于查询的向量矩阵。</li>
<li><strong><span class="math inline"><em>K</em></span>（Key）</strong>:
表示键的向量矩阵，用于与查询匹配。</li>
<li><strong><span class="math inline"><em>V</em></span>（Value）</strong>:
值矩阵，注意力权重最终会作用在该矩阵上。</li>
<li><strong><span class="math inline"><em>d</em><sub><em>k</em></sub></span></strong>:
键或查询向量的维度。</li>
</ul>
<blockquote>
<p>理解 Q、K、V
的关键在于代码，它们实际上是通过线性变换从输入序列生成的</p>
</blockquote>
<p>公式解释</p>
<ol type="1">
<li><p><strong>点积计算（Dot Produce）</strong></p>
<p>将查询矩阵 <span class="math inline"><em>Q</em></span> 与键矩阵的转置
<span class="math inline"><em>K</em><sup>⊤</sup></span>
做点积，计算每个查询向量与所有键向量之间的相似度：</p>
<p><span class="math inline">$`\text{Scores} = Q K^\top`$</span></p>
<ul>
<li><strong>每一行</strong>表示某个查询与所有键之间的相似度（匹配分数）。</li>
<li><strong>每一列</strong>表示某个键与所有查询之间的相似度（匹配分数）。</li>
</ul></li>
<li><p><strong>缩放（Scaling）</strong></p>
<p>当 <span class="math inline"><em>d</em><sub><em>k</em></sub></span>
较大时，点积的数值可能会过大，导致 Softmax 过后的梯度变得极小，因此除以
<span class="math inline">$\sqrt{d_k}$</span>
缩放点积结果的数值范围：</p>
<p><span class="math inline">$`\text{Scaled Scores} = \frac{Q
K^\top}{\sqrt{d_k}}`$</span></p>
<p>缩放后（Scaled Dot-Product）也称为注意力分数（<strong>attention
scores</strong>）。</p></li>
<li><p><strong>Softmax 归一化</strong></p>
<p>使用 Softmax 函数将缩放后的分数转换为概率分布：</p>
<p><span class="math inline">$`\text{Attention Weights} =
\text{Softmax}\left(\frac{Q K^\top}{\sqrt{d_k}}\right)`$</span></p>
<blockquote>
<p><strong>注意</strong>：Softmax
是在每一行上进行的，这意味着每个查询的匹配分数将归一化为概率，总和为
1。</p>
</blockquote></li>
<li><p><strong>加权求和（Weighted Sum）</strong></p>
<p>最后，使用归一化后的注意力权重对值矩阵 <span class="math inline"><em>V</em></span>
进行加权求和，得到每个查询位置的最终输出： <span class="math inline">$`\text{Output} = \text{Attention Weights} \times
V`$</span></p></li>
</ol>
<h3 id="单头注意力机制single-head-attention">单头注意力机制（Single-Head
Attention）</h3>
<p>将输入序列（Inputs）通过线性变换生成<strong>查询矩阵</strong>（Query,
Q）、<strong>键矩阵</strong>（Key, K）和<strong>值矩阵</strong>（Value,
V），随后执行<strong>缩放点积注意力</strong>（Scaled Dot-Product
Attention）。</p>
<h4 id="掩码注意力机制masked-attention">掩码注意力机制（Masked
Attention）</h4>
<p>如果使用 mask 掩盖将要预测的词汇，那么 Attention 就延伸为 Masked
Attention</p>
<p>在这段代码中，<code>mask</code>
矩阵用于指定哪些位置应该被遮蔽（即填充为
-∞），从而保证这些位置的注意力权重在 softmax
输出中接近于零。注意，掩码机制并不是直接在截断输入序列，也不是在算分数的时候就排除不应该看到的位置，因为看到也没有关系，不会影响与其他位置的分数，所以在传入
Softmax（计算注意力权重）之前排除就可以了。</p>
<p>另外，根据输入数据的来源，还可以将注意力分为<strong>自注意力（Self-Attention）和交叉注意力（Cross-Attention)</strong>。</p>
<h4 id="自注意力机制self-attention">自注意力机制（Self-attention）</h4>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808142109091.png" alt="image-20250808142109091">
<figcaption aria-hidden="true">image-20250808142109091</figcaption>
</figure>
<p>Transformer
模型架构使用到了三个看起来不同的注意力机制，我们继续忽视共有的
Multi-Head。观察输入，线条一分为三传入 Attention
模块，这意味着查询（query）、键（key）和值（value）实际上都来自<strong>同一输入序列
<span class="math inline"><strong>X</strong></span></strong>，数学表达如下：</p>
<p><span class="math display"><em>Q</em> = <em>X</em><em>W</em><sup><em>Q</em></sup>,  <em>K</em> = <em>X</em><em>W</em><sup><em>K</em></sup>,  <em>V</em> = <em>X</em><em>W</em><sup><em>V</em></sup></span></p>
<ul>
<li><strong><span class="math inline"><em>W</em><sup><em>Q</em></sup>, <em>W</em><sup><em>K</em></sup>, <em>W</em><sup><em>V</em></sup></span></strong>：可训练的线性变换权重，实际上就是简单的线性层</li>
</ul>
<h4 id="交叉注意力机制cross-attention">交叉注意力机制（Cross-Attention）</h4>
<p>在 Transformer 解码器中，除了自注意力外，还使用了
<strong>交叉注意力（Cross-Attention）</strong>。</p>
<p>如下图所示，解码器（右）在自底向上的处理过程中，先执行自注意力机制，然后通过交叉注意力从编码器的输出中获取上下文信息。</p>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808142428374.png" alt="image-20250808142428374">
<figcaption aria-hidden="true">image-20250808142428374</figcaption>
</figure>
<p>数学表达如下：</p>
<p><span class="math display"><em>Q</em> = <em>X</em><sub>decoder</sub><em>W</em><sup><em>Q</em></sup>,  <em>K</em> = <em>X</em><sub>encoder</sub><em>W</em><sup><em>K</em></sup>,  <em>V</em> = <em>X</em><sub>encoder</sub><em>W</em><sup><em>V</em></sup></span></p>
<h4 id="对比学习">对比学习</h4>
<p><strong>Masked Attention</strong>、<strong>Self-Attention</strong> 和
<strong>Cross-Attention</strong>
的本质是一致的，这一点从代码调用可以看出来，三者的区别在于未来掩码的使用和输入数据的来源：</p>
<ul>
<li><p><strong>Masked
Attention</strong>：用于解码过程，通过掩码屏蔽未来的时间步，确保模型只能基于已生成的部分进行预测，论文中解码器部分的第一个
Attention 使用的是 Masked Self-Attention。</p></li>
<li><p><strong>Self-Attention</strong>：查询、键和值矩阵来自同一输入序列，模型通过自注意力机制学习输入序列的全局依赖关系。</p></li>
<li><p><strong>Cross-Attention</strong>：查询矩阵来自解码器的输入，而键和值矩阵来自编码器的输出，解码器的第二个
Attention 模块就是
Cross-Attention，用于从编码器输出中获取相关的上下文信息。</p>
<ul>
<li><p>以<strong>机器翻译</strong>中的<strong>中译英任务</strong>为例：对于中文句子“<strong>中国的首都是北京</strong>”，假设模型已经生成了部分译文“The
capital of China is”，此时需要预测下一个单词。</p>
<p>在这一阶段，<strong>解码器中的交叉注意力机制</strong>会使用<strong>当前已生成的译文“The
capital of China
is”的编码表示作为查询</strong>，并将<strong>编码器对输入句子“中国的首都是北京”编码表示</strong>作为<strong>键</strong>和<strong>值</strong>，通过计算<strong>查询与键之间的匹配程度</strong>，生成相应的注意力权重，以此从值中提取上下文信息，基于这些信息生成下一个可能的单词（token），比如：“Beijing”。</p></li>
</ul></li>
</ul>
<h3 id="多头注意力机制multi-head-attention">多头注意力机制（Multi-Head
Attention）</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808143810965.png" alt="image-20250808143810965">
<figcaption aria-hidden="true">image-20250808143810965</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808143822630.png" alt="image-20250808143822630">
<figcaption aria-hidden="true">image-20250808143822630</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808143845681.png" alt="image-20250808143845681">
<figcaption aria-hidden="true">image-20250808143845681</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808145725202.png" alt="image-20250808145725202">
<figcaption aria-hidden="true">image-20250808145725202</figcaption>
</figure>
<p>多头注意力机制就是存在多个不同的权重矩阵，形成多个矩阵Z，再把它们
<strong>按最后一维（hidden）拼接（concat）→ 做一次线性变换</strong>
得到最终输出。</p>
<blockquote>
<p>线性bian’h把拼接后的多头结果 <code>Z_concat</code>（形状
batch×seq×d_model）重新<strong>线性映射</strong>回与输入相同的维度，同时让网络可以<strong>学习如何融合不同头的信息</strong>。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1MY41137AK?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Transformer模型】曼妙动画轻松学，形象比喻贼好记_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1HsTyz8ECC?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Transformer原理及架构：多头自注意力机制_哔哩哔哩_bilibili</a></p>
<h3 id="残差连接residual-connection和层归一化layer-normalization-layernorm">残差连接（Residual
Connection）和层归一化（Layer Normalization, LayerNorm）</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808150313758.png" alt="image-20250808150313758">
<figcaption aria-hidden="true">image-20250808150313758</figcaption>
</figure>
<p>在 Transformer 架构中，<strong>残差连接</strong>（Residual
Connection）与<strong>层归一化</strong>（LayerNorm）结合使用，统称为
<strong>Add &amp; Norm</strong> 操作。</p>
<h4 id="add残差连接residual-connection">Add（残差连接，Residual
Connection）</h4>
<p>残差连接是一种跳跃连接（Skip
Connection），它将层的输入直接加到输出上（观察架构图中的箭头），对应的公式如下：</p>
<p><span class="math display">Output = SubLayer(<em>x</em>) + <em>x</em></span></p>
<p>这种连接方式有效缓解了<strong>深层神经网络的梯度消失</strong>问题。</p>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808151004667.png" alt="image-20250808151004667">
<figcaption aria-hidden="true">image-20250808151004667</figcaption>
</figure>
<p>在transform中，就是输入的矩阵x加上经过注意力机制计算出来的z矩阵</p>
<h4 id="norm层归一化layer-normalization">Norm（层归一化，Layer
Normalization）</h4>
<p><strong>层归一化</strong>（LayerNorm）是一种归一化技术，用于提升训练的稳定性和模型的泛化能力。</p>
<p>假设输入向量为 <span class="math inline"><em>x</em> = (<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>d</em></sub>)</span>,
LayerNorm 的计算步骤如下：</p>
<ol type="1">
<li><p><strong>计算均值和方差</strong>： 对输入的所有特征求均值 <span class="math inline"><em>μ</em></span> 和方差 <span class="math inline"><em>σ</em><sup>2</sup></span>：</p>
<p><span class="math inline">$`
\mu = \frac{1}{d} \sum_{j=1}^{d} x_j, \quad
\sigma^2 = \frac{1}{d} \sum_{j=1}^{d} (x_j - \mu)^2
`$</span></p></li>
<li><p><strong>归一化公式</strong>： 将输入特征 <span class="math inline"><em>x̂</em><sub><em>i</em></sub></span>
进行归一化：</p>
<p><span class="math inline">$`
\hat{x}_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}
`$</span></p>
<p>其中, <span class="math inline"><em>ϵ</em></span>
是一个很小的常数（比如 1e-9），用于防止除以零的情况。</p></li>
<li><p><strong>引入可学习参数</strong>： 归一化后的输出乘以 <span class="math inline"><em>γ</em></span> 并加上 <span class="math inline"><em>β</em></span>, 公式如下：</p>
<p><span class="math inline">$`
\text{Output} = \gamma \hat{x} + \beta
`$</span></p>
<p>其中 <span class="math inline"><em>γ</em></span> 和 <span class="math inline"><em>β</em></span>
是可学习的参数，用于进一步调整归一化后的输出。</p></li>
</ol>
<h3 id="前馈神经网络-position-wise-feed-forward-networksffn">前馈神经网络
Position-wise Feed-Forward Networks（FFN）</h3>
<p>在 Transformer 中，前馈网络层（Feed-Forward
Network，FFN）的作用可以概括为一句话：
<strong>“对每个位置的向量进行非线性变换，增加模型的表达能力。”</strong></p>
<p>在编码器-解码器架构中，另一个看起来“大一点”的模块就是 Feed
Forward，它在每个位置 <span class="math inline"><em>i</em></span>
上的计算可以表示为：</p>
<p><span class="math display">FFN(<em>x</em><sub><em>i</em></sub>) = max(0, <em>x</em><sub><em>i</em></sub><em>W</em><sub>1</sub> + <em>b</em><sub>1</sub>)<em>W</em><sub>2</sub> + <em>b</em><sub>2</sub></span></p>
<p>其中：</p>
<ul>
<li><span class="math inline"><em>x</em><sub><em>i</em></sub> ∈ ℝ<sup><em>d</em><sub>model</sub></sup></span>
表示第 <span class="math inline"><em>i</em></span>
个位置的输入向量。</li>
<li><span class="math inline"><em>W</em><sub>1</sub> ∈ ℝ<sup><em>d</em><sub>model</sub> × <em>d</em><sub>ff</sub></sup></span>
和 <span class="math inline"><em>W</em><sub>2</sub> ∈ ℝ<sup><em>d</em><sub>ff</sub> × <em>d</em><sub>model</sub></sup></span>
是两个线性变换的权重矩阵。</li>
<li><span class="math inline"><em>b</em><sub>1</sub> ∈ ℝ<sup><em>d</em><sub>ff</sub></sup></span>
和 <span class="math inline"><em>b</em><sub>2</sub> ∈ ℝ<sup><em>d</em><sub>model</sub></sup></span>
是对应的偏置向量。</li>
<li><span class="math inline">max(0, ⋅)</span> 是 <strong>ReLU
激活函数</strong>，用于引入非线性。</li>
</ul>
<h3 id="大模型发展树">大模型发展树</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807171237889.png" alt="image-20250807171237889">
<figcaption aria-hidden="true">image-20250807171237889</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807173520481.png" alt="image-20250807173520481">
<figcaption aria-hidden="true">image-20250807173520481</figcaption>
</figure>
<h3 id="预训练语言模型">预训练语言模型</h3>
<p>预训练语言模型（PLM）是一种通过大量文本数据进行无监督或弱监督训练的语言模型，目的是学习语言的通用表示（即语言的模式、语法、语义等）。这些模型通常在大规模文本数据上进行预训练，然后可以被微调（Fine
- tuning）以适应各种下游任务，如文本分类、问答、命名实体识别等。</p>
<p>预训练语言模型的核心思想是利用大量的无标注文本数据来学习语言的通用特征，从而为各种自然语言处理任务提供强大的语言理解能力。预训练模型可以显著提高任务的性能，减少对标注数据的依赖，并且能够快速适应新的任务。</p>
<h4 id="bert模型encoder-only-plm">BERT模型（Encoder-only PLM）</h4>
<p>针对 Encoder、Decoder 的特点，引入 ELMo
的预训练思路，开始出现不同的、对 Transformer
进行优化的思路。例如，<strong>Google 仅选择了 Encoder
层</strong>，通过将 Encoder
层进行堆叠，再提出不同的预训练任务-掩码语言模型（Masked Language
Model，MLM），打造了一统自然语言理解（Natural Language
Understanding，NLU）任务的代表模型——<strong>BERT</strong>。</p>
<p>BERT，全名为 Bidirectional Encoder Representations from
Transformers，是由 Google 团队在
2018年发布的预训练语言模型。该模型发布于论文《BERT: Pre-training of Deep
Bidirectional Transformers for Language Understanding》，实现了包括
GLUE、MultiNLI 等七个自然语言处理评测任务的最优性能（State Of The
Art，SOTA），堪称里程碑式的成果。</p>
<h4 id="t5encoder-decoder-plm">T5（Encoder-Decoder PLM）</h4>
<p>BERT 也存在一些问题，例如 MLM
任务和下游任务微调的不一致性，以及无法处理超过模型训练长度的输入等问题。为了解决这些问题，研究者们提出了
<strong>Encoder-Decoder 模型</strong>，通过引入 Decoder
部分来解决这些问题，同时也为 NLP 领域带来了新的思路和方法。</p>
<p><strong>T5（Text-To-Text Transfer Transformer）是由 Google
提出的一种预训练语言模型</strong>，通过将所有 NLP
任务统一表示为文本到文本的转换问题，大大简化了模型设计和任务处理。T5
基于 Transformer
架构，包含编码器和解码器两个部分，使用自注意力机制和多头注意力捕捉全局依赖关系，利用相对位置编码处理长序列中的位置信息，并在每层中包含前馈神经网络进一步处理特征。</p>
<h4 id="llama模型decoder-only-plm">LLama模型（Decoder-Only PLM）</h4>
<p>LLaMA模型是由Meta（前Facebook）开发的一系列大型预训练语言模型。从LLaMA-1到LLaMA-3，LLaMA系列模型展示了大规模预训练语言模型的演进及其在实际应用中的显著潜力。</p>
<h4 id="gpt模型decoder-only-plm">GPT模型（Decoder-Only PLM）</h4>
<p>GPT，即 Generative Pre-Training Language Model，是由 OpenAI 团队于
2018年发布的预训练语言模型。虽然学界普遍认可 BERT
作为预训练语言模型时代的代表，但首先明确提出<strong>预训练-微调思想的模型</strong>其实是
GPT。</p>
<p>GPT
提出了通用预训练的概念，也就是在海量无监督语料上预训练，进而在每个特定任务上进行微调，从而实现这些任务的巨大收益。虽然在发布之初，由于性能略输于不久后发布的
BERT，没能取得轰动性成果，也没能让 GPT 所使用的 <strong>Decoder-Only
架构</strong>成为学界研究的主流，但 OpenAI
团队坚定地选择了不断扩大预训练数据、增加模型参数，在 GPT
架构上不断优化，最终在 2020年发布的 GPT-3 成就了 LLM 时代的基础，并以
GPT-3 为基座模型的 ChatGPT 成功打开新时代的大门，成为 LLM
时代的最强竞争者也是目前的最大赢家。</p>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://transformers.run/">Hello! ·
Transformers快速入门</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/jsksxs360/How-to-use-Transformers">jsksxs360/How-to-use-Transformers:
Transformers 库快速入门教程</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN">Hoper-J/AI-Guide-and-Demos-zh_CN:
这是一份入门AI/LLM大模型的逐步指南，包含教程和演示代码，带你从API走进本地大模型部署和微调，代码文件会提供Kaggle或Colab在线版本，即便没有显卡也可以进行学习。项目中还开设了一个小型的代码游乐场🎡，你可以尝试在里面实验一些有意思的AI脚本。同时，包含李宏毅
(HUNG-YI LEE）2024生成式人工智能导论课程的完整中文镜像作业。</a></p>
<p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/happy-llm/#/">Happy-LLM</a></p>
<p><a target="_blank" rel="noopener" href="https://gengzhige.ai/video.html">梗直哥</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1RBdTYxENw/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">90%人不知道的LLM黑科技：拆解Transformer如何吃透全网知识！_哔哩哔哩_bilibili</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">MCP 学习笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-27 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-27T00:00:00+08:00">2025-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-15 09:25:54" itemprop="dateModified" datetime="2025-08-15T09:25:54+08:00">2025-08-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/mcp/" itemprop="url" rel="index"><span itemprop="name">mcp</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="什么是-mcp">什么是 MCP？</h3>
<ul>
<li><strong>全称</strong>：Model Context Protocol</li>
<li><strong>作用</strong>：让 AI 助手（如 Claude、Cline
等）在对话过程中，动态调用外部工具（Tool）完成复杂任务（读写文件、查询数据库、调用
API 等）。</li>
<li><strong>组成</strong>：
<ol type="1">
<li><strong>MCP Host</strong>（宿主，如 Cline、Claude Desktop）</li>
<li><strong>MCP Server</strong>（提供 Tool 的后台服务）</li>
<li><strong>Tool</strong>（具体功能单元，如 <code>read_file</code>,
<code>exec_command</code> 等）</li>
</ol></li>
</ul>
<h3 id="核心概念速记">核心概念速记</h3>
<ul>
<li><strong>MCP Server</strong>
<ul>
<li>一个独立进程，提供 1-N 个 Tool。</li>
<li>可以用任何语言编写，只要暴露标准 MCP 接口。</li>
</ul></li>
<li><strong>Tool</strong>
<ul>
<li>最小执行单元，必须包含：
<ul>
<li>name（唯一）</li>
<li>description（让 LLM 理解何时调用）</li>
<li>input schema（参数结构，JSON Schema）</li>
</ul></li>
</ul></li>
<li><strong>交互流程（重点）</strong>
<ul>
<li>在启动mcp server时，server将tool信息传送给host</li>
<li>用户在 Host 输入自然语言需求。</li>
<li>Host 将需求 + 可用 Tool 列表发给 LLM。</li>
<li>LLM 判断调用哪个 Tool，并填充参数。</li>
<li>Host 通过 MCP 协议向对应 Server 发送请求。</li>
<li>Server 执行 Tool 并返回结果。</li>
<li>Host 将结果合并上下文，继续对话。</li>
</ul></li>
</ul>
<h3 id="mcp和fuction-calling的区别">mcp和fuction calling的区别</h3>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 46%">
<col style="width: 46%">
</colgroup>
<thead>
<tr>
<th>维度</th>
<th>Function Calling（FC）</th>
<th>MCP（Model Context Protocol）</th>
</tr>
</thead>
<tbody>
<tr>
<td>本质</td>
<td><strong>能力</strong> ——
某个大模型原生就带的一种「调用函数」功能</td>
<td><strong>协议</strong> —— 定义 AI
与外部世界如何长期、标准、可复用地交互</td>
</tr>
<tr>
<td>工作方式</td>
<td>模型在一次推理里<strong>主动</strong>决定要调用哪个函数，并吐出结构化参数</td>
<td>通过「客户端-服务器」架构，由 MCP Server
<strong>被动</strong>等待模型或 Agent 的请求</td>
</tr>
<tr>
<td>是否标准化</td>
<td>否。OpenAI、Anthropic、百度等各家接口格式不同</td>
<td>是。统一 JSON-RPC 2.0 协议，跨模型通用</td>
</tr>
<tr>
<td>上下文管理</td>
<td>单次调用，无状态；复杂多轮任务需自己维护</td>
<td>协议层面支持会话、状态、长链路任务</td>
</tr>
<tr>
<td>复用/共享</td>
<td>函数代码往往紧耦合在项目里，换模型就得重写</td>
<td>一次写成 MCP Server，可被任何支持 MCP 的模型/IDE/Agent 直接插用</td>
</tr>
</tbody>
</table>
<p>一句话总结： <strong>Function Calling
是「某个模型自带的快捷指令」，MCP
是「让任何模型都能统一插拔工具的工业标准」。</strong> 二者并非互斥——MCP
的实现里仍然可以用 Function Calling
去触发具体函数，但它把「怎么描述工具、怎么发现工具、怎么保持会话」这些事都标准化了，从而解决了
FC 带来的碎片化、难维护、难共享的问题 。</p>
<h3 id="安装mcp">安装mcp</h3>
<p>在mcp server市场查找自己想用的mcp服务，如<a target="_blank" rel="noopener" href="https://mcp.so/server/fetch/modelcontextprotocol?tab=content">Fetch
MCP Server</a></p>
<p>复制mcp配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;mcpServers&quot;: &#123;</span><br><span class="line">    &quot;fetch&quot;: &#123;</span><br><span class="line">      &quot;command&quot;: &quot;uvx&quot;,</span><br><span class="line">      &quot;args&quot;: [</span><br><span class="line">        &quot;mcp-server-fetch&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在mcp host 中安装，如trae</p>
<p>host会自动完成对mcp的配置</p>
<h3 id="创建一个mcp-server">创建一个mcp server</h3>
<p>初始化项目</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">uv init weather</span><br><span class="line"></span><br><span class="line">uv sync</span><br><span class="line"></span><br><span class="line">source .venv/bin/activate </span><br><span class="line"></span><br><span class="line">#添加依赖</span><br><span class="line">uv add &quot;mcp[cli]&quot; httpx</span><br></pre></td></tr></table></figure>
<p>创建weather.py</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"># 导入类型提示模块，用于类型注解</span><br><span class="line">from typing import Any</span><br><span class="line"></span><br><span class="line"># 导入httpx库，用于发送HTTP请求</span><br><span class="line">import httpx</span><br><span class="line"></span><br><span class="line"># 从mcp.server.fastmcp模块导入FastMCP类</span><br><span class="line"># FastMCP是一个快速构建MCP（Model Control Protocol）服务器的框架</span><br><span class="line">from mcp.server.fastmcp import FastMCP</span><br><span class="line"></span><br><span class="line"># 创建FastMCP实例，命名为&quot;weather&quot;，日志级别设置为ERROR（只显示错误信息）</span><br><span class="line">mcp = FastMCP(&quot;weather&quot;, log_level=&quot;ERROR&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 常量定义</span><br><span class="line"># NWS（National Weather Service）API的基础URL</span><br><span class="line">NWS_API_BASE = &quot;https://api.weather.gov&quot;</span><br><span class="line"># 用户代理字符串，用于标识应用程序</span><br><span class="line">USER_AGENT = &quot;weather-app/1.0&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">async def make_nws_request(url: str) -&gt; dict[str, Any] | None:</span><br><span class="line">    &quot;&quot;&quot;向NWS API发起请求并处理错误。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        url: 要请求的API URL</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        成功时返回解析后的JSON数据字典，失败时返回None</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 设置请求头信息</span><br><span class="line">    headers = &#123;</span><br><span class="line">        &quot;User-Agent&quot;: USER_AGENT,           # 用户代理标识</span><br><span class="line">        &quot;Accept&quot;: &quot;application/geo+json&quot;    # 接受的数据格式</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    # 创建异步HTTP客户端</span><br><span class="line">    async with httpx.AsyncClient() as client:</span><br><span class="line">        try:</span><br><span class="line">            # 发起GET请求，设置超时时间为30秒</span><br><span class="line">            response = await client.get(url, headers=headers, timeout=30.0)</span><br><span class="line">            # 如果响应状态码不是2xx，抛出异常</span><br><span class="line">            response.raise_for_status()</span><br><span class="line">            # 返回解析后的JSON数据</span><br><span class="line">            return response.json()</span><br><span class="line">        except Exception:</span><br><span class="line">            # 捕获所有异常，返回None表示请求失败</span><br><span class="line">            return None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def format_alert(feature: dict) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;将警报数据格式化为可读的字符串。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        feature: 包含警报信息的字典</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的警报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 获取警报属性</span><br><span class="line">    props = feature[&quot;properties&quot;]</span><br><span class="line">    # 格式化警报信息，使用get方法提供默认值防止键不存在</span><br><span class="line">    return f&quot;&quot;&quot;</span><br><span class="line">事件: &#123;props.get(&#x27;event&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">区域: &#123;props.get(&#x27;areaDesc&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">严重程度: &#123;props.get(&#x27;severity&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">描述: &#123;props.get(&#x27;description&#x27;, &#x27;无描述信息&#x27;)&#125;</span><br><span class="line">指示: &#123;props.get(&#x27;instruction&#x27;, &#x27;无具体指示&#x27;)&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 使用@mcp.tool()装饰器将函数注册为MCP工具</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_alerts(state: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定美国州的天气警报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        state: 两个字母的美国州代码（例如：CA, NY）</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的警报信息字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 构建获取州警报的URL</span><br><span class="line">    url = f&quot;&#123;NWS_API_BASE&#125;/alerts/active/area/&#123;state&#125;&quot;</span><br><span class="line">    # 发起API请求获取数据</span><br><span class="line">    data = await make_nws_request(url)</span><br><span class="line"></span><br><span class="line">    # 检查数据是否有效</span><br><span class="line">    if not data or &quot;features&quot; not in data:</span><br><span class="line">        return &quot;无法获取警报或未找到警报。&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否有警报</span><br><span class="line">    if not data[&quot;features&quot;]:</span><br><span class="line">        return &quot;该州无活动警报。&quot;</span><br><span class="line"></span><br><span class="line">    # 格式化所有警报</span><br><span class="line">    alerts = [format_alert(feature) for feature in data[&quot;features&quot;]]</span><br><span class="line">    # 用分隔符连接所有警报</span><br><span class="line">    return &quot;\n---\n&quot;.join(alerts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 注册为MCP工具的天气预报函数</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_forecast(latitude: float, longitude: float) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定位置的天气预报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        latitude: 位置的纬度</span><br><span class="line">        longitude: 位置的经度</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的天气预报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 首先获取预报网格端点</span><br><span class="line">    points_url = f&quot;&#123;NWS_API_BASE&#125;/points/&#123;latitude&#125;,&#123;longitude&#125;&quot;</span><br><span class="line">    points_data = await make_nws_request(points_url)</span><br><span class="line"></span><br><span class="line">    # 检查点数据是否获取成功</span><br><span class="line">    if not points_data:</span><br><span class="line">        return &quot;无法获取此位置的预报数据。&quot;</span><br><span class="line"></span><br><span class="line">    # 从点响应中获取预报URL</span><br><span class="line">    forecast_url = points_data[&quot;properties&quot;][&quot;forecast&quot;]</span><br><span class="line">    forecast_data = await make_nws_request(forecast_url)</span><br><span class="line"></span><br><span class="line">    # 检查预报数据是否获取成功</span><br><span class="line">    if not forecast_data:</span><br><span class="line">        return &quot;无法获取详细预报。&quot;</span><br><span class="line"></span><br><span class="line">    # 将时间段格式化为可读的预报</span><br><span class="line">    periods = forecast_data[&quot;properties&quot;][&quot;periods&quot;]</span><br><span class="line">    forecasts = []</span><br><span class="line">    # 只显示接下来的5个时间段</span><br><span class="line">    for period in periods[:5]:</span><br><span class="line">        forecast = f&quot;&quot;&quot;</span><br><span class="line">&#123;period[&#x27;name&#x27;]&#125;:</span><br><span class="line">温度: &#123;period[&#x27;temperature&#x27;]&#125;°&#123;period[&#x27;temperatureUnit&#x27;]&#125;</span><br><span class="line">风力: &#123;period[&#x27;windSpeed&#x27;]&#125; &#123;period[&#x27;windDirection&#x27;]&#125;</span><br><span class="line">预报: &#123;period[&#x27;detailedForecast&#x27;]&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">        forecasts.append(forecast)</span><br><span class="line"></span><br><span class="line">    # 用分隔符连接所有预报</span><br><span class="line">    return &quot;\n---\n&quot;.join(forecasts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 初始化并运行服务器，使用stdio传输方式</span><br><span class="line">    mcp.run(transport=&#x27;stdio&#x27;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><span class="citation" data-cites="mcp.tool">@mcp.tool</span>()可以将函数内的字符串，参数类型等信息传给大模型，以供大模型决定何时调用这个tool</p>
<p>mcp.run(transport=‘stdio’)说明mcp
server和host的传输方式是输入和输出</p>
</blockquote>
<p>mcp server 配置信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&quot;weather&quot;: &#123;</span><br><span class="line">    &quot;disabled&quot;: false,</span><br><span class="line">    &quot;timeout&quot;: 60,</span><br><span class="line">    &quot;command&quot;: &quot;uv&quot;,</span><br><span class="line">    &quot;args&quot;: [</span><br><span class="line">      &quot;--directory&quot;,</span><br><span class="line">      &quot;/Users/joeygreen/PycharmProjects/weather&quot;,</span><br><span class="line">      &quot;run&quot;,</span><br><span class="line">      &quot;weather.py&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;transportType&quot;: &quot;stdio&quot;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>“disabled”: false表示该服务是否被禁用。<code>false</code>
表示该服务是启用状态，可以正常运行。</p>
<p>“timeout”: 60设置该服务的超时时间，单位为秒。</p>
<p>“command”: “uv”指定执行该服务时使用的命令。</p>
<p>“args”出了执行 <code>command</code> 时需要传递的参数。</p>
<p>“transportType”: “stdio”指定服务的通信方式。<code>stdio</code>
表示标准输入输出流（Standard Input Output），通常用于进程间通信。</p>
</blockquote>
<h3 id="解析mcp-server与host的通信">解析mcp server与host的通信</h3>
<figure>
<img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727154739013.png" alt="image-20250727154739013">
<figcaption aria-hidden="true">image-20250727154739013</figcaption>
</figure>
<p>输入为host对server发送，输出为server对host发送，以下将列举几个重要的说明</p>
<p>输入中：<code>method</code>字段为host告诉server接下来要干什么，如<strong>初始化
(Initialization)</strong>，<strong>通知已初始化
(Notification)</strong>，<strong>查询可用工具 (Listing
Tools)</strong>，<strong>调用工具 (Calling a Tool)</strong></p>
<p><code>protocolVersion</code>说明了mcp使用的协议版本</p>
<p>以下见server返回的tool信息，其中的一个参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;get_forecast&quot;,</span><br><span class="line">    &quot;description&quot;: &quot;Get weather forecast for a location.\n\nArgs:\n    latitude: Latitude of the location\n    longitude: Longitude of the location\n&quot;,</span><br><span class="line">    &quot;inputSchema&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;latitude&quot;: &#123;</span><br><span class="line">                &quot;title&quot;: &quot;Latitude&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;number&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;longitude&quot;: &#123;</span><br><span class="line">                &quot;title&quot;: &quot;Longitude&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;number&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;required&quot;: [</span><br><span class="line">            &quot;latitude&quot;,</span><br><span class="line">            &quot;longitude&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;title&quot;: &quot;get_forecastArguments&quot;,</span><br><span class="line">        &quot;type&quot;: &quot;object&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以和定义的函数对比学习</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"># 注册为MCP工具的天气预报函数</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_forecast(latitude: float, longitude: float) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定位置的天气预报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        latitude: 位置的纬度</span><br><span class="line">        longitude: 位置的经度</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的天气预报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 首先获取预报网格端点</span><br><span class="line">    points_url = f&quot;&#123;NWS_API_BASE&#125;/points/&#123;latitude&#125;,&#123;longitude&#125;&quot;</span><br><span class="line">    points_data = await make_nws_request(points_url)</span><br><span class="line"></span><br><span class="line">    # 检查点数据是否获取成功</span><br><span class="line">    if not points_data:</span><br><span class="line">        return &quot;无法获取此位置的预报数据。&quot;</span><br><span class="line"></span><br><span class="line">    # 从点响应中获取预报URL</span><br><span class="line">    forecast_url = points_data[&quot;properties&quot;][&quot;forecast&quot;]</span><br><span class="line">    forecast_data = await make_nws_request(forecast_url)</span><br><span class="line"></span><br><span class="line">    # 检查预报数据是否获取成功</span><br><span class="line">    if not forecast_data:</span><br><span class="line">        return &quot;无法获取详细预报。&quot;</span><br><span class="line"></span><br><span class="line">    # 将时间段格式化为可读的预报</span><br><span class="line">    periods = forecast_data[&quot;properties&quot;][&quot;periods&quot;]</span><br><span class="line">    forecasts = []</span><br><span class="line">    # 只显示接下来的5个时间段</span><br><span class="line">    for period in periods[:5]:</span><br><span class="line">        forecast = f&quot;&quot;&quot;</span><br><span class="line">&#123;period[&#x27;name&#x27;]&#125;:</span><br><span class="line">温度: &#123;period[&#x27;temperature&#x27;]&#125;°&#123;period[&#x27;temperatureUnit&#x27;]&#125;</span><br><span class="line">风力: &#123;period[&#x27;windSpeed&#x27;]&#125; &#123;period[&#x27;windDirection&#x27;]&#125;</span><br><span class="line">预报: &#123;period[&#x27;detailedForecast&#x27;]&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">        forecasts.append(forecast)</span><br><span class="line"></span><br><span class="line">    # 用分隔符连接所有预报</span><br><span class="line">    return &quot;\n---\n&quot;.join(forecasts)</span><br></pre></td></tr></table></figure>
<p><code>description</code>内容即为我们在定义这个tool的时候写的<strong>文档字符串</strong>（Documentation
String），通常简称为 <strong>docstring</strong></p>
<p><code>inputSchema</code> 是在MCP（Model Control
Protocol）中用来<strong>描述工具（tool）所需参数的结构和类型的规范</strong>。它本质上是一个JSON
Schema。</p>
<blockquote>
<p>JSON Schema 是一个用于<strong>描述和验证 JSON
数据结构的规范</strong>。你可以把它理解为 JSON
数据的“蓝图”或“模板”。</p>
</blockquote>
<p><code>required</code>指明哪些参数是必需的，哪些是可选的。</p>
<h3 id="理解mcp的本质">理解mcp的本质</h3>
<p>以上内容皆是server与host直接的交互，本质上可以理解成host对server提供的工具进行注册与使用。这其中并不涉及到host与大模型的交互，也就是大模型是如何使用host提供的信息。实际上不同的mcp
host与模型的交互协议也不同，如cline使用的是xml格式；cherry
studio使用的则是fuction calling</p>
<p>再看mcp的全称Model Context
Protocol，模型上下文协议，也就是mcp增加模型的扩展性，使他可以获取更多信息，而server就是为模型提供更多信息的工具</p>
<h3 id="mcp-host与模型的交互">mcp host与模型的交互</h3>
<p>使用中转服务器截获日志</p>
<figure>
<img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727163811531-1753605912284-1.png" alt="image-20250727163811531">
<figcaption aria-hidden="true">image-20250727163811531</figcaption>
</figure>
<p>以下为cline发送给模型的请求</p>
<figure>
<img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727164527797.png" alt="image-20250727164527797">
<figcaption aria-hidden="true">image-20250727164527797</figcaption>
</figure>
<p><code>messages</code>包含了系统提示词与用户输入</p>
<p>先来看系统提示词，cline提供的提示词包括工具使用格式，工具信息，工具使用方法等。这里重点说一下，cline的工具使用格式xml</p>
<p>结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;tool_name&gt;</span><br><span class="line">&lt;parameter1_name&gt;value1&lt;/parameter1_name&gt;</span><br><span class="line">&lt;parameter2_name&gt;value2&lt;/parameter2_name&gt;</span><br><span class="line">...</span><br><span class="line">&lt;/tool_name&gt;</span><br></pre></td></tr></table></figure>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;read_file&gt;</span><br><span class="line">src/main.js</span><br><span class="line">&lt;/read_file&gt;</span><br></pre></td></tr></table></figure>
<p>再举个例子</p>
<p>use_mcp_tool 描述：请求使用由连接的 MCP 服务器提供的工具。每个 MCP
服务器可以提供具有不同功能的多个工具。工具有定义的输入模式，用于指定必需和可选参数。
参数：</p>
<p>server_name: (必需) 提供该工具的 MCP 服务器的名称 tool_name: (必需)
要执行的工具的名称 arguments: (必需) 一个 JSON
对象，包含工具的输入参数，遵循工具的输入模式 用法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;use_mcp_tool&gt;</span><br><span class="line">&lt;server_name&gt;服务器名称在此&lt;/server_name&gt;</span><br><span class="line">&lt;tool_name&gt;工具名称在此&lt;/tool_name&gt;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">&quot;param1&quot;: &quot;value1&quot;,</span><br><span class="line">&quot;param2&quot;: &quot;value2&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&lt;/use_mcp_tool&gt;</span><br></pre></td></tr></table></figure>
<p>模型返回响应如下</p>
<figure>
<img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727174504506.png" alt="image-20250727174504506">
<figcaption aria-hidden="true">image-20250727174504506</figcaption>
</figure>
<p>sse连接，流式输出</p>
<blockquote>
<p>SSE 是一种<strong>基于标准
HTTP</strong>、<strong>只允许服务器向客户端单向推送文本流</strong>的实时通信技术，浏览器原生支持，自动重连，常用于<strong>AI
流式回答</strong>、<strong>实时日志</strong>、<strong>股价/监控推送</strong>等场景。</p>
<p>即客户端发送一次请求，连续接受多次响应直到结束</p>
</blockquote>
<h3 id="mcp的三种传输协议">mcp的三种传输协议</h3>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 29%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 19%">
</colgroup>
<thead>
<tr>
<th>协议名称</th>
<th>通信方式</th>
<th>适用场景</th>
<th>优势</th>
<th>局限</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Stdio</strong>（标准输入输出）</td>
<td>使用进程的标准输入（stdin）和标准输出（stdout）进行本地通信，基于
JSON-RPC 2.0 格式</td>
<td>本地开发、调试、IDE插件、命令行工具</td>
<td>简单易实现、跨平台、低延迟</td>
<td>仅支持本地通信，无法跨网络，低并发</td>
</tr>
<tr>
<td><strong>SSE</strong>（Server-Sent Events）</td>
<td>客户端通过 HTTP POST 发送请求，服务器通过 SSE 单向推送流式响应</td>
<td>实时监控、新闻推送、远程服务调用</td>
<td>基于 HTTP，浏览器友好，支持流式数据</td>
<td>仅支持单向通信，MCP官方已标记为“即将废弃”</td>
</tr>
<tr>
<td><strong>Streamable HTTP</strong>（新型流式HTTP）</td>
<td>支持双向流式通信的现代 HTTP 协议，替代 SSE，支持会话恢复、OAuth
认证等</td>
<td>分布式系统、高并发、双向实时交互</td>
<td>双向通信、高性能、企业级安全机制</td>
<td>实现较复杂，生态仍在发展中</td>
</tr>
</tbody>
</table>
<h3 id="react">ReAct</h3>
<p>ReAct
是一种用于增强大型语言模型（LLMs）推理和行动能力的技术框架，它通过结合“推理”（Reasoning）和“行动”（Acting）来提升模型处理复杂任务的能力。</p>
<p>其工作流程通常包括以下几个步骤：</p>
<ol type="1">
<li><strong>思考（Reasoning）</strong>：模型对当前问题进行分析，思考下一步需要采取的行动。</li>
<li><strong>行动（Acting）</strong>：模型决定调用哪些工具或函数，并提供必要的参数。</li>
<li><strong>观察（Observation）</strong>：工具执行后返回结果，模型对结果进行观察。</li>
<li><strong>响应（Response）</strong>：根据观察结果，模型生成最终的用户响应。</li>
</ol>
<p>实际应用上就是告诉大模型用ReAct这种模式来思考</p>
<h3 id="参考资料">参考资料</h3>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1uronYREWR?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">MCP终极指南
- 从原理到实战，带你深入掌握MCP（基础篇）_哔哩哔哩_bilibili</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/" class="post-title-link" itemprop="url">LangGraph学习——agent——下</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-22T00:00:00+08:00">2025-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-13 09:25:38" itemprop="dateModified" datetime="2025-08-13T09:25:38+08:00">2025-08-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言">前言</h3>
<p>本教程为langchain官方教程的学习记录</p>
<p><a target="_blank" rel="noopener" href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a target="_blank" rel="noopener" href="https://github.com/zxj-2023/learn-rag-langchain">[learn-rag-langchain/academy-langgraph
at main ·
zxj-2023/learn-rag-langchain](https://github.com/zxj-2023/learn-rag-langchain/tree/main/academy-langgraph)</a></p>
<h3 id="module-4">module-4</h3>
<h4 id="parallel-node-execution-并行节点执行"><strong>Parallel node
execution</strong> <strong>并行节点执行</strong></h4>
<h5 id="waiting-for-nodes-to-finish-等待节点完成"><strong>Waiting for
nodes to finish</strong> <strong>等待节点完成</strong></h5>
<p>现在，让我们考虑一个案例，其中一个并行路径的步骤比另一个多。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># Initialize each node with node_secret </span><br><span class="line">builder.add_node(&quot;a&quot;, ReturnNodeValue(&quot;I&#x27;m A&quot;))</span><br><span class="line">builder.add_node(&quot;b&quot;, ReturnNodeValue(&quot;I&#x27;m B&quot;))</span><br><span class="line">builder.add_node(&quot;b2&quot;, ReturnNodeValue(&quot;I&#x27;m B2&quot;))</span><br><span class="line">builder.add_node(&quot;c&quot;, ReturnNodeValue(&quot;I&#x27;m C&quot;))</span><br><span class="line">builder.add_node(&quot;d&quot;, ReturnNodeValue(&quot;I&#x27;m D&quot;))</span><br><span class="line"></span><br><span class="line"># Flow</span><br><span class="line">builder.add_edge(START, &quot;a&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;b&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;c&quot;)</span><br><span class="line">builder.add_edge(&quot;b&quot;, &quot;b2&quot;)</span><br><span class="line">builder.add_edge([&quot;b2&quot;, &quot;c&quot;], &quot;d&quot;)</span><br><span class="line">builder.add_edge(&quot;d&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722143802652.png" alt="image-20250722143802652">
<figcaption aria-hidden="true">image-20250722143802652</figcaption>
</figure>
<p>在这种情况下，<code>b</code>、<code>b2</code> 和 <code>c</code>
都是同一个步骤的一部分。图形将在进入 <code>d</code>
步骤之前等待所有这些操作完成。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Adding I&#x27;m A to []</span><br><span class="line">Adding I&#x27;m B to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m C to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m B2 to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;]</span><br><span class="line">Adding I&#x27;m D to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;]</span><br><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="setting-the-order-of-state-updates-设置状态更新的顺序"><strong>Setting
the order of state updates</strong>
<strong>设置状态更新的顺序</strong></h5>
<p>然而，在每个步骤中，我们无法对状态更新的顺序进行具体控制！简单来说，它是基于图拓扑结构由
LangGraph 确定的确定性顺序，该顺序为
<strong><em>*我们无法控制*</em></strong>。</p>
<p>上面，我们看到 <code>c</code> 被添加在 <code>b2</code> 之前</p>
<p>然而，我们可以使用自定义 reducer
来定制此功能，例如，对状态更新进行排序。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def sorting_reducer(left, right):</span><br><span class="line">    &quot;&quot;&quot; 合并并排序列表中的值&quot;&quot;&quot;</span><br><span class="line">    # 如果 left 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(left, list):</span><br><span class="line">        left = [left]</span><br><span class="line"></span><br><span class="line">    # 如果 right 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(right, list):</span><br><span class="line">        right = [right]</span><br><span class="line">    </span><br><span class="line">    # 合并 left 和 right 列表，然后升序排序</span><br><span class="line">    return sorted(left + right, reverse=False)</span><br><span class="line">class State(TypedDict):</span><br><span class="line">    # sorting_reducer 函数将对 state 中的值进行排序</span><br><span class="line">    state: Annotated[list, sorting_reducer]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<p>现在，reducer 对更新的状态值进行排序！<code>sorting_reducer</code>
示例对所有值进行全局排序。我们还可以：</p>
<ol type="1">
<li>在并行步骤期间将输出写入状态中的单独字段<br>
</li>
<li>在并行步骤之后使用“汇”节点来合并和排序这些输出<br>
</li>
<li>合并后清除临时字段</li>
</ol>
<p>请参阅 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/branching/#stable-sorting">docs</a>
以获取更多详细信息。</p>
<h5 id="working-with-llms-使用-llms"><strong>Working with LLMs</strong>
<strong>使用 LLMs</strong></h5>
<p>现在，让我们添加一个现实中的例子！我们希望从两个外部来源（Wikipedia
和 Web-Search）收集上下文信息，并让 LLM 回答一个问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br><span class="line">from langchain_community.tools import TavilySearchResults</span><br><span class="line"></span><br><span class="line">def search_web(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">    search_docs = tavily_search.invoke(state[&#x27;question&#x27;])</span><br><span class="line"></span><br><span class="line">     # 将多个搜索文档转换成了一个统一格式的长文本，每个文档都有自己的元数据（如URL），并且文档之间有明确的分隔，便于后续处理或展示。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    - 这是一个 列表推导式 (list comprehension) ，它会遍历 search_docs 列表中的每一个元素（这里我们称之为 doc ）。</span><br><span class="line">    - search_docs 里的每个 doc 应该是一个包含 &#x27;url&#x27; 和 &#x27;content&#x27; 键的字典。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = WikipediaLoader(query=state[&#x27;question&#x27;], </span><br><span class="line">                                  load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def generate_answer(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 用于回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    question = state[&quot;question&quot;]</span><br><span class="line"></span><br><span class="line">    # 模板</span><br><span class="line">    answer_template = &quot;&quot;&quot;使用以下上下文回答问题 &#123;question&#125;: &#123;context&#125;&quot;&quot;&quot;</span><br><span class="line">    answer_instructions = answer_template.format(question=question, </span><br><span class="line">                                                       context=context)    </span><br><span class="line">    </span><br><span class="line">    # 回答</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=answer_instructions)]+[HumanMessage(content=f&quot;回答问题。&quot;)])</span><br><span class="line">      </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;answer&quot;: answer&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点</span><br><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># 初始化每个节点</span><br><span class="line">builder.add_node(&quot;search_web&quot;,search_web)</span><br><span class="line">builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">builder.add_node(&quot;generate_answer&quot;, generate_answer)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">builder.add_edge(START, &quot;search_wikipedia&quot;)</span><br><span class="line">builder.add_edge(START, &quot;search_web&quot;)</span><br><span class="line">builder.add_edge(&quot;search_wikipedia&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;search_web&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;generate_answer&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722153534867.png" alt="image-20250722153534867">
<figcaption aria-hidden="true">image-20250722153534867</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = graph.invoke(&#123;&quot;question&quot;: &quot;英伟达2025年第一季度财报表现如何&quot;&#125;)</span><br><span class="line">result[&#x27;answer&#x27;].content</span><br></pre></td></tr></table></figure>
<h4 id="sub-graphs-子图"><strong>Sub-graphs</strong> 子图</h4>
<p>子图允许你在图表的不同部分创建和管理不同的状态。这在多智能体系统中尤其有用，尤其是在每个智能体都有各自状态的智能体团队中。</p>
<p>让我们考虑一个简单的例子：</p>
<ul>
<li>我有一个系统，它接收日志。</li>
<li>该系统通过不同的代理执行两个独立的子任务（总结日志，查找故障模式）。</li>
<li>我希望在两个不同的子图中执行这两个操作。</li>
</ul>
<p>最重要的是要理解图表是如何传达信息的！</p>
<p>简而言之，通信是 <strong><em>*通过重叠密钥*</em></strong>
实现的：</p>
<ul>
<li>子图可以访问父图中的 <code>docs</code>（文档）。</li>
<li>父图可以从子图中访问 <code>summary</code>（摘要）和
<code>failure_report</code>（故障报告）。</li>
</ul>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/66dbb1abf89f2d847ee6f1ff_sub-graph1.png" alt="subgraph.png">
<figcaption aria-hidden="true">subgraph.png</figcaption>
</figure>
<ol type="1">
<li><strong>Logs (Traces)</strong>:
<ul>
<li>这是系统的输入，表示一系列的日志记录。</li>
</ul></li>
<li><strong>Entry Graph</strong>:
<ul>
<li>这是系统的入口图，它包含了总体状态（Overall State），其中包含：
<ul>
<li><code>docs</code>：文档或日志数据。</li>
<li><code>summary report</code>：摘要报告，这是系统执行摘要任务后生成的。</li>
<li><code>failure report</code>：故障报告，这是系统执行故障分析任务后生成的。</li>
</ul></li>
</ul></li>
<li><strong>Call sub-graphs</strong>:
<ul>
<li>这是从入口图调用两个子图的过程，分别用于执行摘要和故障分析任务。</li>
</ul></li>
<li><strong>Summarization</strong>:
<ul>
<li>这个子图负责生成日志的摘要。它的状态（Summary State）包含：
<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>summary</code>：摘要内容。</li>
<li><code>summary report</code>：摘要报告，这是摘要任务完成后生成的。</li>
</ul></li>
</ul></li>
<li><strong>Failure Analysis</strong>:
<ul>
<li>这个子图负责分析日志中的故障模式。它的状态（Failure Analysis
State）包含：
<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>failures</code>：故障模式。</li>
<li><code>failure report</code>：故障报告，这是故障分析任务完成后生成的。</li>
</ul></li>
</ul></li>
<li><strong>Finish</strong>:
<ul>
<li>这是流程的结束点，表示两个子图的任务都已完成，并且生成了摘要报告和故障报告。</li>
</ul></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from typing import List, Optional, Annotated</span><br><span class="line"></span><br><span class="line">#logs结构</span><br><span class="line">class Log(TypedDict):</span><br><span class="line">    id: str</span><br><span class="line">    question: str</span><br><span class="line">    docs: Optional[List]</span><br><span class="line">    answer: str</span><br><span class="line">    grade: Optional[int]</span><br><span class="line">    grader: Optional[str]</span><br><span class="line">    feedback: Optional[str]</span><br></pre></td></tr></table></figure>
<h5 id="sub-graphs"><strong>Sub graphs</strong></h5>
<p>这里是失败分析子图，它使用了 <code>FailureAnalysisState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line"># 故障分析子图</span><br><span class="line">class FailureAnalysisState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于故障分析的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    failures: List[Log]     # 包含故障的日志列表</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class FailureAnalysisOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;故障分析的输出状态。&quot;&quot;&quot;</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def get_failures(state):</span><br><span class="line">    &quot;&quot;&quot;获取包含故障的日志&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 从清理后的日志中筛选出包含 &quot;grade&quot; 键的日志，这些被视为故障</span><br><span class="line">    failures = [log for log in cleaned_logs if &quot;grade&quot; in log]</span><br><span class="line">    return &#123;&quot;failures&quot;: failures&#125;</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;生成故障摘要&quot;&quot;&quot;</span><br><span class="line">    failures = state[&quot;failures&quot;]</span><br><span class="line">    # 添加功能：fa_summary = summary_generation(qs_summary)</span><br><span class="line">    fa_summary = &quot;Chroma 文档的检索质量不佳。&quot;</span><br><span class="line">    # 为每个故障日志生成一个处理过的日志标识符</span><br><span class="line">    return &#123;&quot;fa_summary&quot;: fa_summary, &quot;processed_logs&quot;: [f&quot;failure-analysis-on-log-&#123;failure[&#x27;id&#x27;]&#125;&quot; for failure in failures]&#125;</span><br><span class="line"></span><br><span class="line">fa_builder = StateGraph(state_schema=FailureAnalysisState,output_schema=FailureAnalysisOutputState)</span><br><span class="line">fa_builder.add_node(&quot;get_failures&quot;, get_failures)</span><br><span class="line">fa_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">fa_builder.add_edge(START, &quot;get_failures&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;get_failures&quot;, &quot;generate_summary&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;generate_summary&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = fa_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723094949158.png" alt="image-20250723094949158">
<figcaption aria-hidden="true">image-20250723094949158</figcaption>
</figure>
<p>这里是问题总结子图，它使用了
<code>QuestionSummarizationState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># 摘要生成子图</span><br><span class="line">class QuestionSummarizationState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于问题摘要的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    qs_summary: str         # 问题摘要</span><br><span class="line">    report: str             # 从摘要生成的报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class QuestionSummarizationOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;问题摘要的输出状态。&quot;&quot;&quot;</span><br><span class="line">    report: str             # 最终报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;从日志生成摘要。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 添加功能：summary = summarize(generate_summary)</span><br><span class="line">    summary = &quot;问题集中在 ChatOllama 和 Chroma 向量存储的使用上。&quot;</span><br><span class="line">    # 返回摘要以及已处理的日志ID</span><br><span class="line">    return &#123;&quot;qs_summary&quot;: summary, &quot;processed_logs&quot;: [f&quot;summary-on-log-&#123;log[&#x27;id&#x27;]&#125;&quot; for log in cleaned_logs]&#125;</span><br><span class="line"></span><br><span class="line">def send_to_slack(state):</span><br><span class="line">    &quot;&quot;&quot;模拟发送报告。&quot;&quot;&quot;</span><br><span class="line">    qs_summary = state[&quot;qs_summary&quot;]</span><br><span class="line">    # 添加功能：report = report_generation(qs_summary)</span><br><span class="line">    report = &quot;foo bar baz&quot;</span><br><span class="line">    return &#123;&quot;report&quot;: report&#125;</span><br><span class="line"></span><br><span class="line">qs_builder = StateGraph(QuestionSummarizationState,output_schema=QuestionSummarizationOutputState)</span><br><span class="line">qs_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">qs_builder.add_node(&quot;send_to_slack&quot;, send_to_slack)</span><br><span class="line">qs_builder.add_edge(START, &quot;generate_summary&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;generate_summary&quot;, &quot;send_to_slack&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;send_to_slack&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = qs_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723100648199.png" alt="image-20250723100648199">
<figcaption aria-hidden="true">image-20250723100648199</figcaption>
</figure>
<h5 id="adding-sub-graphs-to-our-parent-graph-向父图添加子图"><strong>Adding
sub graphs to our parent graph </strong>
<strong>向父图添加子图</strong></h5>
<p>现在，我们可以将所有内容整合在一起。我们使用
<code>EntryGraphState</code>
创建父图。并且我们将我们的子图添加为节点！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 入口图</span><br><span class="line">class EntryGraphState(TypedDict):</span><br><span class="line">    # 原始日志数据列表</span><br><span class="line">    raw_logs: List[Log]</span><br><span class="line">    # 经过清洗处理后的日志数据列表</span><br><span class="line">    cleaned_logs: List[Log]</span><br><span class="line">    fa_summary: str # 这只会在故障分析子图中生成</span><br><span class="line">    report: str # 这只会在问题摘要子图中生成</span><br><span class="line">    processed_logs:  Annotated[List[int], add] # 跟踪哪些日志已经被处理过 ，尤其是在子图之间共享状态时。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def clean_logs(state):</span><br><span class="line">    # 获取日志</span><br><span class="line">    raw_logs = state[&quot;raw_logs&quot;]</span><br><span class="line">    # 数据清洗 raw_logs -&gt; docs</span><br><span class="line">    cleaned_logs = raw_logs</span><br><span class="line">    return &#123;&quot;cleaned_logs&quot;: cleaned_logs&#125;</span><br><span class="line"></span><br><span class="line">entry_builder = StateGraph(EntryGraphState)</span><br><span class="line">entry_builder.add_node(&quot;clean_logs&quot;, clean_logs)</span><br><span class="line">#添加子图</span><br><span class="line">entry_builder.add_node(&quot;question_summarization&quot;, qs_builder.compile())</span><br><span class="line">entry_builder.add_node(&quot;failure_analysis&quot;, fa_builder.compile())</span><br><span class="line"></span><br><span class="line">entry_builder.add_edge(START, &quot;clean_logs&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;failure_analysis&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;question_summarization&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;failure_analysis&quot;, END)</span><br><span class="line">entry_builder.add_edge(&quot;question_summarization&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = entry_builder.compile()</span><br><span class="line"></span><br><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line"># 将 xray 设置为 1 将显示嵌套图的内部结构</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723102913524.png" alt="image-20250723102913524">
<figcaption aria-hidden="true">image-20250723102913524</figcaption>
</figure>
<h4 id="map-reduce"><strong>Map-reduce</strong></h4>
<p>LangGraph 里的 <strong>Map-Reduce</strong>
是一种<strong>并行处理模式</strong>，用于将一个大任务拆分成多个子任务（Map），再汇总结果（Reduce）。这是
LangGraph
中处理<strong>批量数据或并行节点执行</strong>的核心机制之一。</p>
<p>让我们设计一个系统，该系统将完成两件事情：</p>
<ol type="1">
<li><strong>映射（Map）</strong> —— 根据主题生成一组笑话。<br>
</li>
<li><strong>归约（Reduce）</strong> —— 从这组笑话中挑出最棒的一条。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"># Prompts we will use</span><br><span class="line">subjects_prompt = &quot;&quot;&quot;生成一个包含3个子主题的列表，这些子主题都与以下总体主题相关：&#123;topic&#125;。&quot;&quot;&quot;</span><br><span class="line">joke_prompt = &quot;&quot;&quot;生成一个关于&#123;subject&#125;的笑话&quot;&quot;&quot;</span><br><span class="line">best_joke_prompt = &quot;&quot;&quot;下面是关于&#123;topic&#125;的一堆笑话。选择最好的一个！返回最好笑话的ID，第一个笑话的ID从0开始。笑话：\n\n  &#123;jokes&#125;&quot;&quot;&quot;</span><br><span class="line"># LLM</span><br><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h5 id="parallelizing-joke-generation-并行化笑话生成"><strong>Parallelizing
joke generation</strong> <strong>并行化笑话生成</strong></h5>
<p>首先，让我们定义图的入口点，它将：</p>
<ul>
<li>接收用户输入的主题<br>
</li>
<li>基于该主题生成若干“笑话子主题”<br>
</li>
<li>将每个子主题发送到上面定义的笑话生成节点</li>
</ul>
<p>我们的状态有一个 <code>jokes</code>
键，它将累积来自并行化笑话生成的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Subjects(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示主题列表。&quot;&quot;&quot;</span><br><span class="line">    subjects: list[str] # 主题字符串列表</span><br><span class="line"></span><br><span class="line">class BestJoke(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示最佳笑话的ID。&quot;&quot;&quot;</span><br><span class="line">    id: int # 最佳笑话的索引ID</span><br><span class="line">    </span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;定义整个图的总体状态，使用TypedDict以便于类型提示和状态管理。&quot;&quot;&quot;</span><br><span class="line">    topic: str # 当前讨论的主题</span><br><span class="line">    subjects: list # 生成的子主题列表</span><br><span class="line">    jokes: Annotated[list, operator.add] # 笑话列表，使用operator.add表示列表内容会累加而不是覆盖</span><br><span class="line">    best_selected_joke: str # 最终选出的最佳笑话</span><br></pre></td></tr></table></figure>
<p>生成笑话的主题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#用于生成主题</span><br><span class="line">def generate_topics(state: OverallState):</span><br><span class="line">    #使用 Python 的 format() 方法来构建一个提示字符串（ prompt ）</span><br><span class="line">    prompt = subjects_prompt.format(topic=state[&quot;topic&quot;])</span><br><span class="line">    #.with_structured_output(Subjects) 它指示模型尝试将其输出格式化为 Subjects 类</span><br><span class="line">    response = model.with_structured_output(Subjects).invoke(prompt)</span><br><span class="line">    return &#123;&quot;subjects&quot;: response.subjects&#125;</span><br></pre></td></tr></table></figure>
<p>这就是妙处：我们利用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#send"><code>Send</code></a>
为每个主题并行生成笑话。</p>
<p>非常实用！无论主题数量多少，它都能自动并行处理。</p>
<ul>
<li><code>generate_joke</code>：图中节点的名字<br>
</li>
<li><code>&#123;"subject": s&#125;</code>：要传递的状态</li>
</ul>
<p><code>Send</code> 允许你向 <code>generate_joke</code>
节点发送<strong>任意</strong>结构的状态，无需与
<code>OverallState</code> 对齐。<br>
在这里，<code>generate_joke</code> 使用自己的内部状态，我们通过
<code>Send</code> 按需填充即可。</p>
<blockquote>
<p>在 LangGraph 里，<code>Send</code>
是一个<strong>“动态派发器”</strong>：它让你<strong>在运行时</strong>决定“要把哪个节点运行多少次、每次给它什么数据”，并自动并行执行。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.types import Send</span><br><span class="line">def continue_to_jokes(state: OverallState):</span><br><span class="line">    # 该函数根据当前状态中的主题列表，为每个主题生成一个 Send 对象。</span><br><span class="line">    # 每个 Send 对象都指示图将数据发送到名为 &quot;generate_joke&quot; 的节点，</span><br><span class="line">    # 并将当前主题作为 &quot;subject&quot; 参数传递，从而实现并行生成笑话。</span><br><span class="line">    return [Send(&quot;generate_joke&quot;, &#123;&quot;subject&quot;: s&#125;) for s in state[&quot;subjects&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="joke-generation-map-笑话生成"><strong>Joke generation
(map)</strong> <strong>笑话生成</strong></h5>
<p>现在，我们只需定义一个节点来生成笑话，命名为
<code>generate_joke</code>！</p>
<p>生成的笑话会被写回到 <code>OverallState</code> 中的
<code>jokes</code> 字段。 该字段配有
reducer，能够自动把多次写入的列表合并成一个大列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 定义 JokeState，用于表示生成笑话任务的输入状态。</span><br><span class="line">class JokeState(TypedDict):</span><br><span class="line">    subject: str#笑话的主题</span><br><span class="line"></span><br><span class="line"># 定义 Joke 模型，用于表示模型生成的笑话的结构。</span><br><span class="line">class Joke(BaseModel):</span><br><span class="line">    joke: str#笑话的文本内容</span><br><span class="line"></span><br><span class="line"># 定义生成笑话的函数。</span><br><span class="line">def generate_joke(state: JokeState):</span><br><span class="line">    # 根据 joke_prompt 模板和当前状态中的主题格式化提示。</span><br><span class="line">    prompt = joke_prompt.format(subject=state[&quot;subject&quot;])</span><br><span class="line">    # 调用语言模型，并指定输出应结构化为 Joke 类型。</span><br><span class="line">    response = model.with_structured_output(Joke).invoke(prompt)</span><br><span class="line">    # 返回一个包含生成的笑话的字典，键为 &quot;jokes&quot;。</span><br><span class="line">    return &#123;&quot;jokes&quot;: [response.joke]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="best-joke-selection-reduce-最佳笑话选择"><strong>Best joke
selection (reduce)</strong> <strong>最佳笑话选择</strong></h5>
<p>现在，我们添加逻辑来挑选最好的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def best_joke(state: OverallState):</span><br><span class="line">    # 将状态中所有笑话列表连接成一个字符串，每个笑话之间用两个换行符分隔</span><br><span class="line">    jokes = &quot;\n\n&quot;.join(state[&quot;jokes&quot;])</span><br><span class="line">    # 使用主题和所有笑话格式化最佳笑话提示语</span><br><span class="line">    prompt = best_joke_prompt.format(topic=state[&quot;topic&quot;], jokes=jokes)</span><br><span class="line">    # 调用模型，期望其输出符合 BestJoke 结构（包含最佳笑话的ID）</span><br><span class="line">    response = model.with_structured_output(BestJoke).invoke(prompt)</span><br><span class="line">    # 根据模型返回的ID，从笑话列表中选择最佳笑话，并将其存储在状态的 best_selected_joke 字段中</span><br><span class="line">    return &#123;&quot;best_selected_joke&quot;: state[&quot;jokes&quot;][response.id]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="compile-编译"><strong>Compile</strong> 编译</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image</span><br><span class="line">from langgraph.graph import END, StateGraph, START</span><br><span class="line"></span><br><span class="line"># 构建图：将所有组件组合在一起构建我们的流程图</span><br><span class="line">graph = StateGraph(OverallState)</span><br><span class="line"></span><br><span class="line">graph.add_node(&quot;generate_topics&quot;, generate_topics)</span><br><span class="line">graph.add_node(&quot;generate_joke&quot;, generate_joke)</span><br><span class="line">graph.add_node(&quot;best_joke&quot;, best_joke)</span><br><span class="line"></span><br><span class="line">graph.add_edge(START, &quot;generate_topics&quot;)</span><br><span class="line"># 根据条件决定是否继续生成笑话</span><br><span class="line">graph.add_conditional_edges(&quot;generate_topics&quot;, continue_to_jokes, [&quot;generate_joke&quot;])</span><br><span class="line"># 生成笑话后执行选择最佳笑话</span><br><span class="line">graph.add_edge(&quot;generate_joke&quot;, &quot;best_joke&quot;)</span><br><span class="line"># 选择最佳笑话后流程结束</span><br><span class="line">graph.add_edge(&quot;best_joke&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = graph.compile()</span><br><span class="line">Image(app.get_graph().draw_mermaid_png())</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723112736244.png" alt="image-20250723112736244">
<figcaption aria-hidden="true">image-20250723112736244</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for s in app.stream(&#123;&quot;topic&quot;: &quot;日本广岛原子弹&quot;&#125;):</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;generate_topics&#x27;: &#123;&#x27;subjects&#x27;: [&#x27;原子弹投放的历史背景与决策过程&#x27;, &#x27;广岛原爆对城市与居民的影响&#x27;, &#x27;战后和平运动与核裁军倡议&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;战后和平运动的人开会讨论核裁军，一个人站起来说：‘我们必须彻底销毁所有核武器！’ 另一个人犹豫地举手：‘那……我们保留一个吧，就一个，藏在冰箱后面，以防万一。’&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&quot;杜鲁门宣布要结束战争，顾问问是否要使用原子弹。罗斯福的棺材板突然震动了一下，丘吉尔的雪茄掉在了地上，斯大林则默默拿起了电话：&#x27;同志，我们的计划可能需要再推迟一下。&#x27;&quot;]&#125;&#125;</span><br><span class="line">&#123;&#x27;best_joke&#x27;: &#123;&#x27;best_selected_joke&#x27;: &#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Research Assistant</strong> <strong>研究助理</strong></p>
<p>见另一篇文章</p>
<h3 id="module-5">module-5</h3>
<h4 id="chatbot-with-memory-带有记忆功能的聊天机器人"><strong>Chatbot
with Memory</strong> <strong>带有记忆功能的聊天机器人</strong></h4>
<p>在这里，我们将介绍 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Memory Store</a> 作为一种保存和检索长期记忆的方法。</p>
<blockquote>
<p>LangGraph Memory Store 是 <strong>LangGraph
提供的长期记忆存储接口</strong>，用于在
<strong>不同对话线程之间</strong> 持久化保存和检索用户信息。</p>
<table>
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead>
<tr>
<th>名称</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BaseStore</strong></td>
<td>抽象接口，定义了 <code>put/get/search/delete</code> 等操作方法</td>
</tr>
<tr>
<td><strong>InMemoryStore</strong></td>
<td>内存实现，适合原型验证</td>
</tr>
<tr>
<td><strong>RedisStore / AsyncRedisStore</strong></td>
<td>生产级实现，支持向量搜索、元数据过滤和命名空间管理</td>
</tr>
</tbody>
</table>
</blockquote>
<p>我们将构建一个使用
<code>short-term (within-thread仅当前对话线程)</code> 和
<code>long-term (across-thread跨所有对话线程    )</code>
内存的聊天机器人。</p>
<p>我们将重点关注长期 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory">semantic
memory<strong>（语义记忆）</strong></a>，它将包含关于用户的事实信息。这些长期记忆将被用于创建一个个性化的聊天机器人，它可以记住有关用户的事实。</p>
<p>它将节省内存 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories">“in
the hot path”</a>，当用户与之聊天时。</p>
<blockquote>
<p><strong>“in the hot path”</strong>
指的是：<strong>在对话或任务执行的</strong>主流程中<strong>（即用户输入后立即、同步地）</strong>主动调用工具或写入记忆，使信息<strong>实时生效</strong>并可用于下一步决策。</p>
</blockquote>
<h5 id="introduction-to-the-langgraph-store-langgraph-存储简介"><strong>Introduction
to the LangGraph Store</strong> <strong>LangGraph 存储简介</strong></h5>
<p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Memory Store</a> 提供了一种在 LangGraph 中 <strong>跨线程</strong>
存储和检索信息的方式。这是一个用于持久化 <code>key-value</code> 存储的
<a target="_blank" rel="noopener" href="https://blog.langchain.dev/launching-long-term-memory-support-in-langgraph/">开源基类</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line">in_memory_store = InMemoryStore()</span><br></pre></td></tr></table></figure>
<p>在 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">Store</a>
中存储对象（例如，记忆）时，我们提供：</p>
<p>- 对象的 <code>namespace</code>（类似于目录的元组）</p>
<p>- 对象的 <code>key</code>（类似于文件名）</p>
<p>- 对象的 <code>value</code>（类似于文件内容）</p>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a>
方法通过 <code>namespace</code> 和 <code>key</code>
将对象保存到存储中。</p>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725155616205-1753430177489-3.png" alt="image-20250725155616205">
<figcaption aria-hidden="true">image-20250725155616205</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;  # 用户ID</span><br><span class="line">namespace_for_memory = (user_id, &quot;memories&quot;)  # 记忆命名空间</span><br><span class="line"></span><br><span class="line"># 生成一个唯一的键值</span><br><span class="line">key = str(uuid.uuid4())  # 使用UUID创建唯一标识符作为键</span><br><span class="line"></span><br><span class="line"># 值需要是一个字典格式</span><br><span class="line">value = &#123;&quot;food_preference&quot;: &quot;我喜欢披萨&quot;&#125;  # 存储的食物偏好信息</span><br><span class="line"></span><br><span class="line"># 保存记忆</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)  # 将记忆存储到内存中</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a>
通过 <code>namespace</code> 从存储中检索对象。这将返回一个列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">memories = in_memory_store.search(namespace_for_memory)</span><br><span class="line">type(memories)</span><br><span class="line"></span><br><span class="line"># Metatdata </span><br><span class="line">memories[0].dict()</span><br><span class="line"></span><br><span class="line"># The key, value</span><br><span class="line">print(memories[0].key, memories[0].value)</span><br><span class="line">9e65de8a-f404-4974-b509-0df0566d8fb5 &#123;&#x27;food_preference&#x27;: &#x27;我喜欢披萨&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a>
通过 <code>namespace</code> 和 <code>key</code> 检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Get the memory by namespace and key</span><br><span class="line">memory = in_memory_store.get(namespace_for_memory, key)</span><br><span class="line">memory.dict()</span><br></pre></td></tr></table></figure>
<h5 id="chatbot-with-long-term-memory-具有长期记忆的聊天机器人"><strong>Chatbot
with long-term memory</strong>
<strong>具有长期记忆的聊天机器人</strong></h5>
<p>我们想要一个聊天机器人，<a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_156">有两种记忆的方式</a>:</p>
<ol type="1">
<li><code>Short-term (within-thread) memory</code>:
聊天机器人可以保留会话历史记录和/或允许在聊天会话中进行中断。<br>
</li>
<li><code>Long-term (cross-thread) memory</code>:
聊天机器人可以记住特定用户在所有聊天会话中的信息
<strong>跨会话</strong>。</li>
</ol>
<p>对于 <code>short-term memory</code>，我们将使用一个 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries">checkpointer</a>。</p>
<ul>
<li>他们在每一步都将图状态写入线程中。</li>
<li>他们在该线程中持久化保存聊天历史记录。</li>
<li>他们允许图在该线程中的任何步骤被中断和/或恢复。</li>
</ul>
<p>对于 <code>long-term memory</code>，我们将使用上面介绍的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Store</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的有用助手，能够提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;&quot;你正在收集用户信息以个性化你的回复。</span><br><span class="line"></span><br><span class="line">当前用户信息：</span><br><span class="line">&#123;memory&#125;</span><br><span class="line"></span><br><span class="line">指令：</span><br><span class="line">1. 仔细查看下面的聊天历史</span><br><span class="line">2. 识别有关用户的新信息，例如：</span><br><span class="line">   - 个人详情（姓名、位置）</span><br><span class="line">   - 偏好（喜欢、不喜欢）</span><br><span class="line">   - 兴趣和爱好</span><br><span class="line">   - 过去的经历</span><br><span class="line">   - 目标或未来计划</span><br><span class="line">3. 将任何新信息与现有记忆合并</span><br><span class="line">4. 将记忆格式化为清晰的项目符号列表</span><br><span class="line">5. 如果新信息与现有记忆冲突，请保留最新版本</span><br><span class="line"></span><br><span class="line">记住：只包括用户直接陈述的事实信息。不要做假设或推断。</span><br><span class="line"></span><br><span class="line">基于以下聊天历史，请更新用户信息：&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    existing_memory = store.get(namespace, key)</span><br><span class="line"></span><br><span class="line">    # 如果存在则提取实际的记忆内容并添加前缀</span><br><span class="line">    if existing_memory:</span><br><span class="line">        # 值是一个带有memory键的字典</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)</span><br><span class="line">    </span><br><span class="line">    # 使用记忆以及聊天历史进行回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">        </span><br><span class="line">    # 提取记忆</span><br><span class="line">    if existing_memory:</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)</span><br><span class="line">    new_memory = model.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖存储中的现有记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line"></span><br><span class="line">    # 将值写入为带有memory键的字典</span><br><span class="line">    store.put(namespace, key, &#123;&quot;memory&quot;: new_memory.content&#125;)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于跨线程的长期记忆存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于线程内的短期记忆检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点器和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725161106319.png" alt="image-20250725161106319">
<figcaption aria-hidden="true">image-20250725161106319</figcaption>
</figure>
<p>聊天历史将通过检查点工具保存到短期记忆中。聊天机器人将回顾聊天历史。然后，它将创建并保存一个记忆到
<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Store</a>。此内存可在未来的聊天会话中访问，以个性化聊天机器人的响应。</p>
<p>当我们与聊天机器人交互时，我们提供两样东西：</p>
<ol type="1">
<li><code>Short-term (within-thread) memory</code>:
一个用于持久化聊天历史的 <code>thread ID</code>。<br>
</li>
<li><code>Long-term (cross-thread) memory</code>:
一个用于将长期记忆命名空间到用户的 <code>user ID</code>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br><span class="line">    </span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，我的名字是Lance</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，Lance！很高兴认识你。有什么我可以帮你的吗？😊</span><br></pre></td></tr></table></figure>
<p>我们正在使用 <code>MemorySaver</code>
检查点来管理线程内内存。这会将聊天历史保存到线程中。我们可以查看保存到线程的聊天历史记录。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">state = graph.get_state(thread).values</span><br><span class="line">for m in state[&quot;messages&quot;]: </span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>回想一下，我们使用存储库编译了该图：<code>across_thread_memory = InMemoryStore()</code>并且，我们向图中添加了一个节点
(<code>write_memory</code>)，该节点反映了聊天历史并保存了一段记忆到存储中。</p>
<p>我们可以查看内存是否已保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.dict()</span><br><span class="line"></span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;memory&#x27;, &#x27;1&#x27;],</span><br><span class="line"> &#x27;key&#x27;: &#x27;user_memory&#x27;,</span><br><span class="line"> &#x27;value&#x27;: &#123;&#x27;memory&#x27;: &#x27;- 姓名：Lance  \n- 位置：旧金山  \n- 兴趣和爱好：骑自行车  \n- 喜欢的活动：在旧金山骑行，可能包括金门大桥和滨海区路线&#x27;&#125;,</span><br><span class="line"> &#x27;created_at&#x27;: &#x27;2025-07-25T08:12:35.877160+00:00&#x27;,</span><br><span class="line"> &#x27;updated_at&#x27;: &#x27;2025-07-25T08:12:35.877161+00:00&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>现在，让我们以
<strong>相同的用户ID</strong>启动一个<strong>新线程</strong>。我们应该看到聊天机器人记住了用户的个人资料，并将其用于个性化响应。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供用户ID用于跨线程记忆以及一个新的线程ID</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好！你推荐我去哪里骑自行车？&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="chatbot-with-profile-schema-带有配置文件模式的聊天机器人"><strong>Chatbot
with Profile Schema</strong>
<strong>带有配置文件模式的聊天机器人</strong></h4>
<p>我们的聊天机器人将记忆保存为字符串。在实践中，我们通常希望记忆具有结构化格式。例如，记忆可以是<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">单个、持续更新的模式</a>。在我们的案例中，我们希望这是一个单一的用户档案。</p>
<p>我们将扩展我们的聊天机器人，将语义记忆保存到单个<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">用户档案</a>中。我们还将介绍一个库
<a target="_blank" rel="noopener" href="https://github.com/hinthornw/trustcall">Trustcall</a>，用于使用新信息更新此模式。</p>
<h5 id="defining-a-user-profile-schema-定义用户配置文件模式"><strong>Defining
a user profile schema</strong>
<strong>定义用户配置文件模式</strong></h5>
<p>Python 有许多不同类型的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition">structured
data</a>，例如 TypedDict、字典、JSON 和 <a target="_blank" rel="noopener" href="https://docs.pydantic.dev/latest/">Pydantic</a>。</p>
<p>让我们先使用 TypedDict 来定义一个用户资料模式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from typing import TypedDict, List</span><br><span class="line"></span><br><span class="line">class UserProfile(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;带有类型字段的用户档案模式&quot;&quot;&quot;</span><br><span class="line">    user_name: str  # 用户的首选名称</span><br><span class="line">    interests: List[str]  # 用户兴趣列表</span><br></pre></td></tr></table></figure>
<h5 id="saving-a-schema-to-the-store-将模式保存到存储中"><strong>Saving
a schema to the store</strong> <strong>将模式保存到存储中</strong></h5>
<p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Store</a> 接受任何 Python 字典作为 <code>value</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># TypedDict 实例</span><br><span class="line">user_profile: UserProfile = &#123;</span><br><span class="line">    &quot;user_name&quot;: &quot;Lance&quot;,  # 用户名</span><br><span class="line">    &quot;interests&quot;: [&quot;骑行&quot;, &quot;科技&quot;, &quot;咖啡&quot;]  # 兴趣爱好</span><br><span class="line">&#125;</span><br><span class="line">user_profile</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a>
方法将 TypedDict 保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line"></span><br><span class="line"># 初始化内存存储</span><br><span class="line">in_memory_store = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 为要保存的记忆创建命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace_for_memory = (user_id, &quot;memory&quot;)</span><br><span class="line"></span><br><span class="line"># 将记忆以键值对的形式保存到命名空间中</span><br><span class="line">key = &quot;user_profile&quot;</span><br><span class="line">value = user_profile</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)</span><br></pre></td></tr></table></figure>
<p>我们使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a>
按命名空间从存储中检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for m in in_memory_store.search(namespace_for_memory):</span><br><span class="line">    print(m.dict())</span><br><span class="line">    </span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;1&#x27;, &#x27;memory&#x27;], &#x27;key&#x27;: &#x27;user_profile&#x27;, &#x27;value&#x27;: &#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;, &#x27;created_at&#x27;: &#x27;2025-07-25T08:58:06.031770+00:00&#x27;, &#x27;updated_at&#x27;: &#x27;2025-07-25T08:58:06.031775+00:00&#x27;, &#x27;score&#x27;: None&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a>
通过命名空间和键来检索特定对象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">profile = in_memory_store.get(namespace_for_memory, &quot;user_profile&quot;)</span><br><span class="line">profile.value</span><br><span class="line"></span><br><span class="line">&#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="chatbot-with-profile-schema-带有配置文件模式的聊天机器人-1"><strong>Chatbot
with profile schema</strong>
<strong>带有配置文件模式的聊天机器人</strong></h5>
<p>现在我们知道了如何为记忆指定一个模式，并将其保存到存储中。现在，我们如何根据这个特定的模式
<strong>创建</strong> 记忆？</p>
<p>在我们的聊天机器人中，我们 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">想要从一个聊天里创建记忆</a>.这就是
<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">structured
outputs格式化输出</a> 概念有用的地方。</p>
<p>LangChain 的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/chat_models/">chat
model</a> 接口有一个 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">PROTECTED<span class="math inline">11</span></a>
方法用于强制结构化输出。这在我们需要确保输出符合某个模式时非常有用，而且它会为我们解析输出。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 将模式绑定到模型</span><br><span class="line">model_with_structure = model.with_structured_output(UserProfile)</span><br><span class="line"></span><br><span class="line"># 调用模型生成符合模式的结构化输出</span><br><span class="line">structured_output = model_with_structure.invoke([HumanMessage(&quot;我的名字是Lance，我喜欢骑自行车。&quot;)])</span><br><span class="line">structured_output</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Structured outputs（结构化输出）
指让大模型<strong>不再“随意说人话”</strong>，而是<strong>按你事先定义好的格式（JSON
/ 表格 / 枚举 /
嵌套对象等）精确返回数据</strong>。相当于给模型套了一个“模具”，保证输出可直接被代码解析、入库或传给下游系统，避免再用正则、字符串拼接去“猜”结果。</p>
<p>使用官方的大模型组件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">model=ChatTongyi(</span><br><span class="line">    model=&quot;qwen-plus-2025-07-14&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>现在，让我们在聊天机器人中使用它。这只需要对
<code>write_memory</code> 函数进行轻微修改。我们使用
<code>model_with_structure</code>，如上所述，来生成一个与我们模式匹配的配置文件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage, AIMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的 helpful 助手，可以提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;根据用户的聊天历史创建或更新用户档案记忆。</span><br><span class="line">这将被保存为长期记忆。如果存在现有记忆，只需更新它。</span><br><span class="line">以下是现有记忆（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 使用记忆以及聊天历史来回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line">        </span><br><span class="line">    # 在指令中格式化现有记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 调用模型生成符合模式的结构化输出</span><br><span class="line">    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖现有的用户档案记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    store.put(namespace, key, new_memory)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于长期（跨线程）记忆的存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于短期（线程内）记忆的检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250726103516996.png" alt="image-20250726103516996">
<figcaption aria-hidden="true">image-20250726103516996</figcaption>
</figure>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance，我喜欢在旧金山骑自行车和在面包店吃饭。&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>查看记忆</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Namespace for the memory to save</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.value</span><br></pre></td></tr></table></figure>
<h5 id="trustcall-for-creating-and-updating-profile-schemas-trustcall-用于创建和更新配置文件模式"><strong>Trustcall
for creating and updating profile schemas</strong> <strong>Trustcall
用于创建和更新配置文件模式</strong></h5>
<p>Trustcall 是一个由 LangChain 团队开发的开源 Python
库，旨在<strong>解决大型语言模型（LLM）在生成或修改复杂 JSON
数据结构时效率低、易出错的问题</strong>。</p>
<p>我们使用 <code>create_extractor</code>，传入模型以及我们的模式作为 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/tools/">tool</a>。使用
TrustCall 时，可以以多种方式提供模式。</p>
<p>例如，我们可以传递一个 JSON 对象 / Python 字典或 Pydantic
模型。在底层，TrustCall 使用 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/tool_calling/">tool
calling</a> 从输入的 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/messages/">messages</a>
列表中生成 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/">structured
output</a>。为了强制 Trustcall 生成 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/concepts/structured_outputs/">structured
output</a>，我们可以在 <code>tool_choice</code> 参数中包含模式名称。</p>
<p>我仅做了解了，感觉用处不多，用结果化输出就能达到效果</p>
<h4 id="chatbot-with-collection-schema-带集合模式的聊天机器人"><strong>Chatbot
with Collection Schema</strong>
<strong>带集合模式的聊天机器人</strong></h4>
<p><strong>“collection”</strong>
指的是一种<strong>将语义记忆组织为多个独立文档（objects）的存储方式</strong>，而不是把所有信息都塞进一个巨大的“用户档案”（single
profile）里。</p>
<p>假设你在做一个 AI 助手，用户说：</p>
<blockquote>
<p>“我下周要去东京出差，住在涩谷区的 Sakura Hotel。” “我朋友 Ken
也要来，他喜欢吃拉面。”</p>
</blockquote>
<p>如果用 <strong>collection</strong>，你会存成两条记忆：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trip&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;destination&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Tokyo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2025-08-04&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hotel&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Sakura Hotel, Shibuya&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;friend&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Ken&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;food_preference&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ramen&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<p>每条记忆都是一个独立文档，后续你可以：</p>
<ul>
<li>搜索“trip”类型的记忆，找到用户的出差安排；</li>
<li>搜索“friend”类型的记忆，找到 Ken 的偏好；</li>
<li>更新 Ken
的信息时，<strong>只改一条记录</strong>，不会影响其它记忆。</li>
</ul>
<h4 id="memory-agent-内存代理"><strong>Memory Agent</strong>
<strong>内存代理</strong></h4>
<p>现在，我们将把学到的内容整合起来，构建一个具有长期记忆的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/">agent</a>。</p>
<p>我们的代理 <code>task_mAIstro</code> 将帮助我们管理待办事项列表！</p>
<p>我们之前构建的聊天机器人 <strong>始终</strong>
会反思对话并保存记忆。<code>task_mAIstro</code> 将决定
<strong>何时</strong> 保存记忆（待办事项列表中的项目）。</p>
<p>我们之前构建的聊天机器人始终保存一种类型的记忆，即个人资料或集合。<code>task_mAIstro</code>
可以决定将数据保存到用户个人资料或 ToDo 事项集合中。</p>
<p>除此之外，<code>task_mAIstro</code>
还将管理程序性记忆。这允许用户更新创建ToDo项的偏好设置。</p>
<h5 id="creating-an-agent-创建一个代理"><strong>Creating an
agent</strong> <strong>创建一个代理</strong></h5>
<p>有许多不同的 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/high_level/">agent</a>
架构可供选择。在这里，我们将实现一个简单的内容，一个 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation">ReAct</a>
代理。这个代理将成为创建和管理待办事项列表的得力助手。</p>
<p>此代理可以决定更新三种类型的长期记忆：</p>
<ol type="a">
<li><p>创建或更新具有普通用户信息的用户 <code>profile</code></p></li>
<li><p>在ToDo列表中添加或更新项目 <code>collection</code></p></li>
<li><p>更新其自身的 <code>instructions</code>
以了解如何更新待办事项列表中的项目</p></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from typing import TypedDict, Literal</span><br><span class="line"></span><br><span class="line"># 更新记忆工具</span><br><span class="line">class UpdateMemory(TypedDict):</span><br><span class="line">    &quot;&quot;&quot; 决定更新哪种记忆类型 &quot;&quot;&quot;</span><br><span class="line">    update_type: Literal[&#x27;user&#x27;, &#x27;todo&#x27;, &#x27;instructions&#x27;]</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><code>'user'</code>：用户相关信息</li>
<li><code>'todo'</code>：待办事项</li>
<li><code>'instructions'</code>：指令信息</li>
</ul>
</blockquote>
<h5 id="graph-definition-图定义"><strong>Graph definition</strong>
<strong>图定义</strong></h5>
<p>我们添加了一个简单的路由器
<code>route_message</code>，它通过二元决策来节省内存。</p>
<h3 id="module-6">module-6</h3>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/" class="post-title-link" itemprop="url">Research Assistant研究助理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-22T00:00:00+08:00">2025-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-08 21:50:22" itemprop="dateModified" datetime="2025-08-08T21:50:22+08:00">2025-08-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="research-assistant-研究助理"><strong>Research Assistant</strong>
<strong>研究助理</strong></h4>
<p>我们的目标是围绕聊天模型构建一个轻量级、多智能体系统，以定制研究过程。</p>
<p>Source Selection</p>
<ul>
<li>用户可为研究自行选择任意输入源。</li>
</ul>
<p>Planning</p>
<ul>
<li>用户提供主题后，系统生成一组 AI
分析师，每位分析师聚焦一个子主题。</li>
<li>在研究开始前，采用 <strong>人机协同</strong>
方式对子主题进行精调。</li>
</ul>
<p>LLM Utilization</p>
<ul>
<li>每位分析师基于所选源，与专家 AI 开展深度访谈。</li>
<li>访谈采用多轮对话形式，以 STORM 论文所示方式提取详尽洞见。</li>
<li>访谈过程将以“<strong>子图</strong>”形式记录，并保存各自内部状态。</li>
</ul>
<p>Research Process</p>
<ul>
<li>专家 AI 并行收集信息，实时回答分析师提问。</li>
<li>所有访谈通过 <strong>map-reduce</strong> 架构同时展开。</li>
</ul>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/66dbb164d61c93d48e604091_research-assistant1.png" alt="Screenshot 2024-08-26 at 7.26.33 PM.png">
<figcaption aria-hidden="true">Screenshot 2024-08-26 at 7.26.33
PM.png</figcaption>
</figure>
<h5 id="generate-analysts-human-in-the-loop-生成分析师"><strong>Generate
Analysts: Human-In-The-Loop</strong> <strong>生成分析师</strong></h5>
<p>创建分析师并使用人工循环（human-in-the-loop）来审查他们。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line">class Analyst(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    分析师模型类</span><br><span class="line">    用于定义单个分析师的基本信息和属性</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    affiliation: str = Field(</span><br><span class="line">        description=&quot;分析师的主要隶属机构。&quot;,</span><br><span class="line">    )</span><br><span class="line">    name: str = Field(</span><br><span class="line">        description=&quot;分析师的姓名&quot;</span><br><span class="line">    )</span><br><span class="line">    role: str = Field(</span><br><span class="line">        description=&quot;分析师在该主题背景下的角色。&quot;,</span><br><span class="line">    )</span><br><span class="line">    description: str = Field(</span><br><span class="line">        description=&quot;分析师的关注点、担忧和动机的描述。&quot;,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    @property#@property 装饰器的作用是将一个方法转换为只读属性 ，让方法可以像访问属性一样使用，而不需要加括号调用。</span><br><span class="line">    def persona(self) -&gt; str:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        生成分析师的人设信息</span><br><span class="line">        返回格式化的字符串包含分析师的所有关键信息</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        return f&quot;姓名: &#123;self.name&#125;\n角色: &#123;self.role&#125;\n隶属机构: &#123;self.affiliation&#125;\n描述: &#123;self.description&#125;\n&quot;</span><br><span class="line"></span><br><span class="line">class Perspectives(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    视角模型类</span><br><span class="line">    用于管理多个分析师的集合</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    analysts: List[Analyst] = Field(</span><br><span class="line">        description=&quot;包含角色和隶属机构的分析师综合列表。&quot;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">class GenerateAnalystsState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    生成分析师状态类型定义</span><br><span class="line">    用于类型提示，定义在生成分析师过程中需要的状态信息</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    topic: str # 研究主题 - 用户输入的研究话题</span><br><span class="line">    max_analysts: int # 分析师数量 - 需要生成的分析师最大数量</span><br><span class="line">    human_analyst_feedback: str # 人类反馈 - 来自用户的反馈信息，用于调整分析师生成</span><br><span class="line">    analysts: List[Analyst] # 提出问题的分析师 - 已生成的分析师列表</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>Field</code> 是 Pydantic
提供的一个函数，主要用于为模型字段添加额外的元数据和配置。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import START, END, StateGraph</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langchain_core.messages import AIMessage, HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line"># 分析师指令模板</span><br><span class="line">analyst_instructions=&quot;&quot;&quot;您需要创建一组AI分析师角色。请仔细遵循以下指令：</span><br><span class="line"></span><br><span class="line">1. 首先，查看研究主题：</span><br><span class="line">&#123;topic&#125;</span><br><span class="line">        </span><br><span class="line">2. 检查任何可选的编辑反馈，这些反馈用于指导分析师的创建： </span><br><span class="line">        </span><br><span class="line">&#123;human_analyst_feedback&#125;</span><br><span class="line">    </span><br><span class="line">3. 根据上述文档和/或反馈确定最有趣的主题。</span><br><span class="line">                    </span><br><span class="line">4. 选择前 &#123;max_analysts&#125; 个主题。</span><br><span class="line"></span><br><span class="line">5. 为每个主题分配一个分析师。</span><br><span class="line"></span><br><span class="line">6. 重要：请以JSON格式返回您的响应，结构如下：</span><br><span class="line">   &#123;&#123;</span><br><span class="line">     &quot;analysts&quot;: [</span><br><span class="line">       &#123;&#123;</span><br><span class="line">         &quot;name&quot;: &quot;分析师姓名&quot;,</span><br><span class="line">         &quot;affiliation&quot;: &quot;所属机构&quot;,</span><br><span class="line">         &quot;role&quot;: &quot;角色描述&quot;,</span><br><span class="line">         &quot;description&quot;: &quot;详细描述&quot;</span><br><span class="line">       &#125;&#125;</span><br><span class="line">     ]</span><br><span class="line">   &#125;&#125;</span><br><span class="line"></span><br><span class="line">7. 请确保响应中包含&#x27;json&#x27;这个词，这是必需的。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def create_analysts(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 创建分析师 &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    topic=state[&#x27;topic&#x27;]</span><br><span class="line">    max_analysts=state[&#x27;max_analysts&#x27;]</span><br><span class="line">    human_analyst_feedback=state.get(&#x27;human_analyst_feedback&#x27;, &#x27;&#x27;)#防止为空</span><br><span class="line">        </span><br><span class="line">    # 强制结构化输出</span><br><span class="line">    structured_llm = llm.with_structured_output(Perspectives)</span><br><span class="line"></span><br><span class="line">    # 系统消息</span><br><span class="line">    system_message = analyst_instructions.format(topic=topic,human_analyst_feedback=human_analyst_feedback, max_analysts=max_analysts)</span><br><span class="line"></span><br><span class="line">    # 生成分析师</span><br><span class="line">    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=&quot;生成分析师集合。&quot;)])</span><br><span class="line">    </span><br><span class="line">    # 将分析师列表写入状态</span><br><span class="line">    return &#123;&quot;analysts&quot;: analysts.analysts&#125;</span><br><span class="line"></span><br><span class="line">def human_feedback(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 无操作节点，应该在此处中断 &quot;&quot;&quot;</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">def should_continue(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 返回下一个要执行的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否有用户反馈</span><br><span class="line">    human_analyst_feedback=state.get(&#x27;human_analyst_feedback&#x27;, None)</span><br><span class="line">    if human_analyst_feedback:</span><br><span class="line">        return &quot;create_analysts&quot;</span><br><span class="line">    </span><br><span class="line">    # 否则结束</span><br><span class="line">    return END</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">builder = StateGraph(GenerateAnalystsState)</span><br><span class="line">builder.add_node(&quot;create_analysts&quot;, create_analysts)  # 添加创建分析师节点</span><br><span class="line">builder.add_node(&quot;human_feedback&quot;, human_feedback)   # 添加用户反馈节点</span><br><span class="line">builder.add_edge(START, &quot;create_analysts&quot;)           # 从开始到创建分析师</span><br><span class="line">builder.add_edge(&quot;create_analysts&quot;, &quot;human_feedback&quot;) # 从创建分析师到用户反馈</span><br><span class="line">builder.add_conditional_edges(&quot;human_feedback&quot;, should_continue, [&quot;create_analysts&quot;, END]) # 条件边</span><br><span class="line"></span><br><span class="line"># 编译图</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph = builder.compile(interrupt_before=[&#x27;human_feedback&#x27;], checkpointer=memory)  # 在用户反馈前中断</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))  # 显示流程图</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250723171742889.png" alt="image-20250723171742889">
<figcaption aria-hidden="true">image-20250723171742889</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 输入</span><br><span class="line">max_analysts = 3  # 最大分析师数量</span><br><span class="line">topic = &quot;采用LangGraph作为代理框架的好处&quot;  # 研究主题</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;  # 线程配置，用于会话跟踪</span><br><span class="line"></span><br><span class="line"># 运行图直到第一次中断</span><br><span class="line">for event in graph.stream(&#123;&quot;topic&quot;:topic,&quot;max_analysts&quot;:max_analysts,&#125;, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    # 审查结果</span><br><span class="line">    analysts = event.get(&#x27;analysts&#x27;, &#x27;&#x27;)  # 获取分析师列表</span><br><span class="line">    if analysts:</span><br><span class="line">        for analyst in analysts:</span><br><span class="line">            print(f&quot;姓名: &#123;analyst.name&#125;&quot;)        # 打印分析师姓名</span><br><span class="line">            print(f&quot;隶属机构: &#123;analyst.affiliation&#125;&quot;)  # 打印隶属机构</span><br><span class="line">            print(f&quot;角色: &#123;analyst.role&#125;&quot;)        # 打印角色</span><br><span class="line">            print(f&quot;描述: &#123;analyst.description&#125;&quot;)  # 打印描述</span><br><span class="line">            print(&quot;-&quot; * 50)  # 打印分隔线</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">姓名: 艾琳·史密斯</span><br><span class="line">隶属机构: 人工智能与代理系统研究所</span><br><span class="line">角色: LangGraph架构专家</span><br><span class="line">描述: 专注于研究基于图结构的AI代理框架，尤其是LangGraph在复杂决策流程中的模块化与可扩展性优势。</span><br><span class="line">--------------------------------------------------</span><br><span class="line">姓名: 拉胡尔·梅赫塔</span><br><span class="line">隶属机构: 分布式系统与AI实验室</span><br><span class="line">角色: 代理框架性能分析师</span><br><span class="line">描述: 研究LangGraph在多代理协作中的效率提升，以及其在异步通信、状态管理和错误恢复方面的优势。</span><br><span class="line">--------------------------------------------------</span><br><span class="line">姓名: 艾米丽·陈</span><br><span class="line">隶属机构: 人机交互与智能系统中心</span><br><span class="line">角色: 代理框架用户体验研究员</span><br><span class="line">描述: 分析LangGraph如何支持开发者构建更具交互性和可解释性的AI代理系统，特别是在可视化流程设计和调试方面的优势。</span><br><span class="line">--------------------------------------------------</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 我们现在像 human_feedback 节点一样更新状态</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            &quot;添加一个来自初创公司的人，以增加企业家视角&quot;&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 继续图的执行</span><br><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    # 审查结果</span><br><span class="line">    analysts = event.get(&#x27;analysts&#x27;, &#x27;&#x27;)  # 获取分析师列表</span><br><span class="line">    if analysts:</span><br><span class="line">        for analyst in analysts:</span><br><span class="line">            print(f&quot;姓名: &#123;analyst.name&#125;&quot;)        # 打印分析师姓名</span><br><span class="line">            print(f&quot;隶属机构: &#123;analyst.affiliation&#125;&quot;)  # 打印隶属机构</span><br><span class="line">            print(f&quot;角色: &#123;analyst.role&#125;&quot;)        # 打印角色</span><br><span class="line">            print(f&quot;描述: &#123;analyst.description&#125;&quot;)  # 打印描述</span><br><span class="line">            print(&quot;-&quot; * 50)  # 打印分隔线</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 如果我们满意，那么就不提供任何反馈</span><br><span class="line">further_feedback = None #如果满意就返回none，如果不满意就进行反馈</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            further_feedback&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<h5 id="conduct-interview-进行面试"><strong>Conduct Interview</strong>
<strong>进行面试</strong></h5>
<p><strong>生成问题</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import  Annotated</span><br><span class="line">from langgraph.graph import MessagesState</span><br><span class="line"></span><br><span class="line">class InterviewState(MessagesState):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    访谈状态类</span><br><span class="line">    继承自MessagesState，用于管理访谈过程中的各种状态信息</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    max_num_turns: int # 对话轮数上限</span><br><span class="line">    context: Annotated[list, operator.add] # 源文档，使用operator.add进行合并</span><br><span class="line">    analyst: Analyst # 提问的分析师</span><br><span class="line">    interview: str # 访谈记录（文字记录）</span><br><span class="line">    sections: list # 最终章节，我们在外部状态中重复此字段以用于Send() API</span><br><span class="line"></span><br><span class="line">class SearchQuery(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    搜索查询模型</span><br><span class="line">    用于定义搜索查询的结构</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    search_query: str = Field(None, description=&quot;用于检索的搜索查询。&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 问题生成指令</span><br><span class="line">question_instructions = &quot;&quot;&quot;你是一名分析师，任务是采访专家以了解特定主题。</span><br><span class="line"></span><br><span class="line">你的目标是提炼出与你主题相关的有趣且具体的见解。</span><br><span class="line"></span><br><span class="line">1. 有趣的：人们会感到惊讶或不明显的见解。</span><br><span class="line">        </span><br><span class="line">2. 具体的：避免泛泛而谈的见解，包含来自专家的具体例子。</span><br><span class="line"></span><br><span class="line">这是你的关注主题和目标集合：&#123;goals&#125;</span><br><span class="line">        </span><br><span class="line">首先使用符合你人设的名字介绍自己，然后提出你的问题。</span><br><span class="line"></span><br><span class="line">继续提问以深入挖掘和细化你对该主题的理解。</span><br><span class="line">        </span><br><span class="line">当你对理解满意时，用&quot;非常感谢您的帮助！&quot;来结束采访。</span><br><span class="line"></span><br><span class="line">记住在整个回复中保持角色特征，体现提供给你的人设和目标。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def generate_question(state: InterviewState):</span><br><span class="line">    &quot;&quot;&quot; 生成问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    analyst = state[&quot;analyst&quot;]      # 当前分析师</span><br><span class="line">    messages = state[&quot;messages&quot;]    # 对话历史</span><br><span class="line"></span><br><span class="line">    # 生成问题</span><br><span class="line">    system_message = question_instructions.format(goals=analyst.persona)  # 格式化系统消息</span><br><span class="line">    question = llm.invoke([SystemMessage(content=system_message)]+messages)  # 调用LLM生成问题</span><br><span class="line">        </span><br><span class="line">    # 将消息写入状态</span><br><span class="line">    return &#123;&quot;messages&quot;: [question]&#125;  # 返回新生成的问题</span><br></pre></td></tr></table></figure>
<p><strong>生成问题的并行处理</strong></p>
<p>专家将并行从多个来源收集信息以回答问题。</p>
<ul>
<li>特定网站：例如通过 <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/integrations/document_loaders/web_base/">WebBaseLoader</a><br>
</li>
<li>已索引文档：例如通过 <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/tutorials/rag/">RAG</a><br>
</li>
<li>网页搜索<br>
</li>
<li>维基百科搜索</li>
</ul>
<p>你可以尝试不同的网络搜索工具，比如 <a target="_blank" rel="noopener" href="https://tavily.com/">Tavily</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Web search tool</span><br><span class="line">from langchain_community.tools.tavily_search import TavilySearchResults</span><br><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line">#tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">tavily_search=TavilySearch(max_result=3)</span><br><span class="line"></span><br><span class="line"># Wikipedia search tool</span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br></pre></td></tr></table></figure>
<p>现在，我们创建节点以搜索网络和维基百科。</p>
<p>我们还将创建一个节点来回答分析师的问题。最后，我们将创建节点以保存完整的采访内容，并撰写采访的摘要（“部分”）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import get_buffer_string</span><br><span class="line"></span><br><span class="line"># 搜索查询编写</span><br><span class="line">search_instructions = SystemMessage(content=f&quot;&quot;&quot;你将获得分析师和专家之间的对话。</span><br><span class="line"></span><br><span class="line">你的目标是生成一个结构化的 JSON 对象，该对象包含一个用于网络搜索的查询字符串。</span><br><span class="line"></span><br><span class="line">请严格按照以下步骤操作：</span><br><span class="line"></span><br><span class="line">1.  仔细分析整个对话。</span><br><span class="line">2.  特别关注分析师提出的最后一个问题。</span><br><span class="line">3.  根据该问题，生成一个清晰、简洁、有效的搜索查询字符串。</span><br><span class="line">4.  **你的最终输出必须是一个严格的 JSON 对象，格式如下，不要包含任何其他文字或解释：**</span><br><span class="line">    &#123;&#123;&quot;search_query&quot;: &quot;你的查询字符串放在这里&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">**示例：**</span><br><span class="line">如果最后一个问题涉及 &quot;LangGraph 与其他代理框架（如 AutoGen）相比的优势&quot;，</span><br><span class="line">你的输出必须严格是：</span><br><span class="line">&#123;&#123;&quot;search_query&quot;: &quot;LangGraph vs AutoGen agent framework advantages&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">分析师的最后一个问题才是关键，请基于它生成查询。</span><br><span class="line"></span><br><span class="line">**你的输出：**&quot;&quot;&quot;)</span><br><span class="line"></span><br><span class="line">def search_web(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索查询</span><br><span class="line">    structured_llm = llm.with_structured_output(SearchQuery)</span><br><span class="line">    search_query = structured_llm.invoke([search_instructions]+state[&#x27;messages&#x27;])</span><br><span class="line">    </span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = tavily_search.invoke(search_query.search_query)</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;/&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # # 搜索查询</span><br><span class="line">    # structured_llm = llm.with_structured_output(SearchQuery)</span><br><span class="line">    # search_query = structured_llm.invoke([search_instructions]+state[&#x27;messages&#x27;])</span><br><span class="line">    </span><br><span class="line">    # # 搜索</span><br><span class="line">    # search_docs = WikipediaLoader(query=search_query.search_query, </span><br><span class="line">    #                               load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">    #  # 格式化</span><br><span class="line">    # formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">    #     [</span><br><span class="line">    #         f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;/&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">    #         for doc in search_docs</span><br><span class="line">    #     ]</span><br><span class="line">    # )</span><br><span class="line"></span><br><span class="line">    # return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line">    return &#123;&quot;context&quot;: [&quot;&quot;]&#125;</span><br><span class="line"></span><br><span class="line">answer_instructions = &quot;&quot;&quot;你是一位正在接受分析师采访的专家。</span><br><span class="line"></span><br><span class="line">这是分析师的关注领域：&#123;goals&#125;。</span><br><span class="line">        </span><br><span class="line">你的目标是回答面试官提出的问题。</span><br><span class="line"></span><br><span class="line">要回答问题，请使用此上下文：</span><br><span class="line">        </span><br><span class="line">&#123;context&#125;</span><br><span class="line"></span><br><span class="line">回答问题时，请遵循以下准则：</span><br><span class="line">        </span><br><span class="line">1. 仅使用上下文中提供的信息。</span><br><span class="line">        </span><br><span class="line">2. 不要引入外部信息或在上下文中明确说明之外进行假设。</span><br><span class="line"></span><br><span class="line">3. 上下文包含每个独立文档主题的来源。</span><br><span class="line"></span><br><span class="line">4. 在任何相关陈述旁边包含这些来源。例如，对于来源 # 1 使用 [1]。</span><br><span class="line"></span><br><span class="line">5. 在答案底部按顺序列出你的来源。 [1] 来源 1，[2] 来源 2，等等</span><br><span class="line">        </span><br><span class="line">6. 如果来源是：&lt;Document source=&quot;assistant/docs/llama3_1.pdf&quot; page=&quot;7&quot;/&gt;&#x27; 那么只需列出：</span><br><span class="line">        </span><br><span class="line">[1] assistant/docs/llama3_1.pdf, page 7 </span><br><span class="line">        </span><br><span class="line">并跳过括号的添加以及引用中的 Document source 前言。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def generate_answer(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    analyst = state[&quot;analyst&quot;]</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line"></span><br><span class="line">    # 回答问题</span><br><span class="line">    system_message = answer_instructions.format(goals=analyst.persona, context=context)</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=system_message)]+messages)</span><br><span class="line">            </span><br><span class="line">    # 将消息命名为来自专家</span><br><span class="line">    answer.name = &quot;expert&quot;</span><br><span class="line">    </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;messages&quot;: [answer]&#125;</span><br><span class="line"></span><br><span class="line">def save_interview(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 保存采访 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取消息</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    </span><br><span class="line">    # 将采访转换为字符串</span><br><span class="line">    interview = get_buffer_string(messages)</span><br><span class="line">    </span><br><span class="line">    # 保存到 interviews 键</span><br><span class="line">    return &#123;&quot;interview&quot;: interview&#125;</span><br><span class="line"></span><br><span class="line">def route_messages(state: InterviewState, </span><br><span class="line">                   name: str = &quot;expert&quot;):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 在问题和答案之间路由 &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 获取消息</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    max_num_turns = state.get(&#x27;max_num_turns&#x27;,2)</span><br><span class="line"></span><br><span class="line">    # 检查专家答案的数量</span><br><span class="line">    #isinstance(m, AIMessage) ：检查当前消息 m 是否是 AIMessage 类的实例。这通常用于识别由 AI 模型生成的消息。</span><br><span class="line">    num_responses = len(</span><br><span class="line">        [m for m in messages if isinstance(m, AIMessage) and m.name == name]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 如果专家回答的次数超过最大轮数，则结束</span><br><span class="line">    if num_responses &gt;= max_num_turns:</span><br><span class="line">        return &#x27;save_interview&#x27;</span><br><span class="line"></span><br><span class="line">    # 获取提出的最后一个问题，以检查它是否表示讨论结束</span><br><span class="line">    #messages[-2] ：分析师提出的 最后一个问题 。</span><br><span class="line">    #messages[-1] ：专家对这个问题的 最新回答 。</span><br><span class="line">    last_question = messages[-2]</span><br><span class="line">    </span><br><span class="line">    if &quot;非常感谢你的帮助&quot; in last_question.content:</span><br><span class="line">        return &#x27;save_interview&#x27;</span><br><span class="line">    return &quot;ask_question&quot;</span><br><span class="line"></span><br><span class="line">section_writer_instructions = &quot;&quot;&quot;你是一位专业的科技作家。</span><br><span class="line">            </span><br><span class="line">你的任务是根据一组源文档创建一份简短、易于理解的报告部分。</span><br><span class="line"></span><br><span class="line">1. 分析源文档的内容：</span><br><span class="line">- 每个源文档的名称都在文档开头，带有 &lt;Document 标签。</span><br><span class="line">        </span><br><span class="line">2. 使用 markdown 格式创建报告结构：</span><br><span class="line">- 使用 ## 作为章节标题</span><br><span class="line">- 使用 ### 作为小节标题</span><br><span class="line">        </span><br><span class="line">3. 按照此结构编写报告：</span><br><span class="line">a. 标题 (## header)</span><br><span class="line">b. 摘要 (### header)</span><br><span class="line">c. 来源 (### header)</span><br><span class="line"></span><br><span class="line">4. 根据分析师的关注领域，使你的标题引人入胜：</span><br><span class="line">&#123;focus&#125;</span><br><span class="line"></span><br><span class="line">5. 对于摘要部分：</span><br><span class="line">- 设置与分析师关注领域相关的通用背景/上下文的摘要</span><br><span class="line">- 强调从采访中收集到的新颖、有趣或令人惊讶的见解</span><br><span class="line">- 创建一个使用过的源文档的编号列表</span><br><span class="line">- 不要提及面试官或专家的姓名</span><br><span class="line">- 目标是最多约 400 字</span><br><span class="line">- 根据源文档中的信息，在报告中使用编号来源（例如，[1]、[2]）</span><br><span class="line">        </span><br><span class="line">6. 在来源部分：</span><br><span class="line">- 包含报告中使用的所有来源</span><br><span class="line">- 提供相关网站或特定文档路径的完整链接</span><br><span class="line">- 每个来源用换行符分隔。在每行末尾使用两个空格以在 Markdown 中创建换行符。</span><br><span class="line">- 它看起来像：</span><br><span class="line"></span><br><span class="line">### 来源</span><br><span class="line">[1] 链接或文档名称</span><br><span class="line">[2] 链接或文档名称</span><br><span class="line"></span><br><span class="line">7. 务必合并来源。例如，这不正确：</span><br><span class="line"></span><br><span class="line">[3] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line">[4] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line"></span><br><span class="line">不应有冗余来源。它应该只是：</span><br><span class="line"></span><br><span class="line">[3] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line">        </span><br><span class="line">8. 最终审查：</span><br><span class="line">- 确保报告遵循所需的结构</span><br><span class="line">- 在报告标题之前不包含任何前言</span><br><span class="line">- 检查所有准则是否已遵循&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_section(state: InterviewState):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 编写章节的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    interview = state[&quot;interview&quot;]</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    analyst = state[&quot;analyst&quot;]</span><br><span class="line">   </span><br><span class="line">    # 使用从采访（上下文）或采访本身（interview）收集的源文档编写章节</span><br><span class="line">    system_message = section_writer_instructions.format(focus=analyst.description)</span><br><span class="line">    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f&quot;Use this source to write your section: &#123;context&#125;&quot;)]) </span><br><span class="line">                </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;sections&quot;: [section.content]&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">interview_builder = StateGraph(InterviewState)</span><br><span class="line">interview_builder.add_node(&quot;ask_question&quot;, generate_question)</span><br><span class="line">interview_builder.add_node(&quot;search_web&quot;, search_web)</span><br><span class="line">interview_builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">interview_builder.add_node(&quot;answer_question&quot;, generate_answer)</span><br><span class="line">interview_builder.add_node(&quot;save_interview&quot;, save_interview)</span><br><span class="line">interview_builder.add_node(&quot;write_section&quot;, write_section)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">interview_builder.add_edge(START, &quot;ask_question&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;ask_question&quot;, &quot;search_web&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;ask_question&quot;, &quot;search_wikipedia&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;search_web&quot;, &quot;answer_question&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;search_wikipedia&quot;, &quot;answer_question&quot;)</span><br><span class="line">interview_builder.add_conditional_edges(&quot;answer_question&quot;, route_messages,[&#x27;ask_question&#x27;,&#x27;save_interview&#x27;])</span><br><span class="line">interview_builder.add_edge(&quot;save_interview&quot;, &quot;write_section&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;write_section&quot;, END)</span><br><span class="line"></span><br><span class="line"># 采访</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=&quot;Conduct Interviews&quot;)</span><br><span class="line"></span><br><span class="line"># 视图</span><br><span class="line">display(Image(interview_graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725101725158.png" alt="image-20250725101725158">
<figcaption aria-hidden="true">image-20250725101725158</figcaption>
</figure>
<h5 id="map-reduceparallelze-interviews-map-reduce-并行化访谈"><strong>Map-Reduce（Parallelze
interviews: Map-Reduce）</strong> <strong>并行化访谈</strong></h5>
<p>我们通过 <code>Send()</code> API
并行化处理访谈，这是一个映射步骤。我们将它们在 reduce
步骤中组合成报告正文。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import List, Annotated</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line">class ResearchGraphState(TypedDict):</span><br><span class="line">    topic: str                           # 研究主题 (字符串类型)</span><br><span class="line">    max_analysts: int                   # 分析师数量 (整数类型)</span><br><span class="line">    human_analyst_feedback: str         # 人类分析师的反馈 (字符串类型)</span><br><span class="line">    analysts: List[Analyst]             # 提问的分析师列表 (Analyst 对象的列表)</span><br><span class="line">    sections: Annotated[list, operator.add] # 报告章节列表 (使用 operator.add 作为 Send() API 的键，意味着列表可以通过相加来合并)</span><br><span class="line">    introduction: str                   # 最终报告的引言部分 (字符串类型)</span><br><span class="line">    content: str                        # 最终报告的内容主体部分 (字符串类型)</span><br><span class="line">    conclusion: str                     # 最终报告的结论部分 (字符串类型)</span><br><span class="line">    final_report: str                   # 最终完整的报告 (字符串类型)</span><br><span class="line"></span><br><span class="line"># 从 langgraph.constants 导入 Send 类</span><br><span class="line">from langgraph.constants import Send</span><br><span class="line">def initiate_all_interviews(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 这是“map”（映射）步骤，我们使用 Send API 并行运行每个采访子图 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否存在人类反馈</span><br><span class="line">    human_analyst_feedback = state.get(&#x27;human_analyst_feedback&#x27;)</span><br><span class="line">    if human_analyst_feedback:</span><br><span class="line">        # 如果有反馈，则返回到 &quot;create_analysts&quot; 节点进行调整</span><br><span class="line">        return &quot;create_analysts&quot;</span><br><span class="line"></span><br><span class="line">    # 否则，通过 Send() API 并行启动所有采访</span><br><span class="line">    else:</span><br><span class="line">        topic = state[&quot;topic&quot;]</span><br><span class="line">        # 为每个分析师创建一个 Send 对象</span><br><span class="line">        # 目标是 &quot;conduct_interview&quot; 节点</span><br><span class="line">        # 传递的参数包括该分析师对象和一条初始消息</span><br><span class="line">        return [Send(&quot;conduct_interview&quot;, &#123;&quot;analyst&quot;: analyst,</span><br><span class="line">                                           &quot;messages&quot;: [HumanMessage(</span><br><span class="line">                                               content=f&quot;所以你说你正在写一篇关于 &#123;topic&#125; 的文章？&quot;</span><br><span class="line">                                           )</span><br><span class="line">                                                       ]&#125;) for analyst in state[&quot;analysts&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="finalize-最终确定"><strong>Finalize</strong>
<strong>最终确定</strong></h5>
<p>我们添加最后一个步骤，为最终报告撰写引言和结论。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import List, Annotated</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"># 定义用于撰写最终报告的指令模板</span><br><span class="line">report_writer_instructions = &quot;&quot;&quot;你是一位正在撰写关于以下主题报告的技术作家：</span><br><span class="line"></span><br><span class="line">&#123;topic&#125;</span><br><span class="line">    </span><br><span class="line">你有一个分析师团队。每个分析师做了两件事：</span><br><span class="line"></span><br><span class="line">1. 他们就一个特定的子主题与专家进行了采访。</span><br><span class="line">2. 他们将他们的发现写成了一份备忘录。</span><br><span class="line"></span><br><span class="line">你的任务：</span><br><span class="line"></span><br><span class="line">1. 你将得到一份来自你所有分析师的备忘录集合。</span><br><span class="line">2. 仔细思考每份备忘录中的见解。</span><br><span class="line">3. 将这些见解整合成一个清晰的整体摘要，把所有备忘录中的核心思想联系起来。</span><br><span class="line">4. 将每份备忘录中的要点总结成一个连贯的单一叙述。</span><br><span class="line"></span><br><span class="line">报告格式要求：</span><br><span class="line"> </span><br><span class="line">1. 使用 Markdown 格式。</span><br><span class="line">2. 报告开头不要有前言。</span><br><span class="line">3. 不要使用子标题。</span><br><span class="line">4. 报告开头使用一个一级标题：## Insights （## 见解）</span><br><span class="line">5. 在报告中不要提及任何分析师的名字。</span><br><span class="line">6. 保留备忘录中的所有引用，这些引用会用方括号标注，例如 [1] 或 [2]。</span><br><span class="line">7. 创建一个最终的、合并的来源列表，并添加到以 `## Sources` 为标题的部分。</span><br><span class="line">8. 按顺序列出你的来源，不要重复。</span><br><span class="line"></span><br><span class="line">[1] 来源 1</span><br><span class="line">[2] 来源 2</span><br><span class="line"></span><br><span class="line">以下是你的分析师提供的备忘录，你需要根据它们来撰写报告：</span><br><span class="line"></span><br><span class="line">&#123;context&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_report(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告主体内容的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节（备忘录）</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节（备忘录）连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和备忘录内容，调用 LLM 生成最终报告</span><br><span class="line">    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)    </span><br><span class="line">    report = llm.invoke([SystemMessage(content=system_message)] + [HumanMessage(content=&quot;根据这些备忘录写一份报告。&quot;)]) </span><br><span class="line">    # 返回报告内容</span><br><span class="line">    return &#123;&quot;content&quot;: report.content&#125;</span><br><span class="line"></span><br><span class="line"># 定义用于撰写引言和结论的指令模板</span><br><span class="line">intro_conclusion_instructions = &quot;&quot;&quot;你是一位正在完成关于 &#123;topic&#125; 报告的技术作家。</span><br><span class="line"></span><br><span class="line">你将得到报告的所有章节。</span><br><span class="line"></span><br><span class="line">你的工作是撰写一个清晰且有说服力的引言或结论部分。</span><br><span class="line"></span><br><span class="line">用户会指示你是写引言还是结论。</span><br><span class="line"></span><br><span class="line">两个部分都不要有前言。</span><br><span class="line"></span><br><span class="line">目标大约 100 个词，简洁地预览（对于引言）或回顾（对于结论）报告的所有章节。</span><br><span class="line"></span><br><span class="line">使用 Markdown 格式。</span><br><span class="line"></span><br><span class="line">对于你的引言，创建一个引人注目的标题，并使用 # 标题级别。</span><br><span class="line">对于你的引言，使用 ## Introduction （## 引言） 作为部分标题。</span><br><span class="line"></span><br><span class="line">对于你的结论，使用 ## Conclusion （## 结论） 作为部分标题。</span><br><span class="line"></span><br><span class="line">以下是供你参考以撰写相应部分的章节：&#123;formatted_str_sections&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_introduction(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告引言的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和章节内容，调用 LLM 生成引言</span><br><span class="line">    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    </span><br><span class="line">    intro = llm.invoke([instructions] + [HumanMessage(content=&quot;写报告的引言&quot;)]) </span><br><span class="line">    # 返回引言内容</span><br><span class="line">    return &#123;&quot;introduction&quot;: intro.content&#125;</span><br><span class="line"></span><br><span class="line">def write_conclusion(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告结论的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和章节内容，调用 LLM 生成结论</span><br><span class="line">    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    </span><br><span class="line">    conclusion = llm.invoke([instructions] + [HumanMessage(content=&quot;写报告的结论&quot;)]) </span><br><span class="line">    # 返回结论内容</span><br><span class="line">    return &#123;&quot;conclusion&quot;: conclusion.content&#125;</span><br><span class="line"></span><br><span class="line">def finalize_report(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 这是“reduce”（归约）步骤，我们收集所有部分，将它们组合起来，并进行反思以写出引言/结论 &quot;&quot;&quot;</span><br><span class="line">    &quot;&quot;&quot; 最终整合报告的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取报告主体内容</span><br><span class="line">    content = state[&quot;content&quot;]</span><br><span class="line">    # 如果内容以 &quot;## Insights&quot; 开头，则移除这个标题</span><br><span class="line">    if content.startswith(&quot;## Insights&quot;):</span><br><span class="line">        content = content.strip(&quot;## Insights&quot;)</span><br><span class="line">    # 尝试分离报告主体和来源部分</span><br><span class="line">    if &quot;## Sources&quot; in content:</span><br><span class="line">        try:</span><br><span class="line">            content, sources = content.split(&quot;\n## Sources\n&quot;)</span><br><span class="line">        except:</span><br><span class="line">            sources = None # 如果分离失败，则来源部分为空</span><br><span class="line">    else:</span><br><span class="line">        sources = None</span><br><span class="line"></span><br><span class="line">    # 将引言、主体内容和结论连接起来形成最终报告</span><br><span class="line">    final_report = state[&quot;introduction&quot;] + &quot;\n\n---\n\n&quot; + content + &quot;\n\n---\n\n&quot; + state[&quot;conclusion&quot;]</span><br><span class="line">    # 如果存在来源部分，则将其附加到最终报告末尾</span><br><span class="line">    if sources is not None:</span><br><span class="line">        final_report += &quot;\n\n## Sources\n&quot; + sources</span><br><span class="line">    # 返回最终报告</span><br><span class="line">    return &#123;&quot;final_report&quot;: final_report&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">builder = StateGraph(ResearchGraphState)</span><br><span class="line">builder.add_node(&quot;create_analysts&quot;, create_analysts)</span><br><span class="line">builder.add_node(&quot;human_feedback&quot;, human_feedback)</span><br><span class="line">builder.add_node(&quot;conduct_interview&quot;, interview_builder.compile()) # 将之前定义的采访图编译后作为一个节点</span><br><span class="line">builder.add_node(&quot;write_report&quot;, write_report)</span><br><span class="line">builder.add_node(&quot;write_introduction&quot;, write_introduction)</span><br><span class="line">builder.add_node(&quot;write_conclusion&quot;, write_conclusion)</span><br><span class="line">builder.add_node(&quot;finalize_report&quot;, finalize_report)</span><br><span class="line"></span><br><span class="line"># 定义工作流逻辑</span><br><span class="line">builder.add_edge(START, &quot;create_analysts&quot;) # 从开始到创建分析师</span><br><span class="line">builder.add_edge(&quot;create_analysts&quot;, &quot;human_feedback&quot;) # 创建分析师后进入人类反馈环节</span><br><span class="line"># 条件边：根据 human_feedback 节点的输出，决定是回到创建分析师还是开始采访</span><br><span class="line">builder.add_conditional_edges(&quot;human_feedback&quot;, initiate_all_interviews, [&quot;create_analysts&quot;, &quot;conduct_interview&quot;]) </span><br><span class="line"># 采访完成后，并行执行撰写报告、引言和结论</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_report&quot;)</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_introduction&quot;)</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_conclusion&quot;)</span><br><span class="line"># 撰写完报告的三个部分后，汇聚到最终整合步骤</span><br><span class="line">builder.add_edge([&quot;write_conclusion&quot;, &quot;write_report&quot;, &quot;write_introduction&quot;], &quot;finalize_report&quot;)</span><br><span class="line">builder.add_edge(&quot;finalize_report&quot;, END) # 最终整合后结束</span><br><span class="line"></span><br><span class="line"># 编译图</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"># 编译图，并设置在 &#x27;human_feedback&#x27; 节点前中断，以及使用检查点保存器</span><br><span class="line">graph = builder.compile(interrupt_before=[&#x27;human_feedback&#x27;], checkpointer=memory)</span><br><span class="line"># 显示图的可视化表示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725102148881.png" alt="image-20250725102148881">
<figcaption aria-hidden="true">image-20250725102148881</figcaption>
</figure>
<h5 id="测试">测试</h5>
<p>让我们提出一个关于 LangGraph 的开放式问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">max_analysts = 3 </span><br><span class="line">topic = &quot;采用 LangGraph 作为代理框架的好处&quot;</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 使用 stream 但不执行打印逻辑</span><br><span class="line">for event in graph.stream(&#123;</span><br><span class="line">    &quot;topic&quot;: topic,</span><br><span class="line">    &quot;max_analysts&quot;: max_analysts</span><br><span class="line">&#125;, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    pass  # 不执行任何操作</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#人工更新节点</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                                &quot;请加入这家原生生成式 AI 创业公司的首席执行官。&quot;&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 确认我们已经满意，返回none</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            None&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 继续执行</span><br><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;updates&quot;):</span><br><span class="line">    print(&quot;--Node--&quot;)</span><br><span class="line">    node_name = next(iter(event.keys()))</span><br><span class="line">    print(node_name)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725103159942.png" alt="image-20250725103159942">
<figcaption aria-hidden="true">image-20250725103159942</figcaption>
</figure>
<p>https://smith.langchain.com/public/6504cafd-d314-48d1-8640-57dc3f472e61/r</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/21/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/Retrieval/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/21/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/Retrieval/" class="post-title-link" itemprop="url">Retrieval</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-21 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-21T00:00:00+08:00">2025-07-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-05 10:41:58" itemprop="dateModified" datetime="2025-08-05T10:41:58+08:00">2025-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">实习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/" itemprop="url" rel="index"><span itemprop="name">晨晟智控</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="elastic-search">elastic search</h3>
<p>Elasticsearch 是当今最流行的
<strong>开源分布式搜索与分析引擎</strong>，用 Java 开发，基于
<strong>Apache Lucene</strong>
构建。它把<strong>全文检索、实时分析、时序数据、地理空间查询</strong>和<strong>向量检索</strong>统一到一个平台，被广泛用于日志、指标、安全、企业搜索以及
AI/RAG 场景。</p>
<p>RAG 系统中，<strong>Elasticsearch
不仅是向量数据库，更是语义检索引擎和上下文构建器</strong>，更准确地说，是<strong>向量数据库
+ 全文检索引擎</strong>的混合角色。</p>
<h4 id="查找语句">查找语句</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">GET /test_full_v1/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;高压旁路管道磁粉检测使用的是哪种磁化方法和磁悬液浓度？&quot;,</span><br><span class="line">      &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;,&quot;report_url&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices?v#查看所有的所有</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_count#查看文件数</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_mapping#查看映射</span><br><span class="line"></span><br><span class="line">GET test_full_v1#查看索引内容</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_search#查看索引内容</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 3,</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices/zxj_test#查看索引是否存在</span><br></pre></td></tr></table></figure>
<p>可视化平台kibana的内网路径：</p>
<ul>
<li><code>http://10.117.128.50:5601</code></li>
<li>http://10.117.128.50:5601/app/dev_tools#/console/shell
开发者工具</li>
</ul>
<h4 id="es支持的几种检索函数">es支持的几种检索函数</h4>
<h5 id="向量搜索">向量搜索</h5>
<p>这里的向量搜索也就是稠密向量检索，过程为<strong>“把文本/图像等非结构化数据映射成高维向量
→ 在向量空间里做近似最近邻（ANN）搜索 →
按相似度排序返回结果”</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def vector_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建Elasticsearch KNN查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;knn&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: dense_vector_field,      # 指定存储向量的字段名</span><br><span class="line">            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">            &quot;k&quot;: 5,                          # 返回最相似的5个结果</span><br><span class="line">            &quot;num_candidates&quot;: 10,            # 在10个候选中选择最优的5个（提高搜索效率和准确性）</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="bm25">bm25</h5>
<p>BM25（<strong>Best Matching
25</strong>）也就是全文关键词搜索，或者叫传统关键词搜索，他的核心思想为<strong>“词频越高、文档越短、词越稀有，则相关性越高”</strong>，在
TF-IDF 的基础上引入词频饱和、文档长度归一化两项修正。</p>
<blockquote>
<p>TF-IDF（<strong>Term Frequency–Inverse Document
Frequency，词频-逆文档频率</strong>）是一种经典的
<strong>文本特征权重计算方法</strong>，用于衡量
<strong>一个词对一篇文档的重要性</strong>。</p>
</blockquote>
<p>项目中的bm25检索采取多字段匹配的方式，还有几个参数需要了解，如下</p>
<ol type="1">
<li><p><strong>‘type’</strong> :决定了<strong>如何把多个字段的 BM25
打分合并成最终得分</strong>,常用的参数有以下三种</p>
<table>
<colgroup>
<col style="width: 24%">
<col style="width: 12%">
<col style="width: 63%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">type</th>
<th style="text-align: left;">中文含义</th>
<th style="text-align: left;">打分逻辑</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>best_fields</strong>（默认）</td>
<td style="text-align: left;">最佳字段优先</td>
<td style="text-align: left;">取 <strong>得分最高的那个字段</strong>
做最终分（可用 <code>tie_breaker</code> 让次佳字段再贡献一点点）。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>most_fields</strong></td>
<td style="text-align: left;">最多字段优先</td>
<td style="text-align: left;">把所有命中字段的得分
<strong>直接相加</strong>（类似 OR 逻辑），字段越多分越高。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>cross_fields</strong></td>
<td style="text-align: left;">跨字段合并</td>
<td style="text-align: left;">把多个字段视为
<strong>一个虚拟大字段</strong>，统一计算 TF 和
IDF，解决“关键词分散在不同字段”问题。</td>
</tr>
</tbody>
</table></li>
<li><p><strong><code>'tie_breaker'</code></strong>：当多个字段都匹配时，<strong>“最佳字段”得分
+ 其余字段得分×tie_breaker</strong> 作为最终得分。</p></li>
<li><p><strong><code>'operator'</code></strong>:控制<strong>单个字段内</strong>的多个词项是“AND”还是“OR”关系。</p>
<ul>
<li><strong><code>"AND"</code></strong>
要求<strong>同一个字段</strong>必须同时包含所有查询词，减少噪音，提高精准度。适合地址、姓名等跨字段严格匹配。</li>
<li><strong><code>"OR"</code></strong>
只要字段里出现任意一个词就匹配，召回量大，但可能引入不相关结果。</li>
</ul></li>
</ol>
<p>最后，每个字段还可以人工设置权重，如<code>"fields": ["title^3", "content", "tags^2"]</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def bm25_query(search_query: str):</span><br><span class="line">    # 使用BM25算法进行传统关键词匹配</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            &quot;multi_match&quot;: &#123;  # 多字段匹配查询</span><br><span class="line">                &quot;query&quot;: search_query,</span><br><span class="line">                &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;size&quot;: 8,  # 返回最多8个结果</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="混合检索">混合检索</h5>
<p>混合检索也就是 <a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html">Reciprocal
Rank Fusion</a>（RRF），通过结合向量搜索和 BM25 搜索的结果综合判断。</p>
<p>但由于es中混合检索需要付费使用，后续检索效果评估时不做测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">def hybrid_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建混合搜索查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;retriever&quot;: &#123;</span><br><span class="line">            # 使用RRF (Reciprocal Rank Fusion) 算法融合多个检索器的结果</span><br><span class="line">            &quot;rrf&quot;: &#123;</span><br><span class="line">                # 定义多个检索器列表</span><br><span class="line">                &quot;retrievers&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第一个检索器：多字段BM25关键词搜索</span><br><span class="line">                        &quot;standard&quot;: &#123;</span><br><span class="line">                            &quot;query&quot;: &#123;</span><br><span class="line">                                # 使用multi_match在多个字段上进行BM25搜索</span><br><span class="line">                                &quot;multi_match&quot;: &#123;</span><br><span class="line">                                    &quot;query&quot;: search_query,</span><br><span class="line">                                    &quot;type&quot;: &quot;best_fields&quot;,      # 选择最佳匹配字段</span><br><span class="line">                                    &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第二个检索器：KNN向量近似搜索</span><br><span class="line">                        &quot;knn&quot;: &#123;</span><br><span class="line">                            &quot;field&quot;: dense_vector_field,      # 向量字段名（使用定义的变量）</span><br><span class="line">                            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">                            &quot;k&quot;: 5,                          # 返回5个最相似的向量结果</span><br><span class="line">                            &quot;num_candidates&quot;: 10,            # 候选向量数量，用于提高搜索准确性</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="模糊检索">模糊检索</h5>
<p>无论是在网页搜索、文件检索，还是数据库查询中，我们时常会因为拼写错误或信息不完整而无法找到需要的结果。<strong>模糊搜索</strong>（Fuzzy
Search）应运而生，它通过识别与查询相似的词语来帮助我们获得更加灵活的搜索结果。</p>
<p>这里是将bm25与模糊搜索结合起来</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">def fuzzy_query(search_query: str):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    创建模糊搜索查询函数，支持拼写错误和近似匹配</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        search_query (str): 用户输入的搜索查询文本</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        Dict: Elasticsearch模糊搜索查询体</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            # 使用match查询进行文本匹配</span><br><span class="line">            &quot;match&quot;: &#123;</span><br><span class="line">                # 在指定的文本字段中进行搜索</span><br><span class="line">                text_field: &#123;</span><br><span class="line">                    &quot;query&quot;: search_query,        # 用户的搜索查询文本</span><br><span class="line">                    &quot;fuzziness&quot;: &quot;AUTO&quot;,          # 自动模糊匹配设置</span><br><span class="line">                    # fuzziness参数说明：</span><br><span class="line">                    # - &quot;AUTO&quot;：根据词长度自动调整模糊度</span><br><span class="line">                    #   - 0-2个字符：不允许错误</span><br><span class="line">                    #   - 3-5个字符：允许1个编辑距离错误</span><br><span class="line">                    #   - 5个以上字符：允许2个编辑距离错误</span><br><span class="line">                    # - 也可以设置具体数值：0, 1, 2</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><code>AUTO</code> 规则：<strong>0~2
字符</strong>不允许错；<strong>3~5 字符</strong>最多1错；<strong>&gt;5
字符</strong>最多2错。</li>
<li>对 <strong>text 字段</strong>先分词，再对每个 token 做模糊 → 召回
<code>Elasticsearch</code>。</li>
</ul>
<h4 id="elasticsearch的连接">elasticsearch的连接</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from langchain_elasticsearch import ElasticsearchRetriever</span><br><span class="line">from embeddings_model import select_embeddings_model</span><br><span class="line"># 根据模型名称选择嵌入模型</span><br><span class="line">embedding_model_name=&#x27;bge&#x27;</span><br><span class="line">embeddings = select_embeddings_model(embedding_model_name)</span><br><span class="line">dense_vector_field=&#x27;vector&#x27;</span><br><span class="line">text_field=&#x27;text&#x27;</span><br><span class="line">search_func=fuzzy_query</span><br><span class="line"># 创建Elasticsearch检索器</span><br><span class="line">retriever = ElasticsearchRetriever.from_es_params(</span><br><span class="line">    index_name=&quot;zxj_test&quot;,  # 指定索引名称</span><br><span class="line">    body_func=fuzzy_query,  # 查询函数</span><br><span class="line">    content_field=&quot;text&quot;,  # 内容字段名</span><br><span class="line">    url=&#x27;http://elasticsearch:9200/&#x27;# Elasticsearch服务器地址</span><br><span class="line">)</span><br><span class="line">print(&quot;连接成功&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="elasticsearch的入库">elasticsearch的入库</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">document = []</span><br><span class="line">id_list = []</span><br><span class="line"></span><br><span class="line"># 遍历文件夹中的所有.md文件</span><br><span class="line">for filename in os.listdir(folder_path):</span><br><span class="line">    if filename.endswith(&quot;.md&quot;):</span><br><span class="line">        file_path = os.path.join(folder_path, filename)</span><br><span class="line"></span><br><span class="line">        # 从文件名中提取chunk_id（去除.md扩展名）</span><br><span class="line">        chunk_id = filename.replace(&quot;.md&quot;, &quot;&quot;)</span><br><span class="line"></span><br><span class="line">        # 读取MD文件内容</span><br><span class="line">        with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as file:</span><br><span class="line">            text_content = file.read()</span><br><span class="line">  </span><br><span class="line">        # 查找对应的URL（根据文件名匹配）</span><br><span class="line">        report_url = &quot;&quot;</span><br><span class="line">        # 从folder_name中提取核心文档名（最后一个^后面的部分）</span><br><span class="line">        core_folder_name = folder_name.split(&#x27;^&#x27;)[-1]  # 提取核心文档名</span><br><span class="line"></span><br><span class="line">        # 根据core_folder_name查找对应的URL</span><br><span class="line">        report_url = find_url_by_name_from_list(docs_data, core_folder_name)</span><br><span class="line"></span><br><span class="line">        # 构建document结构</span><br><span class="line">        doc = Document(</span><br><span class="line">            page_content=text_content,</span><br><span class="line">            metadata=&#123;</span><br><span class="line">                &quot;report_name&quot;: folder_name,</span><br><span class="line">                &quot;report_url&quot;: report_url,</span><br><span class="line">                &quot;chunk_id&quot;: chunk_id</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        document.append(doc)</span><br><span class="line">        id_list.append(folder_name + &quot;_&quot; + chunk_id)</span><br><span class="line"></span><br><span class="line"># 批量添加到向量库</span><br><span class="line">es_vector_store.add_documents(documents=document, ids=id_list)</span><br><span class="line">print(f&quot;    文件夹 &#123;folder_name&#125; 已成功入库，共 &#123;len(document)&#125; 个文档块&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="相关资料">相关资料</h4>
<p><a target="_blank" rel="noopener" href="https://python.langchain.ac.cn/docs/integrations/retrievers/elasticsearch_retriever/#bm25">Elasticsearch检索器
| 🦜️🔗 LangChain 框架</a></p>
<h3 id="主流的检索策略">主流的检索策略</h3>
<h4 id="bm25-全文关键词检索">BM25 全文关键词检索</h4>
<p>BM25（Best Matching
25）是一种久经考验的排序算法，广泛应用于传统搜索引擎中。它基于“词袋模型”，核心思想是通过关键词匹配程度来衡量文档与查询的相关性。</p>
<p>核心原理概览：</p>
<p>词频 (Term Frequency,
TF)：一个词在文档中出现的次数越多，通常意味着这篇文档与该词相关性越高。但BM25会进行“饱和度”处理，避免某些超高频词过度影响结果。可以想象成，一篇文章提到“苹果”10次，比提到1次更相关，但提到100次和提到50次，在“苹果”这个主题上的相关性增加可能就没那么显著了。
逆文档频率 (Inverse Document Frequency,
IDF)：如果一个词在整个文档集合中都很罕见（只在少数文档中出现），那么它对于区分文档主题就更重要，IDF值就高。比如“量子纠缠”这个词远比“的”、“是”这类词更能锁定专业文档。
文档长度归一化：用于平衡长短文档的得分，避免长文档仅仅因为内容多而获得不公平的高分。
工作方式举例：当用户搜索“深度学习入门教程”时，BM25会倾向于找出那些更频繁出现“深度学习”、“入门”、“教程”这些词，且这些词相对不那么常见的文档。</p>
<p><strong>1. 公式整体结构</strong> <span class="math display">$$
\text{score}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot
\underbrace{\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot
\left(1 - b + b \cdot
\frac{|D|}{\text{avgdl}}\right)}}_{\text{词频归一化项（TF）}}
$$</span> - <strong>IDF 部分</strong>：衡量词项 $ q_i $
的区分能力（逆文档频率）。 - <strong>TF 部分</strong>：衡量词项 $ q_i $
在文档 $ D $ 中的匹配程度（词频归一化）。 -
<strong>求和</strong>：对查询中的所有词项 $ q_i $
的得分求和，得到最终相关性分数。</p>
<p><strong>2. IDF 部分</strong> <span class="math display">$$
\text{IDF}(q_i) = \ln\left(\frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}\right)
$$</span> - <strong>意义</strong>：IDF 值越高，词项 $ q_i $
越能区分文档（常见于少数文档中的词）。 -
<strong>平滑处理</strong>：分子和分母均加 0.5，避免极端值（如 $ n(q_i) =
0 $ 时 ID 无限大）。 - <strong>参数</strong>： - $ N $：文档总数。 - $
n(q_i) $：包含 $ q_i $ 的文档数。</p>
<p><strong>3. 词频归一化项（TF）</strong> <span class="math display">$$
\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot \left(1 - b + b
\cdot \frac{|D|}{\text{avgdl}}\right)}
$$</span> - <strong>非线性饱和</strong>：分子和分母均包含 $ f(q_i, D)
$，使词频增长带来的增益逐渐减小（避免长文档中重复词项的过度影响）。 -
<strong>文档长度归一化</strong>： - $ |D| $：文档 $ D $ 的长度（词数）。
- $ $：整个文档集合的平均文档长度。 - $ b <span class="math inline">：<em>控</em><em>制</em><em>文</em><em>档</em><em>长</em><em>度</em><em>对</em><em>得</em><em>分</em><em>的</em><em>影</em><em>响</em>（</span>
b=1 $ 时完全归一化，$ b=0 $ 时忽略长度）。 - <strong>参数</strong>： - $
k_1 $：控制词频饱和的系数（通常 $ k_1 $，默认 $ k_1 = 1.5 $）。 - $ b
$：默认 $ b = 0.75 $。</p>
<p>这个公式虽然看起来有些复杂，但它精妙地平衡了词频、词的稀有度以及文档长度这几个核心因素，是BM25算法效果出色的关键。</p>
<h6 id="bm25全文搜索与倒排索引它们是如何协同工作的">BM25、全文搜索与倒排索引：它们是如何协同工作的？</h6>
<p><strong>这三者是构建搜索系统的关键组件：</strong></p>
<ul>
<li><p>全文搜索 (Full-Text
Search)：这是我们希望达成的目标——在大量文本中找到包含特定信息的文档。</p></li>
<li><p>倒排索引 (Inverted
Index)：这是实现高效全文搜索的数据结构基础。它像一本书末尾的详细“关键词索引”，记录了每个词出现在哪些文档中以及相关位置信息。当用户查询时，系统可以通过倒排索引快速定位到包含查询词的候选文档。</p></li>
<li><p>BM25：在通过倒排索引找到候选文档后，BM25算法登场，为每个文档计算一个相关性得分，然后按分排序，将最相关的结果呈现给用户。</p></li>
</ul>
<p><strong>把它们比作在图书馆找特定主题的书籍：</strong></p>
<ul>
<li>你告诉图书管理员你要找关于“天体物理学”的书（用户查询）。</li>
<li>管理员查阅一个总卡片索引（倒排索引），迅速告诉你哪些书架（文档ID）上有包含“天体物理学”这个词的书。</li>
<li>你走到这些书架，快速翻阅这些书（BM25评分过程），根据目录、摘要和提及“天体物理学”的频繁程度及重要性，判断哪几本最符合你的需求，并把它们按相关性高低排好。</li>
</ul>
<h4 id="dense-vector-knn-向量语义检索">Dense Vector / kNN
向量语义检索</h4>
<p>向量语义检索（Dense Vector / k-Nearest Neighbor，简称
kNN）是一种<strong>基于高维稠密向量表示的语义检索技术</strong>，与传统关键词倒排索引不同，它通过<strong>自然语言的上下文含义</strong>而非字面匹配来寻找最相关的文档或实体。</p>
<ol type="1">
<li><p><strong>Embedding</strong>：使用预训练语言模型（如
BERT、Sentence-Transformers）把文本映射为<strong>固定维度的稠密向量</strong>（通常
128–1024 维）。</p></li>
<li><p><strong>kNN
搜索</strong>：给定查询向量，<strong>在向量空间中找距离最近的 k
个文档向量</strong>。距离度量常见：</p>
<ul>
<li>余弦相似度（cosine）</li>
<li>内积 / dot-product</li>
<li>L2 欧氏距离</li>
</ul></li>
</ol>
<h4 id="hybrid-retrieval-混合检索">Hybrid Retrieval 混合检索</h4>
<p>既然不同的检索策略各有千秋（例如，BM25擅长关键词精确匹配，Embedding擅长语义理解），那么将它们结合起来，是不是能达到“1+1&gt;2”的效果呢？答案是肯定的，这就是混合检索的核心思想。</p>
<p>常见做法：同时使用BM25（或其他稀疏检索方法）和一种或多种Embedding检索方法，然后将它们各自的检索结果进行融合排序。</p>
<p>融合策略举例：</p>
<p>RRF (Reciprocal Rank Fusion,
倒数排序融合)：一种简单但鲁棒的融合方法。它不关心不同检索系统输出的原始得分，只关心每个文档在各自结果列表中的排名。一个文档
doc 的RRF得分计算如下： <span class="math display"><em>S</em><em>c</em><em>o</em><em>r</em><em>e</em><sub><em>R</em></sub><em>R</em><em>F</em>(<em>d</em><em>o</em><em>c</em>) = <em>Σ</em><sub><em>s</em> ∈ <em>S</em><em>y</em><em>s</em><em>t</em><em>e</em><em>m</em><em>s</em></sub>(1/(<em>k</em> + <em>r</em><em>a</em><em>n</em><em>k</em><sub><em>s</em></sub>(<em>d</em><em>o</em><em>c</em>)))</span>
其中：</p>
<ul>
<li>Systems 是所有参与融合的检索系统的集合。</li>
<li>rank_s(doc) 是文档 doc 在检索系统 s
给出的结果列表中的排名（例如，第一名是1，第二名是2）。</li>
<li>k
是一个小常数（例如，常设置为60），用于平滑得分，避免排名靠后的文档得分过小或排名第一的文档得分占比过高。</li>
</ul>
<h4 id="reranker-重排序器">Reranker 重排序器</h4>
<p>经过上述一种或多种检索策略的“粗筛”（召回阶段），我们通常会得到一个包含较多候选文档的列表（比如几百个）。为了进一步提升最终喂给LLM的文档质量，Reranker（重排序器）应运而生。它相当于一位“精炼师”或“质量品鉴官”，对初步召回的结果进行更细致、更精准的二次排序。</p>
<ol type="1">
<li>召回 倒排 / 向量 / 混合先给 <strong>Top-N</strong>（N≈100~1
k）。</li>
<li>拼特征 把 <code>(query, doc)</code> 拼成一条输入：
<code>[CLS] 用户问题 [SEP] 标题+正文 [SEP]</code>。</li>
<li>打分 扔给 Cross-Encoder 或 ColBERT →
输出<strong>一个相关性分数</strong>。</li>
<li>重排 按分数从高到低重新排序，只留
<strong>Top-K</strong>（K≈10~20）。</li>
<li>返回 重排后的短列表交给前端或 LLM，完成一次“精读”。</li>
</ol>
<h4 id="参考">参考</h4>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_59614665/article/details/149066780">大模型RAG
|
深入了解几种主流的检索策略（BM25、Embedding、混合检索、Reranker）-CSDN博客</a></p>
<h3 id="项目关于elasticsearch代码阅读记录">项目关于elasticsearch代码阅读记录</h3>
<p>阅读elasticsearch代码相关记录:</p>
<ol type="1">
<li><strong>embedding_model</strong>.select_embeddings_model:根据指定的模型名称加载</li>
<li><strong>make_es_vector_store</strong>：
<ol type="1">
<li>docs_url =
pd.read_excel(‘docs_new.xlsx’)，从excel加载url并进行数据处理，保存筛选后的ur</li>
<li>完成文件加载测试：xizhang/retrival/docfile_test/test.py；</li>
<li>初始化es，使用elastic_search.load_es_index加载存储索引</li>
<li>完成测试elasticsearch连接与索引构建（索引名zxj_test）：/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_es_connect.py，/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_add_es.py</li>
<li>顺序批量处理文件：共16000多份，每十份为一批进行处理，使用download_pdf.py进行文件下载，使用，使用vector_base.rewrite_file对文件进行处理，这里可以修改代码，增加对mineru处理pdf的markdown文件的处理，返回Document对象列表；</li>
</ol></li>
<li><strong>elastic_search</strong></li>
</ol>
<p>重写了检索策略的函数，包括BM25，KNN，混合搜索</p>
<ol type="1">
<li><p>elastic_retriever创建Elasticsearch检索器：根据搜索类型选择对应的查询函数，创建Elasticsearch检索器ElasticsearchRetriever.from_es_params</p></li>
<li><p><strong>retrievers</strong></p>
<ol type="1">
<li>定义函数select_retriever，根据指定的名称选择并返回相应的检索器，目前只有bm25</li>
</ol></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/" class="post-title-link" itemprop="url">LangGraph学习——agent——上</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-07-18T00:00:00+08:00">2025-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-13 09:25:22" itemprop="dateModified" datetime="2025-08-13T09:25:22+08:00">2025-08-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">ai框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ai%E6%A1%86%E6%9E%B6/langgraph/" itemprop="url" rel="index"><span itemprop="name">langgraph</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="前言">前言</h3>
<p>本教程为langchain官方教程的学习记录</p>
<p><a target="_blank" rel="noopener" href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a target="_blank" rel="noopener" href="https://github.com/zxj-2023/learn-rag-langchain">[learn-rag-langchain/academy-langgraph
at main ·
zxj-2023/learn-rag-langchain](https://github.com/zxj-2023/learn-rag-langchain/tree/main/academy-langgraph)</a></p>
<h3 id="module-1">module-1</h3>
<h4 id="route路由">route路由</h4>
<p>在 LangGraph
中，<strong>route（路由）*<em>的核心作用是*</em>根据当前状态动态决定“下一步应该执行哪个节点”</strong></p>
<h5 id="定义工具">定义工具</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def multiply(a: int, b: int) -&gt; int:</span><br><span class="line">    &quot;&quot;&quot;Multiply a and b.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: first int</span><br><span class="line">        b: second int</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line">    </span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">llm_with_tools = llm.bind_tools([multiply])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>三引号字符串叫 <strong>docstring</strong>，它会被 LangChain
拿来做两件事：</p>
<ol type="1">
<li><strong>生成工具的 description（给大模型看的“说明书”）</strong>
没有它时，LangChain 只能退而求其次，把函数名 <code>multiply</code>
拼成一句 “multiply tool”
之类的默认描述。大模型拿到的工具列表里，这个工具就只有一个干巴巴的名字和参数列表，它可能猜不到这个工具到底是干什么的</li>
<li><strong>给人类开发者自己看</strong>
IDE、文档生成器、静态检查工具都会读取这段文字，方便后期维护。</li>
</ol>
</blockquote>
<h5 id="构建条件边">构建条件边</h5>
<p><code>tool_calling_llm</code>
是一个<strong>普通的计算节点</strong>（node），负责把当前对话状态交给大模型，让大模型决定要不要调用工具；</p>
<p>真正完成“路由”动作的是 <strong><code>tools_condition</code></strong>
这个函数——它才是 LangGraph 里的 <strong>route（条件边）</strong>。</p>
<p><code>tools_condition</code> 是 作为<strong>LangGraph
预置的“默认路由函数”</strong>，功能就是，如果大模型的最新回复中包含工具调用，就调用工具</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># Node</span><br><span class="line">def tool_calling_llm(state: MessagesState):</span><br><span class="line">	#调用大模型后将最新的消息返回</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm_with_tools.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">#MessagesState 是 LangGraph 官方预置 的一种 状态（State）定义</span><br><span class="line">#这个状态维护了一个消息list，有新的消息就加进这个消息list</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;tool_calling_llm&quot;, tool_calling_llm)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode([multiply]))</span><br><span class="line">builder.add_edge(START, &quot;tool_calling_llm&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;tool_calling_llm&quot;,</span><br><span class="line">    # 如果助手（结果）的最新消息是工具调用 -&gt; tools_condition 路由到工具</span><br><span class="line">    # 如果助手（结果）的最新消息不是工具调用 -&gt; tools_condition 路由到 END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719142543838.png" alt="image-20250719142543838">
<figcaption aria-hidden="true">image-20250719142543838</figcaption>
</figure>
<h5 id="调用">调用</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage</span><br><span class="line">messages = [HumanMessage(content=&quot;你好，2乘2是多少&quot;)]</span><br><span class="line">messages = graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，2乘2是多少</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_e026ceb409e247748786ad)</span><br><span class="line"> Call ID: call_e026ceb409e247748786ad</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">4</span><br></pre></td></tr></table></figure>
<h4 id="agent代理">agent代理</h4>
<p>在 LangGraph 中，<strong>代理（Agent）</strong>
被明确定义为<strong>“一个由大语言模型（LLM）驱动的、能够循环决策并调用外部工具来完成任务的节点或子图”</strong>。</p>
<p><strong>Agent = LLM + 工具集合 + 提示模板</strong>，三者在 LangGraph
的状态化图结构里循环运行，直到满足停止条件。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.03629">ReAct</a>
是一种流行的通用智能体架构，它结合了这些扩展，并整合了三个核心概念。</p>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#tool-calling">工具调用</a>：允许LLM根据需要选择和使用各种工具。</li>
<li><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#memory">记忆</a>：使智能体能够保留和使用之前步骤的信息。</li>
<li><a target="_blank" rel="noopener" href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#planning">规划</a>：使LLM能够创建并遵循多步计划以实现目标。</li>
</ol>
<p>即</p>
<p><code>act</code>- 让模型调用特定工具</p>
<p><code>observe</code> - 将工具输出传递回模型</p>
<p><code>reason</code> -
让模型对工具输出进行推理，以决定下一步操作（例如，调用另一个工具或直接响应）</p>
</blockquote>
<h5 id="定义工具-1">定义工具</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tools = [add, multiply, divide]#工具函数具体内容省略</span><br><span class="line">llm = ChatOpenAI()</span><br><span class="line"></span><br><span class="line"># 在这个 ipynb 文件中，我们将并行工具调用（parallel tool calling）设置为 false，因为数学计算通常是按顺序执行的，并且这次我们有3个可以进行数学计算的工具。</span><br><span class="line"># OpenAI 模型为了效率，默认进行并行工具调用，详情请参阅 `https://python.langchain.com/docs/how_to/tool_calling_parallel/`</span><br><span class="line"># 不妨尝试一下，看看模型在处理数学方程式时的表现！</span><br><span class="line">llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)</span><br></pre></td></tr></table></figure>
<h5 id="创建代理">创建代理</h5>
<p>定义节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line"># System message</span><br><span class="line">sys_msg = SystemMessage(content=&quot;你是一个乐于助人的助手，负责对一组输入执行算术运算。&quot;)</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def assistant(state: MessagesState):</span><br><span class="line">   return &#123;&quot;messages&quot;: [llm_with_tools.invoke([sys_msg] + state[&quot;messages&quot;])]&#125;</span><br></pre></td></tr></table></figure>
<p>这一步相当于定义了系统提示词，然后在 assistant 这个节点里，通过
[sys_msg] + state[“messages”]
这部分代码，这个系统提示词被添加到了整个对话历史的最前面，然后一起发送给模型。这样一来，模型在生成回复时就会遵循这个系统提示词的指示。</p>
<p>与上一个不同的是，我们将 <code>Tools</code> 节点
<strong>回环</strong> 连接到
<code>Assistant</code>，从而形成一个回路。</p>
<p>在
assistant节点执行后，<code>tools_condition</code>检查模型的输出是否为工具调用。</p>
<p>如果是工具调用，则流程被导向至 <code>tools</code> 节点。</p>
<p><code>tools</code>节点重新连接到<code>assistant</code><strong>。</strong>
只要模型决定调用工具，此循环就会继续。</p>
<p>如果模型的响应不是工具调用，则流程被导向至结束，终止该过程。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># Graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line"></span><br><span class="line"># Define nodes: these do the work</span><br><span class="line">builder.add_node(&quot;assistant&quot;, assistant)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode(tools))</span><br><span class="line"></span><br><span class="line"># Define edges: these determine how the control flow moves</span><br><span class="line">builder.add_edge(START, &quot;assistant&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;assistant&quot;,</span><br><span class="line">    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools</span><br><span class="line">    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, &quot;assistant&quot;)</span><br><span class="line">react_graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># Show</span><br><span class="line">display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719145948088.png" alt="image-20250719145948088">
<figcaption aria-hidden="true">image-20250719145948088</figcaption>
</figure>
<h5 id="调用-1">调用</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">messages = [HumanMessage(content=&quot;将3和4相加。将结果乘以2。再将结果除以5。&quot;)]</span><br><span class="line">messages = react_graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line"></span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=False的输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_6c69898dba0342bfbb889e)</span><br><span class="line"> Call ID: call_6c69898dba0342bfbb889e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_9940e7603ecf4a13a5f2fb)</span><br><span class="line"> Call ID: call_9940e7603ecf4a13a5f2fb</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  divide (call_d48fbbe205a14dfbaa3500)</span><br><span class="line"> Call ID: call_d48fbbe205a14dfbaa3500</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是2.8。</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=True的输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_e0c7d8e65f2c49e8aecd3e)</span><br><span class="line"> Call ID: call_e0c7d8e65f2c49e8aecd3e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">  multiply (call_5bf824058e64489aaace91)</span><br><span class="line"> Call ID: call_5bf824058e64489aaace91</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">  divide (call_36c34f69f6574028b28847)</span><br><span class="line"> Call ID: call_36c34f69f6574028b28847</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是 **2.8**。</span><br></pre></td></tr></table></figure>
<h4 id="agent-memory代理记忆">Agent memory代理记忆</h4>
<p>使用chekpointer检查点的功能，最简单的检查点之一是
<code>MemorySaver</code>，这是一个用于图形状态的内存键值存储。</p>
<p>这个检查点就相当于把<strong>图的每一次“状态快照”持久化到外部存储</strong>的机制。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">react_graph_memory = builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p>我们可以使用 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/persistence/">记忆功能</a>
来解决这个问题！LangGraph
可以使用检查点工具在每一步之后自动保存图的状态。这一内置的持久化层为我们提供了内存功能，使
LangGraph 能够从最后一次状态更新处继续。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Specify a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Specify an input</span><br><span class="line">messages = [HumanMessage(content=&quot;Add 3 and 4.&quot;)]</span><br><span class="line"></span><br><span class="line"># Run</span><br><span class="line">messages = react_graph_memory.invoke(&#123;&quot;messages&quot;: messages&#125;,config)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当我们使用内存时，我们需要指定一个 <code>thread_id</code>。这
<code>thread_id</code> 将存储我们的图形状态集合。</p>
<p>如下图，检查点在图的每一步写入状态，这些检查点保存在一个线程中
，我们可以使用 <code>thread_id</code> 在未来访问该线程</p>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66e0e9f526b41a4ed9e2d28b_agent-memory2.png" alt="state.jpg">
<figcaption aria-hidden="true">state.jpg</figcaption>
</figure>
<h3 id="module-2">module-2</h3>
<h4 id="state-scheme状态模式">state-scheme状态模式</h4>
<p>LangGraph 的 <strong>state-scheme（状态模式）</strong>
就是“一张<strong>蓝图</strong>”，它告诉框架：“在整个图的生命周期里，状态对象应该长什么样、每个字段怎样被更新、以及节点之间如何共享或隔离数据。”</p>
<p>state-scheme 用 <strong>TypedDict</strong> 或 <strong>Pydantic
BaseModel</strong> 来声明，定义了：</p>
<ul>
<li>状态里有哪些字段（key）</li>
<li>每个字段的 Python 类型</li>
<li><strong>可选</strong> 该字段的
<strong>reducer</strong>（更新规则）</li>
</ul>
<h5 id="typeddict"><strong>TypedDict</strong></h5>
<p><strong>基本定义</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    foo: str</span><br><span class="line">    bar: str</span><br></pre></td></tr></table></figure>
<p><strong>可增加像 <code>Literal</code>
这样的类型提示，使其更有价值</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from typing import Literal</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p>在这里，<code>mood</code> 只能是 “happy” 或 “sad”。</p>
<p><strong>加 reducer：让更新“可追加”而不覆盖</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class MathState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line">    scratchpad: Annotated[list[str], add_message]  # 新元素自动追加</span><br><span class="line">    answer: int</span><br></pre></td></tr></table></figure>
<p><code>Annotated[list[str], add]</code> 告诉 LangGraph：当节点返回
<code>&#123;"scratchpad": ["新步骤"]&#125;</code>
时，<strong>追加</strong>到现有列表，而不是替换</p>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">#定义节点</span><br><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state[&#x27;name&#x27;] + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state):</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;happy&quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_3(state):</span><br><span class="line">    print(&quot;---Node 3---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;sad&quot;&#125;</span><br><span class="line">#路由函数</span><br><span class="line">def decide_mood(state) -&gt; Literal[&quot;node_2&quot;, &quot;node_3&quot;]:</span><br><span class="line">        </span><br><span class="line">    # Here, let&#x27;s just do a 50 / 50 split between nodes 2, 3</span><br><span class="line">    if random.random() &lt; 0.5:</span><br><span class="line"></span><br><span class="line">        # 50% of the time, we return Node 2</span><br><span class="line">        return &quot;node_2&quot;</span><br><span class="line">    </span><br><span class="line">    # 50% of the time, we return Node 3</span><br><span class="line">    return &quot;node_3&quot;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(TypedDictState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719154439415.png" alt="image-20250719154439415">
<figcaption aria-hidden="true">image-20250719154439415</figcaption>
</figure>
<p>因为我们的状态是一个字典，我们只需用一个字典调用图，以设置状态中
<code>name</code> 键的初始值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;name&quot;:&quot;Lance&quot;&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="dataclass数据类"><strong>Dataclass数据类</strong></h5>
<p>python的dataclasses库提供了一种简洁的语法，用于创建主要用于存储数据的类。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line"></span><br><span class="line">@dataclass</span><br><span class="line">class DataclassState:</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state.name + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(DataclassState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>要访问 <code>dataclass</code> 的键，我们只需修改在
<code>node_1</code> 中使用的下标即可：</p>
<p>我们使用 <code>state.name</code> 来表示 <code>dataclass</code>
状态，而不是使用 <code>state["name"]</code> 来表示上面的
<code>TypedDict</code>。</p>
<p>你会注意到一个有点奇怪的地方：在每个节点中，我们仍然返回一个字典来执行状态更新。</p>
<p><strong>Dataclass 只是“描述”状态的形状，而真正在 LangGraph
的节点之间流动的依旧是「字典」</strong>，这是框架设计层面的约定</p>
<p>在这种情况下，<code>dataclass</code> 拥有键
<code>name</code>，因此我们可以通过从节点传递一个字典来更新它，就像在状态为
<code>TypedDict</code> 时所做的那样。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.invoke(DataclassState(name=&quot;Lance&quot;,mood=&quot;sad&quot;))</span><br></pre></td></tr></table></figure>
<p>我们通过 <code>dataclass</code> 来设置状态中每个键/通道的初始值！</p>
<h4 id="state-reducers状态更新函数"><strong>State
Reducers</strong>状态更新函数</h4>
<p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers">Reducers</a>
为我们指定了如何执行更新。它接收 <strong>旧状态</strong> 与
<strong>一次变更指令（action /
增量字段）</strong>，<strong>返回全新的状态对象</strong>，整个过程中<strong>不能修改原有数据</strong>。</p>
<p>我们可以使用 <code>Annotated</code> 类型来指定一个 reducer
函数。在这种情况下，让我们将每个节点返回的值附加到结果中，而不是覆盖它们。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing import Annotated</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br></pre></td></tr></table></figure>
<p>我们只需要一个可以执行此操作的缩减器：<code>operator.add</code> 是
Python 内置 operator 模块中的一个函数。当 <code>operator.add</code>
应用于列表时，它执行列表连接。</p>
<h5 id="custom-reducers-自定义-reducers"><strong>Custom Reducers 自定义
Reducers</strong></h5>
<p>我们同样可以自定义reducers函数，解决一些特殊情况，比如，如下可以解决传入参数为none的情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def reduce_list(left: list | None, right: list | None) -&gt; list:</span><br><span class="line">    &quot;&quot;&quot;安全地合并两个列表，处理其中一个或两个输入可能为 None 的情况。</span><br><span class="line"></span><br><span class="line">    参数：</span><br><span class="line">        left (list | None): 要合并的第一个列表，或 None。</span><br><span class="line">        right (list | None): 要合并的第二个列表，或 None。</span><br><span class="line"></span><br><span class="line">    返回：</span><br><span class="line">        list: 一个包含两个输入列表所有元素的新列表。</span><br><span class="line">               如果输入为 None，则将其视为空列表。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if not left:</span><br><span class="line">        left = []</span><br><span class="line">    if not right:</span><br><span class="line">        right = []</span><br><span class="line">    return left + right</span><br><span class="line"></span><br><span class="line">class DefaultState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br><span class="line"></span><br><span class="line">class CustomReducerState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], reduce_list]</span><br></pre></td></tr></table></figure>
<h5 id="messagesstate">MessagesState</h5>
<p>我可以使用内置的 reducer <code>add_messages</code>
来处理状态中的消息</p>
<p>而<em><code>MessagesState</code></em> <em>内置了一个</em>
<em><code>messages</code></em> 键 它还为该键内置了一个
<code>add_messages</code> 合并器，这两个是等价的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from typing import Annotated</span><br><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import AnyMessage</span><br><span class="line">from langgraph.graph.message import add_messages</span><br><span class="line"></span><br><span class="line"># 定义一个自定义的 TypedDict，其中包含一个带有 add_messages reducer 的消息列表。</span><br><span class="line">class CustomMessagesState(TypedDict):</span><br><span class="line">    messages: Annotated[list[AnyMessage], add_messages]</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br><span class="line"></span><br><span class="line"># 使用 MessagesState ，它包含带有 add_messages reducer 的 messages 键。</span><br><span class="line">class ExtendedMessagesState(MessagesState):</span><br><span class="line">    # 添加除 messages 之外所需的任何键， messages 是预构建的。</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br></pre></td></tr></table></figure>
<p>在使用 <code>add_messages</code> reducer
时，让我们展示一些有用的技巧。</p>
<p><strong>重写（Re-writing）</strong></p>
<p>如果我们传递的消息与 <code>messages</code> 列表中已有的消息具有相同的
ID，则该消息将被覆盖！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Initial state</span><br><span class="line">initial_messages = [AIMessage(content=&quot;Hello! How can I assist you?&quot;, name=&quot;Model&quot;, id=&quot;1&quot;),</span><br><span class="line">                    HumanMessage(content=&quot;I&#x27;m looking for information on marine biology.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line">                   ]</span><br><span class="line"></span><br><span class="line"># New message to add</span><br><span class="line">new_message = HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line"></span><br><span class="line"># Test</span><br><span class="line">add_messages(initial_messages , new_message)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[AIMessage(content=&#x27;Hello! How can I assist you?&#x27;, name=&#x27;Model&#x27;, id=&#x27;1&#x27;),</span><br><span class="line"> HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&#x27;Lance&#x27;, id=&#x27;2&#x27;)]</span><br></pre></td></tr></table></figure>
<p><strong>删除（Removal）</strong></p>
<p><code>add_messages</code> 也 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/">同样支持删除</a>。为此，我们简单地使用
<a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/messages/langchain_core.messages.modifier.RemoveMessage.html">RemoveMessage</a>
来自 <code>langchain_core</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Message list</span><br><span class="line">messages = [AIMessage(&quot;Hi.&quot;, name=&quot;Bot&quot;, id=&quot;1&quot;)]</span><br><span class="line">messages.append(HumanMessage(&quot;Hi.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;))</span><br><span class="line">messages.append(AIMessage(&quot;So you said you were researching ocean mammals?&quot;, name=&quot;Bot&quot;, id=&quot;3&quot;))</span><br><span class="line">messages.append(HumanMessage(&quot;Yes, I know about whales. But what others should I learn about?&quot;, name=&quot;Lance&quot;, id=&quot;4&quot;))</span><br><span class="line"></span><br><span class="line"># Isolate messages to delete</span><br><span class="line">delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]</span><br><span class="line">print(delete_messages)</span><br></pre></td></tr></table></figure>
<h4 id="multiple-schemas-多种状态"><strong>Multiple Schemas</strong>
多种状态</h4>
<h5 id="private-state-私有状态"><strong>Private State</strong>
私有状态</h5>
<p>首先，让我们讨论在节点之间传递 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/pass_private_state/">private
state</a>
的情况。这对于图的中间计算逻辑中需要的任何内容都很有用，但与图的整体输入或输出无关。</p>
<p>示例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    foo: int</span><br><span class="line"></span><br><span class="line">class PrivateState(TypedDict):</span><br><span class="line">    baz: int</span><br><span class="line"></span><br><span class="line">def node_1(state: OverallState) -&gt; PrivateState:</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;baz&quot;: state[&#x27;foo&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state: PrivateState) -&gt; OverallState:</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;foo&quot;: state[&#x27;baz&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(OverallState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_edge(&quot;node_1&quot;, &quot;node_2&quot;)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719171509917.png" alt="image-20250719171509917">
<figcaption aria-hidden="true">image-20250719171509917</figcaption>
</figure>
<p>我们将定义一个 <code>OverallState</code> 和一个
<code>PrivateState</code>。<code>node_2</code> 使用
<code>PrivateState</code> 作为输入，但输出写入到
<code>OverallState</code>。</p>
<p><code>baz</code> 仅包含在 <code>PrivateState</code>
中。因此，我们可以看到 <code>baz</code> 被排除在图形输出之外，因为它不在
<code>OverallState</code> 中。</p>
<h5 id="input-output-schema-输入输出模式"><strong>Input / Output Schema
</strong>输入/输出模式</h5>
<p>在 LangGraph 中，<strong>Input / Output Schema</strong>
就是“<strong>图的对外接口协议</strong>”：<strong>调用者只能按 Input
Schema 传参；图运行完后，只吐出 Output Schema 规定的字段。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"># 定义输入的模式</span><br><span class="line">class InputState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line"></span><br><span class="line"># 定义输出的模式</span><br><span class="line">class OutputState(TypedDict):</span><br><span class="line">    answer: str</span><br><span class="line"></span><br><span class="line"># 定义整体模式，结合输入和输出</span><br><span class="line">class OverallState(InputState, OutputState):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"># 定义处理输入并生成答案的节点</span><br><span class="line">def answer_node(state: InputState):</span><br><span class="line">    # 示例答案和额外键</span><br><span class="line">    return &#123;&quot;answer&quot;: &quot;bye&quot;, &quot;question&quot;: state[&quot;question&quot;]&#125;</span><br><span class="line"></span><br><span class="line"># 构建图，并指定输入和输出模式</span><br><span class="line">builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)</span><br><span class="line">builder.add_node(answer_node)  # 添加答案节点</span><br><span class="line">builder.add_edge(START, &quot;answer_node&quot;)  # 定义起始边</span><br><span class="line">builder.add_edge(&quot;answer_node&quot;, END)  # 定义结束边</span><br><span class="line">graph = builder.compile()  # 编译图</span><br><span class="line"></span><br><span class="line"># 使用输入调用图并打印结果</span><br><span class="line">print(graph.invoke(&#123;&quot;question&quot;: &quot;hi&quot;&#125;))</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;answer&#x27;: &#x27;bye Lance&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，<code>input</code> / <code>output</code>
模式对图的输入和输出上允许的键进行 <strong>过滤</strong>。可以看到
<code>output</code> 模式将输出限制为仅包含 <code>answer</code> 键。</p>
<h4 id="filtering-and-trimming-messages筛选和精简消息"><strong>Filtering
and trimming messages</strong>筛选和精简消息</h4>
<p>如果我们在处理长时间对话时不够小心，会导致高令牌使用量和延迟，因为我们传递给模型的是一系列不断增加的消息。所以要进行筛选和精简消息。</p>
<h5 id="简化器reducer"><strong>简化器（Reducer）</strong></h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Nodes</span><br><span class="line">def filter_messages(state: MessagesState):</span><br><span class="line">    # 删除除最近两条消息外的所有消息</span><br><span class="line">    delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]]</span><br><span class="line">    return &#123;&quot;messages&quot;: delete_messages&#125;</span><br><span class="line"></span><br><span class="line">def chat_model_node(state: MessagesState):    </span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;filter&quot;, filter_messages)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;filter&quot;)</span><br><span class="line">builder.add_edge(&quot;filter&quot;, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719203204234.png" alt="image-20250719203204234">
<figcaption aria-hidden="true">image-20250719203204234</figcaption>
</figure>
<h5 id="筛选消息filtering-messages"><strong>筛选消息（Filtering
messages）</strong></h5>
<p>如果你不需要或不希望修改图状态，可以直接过滤传递给聊天模型的消息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;][-1:])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>例如，只需传递一个过滤后的列表：<code>llm.invoke(messages[-1:])</code>
给模型。</p>
<p>状态包含了所有消息。但这里模型调用仅使用最后一条消息</p>
<h5 id="裁剪消息trim-messages"><strong>裁剪消息（Trim
messages）</strong></h5>
<p>另一种方法是根据设定一定数量的tokens进行 <a target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/trim_messages/#getting-the-last-max_tokens-tokens">trim
messages</a>。在把对话历史发给大模型之前，按 <strong>token 预算</strong>
把超长消息列表“剪”到合适长度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import trim_messages</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    # 使用 trim_messages 函数修剪消息列表</span><br><span class="line">    # max_tokens: 限制消息的最大令牌数</span><br><span class="line">    # strategy: 修剪策略，这里是“last”，表示保留最新的消息</span><br><span class="line">    # token_counter: 用于计算令牌数的模型实例</span><br><span class="line">    # allow_partial: 是否允许部分修剪</span><br><span class="line">    messages = trim_messages(</span><br><span class="line">            state[&quot;messages&quot;],</span><br><span class="line">            max_tokens=100,</span><br><span class="line">            strategy=&quot;last&quot;,</span><br><span class="line">            token_counter= ChatOpenAI(</span><br><span class="line">                model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">                api_key=&quot;sk-&quot;,</span><br><span class="line">                base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;),</span><br><span class="line">            allow_partial=False,</span><br><span class="line">        )</span><br><span class="line">    # 调用语言模型（llm）处理修剪后的消息，并返回结果</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(messages)]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h4 id="chatbot-with-message-summarization带有消息总结功能的聊天机器人"><strong>Chatbot
with message summarization</strong>带有消息总结功能的聊天机器人</h4>
<p>与其仅仅修剪或过滤消息，我们将展示如何使用大型语言模型（LLMs）来生成对话的实时摘要。</p>
<p>这使我们能够保留整个对话的压缩表示，而不仅仅是通过修剪或过滤将其移除。</p>
<p>我们将为该聊天机器人配备记忆功能，支持长时间对话，同时不会产生高昂的
token 成本或延迟。</p>
<h5 id="定义总结状态">定义总结状态</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">class State(MessagesState):</span><br><span class="line">    summary: str</span><br></pre></td></tr></table></figure>
<p>除了内置的 <code>messages</code>
键之外，我们现在还将包含一个自定义键（<code>summary</code>）。</p>
<h5 id="定义llm节点">定义LLM节点</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage </span><br><span class="line"> </span><br><span class="line"> # 定义调用模型的逻辑</span><br><span class="line">def call_model(state: State): </span><br><span class="line">     </span><br><span class="line">     # 获取摘要（如果存在） </span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 如果有摘要，则添加它</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 将摘要添加到系统消息中</span><br><span class="line">         system_message = f&quot;先前对话的摘要：&#123;summary&#125;&quot; </span><br><span class="line"> </span><br><span class="line">         # 将摘要附加到任何较新的消息中</span><br><span class="line">         messages = [SystemMessage(content=system_message)] + state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     else: </span><br><span class="line">         messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     return &#123;&quot;messages&quot;: response&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>调用我们的LLM</strong>，如果存在摘要，则将其纳入提示中。</p>
<blockquote>
<p>当 call_model 函数返回 {“messages”: response} 时，它是在告诉
langgraph ：“请用 response （即模型的新输出）来更新 State 对象中
messages 键对应的值。” langgraph 会将这个新消息追加到 messages
列表中，从而保持了对话历史的连续性</p>
</blockquote>
<h5 id="定义摘要节点">定义摘要节点</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def summarize_conversation(state: State): </span><br><span class="line">     </span><br><span class="line">     # 首先，我们获取任何现有的摘要</span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 创建我们的摘要提示</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 摘要已存在</span><br><span class="line">         summary_message = ( </span><br><span class="line">             f&quot;这是迄今为止对话的摘要：&#123;summary&#125;\n\n&quot; </span><br><span class="line">             &quot;请结合以上新消息扩展摘要：&quot; </span><br><span class="line">         ) </span><br><span class="line">         </span><br><span class="line">     else: </span><br><span class="line">         summary_message = &quot;创建以上对话的摘要：&quot; </span><br><span class="line"> </span><br><span class="line">     # 将提示添加到我们的历史记录中</span><br><span class="line">     messages = state[&quot;messages&quot;] + [HumanMessage(content=summary_message)] </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     </span><br><span class="line">     # 删除除最近2条消息外的所有消息</span><br><span class="line">     delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]] </span><br><span class="line">     return &#123;&quot;summary&quot;: response.content, &quot;messages&quot;: delete_messages&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>生成摘要</strong>。请注意，这里我们将使用
<code>RemoveMessage</code> 在生成摘要后过滤我们的状态。</p>
<h5 id="定义路由函数">定义路由函数</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.graph import END </span><br><span class="line"> # 决定是结束对话还是总结对话</span><br><span class="line">def should_continue(state: State): </span><br><span class="line">     </span><br><span class="line">     &quot;&quot;&quot;返回要执行的下一个节点。&quot;&quot;&quot; </span><br><span class="line">     </span><br><span class="line">     messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     # 如果消息超过六条，那么我们总结对话</span><br><span class="line">     if len(messages) &gt; 6: </span><br><span class="line">         return &quot;summarize_conversation&quot; </span><br><span class="line">     </span><br><span class="line">     # 否则我们就可以结束了</span><br><span class="line">     return END </span><br></pre></td></tr></table></figure>
<p>我们将添加一个条件边，以根据对话长度确定是否生成摘要。</p>
<blockquote>
<p>在 langgraph 中， Command
是一个特殊的类型，用于指导图形（graph）决定接下来应该执行哪个节点。
您可以把它看作是给图形下达的一个“命令”。</p>
</blockquote>
<h5 id="添加内存并编译图">添加内存并编译图</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, START</span><br><span class="line"></span><br><span class="line"># Define a new graph</span><br><span class="line">workflow = StateGraph(State)</span><br><span class="line">workflow.add_node(&quot;conversation&quot;, call_model)</span><br><span class="line">workflow.add_node(&quot;summarize_conversation&quot;,summarize_conversation)</span><br><span class="line"></span><br><span class="line"># Set the entrypoint as conversation</span><br><span class="line">workflow.add_edge(START, &quot;conversation&quot;)</span><br><span class="line">workflow.add_conditional_edges(&quot;conversation&quot;, should_continue)</span><br><span class="line">workflow.add_edge(&quot;summarize_conversation&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Compile</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph = workflow.compile(checkpointer=memory)</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h5 id="使用线程调用">使用线程调用</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">input_message = HumanMessage(content=&quot;我喜欢玩lol，你知道这个游戏吗&quot;)</span><br><span class="line">output = graph.invoke(&#123;&quot;messages&quot;: [input_message]&#125;, config) </span><br><span class="line">for m in output[&#x27;messages&#x27;][-1:]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当对话大于6，可生成概要</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.get_state(config).values.get(&quot;summary&quot;,&quot;&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="chatbot-with-message-summarization-external-db-memory具有消息总结和外部数据库记忆的聊天机器人"><strong>Chatbot
with message summarization &amp; external DB
memory</strong>具有消息总结和外部数据库记忆的聊天机器人</h4>
<h5 id="使用数据库">使用数据库</h5>
<p><code>SqliteSaver</code> 是 LangGraph 提供的一个
<strong>轻量级状态持久化工具</strong>，它将图的运行状态（即
checkpoint）保存到本地的 SQLite
数据库中，使得你可以在程序中断或重启后<strong>恢复执行上下文</strong>，特别适合本地开发、实验性项目或中小规模应用。</p>
<p>如果我们提供 “:memory:” ，它将创建一个内存中的 SQLite 数据库。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import sqlite3</span><br><span class="line"># In memory</span><br><span class="line">conn = sqlite3.connect(&quot;:memory:&quot;, check_same_thread = False)</span><br></pre></td></tr></table></figure>
<p>如果我们提供一个 db 路径，那么它将为我们创建一个数据库！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#在本地创建一个目录 state_db，并尝试从 GitHub 下载一个名为 example.db 的 SQLite 数据库文件</span><br><span class="line">!mkdir -p state_db &amp;&amp; [ ! -f state_db/example.db ] &amp;&amp; wget -P state_db https://github.com/langchain-ai/langchain-academy/raw/main/module-2/state_db/example.db</span><br><span class="line"></span><br><span class="line">db_path = &quot;state_db/example.db&quot;</span><br><span class="line">conn = sqlite3.connect(db_path, check_same_thread=False)</span><br></pre></td></tr></table></figure>
<p>定义checkpoint</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.checkpoint.sqlite import SqliteSaver</span><br><span class="line">memory = SqliteSaver(conn)</span><br></pre></td></tr></table></figure>
<p>像上一个形式编译图</p>
<p>让我们确认一下我们的状态是否已保存到本地。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">graph_state = graph.get_state(config)</span><br><span class="line">graph_state</span><br></pre></td></tr></table></figure>
<p>使用像 Sqlite 这样的数据库意味着状态会被持久化！</p>
<h3 id="module-3">module-3</h3>
<h4 id="streaming-流式传输"><strong>Streaming</strong> 流式传输</h4>
<p>现在，让我们来谈谈 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming">流式传输我们的图状态</a>
的方法。<code>.stream</code> 和 <code>.astream</code>
是用于流式返回结果的同步和异步方法。</p>
<p><code>values</code>：这将在每个节点被调用后流式传输图的完整状态。
<code>updates</code>：这将在每个节点被调用后流式传输图的状态更新。</p>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbaf892d24625a201744e5_streaming1.png" alt="values_vs_updates.png">
<figcaption aria-hidden="true">values_vs_updates.png</figcaption>
</figure>
<h5 id="stream_modeupdates">stream_mode=“updates”</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Create a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    print(chunk)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;conversation&#x27;: &#123;&#x27;messages&#x27;: AIMessage(content=&#x27;你好，zxj！很高兴认识你～有什么我可以帮你的吗？😊&#x27;, additional_kwargs=&#123;&#x27;refusal&#x27;: None&#125;, response_metadata=&#123;&#x27;token_usage&#x27;: &#123;&#x27;completion_tokens&#x27;: 16, &#x27;prompt_tokens&#x27;: 576, &#x27;total_tokens&#x27;: 592, &#x27;completion_tokens_details&#x27;: None, &#x27;prompt_tokens_details&#x27;: None&#125;, &#x27;model_name&#x27;: &#x27;qwen-plus-2025-04-28&#x27;, &#x27;system_fingerprint&#x27;: None, &#x27;id&#x27;: &#x27;chatcmpl-891471ae-2fe8-9b3d-b5f7-f4fcd55a4e16&#x27;, &#x27;service_tier&#x27;: None, &#x27;finish_reason&#x27;: &#x27;stop&#x27;, &#x27;logprobs&#x27;: None&#125;, id=&#x27;run--f36409f3-af43-4e9b-8a46-39646ad7c106-0&#x27;, usage_metadata=&#123;&#x27;input_tokens&#x27;: 576, &#x27;output_tokens&#x27;: 16, &#x27;total_tokens&#x27;: 592, &#x27;input_token_details&#x27;: &#123;&#125;, &#x27;output_token_details&#x27;: &#123;&#125;&#125;)&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>让我们来看一下 <code>stream_mode="updates"</code>。</p>
<p>因为我们使用 <code>updates</code>
进行流式传输，所以只有在图中的节点运行后，我们才能看到状态的更新。每个
<code>chunk</code> 是一个字典，以 <code>node_name</code>
为键，更新后的状态为值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    chunk[&#x27;conversation&#x27;][&quot;messages&quot;].pretty_print()</span><br></pre></td></tr></table></figure>
<p>现在我们直接打印状态更新。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好呀，zxj！再次见到你真高兴～😊 有什么我可以帮忙的吗？</span><br></pre></td></tr></table></figure>
<h5 id="stream_modevalues">stream_mode=“values”</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Start conversation, again</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">input_message = HumanMessage(content=&quot;你好我是zxj&quot;)</span><br><span class="line">for event in graph.stream(&#123;&quot;messages&quot;: [input_message]&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    for m in event[&#x27;messages&#x27;]:</span><br><span class="line">        m.pretty_print()</span><br><span class="line">    print(&quot;---&quot;*25)</span><br></pre></td></tr></table></figure>
<p>现在，我们可以看到 <code>stream_mode="values"</code>.这是在
<code>conversation</code> 节点被调用后，图的整个状态。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，zxj！有什么我可以帮你的吗？😊</span><br><span class="line">---------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h5 id="streaming-tokens-流式传输令牌"><strong>Streaming tokens</strong>
<strong>流式传输令牌</strong></h5>
<p>在 LangGraph 中，“流式传输令牌（Streaming
tokens）”指的是<strong>在节点内部的大模型（LLM）生成过程中，逐 token
地将中间结果实时推送到客户端</strong>的能力。实现这一能力的核心方法是
<code>astream_events</code>，它会以事件流的形式暴露整个执行过程中的所有细节，包括每一次
LLM 调用产生的 token。</p>
<p>每个事件是一个包含几个键的字典：</p>
<p><code>event</code>：这是正在发出的事件的类型。</p>
<p><code>name</code>：这是事件的名称。</p>
<p><code>data</code>：这是与事件相关联的数据。</p>
<p><code>metadata</code>：包含
<code>langgraph_node</code>，即发出事件的节点。</p>
<p>要点是，图表中聊天模型的令牌具有 <code>on_chat_model_stream</code>
类型。我们可以使用 <code>event['metadata']['langgraph_node']</code>
来选择要流式的节点。并且我们可以使用 <code>event['data']</code>
来获取每个事件的实际数据，而在这种情况下，数据是一个
<code>AIMessageChunk</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">node_to_stream = &#x27;conversation&#x27;#定义流式传输的节点</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;5&quot;&#125;&#125;</span><br><span class="line">input_message = HumanMessage(content=&quot;为我介绍lol&quot;)</span><br><span class="line">async for event in graph.astream_events(&#123;&quot;messages&quot;: [input_message]&#125;, config, version=&quot;v2&quot;):</span><br><span class="line">    # 从特定节点获取聊天模型生成的 Token</span><br><span class="line">    #事件类型必须是 逐 token 流式输出（on_chat_model_stream）。</span><br><span class="line">    if event[&quot;event&quot;] == &quot;on_chat_model_stream&quot; and event[&#x27;metadata&#x27;].get(&#x27;langgraph_node&#x27;,&#x27;&#x27;) == node_to_stream:</span><br><span class="line">        data = event[&quot;data&quot;]</span><br><span class="line">        print(data[&quot;chunk&quot;].content, end=&quot;|&quot;)</span><br></pre></td></tr></table></figure>
<p>event的常见类型</p>
<table>
<colgroup>
<col style="width: 32%">
<col style="width: 67%">
</colgroup>
<thead>
<tr>
<th>事件类型 (<code>event</code>)</th>
<th>触发时机与说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>on_chain_start</code></td>
<td>任意 Runnable（节点、子图或整个图）开始执行</td>
</tr>
<tr>
<td><code>on_chain_stream</code></td>
<td>节点/图在运行过程中 <strong>增量输出</strong> chunk</td>
</tr>
<tr>
<td><code>on_chain_end</code></td>
<td>任意 Runnable 执行完成</td>
</tr>
<tr>
<td><code>on_chat_model_start</code></td>
<td><strong>ChatModel</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_chat_model_stream</code></td>
<td><strong>ChatModel</strong> 逐 token 返回内容（打字机效果）</td>
</tr>
<tr>
<td><code>on_chat_model_end</code></td>
<td><strong>ChatModel</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_tool_start</code></td>
<td><strong>Tool</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_tool_end</code></td>
<td><strong>Tool</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_retriever_start</code></td>
<td><strong>Retriever</strong> 开始检索</td>
</tr>
<tr>
<td><code>on_retriever_end</code></td>
<td><strong>Retriever</strong> 检索结束</td>
</tr>
</tbody>
</table>
<h4 id="breakpoints-断点"><strong>Breakpoints 断点</strong></h4>
<p><code>human-in-the-loop</code>（人工介入/人在回路）的三大动机：</p>
<p>1️⃣
Approval（审批）我们可以中断智能体，将当前状态呈现给用户，并让用户决定是否执行该操作。</p>
<p>2️⃣ Debugging（调试/回放）我们可以回退图形以重现或避免问题</p>
<p>3️⃣ Editing（编辑）AI
产出的中间结果不符合预期，但不想重跑整图，可以直接修改状态</p>
<p>我们将介绍 <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/#simple-usage">breakpoints</a>，它提供了一种在特定步骤停止图的简单方法。</p>
<h5 id="breakpoints-for-human-approval用于人类审批的断点"><strong>Breakpoints
for human approval</strong>用于人类审批的断点</h5>
<p>假设我们关注工具的使用：我们希望批准代理使用其任何工具。</p>
<p>我们所需要做的就是简单地用 <code>interrupt_before=["tools"]</code>
编译图形，其中 <code>tools</code> 是我们的工具节点。</p>
<p>这意味着在执行工具调用的节点 <code>tools</code>
之前，执行将被中断。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;tools&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720225640772.png" alt="image-20250720225640772">
<figcaption aria-hidden="true">image-20250720225640772</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: HumanMessage(content=&quot;2乘3&quot;)&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br></pre></td></tr></table></figure>
<p>我们可以获取状态并查看要调用的下一个节点。这是一种很好的方法，可以发现图已被中断。</p>
<p>现在，我们将介绍一个很好的技巧。当我们使用 <code>None</code>
调用图时，它将直接从最后一个状态检查点继续！</p>
<figure>
<img src="https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png" alt="breakpoints.jpg">
<figcaption aria-hidden="true">breakpoints.jpg</figcaption>
</figure>
<p>状态快照（StateSnapshot）</p>
<ul>
<li>类型：专门用来存 <strong>一个时刻</strong> 的完整状态</li>
<li>获取方式：
<ul>
<li><code>Graph.get_state()</code> → <strong>最新的</strong> 快照</li>
<li><code>Graph.get_state_history()</code> → <strong>所有</strong>
快照列表</li>
</ul></li>
</ul>
<p>继续/重跑图</p>
<ul>
<li><code>Graph.stream(None, &#123;"thread_id": "xxx"&#125;)</code>
<ul>
<li>不传新输入 <code>None</code> 表示
<strong>从当前最新状态继续跑</strong></li>
<li>也可回退到历史快照，再重跑（调试/回放）</li>
</ul></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">6</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">2乘3的结果是6。</span><br></pre></td></tr></table></figure>
<h4 id="editing-graph-state-编辑图状态"><strong>Editing graph state
</strong>编辑图状态</h4>
<p>断点也是<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/">修改图状态的机会</a>让我们在
<code>assistant</code> 节点之前为代理设置断点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;assistant&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720230924672.png" alt="image-20250720230924672">
<figcaption aria-hidden="true">image-20250720230924672</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: &quot;2乘3&quot;&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br></pre></td></tr></table></figure>
<p>当状态中断时，我们可以直接应用状态更新</p>
<p>记住，对 <code>messages</code> 键的更新将使用
<code>add_messages</code> reducer：</p>
<p>**如果我们想覆盖现有的消息，可以提供带有* <em><code>id</code></em>
*的消息。** 如果我们只想将消息添加到消息列表中，则可以传递未指定
<code>id</code> 的消息，如下所示。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&quot;不要，实际上要3乘3!&quot;)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">new_state = graph.get_state(thread).values</span><br><span class="line">for m in new_state[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">不要，实际上要3乘3!</span><br></pre></td></tr></table></figure>
<p>现在，让我们继续进行我们的代理操作，只需传递 <code>None</code>
并允许其从当前状态继续执行。我们输出当前内容，然后继续执行剩余的节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="dynamic-breakpoints-动态断点"><strong>Dynamic breakpoints
</strong>动态断点</h4>
<p>你可以根据条件来实现它（从节点内部基于开发人员定义的逻辑）。您可以向用户说明其中断原因（通过将您想传递的内容发送到
<code>NodeInterrupt</code>）。</p>
<p>让我们创建一个图表，其中根据输入的长度会抛出一个
<code>NodeInterrupt</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.errors import NodeInterrupt</span><br><span class="line">from langgraph.graph import START, END, StateGraph</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    input: str</span><br><span class="line"></span><br><span class="line">def step_1(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 1---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_2(state: State) -&gt; State:</span><br><span class="line">    # 如果输入字符串长度超过5个字符，我们可以选择抛出NodeInterrupt异常</span><br><span class="line">    if len(state[&#x27;input&#x27;]) &gt; 5:</span><br><span class="line">        raise NodeInterrupt(f&quot;收到长度超过5个字符的输入: &#123;state[&#x27;input&#x27;]&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    print(&quot;---Step 2---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_3(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 3---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">builder = StateGraph(State)</span><br><span class="line">builder.add_node(&quot;step_1&quot;, step_1)</span><br><span class="line">builder.add_node(&quot;step_2&quot;, step_2)</span><br><span class="line">builder.add_node(&quot;step_3&quot;, step_3)</span><br><span class="line">builder.add_edge(START, &quot;step_1&quot;)</span><br><span class="line">builder.add_edge(&quot;step_1&quot;, &quot;step_2&quot;)</span><br><span class="line">builder.add_edge(&quot;step_2&quot;, &quot;step_3&quot;)</span><br><span class="line">builder.add_edge(&quot;step_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Set up memory</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># Compile the graph with memory</span><br><span class="line">graph = builder.compile(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250721222709712.png" alt="image-20250721222709712">
<figcaption aria-hidden="true">image-20250721222709712</figcaption>
</figure>
<p>让我们运行一个输入超过5个字符的图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">initial_input = &#123;&quot;input&quot;: &quot;hello world&quot;&#125;</span><br><span class="line">thread_config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread_config, stream_mode=&quot;values&quot;):</span><br><span class="line">    print(event)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br><span class="line">---Step 1---</span><br><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以尝试从断点恢复图。但是，这只会重新运行相同的节点！除非状态发生变化，否则我们将一直卡在这里。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread_config,</span><br><span class="line">    &#123;&quot;input&quot;: &quot;hi&quot;&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>使用update_state更新状态</p>
<h4 id="time-travel-时间旅行"><strong>Time travel</strong> 时间旅行</h4>
<p>现在，让我们通过查看、重播，甚至从过去的状态叉出，来展示 LangGraph <a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/">支持debug</a>
的功能。</p>
<h5 id="browsing-history-浏览历史"><strong>Browsing History</strong>
<strong>浏览历史</strong></h5>
<p>我们可以使用 <code>get_state</code> 来查看给定 <code>thread_id</code>
的图的 当前 状态！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.get_state(&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;&#125;&#125;)</span><br></pre></td></tr></table></figure>
<p>我们还可以浏览代理的状态历史。<code>get_state_history</code>
让我们能够获取所有先前步骤的状态。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_states = [s for s in graph.get_state_history(thread)]</span><br><span class="line">len(all_states)</span><br><span class="line">print(all_states)</span><br></pre></td></tr></table></figure>
<h5 id="replaying-回放"><strong>Replaying</strong>
<strong>回放</strong></h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">to_replay = all_states[-2]</span><br><span class="line">to_replay.values</span><br><span class="line">&#123;&#x27;messages&#x27;: [HumanMessage(content=&#x27;2乘3&#x27;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#x27;0676d9b5-cd59-4630-924d-b5c8d950e8d8&#x27;)]&#125;</span><br><span class="line">to_replay.next</span><br><span class="line">(&#x27;assistant&#x27;,)</span><br></pre></td></tr></table></figure>
<p>我们还获取了配置，它告诉了我们 <code>checkpoint_id</code> 以及
<code>thread_id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">to_replay.config</span><br><span class="line">&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;,</span><br><span class="line">  &#x27;checkpoint_ns&#x27;: &#x27;&#x27;,</span><br><span class="line">  &#x27;checkpoint_id&#x27;: &#x27;1f066c0e-2ee2-66d5-8000-5dde78194aae&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>要从这里重播，我们只需将配置传回给代理！图知道这个检查点已经执行过了。它只是从这个检查点重新播放！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for event in graph.stream(None, to_replay.config, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h5 id="forking-分叉"><strong>Forking</strong> 分叉</h5>
<p>如果我们想从相同的步骤运行，但使用不同的输入，该怎么办呢？这是分叉。</p>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbb038f89f2d847ee5c336_time-travel3.png" alt="fig3.jpg">
<figcaption aria-hidden="true">fig3.jpg</figcaption>
</figure>
<p>让我们修改此检查点的状态。我们可以直接使用提供的
<code>checkpoint_id</code> 来运行 <code>update_state</code>。</p>
<p>请记住我们对 <code>messages</code> 的 reducer 是如何工作的：</p>
<ul>
<li>它会追加消息，除非我们提供了一个消息 ID。</li>
<li>我们提供消息 ID 是为了覆盖消息，而不是将消息追加到状态中！</li>
</ul>
<p>因此，要覆盖消息，我们只需提供消息 ID，而我们已有
<code>to_fork.values["messages"].id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fork_config = graph.update_state(</span><br><span class="line">    to_fork.config,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&#x27;5乘3&#x27;, </span><br><span class="line">                               id=to_fork.values[&quot;messages&quot;][0].id)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="基础知识">基础知识</h3>
<h4 id="message">message</h4>
<p>LangChain 中的 HumanMessage 、 AIMessage 、 SystemMessage 和
ToolMessage
。这些消息类型是构建与语言模型（LLM）交互的核心组件，它们共同构成了一个完整的对话历史，帮助模型理解上下文并做出恰当的回应。</p>
<ol type="1">
<li>SystemMessage</li>
</ol>
<p>SystemMessage 的结构最简单，它只包含内容和类型。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 消息的具体内容，即给 AI 的指令。</li>
<li>type (str): 固定为字符串 ‘system’ 。</li>
</ul>
<ol start="2" type="1">
<li>HumanMessage</li>
</ol>
<p>HumanMessage 的结构也同样简单，代表用户的输入。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 用户输入的文本。</li>
<li>type (str): 固定为字符串 ‘human’ 。</li>
</ul>
<ol start="3" type="1">
<li>AIMessage</li>
</ol>
<p>AIMessage
的结构相对复杂，因为它不仅可以包含文本响应，还可以包含对工具的调用请求。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): AI 生成的文本响应。如果 AI
的回复是发起工具调用，此字段可以为空字符串。</li>
<li>tool_calls (list[dict], 可选):
一个字典列表，每个字典代表一个工具调用请求。这是支持“Function
Calling”或“Tool Calling”功能的核心。其结构通常包含：
<ul>
<li>name (str): 要调用的工具名称。</li>
<li>args (dict): 调用工具时需要传入的参数。</li>
<li>id (str): 此次工具调用的唯一标识符，用于后续 ToolMessage
的关联。</li>
</ul></li>
<li>type (str): 固定为字符串 ‘ai’ 。</li>
</ul>
<ol start="4" type="1">
<li>ToolMessage</li>
</ol>
<p>ToolMessage 用于承载工具执行后的返回结果。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 工具执行返回的结果。通常是一个字符串，比如 JSON
格式的字符串。</li>
<li>tool_call_id (str): 此次工具调用的唯一标识符， 必须 与之前 AIMessage
中 tool_calls 里的 id
相对应。这使得模型能够准确地将结果与请求匹配起来。</li>
<li>type (str): 固定为字符串 ‘tool’ 。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/5/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/7/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">张熙浚</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="本站访问数 fa fa-user 次"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="本站总访问量 fa fa-eye 次"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="400" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
