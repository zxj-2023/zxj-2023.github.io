<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="zxj Blogs">
<meta property="og:type" content="website">
<meta property="og:title" content="Zhang XiJun">
<meta property="og:url" content="http://example.com/page/7/index.html">
<meta property="og:site_name" content="Zhang XiJun">
<meta property="og:description" content="zxj Blogs">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="张熙浚">
<meta property="article:tag" content="zxj">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/7/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/7/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Zhang XiJun</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhang XiJun</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">BLOGS</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="张熙浚"
      src="/images/zxjavatar.gif">
  <p class="site-author-name" itemprop="name">张熙浚</p>
  <div class="site-description" itemprop="description">zxj Blogs</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">127</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">47</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zxj-2023" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxj-2023" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=2902065320&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;2902065320&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener me" target="_blank"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zxj-2023.github.io/" title="https:&#x2F;&#x2F;zxj-2023.github.io" rel="noopener" target="_blank">Zhang XiJun</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org" rel="noopener" target="_blank">NexT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/" class="post-title-link" itemprop="url">梦龙</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-19 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-19T00:00:00+08:00">2025-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-12 18:39:00" itemprop="dateModified" datetime="2025-06-12T18:39:00+08:00">2025-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%9B%9E%E5%BF%86/" itemprop="url" rel="index"><span itemprop="name">回忆</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="梦龙演唱会"><a href="#梦龙演唱会" class="headerlink" title="梦龙演唱会"></a>梦龙演唱会</h3><p>4.6 Imagine Dragons 杭州<br>真的太嗨太嗨了，内场氛围巨好无比，所有人都在合唱，超值啊！<br>再记录一下这次比较特别的体验，在小红书找到了一个自驾去看演唱会的，五个人一辆车边走边聊边听歌，也是很不错啊</p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837710.jpg" alt="1745078837710"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837725.jpg" alt="1745078837725"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837752.jpg" alt="1745078837752"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837739.jpg" alt="1745078837739"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837778.jpg" alt="1745078837778"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/" class="post-title-link" itemprop="url">橘子海</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-19 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-19T00:00:00+08:00">2025-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-12 18:37:53" itemprop="dateModified" datetime="2025-06-12T18:37:53+08:00">2025-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%9B%9E%E5%BF%86/" itemprop="url" rel="index"><span itemprop="name">回忆</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="橘子海"><a href="#橘子海" class="headerlink" title="橘子海"></a>橘子海</h3><p>橘子海，现场超超超超级赞，嗨到爆，完全超出预期</p>
<p>Give me the faith that we broke</p>
<p>请重拾我们背叛过的誓言</p>
<p>Reminds me the verse that we spoke</p>
<p>不要让我遗忘共同诵读过的诗篇</p>
<p>There is no chance for start it over</p>
<p>一切已经永远无法重来</p>
<p>Back to the check point be my lover</p>
<p>回不去那个你我还是“我们”的存盘点</p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894738.jpg" alt="1745079894738"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894693.jpg" alt="1745079894693"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894721.jpg" alt="1745079894721"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894676.jpg" alt="1745079894676"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894659.jpg" alt="1745079894659"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894631.jpg" alt="1745079894631"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894645.jpg" alt="1745079894645"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/" class="post-title-link" itemprop="url">我想听他扫弦的声音</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-19 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-19T00:00:00+08:00">2025-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-12 18:39:42" itemprop="dateModified" datetime="2025-06-12T18:39:42+08:00">2025-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%9B%9E%E5%BF%86/" itemprop="url" rel="index"><span itemprop="name">回忆</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="我想听他扫弦的声音"><a href="#我想听他扫弦的声音" class="headerlink" title="我想听他扫弦的声音"></a>我想听他扫弦的声音</h3><p>南京1701livehouse</p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840515.jpg" alt="1745077840515"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840490.jpg" alt="1745077840490"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840469.jpg" alt="1745077840469"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840480.jpg" alt="1745077840480"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/19/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/%E5%8A%A8%E6%89%8B%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/19/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/%E5%8A%A8%E6%89%8B%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/" class="post-title-link" itemprop="url">大模型开发学习之路——动手学大模型应用开发</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-19 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-19T00:00:00+08:00">2025-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-14 15:54:59" itemprop="dateModified" datetime="2025-05-14T15:54:59+08:00">2025-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/" itemprop="url" rel="index"><span itemprop="name">大模型开发学习之路</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/%E5%8A%A8%E6%89%8B%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/" itemprop="url" rel="index"><span itemprop="name">动手学大模型应用开发</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h3><p>技术栈：streamlit，fastapi，Gradio，langchain，dify，coze</p>
<h4 id="conda常用指令"><a href="#conda常用指令" class="headerlink" title="conda常用指令"></a>conda常用指令</h4><p><strong>列出所有环境</strong>conda env list</p>
<p><strong>删除指定环境</strong>conda env remove —name 环境名称</p>
<p>创建 Conda 环境conda create -n llm-universe python==3.9.0</p>
<p>激活 Conda 环境conda activate llm-universe</p>
<p>安装依赖项pip install -r requirements.txt</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><a target="_blank" rel="noopener" href="https://www.datawhale.cn/learn/content/19/445">动手学大模型应用开发-课程详情 | Datawhale</a></p>
<p><a target="_blank" rel="noopener" href="https://datawhalechina.github.io/llm-universe/#/">动手学大模型应用开发</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1QuZAY2EW1?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">10 分钟！零基础彻底学会 Cursor AI 编程 | Cursor AI 编程｜Cursor 进阶技巧 | Cursor 开发小程序 | 小白 AI 编程_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV12TLAzuEni?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=12">【Langchain进阶篇】12.Prompt templates Few shot. Example selector(提示模板：少镜头。示例选择器)_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.langchain.com.cn/docs/concepts/">概念指南 | LangChain中文网</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/" class="post-title-link" itemprop="url">hexo常用指令</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-16 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-16T00:00:00+08:00">2025-04-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-07-29 15:28:19" itemprop="dateModified" datetime="2025-07-29T15:28:19+08:00">2025-07-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0/blog/" itemprop="url" rel="index"><span itemprop="name">blog</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>以下是 Hexo 常用的指令整理，方便快速查阅：</p>
<hr>
<h3 id="基础操作"><a href="#基础操作" class="headerlink" title="基础操作"></a><strong>基础操作</strong></h3><ol>
<li><p><strong>初始化博客</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init [文件夹名]  <span class="comment"># 创建新博客（不指定文件夹则在当前目录生成）</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>安装依赖</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install           <span class="comment"># 安装 Hexo 核心依赖（初始化后可能需要执行）</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>本地预览</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo server           <span class="comment"># 启动本地服务器（默认端口 4000），缩写：hexo s</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>生成静态文件</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo generate         <span class="comment"># 生成 public 文件夹的静态文件，缩写：hexo g</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>部署到服务器</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo deploy           <span class="comment"># 部署到 GitHub Pages 或其他平台，缩写：hexo d</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="文章与页面"><a href="#文章与页面" class="headerlink" title="文章与页面"></a><strong>文章与页面</strong></h3><ol>
<li><p><strong>新建文章</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new <span class="string">&quot;文章标题&quot;</span>    <span class="comment"># 生成新文章（Markdown 文件），缩写：hexo n</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>新建页面</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page <span class="string">&quot;页面名&quot;</span> <span class="comment"># 创建自定义页面（如 about、tags）</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="清理与调试"><a href="#清理与调试" class="headerlink" title="清理与调试"></a><strong>清理与调试</strong></h3><ol>
<li><p><strong>清理缓存</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean            <span class="comment"># 删除生成的 public 和缓存文件（修改主题后建议执行）</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>查看帮助</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo <span class="built_in">help</span>             <span class="comment"># 查看所有指令说明</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="组合指令（高效操作）"><a href="#组合指令（高效操作）" class="headerlink" title="组合指令（高效操作）"></a><strong>组合指令（高效操作）</strong></h3><ul>
<li><p><strong>生成并部署</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g -d          <span class="comment"># 先生成静态文件，再部署（等同 hexo generate &amp;&amp; hexo deploy）</span></span><br><span class="line">hexo d -g          <span class="comment"># 同上，顺序不影响结果</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>生成并预览</strong>  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s -g          <span class="comment"># 先生成文件，再启动本地服务器</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a><strong>注意事项</strong></h3><ul>
<li><strong>部署前配置</strong>：需在 <code>_config.yml</code> 中设置 <code>deploy</code> 参数（如 GitHub 仓库地址）。</li>
<li><strong>安装部署插件</strong>：首次部署需运行 <code>npm install hexo-deployer-git</code>。</li>
<li><strong>主题安装</strong>：将主题克隆到 <code>themes/</code> 文件夹后，在配置文件中指定主题名称。</li>
</ul>
<p>如果需要更详细的操作说明，可以补充具体场景（如更换主题、设置分类等）！</p>
<h3 id="hexo-d上传失败，网络连接问题解决方案"><a href="#hexo-d上传失败，网络连接问题解决方案" class="headerlink" title="hexo d上传失败，网络连接问题解决方案"></a>hexo d上传失败，网络连接问题解决方案</h3><p>原因：<strong>Clash 虽然开启了代理，但 Git 默认不会走这个代理</strong>，导致连接 GitHub 时失败</p>
<p><img src="/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/image-20250722204420664.png" alt="image-20250722204420664"></p>
<p>解决方案：</p>
<p>查看端口号</p>
<p><img src="/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/image-20250722204512612.png" alt="image-20250722204512612"></p>
<p>查看git代理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global --get http.proxy</span><br><span class="line">git config --global --get https.proxy</span><br></pre></td></tr></table></figure>
<p>更改代理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy socks5://127.0.0.1:1080</span><br><span class="line">git config --global https.proxy socks5://127.0.0.1:1080</span><br></pre></td></tr></table></figure>
<h3 id="参考教程"><a href="#参考教程" class="headerlink" title="参考教程"></a>参考教程</h3><p><a target="_blank" rel="noopener" href="https://tech.yemengstar.com/hexo-tutorial-deploy-githubpages-beginner/">HEXO系列教程 | 使用GitHub部署静态博客HEXO | 小白向教程 – 夜梦星尘の折腾日记</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV12H4y1N7Q4/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Github王炸功能Pages,免费免服务器上线网站,详细教程_哔哩哔哩_bilibili</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" class="post-title-link" itemprop="url">机器学习——支持向量机</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-16 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-16T00:00:00+08:00">2025-04-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-12 19:00:01" itemprop="dateModified" datetime="2025-06-12T19:00:01+08:00">2025-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>下面我将为你详细解释KKT（Karush-Kuhn-Tucker）条件。KKT条件是优化理论中用于求解带约束非线性规划问题的一组必要条件，广泛应用于支持向量机（SVM）等机器学习算法中。我会使用内联数学公式（如 <script type="math/tex">f(\mathbf{x})</script>）来展示相关表达式。</p>
<hr>
<h3 id="1-优化问题的一般形式"><a href="#1-优化问题的一般形式" class="headerlink" title="1. 优化问题的一般形式"></a>1. 优化问题的一般形式</h3><p>我们考虑一个带有约束的优化问题，数学形式如下：</p>
<ul>
<li>目标：<script type="math/tex">\min_{\mathbf{x}} f(\mathbf{x})</script></li>
<li>不等式约束：<script type="math/tex">g_i(\mathbf{x}) \leq 0</script>，其中 <script type="math/tex">i = 1, 2, \dots, m</script></li>
<li>等式约束：<script type="math/tex">h_j(\mathbf{x}) = 0</script>，其中 <script type="math/tex">j = 1, 2, \dots, p</script></li>
</ul>
<p>这里：</p>
<ul>
<li><script type="math/tex">f(\mathbf{x})</script> 是目标函数，通常是我们希望最小化的函数。</li>
<li><script type="math/tex">g_i(\mathbf{x}) \leq 0</script> 表示 <script type="math/tex">m</script> 个不等式约束。</li>
<li><script type="math/tex">h_j(\mathbf{x}) = 0</script> 表示 <script type="math/tex">p</script> 个等式约束。</li>
</ul>
<p>KKT条件的目标是找到满足这些约束的局部最优解 <script type="math/tex">\mathbf{x}</script>。</p>
<hr>
<h3 id="2-拉格朗日函数"><a href="#2-拉格朗日函数" class="headerlink" title="2. 拉格朗日函数"></a>2. 拉格朗日函数</h3><p>为了引入KKT条件，我们首先定义拉格朗日函数：</p>
<script type="math/tex; mode=display">\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = f(\mathbf{x}) + \sum_{i=1}^{m} \lambda_i g_i(\mathbf{x}) + \sum_{j=1}^{p} \mu_j h_j(\mathbf{x})</script><p>其中：</p>
<ul>
<li><script type="math/tex">\boldsymbol{\lambda} = (\lambda_1, \lambda_2, \dots, \lambda_m)</script> 是与不等式约束 <script type="math/tex">g_i(\mathbf{x}) \leq 0</script> 对应的拉格朗日乘子。</li>
<li><script type="math/tex">\boldsymbol{\mu} = (\mu_1, \mu_2, \dots, \mu_p)</script> 是与等式约束 <script type="math/tex">h_j(\mathbf{x}) = 0</script> 对应的拉格朗日乘子。</li>
</ul>
<p>拉格朗日函数将目标函数和约束条件结合在一起，通过引入乘子 <script type="math/tex">\lambda_i</script> 和 <script type="math/tex">\mu_j</script> 来平衡约束对优化的影响。</p>
<hr>
<h3 id="3-KKT条件的组成部分"><a href="#3-KKT条件的组成部分" class="headerlink" title="3. KKT条件的组成部分"></a>3. KKT条件的组成部分</h3><p>KKT条件由以下四个部分组成，只有当某些正则性条件（如Slater条件）满足时，局部最优解 <script type="math/tex">\mathbf{x}</script> 才会同时满足这些条件。以下是具体的KKT条件：</p>
<h4 id="3-1-梯度条件（Stationarity）"><a href="#3-1-梯度条件（Stationarity）" class="headerlink" title="3.1 梯度条件（Stationarity）"></a>3.1 梯度条件（Stationarity）</h4><p>拉格朗日函数对 <script type="math/tex">\mathbf{x}</script> 的梯度必须为零，即：</p>
<script type="math/tex; mode=display">\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = \nabla f(\mathbf{x}) + \sum_{i=1}^{m} \lambda_i \nabla g_i(\mathbf{x}) + \sum_{j=1}^{p} \mu_j \nabla h_j(\mathbf{x}) = 0</script><p>这意味着在最优解处，目标函数的梯度可以通过约束函数梯度的线性组合来表示。</p>
<h4 id="3-2-原始可行性（Primal-Feasibility）"><a href="#3-2-原始可行性（Primal-Feasibility）" class="headerlink" title="3.2 原始可行性（Primal Feasibility）"></a>3.2 原始可行性（Primal Feasibility）</h4><p>解 <script type="math/tex">\mathbf{x}</script> 必须满足原始问题的所有约束：</p>
<ul>
<li>不等式约束：<script type="math/tex">g_i(\mathbf{x}) \leq 0</script>，其中 <script type="math/tex">i = 1, 2, \dots, m</script></li>
<li>等式约束：<script type="math/tex">h_j(\mathbf{x}) = 0</script>，其中 <script type="math/tex">j = 1, 2, \dots, p</script></li>
</ul>
<p>这确保了解仍在问题的可行域内。</p>
<h4 id="3-3-对偶可行性（Dual-Feasibility）"><a href="#3-3-对偶可行性（Dual-Feasibility）" class="headerlink" title="3.3 对偶可行性（Dual Feasibility）"></a>3.3 对偶可行性（Dual Feasibility）</h4><p>对于不等式约束对应的拉格朗日乘子，必须满足：</p>
<script type="math/tex; mode=display">\lambda_i \geq 0$$，其中 $$i = 1, 2, \dots, m</script><p>这表明不等式约束的乘子非负，反映了约束对优化方向的影响。</p>
<h4 id="3-4-互补松弛条件（Complementary-Slackness）"><a href="#3-4-互补松弛条件（Complementary-Slackness）" class="headerlink" title="3.4 互补松弛条件（Complementary Slackness）"></a>3.4 互补松弛条件（Complementary Slackness）</h4><p>对于每个不等式约束，乘子与约束函数的乘积必须为零：</p>
<script type="math/tex; mode=display">\lambda_i g_i(\mathbf{x}) = 0$$，其中 $$i = 1, 2, \dots, m</script><p>这意味着：</p>
<ul>
<li>如果某个约束不“紧”（即 <script type="math/tex">g_i(\mathbf{x}) < 0</script>），则对应的乘子 <script type="math/tex">\lambda_i = 0</script>。</li>
<li>如果 <script type="math/tex">\lambda_i > 0</script>，则该约束必须是“紧”的（即 <script type="math/tex">g_i(\mathbf{x}) = 0</script>）。</li>
</ul>
<hr>
<h3 id="4-KKT条件的意义"><a href="#4-KKT条件的意义" class="headerlink" title="4. KKT条件的意义"></a>4. KKT条件的意义</h3><ul>
<li><strong>梯度条件</strong>：表明最优解处目标函数的改变方向被约束完全平衡。</li>
<li><strong>原始可行性</strong>：确保解满足所有约束条件。</li>
<li><strong>对偶可行性</strong>：限制拉格朗日乘子的符号，保证优化方向的合理性。</li>
<li><strong>互补松弛条件</strong>：揭示哪些约束在最优解处起作用（紧约束），哪些不起作用。</li>
</ul>
<hr>
<h3 id="5-KKT条件在SVM中的应用示例"><a href="#5-KKT条件在SVM中的应用示例" class="headerlink" title="5. KKT条件在SVM中的应用示例"></a>5. KKT条件在SVM中的应用示例</h3><p>KKT条件在支持向量机（SVM）中尤为重要。SVM的原始优化问题为：</p>
<ul>
<li>目标：<script type="math/tex">\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2</script></li>
<li>约束：<script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1</script>，其中 <script type="math/tex">i = 1, 2, \dots, n</script></li>
</ul>
<p>将其改写为标准形式的不等式约束：<script type="math/tex">1 - y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \leq 0</script>。</p>
<p>拉格朗日函数为：</p>
<script type="math/tex; mode=display">\mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha}) = \frac{1}{2} \|\mathbf{w}\|^2 + \sum_{i=1}^{n} \alpha_i \left[ 1 - y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \right]</script><p>应用KKT条件：</p>
<ol>
<li><strong>梯度条件</strong>：<ul>
<li>对 <script type="math/tex">\mathbf{w}</script>：<script type="math/tex">\nabla_{\mathbf{w}} \mathcal{L} = \mathbf{w} - \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i = 0</script></li>
<li>对 <script type="math/tex">b</script>：<script type="math/tex">\frac{\partial \mathcal{L}}{\partial b} = -\sum_{i=1}^{n} \alpha_i y_i = 0</script></li>
</ul>
</li>
<li><strong>原始可行性</strong>：<script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1</script></li>
<li><strong>对偶可行性</strong>：<script type="math/tex">\alpha_i \geq 0</script></li>
<li><strong>互补松弛条件</strong>：<script type="math/tex">\alpha_i \left[ y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 \right] = 0</script></li>
</ol>
<p>这些条件帮助我们识别支持向量（<script type="math/tex">\alpha_i > 0</script> 的点）并求解最优的 <script type="math/tex">\mathbf{w}</script> 和 <script type="math/tex">b</script>。</p>
<hr>
<h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h3><p>KKT条件是求解带约束优化问题的核心工具，它通过梯度条件、原始可行性、对偶可行性和互补松弛条件，确保了解既是最优的，又满足所有约束。在机器学习中，KKT条件为SVM等算法提供了理论支持，是理解和实现这些模型的关键。</p>
<h3 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h3><h4 id="关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）"><a href="#关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）" class="headerlink" title="关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）"></a>关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）</h4><p><img src="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/IMG_20250416_164811.jpg" alt="IMG_20250416_164811"></p>
<p>下面我们将推导支持向量机（SVM）中目标函数从原始问题转换为对偶问题的过程和条件，使用拉格朗日乘子法。我们将一步步展开，确保推导清晰且完整。</p>
<hr>
<h3 id="1-原始问题"><a href="#1-原始问题" class="headerlink" title="1. 原始问题"></a>1. 原始问题</h3><p>支持向量机（SVM）的目标是找到一个超平面，能够最大化到最近数据点的间隔。对于线性可分的情况，原始优化问题可以定义为：</p>
<ul>
<li><p><strong>目标函数</strong>：  </p>
<script type="math/tex; mode=display">\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2</script></li>
<li><p><strong>约束条件</strong>：  </p>
<script type="math/tex; mode=display">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1, \quad i = 1, 2, \dots, n</script></li>
</ul>
<p>其中：</p>
<ul>
<li><script type="math/tex">\mathbf{w}</script> 是超平面的法向量；</li>
<li><script type="math/tex">b</script> 是超平面的截距；</li>
<li><script type="math/tex">\mathbf{x}_i</script> 是训练样本，<script type="math/tex">y_i \in \{-1, 1\}</script> 是对应的类别标签；</li>
<li><script type="math/tex">\|\mathbf{w}\|^2</script> 表示法向量的平方范数，目标是最小化它以最大化间隔；</li>
<li>约束条件确保所有样本点被正确分类，并且到超平面的归一化距离至少为 1。</li>
</ul>
<hr>
<h3 id="2-引入拉格朗日乘子法"><a href="#2-引入拉格朗日乘子法" class="headerlink" title="2. 引入拉格朗日乘子法"></a>2. 引入拉格朗日乘子法</h3><p>由于这是一个带不等式约束的优化问题，我们使用拉格朗日乘子法将其转换为无约束形式。引入拉格朗日乘子 <script type="math/tex">\boldsymbol{\alpha} = (\alpha_1, \alpha_2, \dots, \alpha_n)</script>，其中 <script type="math/tex">\alpha_i \geq 0</script>，构造拉格朗日函数：</p>
<script type="math/tex; mode=display">\mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha}) = \frac{1}{2} \|\mathbf{w}\|^2 - \sum_{i=1}^{n} \alpha_i \left[ y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 \right]</script><ul>
<li>第一项 <script type="math/tex">\frac{1}{2} \|\mathbf{w}\|^2</script> 是原始目标函数；</li>
<li>第二项 <script type="math/tex">-\sum_{i=1}^{n} \alpha_i \left[ y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 \right]</script> 将约束条件引入，由于是 <script type="math/tex">\geq</script> 不等式，乘子 <script type="math/tex">\alpha_i \geq 0</script>。</li>
</ul>
<p>我们的目标是通过拉格朗日函数，将原始问题转换为对偶问题。</p>
<hr>
<h3 id="3-转换为对偶问题"><a href="#3-转换为对偶问题" class="headerlink" title="3. 转换为对偶问题"></a>3. 转换为对偶问题</h3><p>对偶问题的核心思想是：先对 <script type="math/tex">\mathbf{w}</script> 和 <script type="math/tex">b</script> 求拉格朗日函数的极小值，然后对 <script type="math/tex">\boldsymbol{\alpha}</script> 求极大值。即：</p>
<script type="math/tex; mode=display">\max_{\boldsymbol{\alpha} \geq 0} \min_{\mathbf{w}, b} \mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha})</script><h4 id="3-1-对-mathbf-w-和-b-求偏导"><a href="#3-1-对-mathbf-w-和-b-求偏导" class="headerlink" title="3.1 对 \mathbf{w} 和 b 求偏导"></a>3.1 对 <script type="math/tex">\mathbf{w}</script> 和 <script type="math/tex">b</script> 求偏导</h4><p>为了找到 <script type="math/tex">\mathcal{L}</script> 关于 <script type="math/tex">\mathbf{w}</script> 和 <script type="math/tex">b</script> 的极小值，分别求偏导并令其为零：</p>
<ul>
<li><p>对 <script type="math/tex">\mathbf{w}</script> 求偏导：  </p>
<script type="math/tex; mode=display">\frac{\partial \mathcal{L}}{\partial \mathbf{w}} = \mathbf{w} - \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i = 0</script><p>解得：  </p>
<script type="math/tex; mode=display">\mathbf{w} = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i</script></li>
<li><p>对 <script type="math/tex">b</script> 求偏导：  </p>
<script type="math/tex; mode=display">\frac{\partial \mathcal{L}}{\partial b} = -\sum_{i=1}^{n} \alpha_i y_i = 0</script><p>解得：  </p>
<script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i = 0</script></li>
</ul>
<p>这两个结果是后续推导的关键。</p>
<h4 id="3-2-代入拉格朗日函数"><a href="#3-2-代入拉格朗日函数" class="headerlink" title="3.2 代入拉格朗日函数"></a>3.2 代入拉格朗日函数</h4><p>将 <script type="math/tex">\mathbf{w} = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i</script> 代入拉格朗日函数，并利用 <script type="math/tex">\sum_{i=1}^{n} \alpha_i y_i = 0</script> 简化：</p>
<script type="math/tex; mode=display">\mathcal{L} = \frac{1}{2} \left\| \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \right\|^2 - \sum_{i=1}^{n} \alpha_i \left[ y_i \left( \left( \sum_{j=1}^{n} \alpha_j y_j \mathbf{x}_j \right) \cdot \mathbf{x}_i + b \right) - 1 \right]</script><ul>
<li><p>计算第一项：  </p>
<script type="math/tex; mode=display">\left\| \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \right\|^2 = \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)</script></li>
<li><p>计算第二项中的内积部分：  </p>
<script type="math/tex; mode=display">y_i \left( \sum_{j=1}^{n} \alpha_j y_j \mathbf{x}_j \right) \cdot \mathbf{x}_i = y_i \sum_{j=1}^{n} \alpha_j y_j (\mathbf{x}_j \cdot \mathbf{x}_i)</script><p>所以：  </p>
<script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i \left( \sum_{j=1}^{n} \alpha_j y_j (\mathbf{x}_j \cdot \mathbf{x}_i) \right) = \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)</script></li>
<li><p>考虑 <script type="math/tex">b</script> 项：  </p>
<script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i b = b \sum_{i=1}^{n} \alpha_i y_i = 0 \quad (\text{因为} \sum_{i=1}^{n} \alpha_i y_i = 0)</script></li>
</ul>
<p>代入后，拉格朗日函数变为：  </p>
<script type="math/tex; mode=display">\mathcal{L} = \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) - \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) + \sum_{i=1}^{n} \alpha_i</script><p>化简：  </p>
<script type="math/tex; mode=display">\mathcal{L} = -\frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) + \sum_{i=1}^{n} \alpha_i</script><h4 id="3-3-对偶优化问题"><a href="#3-3-对偶优化问题" class="headerlink" title="3.3 对偶优化问题"></a>3.3 对偶优化问题</h4><p>于是，对偶问题是：  </p>
<script type="math/tex; mode=display">\max_{\boldsymbol{\alpha}} \left[ \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) \right]</script><ul>
<li><strong>约束条件</strong>：  <script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i = 0</script><script type="math/tex; mode=display">\alpha_i \geq 0, \quad i = 1, 2, \dots, n</script></li>
</ul>
<p>为了与标准优化形式一致，常将其写为最小化问题：  </p>
<script type="math/tex; mode=display">\min_{\boldsymbol{\alpha}} \left[ \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) - \sum_{i=1}^{n} \alpha_i \right]</script><ul>
<li><strong>约束条件不变</strong>：  <script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i = 0</script><script type="math/tex; mode=display">\alpha_i \geq 0</script></li>
</ul>
<hr>
<h3 id="4-转换的条件"><a href="#4-转换的条件" class="headerlink" title="4. 转换的条件"></a>4. 转换的条件</h3><p>原始问题与对偶问题之间的关系由<strong>强对偶性</strong>保证。在SVM中：</p>
<ul>
<li>目标函数 <script type="math/tex">\frac{1}{2} \|\mathbf{w}\|^2</script> 是凸函数（二次函数）；</li>
<li>约束条件 <script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1</script> 是线性不等式；</li>
<li>对于线性可分数据，Slater条件满足（存在可行解使约束严格成立）。</li>
</ul>
<p>因此，强对偶性成立，原始问题的最优解可以通过对偶问题求解得到。</p>
<p>此外：</p>
<ul>
<li>最优的 <script type="math/tex">\boldsymbol{\alpha}</script> 通过对偶问题求解；</li>
<li><script type="math/tex">\mathbf{w} = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i</script>；</li>
<li>对于支持向量（<script type="math/tex">\alpha_i > 0</script> 的样本），<script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) = 1</script>，可据此解出 <script type="math/tex">b</script>。</li>
</ul>
<hr>
<h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h3><ul>
<li><p><strong>原始问题</strong>：  </p>
<script type="math/tex; mode=display">\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2</script><p>受约束：<script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1</script></p>
</li>
<li><p><strong>对偶问题</strong>：  </p>
<script type="math/tex; mode=display">\max_{\boldsymbol{\alpha}} \left[ \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) \right]</script><p>受约束：<script type="math/tex">\sum_{i=1}^{n} \alpha_i y_i = 0</script>，<script type="math/tex">\alpha_i \geq 0</script></p>
</li>
<li><p><strong>转换条件</strong>：<br>通过拉格朗日乘子法，基于凸优化和强对偶性完成转换。对偶形式不仅便于求解，还为引入核函数奠定了基础。</p>
</li>
</ul>
<p>以上就是SVM目标函数从原始问题到对偶问题的推导过程和条件。</p>
<h4 id="2-已知训练数据集中正例点x1-2-3-，x2-3-3-，x3-3-2-，负例点x4-1-2-，-x5-2-1-，x6-3-1-，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。"><a href="#2-已知训练数据集中正例点x1-2-3-，x2-3-3-，x3-3-2-，负例点x4-1-2-，-x5-2-1-，x6-3-1-，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。" class="headerlink" title="2.已知训练数据集中正例点x1=(2,3)，x2=(3,3)，x3=(3,2)，负例点x4=(1,2)，    x5=(2,1)，x6=(3,1)，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。"></a>2.已知训练数据集中正例点x1=(2,3)，x2=(3,3)，x3=(3,2)，负例点x4=(1,2)，    x5=(2,1)，x6=(3,1)，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。</h4><p><img src="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/IMG_20250416_164804-1744793466526-4.jpg" alt="IMG_20250416_164804"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/" class="post-title-link" itemprop="url">计算机系统基础——知识点</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-16 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-16T00:00:00+08:00">2025-04-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-11 10:26:19" itemprop="dateModified" datetime="2025-06-11T10:26:19+08:00">2025-06-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">计算机系统基础</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h2><p>在这张图片中，表格列出了 <code>x</code> 和 <code>y</code> 的十六进制值，并且要求用 C 语言中的位运算符对它们进行操作。接下来，我将对每个表达式进行详细的计算和解释。</p>
<p>在表格中，要求使用 C 语言中的不同位运算符来计算 <code>x</code> 和 <code>y</code> 之间的结果。位运算符包括：</p>
<ol>
<li><code>&amp;</code>（位与）</li>
<li><code>|</code>（位或）</li>
<li><code>^</code>（位异或）</li>
<li><code>~</code>（位取反）</li>
<li><code>&lt;&lt;</code>（左移）</li>
<li><code>&gt;&gt;</code>（右移）</li>
<li><code>!</code>（逻辑非）</li>
</ol>
<h3 id="计算步骤："><a href="#计算步骤：" class="headerlink" title="计算步骤："></a>计算步骤：</h3><ol>
<li><strong>位与运算 <code>x &amp; y</code></strong>： 位与运算会比较 <code>x</code> 和 <code>y</code> 的每一位，只有当对应位都为 1 时，结果才为 1，否则为 0。</li>
<li><strong>位或运算 <code>x | y</code></strong>： 位或运算会比较 <code>x</code> 和 <code>y</code> 的每一位，只要对应位有一个为 1，结果就为 1。</li>
<li><strong>位异或运算 <code>x ^ y</code></strong>： 位异或运算会比较 <code>x</code> 和 <code>y</code> 的每一位，当两者相同时，结果为 0；当两者不同时，结果为 1。</li>
<li><strong>位取反运算 <code>~x</code> 和 <code>~y</code></strong>： 位取反运算会将 <code>x</code> 或 <code>y</code> 的每一位都反转，0 变 1，1 变 0。</li>
<li><strong>左移运算 <code>x &lt;&lt; y</code></strong>： 左移运算会将 <code>x</code> 的二进制位向左移动 <code>y</code> 位，并在右边补 0。</li>
<li><strong>右移运算 <code>x &gt;&gt; y</code></strong>： 右移运算会将 <code>x</code> 的二进制位向右移动 <code>y</code> 位，符号位（对于负数来说是 1）保持不变。</li>
<li><strong>逻辑非运算 <code>!x</code></strong>： 逻辑非运算对 <code>x</code> 进行布尔值判断，如果 <code>x</code> 为 0，则结果为 1，否则为 0。</li>
</ol>
<h2 id="十六进制（Hexadecimal-H）和二进制（Binary-b）之间的直接关系"><a href="#十六进制（Hexadecimal-H）和二进制（Binary-b）之间的直接关系" class="headerlink" title="十六进制（Hexadecimal, H）和二进制（Binary, b）之间的直接关系"></a>十六进制（Hexadecimal, H）和二进制（Binary, b）之间的直接关系</h2><p><strong>核心原理:</strong> 每一个十六进制数字正好对应 4 个二进制位。这是因为 16=24。</p>
<p>我们可以将十六进制数 <code>8080 108B</code> H 中的每一位数字，分别转换为它对应的4位二进制数：</p>
<ol>
<li><strong><code>8</code></strong> H = <strong><code>1000</code></strong> b</li>
<li><strong><code>0</code></strong> H = <strong><code>0000</code></strong> b</li>
<li><strong><code>8</code></strong> H = <strong><code>1000</code></strong> b</li>
<li><strong><code>0</code></strong> H = <strong><code>0000</code></strong> b</li>
<li><strong><code>1</code></strong> H = <strong><code>0001</code></strong> b</li>
<li><strong><code>0</code></strong> H = <strong><code>0000</code></strong> b</li>
<li><strong><code>8</code></strong> H = <strong><code>1000</code></strong> b</li>
<li><strong><code>B</code></strong> H (B 代表十进制的 11) = <strong><code>1011</code></strong> b</li>
</ol>
<p><strong>组合:</strong> 现在，按照原始十六进制数的顺序，把这些4位的二进制数组合起来：</p>
<p><code>1000</code> (来自<code>8</code>) + <code>0000</code> (来自<code>0</code>) + <code>1000</code> (来自<code>8</code>) + <code>0000</code> (来自<code>0</code>) + <code>0001</code> (来自<code>1</code>) + <code>0000</code> (来自<code>0</code>) + <code>1000</code> (来自<code>8</code>) + <code>1011</code> (来自<code>B</code>)</p>
<p>结果: 将它们连接在一起就得到：</p>
<p>1000 0000 1000 0000 0001 0000 1000 1011 b</p>
<p><strong>所以，<code>8080 108B</code> H 等于 <code>1000 0000 1000 0000 0001 0000 1000 1011</code> b 是因为每个十六进制位都可以独立地、直接地转换为一个4位的二进制表示，然后按顺序拼接起来。</strong></p>
<h2 id="指令决定了如何解释寄存器中的二进制位串"><a href="#指令决定了如何解释寄存器中的二进制位串" class="headerlink" title="指令决定了如何解释寄存器中的二进制位串"></a>指令决定了如何解释寄存器中的二进制位串</h2><p>好的，我们来详细解释一下为什么在不同的指令下，寄存器 R1 和 R2 的内容 <code>0000 108B</code> H 和 <code>8080 108B</code> H 会对应不同的真值。核心原因在于，<strong>指令决定了如何解释寄存器中的二进制位串</strong>。</p>
<p><strong>（1）无符号数加法指令 (Unsigned Addition)</strong></p>
<ul>
<li><strong>解释规则:</strong> 当执行无符号数指令时，计算机会将寄存器中的 <strong>所有32位</strong> 都视为表示数值大小（magnitude）的部分，没有单独的符号位。数值就是这个32位二进制数直接转换成的十进制（或十六进制）值。</li>
</ul>
<p><strong>（2）带符号整数乘法指令 (Signed Integer Multiplication)</strong></p>
<ul>
<li><p>解释规则:</p>
<p> 当执行带符号整数指令时，计算机会使用</p>
<p>补码 (Two’s Complement)</p>
<p> 来表示整数。</p>
<ul>
<li><strong>最高位 (MSB, Most Significant Bit)</strong> 是符号位：<code>0</code> 代表正数或零，<code>1</code> 代表负数。</li>
<li><strong>正数:</strong> 其补码、原码、反码相同，数值就是除去符号位后的二进制值。</li>
<li><strong>负数:</strong> 其真值需要通过补码转换回原码来确定其绝对值。转换方法是：<strong>对补码再次求补（符号位不变，数值位按位取反，末位加1；或者全部位按位取反，末位加1）得到原码的绝对值</strong>。</li>
</ul>
</li>
</ul>
<p><strong>（3）单精度浮点数减法指令 (Single-Precision Floating-Point Subtraction)</strong></p>
<ul>
<li><p>解释规则:</p>
<p> 当执行浮点数指令时，计算机会按照 </p>
<p>IEEE 754 单精度 (32位)</p>
<p> 标准来解释寄存器中的位。格式如下：</p>
<ul>
<li><strong>符号位 (Sign, S):</strong> 1位 (第31位)。<code>0</code> 为正，<code>1</code> 为负。</li>
<li><strong>阶码 (Exponent, E):</strong> 8位 (第30-23位)。存储的是 <code>e + bias</code>，其中 <code>e</code> 是实际指数，<code>bias</code> (偏移量) 对于单精度是 <strong>127</strong>。</li>
<li><strong>尾数 (Mantissa/Fraction, F):</strong> 23位 (第22-0位)。表示小数部分。对于规格化数，实际尾数是 <code>1.F</code>（有一个隐藏的1）。</li>
<li><strong>数值公式 (规格化):</strong> Value=(−1)S×(1.F)2×2(E−127)</li>
<li><strong>特殊情况:</strong> 需要注意 E=0 (表示0或非规格化数) 和 E=255 (表示无穷大或NaN)。</li>
</ul>
</li>
</ul>
<h2 id="补码的基本规则"><a href="#补码的基本规则" class="headerlink" title="补码的基本规则"></a>补码的基本规则</h2><p>在开始计算之前，我们先了解补码的基本规则：</p>
<ol>
<li><p><strong>符号位</strong>：</p>
<ul>
<li>补码的最高位（最左边的位）是符号位。</li>
<li>符号位为 <strong>0</strong> 表示正数或零，符号位为 <strong>1</strong> 表示负数。</li>
</ul>
</li>
<li><p><strong>正数的补码</strong>：</p>
<ul>
<li>如果符号位是 0，补码与原码相同，直接按照二进制数值解释即可。</li>
</ul>
</li>
<li><p><strong>负数的补码</strong>：</p>
<ul>
<li>如果符号位是 1，表示负数。要得到原码（即实际的数值），需要对数值部分取反（0 变 1，1 变 0），然后加 1。</li>
<li>最后在结果前加上负号。</li>
</ul>
</li>
<li><p><strong>小数部分的处理</strong>：</p>
<ul>
<li>如果补码表示包含小数点，符号位在小数点左边，数值部分在小数点右边，按照二进制小数计算。</li>
</ul>
</li>
</ol>
<h2 id="是的，在-C-语言中，0U-后面的-U-确实表示无符号的意思。具体来说："><a href="#是的，在-C-语言中，0U-后面的-U-确实表示无符号的意思。具体来说：" class="headerlink" title="是的，在 C 语言中，0U 后面的 U 确实表示无符号的意思。具体来说："></a>是的，在 C 语言中，<code>0U</code> 后面的 <code>U</code> 确实表示无符号的意思。具体来说：</h2><ul>
<li><strong><code>0</code> 本身</strong>：这是一个整数常量，默认情况下是有符号整数类型（<code>signed int</code>）。</li>
<li><strong><code>0U</code> 的含义</strong>：当在 <code>0</code> 后面加上 <code>U</code> 后缀时，它就变成了一个无符号整数常量（<code>unsigned int</code>）。<code>U</code> 后缀明确指定了这个数字是无符号类型。</li>
</ul>
<h3 id="C-语言中整数常量的后缀规则"><a href="#C-语言中整数常量的后缀规则" class="headerlink" title="C 语言中整数常量的后缀规则"></a>C 语言中整数常量的后缀规则</h3><p>在 C 语言中，可以通过后缀来指定整数常量的类型：</p>
<ul>
<li><strong>无后缀</strong>：表示默认的有符号整数（<code>int</code>）。</li>
<li><strong><code>U</code> 或 <code>u</code></strong>：表示无符号整数（<code>unsigned int</code>）。</li>
<li><strong><code>L</code> 或 <code>l</code></strong>：表示长整型（<code>long int</code>）。</li>
<li><strong><code>UL</code> 或 <code>ul</code></strong>：表示无符号长整型（<code>unsigned long int</code>）。</li>
</ul>
<h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><ul>
<li><code>0</code>：有符号整数，值是 0。</li>
<li><code>0U</code>：无符号整数，值仍然是 0，但它的类型是 <code>unsigned int</code>。</li>
</ul>
<h3 id="为什么这很重要？"><a href="#为什么这很重要？" class="headerlink" title="为什么这很重要？"></a>为什么这很重要？</h3><p>无符号类型和有符号类型的区别在某些情况下会影响程序的行为，比如比较运算：</p>
<ul>
<li>如果比较两个无符号整数，或者两个有符号整数，直接按数值比较即可。</li>
<li>如果一个是有符号整数，另一个是无符号整数，C 语言会将有符号整数转换为无符号整数后再比较。这可能导致意外结果，例如负数在转换为无符号整数时变成一个很大的正数。</li>
</ul>
<p>总之，<code>U</code> 后缀的作用就是告诉编译器，这个整数常量是无符号的。所以你的理解是对的，后面带 <code>U</code> 就是无符号的意思！</p>
<h2 id="让我们来分析这个问题：为什么在表达式-unsigned-1-gt-2-中，-1-被转换为无符号整数，而-2-也被按无符号数处理。"><a href="#让我们来分析这个问题：为什么在表达式-unsigned-1-gt-2-中，-1-被转换为无符号整数，而-2-也被按无符号数处理。" class="headerlink" title="让我们来分析这个问题：为什么在表达式 (unsigned) -1 &gt; -2 中，-1 被转换为无符号整数，而 -2 也被按无符号数处理。"></a>让我们来分析这个问题：为什么在表达式 <code>(unsigned) -1 &gt; -2</code> 中，<code>-1</code> 被转换为无符号整数，而 <code>-2</code> 也被按无符号数处理。</h2><h3 id="1-表达式-unsigned-1-的含义"><a href="#1-表达式-unsigned-1-的含义" class="headerlink" title="1. 表达式 (unsigned) -1 的含义"></a>1. 表达式 <code>(unsigned) -1</code> 的含义</h3><ul>
<li><strong>(unsigned)</strong> 是一个强制类型转换，表示将后面的值 <code>-1</code> 从有符号整数（<code>int</code>）转换为无符号整数（<code>unsigned int</code>）。</li>
<li>在计算机中，整数通常以补码形式存储。以 32 位为例：<ul>
<li>有符号整数 <code>-1</code> 的补码是 <code>1111...1111</code>（32 位全 1）。</li>
<li>当将其强制转换为无符号整数时，这串二进制位被重新解释为一个正数。</li>
<li><code>1111...1111</code> 作为无符号整数的值是 (2^{32} - 1 = 4294967295)。</li>
</ul>
</li>
<li>所以，<code>(unsigned) -1</code> 的结果是 <code>4294967295</code>。</li>
</ul>
<h3 id="2-比较中的-2-为什么按无符号数处理"><a href="#2-比较中的-2-为什么按无符号数处理" class="headerlink" title="2. 比较中的 -2 为什么按无符号数处理"></a>2. 比较中的 <code>-2</code> 为什么按无符号数处理</h3><ul>
<li>在表达式 <code>(unsigned) -1 &gt; -2</code> 中，<code>-2</code> 默认是一个有符号整数（<code>int</code>），其补码表示为 <code>1111...1110</code>（32 位中最后一位是 0）。</li>
<li>当一个无符号整数（<code>(unsigned) -1</code>）与一个有符号整数（<code>-2</code>）进行比较时，C 语言会执行<strong>隐式类型转换</strong>，以确保两个操作数的类型一致。</li>
<li>根据 C 语言的规则：<ul>
<li>如果一个操作数是无符号整数，另一个是有符号整数，有符号整数会被转换为无符号整数。</li>
</ul>
</li>
<li>因此，<code>-2</code> 会被隐式转换为无符号整数：<ul>
<li><code>1111...1110</code> 作为无符号整数的值是 (2^{32} - 2 = 4294967294)。</li>
</ul>
</li>
</ul>
<h3 id="3-比较的过程"><a href="#3-比较的过程" class="headerlink" title="3. 比较的过程"></a>3. 比较的过程</h3><ul>
<li>现在，表达式 <code>(unsigned) -1 &gt; -2</code> 变成了：<ul>
<li><code>(unsigned) -1 = 4294967295</code>（无符号整数）。</li>
<li><code>-2</code> 被转换为 <code>4294967294</code>（无符号整数）。</li>
</ul>
</li>
<li>比较 <code>4294967295 &gt; 4294967294</code>，显然成立，结果为真（<code>1</code>）。</li>
</ul>
<h3 id="4-为什么-2-被按无符号数处理"><a href="#4-为什么-2-被按无符号数处理" class="headerlink" title="4. 为什么 -2 被按无符号数处理"></a>4. 为什么 <code>-2</code> 被按无符号数处理</h3><ul>
<li><code>-2</code> 被按无符号数处理的原因在于 C 语言的<strong>类型转换规则</strong>：<ul>
<li>当有符号整数与无符号整数进行运算或比较时，有符号整数会被自动转换为无符号整数。</li>
<li>这种转换基于补码的二进制表示，直接将补码重新解释为无符号值，而不改变位模式。</li>
</ul>
</li>
<li>在这个例子中：<ul>
<li><code>(unsigned) -1</code> 强制指定了无符号类型。</li>
<li><code>-2</code> 由于与无符号数比较，被隐式转换成了无符号数。</li>
</ul>
</li>
</ul>
<h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h3><ul>
<li><strong>(unsigned) -1</strong> 将 <code>-1</code> 显式转换为无符号整数，结果是 <code>4294967295</code>。</li>
<li><strong>-2</strong> 在比较中被隐式转换为无符号整数，结果是 <code>4294967294</code>。</li>
<li>这种行为是 C 语言类型转换规则的结果：为了保证比较时类型一致，<code>-2</code> 被按无符号数处理。</li>
</ul>
<p>这种机制虽然确保了类型一致性，但在处理负数时可能导致意外结果，因此在使用无符号类型时需要特别注意。希望这个解释清晰地回答了你的问题！</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/" class="post-title-link" itemprop="url">机器学习——上机实验11--核化分类器判定西瓜好坏</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-15 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-15T00:00:00+08:00">2025-04-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-12 19:02:01" itemprop="dateModified" datetime="2025-06-12T19:02:01+08:00">2025-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="上机实验11：核化分类器判定西瓜好坏"><a href="#上机实验11：核化分类器判定西瓜好坏" class="headerlink" title="上机实验11：核化分类器判定西瓜好坏"></a>上机实验11：核化分类器判定西瓜好坏</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&quot;work/西瓜数据集3.0α.txt&quot;</span>)</span><br><span class="line">data</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">yes = data[data[<span class="string">&#x27;Good melon&#x27;</span>].isin([<span class="string">&#x27;是&#x27;</span>])]</span><br><span class="line">no = data[data[<span class="string">&#x27;Good melon&#x27;</span>].isin([<span class="string">&#x27;否&#x27;</span>])]</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax.scatter(yes[<span class="string">&#x27;Density&#x27;</span>], yes[<span class="string">&#x27;Sugar content&#x27;</span>], marker=<span class="string">&#x27;o&#x27;</span>, c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Yes&#x27;</span>)</span><br><span class="line">ax.scatter(no[<span class="string">&#x27;Density&#x27;</span>], no[<span class="string">&#x27;Sugar content&#x27;</span>], marker=<span class="string">&#x27;x&#x27;</span>, c=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;No&#x27;</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Sugar content&#x27;</span>)</span><br><span class="line">plt.show() <span class="comment"># 可以发现线性不可分</span></span><br></pre></td></tr></table></figure>
<p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_3_0.png" alt="output_3_0"></p>
<h2 id="任务1：SVM分类器判定西瓜好坏"><a href="#任务1：SVM分类器判定西瓜好坏" class="headerlink" title="任务1：SVM分类器判定西瓜好坏"></a>任务1：SVM分类器判定西瓜好坏</h2><p>在SVM分类器中，使用线性核与高斯核进行比较。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用线性核与高斯核进行比较</span></span><br><span class="line">linear_svc = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>)  <span class="comment"># 线性核</span></span><br><span class="line">rbf_svc = svm.SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>)        <span class="comment"># 高斯核（RBF）</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">temp = &#123;<span class="string">&#x27;是&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;否&#x27;</span>: -<span class="number">1</span>&#125;</span><br><span class="line">X = np.array(data.iloc[:, :<span class="number">2</span>])</span><br><span class="line">y = np.array(data.iloc[:, <span class="number">2</span>].replace(temp))[<span class="literal">None</span>].T</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">linear_svc.fit(X, y)</span><br><span class="line">linear_svc.score(X,y)</span><br><span class="line"><span class="comment"># 查看支持向量</span></span><br><span class="line">linear_svc.support_vectors_</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)





array([[0.666, 0.091],
       [0.243, 0.267],
       [0.343, 0.099],
       [0.639, 0.161],
       [0.657, 0.198],
       [0.36 , 0.37 ],
       [0.593, 0.042],
       [0.719, 0.103],
       [0.697, 0.46 ],
       [0.774, 0.376],
       [0.634, 0.264],
       [0.608, 0.318],
       [0.556, 0.215],
       [0.403, 0.237],
       [0.481, 0.149],
       [0.437, 0.211]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rbf_svc.fit(X, y)</span><br><span class="line">rbf_svc.score(X,y)</span><br><span class="line"><span class="comment"># 查看支持向量</span></span><br><span class="line">rbf_svc.support_vectors_</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

array([[0.666, 0.091],
       [0.243, 0.267],
       [0.245, 0.057],
       [0.343, 0.099],
       [0.639, 0.161],
       [0.657, 0.198],
       [0.36 , 0.37 ],
       [0.593, 0.042],
       [0.719, 0.103],
       [0.697, 0.46 ],
       [0.774, 0.376],
       [0.634, 0.264],
       [0.608, 0.318],
       [0.556, 0.215],
       [0.403, 0.237],
       [0.481, 0.149],
       [0.437, 0.211]])
</code></pre><h2 id="任务2：Kernel-Logistic-Regression-判定西瓜好坏"><a href="#任务2：Kernel-Logistic-Regression-判定西瓜好坏" class="headerlink" title="任务2：Kernel Logistic Regression 判定西瓜好坏"></a>任务2：Kernel Logistic Regression 判定西瓜好坏</h2><p>将原始的Logistic Regression 进行核化，使用不同的核函数进行比较。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.colors <span class="keyword">as</span> colors</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>:</span><br><span class="line">    kern_param = <span class="number">0</span></span><br><span class="line">    X = np.array([])</span><br><span class="line">    a = np.array([])</span><br><span class="line">    kernel = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel=<span class="string">&#x27;poly&#x27;</span>, kern_param=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> kernel == <span class="string">&#x27;poly&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__linear__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> kernel == <span class="string">&#x27;gaussian&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__gaussian__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">0.1</span></span><br><span class="line">        <span class="keyword">elif</span> kernel == <span class="string">&#x27;laplace&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__laplace__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y, max_rate=<span class="number">100</span>, min_rate=<span class="number">0.001</span>, gd_step=<span class="number">10</span>, epsilon=<span class="number">0.0001</span></span>):</span><br><span class="line">        m = <span class="built_in">len</span>(X)</span><br><span class="line">        <span class="variable language_">self</span>.X = np.vstack([X.T, np.ones(m)]).T</span><br><span class="line">        <span class="comment"># Construct kernel matrix</span></span><br><span class="line">        K =<span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X, <span class="variable language_">self</span>.X, <span class="variable language_">self</span>.kern_param)  <span class="comment"># 填空1：计算核矩阵</span></span><br><span class="line">        <span class="comment"># Gradient descent</span></span><br><span class="line">        <span class="variable language_">self</span>.a = np.zeros([m])</span><br><span class="line">        prev_cost = <span class="number">0</span></span><br><span class="line">        next_cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">        <span class="keyword">while</span> np.fabs(prev_cost-next_cost) &gt; epsilon:</span><br><span class="line">            neg_grad = -<span class="variable language_">self</span>.__gradient__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">            best_rate = rate = max_rate</span><br><span class="line">            min_cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">            <span class="keyword">while</span> rate &gt;= min_rate:</span><br><span class="line">                cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a+neg_grad*rate)</span><br><span class="line">                <span class="keyword">if</span> cost &lt; min_cost:</span><br><span class="line">                    min_cost = cost</span><br><span class="line">                    best_rate = rate</span><br><span class="line">                rate /= gd_step</span><br><span class="line">            <span class="variable language_">self</span>.a += neg_grad * best_rate</span><br><span class="line">            prev_cost = next_cost</span><br><span class="line">            next_cost = min_cost</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 1. 添加偏置项（与训练数据处理一致）</span></span><br><span class="line">        X = np.vstack([X.T, np.ones(<span class="built_in">len</span>(X))]).T  <span class="comment"># 形状变为 (n_samples, n_features + 1)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 计算核矩阵（训练数据与测试数据之间的核函数值）</span></span><br><span class="line">        K = <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X, X, <span class="variable language_">self</span>.kern_param)  <span class="comment"># 形状：(训练样本数, 测试样本数)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 计算预测得分（关键修正：移除 self.Y 的乘法）</span></span><br><span class="line">        pred = np.dot(<span class="variable language_">self</span>.a, K) </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. Sigmoid转换为概率并二值化</span></span><br><span class="line">        prob = <span class="variable language_">self</span>.__sigmoid__(pred)</span><br><span class="line">        <span class="keyword">return</span> (prob &gt;= <span class="number">0.5</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Kernels</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__linear__</span>(<span class="params">a, b, parameter</span>):</span><br><span class="line">        <span class="keyword">return</span> np.dot(a, np.transpose(b))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__gaussian__</span>(<span class="params">a, b, kern_param</span>):</span><br><span class="line">        mat = np.zeros([<span class="built_in">len</span>(a), <span class="built_in">len</span>(b)])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(b)):</span><br><span class="line">                mat[i][j] = np.exp(-np.<span class="built_in">sum</span>(np.square(np.subtract(a[i], b[j]))) / (<span class="number">2</span> * kern_param * kern_param))</span><br><span class="line">        <span class="keyword">return</span> mat</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__laplace__</span>(<span class="params">a, b, kern_param</span>):</span><br><span class="line">        mat = np.zeros([<span class="built_in">len</span>(a), <span class="built_in">len</span>(b)])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(b)):</span><br><span class="line">                mat[i][j] = np.exp(-np.linalg.norm(np.subtract(a[i], b[j])) / kern_param)</span><br><span class="line">        <span class="keyword">return</span> mat</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__sigmoid__</span>(<span class="params">X</span>):</span><br><span class="line">        <span class="keyword">return</span> np.exp(X) / (<span class="number">1</span> + np.exp(X))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__cost__</span>(<span class="params">K, y, a</span>):</span><br><span class="line">        <span class="keyword">return</span> -np.dot(y, np.dot(a, K)) + np.<span class="built_in">sum</span>(np.log(<span class="number">1</span> + np.exp(np.dot(a, K))))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__gradient__</span>(<span class="params">cls, K, y, a</span>):</span><br><span class="line">        <span class="keyword">return</span> -np.dot(K, y - cls.__sigmoid__(np.dot(a, K)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read data</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;work/西瓜数据集3.0α.txt&quot;</span>)</span><br><span class="line">X = np.array(data[[<span class="string">&#x27;Density&#x27;</span>, <span class="string">&#x27;Sugar content&#x27;</span>]])</span><br><span class="line">y = np.array(data[<span class="string">&#x27;Good melon&#x27;</span>]) == <span class="string">&#x27;是&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Kernels</span></span><br><span class="line">kernels = [<span class="string">&#x27;poly&#x27;</span>, <span class="string">&#x27;gaussian&#x27;</span>, <span class="string">&#x27;laplace&#x27;</span>]</span><br><span class="line">titles = [<span class="string">&#x27;linear kernel&#x27;</span>, <span class="string">&#x27;gaussian kernel, σ=0.1&#x27;</span>, <span class="string">&#x27;laplace kernel, σ=0.1&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(kernels)):</span><br><span class="line">    <span class="comment"># Training</span></span><br><span class="line">    <span class="comment"># 填空3：实例化并训练模型</span></span><br><span class="line">    model = LogisticRegression(kernel=kernels[i])</span><br><span class="line">    model.fit(X, y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Plot</span></span><br><span class="line">    cmap = colors.LinearSegmentedColormap.from_list(<span class="string">&#x27;watermelon&#x27;</span>, [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>])</span><br><span class="line">    xx, yy = np.meshgrid(np.arange(<span class="number">0.2</span>, <span class="number">0.8</span>, <span class="number">0.01</span>), np.arange(<span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">0.01</span>))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    plt.contourf(xx, yy, Z, cmap=cmap, alpha=<span class="number">0.3</span>, antialiased=<span class="literal">True</span>)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sugar content&#x27;</span>)</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:97: RuntimeWarning: overflow encountered in exp
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_1.png" alt="output_10_1"></p>
<p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_2.png" alt="output_10_2"></p>
<p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_3.png" alt="output_10_3"></p>
<h3 id="1-线性核（Linear-Kernel）"><a href="#1-线性核（Linear-Kernel）" class="headerlink" title="1. 线性核（Linear Kernel）"></a><strong>1. 线性核（Linear Kernel）</strong></h3><ul>
<li><strong>数学形式</strong>：<br>[<br>K(x_i, x_j) = x_i^T x_j + c \quad (c \text{为可选常数})<br>]</li>
<li><strong>特点</strong>：  <ul>
<li>直接计算特征向量的内积，不进行非线性映射。  </li>
<li>决策边界为线性超平面，计算效率高。  </li>
</ul>
</li>
<li><strong>适用场景</strong>：  <ul>
<li>数据线性可分（如两类可通过一条直线/平面分开）。  </li>
<li>特征维度较高时（避免核方法的计算开销）。  </li>
</ul>
</li>
<li><strong>西瓜数据集表现</strong>：  <ul>
<li>生成直线决策边界，可能误分类非线性分布的样本。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-高斯核（Gaussian-RBF-Kernel）"><a href="#2-高斯核（Gaussian-RBF-Kernel）" class="headerlink" title="2. 高斯核（Gaussian/RBF Kernel）"></a><strong>2. 高斯核（Gaussian/RBF Kernel）</strong></h3><ul>
<li><strong>数学形式</strong>：<br>[<br>K(x_i, x_j) = \exp\left(-\gamma |x_i - x_j|^2\right) \quad (\gamma &gt; 0)<br>]</li>
<li><strong>特点</strong>：  <ul>
<li>基于样本间的欧氏距离（L2距离），隐式映射到无限维空间。  </li>
<li>参数 <code>γ</code> 控制影响范围：<code>γ</code> 越大，局部性越强（对邻近点更敏感）。  </li>
</ul>
</li>
<li><strong>适用场景</strong>：  <ul>
<li>数据非线性可分（如环形分布、复杂流形）。  </li>
<li>特征维度较低或中等时效果最佳。  </li>
</ul>
</li>
<li><strong>西瓜数据集表现</strong>：  <ul>
<li>生成平滑的非线性边界，能捕捉密度与含糖量的复杂交互关系。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-拉普拉斯核（Laplace-Kernel）"><a href="#3-拉普拉斯核（Laplace-Kernel）" class="headerlink" title="3. 拉普拉斯核（Laplace Kernel）"></a><strong>3. 拉普拉斯核（Laplace Kernel）</strong></h3><ul>
<li><strong>数学形式</strong>：<br>[<br>K(x_i, x_j) = \exp\left(-\gamma |x_i - x_j|_1\right) \quad (\gamma &gt; 0)<br>]</li>
<li><strong>特点</strong>：  <ul>
<li>基于曼哈顿距离（L1距离），对异常值鲁棒性更强。  </li>
<li>隐式映射到无限维空间，但形状更尖锐（适合非光滑边界）。  </li>
</ul>
</li>
<li><strong>适用场景</strong>：  <ul>
<li>数据分布不规则或存在离群点。  </li>
<li>特征具有稀疏性（如文本分类）。  </li>
</ul>
</li>
<li><strong>西瓜数据集表现</strong>：  <ul>
<li>生成尖锐的非线性边界，可能更好地处理边缘样本。</li>
</ul>
</li>
</ul>
<p>以下是欧氏距离（Euclidean Distance）与曼哈顿距离（Manhattan Distance）的详细对比：</p>
<hr>
<h3 id="1-数学定义"><a href="#1-数学定义" class="headerlink" title="1. 数学定义"></a><strong>1. 数学定义</strong></h3><div class="table-container">
<table>
<thead>
<tr>
<th>距离类型</th>
<th>公式</th>
<th>几何意义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>欧氏距离</strong></td>
<td>( \</td>
<td>x - y\</td>
<td><em>2 = \sqrt{\sum</em>{i=1}^n (x_i - y_i)^2} )</td>
<td>两点之间的<strong>直线距离</strong></td>
</tr>
<tr>
<td><strong>曼哈顿距离</strong></td>
<td>( \</td>
<td>x - y\</td>
<td><em>1 = \sum</em>{i=1}^n</td>
<td>x_i - y_i</td>
<td>)</td>
<td>两点在<strong>网格路径</strong>上的行走距离</td>
</tr>
</tbody>
</table>
</div>
<h3 id="5-选择建议"><a href="#5-选择建议" class="headerlink" title="5. 选择建议"></a><strong>5. 选择建议</strong></h3><ul>
<li><strong>优先欧氏距离</strong>：<br>数据分布连续、特征维度较低、需要捕捉局部相似性时（如图像分类）。</li>
<li><strong>优先曼哈顿距离</strong>：<br>数据稀疏（如文本）、存在噪声或异常值、特征维度较高时（如推荐系统）。</li>
</ul>
<hr>
<h3 id="示例对比"><a href="#示例对比" class="headerlink" title="示例对比"></a><strong>示例对比</strong></h3><p>假设两点 ( A(1, 1) ) 和 ( B(4, 5) )：</p>
<ul>
<li><strong>欧氏距离</strong>：<br>[<br>\sqrt{(4-1)^2 + (5-1)^2} = 5<br>]</li>
<li><strong>曼哈顿距离</strong>：<br>[<br>|4-1| + |5-1| = 3 + 4 = 7<br>]</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><ul>
<li><strong>欧氏距离</strong>：强调“直线最短”，适合低维连续数据。  </li>
<li><strong>曼哈顿距离</strong>：强调“网格路径”，适合高维稀疏数据。  </li>
<li><strong>在核函数中的体现</strong>：  <ul>
<li>高斯核通过欧氏距离捕捉平滑边界，拉普拉斯核通过曼哈顿距离增强鲁棒性。</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">机器学习——上机实验9--神经网络</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-15 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-15T00:00:00+08:00">2025-04-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-12 19:01:31" itemprop="dateModified" datetime="2025-06-12T19:01:31+08:00">2025-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="上机实验9：神经网络"><a href="#上机实验9：神经网络" class="headerlink" title="上机实验9：神经网络"></a>上机实验9：神经网络</h1><h2 id="任务1：神经元模型"><a href="#任务1：神经元模型" class="headerlink" title="任务1：神经元模型"></a>任务1：神经元模型</h2><ul>
<li>给定数据集X和y</li>
<li>请补全以下代码以实现一个简单的神经元模型（即不包含隐层），并计算模型的参数向量w_vec</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 输入X和y</span></span><br><span class="line">X = np.array([ [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">y = np.array([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]]).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># Sigmoid激活函数以及其导数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x, derivative = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># 计算sigmoid的输出</span></span><br><span class="line">    sigmoid_value =<span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">    <span class="keyword">if</span> derivative == <span class="literal">False</span>:     </span><br><span class="line">        <span class="keyword">return</span> sigmoid_value</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> derivative == <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 计算sigmoid的导数</span></span><br><span class="line">        <span class="keyword">return</span> sigmoid_value * (<span class="number">1</span> - sigmoid_value)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代次数</span></span><br><span class="line">iter_num  = <span class="number">1000</span></span><br><span class="line">eta = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化权重向量w</span></span><br><span class="line">num, dim = X.shape</span><br><span class="line">w_vec = np.ones((dim, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(iter_num):</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## X通过权重向量w_vec，实现线性加和，结果为z1</span></span><br><span class="line">    z_1 =  X.dot(w_vec)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 经过激活函数Sigmoid，获得输出a_1</span></span><br><span class="line">    a_1 = sigmoid(z_1)</span><br><span class="line">      </span><br><span class="line">    <span class="comment"># 模型输出a_1与真实值的误差</span></span><br><span class="line">    error = a_1 - y</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 权重更新</span></span><br><span class="line">    w_vec_delta = X.T.dot(error * sigmoid(z_1, derivative=<span class="literal">True</span>))</span><br><span class="line">    w_vec = w_vec + eta*w_vec_delta  </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (w_vec)</span><br></pre></td></tr></table></figure>
<pre><code>[[0.94321144]
 [1.83125284]
 [4.71149329]]
</code></pre><h2 id="任务2：-感知机"><a href="#任务2：-感知机" class="headerlink" title="任务2： 感知机"></a>任务2： 感知机</h2><p>1．感知机是根据输入实例的特征向量$x$对其进行二类分类的线性分类模型：</p>
<script type="math/tex; mode=display">
f(x)=\operatorname{sign}(w \cdot x+b)</script><p>感知机模型对应于输入空间（特征空间）中的分离超平面$w \cdot x+b=0$。</p>
<p>2．感知机学习的策略是极小化损失函数：</p>
<script type="math/tex; mode=display">
\min _{w, b} L(w, b)=-\sum_{x_{i} \in M} y_{i}\left(w \cdot x_{i}+b\right)</script><p>损失函数对应于误分类点到分离超平面的总距离。</p>
<p>3．感知机学习算法是基于随机梯度下降法的对损失函数的最优化算法，有原始形式和对偶形式。算法简单且易于实现。原始形式中，首先任意选取一个超平面，然后用梯度下降法不断极小化目标函数。在这个过程中一次随机选取一个误分类点使其梯度下降。</p>
<p>4．当训练数据集线性可分时，感知机学习算法是收敛的。感知机算法在训练数据集上的误分类次数$k$满足不等式：</p>
<script type="math/tex; mode=display">
k \leqslant\left(\frac{R}{\gamma}\right)^{2}</script><p>当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同。</p>
<ol>
<li>随机梯度下降算法 Stochastic Gradient Descent：</li>
</ol>
<p>随机抽取一个误分类点使其梯度下降。</p>
<p>$w = w + \eta y<em>{i}x</em>{i}$</p>
<p>$b = b + \eta y_{i}$</p>
<p>当实例点被误分类，即位于分离超平面的错误侧，则调整$w$, $b$的值，使分离超平面向该无分类点的一侧移动，直至误分类点被正确分类。</p>
<p><strong>使用iris数据集中两个类别的数据和[sepal length，sepal width]作为特征，进行感知机分类。</strong></p>
<ol>
<li>自定义感知机模型，实现iris数据分类；</li>
<li>调用sklearn中Perceptron函数来分类；</li>
<li>验证感知机为什么不能表示异或（选做）。</li>
</ol>
<h3 id="1-自定义感知机模型，实现iris数据分类"><a href="#1-自定义感知机模型，实现iris数据分类" class="headerlink" title="1. 自定义感知机模型，实现iris数据分类"></a>1. 自定义感知机模型，实现iris数据分类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line"></span><br><span class="line">df.columns = [</span><br><span class="line">    <span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>, <span class="string">&#x27;label&#x27;</span></span><br><span class="line">]</span><br><span class="line">df.label.value_counts()</span><br><span class="line"></span><br><span class="line">data = np.array(df.iloc[:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">X, y = data[:,:-<span class="number">1</span>], data[:,-<span class="number">1</span>]</span><br><span class="line">y = np.array([<span class="number">1</span> <span class="keyword">if</span> i == <span class="number">1</span> <span class="keyword">else</span> -<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> y])</span><br><span class="line"></span><br><span class="line">plt.scatter(df[:<span class="number">50</span>][<span class="string">&#x27;sepal length&#x27;</span>], df[:<span class="number">50</span>][<span class="string">&#x27;sepal width&#x27;</span>], label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.scatter(df[<span class="number">50</span>:<span class="number">100</span>][<span class="string">&#x27;sepal length&#x27;</span>], df[<span class="number">50</span>:<span class="number">100</span>][<span class="string">&#x27;sepal width&#x27;</span>], label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f177628f110&gt;



/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_6_2.png" alt="output_6_2"></p>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据线性可分，二分类数据</span></span><br><span class="line"><span class="comment"># 此处为一元一次线性方程</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.w = np.ones(<span class="built_in">len</span>(data[<span class="number">0</span>]) - <span class="number">1</span>, dtype=np.float32)</span><br><span class="line">        <span class="variable language_">self</span>.b = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.l_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">self, x, w, b</span>):</span><br><span class="line">        y = np.sign(np.dot(x, w) + b)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机梯度下降法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X_train, y_train</span>):</span><br><span class="line">        is_wrong = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> is_wrong:</span><br><span class="line">            wrong_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train)):</span><br><span class="line">                X = X_train[d]</span><br><span class="line">                y = y_train[d]</span><br><span class="line">                <span class="keyword">if</span> y * (np.dot(X, <span class="variable language_">self</span>.w) + <span class="variable language_">self</span>.b) &lt;= <span class="number">0</span>: <span class="comment">#判断样本被误分类</span></span><br><span class="line">                    <span class="comment"># 更新权重和偏置</span></span><br><span class="line">                    <span class="variable language_">self</span>.w = <span class="variable language_">self</span>.w + <span class="variable language_">self</span>.l_rate * y * X</span><br><span class="line">                    <span class="variable language_">self</span>.b = <span class="variable language_">self</span>.b + <span class="variable language_">self</span>.l_rate * y</span><br><span class="line">                    wrong_count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> wrong_count == <span class="number">0</span>:</span><br><span class="line">                is_wrong = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Perceptron Model!&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进行模型训练</span></span><br><span class="line">perceptron = Model()</span><br><span class="line">perceptron.fit(X, y)</span><br><span class="line"></span><br><span class="line">x_points = np.linspace(<span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">y_ = -(perceptron.w[<span class="number">0</span>] * x_points + perceptron.b) / perceptron.w[<span class="number">1</span>]</span><br><span class="line">plt.plot(x_points, y_)</span><br><span class="line"></span><br><span class="line">plt.plot(data[:<span class="number">50</span>, <span class="number">0</span>], data[:<span class="number">50</span>, <span class="number">1</span>], <span class="string">&#x27;bo&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.plot(data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], <span class="string">&#x27;bo&#x27;</span>, color=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f1773a0c950&gt;
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_9_1.png" alt="output_9_1"></p>
<h3 id="2-调用sklearn中Perceptron函数来分类"><a href="#2-调用sklearn中Perceptron函数来分类" class="headerlink" title="2. 调用sklearn中Perceptron函数来分类"></a>2. 调用sklearn中Perceptron函数来分类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="comment"># 调用sklearn中Perceptron函数进行分类</span></span><br><span class="line">clf = Perceptron(</span><br><span class="line">    max_iter=<span class="number">5000</span>,      <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">    eta0=<span class="number">0.05</span>,           <span class="comment"># 调整学习率（原0.01可能过小）</span></span><br><span class="line">    shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 训练模型</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"><span class="comment"># Weights assigned to the features.</span></span><br><span class="line"><span class="built_in">print</span>(clf.coef_)</span><br><span class="line"><span class="comment"># 截距 Constants in decision function.</span></span><br><span class="line"><span class="built_in">print</span>(clf.intercept_)</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.16  -1.935]]
[-0.25]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 画布大小</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文标题</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.title(<span class="string">&#x27;鸢尾花线性数据示例&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(data[:<span class="number">50</span>, <span class="number">0</span>], data[:<span class="number">50</span>, <span class="number">1</span>], c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Iris-setosa&#x27;</span>,)</span><br><span class="line">plt.scatter(data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], c=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;Iris-versicolor&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画感知机的线</span></span><br><span class="line">x_ponits = np.arange(<span class="number">4</span>, <span class="number">8</span>)</span><br><span class="line">y_ = -(clf.coef_[<span class="number">0</span>][<span class="number">0</span>]*x_ponits + clf.intercept_)/clf.coef_[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">plt.plot(x_ponits, y_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他部分</span></span><br><span class="line">plt.legend()  <span class="comment"># 显示图例</span></span><br><span class="line">plt.grid(<span class="literal">False</span>)  <span class="comment"># 不显示网格</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f1769a4eb50&gt;



/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_12_2.png" alt="output_12_2"></p>
<h3 id="3-验证感知机为什么不能表示异或（选做）"><a href="#3-验证感知机为什么不能表示异或（选做）" class="headerlink" title="3. 验证感知机为什么不能表示异或（选做）"></a>3. 验证感知机为什么不能表示异或（选做）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">x=np.array([[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line">y=np.array([<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">plt.plot(x[:<span class="number">2</span>,<span class="number">0</span>],x[:<span class="number">2</span>,<span class="number">1</span>],<span class="string">&#x27;bo&#x27;</span>,color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.plot(x[<span class="number">2</span>:<span class="number">4</span>,<span class="number">0</span>],x[<span class="number">2</span>:<span class="number">4</span>,<span class="number">1</span>],<span class="string">&#x27;bo&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>,label=<span class="string">&#x27;-1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 初始化感知机模型</span></span><br><span class="line">clf = Perceptron(</span><br><span class="line">    max_iter=<span class="number">1000</span>,      <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">    eta0=<span class="number">0.1</span>,           <span class="comment"># 学习率</span></span><br><span class="line">    random_state=<span class="number">42</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>        <span class="comment"># 每次迭代打乱数据</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出模型参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征权重 (w):&quot;</span>, clf.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;截距 (b):&quot;</span>, clf.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">predictions = clf.predict(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测结果:&quot;</span>, predictions)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;真实标签:&quot;</span>, y)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>特征权重 (w): [[0. 0.]]
截距 (b): [0.]
预测结果: [-1 -1 -1 -1]
真实标签: [ 1  1 -1 -1]


/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_14_2.png" alt="output_14_2"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C10--%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C10--%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" class="post-title-link" itemprop="url">机器学习——上机实验10--支持向量机</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-15 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-15T00:00:00+08:00">2025-04-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-04-17 11:30:37" itemprop="dateModified" datetime="2025-04-17T11:30:37+08:00">2025-04-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="上机实验10—支持向量机"><a href="#上机实验10—支持向量机" class="headerlink" title="上机实验10—支持向量机"></a>上机实验10—支持向量机</h1><h2 id="任务1：sklearn中的SVC与惩罚系数C"><a href="#任务1：sklearn中的SVC与惩罚系数C" class="headerlink" title="任务1：sklearn中的SVC与惩罚系数C"></a>任务1：sklearn中的SVC与惩罚系数C</h2><ul>
<li>提供一份糖尿病患者数据集diabetes.csv，该数据集有768个数据样本，9个特征(最后一列为目标特征数据)，并且已经存入变量data。特征的具体信息如下：</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>特征名称</th>
<th>特征含义</th>
<th>取值举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>feature1</td>
<td>怀孕次数</td>
<td>6</td>
</tr>
<tr>
<td>feature2</td>
<td>2小时口服葡萄糖耐受实验中的血浆葡萄浓度</td>
<td>148</td>
</tr>
<tr>
<td>feature3</td>
<td>舒张压 (mm Hg)</td>
<td>72</td>
</tr>
<tr>
<td>feature4</td>
<td>三头肌皮褶厚度(mm)</td>
<td>35</td>
</tr>
<tr>
<td>feature5</td>
<td>2小时血清胰岛素浓度 (mu U/ml)</td>
<td>0</td>
</tr>
<tr>
<td>feature6</td>
<td>体重指数(weight in kg/(height in m)^2)</td>
<td>33.6</td>
</tr>
<tr>
<td>feature7</td>
<td>糖尿病谱系功能(Diabetes pedigree function)</td>
<td>0.627</td>
</tr>
<tr>
<td>feature8</td>
<td>年龄</td>
<td>50</td>
</tr>
<tr>
<td>class</td>
<td>是否患有糖尿病</td>
<td>1：阳性；0：阴性</td>
</tr>
</tbody>
</table>
</div>
<p>主要任务如下：</p>
<ul>
<li>请先将数据使用sklearn中的StandardScaler进行标准化；</li>
<li>然后使用sklearn中的svm.SVC支持向量分类器，构建支持向量机模型（所有参数使用默认参数），对测试集进行预测，将预测结果存为pred_y，并对模型进行评价；</li>
<li>最后新建一个svm.SVC实例clf_new，并设置惩罚系数C=0.3，并利用该支持向量分类器对测试集进行预测，将预测结果存为pred_y_new，并比较两个模型的预测效果。</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># 将目标特征与其他特征分离</span></span><br><span class="line">X = data.drop(<span class="string">&#x27;class&#x27;</span>, axis=<span class="number">1</span>)  </span><br><span class="line">y = data[<span class="string">&#x27;class&#x27;</span>]  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集train_X, train_y和测试集train_X, train_y</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = <span class="number">.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集标准化，返回结果为scaled_train_X</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaled_train_X = scaler.fit_transform(train_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建支持向量机模型</span></span><br><span class="line">clf = SVC()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">clf.fit(scaled_train_X, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集标准化</span></span><br><span class="line">scaled_test_X = scaler.transform(test_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型返回预测值</span></span><br><span class="line">pred_y = clf.predict(scaled_test_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印支持向量的个数，返回结果为列表，[-1标签的支持向量，+1标签的支持向量]</span></span><br><span class="line"><span class="built_in">print</span>(clf.n_support_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用classification_report函数进行模型评价</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建惩罚系数C为0.3的模型，并与之前的模型做比较</span></span><br><span class="line">clf_new = SVC(C=<span class="number">0.3</span>)</span><br><span class="line">clf_new.fit(scaled_train_X, train_y)</span><br><span class="line">pred_y_new = clf_new.predict(scaled_test_X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(clf_new.n_support_)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y_new))</span><br><span class="line"></span><br><span class="line"><span class="comment">#调整惩罚系数C寻优</span></span><br></pre></td></tr></table></figure>
<pre><code>[187 180]

              precision    recall  f1-score   support
</code></pre><p>​    </p>
<pre><code>           0       0.82      0.90      0.86       107

           1       0.70      0.55      0.62        47
</code></pre><p>​    </p>
<pre><code>    accuracy                           0.79       154

   macro avg       0.76      0.73      0.74       154

weighted avg       0.78      0.79      0.78       154
</code></pre><p>​    </p>
<pre><code>[197 196]

              precision    recall  f1-score   support
</code></pre><p>​    </p>
<pre><code>           0       0.83      0.92      0.87       107

           1       0.75      0.57      0.65        47
</code></pre><p>​    </p>
<pre><code>    accuracy                           0.81       154

   macro avg       0.79      0.75      0.76       154

weighted avg       0.81      0.81      0.80       154
</code></pre><p>​    </p>
<blockquote>
<p>预期结果</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/0768604ae0644fcdb3edd584090f6af7fae81344e0b14da789ec1324ee81bcf0" alt></p>
<h2 id="任务2：SVC选定RBF核函数，并寻优核带宽参数gamma"><a href="#任务2：SVC选定RBF核函数，并寻优核带宽参数gamma" class="headerlink" title="任务2：SVC选定RBF核函数，并寻优核带宽参数gamma"></a>任务2：SVC选定RBF核函数，并寻优核带宽参数gamma</h2><blockquote>
<p>在支持向量分类器中，核函数对其性能有直接的影响。已知径向基函数 RBF 及核矩阵元素为：</p>
<script type="math/tex; mode=display">K(\boldsymbol{x}_i, \boldsymbol{x}_j)=\exp(-\gamma\|\boldsymbol{x}_i-\boldsymbol{x}_j\|^2)</script><p>且对于核矩阵K，有$K_{ij}=K(\boldsymbol{x}_i, \boldsymbol{x}_j).$</p>
</blockquote>
<p>主要任务如下：</p>
<ul>
<li>自定义函数实现径向基函数 rbf_kernel，要求输入参数为两个矩阵 X、Y，以及 gamma；</li>
<li>利用rbf_kernel核函数，计算标准化后的训练集scaled_train_X的核矩阵，并存为 rbf_matrix；</li>
<li>利用rbf_kernel核函数，训练支持向量分类器 clf，并预测标准化后的测试数据 scaled_test_X 的标签，最后评价模型效果。<blockquote>
<p>提示：先计算各自的 Gram 矩阵，然后再使用 np.diag 提取对角线元素，使用 np.tile 将列表扩展成一个矩阵。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rbf_kernel</span>(<span class="params">X, Y, gamma=<span class="number">0.5</span></span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取X和Y的大小</span></span><br><span class="line">    num1 = X.shape[<span class="number">0</span>]</span><br><span class="line">    num2 = Y.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算X和X^T的矩阵乘积</span></span><br><span class="line">    gram_1 = X.dot(X.T)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取gram_1对角线位置的元素，组成大小(num1, 1)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component1</span></span><br><span class="line">    component1 = np.tile(np.diag(gram_1).reshape(-<span class="number">1</span>, <span class="number">1</span>), (<span class="number">1</span>, num2))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算Y和Y^T的乘积</span></span><br><span class="line">    gram_2 = Y.dot(Y.T)</span><br><span class="line">     </span><br><span class="line">    <span class="comment"># 获取gram_2对角线位置的元素，组成(1, num2)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component2</span></span><br><span class="line">    component2 = np.tile(np.diag(gram_2).reshape(<span class="number">1</span>, -<span class="number">1</span>), (num1, <span class="number">1</span>))</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># 计算2X和Y^T的内积 </span></span><br><span class="line">    component3 = <span class="number">2</span> * X.dot(Y.T)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 返回结果</span></span><br><span class="line">    result = np.exp(gamma*(component3 - component1 - component2))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算糖尿病患者训练数据集的核矩阵</span></span><br><span class="line">rbf_matrix = rbf_kernel(scaled_train_X, scaled_train_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练一个支持向量分类器</span></span><br><span class="line">clf = SVC(kernel=rbf_kernel)</span><br><span class="line">clf.fit(scaled_train_X, train_y)</span><br><span class="line">pred_y = clf.predict(scaled_test_X)</span><br><span class="line"><span class="built_in">print</span> (clf.n_support_)</span><br><span class="line"><span class="built_in">print</span> (classification_report(test_y, pred_y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整gamma值寻找最优</span></span><br></pre></td></tr></table></figure>
<pre><code>[250 208]

              precision    recall  f1-score   support

           0       0.84      0.89      0.86       107

           1       0.71      0.62      0.66        47

    accuracy                           0.81       154

   macro avg       0.77      0.75      0.76       154

weighted avg       0.80      0.81      0.80       154
</code></pre><blockquote>
<p>预期结果</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/09cbd0f9a36e4802941289e87082169b6640e370714642d38606e76575bc5632" alt></p>
<h2 id="任务3：自定义函数实现SVM（选做）"><a href="#任务3：自定义函数实现SVM（选做）" class="headerlink" title="任务3：自定义函数实现SVM（选做）"></a>任务3：自定义函数实现SVM（选做）</h2><p>主要任务如下：</p>
<ul>
<li>读取sklearn中的iris数据集，提取特征与标记，并进行数据划分为训练与测试集；</li>
<li>自定义函数实现SVM；</li>
<li>调用SVM函数进行支持向量机训练，并对测试集进行测试。</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_data</span>():</span><br><span class="line">    iris = load_iris()</span><br><span class="line">    df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">    df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line">    df.columns = [<span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">    data = np.array(df.iloc[:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">        <span class="keyword">if</span> data[i,-<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">            data[i,-<span class="number">1</span>] = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># print(data)</span></span><br><span class="line">    <span class="keyword">return</span> data[:,:<span class="number">2</span>], data[:,-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据，拆分数据，训练测试集划分</span></span><br><span class="line">X, y = create_data()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.25</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SVM</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_iter=<span class="number">100</span>, kernel=<span class="string">&#x27;linear&#x27;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.max_iter = max_iter</span><br><span class="line">        <span class="variable language_">self</span>._kernel = kernel</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_args</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.m, <span class="variable language_">self</span>.n = features.shape</span><br><span class="line">        <span class="variable language_">self</span>.X = features</span><br><span class="line">        <span class="variable language_">self</span>.Y = labels</span><br><span class="line">        <span class="variable language_">self</span>.b = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将Ei保存在一个列表里</span></span><br><span class="line">        <span class="variable language_">self</span>.alpha = np.ones(<span class="variable language_">self</span>.m)</span><br><span class="line">        <span class="variable language_">self</span>.E = [<span class="variable language_">self</span>._E(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m)]</span><br><span class="line">        <span class="comment"># 松弛变量</span></span><br><span class="line">        <span class="variable language_">self</span>.C = <span class="number">1.0</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_KKT</span>(<span class="params">self, i</span>):</span><br><span class="line">        y_g = <span class="variable language_">self</span>._g(i)*<span class="variable language_">self</span>.Y[i]</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.alpha[i] == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> y_g &gt;= <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.alpha[i] &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">            <span class="keyword">return</span> y_g == <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> y_g &lt;= <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># g(x)预测值，输入xi（X[i]）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_g</span>(<span class="params">self, i</span>):</span><br><span class="line">        r = <span class="variable language_">self</span>.b</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m):</span><br><span class="line">            r += <span class="variable language_">self</span>.alpha[j] * <span class="variable language_">self</span>.Y[j] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[j], <span class="variable language_">self</span>.X[i])</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 核函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kernel</span>(<span class="params">self, x1, x2</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._kernel == <span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> np.dot(x1, x2)</span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>._kernel == <span class="string">&#x27;poly&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="built_in">sum</span>([x1[k]*x2[k] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.n)]) + <span class="number">1</span>)**<span class="number">2</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># E（x）为g(x)对输入x的预测值和y的差</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_E</span>(<span class="params">self, i</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._g(i) - <span class="variable language_">self</span>.Y[i]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_alpha</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 外层循环首先遍历所有满足0&lt;a&lt;C的样本点，检验是否满足KKT</span></span><br><span class="line">        index_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m) <span class="keyword">if</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.alpha[i] &lt; <span class="variable language_">self</span>.C]</span><br><span class="line">        <span class="comment"># 否则遍历整个训练集</span></span><br><span class="line">        non_satisfy_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m) <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> index_list]</span><br><span class="line">        index_list.extend(non_satisfy_list)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> index_list:</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>._KKT(i):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            E1 = <span class="variable language_">self</span>.E[i]</span><br><span class="line">            <span class="comment"># 如果E2是+，选择最小的；如果E2是负的，选择最大的</span></span><br><span class="line">            <span class="keyword">if</span> E1 &gt;= <span class="number">0</span>:</span><br><span class="line">                j = <span class="built_in">min</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.m), key=<span class="keyword">lambda</span> x: <span class="variable language_">self</span>.E[x])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                j = <span class="built_in">max</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.m), key=<span class="keyword">lambda</span> x: <span class="variable language_">self</span>.E[x])</span><br><span class="line">            <span class="keyword">return</span> i, j</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compare</span>(<span class="params">self, _alpha, L, H</span>):</span><br><span class="line">        <span class="keyword">if</span> _alpha &gt; H:</span><br><span class="line">            <span class="keyword">return</span> H</span><br><span class="line">        <span class="keyword">elif</span> _alpha &lt; L:</span><br><span class="line">            <span class="keyword">return</span> L</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> _alpha      </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.init_args(features, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.max_iter):</span><br><span class="line">            <span class="comment"># train</span></span><br><span class="line">            i1, i2 =<span class="variable language_">self</span>._init_alpha()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 边界</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.Y[i1] == <span class="variable language_">self</span>.Y[i2]:</span><br><span class="line">                L = <span class="built_in">max</span>(<span class="number">0</span>, <span class="variable language_">self</span>.alpha[i1]+<span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.C)</span><br><span class="line">                H = <span class="built_in">min</span>(<span class="variable language_">self</span>.C, <span class="variable language_">self</span>.alpha[i1]+<span class="variable language_">self</span>.alpha[i2])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                L = <span class="built_in">max</span>(<span class="number">0</span>, <span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.alpha[i1])</span><br><span class="line">                H = <span class="built_in">min</span>(<span class="variable language_">self</span>.C, <span class="variable language_">self</span>.C+<span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.alpha[i1])</span><br><span class="line">                </span><br><span class="line">            E1 = <span class="variable language_">self</span>.E[i1]</span><br><span class="line">            E2 = <span class="variable language_">self</span>.E[i2]</span><br><span class="line">            <span class="comment"># eta=K11+K22-2K12</span></span><br><span class="line">            eta = <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i1]) + \</span><br><span class="line">                  <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i2]) - \</span><br><span class="line">                  <span class="number">2</span> * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i2])</span><br><span class="line">            <span class="keyword">if</span> eta &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># print(&#x27;eta &lt;= 0&#x27;)</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            alpha2_new_unc = <span class="variable language_">self</span>.alpha[i2] + <span class="variable language_">self</span>.Y[i2] * (E2 - E1) / eta</span><br><span class="line">            alpha2_new = <span class="variable language_">self</span>._compare(alpha2_new_unc, L, H)</span><br><span class="line">            </span><br><span class="line">            alpha1_new = <span class="variable language_">self</span>.alpha[i1] + <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.Y[i2] * (<span class="variable language_">self</span>.alpha[i2] - alpha2_new)</span><br><span class="line">            </span><br><span class="line">            b1_new = -E1 - <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i1]) * (alpha1_new-<span class="variable language_">self</span>.alpha[i1]) - <span class="variable language_">self</span>.Y[i2] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i1]) * (alpha2_new-<span class="variable language_">self</span>.alpha[i2])+ <span class="variable language_">self</span>.b </span><br><span class="line">            b2_new = -E2 - <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i2]) * (alpha1_new-<span class="variable language_">self</span>.alpha[i1]) - <span class="variable language_">self</span>.Y[i2] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i2]) * (alpha2_new-<span class="variable language_">self</span>.alpha[i2])+ <span class="variable language_">self</span>.b </span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt; alpha1_new &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">                b_new = b1_new</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">0</span> &lt; alpha2_new &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">                b_new = b2_new</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 选择中点</span></span><br><span class="line">                b_new = (b1_new + b2_new) / <span class="number">2</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 更新参数</span></span><br><span class="line">            <span class="variable language_">self</span>.alpha[i1] = alpha1_new</span><br><span class="line">            <span class="variable language_">self</span>.alpha[i2] = alpha2_new</span><br><span class="line">            <span class="variable language_">self</span>.b = b_new</span><br><span class="line">            </span><br><span class="line">            <span class="variable language_">self</span>.E[i1] = <span class="variable language_">self</span>._E(i1)</span><br><span class="line">            <span class="variable language_">self</span>.E[i2] = <span class="variable language_">self</span>._E(i2)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;train done!&#x27;</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, data</span>):</span><br><span class="line">        r = <span class="variable language_">self</span>.b</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m):</span><br><span class="line">            r += <span class="variable language_">self</span>.alpha[i] * <span class="variable language_">self</span>.Y[i] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i], data)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> r &gt; <span class="number">0</span> <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self, X_test, y_test</span>):</span><br><span class="line">        right_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_test)):</span><br><span class="line">            result = <span class="variable language_">self</span>.predict(X_test[i])</span><br><span class="line">            <span class="keyword">if</span> result == y_test[i]:</span><br><span class="line">                right_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> right_count / <span class="built_in">len</span>(X_test)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_weight</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># linear model</span></span><br><span class="line">        yx = <span class="variable language_">self</span>.Y.reshape(-<span class="number">1</span>, <span class="number">1</span>)*<span class="variable language_">self</span>.X</span><br><span class="line">        <span class="variable language_">self</span>.w = np.dot(<span class="variable language_">self</span>.alpha, yx)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.w</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用SVM进行模型训练与测试评估</span></span><br><span class="line">svm = SVM(max_iter=<span class="number">100</span>)</span><br><span class="line">svm.fit(X_train, y_train)</span><br><span class="line">svm.score(X_test, y_test)</span><br></pre></td></tr></table></figure>
<pre><code>0.92
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/6/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/8/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">张熙浚</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="本站访问数 fa fa-user 次"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="本站总访问量 fa fa-eye 次"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="400" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
