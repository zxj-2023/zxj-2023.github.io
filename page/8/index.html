<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="zxj Blogs">
<meta property="og:type" content="website">
<meta property="og:title" content="Zhang XiJun">
<meta property="og:url" content="http://example.com/page/8/index.html">
<meta property="og:site_name" content="Zhang XiJun">
<meta property="og:description" content="zxj Blogs">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="张熙浚">
<meta property="article:tag" content="zxj">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/8/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/8/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Zhang XiJun</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhang XiJun</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">BLOGS</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="张熙浚"
      src="/images/zxjavatar.gif">
  <p class="site-author-name" itemprop="name">张熙浚</p>
  <div class="site-description" itemprop="description">zxj Blogs</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">127</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">47</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/zxj-2023" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxj-2023" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=2902065320&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;2902065320&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener me" target="_blank"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zxj-2023.github.io/" title="https:&#x2F;&#x2F;zxj-2023.github.io" rel="noopener" target="_blank">Zhang XiJun</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org" rel="noopener" target="_blank">NexT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">机器学习——神经网络</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-03 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-03T00:00:00+08:00">2025-04-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-04-16 16:49:46" itemprop="dateModified" datetime="2025-04-16T16:49:46+08:00">2025-04-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h3><h4 id="类别不均衡指的是什么？有哪些解决方案。"><a href="#类别不均衡指的是什么？有哪些解决方案。" class="headerlink" title="类别不均衡指的是什么？有哪些解决方案。"></a>类别不均衡指的是什么？有哪些解决方案。</h4><p><strong>类别不均衡（Class Imbalance）</strong> 是指分类任务中不同类别样本的数量差异显著，例如：  </p>
<ul>
<li><strong>多数类（Majority Class）</strong>：样本数量多（如正常交易占99%）。  </li>
<li><strong>少数类（Minority Class）</strong>：样本数量极少（如欺诈交易仅占1%）。  </li>
</ul>
<p>这种问题会导致模型倾向于预测多数类，严重降低少数类的预测性能（如漏检欺诈行为）。以下是详细解释和解决方案：</p>
<p><strong>1. 类别不均衡的影响</strong></p>
<ul>
<li><strong>模型偏差</strong>：模型过度关注多数类，忽略少数类（如将所有样本预测为多数类，准确率虚高）。  </li>
<li><strong>评估指标失效</strong>：准确率（Accuracy）失去意义（例如：99% 的样本是多数类，模型只需预测多数类即可达到 99% 准确率）。  </li>
</ul>
<p><strong>2. 解决方案</strong></p>
<p><strong>2.1 数据层面调整</strong></p>
<ul>
<li><p><strong>过采样（Oversampling）</strong>  </p>
<ul>
<li><strong>复制少数类样本</strong>：直接复制少数类数据（可能导致过拟合）。  </li>
<li><strong>生成合成样本</strong>：使用 <strong>SMOTE</strong>（Synthetic Minority Over-sampling Technique）生成新样本（通过插值法）。  </li>
<li><strong>改进版算法</strong>：如 <strong>ADASYN</strong>（自适应合成采样），根据样本分布动态生成数据。  </li>
</ul>
</li>
<li><p><strong>欠采样（Undersampling）</strong>  </p>
<ul>
<li><strong>随机删除多数类样本</strong>：减少多数类数量，但可能丢失重要信息。  </li>
<li><strong>选择性欠采样</strong>：保留多数类中更具代表性的样本（如 <strong>Tomek Links</strong> 或 <strong>Cluster Centroids</strong>）。  </li>
</ul>
</li>
<li><p><strong>混合采样</strong><br>结合过采样和欠采样（如先过采样少数类，再欠采样多数类）。</p>
</li>
</ul>
<p><strong>2.2 算法层面调整</strong></p>
<ul>
<li><p><strong>调整类别权重（Class Weight）</strong>  </p>
<ul>
<li>为少数类分配更高的权重（如 <code>class_weight=&#39;balanced&#39;</code>），让模型更关注少数类。  </li>
<li>公式：<br>[<br>\text{权重} = \frac{\text{多数类样本数}}{\text{少数类样本数}}<br>]</li>
</ul>
</li>
<li><p><strong>集成学习（Ensemble Methods）</strong>  </p>
<ul>
<li><strong>EasyEnsemble</strong>：从多数类中随机采样多个子集，分别与少数类结合训练多个模型，集成结果。  </li>
<li><strong>BalanceCascade</strong>：逐步筛选多数类样本，避免冗余信息。  </li>
<li><strong>RUSBoost</strong>：结合欠采样和提升算法（Boosting）。  </li>
</ul>
</li>
<li><p><strong>改进损失函数</strong>  </p>
<ul>
<li><strong>Focal Loss</strong>：降低易分类样本的权重，聚焦于难分类的少数类样本。  </li>
<li><strong>Cost-sensitive Learning</strong>：为不同类别分配不同的误分类代价。  </li>
</ul>
</li>
</ul>
<p><strong>2.3 评估指标调整</strong></p>
<ul>
<li><strong>避免使用准确率（Accuracy）</strong>，改用以下指标：  <ul>
<li><strong>F1-Score</strong>：精确率（Precision）和召回率（Recall）的调和平均。  </li>
<li><strong>AUC-ROC 曲线</strong>：衡量分类器在不同阈值下的整体性能。  </li>
<li><strong>精确率-召回率曲线（PR Curve）</strong>：关注少数类的识别能力。  </li>
<li><strong>平衡准确率（Balanced Accuracy）</strong>：计算每个类别的召回率的平均值。  </li>
</ul>
</li>
</ul>
<p><strong>2.4 高级技术</strong></p>
<ul>
<li><p><strong>异常检测（Anomaly Detection）</strong><br>将少数类视为异常，使用 One-Class SVM 或孤立森林（Isolation Forest）检测。  </p>
</li>
<li><p><strong>生成对抗网络（GAN）</strong><br>使用 GAN 生成高质量的少数类样本（如医疗数据中的罕见病样本）。  </p>
</li>
<li><p><strong>阈值调整</strong><br>根据业务需求调整分类阈值（如将欺诈检测的阈值从 0.5 降低到 0.3）。  </p>
</li>
</ul>
<p><strong>3. 实际应用建议</strong></p>
<ul>
<li><strong>场景举例</strong>：  <ul>
<li><strong>欺诈检测</strong>：少数类（欺诈）样本极少，需使用 SMOTE + 集成学习。  </li>
<li><strong>医疗诊断</strong>：罕见病识别可尝试 GAN 生成数据或异常检测。  </li>
</ul>
</li>
<li><strong>工具库</strong>：  <ul>
<li>Python 的 <code>imbalanced-learn</code>（提供 SMOTE、EasyEnsemble 等）。  </li>
<li>TensorFlow/PyTorch 中的 <code>class_weight</code> 参数。  </li>
</ul>
</li>
</ul>
<p><strong>总结</strong></p>
<p>类别不均衡的核心是让模型“看到”足够的少数类信息，同时选择合适的评估指标。根据数据特点和业务需求，灵活组合数据采样、算法改进和评估方法，才能有效提升模型对少数类的识别能力。</p>
<h4 id="关于误差逆传播BP算法，详细推导E-k对w-hj的导数和对v-ih的导数。"><a href="#关于误差逆传播BP算法，详细推导E-k对w-hj的导数和对v-ih的导数。" class="headerlink" title="关于误差逆传播BP算法，详细推导E_k对w_hj的导数和对v_ih的导数。"></a>关于误差逆传播BP算法，详细推导E_k对w_hj的导数和对v_ih的导数。</h4><p>以下是误差逆传播（Backpropagation, BP）算法中误差 ( E<em>k ) 对权重 ( w</em>{hj} )（输出层权重）和 ( v_{ih} )（隐藏层权重）的详细导数推导过程：</p>
<p><strong>符号定义</strong></p>
<ul>
<li><strong>输入层节点</strong>：( $x_i$ )（( i = 1, 2, $\dots, n $)）  </li>
<li><strong>隐藏层节点</strong>：( $b_h$ )（( h = 1, 2, $\dots, q $)）  </li>
<li><strong>输出层节点</strong>：( $y_j$ )（( j = 1, 2,$ \dots, l $)）  </li>
<li><strong>隐藏层到输出层的权重</strong>：( $w_{hj}$ )（从隐藏层节点 ( h ) 到输出层节点 ( j )）  </li>
<li><strong>输入层到隐藏层的权重</strong>：( $v_{ih}$ )（从输入层节点 ( i ) 到隐藏层节点 ( h )）  </li>
<li><strong>激活函数</strong>：假设为 Sigmoid 函数 ($ f(x) = \frac{1}{1 + e^{-x}} $)，其导数为 ($ f’(x) = f(x)(1 - f(x)) $)  </li>
<li><strong>损失函数</strong>：均方误差 ($ E<em>k = \frac{1}{2} \sum</em>{j=1}^l (y_j - \hat{y}_j)^2 $)，其中 ( $\hat{y}_j $) 是真实标签。</li>
</ul>
<p><strong>1. 计算 ( $\frac{\partial E<em>k}{\partial w</em>{hj}} $)（输出层权重的梯度）</strong></p>
<p><strong>步骤分解</strong>：  </p>
<ol>
<li><p><strong>输出层输入</strong>：<br>[<br>$net<em>j = \sum</em>{h=1}^q w_{hj} b_h$<br>]<br>输出层节点的激活值为 ( $y_j = f(net_j)$ )。</p>
</li>
<li><p><strong>损失函数对 ( net_j ) 的导数</strong>：<br>[<br>$\frac{\partial E_k}{\partial net_j} = \frac{\partial E_k}{\partial y_j} \cdot \frac{\partial y_j}{\partial net_j}$<br>]</p>
<ul>
<li>( $\frac{\partial E_k}{\partial y_j} = (y_j - \hat{y}_j)$ )（均方误差导数）  </li>
<li>( $\frac{\partial y_j}{\partial net_j} = f’(net_j) = y_j (1 - y_j) $)（Sigmoid 导数）<br>因此：<br>[<br>$\frac{\partial E_k}{\partial net_j} = (y_j - \hat{y}_j) \cdot y_j (1 - y_j)$<br>]</li>
</ul>
</li>
<li><p><strong>损失函数对 ( w_{hj} ) 的导数</strong>：<br>[<br>$\frac{\partial E<em>k}{\partial w</em>{hj}} = \frac{\partial E<em>k}{\partial net_j} \cdot \frac{\partial net_j}{\partial w</em>{hj}}$<br>]</p>
<ul>
<li>( $\frac{\partial net<em>j}{\partial w</em>{hj}} = b<em>h$ )（因为 ( $net_j = \sum w</em>{hj} b<em>h $)）<br>因此：<br>[<br>$\frac{\partial E_k}{\partial w</em>{hj}} = (y_j - \hat{y}_j) \cdot y_j (1 - y_j) \cdot b_h$<br>]</li>
</ul>
</li>
</ol>
<p><strong>2. 计算 ( $\frac{\partial E<em>k}{\partial v</em>{ih}} $)（隐藏层权重的梯度）</strong></p>
<p><strong>步骤分解</strong>：  </p>
<ol>
<li><p><strong>隐藏层输入</strong>：<br>[<br>$net<em>h = \sum</em>{i=1}^n v_{ih} x_i$<br>]<br>隐藏层节点的激活值为 ($ b_h = f(net_h) $)。</p>
</li>
<li><p><strong>损失函数对 ( net_h ) 的导数</strong>：<br>需要将误差从输出层反向传播到隐藏层：<br>[<br>$\frac{\partial E<em>k}{\partial net_h} = \sum</em>{j=1}^l \left( \frac{\partial E_k}{\partial net_j} \cdot \frac{\partial net_j}{\partial b_h} \right) \cdot \frac{\partial b_h}{\partial net_h}$<br>]</p>
<ul>
<li>($ \frac{\partial net<em>j}{\partial b_h} = w</em>{hj} $)（输出层输入依赖于隐藏层输出 ( b_h )）  </li>
<li>($ \frac{\partial b<em>h}{\partial net_h} = f’(net_h) = b_h (1 - b_h) $)<br>因此：<br>[<br>$\frac{\partial E_k}{\partial net_h} = \left( \sum</em>{j=1}^l \frac{\partial E<em>k}{\partial net_j} \cdot w</em>{hj} \right) \cdot b_h (1 - b_h)$<br>]</li>
</ul>
</li>
<li><p><strong>损失函数对 ( v_{ih} ) 的导数</strong>：<br>[<br>$\frac{\partial E<em>k}{\partial v</em>{ih}} = \frac{\partial E<em>k}{\partial net_h} \cdot \frac{\partial net_h}{\partial v</em>{ih}}$<br>]</p>
<ul>
<li>($ \frac{\partial net<em>h}{\partial v</em>{ih}} = x<em>i $)（因为 ($ net_h = \sum v</em>{ih} x<em>i $）<br>因此：<br>[<br>$\frac{\partial E_k}{\partial v</em>{ih}} = \left( \sum<em>{j=1}^l \frac{\partial E_k}{\partial net_j} \cdot w</em>{hj} \right) \cdot b_h (1 - b_h) \cdot x_i$<br>]</li>
</ul>
</li>
</ol>
<p><strong>3. 最终梯度公式</strong></p>
<ul>
<li><p><strong>输出层权重梯度</strong>：<br>[<br>$\frac{\partial E<em>k}{\partial w</em>{hj}} = \delta_j \cdot b_h, \quad \text{其中 } \delta_j = (y_j - \hat{y}_j) \cdot y_j (1 - y_j)$<br>]</p>
</li>
<li><p><strong>隐藏层权重梯度</strong>：<br>[<br>$\frac{\partial E<em>k}{\partial v</em>{ih}} = \delta<em>h \cdot x_i, \quad \text{其中 } \delta_h = \left( \sum</em>{j=1}^l \delta<em>j \cdot w</em>{hj} \right) \cdot b_h (1 - b_h)$<br>]</p>
</li>
</ul>
<p><strong>4. 参数更新规则</strong></p>
<p>使用梯度下降法更新权重：  </p>
<ol>
<li><p><strong>输出层权重更新</strong>：<br>[<br>$w<em>{hj} \leftarrow w</em>{hj} - \eta \cdot \frac{\partial E<em>k}{\partial w</em>{hj}}$<br>]</p>
</li>
<li><p><strong>隐藏层权重更新</strong>：<br>[<br>$v<em>{ih} \leftarrow v</em>{ih} - \eta \cdot \frac{\partial E<em>k}{\partial v</em>{ih}}$<br>]<br>其中，( $\eta $) 是学习率。</p>
</li>
</ol>
<p><strong>关键点总结</strong></p>
<ol>
<li><strong>链式法则</strong>：通过逐层反向传播误差，将全局误差分解为对每个权重的局部梯度。  </li>
<li><strong>敏感度（Delta）</strong>：  <ul>
<li>输出层：($ \delta_j = (y_j - \hat{y}_j) \cdot f’(net_j)$ )  </li>
<li>隐藏层：($ \delta<em>h = \left( \sum \delta_j w</em>{hj} \right) \cdot f’(net_h)$ )  </li>
</ul>
</li>
<li><strong>高效性</strong>：通过存储中间结果（如 ( \delta_j )），避免重复计算，降低时间复杂度。</li>
</ol>
<p>如果需要进一步解释具体步骤或示例，请随时告诉我！ 😊</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1oY411N7Xz/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">[5分钟深度学习] #01 梯度下降算法_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1zV4y1R7B4/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">反向传播算法可视化展示_哔哩哔哩_bilibili</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/" class="post-title-link" itemprop="url">机器学习——上机4——决策树</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-03 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-03T00:00:00+08:00">2025-04-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-04-04 20:12:21" itemprop="dateModified" datetime="2025-04-04T20:12:21+08:00">2025-04-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="上机实验：决策树"><a href="#上机实验：决策树" class="headerlink" title="上机实验：决策树"></a>上机实验：决策树</h1><h2 id="任务1：分支节点的选择方法"><a href="#任务1：分支节点的选择方法" class="headerlink" title="任务1：分支节点的选择方法"></a>任务1：分支节点的选择方法</h2><p>现有一个数据集 weekend.txt，目标是根据一个人的特征来预测其周末是否出行。</p>
<p>所有特征均为二元特征，取值为 0 或 1，其中“status”（目标特征也是类别）表示用户的周末是否出行，1 表示出行，0 表示不出行，“marriageStatus”表示申请人是否已婚、“hasChild”表示申请人是否有小孩、“hasAppointment”表示申请人是否有约、“weather”表示天气是否晴朗。</p>
<p>已知信息熵和信息增益的公式为：</p>
<script type="math/tex; mode=display">\text{Entropy}(D)=-\sum_{k=1}^{C}p_k \cdot log_2(p_k)</script><script type="math/tex; mode=display">\text{InfoGain}(D, a)=\text{Entropy}(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|} \cdot\text{Entropy}(D^v)</script><p>请完成以下三个内容：</p>
<ul>
<li><p>请自定义函数 cal_entropy(data, feature_name)计算数据集data关于feature_name的信息熵。输入参数 data 为 DataFrame，feature_name 为目标特征(或类别)的名称；</p>
</li>
<li><p>请调用 cal_entropy() 函数计算决策树分支之前的信息熵，保存为 data_entropy；</p>
</li>
<li><p>请自定义函数 cal_infoGain(data, base_entropy) 计算 weekend.txt 中各个特征的信息增益，保存为列表 infogains，并选择信息增益最大的分支节点 best_feature。</p>
</li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入必要库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据（假设文件为tab分隔，包含特征和目标变量&#x27;status&#x27;）</span></span><br><span class="line">weekend_data = pd.read_table(<span class="string">&#x27;weekend.txt&#x27;</span>, sep=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义熵计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数（如：status特征中&quot;出门&quot;和&quot;不出门&quot;的数量）</span></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（注意：熵公式为负数求和）</span></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算初始信息熵（假设目标特征列为&#x27;status&#x27;）</span></span><br><span class="line">data_entropy = cal_entropy(weekend_data, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义信息增益计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 获取所有特征名称</span></span><br><span class="line">    feature_list.remove(<span class="string">&#x27;status&#x27;</span>)  <span class="comment"># 移除目标特征（避免计算自身）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布（如：天气特征的&quot;晴朗/下雨/阴天&quot;）</span></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历特征的每个取值</span></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line">            <span class="comment"># 获取特征取当前值的子集</span></span><br><span class="line">            subset = data[data[feature] == value]</span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算子集的熵并累加加权熵</span></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算信息增益（信息增益 = 基础熵 - 条件熵）</span></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到信息增益最大的特征</span></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大增益值</span></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 对应的最优特征名称</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"><span class="comment">## 执行信息增益计算</span></span><br><span class="line">infogains, best_feature = cal_infoGain(weekend_data, data_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 结果输出</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;各特征的信息增益：&#x27;</span>, infogains)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n信息增益最大的特征：&#x27;</span>, best_feature)</span><br></pre></td></tr></table></figure>
<pre><code>各特征的信息增益： [0.0076, 0.0076, 0.0322, 0.0868]
</code></pre><p>​    </p>
<pre><code>信息增益最大的特征： weather
</code></pre><blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc" alt></p>
<h2 id="任务2：常见的决策树算法"><a href="#任务2：常见的决策树算法" class="headerlink" title="任务2：常见的决策树算法"></a>任务2：常见的决策树算法</h2><p>现在有一份有关商品销量的数据集product.csv，数据集的离散型特征信息如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>特征名称</th>
<th>取值说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>天气</td>
<td>1：天气好；0：天气坏</td>
</tr>
<tr>
<td>是否周末</td>
<td>1：是；0：不是</td>
</tr>
<tr>
<td>是否有促销</td>
<td>1：有促销；0：没有促销</td>
</tr>
<tr>
<td>销量</td>
<td>1：销量高；0：销量低</td>
</tr>
</tbody>
</table>
</div>
<p>请完成以下三个内容：</p>
<ul>
<li>请根据提供的商品销量数据集 data，使用 sklearn 中的 DecisionTreeClassifier()函数构建决策树模型，模型选择分支结点的特征以Gini指数为判定准则；</li>
<li>训练模型，并对测试集test_X进行预测，将预测结果存为 pred_y，进行模型评估；</li>
<li>将构建的决策树模型进行可视化。</li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz  <span class="comment"># 补全export_graphviz导入</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;product.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取除目标特征以外的其他特征的数据记录X</span></span><br><span class="line">X = data[[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>]]  <span class="comment"># 使用双括号选择多列</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取目标特征`销量`的数据记录y</span></span><br><span class="line">y = data[<span class="string">&quot;销量&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用train_test_split函数划分训练集train_X, train_y和测试集test_X, test_y</span></span><br><span class="line"><span class="comment">## 测试集所占比例为0.1,random_state为0</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 构建分支节点选择方法为基尼指数的决策树模型tree_model，进行模型训练、测试与性能评估</span></span><br><span class="line">tree_model = DecisionTreeClassifier(criterion=<span class="string">&#x27;gini&#x27;</span>)  <span class="comment"># 设置基尼指数准则</span></span><br><span class="line">tree_model.fit(train_X, train_y)  <span class="comment"># 模型训练</span></span><br><span class="line"></span><br><span class="line">pred_y = tree_model.predict(test_X)  <span class="comment"># 测试集预测</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型分类报告：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y))  <span class="comment"># 输出评估报告</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 决策树可视化（修正特征名称与数据列一致）</span></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line">dot_data = export_graphviz(</span><br><span class="line">    tree_model,</span><br><span class="line">    out_file=<span class="literal">None</span>,</span><br><span class="line">    feature_names=[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>],  <span class="comment"># 修正为完整特征名称</span></span><br><span class="line">    class_names=[<span class="string">&quot;销量低&quot;</span>, <span class="string">&quot;销量高&quot;</span>],</span><br><span class="line">    filled=<span class="literal">True</span>,</span><br><span class="line">    rounded=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph</span><br></pre></td></tr></table></figure>
<pre><code>模型分类报告：

              precision    recall  f1-score   support
</code></pre><p>​    </p>
<pre><code>           0       1.00      0.50      0.67         2

           1       0.67      1.00      0.80         2
</code></pre><p>​    </p>
<pre><code>    accuracy                           0.75         4

   macro avg       0.83      0.75      0.73         4

weighted avg       0.83      0.75      0.73         4
</code></pre><p>​    </p>
<p>​<br><img src="/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/main_7_1.svg" alt="svg"><br>​    </p>
<blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/f7c9f4d97660416b9ac354a1bcd6c87efcb7a0958cfa4579bf70a83d01ee64f7" alt><br><img src="https://ai-studio-static-online.cdn.bcebos.com/eb46fe19bf43414290f904042a511f25140e1908a2eb4c2e81c52450f1de68bd" alt></p>
<h2 id="任务3：利用任务1的cal-infoGain函数自行实现ID3决策树算法"><a href="#任务3：利用任务1的cal-infoGain函数自行实现ID3决策树算法" class="headerlink" title="任务3：利用任务1的cal_infoGain函数自行实现ID3决策树算法"></a>任务3：利用任务1的cal_infoGain函数自行实现ID3决策树算法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的熵计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line"></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数分布</span></span><br><span class="line"></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line"></span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（Σ -p_i log2(p_i)）</span></span><br><span class="line"></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的信息增益计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line"></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line"></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 所有特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自动识别目标特征（假设目标特征不在特征列表中）</span></span><br><span class="line"></span><br><span class="line">    target_feature = [col <span class="keyword">for</span> col <span class="keyword">in</span> feature_list <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> data.columns][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    feature_list = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]  <span class="comment"># 移除目标特征</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line"></span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布</span></span><br><span class="line"></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line"></span><br><span class="line">            subset = data[data[feature] == value]  <span class="comment"># 特征取当前值的子集</span></span><br><span class="line"></span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line"></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 累加加权熵</span></span><br><span class="line"></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, target_feature)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算信息增益</span></span><br><span class="line"></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line"></span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 选择最优特征</span></span><br><span class="line"></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大信息增益值</span></span><br><span class="line"></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line"></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 最优特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## ID3决策树实现</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ID3DecisionTree</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="literal">None</span>  <span class="comment"># 存储决策树结构</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = <span class="literal">None</span>  <span class="comment"># 目标特征名称</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, data, target_feature</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        训练决策树模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 包含特征和目标列的DataFrame</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param target_feature: 目标特征名称（如&#x27;销量&#x27;）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = target_feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取特征列表（排除目标特征）</span></span><br><span class="line"></span><br><span class="line">        features = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建决策树</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="variable language_">self</span>._build_tree(data, features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_tree</span>(<span class="params">self, data, features</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 当前节点的数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param features: 当前可用的特征列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 字典形式的树节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件1：所有样本属于同一类别</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(data[<span class="variable language_">self</span>.target].unique()) == <span class="number">1</span>:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: data[<span class="variable language_">self</span>.target].values[<span class="number">0</span>],  <span class="comment"># 叶节点类别</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件2：无剩余特征可用时选择多数类</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> features:</span><br><span class="line"></span><br><span class="line">            class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),  <span class="comment"># 多数类</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算当前数据集的熵</span></span><br><span class="line"></span><br><span class="line">        base_entropy = cal_entropy(data, <span class="variable language_">self</span>.target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取最优特征和信息增益列表</span></span><br><span class="line"></span><br><span class="line">        info_gains, best_feature = cal_infoGain(data, base_entropy)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建当前树节点</span></span><br><span class="line"></span><br><span class="line">        node = &#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;feature&#x27;</span>: best_feature,  <span class="comment"># 分裂特征</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;info_gain&#x27;</span>: info_gains[features.index(best_feature)],  <span class="comment"># 信息增益值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data),  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;children&#x27;</span>: &#123;&#125;  <span class="comment"># 子节点</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建子树（排除当前最优特征）</span></span><br><span class="line"></span><br><span class="line">        remaining_features = [f <span class="keyword">for</span> f <span class="keyword">in</span> features <span class="keyword">if</span> f != best_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历最优特征的所有取值</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> data[best_feature].unique():</span><br><span class="line"></span><br><span class="line">            subset = data[data[best_feature] == value]  <span class="comment"># 获取子集</span></span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 处理空子集（采用父节点多数类）</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> subset.empty:</span><br><span class="line"></span><br><span class="line">                class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;samples&#x27;</span>: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 递归构建子树</span></span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = <span class="variable language_">self</span>._build_tree(subset, remaining_features)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        对新样本进行预测</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param X: 特征数据（DataFrame格式）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 预测结果列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        predictions = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历每个样本</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _, sample <span class="keyword">in</span> X.iterrows():</span><br><span class="line"></span><br><span class="line">            current_node = <span class="variable language_">self</span>.tree</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 遍历树直到叶节点</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                feature = current_node[<span class="string">&#x27;feature&#x27;</span>]  <span class="comment"># 当前分裂特征</span></span><br><span class="line"></span><br><span class="line">                value = sample[feature]  <span class="comment"># 样本在该特征的取值</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 处理未见过的特征值（采用当前节点多数类）</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> value <span class="keyword">not</span> <span class="keyword">in</span> current_node[<span class="string">&#x27;children&#x27;</span>]:</span><br><span class="line"></span><br><span class="line">                    class_counts = <span class="variable language_">self</span>._get_class_counts(current_node)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 选择样本数最多的类别</span></span><br><span class="line"></span><br><span class="line">                    predictions.append(<span class="built_in">max</span>(class_counts, key=class_counts.get))</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">break</span>  <span class="comment"># 跳出循环</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 移动到子节点</span></span><br><span class="line"></span><br><span class="line">                current_node = current_node[<span class="string">&#x27;children&#x27;</span>][value]</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 记录叶节点类别</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                predictions.append(current_node[<span class="string">&#x27;class&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_class_counts</span>(<span class="params">self, node</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归统计节点中的类别分布</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 类别计数字典</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        counts = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果是叶节点直接返回</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;node[<span class="string">&#x27;class&#x27;</span>]: node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归统计子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].values():</span><br><span class="line"></span><br><span class="line">            child_counts = <span class="variable language_">self</span>._get_class_counts(child)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> cls, cnt <span class="keyword">in</span> child_counts.items():</span><br><span class="line"></span><br><span class="line">                counts[cls] = counts.get(cls, <span class="number">0</span>) + cnt</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> counts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">visualize</span>(<span class="params">self, feature_names, class_names</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        可视化决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: graphviz对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        dot = graphviz.Digraph()  <span class="comment"># 创建有向图</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建图形</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._build_graph(dot, <span class="variable language_">self</span>.tree, feature_names, class_names)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_graph</span>(<span class="params">self, dot, node, feature_names, class_names, parent=<span class="literal">None</span>, edge_label=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建graphviz图形</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param dot: graphviz.Digraph对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param parent: 父节点（用于连接边）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param edge_label: 边标签（特征取值）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 叶节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;class_names[<span class="built_in">int</span>(node[<span class="string">&#x27;class&#x27;</span>])]&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),  <span class="comment"># 唯一节点ID</span></span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;box&quot;</span>,  <span class="comment"># 矩形框</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,  <span class="comment"># 填充颜色</span></span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightblue&quot;</span>  <span class="comment"># 浅蓝色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 内部节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;node[<span class="string">&#x27;feature&#x27;</span>]&#125;</span>\\nIG=<span class="subst">&#123;node[<span class="string">&#x27;info_gain&#x27;</span>]:<span class="number">.3</span>f&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;ellipse&quot;</span>,  <span class="comment"># 椭圆</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,</span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightgreen&quot;</span>  <span class="comment"># 浅绿色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建父节点到当前节点的边</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> parent:</span><br><span class="line"></span><br><span class="line">            dot.edge(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(parent)),</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label=edge_label  <span class="comment"># 显示特征取值</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归处理子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> value, child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].items():</span><br><span class="line"></span><br><span class="line">                <span class="variable language_">self</span>._build_graph(</span><br><span class="line"></span><br><span class="line">                    dot,</span><br><span class="line"></span><br><span class="line">                    child,</span><br><span class="line"></span><br><span class="line">                    feature_names,</span><br><span class="line"></span><br><span class="line">                    class_names,</span><br><span class="line"></span><br><span class="line">                    node,  <span class="comment"># 当前节点作为父节点</span></span><br><span class="line"></span><br><span class="line">                    <span class="built_in">str</span>(value)  <span class="comment"># 边标签为特征取值</span></span><br><span class="line"></span><br><span class="line">                )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A2/" class="post-title-link" itemprop="url">计算机系统基础——上机作业2</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-03-31 00:00:00 / 修改时间：15:53:32" itemprop="dateCreated datePublished" datetime="2025-03-31T00:00:00+08:00">2025-03-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">计算机系统基础</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="实验1：变量输出与机器数分析"><a href="#实验1：变量输出与机器数分析" class="headerlink" title="实验1：变量输出与机器数分析"></a><strong>实验1：变量输出与机器数分析</strong></h3><h4 id="1-1-运行代码并分析输出"><a href="#1-1-运行代码并分析输出" class="headerlink" title="1.1 运行代码并分析输出"></a><strong>1.1 运行代码并分析输出</strong></h4><p><strong>源代码</strong>：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> x = <span class="number">-1</span>;</span><br><span class="line">    <span class="type">unsigned</span> u = <span class="number">2147483648</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x = %u = %d.\n&quot;</span>, x, x);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;u = %u = %d.\n&quot;</span>, u, u);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>编译与运行</strong>：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc -o test1 test1.c</span><br><span class="line">./test1</span><br></pre></td></tr></table></figure></p>
<p><strong>输出结果</strong>（假设32位系统）：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = 4294967295 = -1.</span><br><span class="line">u = 2147483648 = -2147483648.</span><br></pre></td></tr></table></figure></p>
<p><strong>结果分析</strong>：</p>
<ul>
<li><strong><code>x = %u</code></strong>：<br><code>x</code> 是 <code>int</code> 类型的 <code>-1</code>，二进制补码为 <code>0xFFFFFFFF</code>。用 <code>%u</code>（无符号）解释时，<code>0xFFFFFFFF</code> 对应 <code>4294967295</code>。</li>
<li><strong><code>x = %d</code></strong>：<br>正常输出 <code>-1</code>。</li>
<li><strong><code>u = %u</code></strong>：<br><code>u</code> 是 <code>unsigned</code> 类型的 <code>2147483648</code>（即 <code>0x80000000</code>），直接输出为 <code>2147483648</code>。</li>
<li><strong><code>u = %d</code></strong>：<br>用 <code>%d</code>（有符号）解释 <code>0x80000000</code>，最高位为1，表示负数，结果为 <code>-2147483648</code>。</li>
</ul>
<hr>
<h4 id="1-2-反汇编分析机器数"><a href="#1-2-反汇编分析机器数" class="headerlink" title="1.2 反汇编分析机器数"></a><strong>1.2 反汇编分析机器数</strong></h4><p><strong>步骤</strong>：</p>
<ol>
<li>生成目标文件：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -c test1.c -o test1.o</span><br></pre></td></tr></table></figure></li>
<li>反汇编查看变量赋值：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objdump -d -M intel test1.o</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>关键汇编代码</strong>（简化）：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mov DWORD PTR [rbp-4], 0xffffffff   ; x = -1 (机器数 0xFFFFFFFF)</span><br><span class="line">mov DWORD PTR [rbp-8], 0x80000000   ; u = 2147483648 (机器数 0x80000000)</span><br></pre></td></tr></table></figure></p>
<p><strong>变量机器数总结</strong>：<br>| 变量 | 机器数（十六进制） |<br>| —— | ————————— |<br>| x    | 0xFFFFFFFF         |<br>| u    | 0x80000000         |</p>
<hr>
<h3 id="实验2：表达式结果与反汇编分析"><a href="#实验2：表达式结果与反汇编分析" class="headerlink" title="实验2：表达式结果与反汇编分析"></a><strong>实验2：表达式结果与反汇编分析</strong></h3><h4 id="2-1-验证表达式结果"><a href="#2-1-验证表达式结果" class="headerlink" title="2.1 验证表达式结果"></a><strong>2.1 验证表达式结果</strong></h4><p><strong>源代码</strong>：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;-1 &lt; 0\t\t -&gt; %d\n&quot;</span>, (<span class="number">-1</span> &lt; <span class="number">0</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;-1 &lt; 0U\t -&gt; %d\n&quot;</span>, (<span class="number">-1</span> &lt; <span class="number">0U</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;2147483647 &gt; -2147483647 - 1\t -&gt; %d\n&quot;</span>, (<span class="number">2147483647</span> &gt; <span class="number">-2147483647</span> - <span class="number">1</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;2147483647U &gt; -2147483647 - 1\t -&gt; %d\n&quot;</span>, (<span class="number">2147483647U</span> &gt; <span class="number">-2147483647</span> - <span class="number">1</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>编译与运行</strong>：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc -o test2 test2.c</span><br><span class="line">./test2</span><br></pre></td></tr></table></figure></p>
<p><strong>输出结果</strong>：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-1 &lt; 0           -&gt; 1</span><br><span class="line">-1 &lt; 0U          -&gt; 0</span><br><span class="line">2147483647 &gt; -2147483647 - 1  -&gt; 1</span><br><span class="line">2147483647U &gt; -2147483647 - 1 -&gt; 0</span><br></pre></td></tr></table></figure></p>
<p><strong>结果分析</strong>：</p>
<ol>
<li><strong><code>-1 &lt; 0</code></strong>：<br>有符号比较，<code>-1</code> 小于 <code>0</code>，结果为真（<code>1</code>）。</li>
<li><strong><code>-1 &lt; 0U</code></strong>：<br><code>0U</code> 是无符号，<code>-1</code> 被转换为无符号数 <code>0xFFFFFFFF</code>（4294967295），远大于 <code>0U</code>，结果为假（<code>0</code>）。</li>
<li><strong><code>2147483647 &gt; -2147483647 - 1</code></strong>：<br>右侧表达式 <code>-2147483647 - 1</code> 等于 <code>-2147483648</code>（<code>INT_MIN</code>），有符号比较，<code>2147483647</code>（<code>INT_MAX</code>）大于 <code>INT_MIN</code>，结果为真（<code>1</code>）。</li>
<li><strong><code>2147483647U &gt; -2147483647 - 1</code></strong>：<br>左侧是无符号，右侧 <code>INT_MIN</code> 被转换为无符号数 <code>0x80000000</code>（2147483648），比较 <code>2147483647</code> 和 <code>2147483648</code>，结果为假（<code>0</code>）。</li>
</ol>
<hr>
<h4 id="2-2-反汇编分析表达式"><a href="#2-2-反汇编分析表达式" class="headerlink" title="2.2 反汇编分析表达式"></a><strong>2.2 反汇编分析表达式</strong></h4><p><strong>步骤</strong>：</p>
<ol>
<li>生成目标文件：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -c test2.c -o test2.o</span><br></pre></td></tr></table></figure></li>
<li>反汇编查看比较指令：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objdump -d -M intel test2.o</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>关键汇编代码</strong>（以 <code>-1 &lt; 0U</code> 为例）：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov DWORD PTR [rbp-4], 0xffffffff   ; -1 的机器数</span><br><span class="line">cmp DWORD PTR [rbp-4], 0            ; 比较时，-1 被视为无符号数 4294967295</span><br><span class="line">setb al                             ; 设置结果（0 表示假）</span><br></pre></td></tr></table></figure></p>
<p><strong>总结</strong>：</p>
<ul>
<li>类型转换规则决定了比较结果。</li>
<li>反汇编显示编译器如何处理有符号与无符号的隐式转换。</li>
</ul>
<hr>
<h3 id="实验报告建议"><a href="#实验报告建议" class="headerlink" title="实验报告建议"></a><strong>实验报告建议</strong></h3><ol>
<li><strong>源代码与输出结果</strong>：附上代码及运行结果。</li>
<li><strong>反汇编截图</strong>：展示变量赋值和表达式比较的汇编代码。</li>
<li><strong>分析</strong>：<ul>
<li>解释类型转换对输出的影响。</li>
<li>说明反汇编中机器数与表达式比较的底层实现。</li>
</ul>
</li>
</ol>
<p>如果需要更详细的反汇编代码或具体步骤解释，请随时告知！</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A1/" class="post-title-link" itemprop="url">计算机系统基础——上机作业1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-03-31 00:00:00 / 修改时间：15:42:32" itemprop="dateCreated datePublished" datetime="2025-03-31T00:00:00+08:00">2025-03-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">计算机系统基础</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>安装vmware虚拟机</p>
<p>安装ubuntu</p>
<h2 id="在Ubuntu终端里编写C语言程序"><a href="#在Ubuntu终端里编写C语言程序" class="headerlink" title="在Ubuntu终端里编写C语言程序"></a>在Ubuntu终端里编写C语言程序</h2><p> 打开终端：ctrl+alt+t</p>
<p>新建文件：<strong>vim hello.c</strong></p>
<p>输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#define DISPLAY &quot;hello c!&quot;</span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">  printf(&quot;%s\n&quot;, DISPLAY);</span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br><span class="line">ZZ（*说明：ZZ当前文件进行快速保存操作*）</span><br></pre></td></tr></table></figure>
<p>退出编译模式：shift+：</p>
<p>输入：w保存q退出</p>
<p><strong>预编译(Preprocessing)</strong></p>
<p><em>对各种预处理指令（#include #define #ifdef 等#开始的代码行）进行处理，删除注释和多余的空白字符，生成一份新的代码</em></p>
<p>输入：<strong>gcc -E hello.c -o hello.i</strong></p>
<ol>
<li><strong>命令分解</strong></li>
</ol>
<ul>
<li><strong><code>gcc</code></strong> ：GNU Compiler Collection（GCC）的编译器命令。</li>
<li><strong><code>-E</code></strong> ：选项表示 <strong>仅执行预处理阶段</strong> ，不进行编译、汇编和链接。</li>
<li><strong><code>hello.c</code></strong> ：输入的C语言源文件。</li>
<li><strong><code>-o hello.i</code></strong> ：指定预处理后的输出文件名为 <code>hello.i</code>（<code>.i</code> 是预处理文件的默认后缀）。</li>
</ul>
<p><strong>2. 预处理阶段的作用</strong></p>
<p>预处理是编译过程的第一个阶段，主要处理以下内容：</p>
<ol>
<li>头文件展开 <ul>
<li>将 <code>#include &lt;stdio.h&gt;</code> 等指令替换为对应头文件的实际内容。</li>
</ul>
</li>
<li>宏展开 <ul>
<li>替换 <code>#define PI 3.14</code> 等宏定义。</li>
</ul>
</li>
<li>条件编译 <ul>
<li>处理 <code>#ifdef</code>, <code>#ifndef</code>, <code>#endif</code> 等条件编译指令。</li>
</ul>
</li>
<li>删除注释 <ul>
<li>移除代码中的注释（<code>//</code> 或 <code>/* */</code>）。</li>
</ul>
</li>
</ol>
<p><strong>编译(Compilation)</strong></p>
<p><em>对代码进行语法、语义分析和错误判断，生成汇编代码文件</em></p>
<p><strong>gcc -S hello.i -o hello.s</strong></p>
<p><strong>编译阶段的作用</strong></p>
<p>在编译流程中，<code>-S</code> 选项对应 <strong>编译阶段</strong> ，主要完成以下任务：</p>
<ol>
<li><strong>语法分析</strong> ：检查代码是否符合C语言语法规则。</li>
<li><strong>中间代码生成</strong> ：将预处理后的代码转换为中间表示（如抽象语法树）。</li>
<li><strong>优化</strong> ：根据优化选项（如 <code>-O2</code>）对代码进行优化。</li>
<li><strong>生成汇编代码</strong> ：将优化后的中间代码转换为目标平台的汇编指令（如x86-64汇编）。</li>
</ol>
<p><strong>汇编(Assembly)</strong></p>
<p><strong>gcc -c hello.s -o hello.o</strong></p>
<p><strong>汇编阶段的作用</strong></p>
<p>该命令执行 <strong>汇编阶段</strong> ，将人类可读的汇编代码（如 <code>mov</code>, <code>call</code> 等指令）转换为 <strong>二进制机器码</strong> ，生成目标文件（<code>.o</code>）。<br>目标文件包含：</p>
<ul>
<li>机器指令（二进制代码）。</li>
<li>符号表（函数名、变量名等）。</li>
<li>未解析的引用（如外部函数 <code>printf</code> 的地址）。</li>
</ul>
<p><strong>链接(Linking/Build)</strong></p>
<p><strong>gcc hello.o -o hello</strong></p>
<p><strong>链接阶段的作用</strong></p>
<p>链接器（<code>ld</code>）完成以下任务：</p>
<ol>
<li>合并代码和数据 <ul>
<li>将 <code>hello.o</code> 中的机器码与标准库（如 <code>stdio.h</code> 中的 <code>printf</code>）的二进制代码合并。</li>
</ul>
</li>
<li>解析符号引用 <ul>
<li>解决外部符号（如 <code>printf</code>）的地址，确保所有函数和全局变量正确关联。</li>
</ul>
</li>
<li>生成可执行文件格式 <ul>
<li>创建符合操作系统要求的可执行文件（如Linux的ELF格式）。</li>
</ul>
</li>
</ol>
<p><strong>程序运行</strong></p>
<p><strong>./hello</strong></p>
<h2 id="手动安装VMware-tools"><a href="#手动安装VMware-tools" class="headerlink" title="手动安装VMware tools"></a>手动安装VMware tools</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1F6DzY2Ep9/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">手动安装VMware Tools（提示VMware Tools 不再随旧版客户机操作系统的 VMware Workstation 一起提供的解决办法）_哔哩哔哩_bilibili</a></p>
<p><strong>在线安装</strong></p>
<p>如果方法一不行，可以试试方法二，我是通过方法二进行安装的。</p>
<p>首先更新系统已安装的软件源，以确保是最新的，在终端输入命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br></pre></td></tr></table></figure>
<p>然后再输入命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install open-vm-tools-desktop</span><br></pre></td></tr></table></figure>
<p>完成后运行upgrade命令，来升级系统中已安装的软件包(命令后面的 -y可以跳过确认询问)：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt upgrade -y</span><br></pre></td></tr></table></figure>
<p>完成后进行重启，重启过后，点击菜单栏查看，变成重新安装就是成功了。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A3/" class="post-title-link" itemprop="url">计算机系统基础——上机作业3</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-03-31 00:00:00 / 修改时间：16:25:38" itemprop="dateCreated datePublished" datetime="2025-03-31T00:00:00+08:00">2025-03-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">计算机系统基础</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>以下是针对表1和表2中所有函数的实现和验证分析，严格按照约束条件和操作符数量限制设计：</p>
<hr>
<h3 id="表1-位操作函数实现"><a href="#表1-位操作函数实现" class="headerlink" title="表1 位操作函数实现"></a><strong>表1 位操作函数实现</strong></h3><h4 id="1-lsbZero-将x的最低有效位清零"><a href="#1-lsbZero-将x的最低有效位清零" class="headerlink" title="1. lsbZero (将x的最低有效位清零)"></a><strong>1. lsbZero (将x的最低有效位清零)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">lsbZero</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> x &amp; (~<span class="number">1</span>);  <span class="comment">// 操作符: &amp; ~ 1 (共3个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x = 0x05 (0b101)</code> → <code>0x04 (0b100)</code></p>
<hr>
<h4 id="2-byteNot-将x的第n个字节取反"><a href="#2-byteNot-将x的第n个字节取反" class="headerlink" title="2. byteNot (将x的第n个字节取反)"></a><strong>2. byteNot (将x的第n个字节取反)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">byteNot</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = <span class="number">0xFF</span> &lt;&lt; (n &lt;&lt; <span class="number">3</span>);  <span class="comment">// 构造字节掩码</span></span><br><span class="line">    <span class="keyword">return</span> x ^ mask;               <span class="comment">// 操作符: &lt;&lt; &lt;&lt; 3 &lt;&lt; 8 (共6个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x = 0x12345678, n=1</code> → <code>0x1234A978</code>（第1字节 <code>0x56</code> 取反为 <code>0xA9</code>）</p>
<hr>
<h4 id="3-byteXor-比较x和y的第n个字节"><a href="#3-byteXor-比较x和y的第n个字节" class="headerlink" title="3. byteXor (比较x和y的第n个字节)"></a><strong>3. byteXor (比较x和y的第n个字节)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">byteXor</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> shift = n &lt;&lt; <span class="number">3</span>;</span><br><span class="line">    <span class="type">int</span> x_byte = (x &gt;&gt; shift) &amp; <span class="number">0xFF</span>;</span><br><span class="line">    <span class="type">int</span> y_byte = (y &gt;&gt; shift) &amp; <span class="number">0xFF</span>;</span><br><span class="line">    <span class="keyword">return</span> !!(x_byte ^ y_byte);  <span class="comment">// 操作符: &lt;&lt; &gt;&gt; &amp; ^ !! (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0x12345678, y=0x12745678, n=2</code> → <code>1</code>（第2字节 <code>0x34</code> vs <code>0x74</code>）</p>
<hr>
<h4 id="4-logicalAnd-模拟x-amp-amp-y"><a href="#4-logicalAnd-模拟x-amp-amp-y" class="headerlink" title="4. logicalAnd (模拟x &amp;&amp; y)"></a><strong>4. logicalAnd (模拟x &amp;&amp; y)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">logicalAnd</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (!!x) &amp; (!!y);  <span class="comment">// 操作符: !! &amp; (共2个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0, y=5</code> → <code>0</code>；<code>x=1, y=2</code> → <code>1</code></p>
<hr>
<h4 id="5-logicalOr-模拟x-y"><a href="#5-logicalOr-模拟x-y" class="headerlink" title="5. logicalOr (模拟x || y)"></a><strong>5. logicalOr (模拟x || y)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">logicalOr</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (!!x) | (!!y);  <span class="comment">// 操作符: !! | (共2个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0, y=0</code> → <code>0</code>；<code>x=0, y=1</code> → <code>1</code></p>
<hr>
<h4 id="6-rotateLeft-循环左移n位"><a href="#6-rotateLeft-循环左移n位" class="headerlink" title="6. rotateLeft (循环左移n位)"></a><strong>6. rotateLeft (循环左移n位)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">rotateLeft</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = (<span class="number">0xFF</span> &lt;&lt; <span class="number">24</span>) &gt;&gt; (<span class="number">32</span> - n);  <span class="comment">// 构造高位掩码</span></span><br><span class="line">    <span class="keyword">return</span> (x &lt;&lt; n) | ((x &gt;&gt; (<span class="number">32</span> - n)) &amp; mask);  <span class="comment">// 操作符: &lt;&lt; &gt;&gt; | &amp; (共25个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0x12345678, n=4</code> → <code>0x23456781</code>（左移4位，高位循环到低位）</p>
<hr>
<h4 id="7-parityCheck-奇偶校验"><a href="#7-parityCheck-奇偶校验" class="headerlink" title="7. parityCheck (奇偶校验)"></a><strong>7. parityCheck (奇偶校验)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">parityCheck</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">16</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">8</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">4</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">2</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> x &amp; <span class="number">1</span>;  <span class="comment">// 操作符: ^ &gt;&gt; &amp; (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0b1010</code> → <code>0</code>（2个1，偶数）；<code>x=0b101</code> → <code>1</code>（奇数）</p>
<hr>
<h3 id="表2-补码运算函数实现"><a href="#表2-补码运算函数实现" class="headerlink" title="表2 补码运算函数实现"></a><strong>表2 补码运算函数实现</strong></h3><h4 id="8-mul2OK-判断2-x是否溢出"><a href="#8-mul2OK-判断2-x是否溢出" class="headerlink" title="8. mul2OK (判断2*x是否溢出)"></a><strong>8. mul2OK (判断2*x是否溢出)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mul2OK</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> sign = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> result = x &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> !(((result &gt;&gt; <span class="number">31</span>) ^ sign) &amp; (!!(x ^ (x &lt;&lt; <span class="number">1</span>))));  <span class="comment">// 操作符: &gt;&gt; &lt;&lt; ^ &amp; !! (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0x40000000</code> → <code>0</code>（溢出）；<code>x=0x3FFFFFFF</code> → <code>1</code></p>
<hr>
<h4 id="9-mult3div2-计算-x-3-2"><a href="#9-mult3div2-计算-x-3-2" class="headerlink" title="9. mult3div2 (计算(x*3)/2)"></a><strong>9. mult3div2 (计算(x*3)/2)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mult3div2</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> temp = x + x + x;</span><br><span class="line">    <span class="type">int</span> sign = temp &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> (temp + (temp &gt;&gt; <span class="number">31</span> &amp; <span class="number">1</span>)) &gt;&gt; <span class="number">1</span>;  <span class="comment">// 操作符: + &gt;&gt; &amp; (共12个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=-3</code> → <code>(-9)/2 = -4</code>（向零取整）</p>
<hr>
<h4 id="10-subOK-判断x-y是否溢出"><a href="#10-subOK-判断x-y是否溢出" class="headerlink" title="10. subOK (判断x - y是否溢出)"></a><strong>10. subOK (判断x - y是否溢出)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">subOK</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="type">int</span> sub = x + (~y + <span class="number">1</span>);</span><br><span class="line">    <span class="type">int</span> x_sign = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> y_sign = (~y + <span class="number">1</span>) &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> sub_sign = sub &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> !((~(x_sign ^ y_sign)) &amp; (x_sign ^ sub_sign));  <span class="comment">// 操作符: ~ ^ + &gt;&gt; &amp; (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0x80000000, y=1</code> → <code>0</code>（溢出）</p>
<hr>
<h4 id="11-absVal-求绝对值"><a href="#11-absVal-求绝对值" class="headerlink" title="11. absVal (求绝对值)"></a><strong>11. absVal (求绝对值)</strong></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">absVal</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> (x + mask) ^ mask;  <span class="comment">// 操作符: &gt;&gt; + ^ (共10个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=-5</code> → <code>5</code>；<code>x=3</code> → <code>3</code></p>
<hr>
<h3 id="验证方法"><a href="#验证方法" class="headerlink" title="验证方法"></a><strong>验证方法</strong></h3><ol>
<li><strong>编写测试代码</strong>：为每个函数设计边界值（如0、最大值、最小值）。</li>
<li><strong>反汇编分析</strong>：使用 <code>objdump -d</code> 检查生成的机器码是否符合操作符限制。</li>
<li><strong>覆盖率测试</strong>：确保所有分支条件被触发（如正负数、溢出情况）。</li>
</ol>
<hr>
<h3 id="关键技巧"><a href="#关键技巧" class="headerlink" title="关键技巧"></a><strong>关键技巧</strong></h3><ul>
<li><strong>位掩码</strong>：使用 <code>0xFF</code>、<code>0x80000000</code> 等构造特定模式。</li>
<li><strong>符号位操作</strong>：通过 <code>x &gt;&gt; 31</code> 提取符号位。</li>
<li><strong>逻辑运算替代</strong>：用 <code>!!x</code> 将非零值转换为1，用 <code>x ^ (x &gt;&gt; 31)</code> 处理绝对值。</li>
</ul>
<p>如果需要具体函数的详细推导或测试用例，可进一步说明！</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/" class="post-title-link" itemprop="url">机器学习——上机3——线性回归（医疗保险费预测）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-03-21 00:00:00" itemprop="dateCreated datePublished" datetime="2025-03-21T00:00:00+08:00">2025-03-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-22 14:44:44" itemprop="dateModified" datetime="2025-03-22T14:44:44+08:00">2025-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><h2 id="任务1-一元线性回归"><a href="#任务1-一元线性回归" class="headerlink" title="任务1. 一元线性回归"></a>任务1. 一元线性回归</h2><h3 id="任务介绍："><a href="#任务介绍：" class="headerlink" title="任务介绍："></a>任务介绍：</h3><ul>
<li>自定义一元回归函数MyLinearRegression()，输入参数为x和y的数组xArr和yArr，输出为参数w1和w0，利用最小二乘法求得参数;</li>
<li>使用美国医疗保险费数据insurance.csv中的输入特征age和目标特征charges，输入MyLinearRegression()函数，得到回归参数值w1和w0，并保留到小数点后两位;</li>
<li>调用sklearn的LinearRegression()函数，比较其运行结果与上述自定义函数MyLinearRegression()的输出结果是否一致。</li>
<li>利用age与charges绘制真实样本点，利用w1与w0计算预测值，再绘制age与预测值的点图，观察真实样本点与预测点之间的拟合程度。</li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line">age = insurance[<span class="string">&#x27;age&#x27;</span>].values</span><br><span class="line">charges = insurance[<span class="string">&#x27;charges&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 定义一元线性回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># x均值, y均值计算</span></span><br><span class="line">    mean_x = xArr.mean()</span><br><span class="line">    mean_y = yArr.mean()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># w0, w1计算，公式</span></span><br><span class="line">    numerator = np.<span class="built_in">sum</span>((xArr - mean_x) * (yArr - mean_y))</span><br><span class="line">    denominator = np.<span class="built_in">sum</span>((xArr - mean_x)**<span class="number">2</span>)</span><br><span class="line">    w1 = numerator / denominator</span><br><span class="line">    w0 = mean_y - w1 * mean_x</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(w0,<span class="number">2</span>), <span class="built_in">round</span>(w1,<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型训练，得到参数值&quot;</span>)</span><br><span class="line">w0, w1 = MyLinearRegression(age, charges)</span><br><span class="line"><span class="built_in">print</span>(w1,<span class="string">&#x27;\n&#x27;</span>, w0)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sklearn的训练结果&quot;</span>)</span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment">#线性回归模型训练</span></span><br><span class="line">lr.fit(age.reshape(-<span class="number">1</span>, <span class="number">1</span>), charges)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.coef_[<span class="number">0</span>],<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.intercept_,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 观察真实样本点与预测点之间的拟合程度</span></span><br><span class="line">plt.scatter(age, charges, marker=<span class="string">&#x27;.&#x27;</span>)  <span class="comment"># 画样本点，随机散点</span></span><br><span class="line"><span class="comment"># 利用w1与w0计算预测值，绘制预测点</span></span><br><span class="line">plt.scatter(age, w1 * age + w0, marker=<span class="string">&#x27;+&#x27;</span>)  <span class="comment"># 画预测点，形成直线</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>模型训练，得到参数值
257.72 
 3165.89
sklearn的训练结果
257.72
3165.89
</code></pre><p><img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/main_2_1.png" alt="png"></p>
<h3 id="最小二乘法求解公式"><a href="#最小二乘法求解公式" class="headerlink" title="最小二乘法求解公式"></a><strong>最小二乘法求解公式</strong></h3><p><strong>目标</strong>：最小化预测值与真实值的平方误差之和：</p>
<script type="math/tex; mode=display">\min_{w_0, w_1} \sum_{i=1}^n (y_i - \hat{y}_i)^2</script><p><strong>闭式解（Normal Equation）</strong>：  </p>
<ol>
<li><p><strong>斜率 ( w_1 )</strong>：  </p>
<script type="math/tex; mode=display">w_1 = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}</script><p>其中 (\bar{x}) 和 (\bar{y}) 分别是 (x) 和 (y) 的均值。</p>
</li>
<li><p><strong>截距 ( w_0 )</strong>：  </p>
<script type="math/tex; mode=display">w_0 = \bar{y} - w_1 \bar{x}</script></li>
</ol>
<p>round(w0, 2) 和 round(w1, 2) 的作用是对线性回归模型的参数进行四舍五入处理，保留两位小数。</p>
<p>这段代码使用 <code>scikit-learn</code> 的 <code>LinearRegression</code> 类实现线性回归，并输出模型参数。以下是逐行解释：</p>
<h3 id="1-创建线性回归模型实例"><a href="#1-创建线性回归模型实例" class="headerlink" title="1. 创建线性回归模型实例"></a>1. <strong>创建线性回归模型实例</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearRegression()</span><br></pre></td></tr></table></figure>
<ul>
<li><code>LinearRegression()</code> 是 <code>scikit-learn</code> 中用于线性回归的类。</li>
<li><code>lr</code> 是该类的一个实例，后续通过它调用模型训练、预测等方法。<h3 id="2-模型训练"><a href="#2-模型训练" class="headerlink" title="2. 模型训练"></a>2. <strong>模型训练</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr.fit(age.reshape(-<span class="number">1</span>, <span class="number">1</span>), charges)</span><br></pre></td></tr></table></figure></li>
<li><strong>作用</strong>：用输入数据 <code>age</code>（特征）和 <code>charges</code>（目标值）训练线性回归模型。</li>
<li><strong>关键细节</strong>：<ul>
<li><code>age</code> 是一维数组（形状如 <code>(n,)</code>），但 <code>scikit-learn</code> 要求输入特征为二维数组（形状如 <code>(n, 1)</code>）。</li>
<li><code>age.reshape(-1, 1)</code> 将一维数组转换为二维列向量（<code>n</code> 行 1 列），确保输入格式正确。</li>
<li><code>charges</code> 是目标值的一维数组，无需调整形状。<h3 id="3-输出模型参数"><a href="#3-输出模型参数" class="headerlink" title="3. 输出模型参数"></a>3. <strong>输出模型参数</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.coef_[<span class="number">0</span>], <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.intercept_, <span class="number">2</span>))</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><strong><code>lr.coef_</code></strong>：<ul>
<li>存储模型的回归系数（即 <code>w1</code>，特征权重）。</li>
<li>对于一元线性回归，<code>coef_</code> 是一个包含单个元素的数组（如 <code>[w1]</code>），因此用 <code>coef_[0]</code> 提取数值。</li>
</ul>
</li>
<li><strong><code>lr.intercept_</code></strong>：<ul>
<li>存储模型的截距项（即 <code>w0</code>）。</li>
<li>直接通过 <code>intercept_</code> 访问，无需索引。</li>
</ul>
</li>
<li><strong><code>round(..., 2)</code></strong>：将参数四舍五入保留两位小数，便于与自定义函数结果对比。</li>
</ul>
<h2 id="任务2-多元线性回归"><a href="#任务2-多元线性回归" class="headerlink" title="任务2. 多元线性回归"></a>任务2. 多元线性回归</h2><h3 id="任务介绍：-1"><a href="#任务介绍：-1" class="headerlink" title="任务介绍："></a>任务介绍：</h3><ul>
<li>自定义多元线性回归函数MyLinearRegression2()，输入参数为X和y的数组xArr和yArr，输出为参数ws，利用最小二乘法求得参数;</li>
<li>使用美国医疗保险费数据insurance.csv中的输入特征age、bmi和children，目标特征charges，根据MyLinearRegression2()函数，得到回归参数值ws；注意判断（X^T X）^{-1}是否为满秩，如果满秩，则引入正则项，参数为alpha，目标函数变为岭回归问题。</li>
<li>为了得到模型的截距，需要在矩阵X最后增加一列，并且该列所有行的值均为1。</li>
<li>调用sklearn的LinearRegression()函数，比较其运行结果与上述自定义函数MyLinearRegression2()的输出结果是否一致。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg, column_stack, ones, array</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># 定义多元线性回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression2</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用mat将Array转换为矩阵</span></span><br><span class="line">    xMat = np.asmatrix(xArr)</span><br><span class="line">    yMat = np.asmatrix(yArr).T  <span class="comment"># 转换为列向量</span></span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    <span class="comment"># 通过调用linalg计算行列式来判定协方差矩阵是否可逆</span></span><br><span class="line">    <span class="keyword">if</span> linalg.det(xTx) &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>( <span class="string">&quot;singular matrix, can&#x27;t do inverse&quot;</span>)</span><br><span class="line">        <span class="comment"># 引入正则项，即 岭回归</span></span><br><span class="line">        alpha = <span class="number">0.1</span></span><br><span class="line">        <span class="comment"># 添加岭回归正则项（单位矩阵大小为特征数+1）</span></span><br><span class="line">        xTx  += alpha * np.eye(xMat.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算参数向量</span></span><br><span class="line">    <span class="comment"># 计算参数并转为一维数组</span></span><br><span class="line">    ws = xTx.I * (xMat.T * yMat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练，得到参数值</span></span><br><span class="line">X = insurance[[<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;bmi&#x27;</span>, <span class="string">&#x27;children&#x27;</span>]].values</span><br><span class="line"><span class="comment"># 调用column_stack函数在矩阵X后增加一列，并且该列所有行的值均为1</span></span><br><span class="line"><span class="comment"># 添加截距列（全1）</span></span><br><span class="line">X = column_stack((X, ones(X.shape[<span class="number">0</span>])))</span><br><span class="line">y = insurance[<span class="string">&#x27;charges&#x27;</span>]</span><br><span class="line">ws = MyLinearRegression2(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自定义的训练结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ws)</span><br><span class="line"><span class="comment"># sklearn的训练结果</span></span><br><span class="line">lr = LinearRegression(fit_intercept=<span class="literal">False</span>)  <span class="comment"># 关键：禁用自动截距</span></span><br><span class="line"><span class="comment">#线性回归模型训练</span></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sklearn的训练结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(lr.coef_)</span><br><span class="line"><span class="built_in">print</span>(lr.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>自定义的训练结果
[[  239.99447429]
 [  332.0833645 ]
 [  542.86465225]
 [-6916.24334779]]
sklearn的训练结果
[  239.99447429   332.0833645    542.86465225 -6916.24334779]
0.0
</code></pre><h2 id="任务3-线性回归应用：预测医疗费用"><a href="#任务3-线性回归应用：预测医疗费用" class="headerlink" title="任务3. 线性回归应用：预测医疗费用"></a>任务3. 线性回归应用：预测医疗费用</h2><h3 id="任务介绍"><a href="#任务介绍" class="headerlink" title="任务介绍"></a>任务介绍</h3><ul>
<li>对insurance.csv中的名义型特征进行One-Hot编码，得到了数据变量insurance</li>
<li>请使用自定义的多元回归函数MyLinearRegression2()得到回归模型参数ws和预测值y_pred，并计算R2分数</li>
<li>比较使用sklearn进行模型训练和模型评价R2分数的结果</li>
</ul>
<p>复用上一节实验中实现的代码，可以复制粘贴代替下面的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model, metrics</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array, mean, ones</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用get_dummies函数对非数值型特征进行 one-hot 编码处理，以便于运算</span></span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line">insurance = pd.get_dummies(insurance, drop_first=<span class="literal">True</span>)  <span class="comment"># One-Hot编码</span></span><br><span class="line"><span class="built_in">print</span>(insurance.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从insurance中获取X与y</span></span><br><span class="line">X = insurance.drop([<span class="string">&#x27;charges&#x27;</span>], axis=<span class="number">1</span>).values.astype(np.float64)</span><br><span class="line">y = insurance[<span class="string">&#x27;charges&#x27;</span>].values.astype(np.float64)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个特征与y的关系进行可视化，观察与y的相关性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">1</span>]):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">6</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.scatter(array(X)[:,i],y,s=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression2</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用mat将Array转换为矩阵</span></span><br><span class="line">    xMat = np.asmatrix(xArr)</span><br><span class="line">    yMat = np.asmatrix(yArr).T  <span class="comment"># 转换为列向量</span></span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    <span class="comment"># 通过调用linalg计算行列式来判定协方差矩阵是否可逆</span></span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(xTx) &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>( <span class="string">&quot;singular matrix, can&#x27;t do inverse&quot;</span>)</span><br><span class="line">        <span class="comment"># 引入正则项，即 岭回归</span></span><br><span class="line">        alpha = <span class="number">0.1</span></span><br><span class="line">        <span class="comment"># 添加岭回归正则项（单位矩阵大小为特征数+1）</span></span><br><span class="line">        xTx  += alpha * np.eye(xMat.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算参数向量</span></span><br><span class="line">    <span class="comment"># 计算参数并转为一维数组</span></span><br><span class="line">    ws = xTx.I * (xMat.T * yMat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据X、y和自定义函数MyLinearRegression2()训练模型参数ws，并计算X的预测值y_pred</span></span><br><span class="line">ws = MyLinearRegression2(X, y)</span><br><span class="line">y_pred = X.dot(ws)</span><br><span class="line">y_pred = array(y_pred).reshape(y_pred.shape[<span class="number">0</span>],) <span class="comment"># 将矩阵转换为一行多列的array格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用metrics中的r2_score函数根据y和y_pred计算决定系数score</span></span><br><span class="line">score = metrics.r2_score(y, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sklearn模型训练与预测</span></span><br><span class="line">lr = linear_model.LinearRegression(fit_intercept=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="comment"># 计算X的预测值y_pred_sk与R2分数score_sk</span></span><br><span class="line">y_pred_sk = lr.predict(X)              <span class="comment"># 使用训练好的sklearn模型进行预测</span></span><br><span class="line">score_sk = metrics.r2_score(y, y_pred_sk)  <span class="comment"># 计算决定系数R²</span></span><br><span class="line"><span class="built_in">print</span>(score_sk)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>(1338, 9)
</code></pre><p><img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/main_9_1.png" alt="png"></p>
<pre><code>0.7235368166092777
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/" class="post-title-link" itemprop="url">机器学习——上机3——逻辑回归（广告点击率预测）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-03-21 00:00:00" itemprop="dateCreated datePublished" datetime="2025-03-21T00:00:00+08:00">2025-03-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-03-22 14:44:25" itemprop="dateModified" datetime="2025-03-22T14:44:25+08:00">2025-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="广告点击率预测"><a href="#广告点击率预测" class="headerlink" title="广告点击率预测"></a>广告点击率预测</h1><p>广告点击率(CTR)预测是广告行业的典型应用，是评估广告效果的一个非常重要的指标。通过历史数据训练预测模型，对于每天的增量数据进行预测，找出广告的CTR符合标准的样本进行投放。</p>
<h2 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h2><p>数据集来自于kaggle，数据包含了10天的Avazu的广告点击数据，训练集10000个，测试集1000个。每一条广告包含：广告id、时间、广告位置等属性。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/1682d3186a5d4fedab10c4ad3a7f3656e3db56852e5c4fdbb4fb26005c0ba811" alt></p>
<h2 id="任务1：导入库和数据集与数据预处理"><a href="#任务1：导入库和数据集与数据预处理" class="headerlink" title="任务1：导入库和数据集与数据预处理"></a>任务1：导入库和数据集与数据预处理</h2><ul>
<li>读入训练数据和测试数据，划分data和label</li>
<li>将string类型的特征转化为int型：1）进行 one-hot 编码处理，会得到高维稀疏的特征，增大内存开销；2）使用python内置的hash函数将那些类型为object的特征变量映射为一定范围内的整数(原来的string被映射成了integer)，可以大大降低内存的消耗。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">types_train = &#123;</span><br><span class="line">    <span class="string">&#x27;id&#x27;</span>: np.dtype(<span class="built_in">int</span>),</span><br><span class="line">    <span class="string">&#x27;click&#x27;</span>: np.dtype(<span class="built_in">int</span>),         <span class="comment">#是否点击,1表示被点击,0表示没被点击</span></span><br><span class="line">    <span class="string">&#x27;hour&#x27;</span>: np.dtype(<span class="built_in">int</span>),          <span class="comment">#广告被展现的日期+时间</span></span><br><span class="line">    <span class="string">&#x27;C1&#x27;</span>: np.dtype(<span class="built_in">int</span>),            <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;banner_pos&#x27;</span>: np.dtype(<span class="built_in">int</span>),    <span class="comment">#广告位置</span></span><br><span class="line">    <span class="string">&#x27;site_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),       <span class="comment">#站点Id</span></span><br><span class="line">    <span class="string">&#x27;site_domain&#x27;</span>: np.dtype(<span class="built_in">str</span>),   <span class="comment">#站点域名</span></span><br><span class="line">    <span class="string">&#x27;site_category&#x27;</span>: np.dtype(<span class="built_in">str</span>), <span class="comment">#站点分类</span></span><br><span class="line">    <span class="string">&#x27;app_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),        <span class="comment"># appId</span></span><br><span class="line">    <span class="string">&#x27;app_domain&#x27;</span>: np.dtype(<span class="built_in">str</span>),    <span class="comment"># app域名</span></span><br><span class="line">    <span class="string">&#x27;app_category&#x27;</span>: np.dtype(<span class="built_in">str</span>),  <span class="comment"># app分类</span></span><br><span class="line">    <span class="string">&#x27;device_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),     <span class="comment">#设备Id</span></span><br><span class="line">    <span class="string">&#x27;device_ip&#x27;</span>: np.dtype(<span class="built_in">str</span>),     <span class="comment">#设备Ip</span></span><br><span class="line">    <span class="string">&#x27;device_model&#x27;</span>: np.dtype(<span class="built_in">str</span>),  <span class="comment">#设备型号</span></span><br><span class="line">    <span class="string">&#x27;device_type&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#设备型号</span></span><br><span class="line">    <span class="string">&#x27;device_conn_type&#x27;</span>: np.dtype(<span class="built_in">int</span>),</span><br><span class="line">    <span class="string">&#x27;C14&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C15&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C16&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C17&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C18&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C19&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C20&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C21&#x27;</span>:np.dtype(<span class="built_in">int</span>)     <span class="comment">#匿名分类变量</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加列名</span></span><br><span class="line">header_row = [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;click&#x27;</span>, <span class="string">&#x27;hour&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;banner_pos&#x27;</span>, <span class="string">&#x27;site_id&#x27;</span>, <span class="string">&#x27;site_domain&#x27;</span>, <span class="string">&#x27;site_category&#x27;</span>, \</span><br><span class="line">              <span class="string">&#x27;app_id&#x27;</span>, <span class="string">&#x27;app_domain&#x27;</span>, <span class="string">&#x27;app_category&#x27;</span>, <span class="string">&#x27;device_id&#x27;</span>, <span class="string">&#x27;device_ip&#x27;</span>, <span class="string">&#x27;device_model&#x27;</span>,\</span><br><span class="line">              <span class="string">&#x27;device_type&#x27;</span>, <span class="string">&#x27;device_conn_type&#x27;</span>, <span class="string">&#x27;C14&#x27;</span>, <span class="string">&#x27;C15&#x27;</span>, <span class="string">&#x27;C16&#x27;</span>, <span class="string">&#x27;C17&#x27;</span>, <span class="string">&#x27;C18&#x27;</span>, <span class="string">&#x27;C19&#x27;</span>,\</span><br><span class="line">              <span class="string">&#x27;C20&#x27;</span>, <span class="string">&#x27;C21&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入训练数据和测试数据</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train_data.csv&#x27;</span>, names=header_row, dtype=types_train)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;test_data.csv&#x27;</span>, names=header_row, dtype=types_train)</span><br><span class="line"><span class="comment"># 去除第0行（表示列的编号，不是样本）</span></span><br><span class="line">train = train.drop(labels=train.index.values[<span class="number">0</span>])</span><br><span class="line">test = test.drop(labels=test.index.values[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(test.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分data和label</span></span><br><span class="line">train_data = train.drop(<span class="string">&#x27;click&#x27;</span>, axis=<span class="number">1</span>) <span class="comment">#去除click 这一列</span></span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br><span class="line">train_label = train[<span class="string">&#x27;click&#x27;</span>] <span class="comment">#提取click 这一列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="comment"># 使用pd.get_dummies对非数值型特征进行 one-hot 编码处理，得到高维稀疏的特征</span></span><br><span class="line">train_data1 = pd.get_dummies(train_data)</span><br><span class="line"><span class="built_in">print</span>(train_data1.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编写convert_obj_to_int()函数将string类型的特征转换为int型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_obj_to_int</span>(<span class="params">self</span>):</span><br><span class="line">    object_list_columns = <span class="variable language_">self</span>.columns</span><br><span class="line">    object_list_dtypes = <span class="variable language_">self</span>.dtypes</span><br><span class="line">    new_col_suffix = <span class="string">&#x27;_int&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(object_list_columns)):</span><br><span class="line">        <span class="keyword">if</span> object_list_dtypes[index] == <span class="built_in">object</span>:</span><br><span class="line">            <span class="comment"># 使用hash和map将string特征变量映射为一定范围内的整数</span></span><br><span class="line">            <span class="variable language_">self</span>[object_list_columns[index] + new_col_suffix] = <span class="variable language_">self</span>[object_list_columns[index]].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">hash</span>(x) % (<span class="number">1</span> &lt;&lt; <span class="number">32</span>))</span><br><span class="line">            <span class="variable language_">self</span>.drop([object_list_columns[index]], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用convert_obj_to_int()函数，将string类型转换为int型    </span></span><br><span class="line">train_data = convert_obj_to_int(train_data)</span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1000, 24)
(10000, 23)
(10000, 10531)
(10000, 23)


C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
</code></pre><h2 id="任务2：特征分析"><a href="#任务2：特征分析" class="headerlink" title="任务2：特征分析"></a>任务2：特征分析</h2><p>以广告在网页中的位置(banner_pos)为例，查看banner_pos和最终类标(click)之间的关系。</p>
<ul>
<li>查看banner_pos在数据集中的取值分布；</li>
<li>查看不同banner_pos对点击率click的贡献。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看banner_pos在数据集中的取值分布</span></span><br><span class="line"><span class="built_in">print</span>(train.banner_pos.value_counts()/<span class="built_in">len</span>(train))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看不同banner_pos对点击率click的贡献</span></span><br><span class="line">banner_pos_val = train.banner_pos.unique()</span><br><span class="line">banner_pos_val.sort()</span><br><span class="line">ctr_avg_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> banner_pos_val:</span><br><span class="line">    selected_data = train.loc[train.banner_pos == i]</span><br><span class="line">    ctr_avg = selected_data.click.mean()</span><br><span class="line">    ctr_avg_list.append(ctr_avg)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; banner 位置: &#123;&#125;,  点击率: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, ctr_avg))</span><br></pre></td></tr></table></figure>
<pre><code>banner_pos
0    0.8041
1    0.1951
2    0.0007
4    0.0001
Name: count, dtype: float64
 banner 位置: 0,  点击率: 0.16975500559631887
 banner 位置: 1,  点击率: 0.19067145053818554
 banner 位置: 2,  点击率: 0.14285714285714285
 banner 位置: 4,  点击率: 0.0
</code></pre><h2 id="任务3：模型训练与评估"><a href="#任务3：模型训练与评估" class="headerlink" title="任务3：模型训练与评估"></a>任务3：模型训练与评估</h2><ul>
<li>调用sklearn的逻辑回归函数LogisticRegression()，进行模型训练</li>
<li>对测试集test_data进行预测，计算预测结果的各项指标acc, pre, recall, auc</li>
<li>绘制ROC曲线（使用预测的概率值而不是预测的类标）</li>
<li><strong>选做</strong>：自定义逻辑回归函数MyLogisticRegression()，进行模型训练与预测，与上述结果比较。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">test_data = test.drop(<span class="string">&#x27;click&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">test_data = convert_obj_to_int(test_data)</span><br><span class="line">test_label = test[<span class="string">&#x27;click&#x27;</span>]</span><br><span class="line"><span class="comment"># 调用sklearn的逻辑回归函数LogisticRegression()</span></span><br><span class="line">clf = linear_model.LogisticRegression(max_iter=<span class="number">1000</span>)  <span class="comment"># 增加最大迭代次数防止不收敛</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">clf.fit(train_data, train_label)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Finish Training!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">pred = clf.predict(test_data)</span><br><span class="line">pred_proba = clf.predict_proba(test_data)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算模型的acc, pre, recall, auc，并输出</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line">acc = accuracy_score(test_label, pred)</span><br><span class="line">pre = precision_score(test_label, pred)</span><br><span class="line">recall = recall_score(test_label, pred)</span><br><span class="line">auc = roc_auc_score(test_label, pred_proba)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>, Precision: <span class="subst">&#123;pre:<span class="number">.4</span>f&#125;</span>, Recall: <span class="subst">&#123;recall:<span class="number">.4</span>f&#125;</span>, AUC: <span class="subst">&#123;auc:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># 绘制roc曲线</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line">fpr, tpr, _ = roc_curve(test_label, pred_proba)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(fpr, tpr, label=<span class="string">f&#x27;AUC = <span class="subst">&#123;auc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>], [<span class="number">0</span>,<span class="number">1</span>], <span class="string">&#x27;k--&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;ROC Curve (sklearn)&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 自定义实现逻辑回归函数MyLogisticRegression()</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Finish Training!
Accuracy: 0.8120, Precision: 0.0000, Recall: 0.0000, AUC: 0.4983


C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
f:\Anconda\Anconda\envs\general\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;&#123;metric.capitalize()&#125; is&quot;, len(result))
</code></pre><p><img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/main_5_2.png" alt="png"></p>
<p>​<br>    Custom Model - Accuracy: 0.8240, Precision: 0.6875, Recall: 0.1170, AUC: 0.6580</p>
<p><img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/main_5_4.png" alt="png"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/" class="post-title-link" itemprop="url">机器学习——决策树</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-03-20 00:00:00" itemprop="dateCreated datePublished" datetime="2025-03-20T00:00:00+08:00">2025-03-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-12 18:57:23" itemprop="dateModified" datetime="2025-06-12T18:57:23+08:00">2025-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><h3 id="什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？"><a href="#什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？" class="headerlink" title="什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？"></a>什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/hw_h_82p6lenbyhkws867e413c0614d3.png" alt="hw_h_82p6lenbyhkws867e413c0614d3"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153252.jpg" alt="IMG_20250329_153252"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153259.jpg" alt="IMG_20250329_153259"></p>
<h3 id="什么是交叉验证法？有什么用途？"><a href="#什么是交叉验证法？有什么用途？" class="headerlink" title="什么是交叉验证法？有什么用途？"></a>什么是交叉验证法？有什么用途？</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153307.jpg" alt="IMG_20250329_153307"></p>
<h3 id="什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？"><a href="#什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？" class="headerlink" title="什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？"></a>什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153310.jpg" alt="IMG_20250329_153310"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">机器学习——线性模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-03-20 00:00:00" itemprop="dateCreated datePublished" datetime="2025-03-20T00:00:00+08:00">2025-03-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-12 18:59:30" itemprop="dateModified" datetime="2025-06-12T18:59:30+08:00">2025-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/" itemprop="url" rel="index"><span itemprop="name">大二下</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200047048.png" alt="image-20250320200047048"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200109835.png" alt="image-20250320200109835"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200139754.png" alt="image-20250320200139754"></p>
<h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><h3 id="1、何为正则化？其功能是什么？如何理解L1和L2正则化？"><a href="#1、何为正则化？其功能是什么？如何理解L1和L2正则化？" class="headerlink" title="1、何为正则化？其功能是什么？如何理解L1和L2正则化？"></a>1、何为正则化？其功能是什么？如何理解L1和L2正则化？</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250320_170100.jpg" alt="IMG_20250320_170100"></p>
<h3 id="2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。"><a href="#2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。" class="headerlink" title="2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。"></a>2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。</h3><div class="table-container">
<table>
<thead>
<tr>
<th>现象</th>
<th>偏差</th>
<th>方差</th>
<th>典型原因</th>
<th>解决方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>欠拟合</td>
<td>高</td>
<td>低</td>
<td>模型过于简单（如线性模型拟合非线性数据）</td>
<td>增加特征、使用更复杂模型、减少正则化</td>
</tr>
<tr>
<td>过拟合</td>
<td>低</td>
<td>高</td>
<td>模型过于复杂（如深度树模型拟合噪声）</td>
<td>增加数据、正则化、简化模型、早停法</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250320_181442.jpg" alt="IMG_20250320_181442"></p>
<h3 id="3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）"><a href="#3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）" class="headerlink" title="3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）"></a>3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163937.jpg" alt="IMG_20250321_163937"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163941.jpg" alt="IMG_20250321_163941"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163944.jpg" alt="IMG_20250321_163944"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163948.jpg" alt="IMG_20250321_163948"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Z44y147xA/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">“L1和L2正则化”直观理解(之一)，从拉格朗日乘数法角度进行理解_哔哩哔哩_bilibili</a></p>
<p>超级棒的公式证明，对我帮助很大</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Mh411e7VU?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=3&amp;spm_id_from=333.788.videopod.episodes">https://www.bilibili.com/video/BV1Mh411e7VU?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=3&amp;spm_id_from=333.788.videopod.episodes</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/zxjavatar.gif">
      <meta itemprop="name" content="张熙浚">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang XiJun">
      <meta itemprop="description" content="zxj Blogs">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhang XiJun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/" class="post-title-link" itemprop="url">决战蓝桥杯</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-03-12 00:00:00" itemprop="dateCreated datePublished" datetime="2025-03-12T00:00:00+08:00">2025-03-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-12 18:44:05" itemprop="dateModified" datetime="2025-06-12T18:44:05+08:00">2025-06-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E8%93%9D%E6%A1%A5%E6%9D%AF/" itemprop="url" rel="index"><span itemprop="name">蓝桥杯</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>好久不编算法了，为了不让300r打水漂，废话不多说，决战蓝桥杯！！！</p>
<p>我是算法彩笔，而且python也不是很会用，所有刷题刷的很慢，后续会把文件整理上传GitHub</p>
<p>思考了一下，因为时间紧迫，没有时间复盘每一道题了，这一篇文章简单记录一下进度</p>
<h2 id="进度记录"><a href="#进度记录" class="headerlink" title="进度记录"></a>进度记录</h2><p>3.13</p>
<p>贪心：1.力扣406. 根据身高重建队列2.P10387 [蓝桥杯 2024 省 A] 训练士兵3.蓝桥杯真题 谈判</p>
<p>3.14</p>
<p>贪心：1.蓝桥杯真题 翻硬币</p>
<p>bfs：1.蓝桥杯真题 扫雷2.蓝桥杯真题 长草3.力扣695.岛屿的最大面积</p>
<p>3.16</p>
<p>哈希：1.力扣 两数之和</p>
<p>前缀和：1.洛谷 求区间和</p>
<p>二分问题：1.洛谷 查找</p>
<p>dfs：1.蓝桥杯真题 小朋友崇拜圈2.蓝桥杯真题 最大数字</p>
<p>3.17</p>
<p>二分问题：1.力扣 统计公平数对的数目2.力扣 2226.每个小孩最多能分到多少糖果</p>
<p>3.18</p>
<p>二分答案：1.蓝桥杯真题 冶炼金属</p>
<p>并查集：1.洛谷P1551 亲戚2.洛谷P1536 村村通</p>
<p>3.19</p>
<p>哈希：1.力扣 3080.执行操作标记数组中的元素</p>
<p>堆：1.力扣 2530.执行k次操作后的最大分数</p>
<p>动态规划：1.力扣 70.爬楼梯2.力扣 198.打家劫舍3.P1048 [NOIP 2005 普及组] 采药4.力扣 494. 目标和5.力扣 322.零钱兑换</p>
<p>3.21</p>
<p>动态规划：1.力扣 2915.和为目标值的最长子序列的长度2.蓝桥杯真题 蓝桥课程抢购3.力扣518. 零钱兑换 II</p>
<p>图论：1.力扣1971.寻找图中是否存在路径</p>
<p>3.25</p>
<p>图论：1.力扣743.网络延迟时间</p>
<p>数论：1.蓝桥杯真题 数字诗意</p>
<p>3.26</p>
<p>贪心：1.蓝桥杯真题 回文数组</p>
<p>图论：1.力扣 1584.连接所有点的最小费用2.蓝桥杯真题 城市规划大师</p>
<p>3.27</p>
<p>动态规划：1.力扣1143.最长公共子序列2.蓝桥杯真题 查找最长公共子序列3.力扣583.两个字符串的删除操作</p>
<p>3.28</p>
<p>动态规划：1.蓝桥杯真题 砍柴</p>
<p>3.30</p>
<p>贪心：1.蓝桥杯真题 三国游戏2.蓝桥杯真题 平均</p>
<p>暴力：1.蓝桥杯真题 翻转</p>
<p>单调队列，单调栈：1.力扣239.滑动窗口最大值2.力扣739.每日温度3.力扣42.接雨水</p>
<p>双指针：1.力扣209.长度最小的子数组2.力扣3.无重复字符的最长字串3.力扣713.乘积小于k的子数组</p>
<p>3.31</p>
<p>二维单调队列：1.蓝桥杯真题 子矩阵（拼劲全力无法战胜，放弃）</p>
<p>4.1</p>
<p>数论：1.蓝桥杯真题 阶乘的和2.蓝桥杯真题 质因数个数</p>
<p>树：1.蓝桥杯真题 子树的大小</p>
<p>4.4</p>
<p>模拟：1.蓝桥杯真题 消除游戏</p>
<p>4.5</p>
<p>差分：1.蓝桥杯真题 重新排序2.力扣1094.拼车</p>
<p>动态规划：1.蓝桥杯真题 全排列的价值2.力扣300.最长递增子序列</p>
<p>贪心：1.蓝桥杯真题 优清零方案</p>
<p>4.9-11</p>
<p>刷填空题</p>
<p>4.12后记：也是考完蓝桥杯了，后面应该很长时间不碰算法了嘿嘿</p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="算法基础"><a href="#算法基础" class="headerlink" title="算法基础"></a>算法基础</h3><h4 id="快读模板"><a href="#快读模板" class="headerlink" title="快读模板"></a>快读模板</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入系统模块</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment"># 重定义input函数，用于快速读取输入</span></span><br><span class="line"><span class="comment"># sys.stdin.readline() 比 python 自带的 input() 快</span></span><br><span class="line"><span class="comment"># strip() 用于去除行末的换行符</span></span><br><span class="line"><span class="built_in">input</span> = <span class="keyword">lambda</span>:sys.stdin.readline().strip()</span><br></pre></td></tr></table></figure>
<p><img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312124949702.png" alt="image-20250312124949702"></p>
<h4 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h4><p><img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312130008507.png" alt="image-20250312130008507"></p>
<h4 id="列表推导器"><a href="#列表推导器" class="headerlink" title="列表推导器"></a>列表推导器</h4><p><img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312131643035.png" alt="image-20250312131643035"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>竟然在b站刷到学长做的视频，太惊喜了，真是雪中送炭</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1wcR3Y5EMg/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【蓝桥杯】Python速成 刷题指南_哔哩哔哩_bilibili</a></p>
<p><a target="_blank" rel="noopener" href="https://wiki.dwj601.cn/ds-and-algo/templates-py/">代码模板 (Python) - Open Wiki Community</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/TsingPig/LanQiao_Python">TsingPig/LanQiao_Python: 视频合集 https://space.bilibili.com/398421867/lists?sid=4898042&amp;spm_id_from=333.788.0.0</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>补充资料</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener" href="https://wiki.dwj601.cn/ds-and-algo/templates-py/">https://wiki.dwj601.cn/ds-and-algo/templates-py/</a></td>
<td>【★★★★★】Python代码模板</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.lanqiao.cn/problems/?first_category_id=1">https://www.lanqiao.cn/problems/?first_category_id=1</a></td>
<td>蓝桥题库</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://ac.nowcoder.com/acm/problem/collection/6999">https://ac.nowcoder.com/acm/problem/collection/6999</a></td>
<td>牛客蓝桥寒假题单</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.luogu.com.cn/training/list">https://www.luogu.com.cn/training/list</a></td>
<td>洛谷题单</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://leetcode.cn/u/endlesscheng/">https://leetcode.cn/u/endlesscheng/</a></td>
<td>力扣分类题单（进入点击“讨论发布”）</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.lanqiao.cn/paper/">https://www.lanqiao.cn/paper/</a></td>
<td>【★★★★★】蓝桥杯真题卷模拟系统</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://leetcode.cn/problemset/">https://leetcode.cn/problemset/</a></td>
<td>力扣题库</td>
</tr>
</tbody>
</table>
</div>
<p>讲的很好的视频</p>
<p><a target="_blank" rel="noopener" href="https://leetcode.cn/discuss/post/3141566/ru-he-ke-xue-shua-ti-by-endlesscheng-q3yd/">分享｜如何科学刷题？- 讨论 - 力扣（LeetCode）</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/7/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/9/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">张熙浚</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="本站访问数 fa fa-user 次"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="本站总访问量 fa fa-eye 次"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script size="400" alpha="0.6" zIndex="-1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  <script src="/js/third-party/pace.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
