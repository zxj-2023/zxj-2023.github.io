<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>指数基金投资指南</title>
    <url>/2025/02/26/reading/%E6%8C%87%E6%95%B0%E5%9F%BA%E9%87%91%E6%8A%95%E8%B5%84%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<h2 id="为什么要读这本书">为什么要读这本书</h2>
<p>我觉得学会投资，学会钱生钱，是一件很重要的事情，一开始这是我父亲告诉我的，后来我自身也是深刻地感受到了。投资，可以避免通货膨胀带了的损失，如果做到了一定的境界，更可以真正实现财富自由。但是想要学好投资并不是一件容易的事。投资的成功，不仅需要敏锐的洞察力与眼光，社会经验的积累，还要有一种成熟的投资心态，进而探索出适合自身的投资理念。我觉得，这是需要一件长期实践的事情，所以我决定早些开始，虽然我现在并没有什么资产，但在投资的过程中，包括看新闻看热点，去搜索去了解一家公司，这都是在锻炼我的视野，为以后做铺垫吧</p>
<h2 id="习惯的力量">习惯的力量</h2>
<blockquote>
<p>因为“习惯”的力量，仍然有许多人把所有的收入存放在收益率较低的“储蓄”里，让通货膨胀</p>
</blockquote>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>金融投资</tag>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>简历备份</title>
    <url>/2024/10/14/diary/zxj/</url>
    <content><![CDATA[<ul>
<li><h1 id="张熙浚">🧑‍💻 张熙浚</h1>
电话：18114477496｜ 个人网站：https://zxj-2023.github.io/ ## 教育背景
<strong>南京师范大学 - 本科 - 人工智能专业（2023.09-2027.07）</strong>
<code>211</code> <code>双一流</code>
<ul>
<li><p><strong>语言：</strong>英语（CET4，589）</p></li>
<li><p><strong>校内任职：</strong>现任院学生会主任、班级学习委员；</p></li>
<li><p><strong>绩点综测：</strong>绩点综测排名均列专业前二；</p></li>
<li><p><strong>校园经历：</strong>在三次获得校优秀学生奖学金一等奖，校优秀学习奖，校三好学生；</p></li>
</ul>
<h2 id="个人荣誉">个人荣誉</h2>
<ul>
<li><p><strong>全国大学生计算机设计大赛 - 全国级三等奖</strong>
(2024)</p></li>
<li><p><strong>全国大学生数学建模大赛 - 江苏省一等奖</strong>
(2024)</p></li>
<li><p><strong>全国大学生蓝桥杯程序算法设计 -
江苏省三等奖</strong></p></li>
<li><p><strong>大学生创新创业项目 - 省重点项目</strong> (2024)</p></li>
<li><p><strong><em>蓝桥杯</em>AIGC 数字内容创意设计大赛 -
国家级三等奖</strong>（2024）</p></li>
</ul>
<h2 id="项目经验">项目经验</h2>
<strong>计算机设计大赛 - 基于 unity 的 2.5D 国风游戏设计 -（2024.03 -
2024.06）</strong>
<ul>
<li><p>围绕《九章算术》设计并开发了四大游戏场景，多个小游戏，动画，对话系统和ui界面。</p></li>
<li><p>在unity平台实现2.5D场景构建，利用playmaker插件实现可视化编程。</p></li>
<li><p>使用C#脚本完成游戏逻辑构建。</p></li>
</ul>
<strong>计算机设计大赛 - 基于 LightRAG 的本地安全大模型 -（2024.10 -
至今）</strong>
<ul>
<li><p>完成LightRAG与GraphRAG的对比，利用LightRAG实现知识检索增强功能,并利用neo4j实现知识图谱可视化。</p></li>
<li><p>采用pycharm+anaconda集成开发环境，使用ollama框架完成本地大模型部署。</p></li>
<li><p>后续会进行大模型的微调，数据集的清洗，网站搭建等工作。</p></li>
</ul>
<strong>25 年大学生创新创业项目 -
基于多模态特征融合的视频暴力行为识别方法研究 -（2024.09 -
至今）</strong>
<ul>
<li><p>完成了一种基于多模态特征融合的视频暴力行为识别算法，通过融合RGB模态、帧差模态以及Depth模态，使其能够准确、鲁棒地在复杂的真实环境下进行暴力行为识别。</p></li>
<li><p>完成了一种自适应的注意力算法用于多模态融合。让模型自适应地学习不同模态特征之间的权重关系。</p></li>
<li><p>完成了系统的设计，后续会继续进行开发。</p></li>
</ul>
<h2 id="竞赛经验">竞赛经验</h2>
<strong>全国大学生数学建模大赛 - 江苏省一等奖 - （2024.09）</strong>
<strong>认证杯数学建模大赛（小美赛）- s奖 -（2024.12）</strong>
<ul>
<li>担任编程手一职，协同建模手完成了部分公式的推导等</li>
</ul>
<strong>蓝桥杯AIGC中数杯 - 国家级三等奖 -（2024.10）</strong>
<ul>
<li>利用市面上现有AIGC技术完成视频制作，实现docker部署stable
Diffusion</li>
</ul>
<h2 id="自我评价">自我评价</h2>
<ul>
<li><p>交际能力强，具备良好的口头表达和书面沟通能力，长于社交，具备丰富的活动组织经验</p></li>
<li><p>学习能力强，陌生的知识与技术会积极学习，会积极请教问题并听取建议</p></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>读书笔记——前言</title>
    <url>/2024/10/15/reading/%E5%89%8D%E8%A8%80/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>我从小就不是一个喜欢读书的人，不管是小说还是文学作品，感觉文字始终无法对我产生兴趣，回忆起来，我自从初中开始，书读的可能最多的就是课本，课外甚至没有完整地看下来一本书。但我一直深知读书的重要性，而且把读书的感悟写下是很有意义的一件事，希望自己以后可以多读书，自勉。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>不要过分苛责自己</title>
    <url>/2024/11/25/diary/%E4%B8%8D%E8%A6%81%E8%BF%87%E5%88%86%E8%8B%9B%E8%B4%A3%E8%87%AA%E5%B7%B1/</url>
    <content><![CDATA[<h3 id="不要过分苛责自己">不要过分苛责自己</h3>
<p>​
数竞的成绩出来，没有看到自己名字，不知道为什么还是有些难受，理性告诉我这是理所应当，因为我根本没有为这个比赛花任何时间，只有前一天晚上临时抱佛脚的两个小时，对于报名，却没有复习的原因，如果别人让我做出解释，我可能会说，那段时间太累了，这不是借口，我记忆中那段时间确实是挺累的，但现在我已经不记得我那段时间忙些了什么，或者为自己留下了什么实际性的收获，似乎什么都没有。</p>
<p>​
结果上看，我对待这个比赛的态度是放弃的，那既然已经决定放弃的事情，为什么还会有些难受呢，我想，一方面，我还对不劳而获存在不切实际的幻想，幻想着不复习，幻想着靠自己脑子那一点点知识，就想在竞赛中占有一席之地，幻想着运气一次又一次眷顾自己，事实会告诉我这是不可能的；另一方面，每个人的精力确实是有限的，但我总是比较贪心，这也想要，那也想要，结果就是应接不暇，这是好强导致的吗，感觉还是比较幼稚，没有舍弃与选择的魄力，没有舍弃的勇气的人，什么也改变不了，hhh突然想起巨人的台词，有些中二嗷，扯远了扯远了。</p>
<p>​
其实，就算做不到也没关系，现实已经一次又一次地证明了，人无完人，这件事你做不好不代表其他事你做不好啊，我并不喜欢钻研数学啊物理啊做题做试卷这种，但我决定参加一些项目，学习新的知识很有意思，我也确实在其他一些科研比赛中获得不错的成绩，为什么要为一个小小的数竟，过分地苛责自己呢，况且你一开始就没有好好准备他，失败是理所应当的，你并没有损失什么，看得开一些，向前看，不要为一些小失败而驻足不前，不要为一些小失败过分地苛责自己。</p>
<p>​
突然发现把一些心里话写下来，心情真的舒畅了很多，继续加油，不要停止奔跑。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>梦开始的地方</title>
    <url>/2024/10/14/diary/Blog/</url>
    <content><![CDATA[<p>这是梦开始的地方</p>
<p>我一直觉得写文章是一件很酷的事情，但奈何自己文采实在有限，又没有练习写作读书的勤奋劲，所以一直搁置，还记得刚上大学那一阵，看了两位学长自己搭的博客，写了很多自己的文章，记录着自己的成长，不仅是对自己成长的记录，也是对后辈的鼓励和启示，真的让我十分崇拜与鼓舞，于是就在心中埋下搭建自己心中埋下搭建自己博客的种子，但因学业和惰性一直搁置下来，还有个重要原因就是，我不知道我的博客应该写些什么，这使我没有动力继续前进。</p>
<p>直到前阵子，我与我的父亲在车上谈话，他与我聊起了他年轻时做贸易的故事，他说他对市场的判断总能先于他人，甚至08年金融危机，他也做出了正确的判断，他与我分享说，他一个很重要的习惯就是，把他读书看新闻遇到的信息整合，实实在在地写下来，记录下来到一个本子上。可能这对别人觉得很正常，但我却很震撼，我没想到不光是我的同龄人们这样做，我的父母辈也是如此，这样一个宝贵的经验我实在应该学习。</p>
<p>现在我已经步入大二，接触的事物也比大一扩展了很多，我绝对不能再等待，即使现在写不好，只要开始就是进步，后面我希望能把我的所思所想，进步痕迹通通记录下来，我的博客不光是我的名片，让大家更好地了解我，也是我自己宝贵的回忆！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>人生匆匆啊</title>
    <url>/2025/03/05/diary/%E5%8C%86%E5%8C%86%E5%95%8A/</url>
    <content><![CDATA[<h3 id="人生匆匆啊">人生匆匆啊</h3>
<p>今天是2025年3月5日，是我的20岁生日，现在是9点45分，刚上完算法课，逃了上机课来到了机房，在开始一天的学习之前，我还是决定写一篇随笔记录一下自己的心情，或许多年之后，我已经忘记当时的心情，但这些文字会保留下来，会见证我的成长。</p>
<p>小时候，或许人人都希望生日到来的那一天，因为生日的到来意味着成长，代表着长大成人，当时的自己得知自己又成长了一岁，心中确实是喜悦的；但今日的我，却没有了这份喜悦，换来的是感慨与思考。自从上大学之后，觉得时间真的好快，转眼我已经是大二下的学生，四年的大学生活已经过半，我到底做了什么，有没有成长与进步，有没有荒度这些时光，这些天我无时无刻不反问自己。我觉得我还有很多事情，很多方面需要成长，但是时间却仿佛没有这么多了，大学本科毕业那年我22岁，如果在国内读研究生，那就是3年，毕业之后我就是25岁，在我的认知里，25岁就算是开始步入中年了，而那时的我才研究生毕业初入社会，可以说是稚嫩一无所有，这是我不能接受的。所以，这也是很大一部分原因让我选择出国留学，我希望更早地步入社会，去闯去打拼，而且就我自身而言，我觉得我的性格，在社会中会更能展现出优势，而不是科研的料。希望我可以在25岁这个结点，能做到小有成就，能做到让自己满意。</p>
<p>再简单记录一下自己这个学期的情况，学校的课程基本要从早八上到下午三点，下课之后在图书馆学习到七点20左右，然后去吃饭，八点在健身房锻炼到9点半左右，十点多洗完澡跟好朋友玩一玩游戏到十二点左右。我秉承着德智体美劳全面发展与劳逸结合，学习不能光学书本上的知识，网上很多各种类型的视频也常常可以给我启发，学习劳累之后去运动运动把身体搞好，学就是学玩就是玩，我分的很开，所以我每天晚上多少会玩一会游戏让自己放松一下。</p>
<p>差不多就说到这吧，写一写随笔真的挺好的，我经常心中有很多话，仿佛构思鸿篇巨制，却常因懒惰没有记录下来，希望以后勤写勤记，加油！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>脚踏实地</title>
    <url>/2025/05/21/diary/%E8%84%9A%E8%B8%8F%E5%AE%9E%E5%9C%B0/</url>
    <content><![CDATA[<h3 id="脚踏实地">脚踏实地</h3>
<p>没有一夜暴富的美梦，天下掉馅饼的事情只有可能是诱惑，在得到某些好处前先想一想你配不配。</p>
<p>杜绝心浮气躁，用双手制造财富。.</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>1912</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/1912/</url>
    <content><![CDATA[<h3 id="section">1912</h3>
<p>2025年的生日，与李哥在百家湖1912聚餐，李哥请我吃的铁板烧，超级美味</p>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784805-1745080945538-24.jpg" alt="1745080784805">
<figcaption aria-hidden="true">1745080784805</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784820-1745080945538-25.jpg" alt="1745080784820">
<figcaption aria-hidden="true">1745080784820</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784834-1745080945538-26.jpg" alt="1745080784834">
<figcaption aria-hidden="true">1745080784834</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784848-1745080945538-27.jpg" alt="1745080784848">
<figcaption aria-hidden="true">1745080784848</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784862-1745080945538-28.jpg" alt="1745080784862">
<figcaption aria-hidden="true">1745080784862</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784789-1745080968451-38.jpg" alt="1745080784789">
<figcaption aria-hidden="true">1745080784789</figcaption>
</figure>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>总结与反思-11.20</title>
    <url>/2024/11/20/diary/%E9%9A%8F%E7%AC%94-11.20/</url>
    <content><![CDATA[<h3 id="总结与反思-11.20">总结与反思-11.20</h3>
<p>距离我正式开始写博客不知不觉已经过去一个多月，决定写一篇随笔，总结反思一下</p>
<p>期中已经考完了，回过头看，其实我对我这个学期的上半学期并不满意，大物的期中和线代的第一次阶段性考核实在是不理想，这跟我自己的学习状态有关，开学一开始给自己定的这学期的主基调是不要太累，导致一直对去图书馆学习十分反感，每天就是在宿舍玩一玩浪费时间，现在回想起来还是挺后悔的，除了期中考试的不如意，主要还因为一个事情让我启发很大，就是我同学的动态，他分享每天自己的收获，可能是学习可能是看书，我看了之后第一感觉是非常的佩服的，觉得他很有毅力很自律，但是他在动态下面评论的一句话让我深有感触，他说他并不觉得他很自律，他没有强迫自己学习，他是以一个享受地态度做这些事，当时我看了可以说大受震撼，因为在过去的一年大学生活中，我一直是以强迫的态度让自己去图书馆的，有时就算到图书馆也坐立不安，最后干脆去都不去了。相比之下，我发现我对自律的理解真是太浅薄了。自律不是强迫自己做某件事情，而是想做成什么事一定会做成的决心。于是，我以一种全新的态度重新审视学习。不想学线代了？那就别强迫自己，看看科研项目相关的事，这样坚持几天下来，我发现这几天过的十分充实，一种精神上的满足。这对我来说，确确实实是一大收获，希望这种享受学习的态度能伴我一直走下去。</p>
<blockquote>
<p>这里引用一下他的话，作为记录</p>
<p>有人爱一行干一行，有人干一行不爱一行，有人爱不干的那一行…感觉我是那种“干一行爱一行”的人，越做越觉得有趣，做一点就想知道更多（可能是我运气好刚好碰上的都是能爱上的..)如果单纯为了绩点不需要这样，刷题就好，但是我会把“学习”当做是我的一种生活或者说是娱乐方式</p>
<p>我很少痛苦地去学习，我要是觉得不舒服就会去学别的，去看书（或者刷刷手机)我也经常写很慢写很久停不下来，如果只是为了做题完全不需要。嗯希望给大家一个思路都能发现生活中的美好～导</p>
</blockquote>
<p>但令我感到开心的是，我在健身这件事上做到了坚持，以前我一直觉得自己总是三分钟热度，什么事情都做不长久，如今回想起来，我自高中以来，已经做成了很多很多我以前不敢想的事情，包括对英语的学习，包括高考的超常发挥，包括大学以来获得的很多成就，希望能对自己更有自信一些，向更好的自己前进！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>前言</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E5%89%8D%E8%A8%80/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>我是一个很珍惜回忆的人，但是任何回忆都有忘却的那一天，所以我能做的就是尽可能把他ji’lu</p>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>我想听他扫弦的声音</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/</url>
    <content><![CDATA[<h3 id="我想听他扫弦的声音">我想听他扫弦的声音</h3>
<p>南京1701livehouse</p>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840515.jpg" alt="1745077840515">
<figcaption aria-hidden="true">1745077840515</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840490.jpg" alt="1745077840490">
<figcaption aria-hidden="true">1745077840490</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840469.jpg" alt="1745077840469">
<figcaption aria-hidden="true">1745077840469</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840480.jpg" alt="1745077840480">
<figcaption aria-hidden="true">1745077840480</figcaption>
</figure>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>梦龙</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/</url>
    <content><![CDATA[<h3 id="梦龙演唱会">梦龙演唱会</h3>
<p>4.6 Imagine Dragons 杭州
真的太嗨太嗨了，内场氛围巨好无比，所有人都在合唱，超值啊！
再记录一下这次比较特别的体验，在小红书找到了一个自驾去看演唱会的，五个人一辆车边走边聊边听歌，也是很不错啊</p>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837710.jpg" alt="1745078837710">
<figcaption aria-hidden="true">1745078837710</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837725.jpg" alt="1745078837725">
<figcaption aria-hidden="true">1745078837725</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837752.jpg" alt="1745078837752">
<figcaption aria-hidden="true">1745078837752</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837739.jpg" alt="1745078837739">
<figcaption aria-hidden="true">1745078837739</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837778.jpg" alt="1745078837778">
<figcaption aria-hidden="true">1745078837778</figcaption>
</figure>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>橘子海</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/</url>
    <content><![CDATA[<h3 id="橘子海">橘子海</h3>
<p>橘子海，现场超超超超级赞，嗨到爆，完全超出预期</p>
<p>Give me the faith that we broke</p>
<p>请重拾我们背叛过的誓言</p>
<p>Reminds me the verse that we spoke</p>
<p>不要让我遗忘共同诵读过的诗篇</p>
<p>There is no chance for start it over</p>
<p>一切已经永远无法重来</p>
<p>Back to the check point be my lover</p>
<p>回不去那个你我还是“我们”的存盘点</p>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894738.jpg" alt="1745079894738">
<figcaption aria-hidden="true">1745079894738</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894693.jpg" alt="1745079894693">
<figcaption aria-hidden="true">1745079894693</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894721.jpg" alt="1745079894721">
<figcaption aria-hidden="true">1745079894721</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894676.jpg" alt="1745079894676">
<figcaption aria-hidden="true">1745079894676</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894659.jpg" alt="1745079894659">
<figcaption aria-hidden="true">1745079894659</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894631.jpg" alt="1745079894631">
<figcaption aria-hidden="true">1745079894631</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894645.jpg" alt="1745079894645">
<figcaption aria-hidden="true">1745079894645</figcaption>
</figure>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>天下英雄如过江之鲫</title>
    <url>/2025/06/24/diary/%E5%A4%A9%E4%B8%8B%E8%8B%B1%E9%9B%84%E5%A6%82%E8%BF%87%E6%B1%9F%E4%B9%8B%E9%B2%AB/</url>
    <content><![CDATA[<p>当你来到双非，你会艳羡211的牌子，当你拼死考上211，你会发现985的头衔会处处卡死你。当你侥幸考上末流
985，你就会发现华五c9的光芒压的你喘不过气。若你真问鼎华五，抬头看，京城中双日凌空。或许你是真正的天才，清北中的佼佼者，他们告诉你，世界不止中国。当你最终成为这一世最不折不扣的天才，你会发现欧拉，黎曼，还有7岁因为想快点放学而创造求和公式的高斯，
早已在山顶等候多时。</p>
<p>有时候想想，这学上到多高才算高啊，大专上面有本科，本科上面有硕博，好不容易毕业了吧，副高，正高，青基，博导，在上面还有杰青，院士。唉，天下英雄，如过江之鲫，无穷尽也。之前没有感觉，自从上了大学，这种感受就像一团乌云一直萦绕在我心头，不禁反思人这一生究竟在追求什么。</p>
<p>大多数人追求的东西，无非三者：权钱学。</p>
<p>有的人梦想升官，但官外有官，权外有权，科级处级厅级，省部级已经算是人中龙凤，但上面还有副国级正国级，大多数人忙忙碌碌一生也就当个副处级，他们真的甘心吗，那种拼劲全力也无法跨过的鸿沟，最后只剩下无奈，遗憾和释然。</p>
<p>有人的渴望财富，赚到了十万就想赚百万，赚到了百万又开始想办法，想赚千万，亿，觉得自己有能力了，开始创业投资，拿着钱去炒股炒币最后赔了个精光，更有甚者权钱勾结，做些不法勾当，不都是为了满足自己的贪婪，但欲望无穷无尽，何时才能填满这个无底洞，更可怕的是，多少人的欲望和他的能力并不符合，自身没有那么大的能力却渴望一切，最后只会反噬，自食其果。</p>
<p>有的人钻研学识，中国的大多数人都是通过高考这一途径踏进学识的殿堂，那些在高中自命不凡的天才们，进入了高校才发现，自己只是芸芸众生的普通一员，以前的光辉也变的暗淡无光，即便是清北级别，已经是很多人可望而不可即的存在，在面对越来越难的知识，在面对更聪明的身边人，在发现自己再努力也无法达成目标时，也会学习释然这一门课。</p>
<p>我想起来看过的一个清华物理系同学的采访，有一句话我印象很深刻，古人会说少壮不努力，老大徒伤悲，但不会说少壮不成功，老大徒伤悲，或许我上面说的这些，都太注重结果了，以结果的好坏判定了过程的意义，这是不对的，在追求这些目标的过程中，我们努力了，拼搏了，奋斗了，其实那就足够了，不应该把结果失利的压力强加在自己身上。</p>
<p>唉，这些说起来容易，真正能做到不为结果所动哪里容易呢，只跟自己比较，不与他人攀比，处之泰然地面对任何困难与挑战。这就是我所追求的心境吧，我什么时候能做到这种地步，可能才是真正的长大了吧。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>笨鸟的共鸣</title>
    <url>/2024/11/25/diary/%E7%AC%A8%E9%B8%9F%E5%85%88%E9%A3%9E/</url>
    <content><![CDATA[<h2 id="笨鸟的共鸣">笨鸟的共鸣</h2>
<p>​
今天刷谈笑间，看的一位同学很沮丧，说自己在南师大感受到了前所未有的压力，自己是高考发挥超常才来到南师大的，而身边很多同学却是高考发挥失常，在大学的学习中感受同辈人巨大的压力，不禁让我引起共鸣。别人的失常发挥上的学校，却是高中三年竭尽全力的结晶，甚至是高考的超常发挥才带来的。想到这里，我不禁再次感慨人与人之间差距的巨大。</p>
<p>​
但是，大一一年已经过去，回望这一年，笨鸟变了吗，变了，这只原来的笨鸟也获得很多成就，也在成长，也遇到很多同行路上的好友，甚至也成了别人口中的优秀者。但他真的变了吗，其实没变，他还是那只笨鸟，天赋比他好的大有人在，比他努力者也数不胜数，他始终要以一种谦逊的态度，然后不断学习，不断奔跑。高中，大学，都只是一个跳板，这种笨鸟天生不会飞，通过这一个个跳板，爬至高处，才能看见世间美景。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>未来的选择</title>
    <url>/2025/03/01/diary/%E6%9C%AA%E6%9D%A5%E7%9A%84%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<h3 id="未来的选择">未来的选择</h3>
<p>前一阵子与很久不见的学长交谈了一阵，两个小时感觉转瞬即逝，从未来选择到现在学业，和学长的交谈总能让我醍醐灌顶。我很喜欢和优秀的人谈话，他们的想法和建议总能让我豁然开朗。我最近一直对未来的选择十分迷惘，想学的东西太多，但时间精力有限，这时候就不得不做出选择。我需要好好想想我未来到底想从事什么方向的工作，并以此为目标钻研下去，而不是像无头苍蝇一样这学一点那学一点，泛而不精的人企业是不会要的。</p>
<p>摆在我眼前的有三个选择，第一个，我最近一直在看前端的知识，并跟着网上的教程编点小项目实操一下，我考虑的是一方面大创需要前端，我近期就可以用得上，另一方面我学的并不是前端很深入的知识，做一个知识上的普及还是有必要的；第二个，近期又来到计算机设计大赛的时间点，我要不要重拾unity的学习，后面走unity游戏开发方向的工作呢。但其实现在这个我不考虑了；第三个，我个人对金融，投资很感兴趣，我自己又是人工智能专业，后续去香港留学也想走ai+金融的方向，我是不是应该把更多的时间用在学习ai相关呢。</p>
<p>学长建议我还是要把更多的时间花在ai相关的学习，现在ai正是主流方向，沿着这个方向努力肯定是不会有问题的，平时要把人工智能相关的专业课，比如机器学习等，学扎实，而且我既然打算香港读研也是这个方向，就更要把时间花在这个地方。后续我打算把手头的项目写完后，有时间就开始在网上学习相关知识。</p>
<p>感觉废话有点多了，特别是上大学之后，选择与方向真的太多，但不管是哪个选择，都要大步走下去，而不是犹犹豫豫原地踏步，任重而道远啊！</p>
<p>最后说点题外话，把能认识到像学长这样优秀的人，我着实感到十分幸运。这两天又看了看学长的博客，每次看都能让我受益良多，我能开始写博客很大部分也受他的影响，但相比之下，确实感到自惭形愧，向学长学习！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>大风起兮云飞扬</title>
    <url>/2024/10/15/%E6%96%87%E6%A1%88/%E5%88%98%E9%82%A6/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>史书上轻轻翻过的一页，便是他们波澜壮阔的一生。鉴史可以明志，知古方能鉴今，以史为镜，可以知兴替。我虽然是一位理科生，但我心里一直深知历史的重要，历史不是冰冷的文字，而是充满温度的生命轨迹。那些沉浮于历史长河中的伟大人物，用他们的智慧与勇气改写了时代的篇章，也为后人留下了宝贵的思想财富。迷茫时读史，退缩时读史，困惑时读史，或许都会有不一样的收获。</p>
<hr>
<p>刘邦，</p>
<p>38岁，一事无成，骗吃骗喝，娶了老婆。 48岁，被逼无奈，起兵反秦。
50岁，被项羽吓得跪地求饶。 51岁，被项羽打得丢盔弃甲，老婆、父亲都被抓。
54岁，建立汉朝，君临天下。 55岁，干翻曾经对他豪横的人。</p>
<p>七年时间，纵横四海，天下归一。 60岁，出征匈奴。
62岁，衣锦还乡时，写下大气磅礴的《大风歌》：</p>
<blockquote>
<p>大风起兮云飞扬， 威加海内兮归故乡， 安得猛士兮守四方。</p>
</blockquote>
<p>有人少年得志，有人大器晚成。人生从来没有太晚的开始，尽自己最大的努力，你也只是在等待一个时机。</p>
<hr>
]]></content>
      <categories>
        <category>文案</category>
      </categories>
      <tags>
        <tag>文案</tag>
      </tags>
  </entry>
  <entry>
    <title>为何需要专一</title>
    <url>/2024/10/29/%E6%96%87%E6%A1%88/%E4%B8%BA%E4%BD%95%E4%B8%93%E4%B8%80/</url>
    <content><![CDATA[<h2 id="为何需要专一">为何需要专一</h2>
<p>以下源自网络</p>
<p>精神层次越高的人对感情越专一，因为善于处理自己内心欲望，因而不会把类似找备胎、和谁玩、玩过谁，这种肤浅的价值观当作得意的谈资。他们更愿意跟某个人担起生活的风雨，因为时间都用来做正经的事情，所以左顾右盼不代表你赢了，花哨是因为你层次太低。欲望是人性，克制是教养，新欢旧爱迎来送往，你以为的魅力难挡实则廉价百搭，得陇望蜀、骑驴找马、悲凉的让人生厌且鄙弃。道德不能杀掉带给我痛苦的人，所以我只能杀死理智和感性的自己。忠诚和专一是最基本的原则和底线，但它也只是三观正且有教养的人对感情中的自我约束</p>
]]></content>
      <categories>
        <category>文案</category>
      </categories>
      <tags>
        <tag>文案</tag>
      </tags>
  </entry>
  <entry>
    <title>AIGC——中数杯</title>
    <url>/2024/12/05/%E6%AF%94%E8%B5%9B/%E4%B8%AD%E6%95%B0%E6%9D%AF/</url>
    <content><![CDATA[<h1 id="老匠新传">《老匠新传》</h1>
<p><strong>背景剧情：</strong></p>
<p>在安徽省一个偏远小山村里，住着一位年迈的老匠人程老。他是村里最后一位木雕匠，祖传的技艺如今面临失传的窘境。一天，城市的女孩小林，来到了这个小山村。她被精致的雕刻作品和老人的精湛技艺所吸引，留下来悉心学习这传统技艺。</p>
<p>多年后，女孩学成回到城市。她呼吸着浮躁的空气，下定决心在城市的一隅开设了一家雕刻工作室。门口摆放着一只木雕鸟，和曾经吸引她踏入木雕门扉的那只一般，精致而美丽。但是简约的线条又让它显得轻盈而现代。</p>
<p>“那是一块文化的拼图，串起了过去岁月的技艺，和当代创新的潮流。”</p>
<p><strong>创作理念：</strong></p>
<p>我们的故事从安徽省一个偏远小山村的年迈木雕匠人程老为起点，通过他与来自城市的女孩小林之间的师徒传承，展现传统技艺在现代社会中的困境与重生。</p>
<p>文化传承：我们希望强调了传统技艺的文化价值，如木雕这一几代人相传的技艺，不仅是技艺本身，更是一种文化的延续。程老作为村里最后一位木雕匠，他的技艺和作品承载着丰富的历史和文化信息。</p>
<p>师徒传承：通过小林对程老技艺的学习和传承，我们希望展现师徒之间深厚的情感纽带和技艺的传递。这种传承不仅是对技艺的保存，更是对文化精神的延续。</p>
<p>创新融合：小林学成后，在城市开设雕刻工作室，将传统技艺与现代审美相结合，创作出既具有传统韵味又符合现代审美的作品。其中表达着对传统文化的创新和发展，以及传统技艺在现代社会中焕发出新的生命力。</p>
<p>文化自信：故事中的小林在回到城市后，能够自信地展示和推销自己的作品，体现了对传统文化的自信和自豪感。</p>
<p><strong>艺术表达：</strong></p>
<p>我们采用现代的技术载体讲述传统技艺的传承和新生，希望增添作品的现实意义。</p>
<p>细节描写：故事中对木雕作品的细节描写，如“精致的雕刻作品”和“一只木雕鸟”，不仅展现了程老技艺的精湛，也通过小林对这些作品的喜爱和学习，传递了她对传统文化的热爱和尊重。</p>
<p>情感渲染：通过小林与程老之间的互动，以及小林学成后回到城市的心理变化，渲染师徒之间的深厚情感和传统文化的厚重感。</p>
<p>象征手法：木雕鸟作为故事中的象征物，既代表了程老的技艺传承，也象征着传统技艺在现代社会中的重生和创新。它的“精致而美丽”和“简约的线条”既体现了传统技艺的精髓，又融入了现代审美元素。</p>
<p>语言风格：故事中的语言风格简洁明了，富有诗意。</p>
<p><strong>使用技术：</strong></p>
<p>图像生成：首先训练GPT-4成为Midjourney提示词生成器。然后通过文字描述剧本中的场景，获取提示词。最后使用Midjourney生成场景图片，进行筛选。</p>
<p>视频生成：我们利用可灵AI进行视频的制作，我们使用生成的图片生成初版视频，然后通过提示词进行多次约束，修改，最后剪辑合并。</p>
]]></content>
      <categories>
        <category>竞赛</category>
      </categories>
      <tags>
        <tag>竞赛</tag>
      </tags>
  </entry>
  <entry>
    <title>2024小美赛</title>
    <url>/2024/11/30/%E6%AF%94%E8%B5%9B/2024%E5%B0%8F%E7%BE%8E%E8%B5%9B/</url>
    <content><![CDATA[<h1 id="论文阅读jupiter-friend-or-foe-an-answer">论文阅读：Jupiter:
friend or foe? An answer</h1>
<p>奥尔特云：</p>
<p><a href="https://zh.wikipedia.org/zh-cn/奥尔特云#潮汐力效應">奥尔特云
- 维基百科，自由的百科全书</a></p>
<p>长周期彗星：这些天体来自奥尔特云，周期超过200年，具有完整的轨道倾角范围，由
1012-1013 个冰体组成，其中绝大多数的直径小于 10
公里，并占据一个距离太阳约 103-105 天文单位的厚球形壳</p>
<p>短周期彗星：一般认为来自于柯伊伯带或离散盘。周期在200年以下</p>
<p>短周期彗星有两大类：木星族彗星（<a href="https://zh.wikipedia.org/wiki/半長軸">半长轴</a>小于5天文单位）及哈雷类彗星</p>
<p><a href="https://zh.wikipedia.org/wiki/短周期彗星">短周期彗星 -
维基百科，自由的百科全书</a></p>
<p>木星族:<a href="https://baike.baidu.com/item/木星/0?fromModule=lemma_inlink">木星</a>有时会缩短一颗彗星的运动周期，有时会延长一颗彗星的运动周期，有时会改变彗星轨道，从而使得周期彗星变成<a href="https://baike.baidu.com/item/非周期彗星/407319?fromModule=lemma_inlink">非周期彗星</a>，反过来也一样。周期3-10年，远日点在木星轨道附近的彗
星称为木星族彗星。</p>
<p>改变木星轨道上巨星的质量Y来 自小行星带的轰击</p>
<p>我们研究了改变“木星”质量对地球从小行星带向内抛出的物体所经历的撞击率的影响。我们在模拟冲击通量时遇到了一些问题。小行星被认为构成了最大的威胁。然而，在创建一群可能进化到撞击地球轨道的测试小行星时，我们面临着巨大的不确定性，特别是<strong>与整合开始时小行星的分布有关的不确定性</strong>。</p>
<p>因为自木星形成以来，它一直在扰乱目前在小行星带中观察到的物体的轨道。因此，尝试为这颗小行星构建一个受干扰程度要小得多的初始种群是很重要的</p>
<p>我们 2008 年的论文详细介绍了我们如何确定小行星分布，<span class="math inline">$\ N_{0}(a)=k(a-a_{min})^\frac{1}{2}$</span>，其中
N（a） 是距离太阳 a 的小行星数量，k 是常数，<span class="math inline"> <em>a</em><sub><em>m</em><em>i</em><em>n</em></sub></span>
是小行星分布的内部边界。<span class="math inline"> <em>a</em><sub><em>m</em><em>i</em><em>n</em></sub></span>的值为1.558AU，相当于火星的轨道半长轴，1.52
AU，加上三个 希尔半径</p>
<p>归一化常数 k 的确定 为了使总的小行星数量 <span class="math inline"> <em>N</em><sub><em>t</em><em>o</em><em>t</em><em>a</em><em>l</em></sub></span>,
为一个固定值，我们需要对 N(a)进行归一化。通过对 N(a)在范
围[amin,amax]内积分，可以得到归一化常数 k</p>
<p><span class="math inline">$\
k=\frac{3N_{total}}{2(a_{max}-a_{min})^\frac{2}{3}}$</span></p>
<p>希尔半径<span class="math inline">$\
R_{H}=a_p(\frac{M_{planet}}{3M_{Sun}})^\frac{1}{3}$</span>，ap
是行星轨道的半长轴，M
表示质量。希尔球半径是一个天体对其周围物体产生重力影响的范围</p>
<p>以这种方式创建的物体代表一个碎片圆盘，在行星形成过程中受到了适度但不过度的搅拌（例如
Ward 2002）。</p>
<p>然后，在地球、火星、木星、土星、天星和海王星的影响下，使用 MERCURY
包中包含的混合积分器对测试粒子进行了 1000
万年的跟踪。进行了简单的测试积分，以检查地球横截面积对所经历的冲击通量的影响。<strong>正如预期的那样，发现撞击率与地球的横截面积成正比，引力聚焦的影响可以忽略不计</strong>。为了<strong>提高撞击率以获得合理的撞击统计数据</strong>，因此我们将地球膨胀到
<span class="math inline"> 10<sup>6</sup></span>
公里的半径。在我们的整合中，小行星与行星和太阳发生引力相互作用，但<strong>彼此之间没有相互作用</strong></p>
<p>我们运行中使用的 “Jupiter” 经过修改，因此我们运行了 12
个单独的质量。在木星质量 MJ
的倍数中，这些是：0.01、0.05、0.10、0.15、0.20、0.25、0.33、0.50、0.75、1.00、1.50
和
2.00。每个“木星”的轨道元素与今天的木星相同。同样，模拟中其他行星的元素与今天相同：一次运行和下一次运行之间行星<strong>设置的唯一区别是木星质量的变化——所有其他变量都是恒定的</strong>。</p>
<p>显示了我们的模拟中 通量与质量关系的形式，其中小行星是
源群体。这些结果令人惊讶。在 1.00 M J 时，对地球的撞击次数约为 0.01 M J
时的撞击次数的 3.5 倍Y几乎没 有屏蔽！在这两个”木星”质量之间， 在 0.2 M J
左右存在一个峰值，其中撞 击次数几乎是 1.00 M J 时的两倍。</p>
<figure>
<img src="/2024/11/30/%E6%AF%94%E8%B5%9B/2024%E5%B0%8F%E7%BE%8E%E8%B5%9B/asdasd.png" alt="asdasd">
<figcaption aria-hidden="true">asdasd</figcaption>
</figure>
<p>我们随机生成了 100 000 个测试群体粒子，近日点位于 0.1– 10 AU
范围内，远日点位于 10 000 和100 000 个AU。人口的结构是为
了模仿观察到的长周期彗星的远日点 分布。近日点距离 q 确定如下<span class="math inline">$\
q=0.1+[(q_{max}-q_{min})^\frac{2}{3}*random]^\frac{2}{3}$</span>其中
<span class="math inline"> <em>q</em><sub><em>m</em><em>a</em><em>x</em></sub></span>
和<span class="math inline"> <em>q</em><sub><em>m</em><em>i</em><em>n</em></sub></span>分别是
0.1 和 10 AU 的最大和最小可能近日点 距离，而 random 是在克隆程序中
生成的 0 到 1 之间的随机数。这导 致大约 3% 的初始样本具有与地球
轨道交叉的轨道（地球交叉轨 道），大约 38% 位于最初与木星 交叉的轨道（q
小于或等于 5.203 AU 的轨道）。这个分布是一个简
单但有效的尝试，试图拟合新奥尔 特云彗星的已知分布</p>
<p>我们计算了奥尔特云 彗星在（膨胀的）地球上的碰撞次
数。需要采取不同的方法。奥尔特 云彗星的轨道周期是如此之大，以 至于即使在
100 Myr 的模拟中，即 使地球严重膨胀，也很少会与地球
近距离接触。因此，为了直接确定 对地球的撞击率，我们必须模拟大
量的测试粒子，其数量级比所使用 的粒子高出许多数量级</p>
<p>我们模拟中使用的”木 星”的质量被修改了从一个场景到
下一个场景。总共考虑了五种不同 的场景。研究了质量为木星质量
0.25、0.50、1.00 和 2.00 倍 的”木星”系统，以及不存在木星
的系统。和以前一样，场景之间的 唯一区别是木星的质量Y所有其
他参数都是恒定的。</p>
<p>大质量情况下彗星的消失速度 明显快于低质量木星的情况。即使 仅在 1 Myr
后，木星质量较高的喷 射率就很明显，并且一直持续到我
们模拟的最后，到那时，在所有情 况下，仅保留了初始彗星种群的一
小部分。</p>
<p>值得注意的是，即使没有 木星存在，到运行结束时，长周期
彗星的数量仍然会显着减少。由于 木星不存在（“木星”质量为 零）</p>
<p>。当考虑基于喷射率的初始代理 的结果时，重要的是要确保该措施
是实际上是冲击通量的合适代理。 例如，地球上的碰撞率似乎可能并
不简单地与幸存的奥尔特云彗星的 数量成正比。特别是，另外两种可
能性似乎值得进一步研究，以确保 我们最初的假设是正确的：考虑到
所研究的彗星轨道的扩展，重要的 是要检查是否存在穿过地球轨道的
奥尔特云彗星的优先生存（ q &lt; 1 AU)，或那些不存在的 (q &gt; 1
AU)。</p>
<p>换句话说，当考虑到长周期彗星通量（与我们之前
的发现相反），一颗质量更大的木星 肯定会在不存在这样的行星的情况下
为地球提供一些可测量的屏蔽。</p>
<p>事实上，只有在来自奥尔特 云的彗星的情况下，我们的结果表
明木星确实是长期以来所假设的地 球的朋友！</p>
<p>然而，应该指出的 是，在长周期轨道上运动的物体平
均而言通常比在短周期或星状轨道 上运动的物体具有更大的碰撞速度
（这是由于它们较高的倾角[包括逆 行轨道]和更大的轨道）速度为 1 天
文单位），这增加了奥尔特云彗星 作为轰炸机群体的相对重要性。</p>
<p>作 为一个整体，我们的工作表明，而 不是充当作为地球的盾牌，木星反
而增加了我们星球所经历的冲击通 量，超过了如果这颗行星以某种方
式神奇地从我们的太阳系中移走时 所受到的冲击通量。然而，如果木
星的质量减少到土星的质量，地球 的情况会更糟</p>
<p>事实上，只有在来自奥尔特 云的彗星的情况下，我们的结果表
明木星确实是长期以来所假设的地 球的朋友！</p>
<figure>
<img src="/2024/11/30/%E6%AF%94%E8%B5%9B/2024%E5%B0%8F%E7%BE%8E%E8%B5%9B/4dd5a3dac2ad91f343c275db992ed5a.png" alt="4dd5a3dac2ad91f343c275db992ed5a">
<figcaption aria-hidden="true">4dd5a3dac2ad91f343c275db992ed5a</figcaption>
</figure>
<p>我们的结果令人震惊。对于当前时代威胁地球的两个主要种群（近地小行星
和短周期彗星），我们发现木星质量与撞击率之间的关系相当复杂。在”木星”质量
较低的情况下，两颗行星的撞击率都非常低，因为这些小行星很难在地球交叉轨道上
放置物体。同样，在高”木星”质量（类似于或大于我们的木星）时，两个种群的撞
击率都相对较低，尽管略高于质量最小的”木星”。然而，在这两个极端之间，我们
在模拟中发现地球上的撞击通量出现了显着的峰值。对于近地小行星(Horner
&amp; Jones, ̚ ̘ ̘ ̠ b)和短周期彗星(Horner &amp; Jones,
2009)，我们发现当模拟中的”木
星”在0.2到0.3倍之间时，撞击通量最大。和我们的木星一样大。换句话说，与质量
小得多的情况相比（例如，当它的质量与海王星相当时），我们的木星仅提供适度的
屏蔽，但如果它围绕土星的质量，那么地球上的撞击通量将是远远大于我们观察到
的。</p>
<p>当我们研究木星质量对第三种潜在危险天体M长周期彗星M的撞击率的影响时
（例如 Wiegert &amp; Tremaine, 1999, Levison, Dones &amp;Duncan, 2001,
Horner &amp; Evans,
2002），我们发现”木星”质量越大，对地球的撞击率就越低（Horner，Jones
&amp;钱伯斯，
2010）。那么，对于长周期彗星来说，木星似乎确实起到了盾牌的作用。然而，长周期彗星
被认为只对小行星和彗星对地球的影响贡献了一小部分（</p>
<p>这是否也在确定其宿主系统中潜在宜居行星的撞击通量中
发挥作用？在这项工作中，我们通过检查木星轨道偏心率和倾角的影响，建立在早期结果
的基础上。在这项工作中，我们只考虑两个主要的撞击星群M近地小行星和短周期彗星。
由于长周期彗星在轨道倾角基本上各向同性分布的轨道上运行，并且几乎不受太阳系引力
约束，因此可以合理地假设木星轨道的微小变化对彗星通量几乎没有影响或没有影响。</p>
<p>总体而言，很明显，巨行星轨道偏心率的增加会导致近地小行星和短周期彗星对地球的
撞击通量增加。</p>
]]></content>
      <categories>
        <category>竞赛</category>
        <category>数学建模</category>
      </categories>
      <tags>
        <tag>竞赛</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>决战蓝桥杯</title>
    <url>/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>好久不编算法了，为了不让300r打水漂，废话不多说，决战蓝桥杯！！！</p>
<p>我是算法彩笔，而且python也不是很会用，所有刷题刷的很慢，后续会把文件整理上传GitHub</p>
<p>思考了一下，因为时间紧迫，没有时间复盘每一道题了，这一篇文章简单记录一下进度</p>
<h2 id="进度记录">进度记录</h2>
<p>3.13</p>
<p>贪心：1.力扣406. 根据身高重建队列2.P10387 [蓝桥杯 2024 省 A]
训练士兵3.蓝桥杯真题 谈判</p>
<p>3.14</p>
<p>贪心：1.蓝桥杯真题 翻硬币</p>
<p>bfs：1.蓝桥杯真题 扫雷2.蓝桥杯真题 长草3.力扣695.岛屿的最大面积</p>
<p>3.16</p>
<p>哈希：1.力扣 两数之和</p>
<p>前缀和：1.洛谷 求区间和</p>
<p>二分问题：1.洛谷 查找</p>
<p>dfs：1.蓝桥杯真题 小朋友崇拜圈2.蓝桥杯真题 最大数字</p>
<p>3.17</p>
<p>二分问题：1.力扣 统计公平数对的数目2.力扣
2226.每个小孩最多能分到多少糖果</p>
<p>3.18</p>
<p>二分答案：1.蓝桥杯真题 冶炼金属</p>
<p>并查集：1.洛谷P1551 亲戚2.洛谷P1536 村村通</p>
<p>3.19</p>
<p>哈希：1.力扣 3080.执行操作标记数组中的元素</p>
<p>堆：1.力扣 2530.执行k次操作后的最大分数</p>
<p>动态规划：1.力扣 70.爬楼梯2.力扣 198.打家劫舍3.P1048 [NOIP 2005
普及组] 采药4.力扣 494. 目标和5.力扣 322.零钱兑换</p>
<p>3.21</p>
<p>动态规划：1.力扣 2915.和为目标值的最长子序列的长度2.蓝桥杯真题
蓝桥课程抢购3.力扣518. 零钱兑换 II</p>
<p>图论：1.力扣1971.寻找图中是否存在路径</p>
<p>3.25</p>
<p>图论：1.力扣743.网络延迟时间</p>
<p>数论：1.蓝桥杯真题 数字诗意</p>
<p>3.26</p>
<p>贪心：1.蓝桥杯真题 回文数组</p>
<p>图论：1.力扣 1584.连接所有点的最小费用2.蓝桥杯真题 城市规划大师</p>
<p>3.27</p>
<p>动态规划：1.力扣1143.最长公共子序列2.蓝桥杯真题
查找最长公共子序列3.力扣583.两个字符串的删除操作</p>
<p>3.28</p>
<p>动态规划：1.蓝桥杯真题 砍柴</p>
<p>3.30</p>
<p>贪心：1.蓝桥杯真题 三国游戏2.蓝桥杯真题 平均</p>
<p>暴力：1.蓝桥杯真题 翻转</p>
<p>单调队列，单调栈：1.力扣239.滑动窗口最大值2.力扣739.每日温度3.力扣42.接雨水</p>
<p>双指针：1.力扣209.长度最小的子数组2.力扣3.无重复字符的最长字串3.力扣713.乘积小于k的子数组</p>
<p>3.31</p>
<p>二维单调队列：1.蓝桥杯真题 子矩阵（拼劲全力无法战胜，放弃）</p>
<p>4.1</p>
<p>数论：1.蓝桥杯真题 阶乘的和2.蓝桥杯真题 质因数个数</p>
<p>树：1.蓝桥杯真题 子树的大小</p>
<p>4.4</p>
<p>模拟：1.蓝桥杯真题 消除游戏</p>
<p>4.5</p>
<p>差分：1.蓝桥杯真题 重新排序2.力扣1094.拼车</p>
<p>动态规划：1.蓝桥杯真题 全排列的价值2.力扣300.最长递增子序列</p>
<p>贪心：1.蓝桥杯真题 优清零方案</p>
<p>4.9-11</p>
<p>刷填空题</p>
<p>4.12后记：也是考完蓝桥杯了，后面应该很长时间不碰算法了嘿嘿</p>
<h2 id="正文">正文</h2>
<h3 id="算法基础">算法基础</h3>
<h4 id="快读模板">快读模板</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入系统模块</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment"># 重定义input函数，用于快速读取输入</span></span><br><span class="line"><span class="comment"># sys.stdin.readline() 比 python 自带的 input() 快</span></span><br><span class="line"><span class="comment"># strip() 用于去除行末的换行符</span></span><br><span class="line"><span class="built_in">input</span> = <span class="keyword">lambda</span>:sys.stdin.readline().strip()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312124949702.png" alt="image-20250312124949702">
<figcaption aria-hidden="true">image-20250312124949702</figcaption>
</figure>
<h4 id="输入">输入</h4>
<figure>
<img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312130008507.png" alt="image-20250312130008507">
<figcaption aria-hidden="true">image-20250312130008507</figcaption>
</figure>
<h4 id="列表推导器">列表推导器</h4>
<figure>
<img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312131643035.png" alt="image-20250312131643035">
<figcaption aria-hidden="true">image-20250312131643035</figcaption>
</figure>
<h2 id="参考文献">参考文献</h2>
<p>竟然在b站刷到学长做的视频，太惊喜了，真是雪中送炭</p>
<p><a href="https://www.bilibili.com/video/BV1wcR3Y5EMg/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【蓝桥杯】Python速成
刷题指南_哔哩哔哩_bilibili</a></p>
<p><a href="https://wiki.dwj601.cn/ds-and-algo/templates-py/">代码模板
(Python) - Open Wiki Community</a></p>
<p><a href="https://github.com/TsingPig/LanQiao_Python">TsingPig/LanQiao_Python:
视频合集
https://space.bilibili.com/398421867/lists?sid=4898042&amp;spm_id_from=333.788.0.0</a></p>
<table>
<colgroup>
<col style="width: 60%">
<col style="width: 39%">
</colgroup>
<thead>
<tr>
<th>补充资料</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>https://wiki.dwj601.cn/ds-and-algo/templates-py/</td>
<td>【★★★★★】Python代码模板</td>
</tr>
<tr>
<td>https://www.lanqiao.cn/problems/?first_category_id=1</td>
<td>蓝桥题库</td>
</tr>
<tr>
<td>https://ac.nowcoder.com/acm/problem/collection/6999</td>
<td>牛客蓝桥寒假题单</td>
</tr>
<tr>
<td>https://www.luogu.com.cn/training/list</td>
<td>洛谷题单</td>
</tr>
<tr>
<td>https://leetcode.cn/u/endlesscheng/</td>
<td>力扣分类题单（进入点击“讨论发布”）</td>
</tr>
<tr>
<td>https://www.lanqiao.cn/paper/</td>
<td>【★★★★★】蓝桥杯真题卷模拟系统</td>
</tr>
<tr>
<td>https://leetcode.cn/problemset/</td>
<td>力扣题库</td>
</tr>
</tbody>
</table>
<p>讲的很好的视频</p>
<p><a href="https://leetcode.cn/discuss/post/3141566/ru-he-ke-xue-shua-ti-by-endlesscheng-q3yd/">分享｜如何科学刷题？-
讨论 - 力扣（LeetCode）</a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>蓝桥杯</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>名言警句</title>
    <url>/2024/10/15/%E6%96%87%E6%A1%88/%E5%90%8D%E8%A8%80/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>我语文不好，始终羡慕那些说话出口成章，底蕴深厚，时不时冒出几句金句的人，所以，为了让我这么一个没有什么文化底蕴的人，说话不至于太俗气，既然我不会说，那我便学名人说，便有了记录名言警句的习惯，此外，这些名言警句背后的哲理，也经常能让我醍醐灌顶。之前在网上看到一些名言警句，就会顺手记录在手机的备忘录上，现在整理下来，希望再看到时能有所收获。我说的名人警句，不光是真正意义上的名人说的，其中也有部分是我看到网友写的，我觉得，学习一切可以学习的，任何人都可以是我的老师，他们很多的文字也能给我很大感触。</p>
<hr>
<h3 id="励志与挑战">1. <strong>励志与挑战</strong></h3>
<ul>
<li><strong>十年运到龙困井，一朝得势入青云</strong></li>
<li><strong>命定的局限尽可永在，不屈的挑战却不可须臾或缺</strong>
——《霍乱时期的爱情》</li>
<li><strong>受任于败军之际,奉命于危难之间</strong>
——诸葛亮《出师表》</li>
<li><strong>他时若遂凌云志，敢笑黄巢不丈夫</strong> ——唐代罗隐</li>
<li><strong>燕雀安知鸿鹄之志</strong> ——《史记·陈涉世家》</li>
<li><strong>攻心为上,攻城为下</strong> ——《孙子兵法》</li>
<li><strong>技不外漏，海不露底，千两黄金不卖道，十字街头送故交</strong></li>
<li><strong>将军不下马，各自奔前程</strong></li>
<li><strong>胜败兵家事不期，包羞忍耻是男儿</strong>
——宋代陆游《秋夜将晓出篱门迎凉有感二首》</li>
<li><strong>大丈夫生于天地之间，岂能郁郁久居人下</strong>
——《三国志·蜀书》</li>
<li><strong>江东子弟多才俊，卷土重来未可知</strong>
——唐代杜牧《题乌江亭》</li>
<li><strong>一位大师曾经说过要像水一样，那我应该就是海啸吧！</strong></li>
<li><strong>命数如织，当为磐石</strong></li>
</ul>
<h3 id="爱情与亲密关系">2. <strong>爱情与亲密关系</strong></h3>
<ul>
<li><strong>我想要爱、激情、真诚和亲密的关系、性，这些使我鲜活，然唯有灵魂的交流使我平静</strong></li>
<li><strong>一顾倾人城，
再顾倾人国。宁不知倾城与倾国？佳人难再得</strong>
——《汉书·李延年传》</li>
<li><strong>不见鹿，不见鲸，亦不见你</strong></li>
</ul>
<h3 id="人生与哲理">3. <strong>人生与哲理</strong></h3>
<ul>
<li><strong>你不妨大胆去冒险，只因生命终将逝去</strong> ——尼采</li>
<li><strong>人生不需要意义，意义需要人生</strong></li>
<li><strong>我曾踏足山巅，也曾进入谷底，二者都让我受益良多</strong></li>
<li><strong>旧游无处不堪寻。无寻处、惟有少年心</strong>
——宋代辛弃疾《南乡子·登京口北固亭有怀》</li>
<li><strong>天下万般兵刃 唯有过往伤人最深</strong></li>
<li><strong>我见青山多妩媚,料青山见我应如是</strong>
——宋代辛弃疾《贺新郎·别茂嘉十二弟》</li>
<li><strong>如果真相带来痛苦，谎言只会雪上加霜</strong></li>
<li><strong>花团锦簇的节日用来铭记逝者，而我，宁愿被人遗忘</strong></li>
<li><strong>坟墓里寂静无比,埋葬你的是所有你没说出口的话</strong></li>
<li><strong>世界既不黑也不白，而是一道极致的灰</strong></li>
<li><strong>梦醒时夜续，惊慌失措</strong></li>
</ul>
<h3 id="自由与个性">4. <strong>自由与个性</strong></h3>
<ul>
<li><strong>因为生活过于教条，所以格外欣赏自由野性的东西</strong></li>
<li><strong>是俗是雅，我已经分不清了，我只知道月亮正圆，我若不看一眼，倒显得我不解风情了</strong></li>
<li><strong>国王们以世袭的权柄和虚名逼你下跪，诺克萨斯要你站起来，要你在荣耀中重获新生</strong></li>
</ul>
<h3 id="孤独与感伤">5. <strong>孤独与感伤</strong></h3>
<ul>
<li><strong>忽有清风化剑气,直斩少年二十意</strong></li>
<li><strong>生活的底片从来都不是遥远的白日梦，而是热爱生活的自己</strong></li>
<li><strong>黄昏见证虔诚的信徒，巅峰诞生虚伪的拥护</strong></li>
<li><strong>假作真时真亦假，无为有处有还无</strong> ——《红楼梦》</li>
<li><strong>林深时雾起，不见归处</strong></li>
<li><strong>海蓝时浪涌，望而却步</strong></li>
</ul>
<h3 id="经典与历史">6. <strong>经典与历史</strong></h3>
<ul>
<li><strong>朕非亡国之君，臣乃亡国之臣</strong>
——明代崇祯帝与大臣对话</li>
<li><strong>满腹经纶书香气,腹有诗书气自华</strong></li>
<li><strong>天下熙熙，皆为利往</strong> ——《史记·货殖列传》</li>
<li><strong>竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生</strong>
——宋代苏轼《定风波》</li>
<li><strong>回首向来萧瑟处，归去，也无风雨也无晴</strong>
——宋代苏轼《定风波》</li>
<li><strong>既生瑜何生亮</strong> ——《三国演义》</li>
<li><strong>欲买桂花同载酒，终不似，少年游</strong>
——宋代刘过《唐多令》</li>
<li><strong>愿以深心奉尘刹，不予自身求利益</strong> ——明代张居正</li>
</ul>
<h3 id="长文">7.长文</h3>
<p>最绝望的人有三种，第一种是始出初之人，他没有同类，而身边全是未知，他无时无刻都在害怕着，你无法想象他是如何作为第一个人活下去的，因为他活着这件事本身，就已经违背了他被创造出来的本能。第二种是终焉之人，他也曾拥有同类，而现在，他便是最后之人，在迎接终焉时，他并不会感到孤单，因为同类早已用别的方式存在于他身上。他只能在可以活动的范围内活动，这使他对环境非常了解，了解到令自己感到绝望。第三种是活着之人，活着本身就是一种折磨，当你足够冷静时，你会发现，你做的一切都对自己没有任何意义，你本是一粒尘埃，最后也终回归尘埃，你认为的有意义只是你本能对你的奴役</p>
<hr>
<p>我不喜欢读书，但却无比向往哲思的海洋，所以游戏常常成为引导我思考的老师，与其是娱乐消遣的工具，我更愿意把他当做一部艺术品，其背后可以是一次次引人深思的哲理，其背后也可以是作者对某种人，对某件事，对某个价值观的思考，其背后还可以是一部引人入胜的恢宏世界观与史诗，无论是哪一种都令我着迷，引领我思考</p>
<hr>
]]></content>
      <categories>
        <category>文案</category>
      </categories>
      <tags>
        <tag>文案</tag>
      </tags>
  </entry>
  <entry>
    <title>api调查</title>
    <url>/2025/09/05/%E5%AE%9E%E4%B9%A0/Tosea.ai/api%E8%B0%83%E6%9F%A5/</url>
    <content><![CDATA[<h3 id="convertapi">convertapi</h3>
<p><a href="https://www.convertapi.com/">ConvertAPI: Powerful File
Conversion API for Developers &amp; Businesses</a></p>
<table>
<colgroup>
<col style="width: 6%">
<col style="width: 15%">
<col style="width: 16%">
<col style="width: 27%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr>
<th>档次</th>
<th>官方名称</th>
<th>月费 (CNY)</th>
<th>每月包含转换次数</th>
<th>单文件上限</th>
<th>并发任务数</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Developer</td>
<td>¥249</td>
<td>1,000 次</td>
<td>200 MB</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>Startup</td>
<td>¥677</td>
<td>5,000 次</td>
<td>300 MB</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>Growth</td>
<td>¥1,247</td>
<td>15,000 次</td>
<td>500 MB</td>
<td>3</td>
</tr>
<tr>
<td>4</td>
<td>Business</td>
<td>¥2,495</td>
<td>50,000 次</td>
<td>1 GB</td>
<td>无限制</td>
</tr>
</tbody>
</table>
<h3 id="cloudconvert">CloudConvert</h3>
<table>
<colgroup>
<col style="width: 26%">
<col style="width: 22%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th>模式</th>
<th>价格</th>
<th>包含内容</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>一次性购买积分</strong></td>
<td><strong>$9 美元</strong> 起</td>
<td>500 个转换积分</td>
</tr>
<tr>
<td><strong>月度订阅</strong></td>
<td><strong>$9 美元/月</strong></td>
<td>每月 1000 个转换积分，未用完可滚存</td>
</tr>
</tbody>
</table>
<p>每天免费 10 次转换</p>
<p>pdf转ppt，一次要花费4积分，平均下来一份需要0.47元，付费情况下可以做到
5个并发任务</p>
<p><a href="https://cloudconvert.com/pricing">定价 |云转换</a></p>
<p><a href="https://cloudconvert.com/pdf-to-pptx">PDF to PowerPoint |
CloudConvert</a></p>
<h3 id="groupdocs.conversionaspose.pdf-cloud">GroupDocs.Conversion/Aspose.PDF
Cloud</h3>
<p>每个月1000次以内的api调用是30美金，平均下来是一份0.21元，但是如果超过1000次每个月，就要0.09美金一次转换</p>
<p>付费默认5并发</p>
<p>https://products.groupdocs.cloud/conversion/python/pdf-to-ppt/</p>
<p><a href="https://dashboard.groupdocs.cloud/#/">Dashboard</a></p>
<p><a href="https://dashboard.aspose.cloud/#/">Dashboard</a></p>
<p><a href="https://purchase.groupdocs.cloud/pricing/">Pricing Guide -
Purchase - groupdocs.cloud</a></p>
<h3 id="adobe-pdf">Adobe PDF</h3>
<p>每个月五百次的免费转换</p>
<p><a href="https://developer.adobe.com/document-services/pricing/main/">Adobe
PDF Services API Pricing | PDF Embed API Pricing | Adobe Acrobat
Services Pricing - Adobe Developers</a></p>
<h3 id="度慧科技">度慧科技</h3>
<p>这个很便宜，我在腾讯云上看，300r可以买五千次，500r可以买5万次转换。阿里云，100r可以买3000次，有效期一个月</p>
<p>并发数为200</p>
<p><a href="https://try.dhconvert.com/">度慧文档转换</a></p>
<p>[<a href="https://market.cloud.tencent.com/products/24078?keyword=度慧">度慧]PDF转Word,PPT,Excel,TXT,OFD（OCR高级版）-腾讯云市场</a></p>
<p><a href="https://market.aliyun.com/detail/cmapi00044824#sku=yuncode3882400007">【度慧文档转换】PDF转Word/PPT/Excel/TXT/OFD
- 支持扫描版OCR【最新版】_数据API_OCR_API-_云市场-阿里云</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>Tosea.ai</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>aippt技术调研</title>
    <url>/2025/08/25/%E5%AE%9E%E4%B9%A0/Tosea.ai/aippt%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<h3 id="技术路线">技术路线</h3>
<p><strong>方案 A：html → PDF →
pptx</strong>（我尝试下来不大可行，无法再进行编辑了）</p>
<p><strong>方案 B：html → PPTXGenJS</strong></p>
<p><strong>方案 C：html → python-pptx</strong> (主流)</p>
<p><strong>方案 D：markdown → Slidev</strong></p>
<p>我尝试了当前市面的ppt生成产品，在网页里面展示还会有良好的动画效果，但是一旦导出成pptx，都是会变成静态页面，没有动画</p>
<p>reveal.js可以利用页面生成丰富的ppt动画效果；Slidev可以将markdown语法转化成ppt，可以导出为pdf或pptx，需要注意的是，PPTX
文件中的所有幻灯片都会被导出为图片。</p>
<p>PPTXGenJS和python-pptx的原理基本一致，区别一个是使用js一个是python，使用方法都是通过解析HTML标签内容，定义一个ppt实例，将html的内容一点点加入这个示例中，最后导出pptx。这样都仅能实现最基本的ppt演示，不会有复杂的结构，而且经常会出现一个问题——某个标签内文字太多往往会超出ppt演示范围</p>
<p>直接让AI来生成非常自由的PPT，最终的效果一般来说都比较烂，大部分都是预定义一个html模板，然后让AI来自动的选择模板往里面填充内容</p>
<h3 id="相关工具">相关工具</h3>
<p><a href="https://cn.sli.dev/guide/">Slidev</a>
是一个为开发者设计的基于 Web 的幻灯片制作工具。它帮助您以 Markdown
的形式专注于编写幻灯片的内容，并制作出具有交互式演示功能的、高度可自定义的幻灯片。</p>
<p><a href="https://github.com/hakimel/reveal.js">reveal.js</a>
是一个开源的 <strong>HTML 演示框架</strong>，用 JavaScript
写成。只要你会写 HTML/CSS/JS，就可以像做网页一样做出
<strong>酷炫、响应式、支持键盘/鼠标/触控交互</strong> 的幻灯片。</p>
<p><a href="https://github.com/gitbrent/PptxGenJS">PptxGenJS</a>
允许您使用 JavaScript 生成专业的 PowerPoint 演示文稿——直接从
Node、React、Vite、Electron，甚至浏览器中生成。</p>
<p><a href="https://github.com/scanny/python-pptx">python-pptx</a>
是一个用于创建、读取和更新 PowerPoint (.pptx)文件的 Python
库。典型的使用场景是从动态内容（如数据库查询、分析输出或 JSON 负载）生成
PowerPoint 演示文稿，可能是在响应 HTTP 请求时生成 PPTX 文件并下载。</p>
<blockquote>
<p>python-pptx使用方式：根据标签解析html文件，如h1，div等，然后一点点添加到定义的页中</p>
</blockquote>
<h3 id="市面同类产品">市面同类产品</h3>
<ol type="1">
<li><a href="https://www.genspark.ai/agents?type=slides_agent">Genspark</a>
<ul>
<li>Genspark 是 <strong>MainFunc</strong> 公司（由前小度 CEO
景鲲和前小度 CTO 朱凯华联合创立）推出的 <strong>AI Agent
搜索引擎</strong>（或称“AI 原生搜索引擎”）。</li>
</ul></li>
<li><a href="https://www.tiangong.cn/?from=ai-tab.cn">skywork</a>
<ul>
<li>Skywork 是昆仑万维（Kunlun Inc.）旗下 <strong>SkyWork AI</strong>
推出的一系列 <strong>开源大模型</strong> 与 <strong>AI
技术品牌</strong>。</li>
</ul></li>
<li><a href="https://manus.im/app">manus</a></li>
<li><a href="https://gamma.app/">Gamma</a> 是一个 <strong>“AI
驱动的在线内容工作站”</strong>：输入一句话、一段大纲或任何资料，它就能在
<strong>1-3 分钟内</strong> 帮你生成
<strong>高颜值、品牌化、可互动</strong> 的演示文稿、网站、社媒图文或
PDF，并可一键导出为 <strong>PPT / Google Slides / PDF /
网站链接</strong>。</li>
</ol>
<p>manus是每页ppt都是一个html文件，我猜测应该是使用像python-pptx的库生成</p>
<h3 id="ppt-mcp">ppt-mcp</h3>
<p>可以参考其中的工具实现，这两个我看下来都是使用python-pptx包</p>
<p><a href="https://github.com/GongRzhe/Office-PowerPoint-MCP-Server">GongRzhe/Office-PowerPoint-MCP-Server:
A MCP (Model Context Protocol) server for PowerPoint manipulation using
python-pptx. This server provides tools for creating, editing, and
manipulating PowerPoint presentations through the MCP protocol.</a></p>
<p><a href="https://github.com/ltc6539/mcp-ppt">ltc6539/mcp-ppt: A mcp
server supporting you to generate powerpoint using LLM and natural
language automatically.</a></p>
<h3 id="架构思考">架构思考</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">flowchart TB</span><br><span class="line">    subgraph &quot;Plan-and-Execute阶段&quot;</span><br><span class="line">        A[&quot;用户输入&quot;] --&gt; B[&quot;Planner Agent&quot;]</span><br><span class="line">        B --&gt; C[&quot;Agent Executor&quot;]</span><br><span class="line">        C --&gt; D[&quot;Replanner&quot;]</span><br><span class="line">        D --&gt;|&quot;需要更多信息&quot;| C</span><br><span class="line">        D --&gt;|&quot;信息充足&quot;| E[&quot;输出结构化信息&quot;]</span><br><span class="line">    end</span><br><span class="line">    </span><br><span class="line">    subgraph &quot;内容生成阶段&quot;</span><br><span class="line">        E --&gt; F[&quot;大纲设计节点&quot;]</span><br><span class="line">        F --&gt; G[&quot;页面内容生成节点&quot;]</span><br><span class="line">        G --&gt; H[&quot;HTML代码生成节点&quot;]</span><br><span class="line">    end</span><br><span class="line">    </span><br><span class="line">    subgraph &quot;文件转换阶段&quot;</span><br><span class="line">        H --&gt; I[&quot;html演示生成&quot;]</span><br><span class="line">        I --&gt; J[&quot;转换pptx节点&quot;]</span><br><span class="line">        J --&gt; K[&quot;输出PPTX文件&quot;]</span><br><span class="line">    end</span><br></pre></td></tr></table></figure>
<h3 id="利用apryse将pdf转成pptx">利用APRYSE将pdf转成pptx</h3>
<p>Apryse（曾用名 PDFTron）是一家加拿大公司推出的商用 SDK 家族，专注
“任何格式进、任何格式出” 的文档处理。</p>
<p>获取apikey<a href="https://docs.apryse.com/core/guides/get-started/trial-key">Free
trial key for Apryse SDK | Apryse documentation</a></p>
<p><a href="https://docs.apryse.com/core/guides/get-started/python3">Python
3.X PDF Library for Windows, Linux and Mac | Apryse
documentation</a></p>
<p><strong>安装 Apryse SDK 的“结构化输出模块”（Structured Output
Module）</strong>。该模块是一个可选的扩展包，PDF → PPTX、PDF → Word
等高级转换功能都依赖它。<a href="https://docs.apryse.com/core/guides/info/modules">库插件：OCR、CAD
转 PDF - 适用于服务器/桌面 SDK | Apryse 文档 — Library Add-ons: OCR, CAD
to PDF - for Server/Desktop SDK | Apryse documentation</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from apryse_sdk import PDFNet, PDFDoc, Convert, StructuredOutputModule</span><br><span class="line"></span><br><span class="line"># 1. 初始化（许可证）</span><br><span class="line">PDFNet.Initialize(&quot;demo:1756369085114:&quot;)</span><br><span class="line"></span><br><span class="line"># 2. 告诉 SDK 模块放在哪里</span><br><span class="line">PDFNet.AddResourceSearchPath(r&quot;F:\project python\test\StructuredOutputWindows\Lib\Windows&quot;)</span><br><span class="line"></span><br><span class="line"># 3. 可选：确认模块已就位</span><br><span class="line">if not StructuredOutputModule.IsModuleAvailable():</span><br><span class="line">    raise RuntimeError(&quot;StructuredOutput module not found!&quot;)</span><br><span class="line"></span><br><span class="line"># 4. 正常调用</span><br><span class="line">doc = PDFDoc(&quot;input.pdf&quot;)</span><br><span class="line">Convert.ToPowerPoint(doc, &quot;output.pptx&quot;)</span><br></pre></td></tr></table></figure>
<p><a href="https://www.convertapi.com/a">Overview</a></p>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV1Zftnz6Ewx/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">动手实现一个做PPT的MCP服务器_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>Tosea.ai</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>landingpage调研</title>
    <url>/2025/09/14/%E5%AE%9E%E4%B9%A0/Tosea.ai/landingpage%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<h3 id="landingpage的组成">landingpage的组成</h3>
<p>1.开始界面，大概说明产品的定位和作用，让用户可以快速注册后进入</p>
<p><a href="https://www.grammarly.com/">Grammarly: Free AI Writing
Assistance</a></p>
<figure>
<img src="/2025/09/14/%E5%AE%9E%E4%B9%A0/Tosea.ai/landingpage%E8%B0%83%E7%A0%94/image-20250914185941887.png" alt="image-20250914185941887">
<figcaption aria-hidden="true">image-20250914185941887</figcaption>
</figure>
<figure>
<img src="/2025/09/14/%E5%AE%9E%E4%B9%A0/Tosea.ai/landingpage%E8%B0%83%E7%A0%94/image-20250914194430975.png" alt="image-20250914194430975">
<figcaption aria-hidden="true">image-20250914194430975</figcaption>
</figure>
<p>2.展示产品的特点功能和使用范例：1.特点功能这块可以像manus把使用过程中比较有特点的功能截屏，做成下面这样；2.范例部分结构可以参考<a href="https://manus.im/?index=1">manus</a>或者<a href="https://www.lovart.ai/zh">lovart</a>垂直滑动的效果，效果可以参考genspack<a href="https://www.genspark.ai/agents?type=slides_agent">Genspark - AI
幻灯片</a></p>
<figure>
<img src="/2025/09/14/%E5%AE%9E%E4%B9%A0/Tosea.ai/landingpage%E8%B0%83%E7%A0%94/image-20250914190352267.png" alt="image-20250914190352267">
<figcaption aria-hidden="true">image-20250914190352267</figcaption>
</figure>
<figure>
<img src="/2025/09/14/%E5%AE%9E%E4%B9%A0/Tosea.ai/landingpage%E8%B0%83%E7%A0%94/image-20250914192344320.png" alt="image-20250914192344320">
<figcaption aria-hidden="true">image-20250914192344320</figcaption>
</figure>
<p><a href="https://gamma.app/zh-cn/products/presentations">专为演示文稿打造的
Gamma | 利用 AI 立即构建演示文稿 | Gamma</a></p>
<figure>
<img src="/2025/09/14/%E5%AE%9E%E4%B9%A0/Tosea.ai/landingpage%E8%B0%83%E7%A0%94/image-20250914194941544.png" alt="image-20250914194941544">
<figcaption aria-hidden="true">image-20250914194941544</figcaption>
</figure>
<p>3.用户的声音，价格。用户声音我觉得参考lovart就可以，声音这边也可以使用一个滚动的效果</p>
<p><a href="https://www.trae.ai/">TRAE - Collaborate with
Intelligence</a></p>
<figure>
<img src="/2025/09/14/%E5%AE%9E%E4%B9%A0/Tosea.ai/landingpage%E8%B0%83%E7%A0%94/image-20250914193756695.png" alt="image-20250914193756695">
<figcaption aria-hidden="true">image-20250914193756695</figcaption>
</figure>
<figure>
<img src="/2025/09/14/%E5%AE%9E%E4%B9%A0/Tosea.ai/landingpage%E8%B0%83%E7%A0%94/image-20250914200906675.png" alt="image-20250914200906675">
<figcaption aria-hidden="true">image-20250914200906675</figcaption>
</figure>
<p>我感觉我们的风格应该还是要简约大气</p>
<h3 id="pptyoda技术调用"><a href="https://github.com/maquedexiju/PPtYoda">PPtYoda</a>技术调用</h3>
<p>这个项目的核心就是基于python-pptx的这个包，其实跟我们不是很符合。</p>
<p>他们ppt生成的逻辑核心是模板，一定要有pptx模板，并带有每个部分的备注，上传后解析，把ppt的各个结构转化成json存储</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">file = models.FileField(</span><br><span class="line">        upload_to=get_template_path,</span><br><span class="line">        storage=ppt_storage,</span><br><span class="line">    )</span><br><span class="line">    created_at = models.DateTimeField(auto_now_add=True)</span><br><span class="line"></span><br><span class="line">    cover_template = models.JSONField(null=True, blank=True, default=dict)</span><br><span class="line">    toc_template = models.JSONField(null=True, blank=True, default=dict)</span><br><span class="line">    chapter_L1_template = models.JSONField(null=True, blank=True, default=dict)</span><br><span class="line">    chapter_L2_template = models.JSONField(null=True, blank=True, default=dict)</span><br><span class="line">    blank_template = models.JSONField(null=True, blank=True, default=dict)</span><br><span class="line"></span><br><span class="line">    slide_templates = models.JSONField(null=True, blank=True, default=list)</span><br><span class="line">    components = models.JSONField(null=True, blank=True, default=list)</span><br><span class="line">    sections = models.JSONField(null=True, blank=True, default=dict)</span><br></pre></td></tr></table></figure>
<p>生成ppt时，也是让大模型生成符合这种规范的json，然后通过python-pptx填入。</p>
<p>这样好处确实是解决了使用python-pptx时，生成的ppt结构混乱的问题，但是这样生成的ppt完全依赖于你输入的模板，灵活性上有所缺陷。</p>
<h3 id="后续任务">后续任务</h3>
<p>1.导出speaknotes-pdf后端</p>
<p>2.生成完整presentation</p>
]]></content>
      <categories>
        <category>实习</category>
        <category>Tosea.ai</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>邀请好友机制调研</title>
    <url>/2025/09/21/%E5%AE%9E%E4%B9%A0/Tosea.ai/%E9%82%80%E8%AF%B7%E5%A5%BD%E5%8F%8B%E6%9C%BA%E5%88%B6%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<h3 id="邀请码"><strong>邀请码</strong></h3>
<figure>
<img src="/2025/09/21/%E5%AE%9E%E4%B9%A0/Tosea.ai/%E9%82%80%E8%AF%B7%E5%A5%BD%E5%8F%8B%E6%9C%BA%E5%88%B6%E8%B0%83%E7%A0%94/image-20250921100514116.png" alt="image-20250921100514116">
<figcaption aria-hidden="true">image-20250921100514116</figcaption>
</figure>
<h3 id="邀请链接"><strong>邀请链接</strong></h3>
<figure>
<img src="/2025/09/21/%E5%AE%9E%E4%B9%A0/Tosea.ai/%E9%82%80%E8%AF%B7%E5%A5%BD%E5%8F%8B%E6%9C%BA%E5%88%B6%E8%B0%83%E7%A0%94/image-20250921100529781.png" alt="image-20250921100529781">
<figcaption aria-hidden="true">image-20250921100529781</figcaption>
</figure>
<figure>
<img src="/2025/09/21/%E5%AE%9E%E4%B9%A0/Tosea.ai/%E9%82%80%E8%AF%B7%E5%A5%BD%E5%8F%8B%E6%9C%BA%E5%88%B6%E8%B0%83%E7%A0%94/image-20250921100700770.png" alt="image-20250921100700770">
<figcaption aria-hidden="true">image-20250921100700770</figcaption>
</figure>
<p>在表里面增加一个邀请链接的字段，每个用户有专属的邀请链接</p>
]]></content>
      <categories>
        <category>实习</category>
        <category>Tosea.ai</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>Retrieval</title>
    <url>/2025/07/21/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/Retrieval/</url>
    <content><![CDATA[<h3 id="elastic-search">elastic search</h3>
<p>Elasticsearch 是当今最流行的
<strong>开源分布式搜索与分析引擎</strong>，用 Java 开发，基于
<strong>Apache Lucene</strong>
构建。它把<strong>全文检索、实时分析、时序数据、地理空间查询</strong>和<strong>向量检索</strong>统一到一个平台，被广泛用于日志、指标、安全、企业搜索以及
AI/RAG 场景。</p>
<p>RAG 系统中，<strong>Elasticsearch
不仅是向量数据库，更是语义检索引擎和上下文构建器</strong>，更准确地说，是<strong>向量数据库
+ 全文检索引擎</strong>的混合角色。</p>
<h4 id="查找语句">查找语句</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /test_full_v1/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;高压旁路管道磁粉检测使用的是哪种磁化方法和磁悬液浓度？&quot;,</span><br><span class="line">      &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;,&quot;report_url&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices?v#查看所有的所有</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_count#查看文件数</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_mapping#查看映射</span><br><span class="line"></span><br><span class="line">GET test_full_v1#查看索引内容</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_search#查看索引内容</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 3,</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices/zxj_test#查看索引是否存在</span><br></pre></td></tr></table></figure>
<p>可视化平台kibana的内网路径：</p>
<ul>
<li><code>http://10.117.128.50:5601</code></li>
<li>http://10.117.128.50:5601/app/dev_tools#/console/shell
开发者工具</li>
</ul>
<h4 id="es支持的几种检索函数">es支持的几种检索函数</h4>
<h5 id="向量搜索">向量搜索</h5>
<p>这里的向量搜索也就是稠密向量检索，过程为<strong>“把文本/图像等非结构化数据映射成高维向量
→ 在向量空间里做近似最近邻（ANN）搜索 →
按相似度排序返回结果”</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def vector_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建Elasticsearch KNN查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;knn&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: dense_vector_field,      # 指定存储向量的字段名</span><br><span class="line">            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">            &quot;k&quot;: 5,                          # 返回最相似的5个结果</span><br><span class="line">            &quot;num_candidates&quot;: 10,            # 在10个候选中选择最优的5个（提高搜索效率和准确性）</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="bm25">bm25</h5>
<p>BM25（<strong>Best Matching
25</strong>）也就是全文关键词搜索，或者叫传统关键词搜索，他的核心思想为<strong>“词频越高、文档越短、词越稀有，则相关性越高”</strong>，在
TF-IDF 的基础上引入词频饱和、文档长度归一化两项修正。</p>
<blockquote>
<p>TF-IDF（<strong>Term Frequency–Inverse Document
Frequency，词频-逆文档频率</strong>）是一种经典的
<strong>文本特征权重计算方法</strong>，用于衡量
<strong>一个词对一篇文档的重要性</strong>。</p>
</blockquote>
<p>项目中的bm25检索采取多字段匹配的方式，还有几个参数需要了解，如下</p>
<ol type="1">
<li><p><strong>‘type’</strong> :决定了<strong>如何把多个字段的 BM25
打分合并成最终得分</strong>,常用的参数有以下三种</p>
<table>
<colgroup>
<col style="width: 24%">
<col style="width: 12%">
<col style="width: 63%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">type</th>
<th style="text-align: left;">中文含义</th>
<th style="text-align: left;">打分逻辑</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>best_fields</strong>（默认）</td>
<td style="text-align: left;">最佳字段优先</td>
<td style="text-align: left;">取 <strong>得分最高的那个字段</strong>
做最终分（可用 <code>tie_breaker</code> 让次佳字段再贡献一点点）。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>most_fields</strong></td>
<td style="text-align: left;">最多字段优先</td>
<td style="text-align: left;">把所有命中字段的得分
<strong>直接相加</strong>（类似 OR 逻辑），字段越多分越高。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>cross_fields</strong></td>
<td style="text-align: left;">跨字段合并</td>
<td style="text-align: left;">把多个字段视为
<strong>一个虚拟大字段</strong>，统一计算 TF 和
IDF，解决“关键词分散在不同字段”问题。</td>
</tr>
</tbody>
</table></li>
<li><p><strong><code>'tie_breaker'</code></strong>：当多个字段都匹配时，<strong>“最佳字段”得分
+ 其余字段得分×tie_breaker</strong> 作为最终得分。</p></li>
<li><p><strong><code>'operator'</code></strong>:控制<strong>单个字段内</strong>的多个词项是“AND”还是“OR”关系。</p>
<ul>
<li><strong><code>"AND"</code></strong>
要求<strong>同一个字段</strong>必须同时包含所有查询词，减少噪音，提高精准度。适合地址、姓名等跨字段严格匹配。</li>
<li><strong><code>"OR"</code></strong>
只要字段里出现任意一个词就匹配，召回量大，但可能引入不相关结果。</li>
</ul></li>
</ol>
<p>最后，每个字段还可以人工设置权重，如<code>"fields": ["title^3", "content", "tags^2"]</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def bm25_query(search_query: str):</span><br><span class="line">    # 使用BM25算法进行传统关键词匹配</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            &quot;multi_match&quot;: &#123;  # 多字段匹配查询</span><br><span class="line">                &quot;query&quot;: search_query,</span><br><span class="line">                &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;size&quot;: 8,  # 返回最多8个结果</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="混合检索">混合检索</h5>
<p>混合检索也就是 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html">Reciprocal
Rank Fusion</a>（RRF），通过结合向量搜索和 BM25 搜索的结果综合判断。</p>
<p>但由于es中混合检索需要付费使用，后续检索效果评估时不做测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def hybrid_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建混合搜索查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;retriever&quot;: &#123;</span><br><span class="line">            # 使用RRF (Reciprocal Rank Fusion) 算法融合多个检索器的结果</span><br><span class="line">            &quot;rrf&quot;: &#123;</span><br><span class="line">                # 定义多个检索器列表</span><br><span class="line">                &quot;retrievers&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第一个检索器：多字段BM25关键词搜索</span><br><span class="line">                        &quot;standard&quot;: &#123;</span><br><span class="line">                            &quot;query&quot;: &#123;</span><br><span class="line">                                # 使用multi_match在多个字段上进行BM25搜索</span><br><span class="line">                                &quot;multi_match&quot;: &#123;</span><br><span class="line">                                    &quot;query&quot;: search_query,</span><br><span class="line">                                    &quot;type&quot;: &quot;best_fields&quot;,      # 选择最佳匹配字段</span><br><span class="line">                                    &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第二个检索器：KNN向量近似搜索</span><br><span class="line">                        &quot;knn&quot;: &#123;</span><br><span class="line">                            &quot;field&quot;: dense_vector_field,      # 向量字段名（使用定义的变量）</span><br><span class="line">                            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">                            &quot;k&quot;: 5,                          # 返回5个最相似的向量结果</span><br><span class="line">                            &quot;num_candidates&quot;: 10,            # 候选向量数量，用于提高搜索准确性</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="模糊检索">模糊检索</h5>
<p>无论是在网页搜索、文件检索，还是数据库查询中，我们时常会因为拼写错误或信息不完整而无法找到需要的结果。<strong>模糊搜索</strong>（Fuzzy
Search）应运而生，它通过识别与查询相似的词语来帮助我们获得更加灵活的搜索结果。</p>
<p>这里是将bm25与模糊搜索结合起来</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def fuzzy_query(search_query: str):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    创建模糊搜索查询函数，支持拼写错误和近似匹配</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        search_query (str): 用户输入的搜索查询文本</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        Dict: Elasticsearch模糊搜索查询体</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            # 使用match查询进行文本匹配</span><br><span class="line">            &quot;match&quot;: &#123;</span><br><span class="line">                # 在指定的文本字段中进行搜索</span><br><span class="line">                text_field: &#123;</span><br><span class="line">                    &quot;query&quot;: search_query,        # 用户的搜索查询文本</span><br><span class="line">                    &quot;fuzziness&quot;: &quot;AUTO&quot;,          # 自动模糊匹配设置</span><br><span class="line">                    # fuzziness参数说明：</span><br><span class="line">                    # - &quot;AUTO&quot;：根据词长度自动调整模糊度</span><br><span class="line">                    #   - 0-2个字符：不允许错误</span><br><span class="line">                    #   - 3-5个字符：允许1个编辑距离错误</span><br><span class="line">                    #   - 5个以上字符：允许2个编辑距离错误</span><br><span class="line">                    # - 也可以设置具体数值：0, 1, 2</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><code>AUTO</code> 规则：<strong>0~2
字符</strong>不允许错；<strong>3~5 字符</strong>最多1错；<strong>&gt;5
字符</strong>最多2错。</li>
<li>对 <strong>text 字段</strong>先分词，再对每个 token 做模糊 → 召回
<code>Elasticsearch</code>。</li>
</ul>
<h4 id="elasticsearch的连接">elasticsearch的连接</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_elasticsearch import ElasticsearchRetriever</span><br><span class="line">from embeddings_model import select_embeddings_model</span><br><span class="line"># 根据模型名称选择嵌入模型</span><br><span class="line">embedding_model_name=&#x27;bge&#x27;</span><br><span class="line">embeddings = select_embeddings_model(embedding_model_name)</span><br><span class="line">dense_vector_field=&#x27;vector&#x27;</span><br><span class="line">text_field=&#x27;text&#x27;</span><br><span class="line">search_func=fuzzy_query</span><br><span class="line"># 创建Elasticsearch检索器</span><br><span class="line">retriever = ElasticsearchRetriever.from_es_params(</span><br><span class="line">    index_name=&quot;zxj_test&quot;,  # 指定索引名称</span><br><span class="line">    body_func=fuzzy_query,  # 查询函数</span><br><span class="line">    content_field=&quot;text&quot;,  # 内容字段名</span><br><span class="line">    url=&#x27;http://elasticsearch:9200/&#x27;# Elasticsearch服务器地址</span><br><span class="line">)</span><br><span class="line">print(&quot;连接成功&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="elasticsearch的入库">elasticsearch的入库</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">document = []</span><br><span class="line">id_list = []</span><br><span class="line"></span><br><span class="line"># 遍历文件夹中的所有.md文件</span><br><span class="line">for filename in os.listdir(folder_path):</span><br><span class="line">    if filename.endswith(&quot;.md&quot;):</span><br><span class="line">        file_path = os.path.join(folder_path, filename)</span><br><span class="line"></span><br><span class="line">        # 从文件名中提取chunk_id（去除.md扩展名）</span><br><span class="line">        chunk_id = filename.replace(&quot;.md&quot;, &quot;&quot;)</span><br><span class="line"></span><br><span class="line">        # 读取MD文件内容</span><br><span class="line">        with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as file:</span><br><span class="line">            text_content = file.read()</span><br><span class="line">  </span><br><span class="line">        # 查找对应的URL（根据文件名匹配）</span><br><span class="line">        report_url = &quot;&quot;</span><br><span class="line">        # 从folder_name中提取核心文档名（最后一个^后面的部分）</span><br><span class="line">        core_folder_name = folder_name.split(&#x27;^&#x27;)[-1]  # 提取核心文档名</span><br><span class="line"></span><br><span class="line">        # 根据core_folder_name查找对应的URL</span><br><span class="line">        report_url = find_url_by_name_from_list(docs_data, core_folder_name)</span><br><span class="line"></span><br><span class="line">        # 构建document结构</span><br><span class="line">        doc = Document(</span><br><span class="line">            page_content=text_content,</span><br><span class="line">            metadata=&#123;</span><br><span class="line">                &quot;report_name&quot;: folder_name,</span><br><span class="line">                &quot;report_url&quot;: report_url,</span><br><span class="line">                &quot;chunk_id&quot;: chunk_id</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        document.append(doc)</span><br><span class="line">        id_list.append(folder_name + &quot;_&quot; + chunk_id)</span><br><span class="line"></span><br><span class="line"># 批量添加到向量库</span><br><span class="line">es_vector_store.add_documents(documents=document, ids=id_list)</span><br><span class="line">print(f&quot;    文件夹 &#123;folder_name&#125; 已成功入库，共 &#123;len(document)&#125; 个文档块&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="相关资料">相关资料</h4>
<p><a href="https://python.langchain.ac.cn/docs/integrations/retrievers/elasticsearch_retriever/#bm25">Elasticsearch检索器
| 🦜️🔗 LangChain 框架</a></p>
<h3 id="主流的检索策略">主流的检索策略</h3>
<h4 id="bm25-全文关键词检索">BM25 全文关键词检索</h4>
<p>BM25（Best Matching
25）是一种久经考验的排序算法，广泛应用于传统搜索引擎中。它基于“词袋模型”，核心思想是通过关键词匹配程度来衡量文档与查询的相关性。</p>
<p>核心原理概览：</p>
<p>词频 (Term Frequency,
TF)：一个词在文档中出现的次数越多，通常意味着这篇文档与该词相关性越高。但BM25会进行“饱和度”处理，避免某些超高频词过度影响结果。可以想象成，一篇文章提到“苹果”10次，比提到1次更相关，但提到100次和提到50次，在“苹果”这个主题上的相关性增加可能就没那么显著了。
逆文档频率 (Inverse Document Frequency,
IDF)：如果一个词在整个文档集合中都很罕见（只在少数文档中出现），那么它对于区分文档主题就更重要，IDF值就高。比如“量子纠缠”这个词远比“的”、“是”这类词更能锁定专业文档。
文档长度归一化：用于平衡长短文档的得分，避免长文档仅仅因为内容多而获得不公平的高分。
工作方式举例：当用户搜索“深度学习入门教程”时，BM25会倾向于找出那些更频繁出现“深度学习”、“入门”、“教程”这些词，且这些词相对不那么常见的文档。</p>
<p><strong>1. 公式整体结构</strong> <span class="math display">$$
\text{score}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot
\underbrace{\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot
\left(1 - b + b \cdot
\frac{|D|}{\text{avgdl}}\right)}}_{\text{词频归一化项（TF）}}
$$</span> - <strong>IDF 部分</strong>：衡量词项 $ q_i $
的区分能力（逆文档频率）。 - <strong>TF 部分</strong>：衡量词项 $ q_i $
在文档 $ D $ 中的匹配程度（词频归一化）。 -
<strong>求和</strong>：对查询中的所有词项 $ q_i $
的得分求和，得到最终相关性分数。</p>
<p><strong>2. IDF 部分</strong> <span class="math display">$$
\text{IDF}(q_i) = \ln\left(\frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}\right)
$$</span> - <strong>意义</strong>：IDF 值越高，词项 $ q_i $
越能区分文档（常见于少数文档中的词）。 -
<strong>平滑处理</strong>：分子和分母均加 0.5，避免极端值（如 $ n(q_i) =
0 $ 时 ID 无限大）。 - <strong>参数</strong>： - $ N $：文档总数。 - $
n(q_i) $：包含 $ q_i $ 的文档数。</p>
<p><strong>3. 词频归一化项（TF）</strong> <span class="math display">$$
\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot \left(1 - b + b
\cdot \frac{|D|}{\text{avgdl}}\right)}
$$</span> - <strong>非线性饱和</strong>：分子和分母均包含 $ f(q_i, D)
$，使词频增长带来的增益逐渐减小（避免长文档中重复词项的过度影响）。 -
<strong>文档长度归一化</strong>： - $ |D| $：文档 $ D $ 的长度（词数）。
- $ $：整个文档集合的平均文档长度。 - $ b <span class="math inline">：<em>控</em><em>制</em><em>文</em><em>档</em><em>长</em><em>度</em><em>对</em><em>得</em><em>分</em><em>的</em><em>影</em><em>响</em>（</span>
b=1 $ 时完全归一化，$ b=0 $ 时忽略长度）。 - <strong>参数</strong>： - $
k_1 $：控制词频饱和的系数（通常 $ k_1 $，默认 $ k_1 = 1.5 $）。 - $ b
$：默认 $ b = 0.75 $。</p>
<p>这个公式虽然看起来有些复杂，但它精妙地平衡了词频、词的稀有度以及文档长度这几个核心因素，是BM25算法效果出色的关键。</p>
<h6 id="bm25全文搜索与倒排索引它们是如何协同工作的">BM25、全文搜索与倒排索引：它们是如何协同工作的？</h6>
<p><strong>这三者是构建搜索系统的关键组件：</strong></p>
<ul>
<li><p>全文搜索 (Full-Text
Search)：这是我们希望达成的目标——在大量文本中找到包含特定信息的文档。</p></li>
<li><p>倒排索引 (Inverted
Index)：这是实现高效全文搜索的数据结构基础。它像一本书末尾的详细“关键词索引”，记录了每个词出现在哪些文档中以及相关位置信息。当用户查询时，系统可以通过倒排索引快速定位到包含查询词的候选文档。</p></li>
<li><p>BM25：在通过倒排索引找到候选文档后，BM25算法登场，为每个文档计算一个相关性得分，然后按分排序，将最相关的结果呈现给用户。</p></li>
</ul>
<p><strong>把它们比作在图书馆找特定主题的书籍：</strong></p>
<ul>
<li>你告诉图书管理员你要找关于“天体物理学”的书（用户查询）。</li>
<li>管理员查阅一个总卡片索引（倒排索引），迅速告诉你哪些书架（文档ID）上有包含“天体物理学”这个词的书。</li>
<li>你走到这些书架，快速翻阅这些书（BM25评分过程），根据目录、摘要和提及“天体物理学”的频繁程度及重要性，判断哪几本最符合你的需求，并把它们按相关性高低排好。</li>
</ul>
<h4 id="dense-vector-knn-向量语义检索">Dense Vector / kNN
向量语义检索</h4>
<p>向量语义检索（Dense Vector / k-Nearest Neighbor，简称
kNN）是一种<strong>基于高维稠密向量表示的语义检索技术</strong>，与传统关键词倒排索引不同，它通过<strong>自然语言的上下文含义</strong>而非字面匹配来寻找最相关的文档或实体。</p>
<ol type="1">
<li><p><strong>Embedding</strong>：使用预训练语言模型（如
BERT、Sentence-Transformers）把文本映射为<strong>固定维度的稠密向量</strong>（通常
128–1024 维）。</p></li>
<li><p><strong>kNN
搜索</strong>：给定查询向量，<strong>在向量空间中找距离最近的 k
个文档向量</strong>。距离度量常见：</p>
<ul>
<li>余弦相似度（cosine）</li>
<li>内积 / dot-product</li>
<li>L2 欧氏距离</li>
</ul></li>
</ol>
<h4 id="hybrid-retrieval-混合检索">Hybrid Retrieval 混合检索</h4>
<p>既然不同的检索策略各有千秋（例如，BM25擅长关键词精确匹配，Embedding擅长语义理解），那么将它们结合起来，是不是能达到“1+1&gt;2”的效果呢？答案是肯定的，这就是混合检索的核心思想。</p>
<p>常见做法：同时使用BM25（或其他稀疏检索方法）和一种或多种Embedding检索方法，然后将它们各自的检索结果进行融合排序。</p>
<p>融合策略举例：</p>
<p>RRF (Reciprocal Rank Fusion,
倒数排序融合)：一种简单但鲁棒的融合方法。它不关心不同检索系统输出的原始得分，只关心每个文档在各自结果列表中的排名。一个文档
doc 的RRF得分计算如下： <span class="math display"><em>S</em><em>c</em><em>o</em><em>r</em><em>e</em><sub><em>R</em></sub><em>R</em><em>F</em>(<em>d</em><em>o</em><em>c</em>) = <em>Σ</em><sub><em>s</em> ∈ <em>S</em><em>y</em><em>s</em><em>t</em><em>e</em><em>m</em><em>s</em></sub>(1/(<em>k</em> + <em>r</em><em>a</em><em>n</em><em>k</em><sub><em>s</em></sub>(<em>d</em><em>o</em><em>c</em>)))</span>
其中：</p>
<ul>
<li>Systems 是所有参与融合的检索系统的集合。</li>
<li>rank_s(doc) 是文档 doc 在检索系统 s
给出的结果列表中的排名（例如，第一名是1，第二名是2）。</li>
<li>k
是一个小常数（例如，常设置为60），用于平滑得分，避免排名靠后的文档得分过小或排名第一的文档得分占比过高。</li>
</ul>
<h4 id="reranker-重排序器">Reranker 重排序器</h4>
<p>经过上述一种或多种检索策略的“粗筛”（召回阶段），我们通常会得到一个包含较多候选文档的列表（比如几百个）。为了进一步提升最终喂给LLM的文档质量，Reranker（重排序器）应运而生。它相当于一位“精炼师”或“质量品鉴官”，对初步召回的结果进行更细致、更精准的二次排序。</p>
<ol type="1">
<li>召回 倒排 / 向量 / 混合先给 <strong>Top-N</strong>（N≈100~1
k）。</li>
<li>拼特征 把 <code>(query, doc)</code> 拼成一条输入：
<code>[CLS] 用户问题 [SEP] 标题+正文 [SEP]</code>。</li>
<li>打分 扔给 Cross-Encoder 或 ColBERT →
输出<strong>一个相关性分数</strong>。</li>
<li>重排 按分数从高到低重新排序，只留
<strong>Top-K</strong>（K≈10~20）。</li>
<li>返回 重排后的短列表交给前端或 LLM，完成一次“精读”。</li>
</ol>
<h4 id="参考">参考</h4>
<p><a href="https://blog.csdn.net/m0_59614665/article/details/149066780">大模型RAG
|
深入了解几种主流的检索策略（BM25、Embedding、混合检索、Reranker）-CSDN博客</a></p>
<h3 id="项目关于elasticsearch代码阅读记录">项目关于elasticsearch代码阅读记录</h3>
<p>阅读elasticsearch代码相关记录:</p>
<ol type="1">
<li><strong>embedding_model</strong>.select_embeddings_model:根据指定的模型名称加载</li>
<li><strong>make_es_vector_store</strong>：
<ol type="1">
<li>docs_url =
pd.read_excel(‘docs_new.xlsx’)，从excel加载url并进行数据处理，保存筛选后的ur</li>
<li>完成文件加载测试：xizhang/retrival/docfile_test/test.py；</li>
<li>初始化es，使用elastic_search.load_es_index加载存储索引</li>
<li>完成测试elasticsearch连接与索引构建（索引名zxj_test）：/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_es_connect.py，/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_add_es.py</li>
<li>顺序批量处理文件：共16000多份，每十份为一批进行处理，使用download_pdf.py进行文件下载，使用，使用vector_base.rewrite_file对文件进行处理，这里可以修改代码，增加对mineru处理pdf的markdown文件的处理，返回Document对象列表；</li>
</ol></li>
<li><strong>elastic_search</strong></li>
</ol>
<p>重写了检索策略的函数，包括BM25，KNN，混合搜索</p>
<ol type="1">
<li><p>elastic_retriever创建Elasticsearch检索器：根据搜索类型选择对应的查询函数，创建Elasticsearch检索器ElasticsearchRetriever.from_es_params</p></li>
<li><p><strong>retrievers</strong></p>
<ol type="1">
<li>定义函数select_retriever，根据指定的名称选择并返回相应的检索器，目前只有bm25</li>
</ol></li>
</ol>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
        <tag>学习</tag>
        <tag>大模型</tag>
        <tag>retrieval</tag>
        <tag>rag</tag>
      </tags>
  </entry>
  <entry>
    <title>记录开发过程中遇到的问题</title>
    <url>/2025/12/11/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%AE%B0/%E8%AE%B0%E5%BD%95%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="浏览器的跨域预检">浏览器的跨域预检</h2>
<blockquote>
<p>INFO: 127.0.0.1:54365 - “OPTIONS /usersrole=admin HTTP/1.1” 200 OK
INFO: 127.0.0.1:54365 - “GET /usersrole=admin HTTP/1.1” 200 OK
为什么每次调用这个接口会有两个</p>
</blockquote>
<p>• 这是浏览器的跨域预检 + 实际请求各一次：</p>
<ul>
<li>前端带 Authorization 头、跨域调用 /users?role=admin 时，浏览器会先发
OPTIONS 预检，看服务器是否允许该方法 头。你启用了 CORS，所以预检返回
200。</li>
<li>预检通过后才发真正的 GET
/users?role=admin，所以日志里看到两条。</li>
</ul>
<p>这是正常行为；非浏览器（如
curl/postman）或同源、无自定义头的请求则不会有预检。</p>
<h2 id="如何解决跨源的问题">如何解决跨源的问题</h2>
<p>我们推导出了两套针对不同环境的最佳实践方案，核心逻辑都是<strong>“利用中间人（代理）实现同源”</strong>。</p>
<h4 id="开发环境-development">💻 开发环境 (Development)</h4>
<ul>
<li><strong>工具：</strong> Vite (<code>server.proxy</code>)</li>
<li><strong>原理：</strong> 利用 Vite 启动的 Node.js 服务转发请求。</li>
<li><strong>效果：</strong> 浏览器只跟 Vite 打交道（同源），Vite
跟后端打交道（服务器间无 CORS
限制）。<strong>完美消除预检和跨域报错。</strong></li>
</ul>
<h4 id="生产环境-production">🚀 生产环境 (Production)</h4>
<ul>
<li><strong>工具：</strong> Nginx (反向代理)</li>
<li><strong>原理：</strong> 浏览器所有请求（页面 + 接口）统一发给
Nginx（比如 80 端口）。
<ul>
<li><code>/</code> -&gt; Nginx 返回静态 HTML/JS 文件。</li>
<li><code>/api</code> -&gt; Nginx 转发给后端服务（8000 端口）。</li>
</ul></li>
<li><strong>效果：</strong>
在浏览器看来，它始终只访问了一个域名（同源），因此<strong>不需要 CORS
配置，也没有预检请求，性能最高</strong>。</li>
</ul>
<h2 id="authorization-头是什么">Authorization 头是什么</h2>
<p><code>Authorization</code> 头（Header）是 HTTP
协议中用来<strong>验证用户身份</strong>的一个标准字段。</p>
<h3 id="标准格式">1. 标准格式</h3>
<p><code>Authorization</code>
头的值并不是随便填写的，它遵循一个严格的语法结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Authorization: &lt;认证类型&gt; &lt;凭证数据&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>认证类型 (Schema)：</strong>
说明后面跟的是哪种类型的凭证（比如是“密码”还是“令牌”）。常见的有
<code>Bearer</code> 和 <code>Basic</code>。</li>
<li><strong>空格：</strong> 中间必须有一个空格分隔。</li>
<li><strong>凭证数据 (Credentials)：</strong> 具体的加密字符串或
Token。</li>
</ul>
<hr>
<h3 id="最常用的两种类型">2. 最常用的两种类型</h3>
<h4 id="a.-bearer-最常见用于-jwt">A. Bearer (最常见，用于 JWT)</h4>
<p>这是目前现代 Web 应用和 API 最主流的方式，通常配合 <strong>JWT (JSON
Web Token)</strong> 使用。</p>
<ul>
<li><p><strong>含义：</strong> “Bearer”
的意思是“持有者”。意思是：“谁持有这个令牌，谁就有权限。”</p></li>
<li><p><strong>场景：</strong> 用户登录后，服务器发给用户一个
JWT。用户下次请求时，把这个 JWT 放在这里。</p></li>
<li><p><strong>HTTP 请求示例：</strong></p>
<p>HTTP</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /api/user/profile HTTP/1.1</span><br><span class="line">Host: example.com</span><br><span class="line">Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong> 这里的乱码字符串 <code>eyJ...</code>
就是上一条回答中提到的 JWT。</p>
</blockquote></li>
</ul>
<h4 id="b.-basic-最基础用于用户名密码">B. Basic
(最基础，用于用户名密码)</h4>
<p>这是 HTTP 协议内置的最古老的认证方式。</p>
<ul>
<li><p><strong>含义：</strong> 直接把“用户名:密码”拼接，然后进行 Base64
编码传给服务器。</p></li>
<li><p><strong>场景：</strong>
内部系统、简单的测试环境、或者某些传统的网关认证。</p></li>
<li><p><strong>原理：</strong></p>
<ol type="1">
<li>用户名 <code>admin</code>，密码 <code>123456</code>。</li>
<li>拼接：<code>admin:123456</code>。</li>
<li>Base64 编码：<code>YWRtaW46MTIzNDU2</code>。</li>
</ol></li>
<li><p><strong>HTTP 请求示例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST /api/login HTTP/1.1</span><br><span class="line">Authorization: Basic YWRtaW46MTIzNDU2</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>python-web</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>chunk分块策略</title>
    <url>/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<h3 id="分块策略">分块策略</h3>
<p>以下是 RAG 应用程序的典型工作流程：</p>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/6878b8fa-5e74-45a1-9a89-5aab92889126_2366x990.gif" alt="6878b8fa-5e74-45a1-9a89-5aab92889126_2366x990">
<figcaption aria-hidden="true">6878b8fa-5e74-45a1-9a89-5aab92889126_2366x990</figcaption>
</figure>
<p>主流主要有五种分块策略：</p>
<figure>
<img src="https___substack-post-media.s3.amazonaws.com_public_images_92c70184-ba0f-4877-9a55-e4add0e311ad_870x1116.gif" alt="https___substack-post-media.s3.amazonaws.com_public_images_92c70184-ba0f-4877-9a55-e4add0e311ad_870x1116">
<figcaption aria-hidden="true">https___substack-post-media.s3.amazonaws.com_public_images_92c70184-ba0f-4877-9a55-e4add0e311ad_870x1116</figcaption>
</figure>
<h4 id="fixed-size-chunking-固定大小的分块">Fixed-size chunking
固定大小的分块</h4>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/98c422a0-f0e2-457c-a256-4476a56a601f_943x232.png" alt="98c422a0-f0e2-457c-a256-4476a56a601f_943x232">
<figcaption aria-hidden="true">98c422a0-f0e2-457c-a256-4476a56a601f_943x232</figcaption>
</figure>
<p>将文本以固定长度分块，overlap为每个块的重合程度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">text = <span class="string">&quot;大家好，我是果粒奶优有果粒，欢迎关注我，让我们一起探索AI。&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> CharacterTextSplitter</span><br><span class="line"></span><br><span class="line">text_splitter = CharacterTextSplitter(</span><br><span class="line">    separator=<span class="string">&quot;&quot;</span>,<span class="comment">#按字切分</span></span><br><span class="line">    chunk_size=<span class="number">5</span>,</span><br><span class="line">    chunk_overlap=<span class="number">1</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span>,<span class="comment">#以长度计算</span></span><br><span class="line">    is_separator_regex=<span class="literal">False</span>,<span class="comment">#不视为正则表达式</span></span><br><span class="line">)</span><br><span class="line">text_splitter.split_text(text)</span><br></pre></td></tr></table></figure>
<h4 id="semantic-chunking-语义分块">Semantic chunking 语义分块</h4>
<figure>
<img src="https___substack-post-media.s3.amazonaws.com_public_images_a6ad83a6-2879-4c77-9e49-393f16577aef_1066x288.gif" alt="https___substack-post-media.s3.amazonaws.com_public_images_a6ad83a6-2879-4c77-9e49-393f16577aef_1066x288">
<figcaption aria-hidden="true">https___substack-post-media.s3.amazonaws.com_public_images_a6ad83a6-2879-4c77-9e49-393f16577aef_1066x288</figcaption>
</figure>
<p>先将文本分段，然后为每个段进行嵌入，若两个段有较高的余弦相似度，则合并成一个块，一直合并到余弦相似度显著下降，再从新的块开始</p>
<p>需要设定阈值来确定余弦相似度是否显著下降，这因文档而异。</p>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/image-20250710150106274.png" alt="image-20250710150106274">
<figcaption aria-hidden="true">image-20250710150106274</figcaption>
</figure>
<p>具体实现思路：利用滑动窗口，从第一句往后移动滑动窗口，如图，emed1与emed2相差sen3，计算出来的distance决定sen3是否加入chunk1，以此类推</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#利用langchain调用</span></span><br><span class="line"><span class="keyword">from</span> langchain_experimental.text_splitter <span class="keyword">import</span> SemanticChunker</span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> DashScopeEmbeddings</span><br><span class="line">embeddings_model = DashScopeEmbeddings(</span><br><span class="line">        model=<span class="string">&quot;text-embedding-v2&quot;</span>,</span><br><span class="line">        dashscope_api_key=<span class="string">&quot;&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">semantic_chunk=SemanticChunker(</span><br><span class="line">    embeddings=embeddings_model,<span class="comment">#嵌入模型</span></span><br><span class="line">    breakpoint_threshold_type=<span class="string">&quot;percentile&quot;</span>,<span class="comment">#定义如何计算语义断点阈值</span></span><br><span class="line">    breakpoint_threshold_amount=<span class="number">95</span>,<span class="comment">#设定阈值</span></span><br><span class="line">    <span class="comment">#min_chunk_size=500#限制生成块最小的字符数，避免生成无意义的块</span></span><br><span class="line">    sentence_split_regex=<span class="string">r&#x27;[。！？.\n]&#x27;</span>,<span class="comment">#语句切分</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><a href="https://developer.aliyun.com/article/1664186">LangChain 搭配
QWen 踩坑-阿里云开发者社区</a></p>
<p>使用OpenAIEmbeddings配置embedding模型，需要设置一个关键参数</p>
<p><code>check_embedding_ctx_length = False</code> 的作用是：</p>
<blockquote>
<p><strong>关闭 langchain_openai
在调用嵌入模型前对输入文本长度的检查与自动截断/分段逻辑。</strong></p>
</blockquote>
<p>但 DashScope 的 <code>text-embedding-v4</code> 接口：</p>
<ul>
<li>对输入格式要求更严格（必须是字符串或字符串列表，不能是分段后的复杂结构）。</li>
<li>不接受 <code>langchain_openai</code>
默认生成的<strong>分段后的列表嵌套结构</strong>。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_openai import OpenAIEmbeddings,  OpenAI</span><br><span class="line">embeddings = OpenAIEmbeddings(</span><br><span class="line">api_key=&quot;sk-&quot;, </span><br><span class="line">base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">model=&quot;text-embedding-v4&quot;,</span><br><span class="line">check_embedding_ctx_length = False,</span><br><span class="line">dimensions=1536</span><br><span class="line">)</span><br><span class="line">result=embeddings.embed_query(&quot;Hello, world!&quot;)</span><br><span class="line">print(len(result))</span><br></pre></td></tr></table></figure>
</blockquote>
<p>源代码理解见最后</p>
<h4 id="recursive-chunking-递归分块">Recursive chunking 递归分块</h4>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/f4009caa-34fc-48d6-8102-3d0f6f2c1386_1066x316.gif" alt="f4009caa-34fc-48d6-8102-3d0f6f2c1386_1066x316">
<figcaption aria-hidden="true">f4009caa-34fc-48d6-8102-3d0f6f2c1386_1066x316</figcaption>
</figure>
<p>先依据大的段落进行分块，再对每个块进行处理，若符合chunk-size的限制，则不会再分</p>
<p>结果可能如下</p>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/b0e40cc1-996f-48f4-9306-781b112536e4_984x428.png" alt="b0e40cc1-996f-48f4-9306-781b112536e4_984x428">
<figcaption aria-hidden="true">b0e40cc1-996f-48f4-9306-781b112536e4_984x428</figcaption>
</figure>
<p>首先，我们定义两个块（紫色的两个段落。接下来，第1段进一步拆分为更小的块。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">recursive_splitter_chinese = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">50</span>,</span><br><span class="line">    chunk_overlap=<span class="number">10</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span>,</span><br><span class="line">    separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;。&quot;</span>, <span class="string">&quot;，&quot;</span>, <span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>]<span class="comment">#中文的分隔符，可以用逗号句号</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="document-structure-based-chunking-基于文档结构的分块">Document
structure-based chunking 基于文档结构的分块</h4>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/e8febecd-ee68-42ff-ab06-41a0a3a43cd3_1102x306.gif" alt="e8febecd-ee68-42ff-ab06-41a0a3a43cd3_1102x306">
<figcaption aria-hidden="true">e8febecd-ee68-42ff-ab06-41a0a3a43cd3_1102x306</figcaption>
</figure>
<p>根据文档的固有结构进行分块，如markdown的一级标题二级标题等</p>
<p><code>langchain.text_splitter</code>中有两个用于md文档分块的类，<code>MarkdownTextSplitter</code>与<code>MarkdownHeaderTextSplitter</code></p>
<p>二者区别主要在：前者继承于<code>RecursiveCharacterTextSplitter</code>递归分块，它会尝试沿着
Markdown
格式的标题进行分割，但其核心仍然是基于字符的递归分割；后者专注于 基于
Markdown 标题的结构化分割 ，并能将标题信息作为元数据保留，更适合需要保持
Markdown 文档层级结构的应用场景。</p>
<p>需要注意的是<code>MarkdownHeaderTextSplitter</code>
本身不直接提供限制块内容长度的参数，但可以通过与
<code>RecursiveCharacterTextSplitter</code>
等其他文本分割器结合使用来有效控制块的大小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> MarkdownHeaderTextSplitter</span><br><span class="line">headers_to_split_on = [</span><br><span class="line">    (<span class="string">&quot;#&quot;</span>, <span class="string">&quot;Header 1&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;##&quot;</span>, <span class="string">&quot;Header 2&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;###&quot;</span>, <span class="string">&quot;Header 3&quot;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)</span><br><span class="line">md_header_splits = markdown_splitter.split_text(markdown_document)</span><br></pre></td></tr></table></figure>
<p>存储结构类似如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Document(metadata=&#123;&#x27;Header 1&#x27;: &#x27;Foo&#x27;, &#x27;Header 2&#x27;: &#x27;Bar&#x27;&#125;, page_content=&#x27;Hi this is Jim  \nHi this is Joe&#x27;),</span><br><span class="line"> Document(metadata=&#123;&#x27;Header 1&#x27;: &#x27;Foo&#x27;, &#x27;Header 2&#x27;: &#x27;Bar&#x27;, &#x27;Header 3&#x27;: &#x27;Boo&#x27;&#125;, page_content=&#x27;Hi this is Lance&#x27;),</span><br><span class="line"> Document(metadata=&#123;&#x27;Header 1&#x27;: &#x27;Foo&#x27;, &#x27;Header 2&#x27;: &#x27;Baz&#x27;&#125;, page_content=&#x27;Hi this is Molly&#x27;)]</span><br></pre></td></tr></table></figure>
<h4 id="llm-based-chunking-基于-llm-的分块">LLM-based chunking 基于 LLM
的分块</h4>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/4d1b6d60-8956-4030-8525-d899ee61a9d5_1140x198.gif" alt="4d1b6d60-8956-4030-8525-d899ee61a9d5_1140x198">
<figcaption aria-hidden="true">4d1b6d60-8956-4030-8525-d899ee61a9d5_1140x198</figcaption>
</figure>
<p>利用大模型进行分块</p>
<p>langchain没有提供官方的类实现LLM-based chunking</p>
<p>但是我在找到了别人实现的agentic_chunker<a href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/agentic_chunker.py">RetrievalTutorials/tutorials/LevelsOfTextSplitting/agentic_chunker.py
at main · FullStackRetrieval-com/RetrievalTutorials</a>，可供参考</p>
<p>后记：agentic
chunk大概的思路为先进行初步分段，按照长度或递归，然后让大模型生成这一段的概要，将段与段合并生成块，但是测试下来，一个文档的内容同质化很严重，基本上都分到一块里了，而且这个主要还是提示词工程，分块并不系统，看个乐吧</p>
<p><a href="https://github.com/zxj-2023/chunks-strategy-/blob/main/agentic_chunker.py">chunks-strategy-/agentic_chunker.py
at main · zxj-2023/chunks-strategy-</a>代码稍作更新，弃用了部分库</p>
<h3 id="embedding">embedding</h3>
<p>之前对chunking和embedding的理解不够清晰，chunking是对文本进行分块，由于大多数文本嵌入模型对输入文本长度有严格限制，如果不分块则无法embedding，从而无法更好的进行向量化或者更好地储存在知识库中，提升retriever性能；embedding则是将文本映射到向量空间，为了更好的相似度计算</p>
<h3 id="语义分块的源代码实战">语义分块的源代码实战</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将文本划分成单句，可以按照标点符号划分</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">single_sentences_list = re.split(<span class="string">r&#x27;(?&lt;=[。！？])&#x27;</span>, essay)</span><br><span class="line"><span class="comment"># 移除可能存在的空字符串</span></span><br><span class="line">single_sentences_list = [s.strip() <span class="keyword">for</span> s <span class="keyword">in</span> single_sentences_list <span class="keyword">if</span> s.strip()]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">我们需要为单个句子拼接更多的句子，但是 `list` 添加比较困难。因此将其转换为字典列（`List[dict]`）</span></span><br><span class="line"><span class="string">&#123; &#x27;sentence&#x27; : XXX  , &#x27;index&#x27; : 0&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sentences = [&#123;<span class="string">&#x27;sentence&#x27;</span>: x, <span class="string">&#x27;index&#x27;</span> : i&#125; <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(single_sentences_list)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用滑动窗口分段</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">combine_sentences</span>(<span class="params">sentences, buffer_size=<span class="number">1</span></span>):</span><br><span class="line">    combined_sentences = [</span><br><span class="line">        <span class="string">&#x27; &#x27;</span>.join(sentences[j][<span class="string">&#x27;sentence&#x27;</span>] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">max</span>(i - buffer_size, <span class="number">0</span>), <span class="built_in">min</span>(i + buffer_size + <span class="number">1</span>, <span class="built_in">len</span>(sentences))))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences))</span><br><span class="line">    ]   </span><br><span class="line">    <span class="comment"># 更新原始字典列表，添加组合后的句子</span></span><br><span class="line">    <span class="keyword">for</span> i, combined_sentence <span class="keyword">in</span> <span class="built_in">enumerate</span>(combined_sentences):</span><br><span class="line">        sentences[i][<span class="string">&#x27;combined_sentence&#x27;</span>] = combined_sentence</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sentences</span><br><span class="line"></span><br><span class="line">sentences = combine_sentences(sentences)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">接下来使用**embedding model**对**sentences** 进行编码</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> DashScopeEmbeddings</span><br><span class="line">embeddings_model = DashScopeEmbeddings(</span><br><span class="line">        model=<span class="string">&quot;text-embedding-v2&quot;</span>,</span><br><span class="line">        dashscope_api_key=<span class="string">&quot;&quot;</span>,</span><br><span class="line"></span><br><span class="line">    )</span><br><span class="line"><span class="comment"># 提取所有组合后的句子用于 embedding</span></span><br><span class="line">combined_sentences_to_embed = [x[<span class="string">&#x27;combined_sentence&#x27;</span>] <span class="keyword">for</span> x <span class="keyword">in</span> sentences]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对句子进行 embedding</span></span><br><span class="line">embeddings = embeddings_model.embed_documents(combined_sentences_to_embed)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;成功对 <span class="subst">&#123;<span class="built_in">len</span>(embeddings)&#125;</span> 个句子进行了 embedding。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将embedding添加到sentence中</span></span><br><span class="line"><span class="keyword">for</span> i, sentence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentences):</span><br><span class="line">    sentence[<span class="string">&#x27;combined_sentence_embedding&#x27;</span>] = embeddings[i]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">接下来需要根据余弦相似度进行切分</span></span><br><span class="line"><span class="string">通过计算两个向量的夹角余弦值来衡量相似性</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cosine_similarity</span>(<span class="params">vec1, vec2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Calculate the cosine similarity between two vectors.&quot;&quot;&quot;</span></span><br><span class="line">    dot_product = np.dot(vec1, vec2)</span><br><span class="line">    norm_vec1 = np.linalg.norm(vec1)</span><br><span class="line">    norm_vec2 = np.linalg.norm(vec2)</span><br><span class="line">    <span class="keyword">return</span> dot_product / (norm_vec1 * norm_vec2)</span><br><span class="line"><span class="comment">#遍历，计算余弦相似度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_cosine_distances</span>(<span class="params">sentences</span>):</span><br><span class="line">    distances = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences) - <span class="number">1</span>):</span><br><span class="line">        embedding_current = sentences[i][<span class="string">&#x27;combined_sentence_embedding&#x27;</span>]</span><br><span class="line">        embedding_next = sentences[i + <span class="number">1</span>][<span class="string">&#x27;combined_sentence_embedding&#x27;</span>]</span><br><span class="line">        <span class="comment"># Calculate cosine similarity</span></span><br><span class="line">        similarity = cosine_similarity(embedding_current, embedding_next)</span><br><span class="line">        <span class="comment"># Convert to cosine distance</span></span><br><span class="line">        distance = <span class="number">1</span> - similarity</span><br><span class="line">        distances.append(distance)</span><br><span class="line">        <span class="comment"># Store distance in the dictionary</span></span><br><span class="line">        sentences[i][<span class="string">&#x27;distance_to_next&#x27;</span>] = distance</span><br><span class="line">    <span class="keyword">return</span> distances, sentences</span><br><span class="line"></span><br><span class="line">distances, sentences = calculate_cosine_distances(sentences)</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据阈值划分</span></span><br><span class="line">breakpoint_percentile_threshold = <span class="number">95</span></span><br><span class="line">breakpoint_distance_threshold = np.percentile(distances, breakpoint_percentile_threshold)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;距离的第95个百分位阈值是:&quot;</span>, breakpoint_distance_threshold)</span><br><span class="line"><span class="comment"># 找到所有距离大于阈值的点的索引，这些索引就是我们的切分点</span></span><br><span class="line">indices_above_thresh = [i <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(distances) <span class="keyword">if</span> x &gt; breakpoint_distance_threshold]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化块的起始句子索引。我们将根据之前计算出的语义分割点（`indices_above_thresh`）来切分句子列表。</span></span><br><span class="line">start_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个列表，用于存储最终组合成的、具有语义连贯性的文本块。</span></span><br><span class="line">chunks = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有识别出的语义分割点（这些是句子列表 `sentences` 中的索引）。</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> indices_above_thresh:</span><br><span class="line">    <span class="comment"># 确定当前文本块的结束点，即当前的分割点索引。</span></span><br><span class="line">    end_index = index</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从原始句子列表（`sentences`）中切片，提取从上一个分割点到当前分割点之间的所有句子。</span></span><br><span class="line">    <span class="comment"># `end_index + 1` 是为了在切片时包含结束索引指向的那个句子。</span></span><br><span class="line">    group = sentences[start_index:end_index + <span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将切分出的句子组（`group`）中的所有 &#x27;sentence&#x27; 字段的值合并成一个单独的字符串，句子之间用空格隔开。</span></span><br><span class="line">    combined_text = <span class="string">&#x27; &#x27;</span>.join([d[<span class="string">&#x27;sentence&#x27;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> group])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将合并后的文本块添加到 `chunks` 列表中。</span></span><br><span class="line">    chunks.append(combined_text)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新下一个文本块的起始索引，设置为当前分割点的下一个位置，为处理下一个块做准备。</span></span><br><span class="line">    start_index = index + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理最后一个文本块。</span></span><br><span class="line"><span class="comment"># 循环结束后，如果 `start_index` 仍然小于句子总数，说明从最后一个分割点到文本末尾还有剩余的句子。</span></span><br><span class="line"><span class="keyword">if</span> start_index &lt; <span class="built_in">len</span>(sentences):</span><br><span class="line">    <span class="comment"># 将这些剩余的句子合并成最后一个文本块。</span></span><br><span class="line">    combined_text = <span class="string">&#x27; &#x27;</span>.join([d[<span class="string">&#x27;sentence&#x27;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> sentences[start_index:]])</span><br><span class="line">    chunks.append(combined_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时，`chunks` 列表包含了所有根据语义距离切分和重组后的文本块。</span></span><br><span class="line"><span class="keyword">for</span> i, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(chunks):</span><br><span class="line">    buffer = <span class="number">200</span></span><br><span class="line">    <span class="built_in">print</span> (<span class="string">f&quot;Chunk #<span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span> (chunk[:buffer].strip())</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;...&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span> (chunk[-buffer:].strip())</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.dailydoseofds.com/p/5-chunking-strategies-for-rag/">RAG
的 5 种分块策略 — 5 Chunking Strategies For RAG</a></p>
<p><a href="https://blog.csdn.net/wjinjie/article/details/148660229">一文读懂
Qwen3 最新开源的 Embedding 和 Rerank
模型优势！_qwen-rerank-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1dr421x7Su/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">一站帮你选择RAG中的文本切分策略_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/The_Thieves/article/details/148747334">LangChain
语义文本拆分指南：基于语义相似度的智能分块技术实战_langchain
语义分割-CSDN博客</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
        <tag>学习</tag>
        <tag>大模型</tag>
        <tag>rag</tag>
        <tag>chunk</tag>
      </tags>
  </entry>
  <entry>
    <title>开发实用网页记录</title>
    <url>/2025/12/16/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%AE%B0/%E5%AE%9E%E7%94%A8%E7%BD%91%E9%A1%B5/</url>
    <content><![CDATA[<h2 id="前端设计网站">前端设计网站</h2>
<p><a href="https://dribbble.com/">Dribbble - Discover the World’s Top
Designers &amp; Creative Professionals</a></p>
<p><a href="https://www.supahero.io/">Supahero - Website hero section
library</a></p>
<p>组件网站</p>
<p><a href="https://ui.shadcn.com/docs">Introduction - shadcn/ui</a></p>
<p><a href="https://mobbin.com/discover/apps/web/latest">Discover Web
apps | Mobbin</a></p>
<p><a href="https://collectui.com/">Collect UI - Daily inspiration
collected from daily ui archive and beyond. Based on Dribbble shots,
hand picked, updating daily.</a></p>
<p>交互设计</p>
<p><a href="https://www.webinteractions.gallery/">Web Animations &amp;
UI Interactions Gallery – Best Website Animation Examples</a></p>
]]></content>
      <categories>
        <category>python-web</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>docker</title>
    <url>/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/</url>
    <content><![CDATA[<h2 id="镜像image">镜像（Image）</h2>
<p>镜像可以被看作是一个轻量级、可执行的独立软件包，包含了运行某个应用所需的所有代码、库、环境变量和配置文件。它是容器的<strong>静态模板</strong>，在创建容器时用作基础。</p>
<p><strong>只读</strong>：镜像本身是只读的，无法修改。</p>
<p><strong>可重用</strong>：镜像是可以多次重用的，你可以基于相同的镜像创建多个容器。</p>
<h2 id="容器container">容器（Container）</h2>
<p>与虚拟机通过操作系统实现隔离不同，容器技术<strong>只隔离应用程序的运行时环境但容器之间可以共享同一个操作系统</strong>，这里的运行时环境指的是程序运行依赖的各种库以及配置。</p>
<p>容器更加的<strong>轻量级且占用的资源更少</strong>，与操作系统动辄几G的内存占用相比，容器技术只需数M空间，因此我们可以在同样规格的硬件上<strong>大量部署容器</strong>，这是虚拟机所不能比拟的，而且不同于操作系统数分钟的启动时间容器几乎瞬时启动，容器技术为<strong>打包服务栈</strong>提供了一种更加高效的方式</p>
<h2 id="镜像与容器的关系">镜像与容器的关系</h2>
<p><strong>镜像是静态的</strong>：它只包含应用和运行环境，不能进行任何运行时的操作。你可以把它看作是软件的<strong>安装包</strong>。</p>
<p><strong>容器是动态的</strong>：它是在镜像的基础上创建的，可以运行、执行代码、修改文件系统等。你可以把它看作是镜像的<strong>运行实例</strong>。</p>
<h2 id="docker">docker</h2>
<p>docker将程序以及程序所有的依赖都打包到<a href="https://zhida.zhihu.com/search?content_id=129800958&amp;content_type=Article&amp;match_order=1&amp;q=docker+container&amp;zhida_source=entity">docker
container</a>，这样你的程序可以在任何环境都会有一致的表现</p>
<p>此外docker的另一个好处就是<strong>快速部署</strong>，这是当前互联网公司最常见的一个应用场景，一个原因在于容器启动速度非常快，另一个原因在于只要确保一个容器中的程序正确运行，那么你就能确信无论在生产环境部署多少都能正确运行。</p>
<p>每一种容器都是一个完整的运行环境，容器之间互相隔离。</p>
<p>简单来说，docker将程序打包部署，方便了软件的部署，避免了环境冲突等问题</p>
<h2 id="常用命令">常用命令</h2>
<p>查看所有容器（包括停止的容器）：<code>docker ps -a</code></p>
<p>在Docker中运行容器：<code>docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</code></p>
<ul>
<li>•
<code>[OPTIONS]</code>：可选参数，用于配置容器的各种选项，如端口映射、容器名称等。</li>
<li>• <code>IMAGE</code>：要运行的镜像名称或ID。</li>
<li>•
<code>[COMMAND] [ARG...]</code>：可选的命令和参数，用于在容器内执行特定的命令。</li>
</ul>
<p>停止正在运行的容器：<code>docker stop [OPTIONS] CONTAINER [CONTAINER...]</code></p>
<p>启动已停止的容器：<code>docker start [OPTIONS] CONTAINER [CONTAINER...]</code></p>
<p>删除已停止的容器或镜像：<code>docker rm [OPTIONS] CONTAINER [CONTAINER...]   docker rmi [OPTIONS] IMAGE [IMAGE...]</code></p>
<ul>
<li>• <code>docker rm</code>：删除容器的命令。</li>
<li>• <code>docker rmi</code>：删除镜像的命令。</li>
</ul>
<p>从Docker仓库中拉取现有的镜像：<code>docker pull [OPTIONS] NAME[:TAG|@DIGEST]</code></p>
<ul>
<li>• <code>docker pull</code>：拉取镜像的命令。</li>
<li>•
<code>[OPTIONS]</code>：可选参数，用于配置拉取过程，如认证信息等。</li>
<li>•
<code>NAME[:TAG|@DIGEST]</code>：要拉取的镜像名称、标签或摘要。</li>
</ul>
<h2 id="docker部分指令">docker部分指令</h2>
<p><strong>linux安装docker</strong>：<code>sudo apt-get update &amp;&amp; sudo apt-get install docker.io</code></p>
<p><strong>查看 Docker
版本信息</strong>：<code>docker version</code></p>
<p><strong>查看镜像</strong>：<code>docker images</code></p>
<p><strong>查看所有的容器</strong>：<code>docker ps -a</code></p>
<blockquote>
<p><code>systemctl</code> 是 <strong>systemd</strong>
系统和服务管理器的核心工具，用于管理系统和服务的状态及配置。</p>
</blockquote>
<p><code>mysql-client</code> 是 MySQL
数据库的命令行客户端工具。它允许你通过命令行连接和操作 MySQL
数据库服务器，比如执行 SQL 查询、管理数据库和用户等。</p>
<p>常用命令格式如下：<code>mysql -h 主机地址 -P 端口号 -u 用户名 -p</code></p>
<p>你可以在终端输入以下命令来检查是否已安装
<code>mysql-client</code>：<code>mysql --version</code></p>
<p>可以使用以下命令安装：<code>sudo apt-get update  sudo apt-get install mysql-client</code></p>
<blockquote>
<p><code>sudo apt-get update</code>
这个命令的作用是<strong>更新本地软件包列表</strong>。</p>
</blockquote>
<p><strong>停止并删除容器</strong>：<code>docker stop fastapi  docker rm fastapi</code></p>
<p><strong>Linux修改镜像源</strong>：<a href="https://blog.csdn.net/couragehope/article/details/137777158">如何查看docker配置的镜像仓库_查看docker镜像地址-CSDN博客</a></p>
<h2 id="常见参数">常见参数</h2>
<p>基础参数：</p>
<table>
<thead>
<tr>
<th><code>-d</code>或<code>--detach</code></th>
<th>后台运行容器（detached mode）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--name &lt;name&gt;</code></td>
<td>为容器指定名称（如<code>--name my_container</code>）</td>
</tr>
<tr>
<td><code>--rm</code></td>
<td>容器停止后自动删除（适用于临时容器）</td>
</tr>
</tbody>
</table>
<p>端口映射：</p>
<table>
<colgroup>
<col style="width: 45%">
<col style="width: 54%">
</colgroup>
<thead>
<tr>
<th><code>-p &lt;主机端口&gt;:&lt;容器端口&gt;</code></th>
<th>映射主机端口到容器端口（如<code>-p 80:80</code>）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-p &lt;主机IP&gt;:&lt;主机端口&gt;:&lt;容器端口&gt;</code></td>
<td>指定主机IP绑定（如<code>-p 127.0.0.1:8080:80</code>）</td>
</tr>
<tr>
<td><code>-P</code>或<code>--publish-all</code></td>
<td>自动映射所有暴露的端口（随机分配主机端口）</td>
</tr>
</tbody>
</table>
<p>卷挂载：</p>
<table>
<thead>
<tr>
<th><code>-v &lt;主机路径&gt;:&lt;容器路径&gt;</code></th>
<th>挂载主机目录到容器（如<code>-v //app</code>）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-v &lt;卷名&gt;:&lt;容器路径&gt;</code></td>
<td>使用命名卷（如<code>-v my_volume:/data</code>）</td>
</tr>
</tbody>
</table>
<p>环境变量：</p>
<table>
<thead>
<tr>
<th><code>-e &lt;KEY=VALUE&gt;</code></th>
<th>设置环境变量（如<code>-e DEBUG=true</code>）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--env-file &lt;文件名&gt;</code></td>
<td>从文件加载环境变量（每行<code>KEY=VALUE</code>）</td>
</tr>
</tbody>
</table>
<p>网络配置：</p>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 72%">
</colgroup>
<thead>
<tr>
<th><code>--network &lt;网络名&gt;</code></th>
<th>指定容器使用的网络（如<code>--network bridge</code>或自定义网络）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--network host</code></td>
<td>使用主机网络（共享主机网络命名空间）</td>
</tr>
</tbody>
</table>
<h2 id="拯救被wsl占用的内存">拯救被wsl占用的内存</h2>
<p>以笔者的情况来说，我的wsl中只有一些必备的开发环境，项目源代码 和
docker。前两者显然没啥可操作的空间，所以只有一个靶子 —— docker。</p>
<p>首先，我们可以进入wsl，通过以下命令，看看 Docker
的磁盘使用情况和资源总量。</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">docker system df </span><br></pre></td></tr></table></figure>
<p>大家都知道，docker运行一段时间后，可能会产生一些无用的镜像文件。要清理无用的
Docker 镜像，则可以运行以下命令：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">docker image prune </span><br></pre></td></tr></table></figure>
<p>该命令可以删除所有未被任何容器使用的镜像。如果想清理所有已停止的容器和未使用的镜像：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">docker system prune -a</span><br></pre></td></tr></table></figure>
<p>执行完后咱们可以再运行第一个命令查看磁盘使用情况，大概率能看到释放了一部分磁盘空间。如果确实长时间为清理过，很大可能可释放几十G。</p>
<p>然而这时候我们退出wsl回到win10,
你可能会看到磁盘空间几乎没啥变化。这是因为wsl还需要我们手动释放这部分空间，即压缩磁盘。</p>
<h2 id="修改docker存储镜像位置">修改docker存储镜像位置</h2>
<p>windows</p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250709095041821.png" alt="image-20250709095041821">
<figcaption aria-hidden="true">image-20250709095041821</figcaption>
</figure>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250709092539404.png" alt="image-20250709092539404">
<figcaption aria-hidden="true">image-20250709092539404</figcaption>
</figure>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250709092605183.png" alt="image-20250709092605183">
<figcaption aria-hidden="true">image-20250709092605183</figcaption>
</figure>
<p>Linux</p>
<p><a href="https://blog.csdn.net/weixin_43412762/article/details/134571411">修改Docker默认镜像和容器存储位置（超详细！！！）_docker更改存储位置-CSDN博客</a></p>
<h2 id="修改镜像源">修改镜像源</h2>
<p>查看可用的镜像源<a href="https://tools.opsnote.top/registry-mirrors/">DockerHub加速器可用性监控</a></p>
<p><a href="https://blog.csdn.net/u014390502/article/details/143472743">国内能用的Docker镜像源【2025最新持续更新】_docker
镜像-CSDN博客</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;registry-mirrors&quot;: [</span><br><span class="line">    &quot;https://docker.m.daocloud.io&quot;,</span><br><span class="line">    &quot;https://docker.1ms.run&quot;,</span><br><span class="line">    &quot;https://ccr.ccs.tencentyun.com&quot;,</span><br><span class="line">    &quot;https://hub.xdark.top&quot;,</span><br><span class="line">    &quot;https://hub.fast360.xyz&quot;,</span><br><span class="line">    &quot;https://docker-0.unsee.tech&quot;,</span><br><span class="line">    &quot;https://docker.xuanyuan.me&quot;,</span><br><span class="line">    &quot;https://docker.tbedu.top&quot;,</span><br><span class="line">    &quot;https://docker.hlmirror.com&quot;,</span><br><span class="line">    &quot;https://doublezonline.cloud&quot;,</span><br><span class="line">    &quot;https://docker.melikeme.cn&quot;,</span><br><span class="line">    &quot;https://image.cloudlayer.icu&quot;,</span><br><span class="line">    &quot;https://dislabaiot.xyz&quot;,</span><br><span class="line">    &quot;https://freeno.xyz&quot;,</span><br><span class="line">    &quot;https://docker.kejilion.pro&quot;</span><br><span class="line">  ]</span><br></pre></td></tr></table></figure>
<h3 id="如何使用vscode进入远程服务器的docker容器内部调试代码">如何使用vscode进入远程服务器的docker容器内部调试代码</h3>
<p>安装一下插件</p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/9a3be11a07b5a0866d09d1bcbbaae4dc.png" alt="9a3be11a07b5a0866d09d1bcbbaae4dc">
<figcaption aria-hidden="true">9a3be11a07b5a0866d09d1bcbbaae4dc</figcaption>
</figure>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250716165555700.png" alt="image-20250716165555700">
<figcaption aria-hidden="true">image-20250716165555700</figcaption>
</figure>
<h2 id="buildpull与run">build，pull与run</h2>
<p><strong><code>docker build</code>：从源代码构建镜像</strong></p>
<ul>
<li><strong>作用</strong>：根据你提供的
<code>Dockerfile</code>（一个包含构建镜像所需指令的文本文件）以及上下文（通常是包含
<code>Dockerfile</code>
的目录及其子目录），<strong>创建</strong>一个新的 Docker 镜像。</li>
</ul>
<p><strong><code>docker pull</code>：从注册中心下载镜像</strong></p>
<ul>
<li><strong>作用</strong>：从 Docker 注册中心（默认是 Docker
Hub，也可以是私有注册中心如 Harbor, GitLab Registry, AWS ECR
等）<strong>下载</strong>一个已经构建好的 Docker
镜像到你的本地机器。</li>
</ul>
<p><strong><code>docker run</code>：创建并启动容器</strong></p>
<ul>
<li><strong>作用</strong>：基于一个<strong>本地已有的镜像</strong>（无论这个镜像是你刚
<code>build</code> 出来的，还是 <code>pull</code>
下来的，或是之前就存在的），<strong>创建</strong>一个新的容器实例，并按照指定的命令（或镜像默认的命令）<strong>启动</strong>它。</li>
</ul>
<h2 id="docker的自定义网络">docker的自定义网络</h2>
<p>创建自定义桥接网络</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker network create mynet</span><br></pre></td></tr></table></figure>
<p>启动服务容器（不映射宿主机端口也能被同网络容器访问）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name api --network demo-net fastapi-svc</span><br></pre></td></tr></table></figure>
<p>列出所有网络（包括自定义网络）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker network ls</span><br><span class="line"></span><br><span class="line">#只列出自定义网络（过滤掉默认网络）</span><br><span class="line">docker network ls --filter type=custom</span><br></pre></td></tr></table></figure>
<p>查看某个自定义网络的详细信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker network inspect network_test </span><br></pre></td></tr></table></figure>
<p><a href="https://www.bilibili.com/video/BV19knhz2Eem?buvid=XX7932A7E9DD8A1DA92D4974AB535749A9B44&amp;from_spmid=tm.recommend.0.0&amp;is_story_h5=false&amp;mid=25yhOI1fPeVYa5V16BFcAw%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=6ceef91b-2187-4b19-adee-025de172a930&amp;share_source=QQ&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1759967919&amp;unique_k=qdW5rAe&amp;up_id=527432927&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">Docker网络介绍_哔哩哔哩_bilibili</a></p>
<h3 id="docker-compose">docker compose</h3>
<p><a href="https://www.bilibili.com/video/BV1vaxqzjEQ6?buvid=XX7932A7E9DD8A1DA92D4974AB535749A9B44&amp;from_spmid=tm.recommend.0.0&amp;is_story_h5=false&amp;mid=25yhOI1fPeVYa5V16BFcAw%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=6ceef91b-2187-4b19-adee-025de172a930&amp;share_source=QQ&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1759967919&amp;unique_k=qdW5rAe&amp;up_id=527432927&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">Docker
Compose基础与语法_哔哩哔哩_bilibili</a></p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1ai421S7zj/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">改变软件行业的技术！程序员、软件爱好者必须掌握的Docker，到底是什么？_哔哩哔哩_bilibili</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/187505981">什么是Docker？看这一篇干货文章就够了！
- 知乎</a></p>
<p><a href="https://blog.csdn.net/Python_0011/article/details/140313812">Docker常用命令大全（非常详细）零基础入门到精通，收藏这一篇就够了-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1THKyzBER6/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">40分钟的Docker实战攻略，一期视频精通Docker_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Libreoffice</title>
    <url>/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/</url>
    <content><![CDATA[<h3 id="libreoffice部署">libreoffice部署</h3>
<h4 id="查看linux发行版">查看Linux发行版</h4>
<figure>
<img src="/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/image-20250718095931232.png" alt="image-20250718095931232">
<figcaption aria-hidden="true">image-20250718095931232</figcaption>
</figure>
<p>系统是 <strong>银河麒麟高级服务器操作系统 V10（Kylin Linux Advanced
Server V10）</strong>，属于 <strong>中国国产、兼容 CentOS/RHEL
生态</strong> 的 Linux 发行版。</p>
<p>因此它使用 <strong>RPM
包管理</strong>（<code>dnf</code>/<code>yum</code>），而不是
<code>.deb</code>。</p>
<h4 id="查看cpu-处理器架构">查看<strong>CPU 处理器架构</strong></h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uname -m</span><br></pre></td></tr></table></figure>
<p>是<strong>x86_64</strong></p>
<h4 id="不用部署了镜像里有直接用了">不用部署了，镜像里有，直接用了</h4>
<h4 id="使用libreoffice处理doc文件转成pdf">使用libreoffice处理doc文件，转成pdf</h4>
<p>将当前目录下所有 <code>.doc</code> 和 <code>.docx</code> 转为
PDF：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">libreoffice --headless --convert-to pdf *.doc *.docx --outdir ./pdf_output/</span><br><span class="line"></span><br><span class="line"># 检查是否有残留进程</span><br><span class="line">ps aux | grep libreoffice</span><br><span class="line"></span><br><span class="line"># 如果有残留进程，杀死它们</span><br><span class="line">killall soffice.bin 2&gt;/dev/null</span><br></pre></td></tr></table></figure>
<h4 id="python">python</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import subprocess</span><br><span class="line">import argparse</span><br><span class="line">import glob</span><br><span class="line">from pathlib import Path</span><br><span class="line">def batch_convert_documents(input_path, output_dir):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    批量转换文档的函数版本</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        input_path (str): 输入路径（文件、目录或通配符）</span><br><span class="line">        output_dir (str): 输出目录</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">        bool: 转换是否成功</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 确保输出目录存在</span><br><span class="line">    Path(output_dir).mkdir(parents=True, exist_ok=True)</span><br><span class="line">    </span><br><span class="line">    # 收集所有要转换的文件</span><br><span class="line">    files_to_convert = []</span><br><span class="line">    </span><br><span class="line">    if os.path.isfile(input_path):</span><br><span class="line">        # 单个文件</span><br><span class="line">        if input_path.lower().endswith((&#x27;.doc&#x27;, &#x27;.docx&#x27;)):</span><br><span class="line">            files_to_convert.append(input_path)</span><br><span class="line">    elif os.path.isdir(input_path):</span><br><span class="line">        # 目录中的所有doc/docx文件</span><br><span class="line">        for pattern in [&#x27;*.doc&#x27;, &#x27;*.docx&#x27;]:</span><br><span class="line">            files_to_convert.extend(glob.glob(os.path.join(input_path, pattern)))</span><br><span class="line">    else:</span><br><span class="line">        # 通配符模式</span><br><span class="line">        files_to_convert = glob.glob(input_path)</span><br><span class="line">        # 过滤出doc和docx文件</span><br><span class="line">        files_to_convert = [f for f in files_to_convert if f.lower().endswith((&#x27;.doc&#x27;, &#x27;.docx&#x27;))]</span><br><span class="line">    </span><br><span class="line">    if not files_to_convert:</span><br><span class="line">        print(&quot;未找到要转换的文档文件&quot;)</span><br><span class="line">        return False</span><br><span class="line">    </span><br><span class="line">    print(f&quot;找到 &#123;len(files_to_convert)&#125; 个文件需要转换&quot;)</span><br><span class="line">    </span><br><span class="line">    # 构建命令</span><br><span class="line">    cmd = [</span><br><span class="line">        &#x27;libreoffice&#x27;,</span><br><span class="line">        &#x27;--headless&#x27;,</span><br><span class="line">        &#x27;--convert-to&#x27;, &#x27;pdf&#x27;,</span><br><span class="line">        &#x27;--outdir&#x27;, output_dir</span><br><span class="line">    ] + files_to_convert</span><br><span class="line">    </span><br><span class="line">    try:</span><br><span class="line">        print(&quot;正在转换文件...&quot;)</span><br><span class="line">        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)</span><br><span class="line">        </span><br><span class="line">        if result.returncode == 0:</span><br><span class="line">            print(f&quot;成功转换 &#123;len(files_to_convert)&#125; 个文件&quot;)</span><br><span class="line">            return True</span><br><span class="line">        else:</span><br><span class="line">            print(f&quot;转换失败: &#123;result.stderr&#125;&quot;)</span><br><span class="line">            return False</span><br><span class="line">            </span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;转换过程中发生错误: &#123;e&#125;&quot;)</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    success = batch_convert_documents(&quot;./docs&quot;, &quot;./pdf_output&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="linux扫盲">Linux扫盲</h3>
<h4 id="发行版">发行版</h4>
<p>像Ubuntu，CentOS都属于Linux的发行版，就像Windows11属于Windows的关系</p>
<p>常见发行版分类：</p>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 46%">
<col style="width: 14%">
<col style="width: 23%">
</colgroup>
<thead>
<tr>
<th>系列</th>
<th>代表发行版</th>
<th>包格式</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Debian 系</strong></td>
<td>Debian、Ubuntu、Kali、Linux Mint</td>
<td><code>.deb</code></td>
<td>包多、社区大、教程多</td>
</tr>
<tr>
<td><strong>Red Hat 系</strong></td>
<td>CentOS、RHEL、Rocky、Alma、Fedora</td>
<td><code>.rpm</code></td>
<td>企业级稳定、官方支持长</td>
</tr>
<tr>
<td><strong>SUSE 系</strong></td>
<td>openSUSE Leap / Tumbleweed</td>
<td><code>.rpm</code></td>
<td>YaST 管理工具、欧洲流行</td>
</tr>
<tr>
<td><strong>Arch 系</strong></td>
<td>Arch Linux、Manjaro</td>
<td><code>.pkg.tar.zst</code></td>
<td>滚动更新、极客向</td>
</tr>
<tr>
<td><strong>轻量/最小</strong></td>
<td>Alpine、Debian netinst、CentOS Stream Minimal</td>
<td>任意</td>
<td>镜像小、资源占用低</td>
</tr>
</tbody>
</table>
<p>如何查看Linux发行版</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat /etc/os-release</span><br></pre></td></tr></table></figure>
<h4 id="deb和rpm">deb和rpm</h4>
<p><code>.deb</code> 和 <code>.rpm</code> 想象成 <strong>“Linux
世界里的安装程序”</strong>，就像 Windows 的 <code>.exe</code> /
<code>.msi</code></p>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 40%">
<col style="width: 50%">
</colgroup>
<thead>
<tr>
<th>格式</th>
<th>适用系统</th>
<th>安装命令</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>.deb</code></strong></td>
<td>Debian、Ubuntu、Linux Mint、Kali 等</td>
<td><code>sudo dpkg -i xxx.deb</code> 或
<code>sudo apt install ./xxx.deb</code></td>
</tr>
<tr>
<td><strong><code>.rpm</code></strong></td>
<td>CentOS、RHEL、Fedora、openSUSE、Rocky、Alma 等</td>
<td><code>sudo rpm -ivh xxx.rpm</code> 或
<code>sudo dnf/yum install xxx.rpm</code></td>
</tr>
</tbody>
</table>
<h4 id="cpu处理器架构">cpu处理器架构</h4>
<table>
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 66%">
</colgroup>
<thead>
<tr>
<th>目录名</th>
<th>代表架构</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>x86_64</strong></td>
<td><strong>Intel/AMD 64 位</strong></td>
<td>绝大多数台式机、服务器（如 Xeon、EPYC、Core、Ryzen）</td>
</tr>
<tr>
<td><strong>aarch64</strong></td>
<td><strong>ARM 64 位</strong></td>
<td>树莓派 4/5、苹果 M 系列（Asahi Linux）、鲲鹏、飞腾、Ampere ARM
服务器等</td>
</tr>
</tbody>
</table>
<p>查看处理器架构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uname -m</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
        <tag>Linux</tag>
        <tag>Libreoffice</tag>
      </tags>
  </entry>
  <entry>
    <title>rag与检索评估</title>
    <url>/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/</url>
    <content><![CDATA[<h3 id="rag评估的指标">rag评估的指标</h3>
<h4 id="忠诚度faithfulness">忠诚度Faithfulness</h4>
<p>Faithfulness：衡量生成答案与给定上下文之间的事实一致性。忠实度得分是基于答案和检索到的上下文
计算出来的，答案的评分范围在0到1之间，分数越高越好。</p>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711154457878.png" alt="image-20250711154457878">
<figcaption aria-hidden="true">image-20250711154457878</figcaption>
</figure>
<p>计算方式：将大模型给出的答案进行切片，检索给出的上下文，计算这些切片是否在上下文中</p>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711155257239.png" alt="image-20250711155257239">
<figcaption aria-hidden="true">image-20250711155257239</figcaption>
</figure>
<h4 id="答案相关性answerrelevance">答案相关性Answerrelevance</h4>
<p>Answerrelevance：答案相关性的评估指标旨在评估生成的答案与给定提示的相关程度。如果答案不完
整或包含冗余信息，则会被赋予较低的分数。这个指标使用问题和答案来计算，其值介于0到1之间，得
分越高表明答案的相关性越好</p>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711155128553.png" alt="image-20250711155128553">
<figcaption aria-hidden="true">image-20250711155128553</figcaption>
</figure>
<p>计算方式：根据答案生成多个问题，然后计算生成的答案与原答案的余弦相似度，再取平均</p>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711155407518.png" alt="image-20250711155407518">
<figcaption aria-hidden="true">image-20250711155407518</figcaption>
</figure>
<h4 id="上下文精确度contextprecision">上下文精确度ContextPrecision</h4>
<p>ContextPrecision：上下文精确度衡量上下文中所有相关的真实信息是否被排在了较高的位置。理想情
况下，所有相关的信息块都应该出现在排名的最前面。这个指标是根据问题和上下文来计算的，数值范
围在0到1之间，分数越高表示精确度越好。 <span class="math display">$$
\text{Context Precision} = \frac{\sum_{k=1}^{K} (\text{rel}(k) \times
\frac{\text{Precision@k}}{\text{Ideal Precision@k}})}{\text{Total
Relevant Documents}}
$$</span></p>
<ul>
<li><code>K</code>：检索返回的文档总数（如 top-5）</li>
<li><code>rel(k)</code>：第 <code>k</code>
个文档是否相关（相关=1，无关=0）</li>
<li><code>Precision@k</code>：前 <code>k</code>
个文档的精确率（相关文档数 / k）</li>
<li><code>Ideal Precision@k</code>：理想情况下前 <code>k</code>
个文档的精确率（假设所有相关文档都排在最前面）</li>
</ul>
<h4 id="上下文召回率contextrecall">上下文召回率ContextRecall</h4>
<p>ContextRecall：用来衡量检索到的上下文与被视为事实真相的标注答案的一致性程度。它根据事实真相
和检索到的上下文来计算，数值范围在0到1之间，数值越高表示性能越好。
为了从事实真相的答案中估计上下文召回率，需要分析答案中的每个句子是否可以归因于检索到的
上下文。在理想情况下，事实真相答案中的所有句子都应该能够对应到检索到的上下文中。
<span class="math display">$$
\text{Context Recall} = \frac{|\{\text{返回的相关文档}\} \cap
\{\text{标准相关文档}\}|}{|\{\text{标准相关文档}\}|}
$$</span> 计算方式：上下文是否包括了标准答案的内容</p>
<h3 id="检索性能的评估">检索性能的评估</h3>
<h4 id="平均倒数排名mean-reciprocal-rank-mrr">平均倒数排名（Mean
Reciprocal Rank, MRR）</h4>
<p><strong>平均倒数排名（Mean Reciprocal Rank, MRR）</strong>
是一种常用于评估信息检索系统、推荐系统或问答系统性能的评价指标。它特别适用于“每个查询只有一个正确答案”或“我们只关心第一个正确结果”的场景。</p>
<ul>
<li><p><strong>倒数排名（Reciprocal Rank,
RR）</strong>：对于一个查询，如果第一个正确答案出现在排序结果的第 $ k $
位，那么它的倒数排名为： <span class="math display">$$
RR = \frac{1}{k}
$$</span> 如果没有正确答案，则 $ RR = 0 $。</p></li>
<li><p><strong>平均倒数排名（MRR）</strong>：对多个查询的倒数排名取平均值：
<span class="math display">$$
MRR = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{\text{rank}_i}
$$</span> 其中：</p>
<ul>
<li>$ |Q| $ 是查询的总数，</li>
<li>$ _i $ 是第 $ i $ 个查询中第一个正确答案的排名（位置）。</li>
</ul></li>
</ul>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250818093714324.png" alt="image-20250818093714324">
<figcaption aria-hidden="true">image-20250818093714324</figcaption>
</figure>
<h4 id="平均精确率均值mean-average-precision-map">平均精确率均值（Mean
Average Precision, MAP）</h4>
<p><strong>MAP（Mean Average Precision）</strong> 是对多个查询或样本的
<strong>平均精确率（Average Precision, AP）</strong>
取平均，用来衡量排序结果的相关性质量。它综合考虑了：</p>
<ul>
<li>排序中相关结果的数量（召回）</li>
<li>相关结果在排序中的位置（越靠前越好）</li>
</ul>
<p><strong>平均精确率（Average Precision, AP）</strong></p>
<p>AP
是对一个查询而言的，衡量该查询下所有相关文档在排序中的整体表现。</p>
<blockquote>
<p><strong>直观理解</strong>：AP
是“在每个相关文档被检索到时”的精确率的平均值。</p>
</blockquote>
<p>公式定义： <span class="math display">$$
AP = \frac{\sum_{k=1}^{n} (P(k) \times
\text{rel}(k))}{\text{总相关文档数}}
$$</span></p>
<p>其中： - $ P(k) $：在第 $ k $ 个位置的精确率（即前 k
个结果中有多少是相关的） - $ (k) $：第 $ k $ 个文档是否相关（1
表示相关，0 表示不相关）</p>
<blockquote>
<p>也就是说，只在相关文档出现的位置计算并累加精确率，最后除以总相关文档数。</p>
</blockquote>
<p><strong>平均精确率均值（MAP）</strong></p>
<p>将所有查询的 AP 求平均：</p>
<p><span class="math display">$$
MAP = \frac{1}{|Q|} \sum_{i=1}^{|Q|} AP_i
$$</span></p>
<p>其中： - $ |Q| $：查询总数 - $ AP_i $：第 $ i $
个查询的平均精确率</p>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250818094149682.png" alt="image-20250818094149682">
<figcaption aria-hidden="true">image-20250818094149682</figcaption>
</figure>
<h4 id="归一化折损累积增益normalized-discounted-cumulative-gain-ndcg">归一化折损累积增益（Normalized
Discounted Cumulative Gain, nDCG）</h4>
<p>nDCG 的核心思想是： 1. <strong>高相关性的文档更有价值</strong> 2.
<strong>排在前面的结果比排在后面的价值更高</strong>（位置越靠前，权重越大）
3. 将系统的得分与“理想排序”对比，进行归一化，便于跨查询比较</p>
<p>1.<strong>累积增益（Cumulative Gain, CG）</strong></p>
<p>CG 是前 $ k $
个结果的相关性评分之和，<strong>不考虑位置</strong>。</p>
<p><span class="math display">$$
CG@k = \sum_{i=1}^{k} rel_i
$$</span></p>
<p>其中 $ rel_i $ 是第 $ i $ 个文档的相关性评分。</p>
<blockquote>
<p>❌ 缺点：CG 不关心排序顺序。无论相关文档排第1还是第10，CG
都一样。</p>
</blockquote>
<ol start="2" type="1">
<li><strong>折损累积增益（Discounted Cumulative Gain,
DCG）</strong></li>
</ol>
<p>DCG 引入“位置折损”：越靠后的结果，其贡献被“打折”。</p>
<p>常用公式（两种形式，第二种更常见）：</p>
<p><span class="math display">$$
DCG@k = \sum_{i=1}^{k} \frac{rel_i}{\log_2(i+1)} \quad \text{或}
$$</span></p>
<p><span class="math display">$$
DCG@k = rel_1 + \sum_{i=2}^{k} \frac{rel_i}{\log_2(i)} \quad
\text{(更常用)}
$$</span></p>
<blockquote>
<p>💡 解释：第1个位置不打折，第2个位置除以 $ _2(2) = 1 $，第3个位置除以
$ _2(3) $，相当于打了约 63% 的折扣。</p>
</blockquote>
<p>这样，<strong>相关文档越早出现，DCG 越高</strong>。</p>
<ol start="3" type="1">
<li><strong>理想折损累积增益（Ideal DCG, IDCG）</strong></li>
</ol>
<p>IDCG
是在<strong>理想排序下</strong>（所有相关文档按相关性从高到低排列）的
DCG 值。</p>
<p><span class="math display"><em>I</em><em>D</em><em>C</em><em>G</em>@<em>k</em> = 将前
<em>k</em> 个最相关文档按最优顺序排列时的
<em>D</em><em>C</em><em>G</em></span></p>
<p>IDCG 是当前查询下 DCG 的理论最大值。</p>
<ol start="4" type="1">
<li><strong>归一化折损累积增益（nDCG@k）</strong></li>
</ol>
<p><span class="math display">$$
nDCG@k = \frac{DCG@k}{IDCG@k}
$$</span></p>
<blockquote>
<p>✅ nDCG 的取值范围是 <span class="math inline">[0, 1]</span>： -
1.0：排序完全理想 - 接近 1：排序质量高 - 接近 0：排序很差</p>
</blockquote>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250818095351579.png" alt="image-20250818095351579">
<figcaption aria-hidden="true">image-20250818095351579</figcaption>
</figure>
<h3 id="利用ragas评估rag性能">利用RAGAS评估rag性能</h3>
<p><a href="https://github.com/zxj-2023/learn-rag-langchain/blob/main/RAGAS-langchian.ipynb">learn-rag-langchain/RAGAS-langchian.ipynb
at main · zxj-2023/learn-rag-langchain</a></p>
<p>检索器 1.Contextprecision(上下文精确度)：评估检索质量。 2.Context
Recall(上下文召回率)：衡量检索的完整性。 生成器
1.Faithfulness(忠实度)：衡量生成答案中的幻觉情况。
2.AnswerRelevance(答案相关性):衡量答案对问题的直接性(紧扣问题的核心)。</p>
<p>最终的RAGAS得分是以上各个指标得分的调和平均值。简而言之，这些指标用来综合评估
-个系统整体的性能。</p>
<h4 id="rag的构建">RAG的构建</h4>
<p>创建RAG文本分割、Embedding model 、 向量库存储Chroma</p>
<p>我们主要使用 <code>RecursiveCharacterTextSplitter</code>
切割文本，通过<code>OpenAIEmbeddings()</code>进行文本编码，存储到
<code>VectorStore</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.vectorstores import Chroma</span><br><span class="line">from langchain.embeddings import OpenAIEmbeddings</span><br><span class="line">from langchain.text_splitter import RecursiveCharacterTextSplitter</span><br><span class="line">from langchain_community.embeddings import DashScopeEmbeddings</span><br><span class="line">embeddings_model = DashScopeEmbeddings(</span><br><span class="line">        model=&quot;text-embedding-v2&quot;,</span><br><span class="line">        dashscope_api_key=openai.api_key,</span><br><span class="line">    )</span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)</span><br><span class="line">#进行文本分割，生成更小、更易于处理的文档块</span><br><span class="line">docs = text_splitter.split_documents(paper_docs)</span><br><span class="line"></span><br><span class="line">vectorstore = Chroma.from_documents(docs, embeddings_model)</span><br></pre></td></tr></table></figure>
<p>Chroma
向量数据库默认情况下是内存存储，这意味着数据在程序运行结束后不会保留。
但是，Chroma
也支持持久化存储，您可以指定一个路径将数据保存到磁盘上。这样，即使程序关闭，数据也会被保留，并在下次启动时自动加载。</p>
<h4 id="检索器的构建">检索器的构建</h4>
<p>现在我们可以利用 <code>Chroma</code> 向量库的
<code>.as_retriever()</code> 方式进行检索，需要控制的主要参数为
<code>k</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">base_retriever = vectorstore.as_retriever(search_kwargs=&#123;&quot;k&quot; : 3&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>ectorstore.as_retriever() : 这个方法的作用是将一个向量数据库实例（
vectorstore ）转换为 LangChain 中的一个检索器（ Retriever
）对象。检索器是 LangChain
中负责根据用户查询从数据源中获取相关文档的核心组件。</li>
<li>“k” : 这个键表示要检索的“最相似”文档的数量。在这里， “k” : 3
意味着当检索器接收到一个查询时，它将从向量存储中返回与该查询最相似的 3
个文档。这在
RAG（检索增强生成）系统中非常常见，用于限制传递给大型语言模型的上下文信息量，以提高效率和相关性。</li>
</ul>
<p>检索器的作用
检索器（Retriever）是一个核心组件，其主要作用是从一个数据源（如向量数据库、文档加载器等）中根据给定的查询（query）检索出相关的文档或信息。</p>
<h4 id="prompt的构建">prompt的构建</h4>
<p>我们需要利用<code>LLM</code>对<code>Context</code>
生成一系列的问题的<code>answer</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain import PromptTemplate</span><br><span class="line"></span><br><span class="line">template = &quot;&quot;&quot;You are an assistant for question-answering tasks. </span><br><span class="line">Use the following pieces of retrieved context to answer the question. </span><br><span class="line">If you don&#x27;t know the answer, just say that you don&#x27;t know. </span><br><span class="line"></span><br><span class="line">Question: &#123;question&#125; </span><br><span class="line"></span><br><span class="line">Context: &#123;context&#125; </span><br><span class="line"></span><br><span class="line">Answer:</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=template, </span><br><span class="line">    input_variables=[&quot;context&quot;,&quot;question&quot;]</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">print(prompt)</span><br></pre></td></tr></table></figure>
<h4 id="生成answer利用llm">生成<code>answer</code>,利用LLM</h4>
<p>利用 <code>Runnable</code> 定义一个 <code>chain</code>
实现rag全流程。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.schema.runnable import RunnablePassthrough</span><br><span class="line">from langchain.schema.output_parser import StrOutputParser</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model_name=&quot;qwen-plus-2025-04-28&quot;, </span><br><span class="line">    temperature=0,</span><br><span class="line">    api_key=&quot;&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">    )</span><br><span class="line">#RunnablePassthrough将输入数据原封不动地传递到输出</span><br><span class="line">#StrOutputParser() 它被用作 RAG 链的最后一步，确保最终的答案以字符串形式输出。</span><br><span class="line">rag_chain = (</span><br><span class="line">    &#123;&quot;context&quot;: base_retriever,  &quot;question&quot;: RunnablePassthrough()&#125; </span><br><span class="line">    | prompt </span><br><span class="line">    | llm</span><br><span class="line">    | StrOutputParser() </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="创建-ragas-所需的数据">创建 RAGAs 所需的数据</h4>
<p>question Answer contexts ground_truths</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Ragas 数据集格式要求  [&#x27;question&#x27;, &#x27;answer&#x27;, &#x27;contexts&#x27;, &#x27;ground_truths&#x27;]</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;question&quot;: [], &lt;-- 问题基于Context的</span><br><span class="line">    &quot;answer&quot;: [], &lt;-- 答案基于LLM生成的</span><br><span class="line">    &quot;contexts&quot;: [], &lt;-- context</span><br><span class="line">    &quot;ground_truths&quot;: [] &lt;-- 标准答案</span><br><span class="line">&#125;</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">from datasets import Dataset</span><br><span class="line">#构建问题与标准答案（黄金数据集）</span><br><span class="line">questions = [&quot;What is faithfulness ?&quot;, </span><br><span class="line">             &quot;How many pages are included in the WikiEval dataset, and which years do they cover information from?&quot;,</span><br><span class="line">             &quot;Why is evaluating Retrieval Augmented Generation (RAG) systems challenging?&quot;,</span><br><span class="line">            ]</span><br><span class="line">ground_truths = [&quot;Faithfulness refers to the idea that the answer should be grounded in the given context.&quot;,</span><br><span class="line">                  &quot; To construct the dataset, we first selected 50 Wikipedia pages covering events that have happened since the start of 2022.&quot;,</span><br><span class="line">                &quot;Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself.&quot;]              </span><br><span class="line">answers = []</span><br><span class="line">contexts = []</span><br><span class="line"></span><br><span class="line"># 生成答案</span><br><span class="line">for query in questions:</span><br><span class="line">    answers.append(rag_chain.invoke(query))</span><br><span class="line">    contexts.append([docs.page_content for docs in base_retriever.get_relevant_documents(query)])</span><br><span class="line"></span><br><span class="line"># 构建数据</span><br><span class="line">data = &#123;</span><br><span class="line">    &quot;user_input&quot;: questions,</span><br><span class="line">    &quot;response&quot;: answers,</span><br><span class="line">    &quot;retrieved_contexts&quot;: contexts,</span><br><span class="line">    &quot;reference&quot;: ground_truths</span><br><span class="line">&#125;</span><br><span class="line">dataset = Dataset.from_dict(data)</span><br></pre></td></tr></table></figure>
<h4 id="使用ragas-进行评估">使用RAGAs 进行评估</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#将评估数据转换成 Ragas 框架专用的格式 。</span><br><span class="line">from ragas import EvaluationDataset</span><br><span class="line">evaluation_dataset = EvaluationDataset.from_list(dataset)</span><br></pre></td></tr></table></figure>
<p>我们可以使用一组常用的RAG评估指标，在收集的数据集上评估我们的RAG系统。您可以选择任何模型作为评估用LLM来进行评估。
ragas默认使用openai的api</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from ragas.llms import LangchainLLMWrapper</span><br><span class="line">evaluator_llm = LangchainLLMWrapper(llm)</span><br></pre></td></tr></table></figure>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness</span><br><span class="line">from ragas import evaluate</span><br><span class="line">result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)</span><br><span class="line">result</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250713164037571.png" alt="image-20250713164037571">
<figcaption aria-hidden="true">image-20250713164037571</figcaption>
</figure>
<h4 id="查看结果">查看结果</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">pd.set_option(&quot;display.max_colwidth&quot;, None)</span><br><span class="line"></span><br><span class="line">df = result.to_pandas()</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://zhuanlan.zhihu.com/p/1892529470419736435">RAG系统效果难评？2025年必备的RAG评估框架与工具详解
- 知乎</a></p>
<p><a href="https://www.bilibili.com/video/BV1Jz421Q7Lw?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">如何利用RAGAs评估RAG系统的好坏_哔哩哔哩_bilibili</a></p>
<p>ragas中文文档<a href="https://www.aidoczh.com/ragas/getstarted/rag_eval/index.html#want-help-in-improving-your-ai-application-using-evals">Evaluate
a simple RAG - Ragas</a></p>
<p><a href="https://segmentfault.com/a/1190000045262257#item-4-5">人工智能 -
RAG系统的7个检索指标：信息检索任务准确性评估指南 - deephub -
SegmentFault 思否</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
        <tag>学习</tag>
        <tag>大模型</tag>
        <tag>rag</tag>
      </tags>
  </entry>
  <entry>
    <title>MinerU</title>
    <url>/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/</url>
    <content><![CDATA[<h3 id="docker部署">docker部署</h3>
<p>使用dockerfile构建镜像：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU@master/docker/china/Dockerfile</span><br><span class="line">docker build -t mineru-sglang:latest -f Dockerfile .</span><br></pre></td></tr></table></figure>
<p>使用<code>wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU @master/docker/china/Dockerfile -O Dockerfile</code>将指定的
Dockerfile 下载到本地</p>
<p>Dockerfile：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用官方的 sglang 镜像作为基础镜像</span><br><span class="line">FROM lmsysorg/sglang:v0.4.9-cu126</span><br><span class="line"></span><br><span class="line"># 安装 OpenCV 依赖库</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y libgl1 &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># 安装 mineru Python 包</span><br><span class="line">RUN python3 -m pip install -U &#x27;mineru[core]&#x27; -i https://mirrors.aliyun.com/pypi/simple --break-system-packages</span><br><span class="line"></span><br><span class="line"># 下载模型并配置</span><br><span class="line">RUN /bin/bash -c &quot;mineru-models-download -s modelscope -m all&quot;</span><br><span class="line"></span><br><span class="line"># 设置容器入口命令</span><br><span class="line">ENTRYPOINT [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;export MINERU_MODEL_SOURCE=local &amp;&amp; exec \&quot;$@\&quot;&quot;, &quot;--&quot;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>SGLang（全称可能为 <strong>Serving Large Language Models with
Golang</strong>
）是由斯坦福大学研究团队开发的一个<strong>高效的大语言模型（LLM）推理服务框架</strong>
，旨在通过优化模型推理过程，显著提升生成式AI服务的吞吐量和响应速度。</p>
<ul>
<li><strong>SGlang 版本</strong> ：<code>v0.4.8.post1</code>（SGlang
是一个用于大语言模型（LLM）推理和服务的高性能框架）。</li>
<li><strong>CUDA 版本</strong> ：<code>cu126</code> 表示使用
<strong>CUDA 12.6</strong> ，适用于 <strong>Turing/Ampere/Ada
Lovelace/Hopper 架构的 GPU</strong> （如 RTX 30/40
系列、A100、H100）。</li>
</ul>
</blockquote>
<h4 id="报错排查">报错排查</h4>
<p>之前由于默认dockerfile内容为<code>FROM lmsysorg/sglang:v0.4.8.post1-cu126</code>报错</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lmsysorg/sglang:v0.4.8.post1-cu126: failed to resolve source metadata for docker.io/lmsysorg/sglang:v0.4.8.post1-cu126: unexpected status from HEAD request to https://yaj2teeh.mirror.aliyuncs.com/v2/lmsysorg/sglang/manifests/v0.4.8.post1-cu126?ns=docker.io: 403 Forbidden</span><br></pre></td></tr></table></figure>
<p>之前以为是sglang版本问题，然后去dockerhub上查找，并通过<code>docker pull sglang:v0.4.8.post1-cu126</code>测试，是可以拉取的，最后认为原因还是网络问题</p>
<p>解决方法，更换了镜像源</p>
<h4 id="镜像源配置">镜像源配置</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;registry-mirrors&quot;: [</span><br><span class="line">  &quot;https://registry.docker-cn.com&quot;,</span><br><span class="line">  &quot;http://hub-mirror.c.163.com&quot;,</span><br><span class="line">  &quot;https://dockerhub.azk8s.cn&quot;,</span><br><span class="line">  &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class="line">  &quot;https://registry.cn-hangzhou.aliyuncs.com&quot;,</span><br><span class="line">  &quot;https://docker.mirrors.ustc.edu.cn&quot;,</span><br><span class="line">  &quot;https://docker.m.daocloud.io&quot;,  </span><br><span class="line">  &quot;https://noohub.ru&quot;, </span><br><span class="line">  &quot;https://huecker.io&quot;,</span><br><span class="line">  &quot;https://dockerhub.timeweb.cloud&quot; </span><br><span class="line"> ]</span><br></pre></td></tr></table></figure>
<p><a href="https://www.bilibili.com/video/BV1xHA3euEcn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">保姆级Docker安装+镜像加速
计算机系必备技能_哔哩哔哩_bilibili</a></p>
<h4 id="为什么要指定基础镜像">为什么要指定基础镜像</h4>
<ul>
<li><strong>提供操作系统和依赖</strong> 基础镜像包含操作系统（如
Ubuntu、Alpine）、运行时环境（如 Python、Node.js）或框架（如
TensorFlow、PyTorch）等核心组件，后续所有操作（如安装依赖、拷贝文件）都基于此环境。
<ul>
<li>例如：<code>FROM python:3.9</code> 提供了 Python 3.9
的运行环境，后续可以直接用 <code>pip install</code> 安装 Python
包。</li>
</ul></li>
<li><strong>避免重复造轮子</strong>
如果直接从空镜像（<code>scratch</code>）开始，需要手动安装所有依赖，效率低下且容易出错。使用现有基础镜像可以复用已验证的环境配置。</li>
</ul>
<h4 id="确认支持的cuda版本">确认支持的cuda版本</h4>
<p>命令<code>nvidia-smi</code></p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250708160948192.png" alt="image-20250708160948192">
<figcaption aria-hidden="true">image-20250708160948192</figcaption>
</figure>
<p><strong>CUDA Version</strong> 显示当前驱动支持的最高 CUDA 版本</p>
<h4 id="问题使用dockerfile直接部署始终出现网络问题">问题：使用dockerfile直接部署，始终出现网络问题</h4>
<p>解决方案</p>
<p>先修改了一下docker储存镜像的位置，太大了</p>
<p>先拉取基础镜像<code>docker pull lmsysorg/sglang:v0.4.8.post1-cu126</code></p>
<p>再使用<code>docker build -t mineru-sglang:latest -f Dockerfile .</code>，可以直接跳过基础镜像的拉取</p>
<h3 id="启动">启动</h3>
<p>官方启动命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name sglang-server \          # 容器命名（便于管理）</span><br><span class="line">  --gpus all \                   # 启用所有GPU</span><br><span class="line">  --shm-size 32g \               # 共享内存大小</span><br><span class="line">  -p 30000:30000 \               # 端口映射（主机端口:容器端口）</span><br><span class="line">  --ipc=host \                   # 共享主机IPC命名空间</span><br><span class="line">  mineru-sglang:latest \</span><br><span class="line">  mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name sglang-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host mineru-sglang:latest mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将mineru-sglang-server暴露到30000端口的作用</p>
<p>为了支持 vlm-sglang-client
后端模式，使得MinerU客户端可以通过网络连接到这个服务器，实现多个客户端可以同时连接到同一个服务器</p>
</blockquote>
<p>使用<code>docker exec -it sglang-server bash</code>命令进入容器</p>
<p>或</p>
<p>使用docker desk</p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250709152627120.png" alt="image-20250709152627120">
<figcaption aria-hidden="true">image-20250709152627120</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 -p 7860:7860 -p 8000:8000 --ipc=host \</span><br><span class="line">-v &quot;F:/project python/实习/mineru/demo/pdfs:/pdfs&quot; \</span><br><span class="line">-v &quot;F:/project python/实习/mineru/output:/output&quot; \</span><br><span class="line">mineru-sglang:latest \</span><br><span class="line">mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<p>使用挂载卷启动</p>
<ul>
<li>将本地的PDF文件目录挂载到容器内的 /pdfs 目录</li>
<li>将本地的输出目录挂载到容器内的 /output 目录</li>
<li>把8000，和7860端口暴露，方便调用fastapi与gradio webui 可视化</li>
</ul>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250710100047464.png" alt="image-20250710100047464">
<figcaption aria-hidden="true">image-20250710100047464</figcaption>
</figure>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250710103505453.png" alt="image-20250710103505453">
<figcaption aria-hidden="true">image-20250710103505453</figcaption>
</figure>
<h3 id="调用">调用</h3>
<h4 id="命令行调用sglang-serverclient-模式">命令行调用sglang-server/client
模式</h4>
<p><code>docker exec mineru-server mineru -p /pdfs/demo1.pdf -o /output -b vlm-sglang-client -u http://localhost:30000</code></p>
<p>这条命令在名为 mineru-server 的容器内执行 mineru 工具，处理 /pdfs
目录下的 demo1.pdf 文件，输出结果到 /output 目录，使用 vlm-sglang-client
后端，并连接到 http://localhost:30000 的SGLang服务器。</p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250710103615272.png" alt="image-20250710103615272">
<figcaption aria-hidden="true">image-20250710103615272</figcaption>
</figure>
<h4 id="fastapi调用与gradio-webui-可视化">fastapi调用与gradio webui
可视化</h4>
<p>在完成docker的端口映射之后，运行<code>mineru-api --host 0.0.0.0 --port 8080</code>启动fastapi服务，</p>
<blockquote>
<p>FastAPI服务的使用场景</p>
<p>FastAPI服务提供了一个<code>/file_parse</code>端点，用于处理PDF和图像文件的解析请求</p>
<p>微服务架构部署，FastAPI服务可以独立部署</p>
<p>服务提供了标准的HTTP API接口，允许客户端通过网络请求进行文档解析</p>
</blockquote>
<p>运行<code>mineru-gradio --server-name 0.0.0.0 --server-port 7860</code>启动gradio
webui服务</p>
<p>或<code>mineru-gradio --server-name 0.0.0.0 --server-port 7860 --enable-sglang-engine true</code></p>
<blockquote>
<p>注意，模型下载需要配置环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在容器内设置环境变量</span><br><span class="line">export MINERU_MODEL_SOURCE=local</span><br><span class="line"># 验证环境变量是否设置成功</span><br><span class="line">echo $MINERU_MODEL_SOURCE</span><br></pre></td></tr></table></figure>
</blockquote>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/115678648318f55f1fe3a5baaeac2aaf.png" alt="115678648318f55f1fe3a5baaeac2aaf">
<figcaption aria-hidden="true">115678648318f55f1fe3a5baaeac2aaf</figcaption>
</figure>
<p><strong>在调用过程中关于端口的问题与思考</strong></p>
<p>调用过程中发现，在容器中使用<code>mineru-api --host 127.0.0.1 --port 8000</code>，宿主机无法访问<code>http://127.0.0.1:8000/docs/</code>，经过查询ai，命令改为<code>mineru-api --host 0.0.0.0 --port 8000</code>就可以正常访问，那么关键在于对这两个地址的理解</p>
<blockquote>
<p>查看端口<code>netstat -ano | findstr LISTENING</code></p>
</blockquote>
<p>127.0.0.1与0.0.0.0</p>
<ul>
<li>127.0.0.1 (localhost) ：仅表示本机回环地址，只能在 同一设备内
访问</li>
<li>0.0.0.0 ：表示监听所有可用的网络接口，允许 来自任何地址 的连接</li>
</ul>
<p>当您在Docker容器内运行服务时：</p>
<ol type="1">
<li><p>使用127.0.0.1作为绑定地址 ：</p>
<ul>
<li>服务只接受来自容器内部的连接</li>
<li>即使您映射了端口，宿主机也无法访问该服务</li>
<li>只有容器内的应用程序可以通过 127.0.0.1:端口 访问</li>
</ul></li>
<li><p>使用0.0.0.0作为绑定地址 ：</p>
<ul>
<li>服务接受来自任何网络接口的连接请求</li>
<li>允许从容器外部（包括宿主机）访问该服务</li>
<li>当您映射端口时（如 -p 8000:8000 ），宿主机可以通过 localhost:8000 或
127.0.0.1:8000 访问</li>
</ul></li>
</ol>
<p><strong>为什么需要在容器内使用0.0.0.0</strong></p>
<p>在Docker环境中，容器有自己独立的网络命名空间，这意味着容器内的
127.0.0.1 与宿主机的 127.0.0.1 是完全不同的两个环境。因此：</p>
<ul>
<li>当您在容器内使用 –host 0.0.0.0
启动服务时，该服务会监听容器的所有网络接口</li>
<li>当您在宿主机上访问 127.0.0.1:映射端口
时，Docker会将请求转发到容器内监听在 0.0.0.0:容器端口 的服务</li>
</ul>
<h3 id="mineru相关知识">mineru相关知识</h3>
<h4 id="参数">参数</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Usage: mineru [OPTIONS]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -v, --version                   显示版本并退出</span><br><span class="line">  -p, --path PATH                 输入文件路径或目录（必填）</span><br><span class="line">  -o, --output PATH               输出目录（必填）</span><br><span class="line">  -m, --method [auto|txt|ocr]     解析方法：auto（默认）、txt、ocr（仅用于 pipeline 后端）</span><br><span class="line">  -b, --backend [pipeline|vlm-transformers|vlm-sglang-engine|vlm-sglang-client]</span><br><span class="line">                                  解析后端（默认为 pipeline）</span><br><span class="line">  -l, --lang [ch|ch_server|ch_lite|en|korean|japan|chinese_cht|ta|te|ka|latin|arabic|east_slavic|cyrillic|devanagari]</span><br><span class="line">                                  指定文档语言（可提升 OCR 准确率，仅用于 pipeline 后端）</span><br><span class="line">  -u, --url TEXT                  当使用 sglang-client 时，需指定服务地址</span><br><span class="line">  -s, --start INTEGER             开始解析的页码（从 0 开始）</span><br><span class="line">  -e, --end INTEGER               结束解析的页码（从 0 开始）</span><br><span class="line">  -f, --formula BOOLEAN           是否启用公式解析（默认开启）</span><br><span class="line">  -t, --table BOOLEAN             是否启用表格解析（默认开启）</span><br><span class="line">  -d, --device TEXT               推理设备（如 cpu/cuda/cuda:0/npu/mps，仅 pipeline 后端）</span><br><span class="line">  --vram INTEGER                  单进程最大 GPU 显存占用(GB)（仅 pipeline 后端）</span><br><span class="line">  --source [huggingface|modelscope|local]</span><br><span class="line">                                  模型来源，默认 huggingface</span><br><span class="line">  --help                          显示帮助信息</span><br></pre></td></tr></table></figure>
<h4 id="后端的区别">后端的区别</h4>
<p>pipeline (默认后端) :</p>
<ul>
<li>含义 : 这是 MinerU 的默认后端，它使用本地安装的 mineru
库来执行文档解析任务。它通常不依赖于外部的
VLM（视觉语言模型）服务，而是直接在本地处理 PDF 文件。</li>
</ul>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/10d6d1a7f702c5806e29ee7b1c51283.png" alt="10d6d1a7f702c5806e29ee7b1c51283">
<figcaption aria-hidden="true">10d6d1a7f702c5806e29ee7b1c51283</figcaption>
</figure>
<p>vlm-transformers :</p>
<ul>
<li>含义 : 这个后端利用 Hugging Face transformers 库中提供的 VLM
模型进行文档分析。它会在本地加载并运行一个基于 transformers 的 VLM
模型来处理 PDF 中的视觉信息和文本内容。</li>
</ul>
<blockquote>
<p>VLM（Vision-Language
Model，视觉语言模型）是一种结合计算机视觉和自然语言处理能力的多模态人工智能模型。</p>
<p>OCR 是 Optical Character
Recognition（光学字符识别）的缩写。它是一种技术，用于将图像中的手写、打印或打字文本转换为机器编码的文本，使其可以被计算机编辑、搜索、存储和处理。</p>
</blockquote>
<p>vlm-sglang-engine :</p>
<ul>
<li>含义 : 这个后端表示 MinerU 将直接集成并使用 SGLang 引擎进行 VLM
推理。SGLang 是一个高性能的推理引擎，旨在优化大型语言模型（LLM）和 VLM
的推理速度和效率。在这种模式下，SGLang 引擎作为 MinerU
进程的一部分运行。</li>
</ul>
<p>vlm-sglang-client :</p>
<ul>
<li>含义 : 这个后端表示 MinerU 作为 SGLang
服务器的客户端。在这种模式下，MinerU 不会直接运行 VLM 模型，而是将 PDF
处理请求发送到一个独立的 SGLang 服务器（通过 -u 参数指定的 URL，例如
http://localhost:30000 ）。SGLang 服务器负责执行实际的 VLM
推理，并将结果返回给 MinerU 客户端。</li>
</ul>
<blockquote>
<p>用场景 : 这是我们之前讨论的 Docker
容器部署场景中推荐的模式。它非常适合以下情况： - 资源隔离 : 将 VLM
推理的计算密集型任务从 MinerU 主进程中分离出来，允许独立扩展和管理
SGLang 服务器。 - 集中管理 : 可以在一个或多个 SGLang 服务器上集中管理
VLM 模型，供多个 MinerU 客户端共享使用。 - 性能优化 : SGLang
服务器可以针对 VLM 推理进行专门优化，提供更好的吞吐量和延迟。 - 灵活部署
: SGLang
服务器可以部署在不同的机器上，甚至作为微服务运行，提供更大的部署灵活性。</p>
</blockquote>
<h4 id="关于吞吐量的相关知识">关于吞吐量的相关知识</h4>
<p><strong>“吞吐量”（throughput）*<em>指的是系统在单位时间内能处理的
**Token 数量**，单位通常是
**tokens/秒**。这个指标衡量的是整体系统*</em>处理并发请求的能力</strong>，而不仅仅是单个请求的速度。</p>
<p>SGLang 支持两种主要并行方式来提升吞吐量：</p>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 43%">
<col style="width: 39%">
</colgroup>
<thead>
<tr>
<th>并行类型</th>
<th>作用</th>
<th>对吞吐量的影响</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>张量并行（TP）</strong></td>
<td>把模型权重切分到多张卡上，<strong>减少单卡负载</strong></td>
<td>提升单请求处理能力，<strong>但通信开销大</strong></td>
</tr>
<tr>
<td><strong>数据并行（DP）</strong></td>
<td>把不同请求分发到不同卡上，<strong>并行处理多个请求</strong></td>
<td>直接提升并发吞吐量，<strong>尤其适合高并发场景</strong></td>
</tr>
</tbody>
</table>
<h3 id="mineru的并发测试和吞吐量测试">mineru的并发测试和吞吐量测试</h3>
<p>并发能力是测试mineru同时处理多个请求的能力，吞吐量是测试mineru处理文件时的tokens</p>
<p>明确要的是哪个吞吐量：一个是<strong>MinerU 内部推理引擎（如
vLLM/SGLang）的 token/s 输出</strong>，即
<strong>生成阶段（decode）的吞吐量</strong>，一个是你压测
<code>/file_parse</code> 接口时的 <strong>端到端 tokens/s</strong>。</p>
<p>是否有缓存（kvcache）</p>
<p><strong>测试场景</strong>：10页的pdf，50用户并发</p>
<p><strong>工具</strong>：locust</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">locust \</span><br><span class="line">  -f locustfile.py \</span><br><span class="line">  --headless \</span><br><span class="line">  -u 50 \               # 并发用户数</span><br><span class="line">  -r 5 \                # 每秒启动用户数</span><br><span class="line">  --host=http://mineru-server:30000 \</span><br><span class="line">  --html=report.html \  # 自动生成 HTML 报告</span><br><span class="line">  --csv=result          # 同时保存 csv（result_stats.csv / result_failures.csv）</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">locust -f locustfile.py --headless -u 100 -r 5 --host=http://mineru-server:30000 --html=report.html --csv=result</span><br></pre></td></tr></table></figure>
<p><strong>测试结果</strong></p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250805152017255.png" alt="image-20250805152017255">
<figcaption aria-hidden="true">image-20250805152017255</figcaption>
</figure>
<p>对于推理模型的吞吐量，在3个gpu开启数据并行的情况下，平均每秒单个gpu处理tokens为1500左右</p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250805152149822.png" alt="image-20250805152149822">
<figcaption aria-hidden="true">image-20250805152149822</figcaption>
</figure>
<p>gpu状态如上:<strong>显存几乎打满 85–87 %</strong>,<strong>GPU 利用率
59–63 %</strong>,<strong>功耗 170–188 W / 350 W</strong></p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250805153516235.png" alt="image-20250805153516235">
<figcaption aria-hidden="true">image-20250805153516235</figcaption>
</figure>
<p>完整压测结果如上</p>
<p>重要指标：</p>
<table>
<colgroup>
<col style="width: 18%">
<col style="width: 28%">
<col style="width: 52%">
</colgroup>
<thead>
<tr>
<th>指标</th>
<th>数值</th>
<th>通俗解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>平均响应时间</strong></td>
<td><strong>241 秒</strong> ≈ <strong>4 分钟</strong></td>
<td>上传一个 PDF → 拿到解析结果，平均要等 4 分钟。</td>
</tr>
<tr>
<td><strong>中位数</strong></td>
<td><strong>215 秒</strong> ≈ <strong>3.6 分钟</strong></td>
<td>一半请求在 3.6 分钟内完成。</td>
</tr>
<tr>
<td><strong>95% 用户</strong></td>
<td><strong>361 秒</strong> ≈ <strong>6 分钟</strong></td>
<td>最慢的 5% 要等 6 分钟以上。</td>
</tr>
<tr>
<td><strong>吞吐量</strong></td>
<td><strong>0.18 req/s</strong></td>
<td>这台 MinerU <strong>每分钟只能处理约11 个 PDF</strong>。</td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250806104340935.png" alt="image-20250806104340935">
<figcaption aria-hidden="true">image-20250806104340935</figcaption>
</figure>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250806110438932.png" alt="image-20250806110438932">
<figcaption aria-hidden="true">image-20250806110438932</figcaption>
</figure>
<p>参考资料</p>
<p><a href="https://github.com/opendatalab/MinerU/blob/be4f3de32b58ccf81c6a6dcb9d3e4998424cee6a/projects/multi_gpu_v2/README_zh.md">MinerU/projects/multi_gpu_v2/README_zh.md
at be4f3de32b58ccf81c6a6dcb9d3e4998424cee6a · opendatalab/MinerU</a></p>
<h3 id="部署服务器并运行">部署服务器并运行</h3>
<p>load镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker load -i mineru-sglang-latest.tar</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">free -h</span><br><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250716092152823.png" alt="image-20250716092152823">
<figcaption aria-hidden="true">image-20250716092152823</figcaption>
</figure>
<p>每秒刷新<code>watch -n1 nvidia-smi          # 每秒刷新</code></p>
<p>查看Linux路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pwd </span><br></pre></td></tr></table></figure>
<p>启动容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 -p 7860:7860 -p 8000:8000 --ipc=host \</span><br><span class="line">-v &quot;/aisys/repo_dev/xizhang/pdfs:/pdfs&quot; \</span><br><span class="line">-v &quot;/aisys/repo_dev/xizhang/outputs:/output&quot; \</span><br><span class="line">mineru-sglang:latest \</span><br><span class="line">mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host -v &quot;/aisys/repo_dev/xizhang/pdfs:/pdfs&quot; -v &quot;/aisys/repo_dev/xizhang/outputs:/output&quot; mineru-sglang:latest mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec mineru-server mineru -p /pdfs/demo1.pdf -o /output -b vlm-sglang-client -u http://localhost:30000`</span><br></pre></td></tr></table></figure>
<p>进入容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it mineru-server /bin/bash</span><br></pre></td></tr></table></figure>
<p>使用pipline解析后端模式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mineru -p /pdfs/demo1.pdf -o /output --source local</span><br></pre></td></tr></table></figure>
<p>使用sglang加速推理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1,2,3 mineru -p /pdfs/small_ocr.pdf -o /output -b vlm-sglang-engine --source local</span><br></pre></td></tr></table></figure>
<blockquote>
<p>vlm模式同样可以处理扫描件</p>
</blockquote>
<p>使用ocr解析扫描件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mineru -p /pdfs/small_ocr.pdf -o /output --source local -m ocr</span><br></pre></td></tr></table></figure>
<p>增加推理设备</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mineru -p /pdfs/small_ocr.pdf -o /output --source local -m ocr -d cuda</span><br></pre></td></tr></table></figure>
<p>通过在命令行的开头添加<code>CUDA_VISIBLE_DEVICES</code>
环境变量来指定可见的 GPU 设备。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1,2,3 mineru -p /pdfs/small_ocr.pdf -o /output --source local -m ocr</span><br></pre></td></tr></table></figure>
<p>使用sglang加速模式的多GPU并行</p>
<p>数据并行（dp-size）和张量并行（tp-size）</p>
<p>MinerU支持通过sglang的多GPU并行模式来提升推理速度。您可以使用以下参数：</p>
<ul>
<li><code>--dp-size</code>:
数据并行，通过多卡同时处理多个输入来增加吞吐量</li>
<li><code>--tp-size</code>:
张量并行，将模型分布到多张GPU上以扩展可用显存</li>
</ul>
<blockquote>
<p>如果您已经可以正常使用sglang对vlm模型进行加速推理，但仍然希望进一步提升推理速度，可以尝试以下参数：</p>
<ul>
<li>如果您有超过多张显卡，可以使用sglang的多卡并行模式来增加吞吐量：<code>--dp-size 2</code></li>
<li>同时您可以启用<code>torch.compile</code>来将推理速度加速约15%：<code>--enable-torch-compile</code></li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1,2,3 mineru -p /pdfs -o /output -b vlm-sglang-engine --source local --dp-size 3 --enable-torch-compile</span><br></pre></td></tr></table></figure>
<p>将python文件上传docker并运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker cp demo.py mineru-server:/demo.py</span><br><span class="line"></span><br><span class="line">docker exec mineru-server python /demo.py</span><br><span class="line"></span><br><span class="line">#删除</span><br><span class="line">rm -i demo.py</span><br></pre></td></tr></table></figure>
<p>添加自定义网络，修改挂载卷</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host -v /aisys/:/aisys/ --network network_test mineru-sglang:latest mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<p>后面才知道，上面这个命令会自动启动sglang-server服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host -v /aisys/:/aisys/ --network network_test mineru-sglang:latest tail -f /dev/null</span><br><span class="line">docker start mineru-server</span><br></pre></td></tr></table></figure>
<p>使用上面这个命令启动容器，但不启动sglang-server服务，使用下面指令手动启动</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it mineru-server /bin/bash</span><br><span class="line">MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3 mineru-sglang-server --port 30000 --dp-size 3 --enable-torch-compile</span><br></pre></td></tr></table></figure>
<p>启动服务后在另一个容器尝试访问</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl http://mineru-server:30000/get_model_info</span><br></pre></td></tr></table></figure>
<p>在另一个容器使用服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mineru -p /test -o / -b vlm-sglang-client -u http://mineru-server:30000</span><br></pre></td></tr></table></figure>
<hr>
<p>启动fastapi服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3 mineru-api --host 0.0.0.0 --port 30000 --dp-size 3 --enable-torch-compile</span><br></pre></td></tr></table></figure>
<p>在另一个容器验证</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl http://mineru-server:30000/openapi.json</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在容器内设置环境变量</span><br><span class="line">export CUDA_VISIBLE_DEVICES=1,2,3</span><br><span class="line"># 验证环境变量是否设置成功</span><br><span class="line">echo $CUDA_VISIBLE_DEVICES</span><br><span class="line"></span><br><span class="line"># 在容器内设置环境变量</span><br><span class="line">export MINERU_MODEL_SOURCE=local</span><br><span class="line"># 验证环境变量是否设置成功</span><br><span class="line">echo $MINERU_MODEL_SOURCE</span><br></pre></td></tr></table></figure>
<h3 id="资料">资料</h3>
<p><a href="https://blog.csdn.net/liuzhenghua66/article/details/148980203">MinerU
2.0部署-CSDN博客</a></p>
<p>https://github.com/opendatalab/MinerU?tab=readme-ov-file#local-deployment</p>
<p>https://deepwiki.com/opendatalab/MinerU</p>
<p><a href="https://www.bilibili.com/video/BV1p8e6z9EEN?buvid=XX7932A7E9DD8A1DA92D4974AB535749A9B44&amp;from_spmid=tm.recommend.0.0&amp;is_story_h5=false&amp;mid=25yhOI1fPeVYa5V16BFcAw%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=a6679733-4670-4814-a87a-1f9b69d58619&amp;share_source=QQ&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1759039603&amp;unique_k=6wGbiDg&amp;up_id=1606629306&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">MinerU：PDF处理神器的Pipeline和VLM两种模式大揭秘_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
        <tag>docker</tag>
        <tag>MineU</tag>
      </tags>
  </entry>
  <entry>
    <title>prompt Engineering与context Engineering</title>
    <url>/2025/07/13/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/prompt%20Engineering%E4%B8%8Econtext%20Engineering/</url>
    <content><![CDATA[<h3 id="prompt-engineering">prompt Engineering</h3>
<p>Prompt
Engineering是与大型语言模型（LLM）交互的基础，其核心在于精心设计输入内容，以引导模型生成期望的输出。</p>
<p>尽管 Prompt Engineering
至关重要，但对于构建稳健、可用于生产环境的系统而言，它存在固有的局限性：</p>
<ul>
<li><p><strong>脆弱性&amp;不可复现性：</strong>
提示中微小的措辞变化可能导致输出结果的巨大差异，使得这一过程更像是一种依赖反复试错的“艺术”，而非可复现的“科学”
。</p></li>
<li><p><strong>扩展性差：</strong>
手动、迭代地优化提示的过程，在面对大量用户、多样化用例和不断出现的边缘情况时，难以有效扩展
。</p></li>
<li><p><strong>用户负担：</strong>
这种方法将精心构建一套详尽指令的负担完全压在了用户身上，对于需要自主运行、或处理高并发请求的系统而言是不切实际的
。</p></li>
<li><p><strong>无状态性：</strong> Prompt Engineering
本质上是为单轮、“一次性”的交互而设计的，难以处理需要记忆和状态管理的长对话或多步骤任务
。</p></li>
</ul>
<h3 id="context-engineering">Context Engineering</h3>
<p><strong>Context
Engineering是一门设计、构建并优化动态自动化系统的学科，旨在为大型语言模型在正确的时间、以正确的格式，提供正确的信息和工具，从而可靠、可扩展地完成复杂任务</strong>
。</p>
<p><strong>prompt 告诉模型如何思考，而 Context
则赋予模型完成工作所需的知识和工具。</strong></p>
<ul>
<li><p>Context Engineering 决定<strong>用什么内容填充 Context
Window</strong> ，</p></li>
<li><p>Prompt Engineering 则负责优化<strong>窗口内的具体指令</strong>
。</p></li>
</ul>
<h3 id="context-engineering-的基石ragretrieval-augmented-generation">Context
Engineering 的基石：RAG（Retrieval-Augmented Generation）</h3>
<p>本部分将阐述检索增强生成（RAG）作为实现 Context Engineering
的主要架构模式。</p>
<h4 id="解决llm的核心弱点">解决LLM的核心弱点</h4>
<p>RAG直接解决了标准LLM在企业应用中存在的固有局限性：</p>
<ul>
<li><p><strong>知识冻结：</strong>
LLM的知识被冻结在<strong>其训练数据的时间点</strong>。RAG通过在推理时注入实时的、最新的信息来解决这个问题
。</p></li>
<li><p><strong>缺乏领域专有知识：</strong>
标准LLM无法访问组织的内部私有数据。RAG则能够将LLM连接到这些内部知识库，如技术手册、政策文件等
。</p></li>
<li><p><strong>幻觉（Hallucination）：</strong> LLM
会不同程度上地编造事实。RAG通过将模型的回答“锚定”在可验证的、检索到的证据上，提高事实的准确性和可信度
。</p></li>
</ul>
<h4 id="rag工作流">RAG工作流</h4>
<ol type="1">
<li><p><strong>索引（离线阶段）：</strong>
在这个阶段，系统会处理外部知识源。文档被加载、分割成更小的
chunks，然后通过Embedding Model
转换为向量表示，并最终存储在专门的向量数据库中以备检索 。</p></li>
<li><p><strong>推理（在线阶段）：</strong>
当用户提出请求时，系统执行以下步骤：</p>
<ol type="1">
<li><strong>检索（Retrieve）：</strong>
将用户的查询同样转换为向量，然后在向量数据库中进行相似性搜索，找出与查询最相关的文档块。</li>
<li><strong>增强（Augment）：</strong>
将检索到的这些文档块与原始的用户查询、系统指令等结合起来，构建一个内容丰富的、增强的最终提示。</li>
<li><strong>生成（Generate）：</strong>
将这个增强后的提示输入给LLM，LLM会基于提供的上下文生成一个有理有据的回答
。</li>
</ol></li>
</ol>
<h3 id="context-工程化如何判断和提取哪些内容应该进入上下文">Context
工程化：如何判断和提取哪些内容应该进入上下文？</h3>
<h4 id="chunking">1.chunking</h4>
<p>文本分块（Chunking）是RAG流程中最关键也最容易被忽视的一步。其目标是创建在语义上自成一体的文本块。</p>
<h4 id="reranking">2.Reranking</h4>
<p>为了平衡检索的速度和准确性，业界普遍采用两阶段检索流程。</p>
<ul>
<li><p><strong>两阶段流程：</strong></p>
<ul>
<li><strong>第一阶段（召回）：</strong>
使用一个快速、高效的检索器（如基于 bi-encoder
的向量搜索或BM25等词法搜索）进行广泛撒网，召回一个较大的候选文档集（例如，前100个）
。</li>
<li><strong>第二阶段（精排/重排序）：</strong>
使用一个更强大但计算成本更高的模型，对这个较小的候选集进行重新评估，以识别出最相关的少数几个文档（例如，前5个）
。</li>
</ul></li>
<li><p><strong>Cross-Encoder：</strong>
交叉编码器之所以在重排序阶段表现优越，是因为它与双编码器的工作方式不同。双编码器独立地为查询和文档生成嵌入向量，然后计算它们的相似度。而交叉编码器则是将查询和文档<strong>同时</strong>作为输入，让模型在内部通过
Attention Mechanism
对二者进行深度交互。这使得模型能够捕捉到更细微的语义关系，从而给出更准确的相关性评分
。</p></li>
<li><p><strong>实际影响：</strong>
重排序显著提高了最终送入LLM的上下文质量，从而产出更准确、幻觉更少的答案。在金融、法律等高风险领域，重排序被认为是必不可少而非可选的步骤
。</p></li>
</ul>
<h4 id="优化上下文窗口压缩与摘要">3.优化上下文窗口：压缩与摘要</h4>
<p>本节详细介绍用于主动管理上下文的技术，确保最有价值的信息被优先呈现。</p>
<ul>
<li><p><strong>上下文压缩的目标：</strong>
缩短检索到的文档列表和/或精简单个文档的内容，只将<strong>最相关的信息传递给LLM</strong>。这能有效降低API调用成本、减少延迟，并缓解
Lost in the Middle 的问题 。</p></li>
<li><p><strong>压缩方法：</strong></p>
<ul>
<li><strong>过滤式压缩：</strong>
这类方法决定是保留还是丢弃整个检索到的文档。
<ul>
<li><strong>LLMChainFilter：</strong>
利用一个LLM对每个文档的相关性做出简单的“是/否”判断 。</li>
<li><strong>EmbeddingsFilter：</strong>
更经济快速的方法，根据文档嵌入与查询嵌入的余弦相似度来过滤文档 。</li>
</ul></li>
<li><strong>内容提取式压缩：</strong> 这类方法会直接修改文档内容。
<ul>
<li><strong>LLMChainExtractor：</strong>
遍历每个文档，并使用LLM从中提取仅与查询相关的句子或陈述 。</li>
</ul></li>
<li><strong>用 top N 代替压缩：</strong>
像LLMListwiseRerank这样的技术，使用LLM对检索到的文档进行重排序，并只返回排名最高的N个，从而起到高质量过滤器的作用
。</li>
</ul></li>
<li><p><strong>作为压缩策略的摘要：</strong>
对于非常长的文档或冗长的对话历史，可以利用LLM生成摘要。这些摘要随后被注入上下文，既保留了关键信息，又大幅减少了
Token 数量。这是在长时程运行的智能体中管理上下文的关键技术 。</p></li>
</ul>
<h3 id="智能体架构中的数据流与工作流编排">智能体架构中的数据流与工作流编排</h3>
<h4 id="工作流workflow-vs.-智能体agent">工作流（Workflow）
vs. 智能体（Agent）</h4>
<ul>
<li><strong>工作流（Workflows）</strong>
<ul>
<li>指的是LLM和工具通过<strong>预定义的代码路径</strong>进行编排的系统。在这种模式下，数据流动的路径是固定的、由开发者明确设计的，类似于上世纪流行的“专家系统”。例如，“第一步：分析用户邮件；第二步：根据分析结果在日历中查找空闲时段；第三步：起草会议邀请邮件”。这种模式确定性高，易于调试和控制，非常适合有明确业务流程的场景（如风控需求高、数据敏感、安全等级要求）。</li>
</ul></li>
<li><strong>智能体（Agents）</strong>
<ul>
<li>指的是LLM<strong>动态地指导</strong>自己的流程和工具使用，自主控制如何完成任务的系统。在这种模式下，数据流动的路径不是预先固定的，而是由LLM在每一步根据当前情况和目标动态决定的。这种模式灵活性高，能处理开放式问题，但可控性和可预测性较低
。</li>
</ul></li>
</ul>
<p>复杂的智能体通常是这两种模式的混合体，在宏观层面遵循一个预定义的工作流，但在某些节点内部，又赋予LLM一定的自主决策权。管理这一切的核心，我们称之为<strong>编排层（Orchestration
Layer）</strong> 。</p>
<h4 id="核心架构预定义数据流的实现"><strong>核心架构：预定义数据流的实现</strong></h4>
<ol type="1">
<li><p><strong>链式工作流（Prompt Chaining）</strong></p></li>
<li><p><strong>路由工作流（Routing)</strong></p></li>
<li><p><strong>编排器-工作者模式（Orchestrator-Workers）</strong></p></li>
</ol>
<h4 id="框架与工具">框架与工具</h4>
<p>上述的架构和机制并非凭空存在，而是通过具体的开发框架实现的。其中，LangGraph作为LangChain的扩展，为构建具有显式数据流的智能体系统提供了强大的工具集。</p>
<p><strong>LangGraph：用图（Graph）定义工作流（Workflow）</strong></p>
<p>LangGraph的核心思想是将智能体应用构建成一个<strong>状态图（State
Graph）</strong>
。这个图由节点和边组成，清晰地定义了数据如何在不同模块间流动</p>
<ul>
<li><strong>状态（State）：</strong>
这是整个图的核心，一个所有节点共享的中央数据对象。
<ul>
<li>你可以把它想象成一个“数据总线”或共享内存。开发者需要预先定义State的结构，每个节点在执行时都可以读取和更新这个State对象
。</li>
</ul></li>
<li><strong>节点（Nodes）：</strong>
代表工作流中的一个计算单元或一个步骤。
<ul>
<li>每个节点通常是一个Python函数，它接收当前的State作为输入，执行特定任务（如调用LLM、执行工具、处理数据），然后返回对State的更新
。</li>
</ul></li>
<li><strong>边（Edges）</strong>：
连接节点，定义了工作流的路径，即数据在State更新后应该流向哪个节点。
<ul>
<li><strong>简单边（Simple Edges）：</strong>
定义了固定的、无条件的流向，用于实现链式工作流 。</li>
<li><strong>条件边（Conditional Edges）：</strong>
用于实现路由逻辑。它会根据一个函数的输出来决定接下来应该走向哪个节点，从而实现流程的分支
。</li>
</ul></li>
<li><strong>检查点（Checkpointer）：</strong>
LangGraph提供了持久化机制，可以在每一步执行后自动保存State的状态。这对于构建需要长期记忆、可中断和恢复、或需要
Human-in-the-Loop 的复杂业务流程至关重要 。</li>
</ul>
<p>复杂业务流程的AI智能体，其核心挑战已从单纯优化信息检索（如RAG）或提示词，转向了对内部<strong>工作流和数据流的精心设计与编排</strong>。</p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
        <tag>学习</tag>
        <tag>大模型</tag>
        <tag>rag</tag>
        <tag>prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>Plan-and-Execute模式</title>
    <url>/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Plan-and-Execute%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h3 id="什么是plan-and-execute模式">什么是Plan-and-Execute模式</h3>
<p>Plan-and-Execute架构流程：先指定计划，后交给执行agent，执行后交给replan节点，判断是否需要更新计划，若要更新计划返回返回更新后的机会，否则返回response，然后路由判断是执行agent还是response</p>
<p>与ReAct模式不同的是，ReAct只做一次规划，而Plan-and-Execute模式核心思想是首先制定一个多步骤计划，然后逐项执行该计划。完成特定任务后，可以重新审视计划并进行适当修改。</p>
<p>举个例子，用户在问一个问题后，agent产生一份任务清单，选取第一份任务开始执行，执行后的结果结合任务清单，执行replan，结合新的信息，更改任务清单的内容，让后续大模型更好地执行，并去除已经完成的任务</p>
<p>实际生产中，应该在planner之前再进行一次判断，如果问题过于简单，不需要进行Plan-and-Execute模式</p>
<h3 id="实战">实战</h3>
<h4 id="安装包">安装包</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install --quiet -U langgraph langchain-community langchain-openai tavily-python</span><br></pre></td></tr></table></figure>
<h4 id="定义网络搜索工具与执行agent">定义网络搜索工具与执行agent</h4>
<p>在产生plan后，要有一个agent对任务清单进行执行，这里以一个ReAct的网络搜索agent为例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#定义工具</span><br><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line">tools = [TavilySearch(max_results=3)]</span><br><span class="line"></span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line">from langgraph.prebuilt import create_react_agent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=&quot;qwen3-235b-a22b-thinking-2507&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br><span class="line">prompt = &quot;You are a helpful assistant.&quot;</span><br><span class="line">agent_executor = create_react_agent(llm, tools, prompt=prompt)</span><br></pre></td></tr></table></figure>
<p>测试功能</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">agent_executor.invoke(&#123;&quot;messages&quot;: [(&quot;user&quot;, &quot;今天是几月几日&quot;)]&#125;)</span><br></pre></td></tr></table></figure>
<p>定义执行节点</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Literal</span><br><span class="line">from langgraph.graph import END</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">async def execute_step(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;执行计划中的步骤&quot;&quot;&quot;</span><br><span class="line">    plan = state[&quot;plan&quot;]</span><br><span class="line">    # 将计划格式化为带编号的字符串</span><br><span class="line">    plan_str = &quot;\n&quot;.join(f&quot;&#123;i + 1&#125;. &#123;step&#125;&quot; for i, step in enumerate(plan))</span><br><span class="line">    task = plan[0]  # 获取第一个待执行的任务</span><br><span class="line">    task_formatted = f&quot;&quot;&quot;对于以下计划:</span><br><span class="line">&#123;plan_str&#125;\n\n你被分配执行第 &#123;1&#125; 步, &#123;task&#125;。&quot;&quot;&quot;</span><br><span class="line">    # 调用代理执行器来执行任务</span><br><span class="line">    agent_response = await agent_executor.ainvoke(</span><br><span class="line">        &#123;&quot;messages&quot;: [(&quot;user&quot;, task_formatted)]&#125;</span><br><span class="line">    )</span><br><span class="line">    # 返回执行结果，添加到历史步骤中</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;past_steps&quot;: [(task, agent_response[&quot;messages&quot;][-1].content)],</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>create_react_agent 是 LangGraph 提供的一个预构建函数，位于
langgraph.prebuilt 模块中，用于快速创建一个基于 ReAct（Reasoning +
Acting）架构的智能代理。</p>
</blockquote>
<blockquote>
<p>langgraph预设的其他常用组件如下</p>
<p><strong>ToolNode</strong></p>
<p>功能：把 LangChain 工具（BaseTool）封装成一个图节点，负责：</p>
<ul>
<li><p>接收 LLM 生成的工具调用请求</p></li>
<li><p>真正执行工具</p></li>
<li><p>把结果返回给图</p></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.prebuilt import ToolNode</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[search, calculator])</span><br></pre></td></tr></table></figure>
<p><strong>tools_condition</strong></p>
<p>功能：判断 LLM 是否要继续调用工具的“路由函数”。</p>
<p>在 ReAct 图里通常放在节点之间的 条件边：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.prebuilt import tools_condition</span><br><span class="line"></span><br><span class="line">graph.add_conditional_edges(&quot;agent&quot;, tools_condition, &#123;</span><br><span class="line"></span><br><span class="line">  &quot;tools&quot;: &quot;tool_node&quot;,    # 需要工具 → 去 ToolNode</span><br><span class="line"></span><br><span class="line">  &quot;**__end__**&quot;: END       # 不需要 → 结束</span><br><span class="line"></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="定义状态">定义状态</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import Annotated, List, Tuple</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class PlanExecute(TypedDict):</span><br><span class="line">    input: str</span><br><span class="line">    plan: List[str]</span><br><span class="line">    past_steps: Annotated[List[Tuple], operator.add]</span><br><span class="line">    response: str</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Plan(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;未来要遵循的计划&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    steps: List[str] = Field(</span><br><span class="line">        description=&quot;需要遵循的不同步骤，应该按排序顺序排列&quot;</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<h4 id="定义模型">定义模型</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">model=ChatTongyi(</span><br><span class="line"> model=&quot;qwen-plus-2025-07-14&quot;,</span><br><span class="line"> api_key=&quot;sk-&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="定义初始计划节点">定义初始计划节点</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.prompts import ChatPromptTemplate</span><br><span class="line"></span><br><span class="line">planner_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (</span><br><span class="line">            &quot;system&quot;,</span><br><span class="line">            &quot;&quot;&quot;对于给定的目标，制定一个简单的逐步计划。\</span><br><span class="line">这个计划应该包含独立的任务，如果正确执行这些任务将得到正确的答案。不要添加任何多余的步骤。\</span><br><span class="line">最后一步的结果应该是最终答案。确保每个步骤都包含所需的所有信息——不要跳过任何步骤。&quot;&quot;&quot;,</span><br><span class="line">        ),</span><br><span class="line">        (&quot;placeholder&quot;, &quot;&#123;messages&#125;&quot;),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">planner = planner_prompt | model.with_structured_output(Plan)</span><br><span class="line"></span><br><span class="line">async def plan_step(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;制定初始计划步骤&quot;&quot;&quot;</span><br><span class="line">    # 使用规划器为用户输入制定计划</span><br><span class="line">    plan = await planner.ainvoke(&#123;&quot;messages&quot;: [(&quot;user&quot;, state[&quot;input&quot;])]&#125;)</span><br><span class="line">    </span><br><span class="line">    return &#123;&quot;plan&quot;: plan.steps&#125;</span><br></pre></td></tr></table></figure>
<h4 id="定义再计划节点">定义再计划节点</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Union</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Response(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;对用户的响应&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    response: str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Act(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;要执行的动作&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    action: Union[Response, Plan] = Field(</span><br><span class="line">        description=&quot;要执行的动作。如果你想响应用户，使用 Response。&quot;</span><br><span class="line">        &quot;如果你需要进一步使用工具来获取答案，使用 Plan。&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">replanner_prompt = ChatPromptTemplate.from_template(</span><br><span class="line">    &quot;&quot;&quot;对于给定的目标，制定一个简单的逐步计划。\</span><br><span class="line">这个    计划应该包含独立的任务，如果正确执行这些任务将得到正确的答案。不要添加任何多余的步骤。\</span><br><span class="line">最后一步的结果应该是最终答案。确保每个步骤都包含所需的所有信息——不要跳过任何步骤。</span><br><span class="line"></span><br><span class="line">你的目标是：</span><br><span class="line">&#123;input&#125;</span><br><span class="line"></span><br><span class="line">你的原始计划是：</span><br><span class="line">&#123;plan&#125;</span><br><span class="line"></span><br><span class="line">你目前已经完成了以下步骤：</span><br><span class="line">&#123;past_steps&#125;</span><br><span class="line"></span><br><span class="line">相应地更新你的计划。如果不需要更多步骤并且可以返回给用户，则直接响应。否则，填写计划。只添加仍需要完成的步骤到计划中。不要将已经完成的步骤作为计划的一部分返回。&quot;&quot;&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">replanner = replanner_prompt | model.with_structured_output(Act)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def replan_step(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;重新规划步骤&quot;&quot;&quot;</span><br><span class="line">    # 使用重新规划器根据当前状态更新计划</span><br><span class="line">    output = await replanner.ainvoke(state)</span><br><span class="line">    if isinstance(output.action, Response):</span><br><span class="line">        # 如果动作是响应，返回最终响应</span><br><span class="line">        return &#123;&quot;response&quot;: output.action.response&#125;</span><br><span class="line">    else:</span><br><span class="line">        # 如果动作是计划，返回新的计划步骤</span><br><span class="line">        return &#123;&quot;plan&quot;: output.action.steps&#125;</span><br></pre></td></tr></table></figure>
<h4 id="定义路由">定义路由</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def should_end(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;判断是否结束执行流程&quot;&quot;&quot;</span><br><span class="line">    if &quot;response&quot; in state and state[&quot;response&quot;]:</span><br><span class="line">        # 如果存在响应内容，结束流程</span><br><span class="line">        return END</span><br><span class="line">    else:</span><br><span class="line">        # 否则继续执行代理步骤</span><br><span class="line">        return &quot;agent&quot;</span><br></pre></td></tr></table></figure>
<h4 id="编译图">编译图</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import StateGraph, START</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line"></span><br><span class="line"># 创建内存检查点保存器</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 创建工作流图，使用 PlanExecute 状态类型</span><br><span class="line">workflow = StateGraph(PlanExecute)</span><br><span class="line"></span><br><span class="line"># 添加计划节点</span><br><span class="line">workflow.add_node(&quot;planner&quot;, plan_step)</span><br><span class="line"></span><br><span class="line"># 添加执行步骤节点</span><br><span class="line">workflow.add_node(&quot;agent&quot;, execute_step)</span><br><span class="line"></span><br><span class="line"># 添加重新规划节点</span><br><span class="line">workflow.add_node(&quot;replan&quot;, replan_step)</span><br><span class="line"></span><br><span class="line"># 从开始节点连接到计划节点</span><br><span class="line">workflow.add_edge(START, &quot;planner&quot;)</span><br><span class="line"></span><br><span class="line"># 从计划节点连接到代理执行节点</span><br><span class="line">workflow.add_edge(&quot;planner&quot;, &quot;agent&quot;)</span><br><span class="line"></span><br><span class="line"># 从代理执行节点连接到重新规划节点</span><br><span class="line">workflow.add_edge(&quot;agent&quot;, &quot;replan&quot;)</span><br><span class="line"></span><br><span class="line"># 添加条件边 - 从重新规划节点根据条件决定下一步</span><br><span class="line">workflow.add_conditional_edges(</span><br><span class="line">    &quot;replan&quot;,</span><br><span class="line">    # 传入决定下一个调用节点的函数</span><br><span class="line">    should_end,</span><br><span class="line">    [&quot;agent&quot;, END],  # 可能的下一个节点：代理节点或结束</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 最后，编译工作流并添加检查点功能！</span><br><span class="line"># 这将其编译为 LangChain Runnable，</span><br><span class="line"># 意味着你可以像使用其他任何 runnable 一样使用它</span><br><span class="line">app = workflow.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Plan-and-Execute%E6%A8%A1%E5%BC%8F/image-20250729092408872.png" alt="image-20250729092408872">
<figcaption aria-hidden="true">image-20250729092408872</figcaption>
</figure>
<h4 id="调用">调用</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 配置递归限制，防止无限循环</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;</span><br><span class="line">        &quot;thread_id&quot;: &quot;1&quot;,  # 必需：线程ID</span><br><span class="line">    &#125;,&quot;recursion_limit&quot;: 50&#125;</span><br><span class="line"></span><br><span class="line"># 输入问题：2024年澳大利亚网球公开赛男单冠军的家乡是哪里？</span><br><span class="line">inputs = &#123;&quot;input&quot;: &quot;2024年澳大利亚网球公开赛男单冠军的家乡是哪里？&quot;&#125;</span><br><span class="line"></span><br><span class="line"># 异步流式执行应用</span><br><span class="line">async for event in app.astream(inputs, config=config):</span><br><span class="line">    # 遍历每个事件</span><br><span class="line">    for k, v in event.items():</span><br><span class="line">        # 排除结束标记，打印其他所有事件内容</span><br><span class="line">        if k != &quot;__end__&quot;:</span><br><span class="line">            print(v)</span><br></pre></td></tr></table></figure>
<h3 id="资源">资源</h3>
<p><a href="https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute/">计划与执行
— Plan-and-Execute</a></p>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>langgraph</tag>
      </tags>
  </entry>
  <entry>
    <title>deepagents实战</title>
    <url>/2025/08/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/deepagent/</url>
    <content><![CDATA[<p><a href="https://www.bilibili.com/video/BV1hjeMzVEUu?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">LangChain
Deep Agents - 构建你自己的深度研究智能体_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.langchain.com/deep-agents/">《深度智能体》 —
Deep Agents</a></p>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>langgraph</tag>
      </tags>
  </entry>
  <entry>
    <title>Multi-Agent Workflows梳理与实战</title>
    <url>/2025/08/18/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Multi-Agent%20Workflows%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>代码见<a href="https://github.com/zxj-2023/learn-rag-langchain/tree/main/multi-agent">learn-rag-langchain/multi-agent
at main · zxj-2023/learn-rag-langchain</a></p>
<h3 id="什么是多智能体">什么是多智能体</h3>
<p>当我们谈论”多智能体”时，我们指的是由llm驱动的多个独立的agent以<strong>特定方式</strong>连接在一起。</p>
<p>每个agent可以拥有自己的提示、LLM、工具和其他自定义代码，以最佳方式与其他智能体协作。</p>
<p>这种思维方式非常适合用图来表示，就像 <code>langgraph</code>
所提供的那样。在这种方法中，每个智能体都是图中的<strong>一个节点</strong>，而它们之间的<strong>连接则表示为一条边</strong>。<strong>控制流由边管理</strong>，它们通过向图的状态中<strong>添加信息来进行通信</strong>。</p>
<h3 id="多智能体架构梳理">多智能体架构梳理</h3>
<p>langgraph给我们提供了几种<strong>多智能体架构</strong></p>
<figure>
<img src="/2025/08/18/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Multi-Agent%20Workflows%E5%AE%9E%E6%88%98/image-20250818163359517.png" alt="image-20250818163359517">
<figcaption aria-hidden="true">image-20250818163359517</figcaption>
</figure>
<p><strong>Network</strong>:
每个智能体可以与其他所有智能体通信。任何智能体都可以决定下一步调用哪个其他智能体。</p>
<p><a href="https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration/">Multi-agent
network</a></p>
<p><strong>Supervisor</strong>：每个智能体与一个单一的监督者智能体通信。监督者智能体决定下一步应该调用哪个智能体。</p>
<p><a href="https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor/">代理监督者
— Agent Supervisor</a></p>
<p><strong>Hierarchical</strong>:
你可以定义一个具有监督者监督者的多代理系统。这是监督者架构的泛化，并允许更复杂的控制流程。</p>
<p><a href="https://langchain-ai.github.io/langgraph/tutorials/multi_agent/hierarchical_agent_teams/">层级代理团队
— Hierarchical Agent Teams</a></p>
<p><strong>Custom multi-agent workflow</strong>:
每个代理只与代理子集通信。流程的部分是确定的，只有一些代理可以决定下一步调用哪些其他代理。</p>
<h3 id="agent-supervisor">Agent Supervisor</h3>
<p>在本教程中，你将构建一个包含两个代理的监督者系统——一个研究专家和一个数学专家。</p>
<h4 id="环境">环境</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -U langgraph langgraph-supervisor langchain-tavily &quot;langchain[openai]&quot;</span><br></pre></td></tr></table></figure>
<h4 id="创建工作代理">1. 创建工作代理</h4>
<p>首先，让我们创建我们的专业工作代理——研究代理和数学代理：</p>
<ul>
<li>研究代理将使用 Tavily API 访问网络搜索工具 <a href="https://www.tavily.com/">Tavily - The Web Access Layer for AI
Agents</a></li>
<li>数学代理将访问简单的数学工具（ <code>add</code> ,
<code>multiply</code> , <code>divide</code> ）</li>
</ul>
<h5 id="研究代理">研究代理</h5>
<p>对于网络搜索，我们将使用 <code>TavilySearch</code> 工具来自
<code>langchain-tavily</code> :</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line"></span><br><span class="line">web_search = TavilySearch(max_results=3,tavily_api_key=&quot;tvly-dev-&quot;)</span><br><span class="line">web_search_results = web_search.invoke(&quot;南京在哪&quot;)</span><br><span class="line"></span><br><span class="line">print(web_search_results[&quot;results&quot;][0][&quot;content&quot;])</span><br></pre></td></tr></table></figure>
<p>为了创建单个工作代理，我们将使用 LangGraph 的<a href="https://langchain-ai.github.io/langgraph/agents/agents/">预构建代理</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.prebuilt import create_react_agent</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line">llm=ChatOpenAI(</span><br><span class="line">    model=&quot;qwen3-235b-a22b-thinking-2507&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">research_agent = create_react_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[web_search],</span><br><span class="line">    prompt=(</span><br><span class="line">        &quot;你是一个研究代理。\n\n指令：\n- 仅协助与研究相关的任务，不得进行任何数学计算\n- 完成任务后，直接向主管回复\n- 仅回复你的工作结果，不得包含任何其他文字。&quot;</span><br><span class="line">    ),</span><br><span class="line">    name=&quot;research_agent&quot;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>让我们运行代理来验证它的行为是否符合预期。<strong>我们将使用</strong>
<code>pretty_print_messages</code>
<strong>辅助工具来美观地渲染流式代理输出</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import convert_to_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pretty_print_message(message, indent=False):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    美化打印单条消息</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        message: 要打印的消息对象</span><br><span class="line">        indent: 是否需要缩进打印</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 将消息转换为美观的HTML格式表示</span><br><span class="line">    pretty_message = message.pretty_repr(html=True)</span><br><span class="line">    if not indent:</span><br><span class="line">        # 如果不需要缩进，直接打印</span><br><span class="line">        print(pretty_message)</span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    # 如果需要缩进，为每一行添加制表符前缀</span><br><span class="line">    indented = &quot;\n&quot;.join(&quot;\t&quot; + c for c in pretty_message.split(&quot;\n&quot;))</span><br><span class="line">    print(indented)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pretty_print_messages(update, last_message=False):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    美化打印消息更新</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        update: 包含消息更新的数据结构</span><br><span class="line">        last_message: 是否只打印最后一条消息</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    is_subgraph = False  # 标记是否为子图更新</span><br><span class="line">    </span><br><span class="line">    # 检查更新是否为元组格式（包含命名空间信息）</span><br><span class="line">    if isinstance(update, tuple):</span><br><span class="line">        ns, update = update</span><br><span class="line">        # 如果命名空间为空，跳过父图更新的打印</span><br><span class="line">        if len(ns) == 0:</span><br><span class="line">            return</span><br><span class="line"></span><br><span class="line">        # 提取图ID并打印子图更新信息</span><br><span class="line">        graph_id = ns[-1].split(&quot;:&quot;)[0]</span><br><span class="line">        print(f&quot;来自子图 &#123;graph_id&#125; 的更新:&quot;)</span><br><span class="line">        print(&quot;\n&quot;)</span><br><span class="line">        is_subgraph = True</span><br><span class="line"></span><br><span class="line">    # 遍历每个节点的更新</span><br><span class="line">    for node_name, node_update in update.items():</span><br><span class="line">        # 构造更新标签</span><br><span class="line">        update_label = f&quot;来自节点 &#123;node_name&#125; 的更新:&quot;</span><br><span class="line">        if is_subgraph:</span><br><span class="line">            # 如果是子图，添加缩进</span><br><span class="line">            update_label = &quot;\t&quot; + update_label</span><br><span class="line"></span><br><span class="line">        print(update_label)</span><br><span class="line">        print(&quot;\n&quot;)</span><br><span class="line"></span><br><span class="line">        # 将节点更新中的消息转换为消息对象列表</span><br><span class="line">        messages = convert_to_messages(node_update[&quot;messages&quot;])</span><br><span class="line">        # 如果只要求最后一条消息，则截取最后一条</span><br><span class="line">        if last_message:</span><br><span class="line">            messages = messages[-1:]</span><br><span class="line"></span><br><span class="line">        # 打印每条消息</span><br><span class="line">        for m in messages:</span><br><span class="line">            pretty_print_message(m, indent=is_subgraph)</span><br><span class="line">        print(&quot;\n&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for chunk in research_agent.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;南京在哪?&quot;&#125;]&#125;</span><br><span class="line">):</span><br><span class="line">    pretty_print_messages(chunk)</span><br></pre></td></tr></table></figure>
<h5 id="数学代理">数学代理</h5>
<p>对于数学代理工具，我们将使用纯 Python 函数：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def add(a: float, b: float):</span><br><span class="line">    &quot;&quot;&quot;将两个数字相加。&quot;&quot;&quot;</span><br><span class="line">    return a + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def multiply(a: float, b: float):</span><br><span class="line">    &quot;&quot;&quot;将两个数字相乘。&quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def divide(a: float, b: float):</span><br><span class="line">    &quot;&quot;&quot;将两个数字相除。&quot;&quot;&quot;</span><br><span class="line">    return a / b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">math_agent = create_react_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[add, multiply, divide],</span><br><span class="line">    prompt=(</span><br><span class="line">        &quot;你是一个数学代理。\n\n&quot;</span><br><span class="line">        &quot;指令：\n&quot;</span><br><span class="line">        &quot;- 仅协助处理数学相关任务\n&quot;</span><br><span class="line">        &quot;- 完成任务后，直接回复给主管\n&quot;</span><br><span class="line">        &quot;- 仅回复你的工作结果，不要包含任何其他文字。&quot;</span><br><span class="line">    ),</span><br><span class="line">    name=&quot;math_agent&quot;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>让我们运行数学代理：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for chunk in math_agent.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what&#x27;s (3 + 5) x 7&quot;&#125;]&#125;</span><br><span class="line">):</span><br><span class="line">    pretty_print_messages(chunk)</span><br></pre></td></tr></table></figure>
<h4 id="创建监督者-langgraph-supervisor">2.创建监督者
<code>langgraph-supervisor</code></h4>
<p>为了实现我们的多智能体系统，我们将使用预构建的
<code>langgraph-supervisor</code> 库中的 <a href="https://langchain-ai.github.io/langgraph/reference/supervisor/#langgraph_supervisor.supervisor.create_supervisor"><code>create_supervisor</code></a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph_supervisor import create_supervisor</span><br><span class="line">from langchain.chat_models import init_chat_model</span><br><span class="line"></span><br><span class="line">supervisor = create_supervisor(</span><br><span class="line">    model=llm,</span><br><span class="line">    agents=[research_agent, math_agent],</span><br><span class="line">    prompt=(</span><br><span class="line">        &quot;你是一个管理两个代理的主管：\n&quot;</span><br><span class="line">        &quot;- 一个研究代理。将研究相关任务分配给这个代理\n&quot;</span><br><span class="line">        &quot;- 一个数学代理。将数学相关任务分配给这个代理\n&quot;</span><br><span class="line">        &quot;一次只分配工作给一个代理，不要并行调用代理。\n&quot;</span><br><span class="line">        &quot;不要自己做任何工作。&quot;</span><br><span class="line">    ),</span><br><span class="line">    add_handoff_back_messages=True,</span><br><span class="line">    output_mode=&quot;full_history&quot;,</span><br><span class="line">).compile()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import display, Image</span><br><span class="line"></span><br><span class="line">display(Image(supervisor.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/08/18/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Multi-Agent%20Workflows%E5%AE%9E%E6%88%98/image-20250819113009108.png" alt="image-20250819113009108">
<figcaption aria-hidden="true">image-20250819113009108</figcaption>
</figure>
<p>现在让我们用一个需要两个代理的查询来运行它：</p>
<p>研究代理将查找必要的 GDP 信息；数学代理将执行除法以找到纽约州 GDP
的百分比，如所请求</p>
<h4 id="从头创建监督者">3.从头创建监督者</h4>
<p>现在让我们从头实现这个多智能体系统。我们需要：</p>
<ol type="1">
<li>设置主管如何与各个代理进行沟通</li>
<li>创建监督代理</li>
<li>将监督代理和工作代理组合成一个多代理图。</li>
</ol>
<h5 id="设置代理通信">设置代理通信</h5>
<p>我们需要定义一种方式，让监督代理能够与工作代理进行通信。在多代理架构中，实现这一功能的一种常见方法是使用<strong>handoffs</strong>，即一个代理将控制权交给另一个代理。交接允许你指定：</p>
<ul>
<li><strong>destination</strong>:要转移到的目标代理</li>
<li><strong>payload</strong>:要传递给该智能体的信息</li>
</ul>
<p>我们将通过<strong>handoff
tools</strong>（转接工具）实现转接，并将这些工具交给监督代理：当监督代理调用这些工具时，它将控制权转交给工作代理，并将完整消息历史传递给该代理。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Annotated</span><br><span class="line">from langchain_core.tools import tool, InjectedToolCallId</span><br><span class="line">from langgraph.prebuilt import InjectedState</span><br><span class="line">from langgraph.graph import StateGraph, START, MessagesState</span><br><span class="line">from langgraph.types import Command</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_handoff_tool(*, agent_name: str, description: str | None = None):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    创建一个“交接”工具函数，用于在 LangGraph 的 Supervisor-Worker 架构中</span><br><span class="line">    把当前对话状态移交给指定名称的子 Agent。</span><br><span class="line"></span><br><span class="line">    参数</span><br><span class="line">    ----</span><br><span class="line">    agent_name : str</span><br><span class="line">        目标子 Agent 的名称，必须与 Supervisor 图中注册的节点名一致。</span><br><span class="line">    description : str | None</span><br><span class="line">        工具的描述文本。如果为 None，则使用默认描述 &quot;Ask &#123;agent_name&#125; for help.&quot;。</span><br><span class="line"></span><br><span class="line">    返回</span><br><span class="line">    ----</span><br><span class="line">    handoff_tool : Callable</span><br><span class="line">        一个已用 @tool 装饰的函数，可直接注入到 Supervisor 的工具列表。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 动态生成工具名，例如 agent_name=&quot;math_agent&quot; -&gt; &quot;transfer_to_math_agent&quot;</span><br><span class="line">    name = f&quot;transfer_to_&#123;agent_name&#125;&quot;</span><br><span class="line"></span><br><span class="line">    # 如果调用者没有提供描述，则使用默认描述</span><br><span class="line">    description = description or f&quot;Ask &#123;agent_name&#125; for help.&quot;</span><br><span class="line"></span><br><span class="line">    # 用 LangGraph 的 @tool 装饰器注册工具</span><br><span class="line">    @tool(name, description=description)</span><br><span class="line">    def handoff_tool(</span><br><span class="line">        state: Annotated[MessagesState, InjectedState],</span><br><span class="line">        tool_call_id: Annotated[str, InjectedToolCallId],</span><br><span class="line">    ) -&gt; Command:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        实际执行交接逻辑的工具函数。</span><br><span class="line"></span><br><span class="line">        参数</span><br><span class="line">        ----</span><br><span class="line">        state : MessagesState</span><br><span class="line">            当前对话状态，由 LangGraph 注入。</span><br><span class="line">        tool_call_id : str</span><br><span class="line">            本次工具调用的唯一 ID，由 LangGraph 注入。</span><br><span class="line"></span><br><span class="line">        返回</span><br><span class="line">        ----</span><br><span class="line">        Command</span><br><span class="line">            一个 LangGraph Command 对象，告诉框架：</span><br><span class="line">            - goto=agent_name        : 跳转到哪个子 Agent</span><br><span class="line">            - update                 : 更新后的状态</span><br><span class="line">            - graph=Command.PARENT   : 在父图（Supervisor）作用域内执行</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 构造一条工具消息，记录交接动作</span><br><span class="line">        tool_message = &#123;</span><br><span class="line">            &quot;role&quot;: &quot;tool&quot;,</span><br><span class="line">            &quot;content&quot;: f&quot;Successfully transferred to &#123;agent_name&#125;&quot;,</span><br><span class="line">            &quot;name&quot;: name,</span><br><span class="line">            &quot;tool_call_id&quot;: tool_call_id,</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        # 使用 Command 把对话状态连同新消息一起发送到目标 Agent</span><br><span class="line">        return Command(</span><br><span class="line">            goto=agent_name,</span><br><span class="line">            update=&#123;**state, &quot;messages&quot;: state[&quot;messages&quot;] + [tool_message]&#125;,</span><br><span class="line">            graph=Command.PARENT,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    # 返回已装饰的工具函数，供 Supervisor 添加进 tools 列表</span><br><span class="line">    return handoff_tool</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建研究代理的交接工具</span><br><span class="line">assign_to_research_agent = create_handoff_tool(</span><br><span class="line">    agent_name=&quot;research_agent&quot;,</span><br><span class="line">    description=&quot;Assign task to a researcher agent.&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 创建数学代理的交接工具</span><br><span class="line">assign_to_math_agent = create_handoff_tool(</span><br><span class="line">    agent_name=&quot;math_agent&quot;,</span><br><span class="line">    description=&quot;Assign task to a math agent.&quot;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h5 id="创建监督代理">创建监督代理</h5>
<p>然后，我们使用刚刚定义的交接工具来创建监督代理。我们将使用预构建的
<code>create_react_agent</code> :</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">supervisor_agent = create_react_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[assign_to_research_agent, assign_to_math_agent],</span><br><span class="line">    prompt=(</span><br><span class="line">        &quot;你是一个管理两个代理的主管：\n&quot;</span><br><span class="line">        &quot;- 一个研究代理。将研究相关任务分配给这个代理\n&quot;</span><br><span class="line">        &quot;- 一个数学代理。将数学相关任务分配给这个代理\n&quot;</span><br><span class="line">        &quot;一次只分配工作给一个代理，不要并行调用代理。\n&quot;</span><br><span class="line">        &quot;不要自己做任何工作。&quot;</span><br><span class="line">    ),</span><br><span class="line">    name=&quot;supervisor&quot;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h5 id="创建多智能体图">创建多智能体图</h5>
<p>将这些内容整合起来，让我们为我们的整体多代理系统创建一个图。我们将添加监督代理和各个代理作为子图节点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import END</span><br><span class="line"></span><br><span class="line"># 定义多代理主管图</span><br><span class="line">supervisor = (</span><br><span class="line">    StateGraph(MessagesState)</span><br><span class="line">    # 注意：`destinations` 仅用于可视化，不影响运行时行为</span><br><span class="line">    .add_node(supervisor_agent, destinations=(&quot;research_agent&quot;, &quot;math_agent&quot;, END))</span><br><span class="line">    .add_node(research_agent)</span><br><span class="line">    .add_node(math_agent)</span><br><span class="line">    .add_edge(START, &quot;supervisor&quot;)</span><br><span class="line">    # 总是返回到主管</span><br><span class="line">    .add_edge(&quot;research_agent&quot;, &quot;supervisor&quot;)</span><br><span class="line">    .add_edge(&quot;math_agent&quot;, &quot;supervisor&quot;)</span><br><span class="line">    .compile()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在这个代码中，去 <code>research_agent</code> 和
<code>math_agent</code>
的条件边是通过<strong>工具调用</strong>实现的，而不是显式的条件边。</p>
<p>工作机制：</p>
<ol type="1">
<li><p><strong>工具作为交接手段</strong>：</p>
<ul>
<li><code>assign_to_research_agent</code> 和
<code>assign_to_math_agent</code> 这两个工具被添加到
<code>supervisor_agent</code> 中</li>
<li>当 supervisor_agent 决定需要某个代理帮助时，它会调用相应的工具</li>
</ul></li>
<li><p><strong>工具内部实现交接</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def handoff_tool(...) -&gt; Command:</span><br><span class="line">    return Command(</span><br><span class="line">        goto=agent_name,  # 这里指定了要跳转到哪个代理</span><br><span class="line">        update=&#123;...&#125;,</span><br><span class="line">        graph=Command.PARENT,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure></li>
<li><p><strong>隐式的条件边</strong>：</p>
<ul>
<li>当 supervisor_agent 调用 <code>assign_to_research_agent</code>
工具时 → 自动跳转到 <code>research_agent</code></li>
<li>当 supervisor_agent 调用 <code>assign_to_math_agent</code> 工具时 →
自动跳转到 <code>math_agent</code></li>
</ul></li>
</ol>
</blockquote>
<blockquote>
<p>什么是 Command 机制</p>
<p>Command 机制是 LangGraph
提供的一种<strong>显式控制流程跳转</strong>的方式。它允许工具或节点直接指定下一步要执行什么操作，而不需要通过传统的条件边路由。</p>
<p>Command 的核心概念</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.types import Command</span><br><span class="line"></span><br><span class="line">Command(</span><br><span class="line">    goto=agent_name,           # 要跳转到的目标节点</span><br><span class="line">    update=state_update,       # 要更新的状态</span><br><span class="line">    graph=Command.PARENT      # 在哪个图中执行（父图/子图）</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>请注意，我们已经从工作代理添加了明确的边回到主管——这意味着它们保证会将控制权返回给主管。如果你希望代理直接响应用户（即，将系统转变为路由器），你可以移除这些边。</p>
<h3 id="multi-agent-network">Multi-agent network</h3>
<p>一个单一智能体通常可以使用单个领域内的一小批工具来有效运作，但即使使用像
<code>gpt-4</code> 这样强大的模型，使用多个工具时也可能效果不佳。</p>
<p>处理复杂任务的一种方法是采用“分而治之”的方法：为每个任务或领域创建一个专门的智能体，并将任务路由到正确的“专家”。这是一个多智能体网络架构的例子。</p>
<figure>
<img src="/2025/08/18/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Multi-Agent%20Workflows%E5%AE%9E%E6%88%98/image-20250819150039818.png" alt="image-20250819150039818">
<figcaption aria-hidden="true">image-20250819150039818</figcaption>
</figure>
<p><strong>这个多agent架构，就像多个agent进行讨论，所以也叫Multi Agent
Collaboration，但是给我的感觉，比较混乱，agent直接的路由很难去定义，agent一多就搞不清楚了</strong>，所以这里也不实战了。</p>
<h3 id="hierarchical-agent-teams">Hierarchical Agent Teams</h3>
<p>对于某些应用，如果工作按层次分布，系统可能会更有效。你可以通过组合不同的子图，并创建一个顶层监督者以及中层监督者来实现这一点。</p>
<figure>
<img src="/2025/08/18/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Multi-Agent%20Workflows%E5%AE%9E%E6%88%98/image-20250819151813264.png" alt="image-20250819151813264">
<figcaption aria-hidden="true">image-20250819151813264</figcaption>
</figure>
<p>使用预设的supervisor构建</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1. 定义研究团队的代理</span><br><span class="line">@tool</span><br><span class="line">def web_search(query: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;执行网络搜索&quot;&quot;&quot;</span><br><span class="line">    return f&quot;搜索结果：关于&#x27;&#123;query&#125;&#x27;的最新信息...&quot;</span><br><span class="line"></span><br><span class="line">@tool</span><br><span class="line">def analyze_data(data: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;分析数据&quot;&quot;&quot;</span><br><span class="line">    return f&quot;数据分析结果：&#123;data&#125;的趋势显示...&quot;</span><br><span class="line"></span><br><span class="line">research_agent = create_react_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[web_search, analyze_data],</span><br><span class="line">    prompt=&quot;你是一个研究专家，负责进行网络搜索和数据分析。&quot;,</span><br><span class="line">    name=&quot;research_specialist&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 2. 定义数学团队的代理</span><br><span class="line">@tool</span><br><span class="line">def calculate_statistics(numbers: list[float]) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;计算统计值&quot;&quot;&quot;</span><br><span class="line">    if not numbers:</span><br><span class="line">        return &quot;错误：数据列表为空&quot;</span><br><span class="line">    avg = sum(numbers) / len(numbers)</span><br><span class="line">    return f&quot;统计结果：平均值=&#123;avg:.2f&#125;，数据点数量=&#123;len(numbers)&#125;&quot;</span><br><span class="line"></span><br><span class="line">@tool</span><br><span class="line">def solve_equation(equation: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;解方程&quot;&quot;&quot;</span><br><span class="line">    return f&quot;方程 &#123;equation&#125; 的解为：x = 42&quot;</span><br><span class="line"></span><br><span class="line">math_agent = create_react_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[calculate_statistics, solve_equation],</span><br><span class="line">    prompt=&quot;你是一个数学专家，负责统计计算和方程求解。&quot;,</span><br><span class="line">    name=&quot;math_specialist&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 3. 创建研究团队主管</span><br><span class="line">research_supervisor = create_supervisor(</span><br><span class="line">    model=llm,</span><br><span class="line">    agents=[research_agent],</span><br><span class="line">    prompt=(</span><br><span class="line">        &quot;你是研究团队的主管。\n&quot;</span><br><span class="line">        &quot;你的团队有一个研究专家，负责网络搜索和数据分析。\n&quot;</span><br><span class="line">        &quot;根据任务需求，将工作分配给研究专家。\n&quot;</span><br><span class="line">        &quot;等待专家完成任务后，总结结果并报告给上级主管。&quot;</span><br><span class="line">    ),</span><br><span class="line">    name=&quot;research_supervisor&quot;</span><br><span class="line">).compile(name=&quot;research_supervisor&quot;)</span><br><span class="line"></span><br><span class="line"># 4. 创建数学团队主管</span><br><span class="line">math_supervisor = create_supervisor(</span><br><span class="line">    model=llm,</span><br><span class="line">    agents=[math_agent],</span><br><span class="line">    prompt=(</span><br><span class="line">        &quot;你是数学团队的主管。\n&quot;</span><br><span class="line">        &quot;你的团队有一个数学专家，负责统计计算和方程求解。\n&quot;</span><br><span class="line">        &quot;根据任务需求，将工作分配给数学专家。\n&quot;</span><br><span class="line">        &quot;等待专家完成任务后，总结结果并报告给上级主管。&quot;</span><br><span class="line">    ),</span><br><span class="line">    name=&quot;math_supervisor&quot;</span><br><span class="line">).compile(name=&quot;math_supervisor&quot;)</span><br><span class="line"></span><br><span class="line"># 5. 创建顶层主管</span><br><span class="line">top_supervisor = create_supervisor(</span><br><span class="line">    model=llm,</span><br><span class="line">    agents=[research_supervisor, math_supervisor],</span><br><span class="line">    prompt=(</span><br><span class="line">        &quot;你是顶层主管，管理两个专业团队：\n&quot;</span><br><span class="line">        &quot;- 研究团队：负责市场调研、数据分析等任务\n&quot;</span><br><span class="line">        &quot;- 数学团队：负责统计计算、方程求解等任务\n&quot;</span><br><span class="line">        &quot;根据任务的性质，将工作分配给相应的团队主管。\n&quot;</span><br><span class="line">        &quot;等待团队完成任务后，整合所有结果并给出最终报告。&quot;</span><br><span class="line">    ),</span><br><span class="line">    name=&quot;top_supervisor&quot;</span><br><span class="line">).compile(name=&quot;top_supervisor&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://blog.langchain.com/langgraph-multi-agent-workflows/">LangGraph：多智能体工作流
— LangGraph: Multi-Agent Workflows</a></p>
<p><a href="https://langchain-ai.github.io/langgraph/concepts/multi_agent/">Overview</a></p>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>langgraph</tag>
      </tags>
  </entry>
  <entry>
    <title>储存向量数据库Chroma</title>
    <url>/2025/07/31/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/%E5%82%A8%E5%AD%98%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93Chroma/</url>
    <content><![CDATA[<h3 id="chroma是什么">Chroma是什么</h3>
<p>Chroma（通常指 <strong>ChromaDB</strong>）是一款 <strong>开源、AI
原生的向量数据库</strong>，专为存储和检索 <strong>高维嵌入向量</strong>
而设计，目标是让开发者 <strong>5 分钟内在本地跑起一个语义搜索或 RAG
系统</strong>。</p>
<p><strong>极简安装</strong>：<code>pip install chromadb</code></p>
<p><strong>双运行模式</strong>：</p>
<ul>
<li><strong>内存模式</strong>：调试/原型随意重启；</li>
<li><strong>持久化模式</strong>：指定 <code>persist_directory</code>
即可落盘，生产也不怕丢数据。</li>
</ul>
<p><strong>HNSW 索引</strong>：百万级向量也能 <strong>毫秒级</strong>
响应。</p>
<h3 id="使用chroma存储">使用chroma存储</h3>
<h4 id="文档分块">文档分块</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.document_loaders import PyPDFLoader</span><br><span class="line">from langchain.text_splitter import RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">loader = PyPDFLoader(&quot;input/健康档案.pdf&quot;)</span><br><span class="line">docs = loader.load()</span><br><span class="line">#递归分块</span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_siz</span><br></pre></td></tr></table></figure>
<h4 id="定义embedding模型与chroma">定义embedding模型与chroma</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">from langchain.vectorstores import Chroma</span><br><span class="line">from langchain_openai import OpenAIEmbeddings</span><br><span class="line">embedding = OpenAIEmbeddings(</span><br><span class="line">api_key=&quot;sk-&quot;, </span><br><span class="line">base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">model=&quot;text-embedding-v4&quot;,</span><br><span class="line">check_embedding_ctx_length = False,</span><br><span class="line">dimensions=1536</span><br><span class="line">)</span><br><span class="line"># 使用 Chroma 向量数据库存储文档 chunks</span><br><span class="line">vectorstore = Chroma.from_documents(</span><br><span class="line">    documents=chunks,           # 要存储的文档chunks列表（已处理好的文本片段）</span><br><span class="line">    embedding=embedding,        </span><br><span class="line">    persist_directory=&quot;chromaDB&quot;,  # 向量数据库的持久化存储目录路径</span><br><span class="line">    collection_name=&quot;demo001&quot;   # 集合名称，用于区分不同的文档集合</span><br><span class="line">)</span><br><span class="line">vectorstore.persist()</span><br></pre></td></tr></table></figure>
<h4 id="检索">检索</h4>
<p>这里采取直接检索进行测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">results = vectorstore.similarity_search(</span><br><span class="line">    &quot;张三九的基本信息是什么&quot;,</span><br><span class="line">    k=2,</span><br><span class="line">    collection_name=&quot;demo001&quot;  # 指定检索的集合</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="重新加载">重新加载</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 重新加载已存在的 Chroma 数据库</span><br><span class="line">vectorstore = Chroma(</span><br><span class="line">    persist_directory=&quot;./chroma_db&quot;,</span><br><span class="line">    embedding_function=embedding</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">retriever = vectorstore.as_retriever()</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://python.langchain.com/docs/integrations/vectorstores/chroma/#add-items-to-vector-store">Chroma
| 🦜️🔗 LangChain — Chroma | 🦜️🔗 LangChain</a></p>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>langgraph</tag>
        <tag>Chroma</tag>
      </tags>
  </entry>
  <entry>
    <title>pgsql实现持久化</title>
    <url>/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/pgsql%E5%AE%9E%E7%8E%B0%E6%8C%81%E4%B9%85%E5%8C%96/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>常使用pgsql与redis配合langgraph的checkpoint与store进行持久化储存，完成长期记忆与短期记忆的实现</p>
<h3 id="pgsql实现持久化">pgsql实现持久化</h3>
<h4 id="什么是pgsql">什么是pgsql</h4>
<p>PostgreSQL（常简称pgsql或Postgres）是一个功能强大的开源对象-关系型数据库管理系统（ORDBMS），以其稳定性、扩展性和符合SQL标准著称。</p>
<h4 id="docker拉取">docker拉取</h4>
<p>docker-compose</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">version: &#x27;3.8&#x27;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  postgres:</span><br><span class="line">    image: postgres:15        # 指定具体版本</span><br><span class="line">    container_name: postgres_db</span><br><span class="line">    environment:</span><br><span class="line">      POSTGRES_USER: postgres</span><br><span class="line">      POSTGRES_PASSWORD: postgres</span><br><span class="line">      POSTGRES_DB: postgres</span><br><span class="line">      TZ: Asia/Shanghai       # 设置时区</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5432:5432&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - pgdata:/var/lib/postgresql/data</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    healthcheck:             # 健康检查</span><br><span class="line">      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;nange&quot;]</span><br><span class="line">      interval: 10s</span><br><span class="line">      timeout: 5s</span><br><span class="line">      retries: 5</span><br><span class="line">    command: [&quot;postgres&quot;, &quot;-c&quot;, &quot;max_connections=200&quot;]  # 自定义配置</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  pgdata:</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Docker Compose</strong> 是一个 <strong>定义和运行多容器
Docker 应用</strong> 的 <strong>声明式工具</strong>。 它通过一个
<strong>YAML 文件（通常叫 <code>docker-compose.yml</code>）</strong>
描述整个应用的服务、网络、存储等配置，然后用一条命令即可
<strong>启动/停止/管理</strong> 所有容器，无需手动逐个
<code>docker run</code>。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#拉取并运行</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>
<h4 id="在pgsqsl安装依赖">在pgsqsl安装依赖</h4>
<p>因为LangGraph的PostgresStore需要使用到pgvector，因此需要在容器中按照如下步骤进行操作，直接使用Docker
Desktop软件中进行操作</p>
<blockquote>
<ul>
<li>为什么需要 <code>pgvector</code>？</li>
<li><code>PostgresStore</code> 支持将
<strong>向量嵌入（embedding）</strong> 存储在 PostgreSQL
中，并基于它们进行 <strong>语义搜索</strong>。</li>
<li>该功能依赖 <code>pgvector</code> 扩展提供的 <code>vector</code>
类型和索引机制（如 HNSW）。</li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">安装依赖           </span><br><span class="line">apt update    #刷新本地软件包索引           </span><br><span class="line">apt install -y git build-essential postgresql-server-dev-15                          </span><br></pre></td></tr></table></figure>
<blockquote>
<p>apt install -y git build-essential postgresql-server-dev-15一次性安装
3 类依赖。</p>
<ul>
<li><code>git</code> —— 用来克隆 pgvector 源码。</li>
<li><code>build-essential</code> —— Debian/Ubuntu
的“编译工具链”元包，包含 gcc、make 等。</li>
<li><code>postgresql-server-dev-15</code> —— 与当前 Postgres
<strong>主版本一致</strong> 的开发头文件和 <code>pg_config</code>。</li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">编译并安装 pgvector      </span><br><span class="line">#把 pgvector 的 v0.7.0 稳定版 源码克隆到本地目录 ./pgvector。</span><br><span class="line">git clone --branch v0.7.0 https://github.com/pgvector/pgvector.git                </span><br><span class="line">cd pgvector  </span><br><span class="line">#调用 Makefile 根据当前操作系统 + PostgreSQL 版本编译出二进制文件（.so 共享库）。</span><br><span class="line">make          </span><br><span class="line">#把刚刚编好的 .so 文件和 .sql/.control 文件复制到 PostgreSQL 的扩展目录</span><br><span class="line">make install                </span><br><span class="line">验证安装，检查扩展文件是否安装成功                    </span><br><span class="line">ls -l /usr/share/postgresql/15/extension/vector* </span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/pgvector/pgvector">pgvector/pgvector:
Open-source vector similarity search for Postgres</a></p>
<p>接下来，若要在脚本中进行使用，首先在系统环境中需要安装PostgreSQL
的开发库（libpq），因为 psycopg 需要它来编译或运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install libpq-dev postgresql-server-dev-all</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>psycopg（Python 操作 PostgreSQL 的库）</strong> 在
<strong>Linux/macOS</strong> 上运行时，底层依赖于 <strong>PostgreSQL 的
C 语言开发库 libpq</strong>。 如果系统里 <strong>没有
libpq</strong>，psycopg 会出现以下两种问题：</p>
<ol type="1">
<li><p><strong>编译安装失败</strong>（源码/旧版本） 当
<code>pip install psycopg2</code> 需要现场编译时，会找不到头文件
<code>libpq-fe.h</code> 或动态库 <code>libpq.so</code>，导致报错：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">error: libpq-fe.h: No such file or directory</span><br></pre></td></tr></table></figure></li>
<li><p><strong>运行时崩溃</strong> 即使通过预编译的 wheel
包安装成功，运行时也可能提示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ImportError: libpq.so.5: cannot open shared object file</span><br></pre></td></tr></table></figure></li>
</ol>
</blockquote>
<p>最后，再安装相关依赖包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install langgraph-checkpoint-postgres                    </span><br><span class="line">pip install psycopg psycopg-pool </span><br></pre></td></tr></table></figure>
<p>psycopg官方 PostgreSQL 驱动，在 <code>psycopg</code>
之上再包一层“<strong>连接池</strong>”，让并发访问更快、更稳定。</p>
<h4 id="连接pgsql">连接pgsql</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.store.postgres import PostgresStore</span><br><span class="line">from langgraph.checkpoint.postgres import PostgresSaver</span><br><span class="line">from psycopg_pool import ConnectionPool</span><br><span class="line"># 1) 连接字符串（URI 语法）</span><br><span class="line">DB_URI = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line">#   协议://      用户   : 密码   @ 主机:端口 / 数据库名  ? 额外参数</span><br><span class="line"></span><br><span class="line"># 2) 连接级参数</span><br><span class="line">connection_kwargs = &#123;</span><br><span class="line">    &quot;autocommit&quot;: True,     # 每条 SQL 执行完立即提交，无需手动 commit</span><br><span class="line">    &quot;prepare_threshold&quot;: 0, # 禁用服务器端 prepared statement，可减少一次往返</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 3) 创建池</span><br><span class="line">connection_pool = ConnectionPool(</span><br><span class="line">    conninfo=DB_URI,</span><br><span class="line">    max_size=20,            # 最多 20 条物理连接</span><br><span class="line">    kwargs=connection_kwargs,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 4) 显式打开池（psycopg 3 的 ConnectionPool 默认懒启动，调 open() 会立即建 min_size 条连接）</span><br><span class="line">connection_pool.open()</span><br><span class="line">print(&quot;数据库连接池初始化成功&quot;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>正常情况每次 SQL 都新建一条 TCP 连接、做 SSL
握手、验证密码、分配内存，如果不复用连接，这些动作就要
<strong>每次都重新来一遍</strong>，<strong>成本非常高</strong>。</p>
<p>连接池（Connection Pool）是一种
<strong>数据库访问层资源管理组件</strong>，其核心目标是在
<strong>高并发、短事务</strong> 场景下，通过
<strong>复用已建立的数据库物理连接</strong>
来降低系统整体延迟、减少资源消耗，并防止数据库因瞬时连接风暴而崩溃。</p>
</blockquote>
<h4 id="初始化pgsql">初始化pgsql</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 初始化PostgresStore</span><br><span class="line">in_postgres_store = PostgresStore(</span><br><span class="line">    pool,</span><br><span class="line">    index=&#123;</span><br><span class="line">        &quot;dims&quot;: 1536,</span><br><span class="line">        &quot;embed&quot;: embedding</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line">in_postgres_store.setup()</span><br><span class="line"></span><br><span class="line">#初始化checkpoint</span><br><span class="line"># 使用传入的连接池创建 PostgresSaver</span><br><span class="line">checkpointer = PostgresSaver(pool)</span><br><span class="line">checkpointer.setup()</span><br><span class="line"></span><br><span class="line">#最后编译时添加</span><br><span class="line">graph_builder.compile(checkpointer=checkpointer, store=in_postgres_store)</span><br></pre></td></tr></table></figure>
<p><code>in_postgres_store.setup()</code> 的角色一句话就能说清：</p>
<blockquote>
<p><strong>把数据库里所有为了让向量存储正常工作的“一次性基建”全部建好</strong>——只建一次，后面再跑就不会重复执行。</p>
</blockquote>
<p>具体而言，它通常干下面三件事：1.<strong>建表 /
建扩展</strong>；2.<strong>建向量索引</strong>；3.<strong>元数据初始化</strong></p>
<h4 id="fastapi实现生命周期的管理">fastapi实现生命周期的管理</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 定义了一个异步函数lifespan，它接收一个FastAPI应用实例app作为参数。这个函数将管理应用的生命周期，包括启动和关闭时的操作</span><br><span class="line"># 函数在应用启动时执行一些初始化操作，如加载上下文数据、以及初始化问题生成器</span><br><span class="line"># 函数在应用关闭时执行一些清理操作</span><br><span class="line"># @asynccontextmanager 装饰器用于创建一个异步上下文管理器，它允许你在 yield 之前和之后执行特定的代码块，分别表示启动和关闭时的操作</span><br><span class="line">@asynccontextmanager</span><br><span class="line">async def lifespan(app: FastAPI):</span><br><span class="line">    # 启动时执行</span><br><span class="line">    # 申明引用全局变量，在函数中被初始化，并在整个应用中使用</span><br><span class="line">    global graph, connection_pool</span><br><span class="line">    # 启动时执行</span><br><span class="line">    try:</span><br><span class="line">        logger.info(&quot;正在初始化模型、定义 Graph...&quot;)</span><br><span class="line">        # 初始化 LLM</span><br><span class="line">        llm, embedding = get_llm(llm_type)</span><br><span class="line">        # 创建数据库连接池</span><br><span class="line">        DB_URI = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line">        connection_kwargs = &#123;</span><br><span class="line">            &quot;autocommit&quot;: True,</span><br><span class="line">            &quot;prepare_threshold&quot;: 0,</span><br><span class="line">        &#125;</span><br><span class="line">        connection_pool = ConnectionPool(</span><br><span class="line">            conninfo=DB_URI,</span><br><span class="line">            max_size=20,</span><br><span class="line">            kwargs=connection_kwargs,</span><br><span class="line">        )</span><br><span class="line">        connection_pool.open()  # 显式打开连接池</span><br><span class="line">        logger.info(&quot;数据库连接池初始化成功&quot;)</span><br><span class="line">        # 短期记忆 初始化checkpointer</span><br><span class="line">        checkpointer = PostgresSaver(connection_pool)</span><br><span class="line">        checkpointer.setup()</span><br><span class="line">        # 长期记忆 初始化PostgresStore</span><br><span class="line">        in_postgres_store = PostgresStore(</span><br><span class="line">            connection_pool,</span><br><span class="line">            index=&#123;</span><br><span class="line">                &quot;dims&quot;: 1536,</span><br><span class="line">                &quot;embed&quot;: embedding</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        in_postgres_store.setup()</span><br><span class="line">        # 定义 Graph</span><br><span class="line">        graph = create_graph(llm, checkpointer, in_postgres_store )</span><br><span class="line">        # 保存 Graph 可视化图</span><br><span class="line">        save_graph_visualization(graph)</span><br><span class="line">        logger.info(&quot;初始化完成&quot;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        logger.error(f&quot;初始化过程中出错: &#123;str(e)&#125;&quot;)</span><br><span class="line">        raise</span><br><span class="line"></span><br><span class="line">    yield  # 应用运行期间</span><br><span class="line"></span><br><span class="line">    # 关闭时执行</span><br><span class="line">    logger.info(&quot;正在关闭...&quot;)</span><br><span class="line">    if connection_pool:</span><br><span class="line">        connection_pool.close()  # 关闭连接池</span><br><span class="line">        logger.info(&quot;数据库连接池已关闭&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># lifespan参数用于在应用程序生命周期的开始和结束时执行一些初始化或清理工作</span><br><span class="line">app = FastAPI(lifespan=lifespan)</span><br></pre></td></tr></table></figure>
<h3 id="pgsql的存储结构">pgsql的存储结构</h3>
<h4 id="一checkpoints-系列">一、Checkpoints 系列</h4>
<blockquote>
<p>作用：让 <strong>LangGraph Runtime</strong> 能在
<strong>分布式/长流程</strong> 场景下
<strong>断点续跑、重放、并发控制</strong>。</p>
</blockquote>
<table>
<colgroup>
<col style="width: 15%">
<col style="width: 31%">
<col style="width: 37%">
<col style="width: 16%">
</colgroup>
<thead>
<tr>
<th>表名</th>
<th>存什么</th>
<th>典型字段（示意）</th>
<th>何时写入</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>checkpoints</strong></td>
<td>每个「图实例」的 <strong>最新快照</strong>（state 的完整
JSONB）</td>
<td><code>thread_id</code>, <code>checkpoint_ns</code>,
<code>checkpoint_id</code>, <code>parent_checkpoint_id</code>,
<code>state</code>, <code>created_at</code></td>
<td>每次节点执行成功后覆盖更新</td>
</tr>
<tr>
<td><strong>checkpoint_blobs</strong></td>
<td>checkpoints 里 <strong>大字段的拆分</strong>（避免行过大）</td>
<td><code>thread_id</code>, <code>checkpoint_ns</code>,
<code>channel</code>, <code>type</code>, <code>blob</code></td>
<td>当 state 过大，自动拆分</td>
</tr>
<tr>
<td><strong>checkpoint_migrations</strong></td>
<td>记录 <strong>schema 版本/迁移脚本</strong></td>
<td><code>version</code>, <code>name</code>,
<code>applied_at</code></td>
<td>只在 <code>setup()</code> 时写一次</td>
</tr>
<tr>
<td><strong>checkpoint_writes</strong></td>
<td><strong>写放大日志</strong>（每个节点写 state 的增量 diff）</td>
<td><code>thread_id</code>, <code>checkpoint_id</code>,
<code>task_id</code>, <code>idx</code>, <code>channel</code>,
<code>type</code>, <code>value</code></td>
<td>每次节点完成时追加</td>
</tr>
</tbody>
</table>
<blockquote>
<p>关系：<br>
<code>checkpoints</code> = 最新完整快照<br>
<code>checkpoint_writes</code> = 所有增量历史（用于重放/审计）<br>
<code>checkpoint_blobs</code> = checkpoints 里超大型 value 的切片</p>
</blockquote>
<h4 id="二store-系列">二、Store 系列</h4>
<blockquote>
<p>作用：给 <strong>业务代码（开发者）</strong> 提供 <strong>持久化 KV /
向量存储</strong>，与图运行状态无关。</p>
</blockquote>
<table>
<colgroup>
<col style="width: 12%">
<col style="width: 27%">
<col style="width: 34%">
<col style="width: 25%">
</colgroup>
<thead>
<tr>
<th>表名</th>
<th>存什么</th>
<th>典型字段（示意）</th>
<th>何时写入</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>store</strong></td>
<td><strong>任意 KV 文档</strong>（LangChain Document → JSONB）</td>
<td><code>uuid</code>, <code>namespace</code>, <code>key</code>,
<code>value</code>, <code>created_at</code>,
<code>updated_at</code></td>
<td>你调用 <code>store.amput</code> / <code>amset</code> 等 API</td>
</tr>
<tr>
<td><strong>store_migrations</strong></td>
<td>同 checkpoint_migrations，记录 store schema 版本</td>
<td><code>version</code>, <code>name</code>,
<code>applied_at</code></td>
<td>只在第一次 <code>setup()</code></td>
</tr>
<tr>
<td><strong>store_vectors</strong></td>
<td><strong>向量索引表</strong>（embedding → vector 类型）</td>
<td><code>uuid</code>, <code>collection_id</code>,
<code>embedding</code>, <code>document</code>,
<code>metadata</code></td>
<td>你调用 <code>add_documents(..., embeddings=...)</code></td>
</tr>
<tr>
<td><strong>vector_migrations</strong></td>
<td>记录 pgvector 扩展及索引迁移版本</td>
<td><code>version</code>, <code>applied_at</code></td>
<td><code>setup()</code> 时若第一次装 pgvector</td>
</tr>
</tbody>
</table>
<h4 id="三调用链脑图">三、调用链脑图</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">┌──────────────┐</span><br><span class="line">│ LangGraph    │ 运行图实例</span><br><span class="line">└────┬─────────┘</span><br><span class="line">     │1. 写 checkpoints</span><br><span class="line">     │2. 写 checkpoint_writes</span><br><span class="line">     │3. 拆大字段到 checkpoint_blobs</span><br><span class="line">     ▼</span><br><span class="line">┌──────────────┐</span><br><span class="line">│ 业务代码     │ 读写 KV/向量</span><br><span class="line">└────┬─────────┘</span><br><span class="line">     │1. 写 store</span><br><span class="line">     │2. 写 store_vectors</span><br><span class="line">     ▼</span><br><span class="line"> PostgreSQL (pgsql)</span><br></pre></td></tr></table></figure>
<h3 id="在linux安装postgresql">在linux安装postgresql</h3>
<h4 id="查看linux发行版本">查看linux发行版本</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看发行版名称和版本</span><br><span class="line">cat /etc/os-release</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PRETTY_NAME=&quot;Ubuntu 24.04.2 LTS&quot;</span><br><span class="line">NAME=&quot;Ubuntu&quot;</span><br><span class="line">VERSION_ID=&quot;24.04&quot;</span><br><span class="line">VERSION=&quot;24.04.2 LTS (Noble Numbat)&quot;</span><br><span class="line">VERSION_CODENAME=noble</span><br><span class="line">ID=ubuntu</span><br><span class="line">ID_LIKE=debian</span><br><span class="line">HOME_URL=&quot;https://www.ubuntu.com/&quot;</span><br><span class="line">SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;</span><br><span class="line">PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;</span><br><span class="line">UBUNTU_CODENAME=noble</span><br><span class="line">LOGO=ubuntu-logo</span><br></pre></td></tr></table></figure>
<h4 id="安装postgresql">安装postgresql</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 更新软件包索引</span><br><span class="line">sudo apt update</span><br><span class="line"></span><br><span class="line"># 安装 PostgreSQL 和常用扩展</span><br><span class="line">sudo apt install -y postgresql postgresql-contrib</span><br><span class="line"></span><br><span class="line"># 检查服务状态</span><br><span class="line">#Linux 容器/子系统（ Docker、WSL 或 LXC）没有使用 systemd ，因此 systemctl 无法工作</span><br><span class="line">sudo systemctl status postgresql</span><br><span class="line"></span><br><span class="line">#确认 PostgreSQL 已安装</span><br><span class="line">which psql            # 应该输出 /usr/bin/psql</span><br><span class="line">pg_ctl --version      # 显示版本号即已安装</span><br></pre></td></tr></table></figure>
<ul>
<li><code>postgresql</code> 是主程序</li>
<li><code>postgresql-contrib</code> 提供额外扩展（如
<code>uuid-ossp</code>、<code>pgcrypto</code> 等）</li>
</ul>
<blockquote>
<p>systemctl一般用于服务器上，完整的linux系统上</p>
<p>Linux 容器/子系统（ Docker、WSL 或 LXC）使用 service</p>
</blockquote>
<h4 id="pgsql常用指令">pgsql常用指令</h4>
<p>启动pgsql服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service postgresql start</span><br></pre></td></tr></table></figure>
<p>停止pgsql服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service postgresql stop</span><br></pre></td></tr></table></figure>
<p>查看状态</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service postgresql status</span><br></pre></td></tr></table></figure>
<p>连接PostgreSQL 默认的系统用户，可以执行pgsql的相关指令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo -u postgres psql</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>psql</strong>为PostgreSQL
的终端客户端，默认会连接与当前操作系统用户名同名的数据库用户和数据库。</p>
<p><strong>postgres</strong>为PostgreSQL
自带的系统数据库，<code>postgres</code> 默认
<strong>数据库密码为空</strong>，可以通过以下指令进行设置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 设置postgres用户密码</span><br><span class="line">ALTER USER postgres PASSWORD &#x27;postgres&#x27;;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>数据库关于user的作用</p>
<p>数据库里的“用户”是 PostgreSQL
<strong>内部用来做“访问控制”的一把钥匙</strong>。一句话：<strong>“谁能连哪个库、谁能读哪张表、谁能改哪些行”——全靠这些数据库用户（角色）来判定。</strong></p>
<table>
<colgroup>
<col style="width: 32%">
<col style="width: 67%">
</colgroup>
<thead>
<tr>
<th>作用</th>
<th>举例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1. 认证</strong>（Authentication）</td>
<td>告诉 PostgreSQL “我连库时提供的用户名+密码是否合法”。</td>
</tr>
<tr>
<td><strong>2. 授权</strong>（Authorization）</td>
<td>决定
“这个用户连进来后，对哪些库、哪些表、哪些行有何种权限（SELECT/INSERT/UPDATE/DELETE…）”。</td>
</tr>
<tr>
<td><strong>3. 资源隔离</strong>（Isolation）</td>
<td>不同业务/团队用不同用户，方便审计、限流、回收权限，互不干扰。</td>
</tr>
</tbody>
</table>
<p>pgsql通用 URL 模板</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">postgresql://&lt;用户名&gt;:&lt;密码&gt;@127.0.0.1:5432/&lt;数据库名&gt;[?参数=值&amp;...]</span><br></pre></td></tr></table></figure>
<h4 id="连接pgsql-1">连接pgsql</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 基于数据库持久化存储的short-term</span><br><span class="line">db_uri = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line"></span><br><span class="line"># short-term短期记忆 实例化PostgresSaver对象 并初始化checkpointer</span><br><span class="line"># long-term长期记忆 实例化PostgresStore对象 并初始化store</span><br><span class="line">async with (</span><br><span class="line">    AsyncPostgresSaver.from_conn_string(db_uri) as checkpointer,</span><br><span class="line">    AsyncPostgresStore.from_conn_string(db_uri) as store</span><br><span class="line"></span><br><span class="line">):</span><br><span class="line">    await store.setup()</span><br><span class="line">    await checkpointer.setup()</span><br></pre></td></tr></table></figure>
<h3 id="更换apt镜像源">更换apt镜像源</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/apt/sources.list &lt;&lt;&#x27;EOF&#x27;</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm-updates main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm-backports main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian-security bookworm-security main contrib non-free</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">apt update</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://juejin.cn/post/7470702616906645540">postgresql向量扩展pgvector的安装与入门本文简答的介绍了
rag 的架构，引申出向量数据库的作用，介绍了 - 掘金</a></p>
<p>langchain支持向量存储<a href="https://python.langchain.com/docs/integrations/vectorstores/">向量存储
| 🦜️🔗 LangChain — Vector stores | 🦜️🔗 LangChain</a></p>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>langgraph</tag>
        <tag>pgsql</tag>
      </tags>
  </entry>
  <entry>
    <title>redis存储状态</title>
    <url>/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/</url>
    <content><![CDATA[<h3 id="为什么用redis">为什么用redis</h3>
<p>Redis通过 RedisSessionManager 类来管理用户会话，存储结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">session:&#123;user_id&#125; -&gt; &#123;</span><br><span class="line">  &quot;session_id&quot;: &quot;会话ID&quot;,</span><br><span class="line">  &quot;status&quot;: &quot;idle|running|interrupted|completed|error&quot;,</span><br><span class="line">  &quot;last_response&quot;: &quot;上次智能体响应&quot;,</span><br><span class="line">  &quot;last_query&quot;: &quot;用户上次查询&quot;,</span><br><span class="line">  &quot;last_updated&quot;: &quot;最后更新时间戳&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/image-20250809232853613.png" alt="image-20250809232853613">
<figcaption aria-hidden="true">image-20250809232853613</figcaption>
</figure>
<p>主要功能</p>
<ul>
<li>会话创建与维护 ：为每个用户创建唯一会话，支持会话超时自动清理</li>
<li>状态跟踪
：实时跟踪智能体执行状态（空闲、运行中、中断、完成、错误）</li>
<li>中断恢复支持
：当智能体需要人工干预时，Redis保存中断状态，支持后续恢复执行</li>
<li>用户管理 ：统计活跃用户数量，管理多用户并发访问</li>
</ul>
<p>与PostgreSQL的分工</p>
<ul>
<li>Redis ：负责临时会话状态和实时数据（快速读写）</li>
<li>PostgreSQL
：负责智能体的长期记忆存储（通过LangGraph的checkpointer）</li>
</ul>
<blockquote>
<p>为什么不使用pgsql完成对状态的存储</p>
<p>频繁读写
：会话状态需要频繁更新（每次请求都要更新状态），PostgreSQL的磁盘I/O比Redis内存操作慢很多4</p>
<p>短期记忆（PostgreSQL + LangGraph Checkpointer）</p>
<p>临时状态记忆（Redis）</p>
</blockquote>
<h3 id="redis实现状态存储业务逻辑总览图">redis实现状态存储业务逻辑总览图</h3>
<figure>
<img src="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/image-20250806164348663.png" alt="image-20250806164348663">
<figcaption aria-hidden="true">image-20250806164348663</figcaption>
</figure>
<p>使用redis的根本逻辑：存储对话的状态，当出现由工具调用或者客户端崩溃导致的中断时，可以存储状态在redis，在开始对话时，通过session_id获取redis的状态，并根据状态判断是要恢复中断还是正常对话</p>
<p>存储的redis（调用invoke_agent接口）：开始（创建）对话时要根据会话user_id获取或创建redis；再调用agent后，根据响应是否存在<strong>status</strong>字段是否是”<strong>interrupt</strong>”，判断是否有终端，最后更新redis状态</p>
<p>恢复的redis（调用resume_agent接口）：获取redis状态，并根据请求的恢复内容，使用Command命令恢复agent，最后更新redis</p>
<figure>
<img src="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/image-20250809233037563.png" alt="image-20250809233037563">
<figcaption aria-hidden="true">image-20250809233037563</figcaption>
</figure>
<h3 id="redis类">redis类</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 初始化异步 Redis 连接和会话配置</span><br><span class="line">def __init__(self, redis_host, redis_port, redis_db, session_timeout):</span><br><span class="line">    self.redis_client = redis.Redis(</span><br><span class="line">        host=redis_host,</span><br><span class="line">        port=redis_port,</span><br><span class="line">        db=redis_db,</span><br><span class="line">        decode_responses=True</span><br><span class="line">    )</span><br><span class="line">    self.session_timeout = session_timeout  # 会话过期时间（秒）</span><br><span class="line"></span><br><span class="line"># 关闭 Redis 连接</span><br><span class="line">async def close(self):</span><br><span class="line">    await self.redis_client.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 16%">
<col style="width: 27%">
<col style="width: 19%">
<col style="width: 27%">
</colgroup>
<thead>
<tr>
<th>方法名</th>
<th>作用</th>
<th>输入参数</th>
<th>返回值</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__init__</code></td>
<td>建立与 Redis 的异步连接并设置会话超时</td>
<td><code>redis_host</code>, <code>redis_port</code>,
<code>redis_db</code>, <code>session_timeout</code></td>
<td>-</td>
<td><code>decode_responses=True</code> 使 Redis 返回字符串而非字节</td>
</tr>
<tr>
<td><code>close</code></td>
<td>优雅关闭 Redis 连接</td>
<td>-</td>
<td>-</td>
<td>异步方法，需 <code>await</code></td>
</tr>
<tr>
<td><code>create_session</code></td>
<td>为指定用户新建（或覆盖）会话记录</td>
<td><code>user_id</code>, 可选 <code>session_id</code>,
<code>status</code>, <code>last_query</code>,
<code>last_response</code>, <code>last_updated</code></td>
<td><code>str</code>：生成的 <code>session_id</code></td>
<td>会话键格式：<code>session:&#123;user_id&#125;</code>；过期时间为
<code>session_timeout</code></td>
</tr>
<tr>
<td><code>get_session</code></td>
<td>读取指定用户的完整会话字典</td>
<td><code>user_id</code></td>
<td><code>dict</code> 或 <code>None</code></td>
<td>自动将 JSON 里的 <code>last_response</code> 反序列化为
<code>AgentResponse</code> 对象</td>
</tr>
<tr>
<td><code>update_session</code></td>
<td>增量更新已有会话的字段</td>
<td><code>user_id</code>, 可选 <code>status</code>,
<code>last_query</code>, <code>last_response</code>,
<code>last_updated</code></td>
<td><code>bool</code>：<code>True</code> 更新成功，<code>False</code>
用户不存在</td>
<td>更新后刷新过期时间</td>
</tr>
<tr>
<td><code>delete_session</code></td>
<td>删除单个用户的会话</td>
<td><code>user_id</code></td>
<td><code>bool</code>：<code>True</code> 删除成功</td>
<td>直接删除 <code>session:&#123;user_id&#125;</code></td>
</tr>
<tr>
<td><code>get_session_count</code></td>
<td>计算当前活跃会话总数</td>
<td>-</td>
<td><code>int</code></td>
<td>使用异步扫描 <code>session:*</code> 键空间</td>
</tr>
<tr>
<td><code>get_all_user_ids</code></td>
<td>取出所有已创建会话的 <code>user_id</code></td>
<td>-</td>
<td><code>List[str]</code></td>
<td>同样基于 <code>session:*</code> 扫描</td>
</tr>
<tr>
<td><code>user_id_exists</code></td>
<td>快速判断某用户是否已有会话</td>
<td><code>user_id</code></td>
<td><code>bool</code></td>
<td>利用 <code>EXISTS</code> 命令</td>
</tr>
</tbody>
</table>
<h3 id="安装redis">安装redis</h3>
<h4 id="linux系统">linux系统</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y redis-server</span><br><span class="line"># 启动 Redis 服务</span><br><span class="line">sudo service redis-server start</span><br><span class="line"># 检查 Redis 服务状态</span><br><span class="line">sudo service redis-server status</span><br></pre></td></tr></table></figure>
<h4 id="docker">docker</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Docker Compose 配置文件，用于启动 Redis 服务</span><br><span class="line"># 该配置为 FastAPI 应用提供 Redis 后端，支持分布式会话管理</span><br><span class="line">version: &#x27;3.8&#x27;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  redis:</span><br><span class="line">    # 使用官方 Redis 镜像</span><br><span class="line">    image: redis:latest</span><br><span class="line">    # 服务名称</span><br><span class="line">    container_name: redis</span><br><span class="line">    # 映射 Redis 默认端口到主机</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;6379:6379&quot;</span><br><span class="line">    # 持久化存储配置（可选）</span><br><span class="line">    volumes:</span><br><span class="line">      - redis-data:/data</span><br><span class="line">    # 确保容器在重启时自动启动</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    # 健康检查：验证 Redis 服务是否正常运行</span><br><span class="line">    healthcheck:</span><br><span class="line">      test: [&quot;CMD&quot;, &quot;redis-cli&quot;, &quot;ping&quot;]</span><br><span class="line">      interval: 30s</span><br><span class="line">      timeout: 10s</span><br><span class="line">      retries: 3</span><br><span class="line">      start_period: 10s</span><br><span class="line">    # 网络配置</span><br><span class="line">    networks:</span><br><span class="line">      - app-network</span><br><span class="line"></span><br><span class="line"># 定义持久化存储卷</span><br><span class="line">volumes:</span><br><span class="line">  redis-data:</span><br><span class="line">    name: redis-data</span><br><span class="line"></span><br><span class="line"># 定义网络</span><br><span class="line">networks:</span><br><span class="line">  app-network:</span><br><span class="line">    driver: bridge</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d  --name redis -p 6379:6379  -v redis-data:/data redis:latest</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>langgraph</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>deepresearch实战</title>
    <url>/2025/08/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/deepresearch/</url>
    <content><![CDATA[<h3 id="理解deepresearch">理解deepresearch</h3>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV1aXg5zzExm?buvid=XX7932A7E9DD8A1DA92D4974AB535749A9B44&amp;from_spmid=tm.recommend.0.0&amp;is_story_h5=false&amp;mid=25yhOI1fPeVYa5V16BFcAw%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=aec53502-2411-4bc1-8ccf-ce85bd6efc1e&amp;share_source=QQ&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1753142992&amp;unique_k=tZcFKrS&amp;up_id=28357052&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">🦜🕸️
Open Deep Research V2：新架构！上下文工程最新实践
📋_哔哩哔哩_bilibili</a></p>
<p><a href="https://academy.langchain.com/courses/take/deep-research-with-langgraph/lessons/67513388-course-overview">Project:
Deep Research with LangGraph - LangChain Academy</a></p>
<p><a href="https://github.com/langchain-ai/open_deep_research">langchain-ai/open_deep_research
— langchain-ai/open_deep_research</a></p>
<p>官方博文<a href="https://blog.langchain.com/open-deep-research/">开启深度研究 —
Open Deep Research</a></p>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>langgraph</tag>
      </tags>
  </entry>
  <entry>
    <title>A2A协议</title>
    <url>/2025/08/14/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/A2A%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>就是client调用agent那一块，感觉还是比较困惑，我看例子是要通过定义给的execut和cancel函数，那就意味着agent提供者都要去自己去定义这些怎么执行的函数，还有描述agent的skill和card，工作量明显比mcp大了很多，可能这也是现在a2a传播没有mcp好的一大原因吧，我的理解，不知道对不对</p>
<hr>
<p>思考：现在利用a2a搭建多agent的现实例子多吗，从概念上，我认为a2a的思路是没问题的，但感觉下来，现在大多数的多agent的实现方式还是像langgraph中<strong>条件边</strong>来控制使用哪个agent，是不是因为a2a对于中小开发者搭建起来还是有些复杂，但我还是认为他这种于mcp类似，模块化，可以自定义的形式会是后续方向。就像现在的mcp
client，可以在市场上下载自己想要的mcp，利用a2a协议，用户可以在市场上下载想用的agent，搭建自己的多agent管家，现在市场上有类似的产品吗？</p>
<p>a2a协议其实与mcp类似，对象不同，一个是mcp client与mcp
server（tool），一个是agent client与agent
server。具体实现中，需要完成对agent
server的信息暴露与executor的编写，以便让client正确调用agent，调用前要启动服务。</p>
<p>一个agent
server所要包含的要素包括：1.AgentSkill，用于描述agent可以实现的能力</p>
<p>2.AgentCard，描述agent的信息，包括运行的url，输入和返回的数据类型，所包含的skills</p>
<p>3.AgentExecutor，定义了如何执行智能体，通过定义execute方法，以便正确调用agent
server</p>
<p>4.通过DefaultRequestHandler，封装调用agent的接口，不用再手写接口，只要提供一个
executor 和一个 store
即可，收到对话内容后，<code>DefaultRequestHandler</code>
会把对话打包成任务，交给 <code>HelloWorldAgentExecutor</code>
去执行。、</p>
<p>5.通过A2AStarletteApplication打包成应用（如fastapi），他的作用如下：1.把这个
handler 注册成真正的 HTTP 路由，于是外部就能通过 <code>POST /</code>
调用上述 JSON-RPC 方法。2.对外暴露名片</p>
<h3 id="什么是a2a协议">什么是A2A协议</h3>
<p>A2A 协议（Agent2Agent Protocol，智能体间通信协议）是 Google 在 2025
年 4 月发布并开源的首个 AI
智能体交互标准。它通过统一的通信规范，解决不同团队、不同框架、不同供应商开发的
AI 智能体如何“对话”和协同工作的问题。</p>
<blockquote>
<p>与mcp区分，<strong>MCP</strong> 解决
<strong>“单个智能体如何调用外部工具/数据”</strong>
的问题，而<strong>A2A</strong> 解决
<strong>“多个智能体如何协同完成任务”</strong> 的问题。</p>
</blockquote>
<figure>
<img src="/2025/08/14/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/A2A%E5%8D%8F%E8%AE%AE/image-20250809222720192.png" alt="image-20250809222720192">
<figcaption aria-hidden="true">image-20250809222720192</figcaption>
</figure>
<h3 id="为什么要使用a2a协议">为什么要使用A2A协议</h3>
<p>随着 AI 应用深化，单一“万能”模型难以兼顾所有领域。A2A
鼓励构建“小而专”的智能体生态：</p>
<ul>
<li>每个智能体专注一个领域（如订票、报税、图像处理）。</li>
<li>通过 A2A
协议，它们像乐高积木一样自由组合，快速响应新的业务需求。</li>
</ul>
<p>比如你让一个agent使用多个工具，不仅会浪费tokens，也会降低其调用工具的准确性。所有，专业的领域使用专业的agent，而agent间的通信便要依靠A2A协议</p>
<h3 id="环境配置">环境配置</h3>
<p><strong>克隆仓库</strong></p>
<p>如果你还没有克隆，请克隆 A2A Samples 仓库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/a2aproject/a2a-samples.git -b main --depth 1</span><br><span class="line">cd a2a-samples</span><br></pre></td></tr></table></figure>
<p><strong>Python 环境和 SDK 安装</strong></p>
<p>我们推荐为 Python 项目使用虚拟环境。A2A Python SDK 使用
<code>uv</code> 进行依赖管理，但你也可以使用 <code>pip</code> 与
<code>venv</code>。</p>
<ol type="1">
<li><p><strong>创建并激活虚拟环境：</strong></p>
<p>使用 <code>venv</code>（标准库）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m venv .venv</span><br><span class="line">source .venv/bin/activate</span><br></pre></td></tr></table></figure></li>
<li><p><strong>安装所需的 Python 依赖项以及 A2A SDK
及其依赖项：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -r samples/python/requirements.txt</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="agent-skills-agent-card">Agent Skills &amp; Agent Card</h3>
<h4 id="agent-skills">Agent Skills</h4>
<p>一个<strong>代理技能</strong>描述了代理可以执行的具体能力或功能。它是告诉客户端代理擅长哪些任务的构建模块。</p>
<p><code>AgentSkill</code> 的关键属性（定义在 <code>a2a.types</code>
中）：</p>
<ul>
<li><code>id</code>: 技能的唯一标识符。</li>
<li><code>name</code>: 人类可读的名称。</li>
<li><code>description</code>：对技能功能的更详细说明。</li>
<li><code>tags</code>：用于分类和发现的关键词。</li>
<li><code>examples</code>：示例提示或使用案例。</li>
<li><code>inputModes</code> / <code>outputModes</code>:
支持的输入和输出媒体类型（例如，“text/plain”，“application/json”）。</li>
</ul>
<p>在 <code>__main__.py</code> 中，你可以看到如何为 Helloworld
代理定义一个技能：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">skill = AgentSkill(</span><br><span class="line">    id=&#x27;hello_world&#x27;,</span><br><span class="line">    name=&#x27;Returns hello world&#x27;,</span><br><span class="line">    description=&#x27;just returns hello world&#x27;,</span><br><span class="line">    tags=[&#x27;hello world&#x27;],</span><br><span class="line">    examples=[&#x27;hi&#x27;, &#x27;hello world&#x27;],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这个技能非常简单：它的名称是 “Returns hello
world”，并且主要处理文本。</p>
<h4 id="agent-card">Agent Card</h4>
<p><strong>代理卡</strong>是一个 A2A 服务器提供的 JSON 文档，通常位于
<code>.well-known/agent-card.json</code>
端点。它就像代理的数字名片。</p>
<p><code>AgentCard</code> 的关键属性（定义在 <code>a2a.types</code>
中）：</p>
<ul>
<li><code>name</code>, <code>description</code>, <code>version</code>:
基本身份信息。</li>
<li><code>url</code>：A2A 服务可访问的端点。</li>
<li><code>capabilities</code>：指定支持的 A2A 功能，如
<code>streaming</code> 或 <code>pushNotifications</code>。</li>
<li><code>defaultInputModes</code> / <code>defaultOutputModes</code>:
代理的默认媒体类型。</li>
<li><code>skills</code>: 代理提供的 <code>AgentSkill</code>
对象列表。</li>
</ul>
<p><code>helloworld</code> 示例定义其 Agent Card 如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># This will be the public-facing agent card</span><br><span class="line">public_agent_card = AgentCard(</span><br><span class="line">    name=&#x27;Hello World Agent&#x27;,</span><br><span class="line">    description=&#x27;Just a hello world agent&#x27;,</span><br><span class="line">    url=&#x27;http://localhost:9999/&#x27;,</span><br><span class="line">    version=&#x27;1.0.0&#x27;,</span><br><span class="line"> 	# 默认输入模式：Agent 能够接收的输入类型列表，这里仅支持纯文本</span><br><span class="line">    default_input_modes=[&#x27;text&#x27;],</span><br><span class="line">    # 默认输出模式：Agent 能够产生的输出类型列表，这里仅返回纯文本</span><br><span class="line">    default_output_modes=[&#x27;text&#x27;],</span><br><span class="line">    # 能力声明：告知调用方 Agent 支持的能力，例如是否支持流式输出（streaming）</span><br><span class="line">    capabilities=AgentCapabilities(streaming=True),</span><br><span class="line">    skills=[skill],  # Only the basic skill for the public card</span><br><span class="line">    supports_authenticated_extended_card=True,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这张卡片告诉我们代理名为 “Hello World Agent”，运行在
<code>http://localhost:9999/</code>，支持文本交互，并具有
<code>hello_world</code>
技能。它还表明支持公开认证，意味着无需特定凭证。</p>
<h3 id="agent-executor">Agent Executor</h3>
<p>A2A 代理处理请求和生成响应/事件的核心逻辑由一个 <strong>Agent
Executor</strong> 负责。A2A Python SDK 提供了一个抽象基类
<code>a2a.server.agent_execution.AgentExecutor</code> 供你实现。</p>
<p><strong><code>AgentExecutor</code> 接口</strong></p>
<p><code>AgentExecutor</code> 类定义了两个主要方法：</p>
<ul>
<li><code>async def execute(self, context: RequestContext, event_queue: EventQueue)</code>
: 处理期望响应或事件流的传入请求。它处理用户输入（可通过
<code>context</code> 获取）并使用 <code>event_queue</code> 发送
<code>Message</code>、<code>Task</code>、<code>TaskStatusUpdateEvent</code>
或 <code>TaskArtifactUpdateEvent</code> 对象。</li>
<li><code>async def cancel(self, context: RequestContext, event_queue: EventQueue)</code>
: 处理取消正在进行的任务的请求。</li>
</ul>
<p><code>RequestContext</code>
提供有关传入请求的信息，例如用户消息和任何现有的任务详情。<code>EventQueue</code>
由执行器使用，用于将事件发送回客户端。</p>
<p><strong>Helloworld AgentExecutor</strong></p>
<p>让我们看看 <code>agent_executor.py</code>。它定义了
<code>HelloWorldAgentExecutor</code>。</p>
<ol type="1">
<li><p><strong>代理（<code>HelloWorldAgent</code>）</strong>：这是一个简单的辅助类，封装了实际的“业务逻辑”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class HelloWorldAgent:</span><br><span class="line">    &quot;&quot;&quot;Hello World Agent.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    async def invoke(self) -&gt; str:</span><br><span class="line">        return &#x27;Hello World&#x27;</span><br></pre></td></tr></table></figure>
<p>它有一个简单的 <code>invoke</code> 方法，返回字符串”Hello
World”。</p></li>
<li><p><strong>执行器（<code>HelloWorldAgentExecutor</code>）</strong>：这个类实现了
<code>AgentExecutor</code> 接口。</p>
<ul>
<li><p><strong><code>__init__</code></strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class HelloWorldAgentExecutor(AgentExecutor):</span><br><span class="line">    &quot;&quot;&quot;Test AgentProxy Implementation.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.agent = HelloWorldAgent()</span><br></pre></td></tr></table></figure>
<p>它实例化了 <code>HelloWorldAgent</code>。</p></li>
<li><p><strong><code>execute</code></strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def execute(</span><br><span class="line">    self,</span><br><span class="line">    context: RequestContext,</span><br><span class="line">    event_queue: EventQueue,</span><br><span class="line">) -&gt; None:</span><br><span class="line">    result = await self.agent.invoke()</span><br><span class="line">    await event_queue.enqueue_event(new_agent_text_message(result))</span><br></pre></td></tr></table></figure>
<p>当收到一个 <code>message/send</code> 或 <code>message/stream</code>
请求时（这两种请求在这个简化的执行器中均由 <code>execute</code>
处理）：</p>
<ol type="1">
<li>它调用 <code>self.agent.invoke()</code> 来获取 “Hello World”
字符串。</li>
<li>它使用 <code>new_agent_text_message</code> 工具函数创建一个 A2A
<code>Message</code> 对象。</li>
<li>它将此消息入队到 <code>event_queue</code>。底层的
<code>DefaultRequestHandler</code>
随后会处理这个队列以向客户端发送响应。对于像这样的一条消息，在流关闭之前，它将导致一个
<code>message/send</code> 的单一响应或一个 <code>message/stream</code>
的单一事件。</li>
</ol></li>
<li><p><strong><code>cancel</code></strong>: Helloworld 示例的
<code>cancel</code>
方法简单地抛出一个异常，表明这个基本代理不支持取消操作。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def cancel(</span><br><span class="line">    self, context: RequestContext, event_queue: EventQueue</span><br><span class="line">) -&gt; None:</span><br><span class="line">    raise Exception(&#x27;cancel not supported&#x27;)</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ol>
<p><code>AgentExecutor</code> 充当 A2A
协议（由请求处理器和服务器应用程序管理）与您的代理特定逻辑之间的桥梁。它接收关于请求的上下文信息，并使用事件队列来通信结果或更新。</p>
<h3 id="启动server">启动server</h3>
<p>现在我们已经有了 Agent Card 和 Agent Executor，可以设置并启动 A2A
服务器。</p>
<p>A2A Python SDK 提供了一个 <code>A2AStarletteApplication</code>
类，简化了运行符合 A2A 标准的 HTTP 服务器。它使用 <a href="https://www.starlette.io/">Starlette</a> 作为 Web 框架，通常与 <a href="https://www.uvicorn.org/">Uvicorn</a> 等 ASGI 服务器一起运行。</p>
<p>让我们再次查看
<code>__main__.py</code>，看看服务器是如何初始化和启动的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import uvicorn</span><br><span class="line"></span><br><span class="line">from a2a.server.apps import A2AStarletteApplication</span><br><span class="line">from a2a.server.request_handlers import DefaultRequestHandler</span><br><span class="line">from a2a.server.tasks import InMemoryTaskStore</span><br><span class="line">from a2a.types import (</span><br><span class="line">    AgentCapabilities,</span><br><span class="line">    AgentCard,</span><br><span class="line">    AgentSkill,</span><br><span class="line">)</span><br><span class="line">from agent_executor import (</span><br><span class="line">    HelloWorldAgentExecutor,  # type: ignore[import-untyped]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    skill = AgentSkill(</span><br><span class="line">        id=&#x27;hello_world&#x27;,</span><br><span class="line">        name=&#x27;返回 hello world&#x27;,</span><br><span class="line">        description=&#x27;简单地返回 hello world&#x27;,</span><br><span class="line">        tags=[&#x27;hello world&#x27;],</span><br><span class="line">        examples=[&#x27;hi&#x27;, &#x27;hello world&#x27;],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    extended_skill = AgentSkill(</span><br><span class="line">        id=&#x27;super_hello_world&#x27;,</span><br><span class="line">        name=&#x27;返回 SUPER Hello World&#x27;,</span><br><span class="line">        description=&#x27;仅限已认证用户使用的更热情的问候。&#x27;,</span><br><span class="line">        tags=[&#x27;hello world&#x27;, &#x27;super&#x27;, &#x27;extended&#x27;],</span><br><span class="line">        examples=[&#x27;super hi&#x27;, &#x27;give me a super hello&#x27;],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 这是面向公众的 Agent 卡片</span><br><span class="line">    public_agent_card = AgentCard(</span><br><span class="line">        name=&#x27;Hello World Agent&#x27;,</span><br><span class="line">        description=&#x27;只是一个 hello world 代理&#x27;,</span><br><span class="line">        url=&#x27;http://localhost:9999/&#x27;,</span><br><span class="line">        version=&#x27;1.0.0&#x27;,</span><br><span class="line">        default_input_modes=[&#x27;text&#x27;],</span><br><span class="line">        default_output_modes=[&#x27;text&#x27;],</span><br><span class="line">        capabilities=AgentCapabilities(streaming=True),</span><br><span class="line">        skills=[skill],  # 公开卡片仅包含基础技能</span><br><span class="line">        supports_authenticated_extended_card=True,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 这是已认证用户的扩展 Agent 卡片</span><br><span class="line">    # 额外包含 &#x27;extended_skill&#x27;</span><br><span class="line">    specific_extended_agent_card = public_agent_card.model_copy(</span><br><span class="line">        update=&#123;</span><br><span class="line">            &#x27;name&#x27;: &#x27;Hello World Agent - Extended Edition&#x27;,  # 使用不同名称以便区分</span><br><span class="line">            &#x27;description&#x27;: &#x27;面向已认证用户的完整功能 hello world 代理。&#x27;,</span><br><span class="line">            &#x27;version&#x27;: &#x27;1.0.1&#x27;,  # 甚至可以是不同的版本</span><br><span class="line">            # capabilities 及其他字段（如 url、default_input_modes、default_output_modes、</span><br><span class="line">            # supports_authenticated_extended_card）均从 public_agent_card 继承，</span><br><span class="line">            # 除非在此处另行指定。</span><br><span class="line">            &#x27;skills&#x27;: [</span><br><span class="line">                skill,</span><br><span class="line">                extended_skill,</span><br><span class="line">            ],  # 扩展卡片包含两个技能</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    request_handler = DefaultRequestHandler(</span><br><span class="line">        agent_executor=HelloWorldAgentExecutor(),</span><br><span class="line">        task_store=InMemoryTaskStore(),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    server = A2AStarletteApplication(</span><br><span class="line">        agent_card=public_agent_card,</span><br><span class="line">        http_handler=request_handler,</span><br><span class="line">        extended_agent_card=specific_extended_agent_card,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 使用 uvicorn 启动服务，监听 0.0.0.0:9999</span><br><span class="line">    uvicorn.run(server.build(), host=&#x27;0.0.0.0&#x27;, port=9999)</span><br></pre></td></tr></table></figure>
<p>我们来分解一下：</p>
<ol type="1">
<li><strong><code>DefaultRequestHandler</code></strong>:
<ul>
<li>SDK 提供了 <code>DefaultRequestHandler</code>。这个处理器接收你的
<code>AgentExecutor</code>
实现（这里，<code>HelloWorldAgentExecutor</code>）和一个
<code>TaskStore</code>（这里，<code>InMemoryTaskStore</code>）。</li>
<li>它将传入的 A2A RPC 调用路由到你的执行器的适当方法上（比如
<code>execute</code> 或 <code>cancel</code>）。</li>
<li><code>TaskStore</code> 被 <code>DefaultRequestHandler</code>
用来管理任务的生命周期，特别是对于有状态交互、流式传输和重新订阅。即使你的代理执行器很简单，处理器也需要一个任务存储。</li>
</ul></li>
<li><strong><code>A2AStarletteApplication</code></strong>:
<ul>
<li><code>A2AStarletteApplication</code> 类使用 <code>agent_card</code>
和 <code>request_handler</code>（在其构造函数中称为
<code>http_handler</code>）进行实例化。</li>
<li><code>agent_card</code> 至关重要，因为服务器将在
<code>/.well-known/agent-card.json</code>
端点（默认情况下）上公开它。</li>
<li><code>request_handler</code> 负责通过与其 <code>AgentExecutor</code>
交互来处理所有传入的 A2A 方法调用。</li>
</ul></li>
<li><strong><code>uvicorn.run(server_app_builder.build(), ...)</code></strong>:
<ul>
<li><code>A2AStarletteApplication</code> 有一个 <code>build()</code>
方法，用于构建实际的 Starlette 应用程序。</li>
<li>然后使用 <code>uvicorn.run()</code> 运行该应用程序，使您的代理可通过
HTTP 访问。</li>
<li><code>host='0.0.0.0'</code>
使服务器可在您机器上的所有网络接口上访问。</li>
<li><code>port=9999</code> 指定监听的端口。这需要与
<code>AgentCard</code> 中的 <code>url</code> 匹配。</li>
</ul></li>
<li><code>specific_extended_agent_card</code>
<ul>
<li><strong>给同一个 Agent
准备“两张不同权限的名片”</strong>，分别用于“普通访客”和“已认证用户”。、</li>
</ul></li>
</ol>
<h3 id="与服务器交互">与服务器交互</h3>
<p>Helloworld A2A 服务器运行后，让我们向它发送一些请求。SDK
包含一个客户端（<code>A2AClient</code>），可以简化这些交互。</p>
<p>让我们看一下 <code>test_client.py</code> 的关键部分：</p>
<ol type="1">
<li><p><strong>获取代理卡 &amp; 初始化客户端</strong> ：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">base_url = &#x27;http://localhost:9999&#x27;</span><br><span class="line"></span><br><span class="line">async with httpx.AsyncClient() as httpx_client:</span><br><span class="line">    # 初始化 A2ACardResolver</span><br><span class="line">    resolver = A2ACardResolver(</span><br><span class="line">        httpx_client=httpx_client,</span><br><span class="line">        base_url=base_url,</span><br><span class="line">        # agent_card_path 使用默认值，extended_agent_card_path 也使用默认值</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p><code>A2ACardResolver</code> 类是一个便捷工具。它首先从服务器端的
<code>/.well-known/agent-card.json</code> 端点（基于提供的基 URL）获取
<code>AgentCard</code>，然后使用它初始化客户端。</p></li>
<li><p><strong>发送非流式消息 (<code>send_message</code>)</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">client = A2AClient(</span><br><span class="line">    httpx_client=httpx_client, </span><br><span class="line">    agent_card=final_agent_card_to_use#这个card为经过认证处理后暴露的card</span><br><span class="line">)</span><br><span class="line">logger.info(&#x27;A2AClient initialized.&#x27;)</span><br><span class="line"></span><br><span class="line">send_message_payload: dict[str, Any] = &#123;</span><br><span class="line">    &#x27;message&#x27;: &#123;</span><br><span class="line">        &#x27;role&#x27;: &#x27;user&#x27;,</span><br><span class="line">        &#x27;parts&#x27;: [</span><br><span class="line">            &#123;&#x27;kind&#x27;: &#x27;text&#x27;, &#x27;text&#x27;: &#x27;how much is 10 USD in INR?&#x27;&#125;</span><br><span class="line">        ],</span><br><span class="line">        &#x27;messageId&#x27;: uuid4().hex,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br><span class="line">request = SendMessageRequest(</span><br><span class="line">    id=str(uuid4()), params=MessageSendParams(**send_message_payload)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response = await client.send_message(request)</span><br><span class="line">print(response.model_dump(mode=&#x27;json&#x27;, exclude_none=True))</span><br></pre></td></tr></table></figure>
<ul>
<li><code>send_message_payload</code> 构建了
<code>MessageSendParams</code> 的数据。</li>
<li>这些数据被封装在 <code>SendMessageRequest</code> 中。</li>
<li>它包含一个 <code>message</code> 对象，其中 <code>role</code>
设置为”用户”，内容在 <code>parts</code> 中。</li>
<li>Helloworld 代理的 <code>execute</code> 方法将入队一条”Hello
World”消息。<code>DefaultRequestHandler</code>
将获取这条消息并将其作为响应发送。</li>
<li><code>response</code> 将是一个 <code>SendMessageResponse</code>
对象，其中包含 <code>SendMessageSuccessResponse</code>（以代理的
<code>Message</code> 作为结果）或
<code>JSONRPCErrorResponse</code>。</li>
</ul></li>
<li><p><strong>处理任务 ID（Helloworld 的说明性注释）</strong>:</p>
<p>Helloworld 客户端（<code>test_client.py</code>）不会直接尝试
<code>get_task</code> 或 <code>cancel_task</code>，因为简单的 Helloworld
代理的 <code>execute</code> 方法，通过 <code>message/send</code>
调用时，会导致 <code>DefaultRequestHandler</code> 返回一个直接的
<code>Message</code> 响应，而不是 <code>Task</code>
对象。更复杂的、明确管理任务的代理（如 LangGraph 示例）会从
<code>message/send</code> 返回一个 <code>Task</code> 对象，然后其
<code>id</code> 可用于 <code>get_task</code> 或
<code>cancel_task</code>。</p></li>
<li><p><strong>发送流式消息（<code>send_message_streaming</code>）</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">streaming_request = SendStreamingMessageRequest(</span><br><span class="line">    id=str(uuid4()), params=MessageSendParams(**send_message_payload)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">stream_response = client.send_message_streaming(streaming_request)</span><br><span class="line"></span><br><span class="line">async for chunk in stream_response:</span><br><span class="line">    print(chunk.model_dump(mode=&#x27;json&#x27;, exclude_none=True))</span><br></pre></td></tr></table></figure>
<ul>
<li>此方法调用代理的 <code>message/stream</code>
端点。<code>DefaultRequestHandler</code> 将调用
<code>HelloWorldAgentExecutor.execute</code> 方法。</li>
<li><code>execute</code> 方法将一个”Hello
World”消息入队，然后关闭事件队列。</li>
<li>客户端将接收这条单条消息为一个
<code>SendStreamingMessageResponse</code> 事件，然后流将终止。</li>
<li><code>stream_response</code> 是一个
<code>AsyncGenerator</code>。</li>
</ul></li>
</ol>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://github.com/a2aproject/a2a-samples?tab=readme-ov-file">a2aproject/a2a-samples:
Samples using the Agent2Agent (A2A) Protocol</a></p>
<p><a href="https://a2a-protocol.org/latest/">Agent2Agent (A2A)
Protocol</a></p>
<p><a href="https://github.com/a2aproject/a2a-python">a2aproject/a2a-python:
Agent2Agent (A2A) 协议的官方 Python SDK — a2aproject/a2a-python:
Official Python SDK for the Agent2Agent (A2A) Protocol</a></p>
]]></content>
      <categories>
        <category>ai相关</category>
        <category>A2A协议</category>
      </categories>
      <tags>
        <tag>A2A协议</tag>
      </tags>
  </entry>
  <entry>
    <title>Claudeskills</title>
    <url>/2025/12/16/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/claudeskills/</url>
    <content><![CDATA[<h2 id="claudeskills">Claudeskills</h2>
<p>Claudeskills是一组指令、脚本和资源的文件夹，Claude
会动态加载它们以提升在特定任务上的性能。技能教会 Claude
如何以可重复的方式完成特定任务，无论是创建符合公司品牌指南的文档、使用组织特定的流程分析数据，还是自动化个人任务。</p>
<h2 id="skills的结构">skills的结构</h2>
<figure>
<img src="/2025/12/16/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/claudeskills/image-20251217085141312.png" alt="image-20251217085141312">
<figcaption aria-hidden="true">image-20251217085141312</figcaption>
</figure>
<p>最简单来说，一个技能是一个包含
<code>SKILL.md 文件</code>的目录。这个文件必须以 YAML
前文开始，其中包含一些必需的元数据：<code>name</code> 和
<code>description</code>。启动时，智能体会将所有已安装技能的
<code>name</code> 和 <code>description</code> 预加载到系统提示中。</p>
<p>这是<strong>第一级</strong>的<em>渐进式披露</em>元数据：它仅提供足够的信息，让
Claude
知道何时应使用每个技能，而无需将所有内容加载到上下文中。该文件的实际主体是<strong>第二级</strong>的详细程度。如果
Claude 认为该技能与当前任务相关，它将通过读取完整的
<code>SKILL.md</code> 将其加载到上下文中。</p>
<figure>
<img src="/2025/12/16/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/claudeskills/image-20251217090930032.png" alt="image-20251217090930032">
<figcaption aria-hidden="true">image-20251217090930032</figcaption>
</figure>
<p>随着技能复杂性的增加，它们可能包含过多上下文而无法放入单个
<code>SKILL.md</code>
中，或者只有特定场景下才相关的上下文。在这些情况下，技能可以在技能目录中捆绑额外的文件，并通过
<code>SKILL.md</code>
中的名称引用它们。这些额外的链接文件是<strong>第三级</strong>
（以及更高级别）的详细程度，Claude 可以根据需要选择导航和发现。</p>
<p>在下面的 PDF 技能中，<code>SKILL.md</code>
指向了两个额外的文件（<code>reference.md</code> 和
<code>forms.md</code>），这些文件由技能作者选择与核心的
<code>SKILL.md</code>
一起打包。通过将填写表单的说明移至单独的文件（<code>forms.md</code>），技能作者能够保持技能的核心部分简洁，并相信
Claude 只有在填写表单时才会读取 <code>forms.md</code>。</p>
<figure>
<img src="/2025/12/16/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/claudeskills/image-20251217090952141.png" alt="image-20251217090952141">
<figcaption aria-hidden="true">image-20251217090952141</figcaption>
</figure>
<figure>
<img src="/2025/12/16/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/claudeskills/image-20251217091013052.png" alt="image-20251217091013052">
<figcaption aria-hidden="true">image-20251217091013052</figcaption>
</figure>
<h2 id="三种-skill-内容类型三个加载级别">三种 Skill
内容类型，三个加载级别</h2>
<p>Skills 可以包含三种类型的内容，每种在不同时间加载：</p>
<h3 id="第-1-级元数据始终加载">第 1 级：元数据（始终加载）</h3>
<p><strong>内容类型：指令</strong>。Skill 的 YAML
前置数据提供发现信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">name: pdf-processing</span><br><span class="line">description: 从 PDF 文件中提取文本和表格、填充表单、合并文档。在处理 PDF 文件或用户提及 PDF、表单或文档提取时使用。</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>Claude
在启动时加载此元数据并将其包含在系统提示中。这种轻量级方法意味着您可以安装许多
Skills 而不会产生上下文成本；Claude 只知道每个 Skill
的存在以及何时使用它。</p>
<h3 id="第-2-级指令触发时加载">第 2 级：指令（触发时加载）</h3>
<p><strong>内容类型：指令</strong>。SKILL.md
的主体包含程序知识：工作流、最佳实践和指导：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># PDF 处理</span><br><span class="line"></span><br><span class="line">## 快速入门</span><br><span class="line"></span><br><span class="line">使用 pdfplumber 从 PDF 中提取文本：</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">import pdfplumber</span><br><span class="line"></span><br><span class="line">with pdfplumber.open(&quot;document.pdf&quot;) as pdf:</span><br><span class="line">    text = pdf.pages[0].extract_text()</span><br><span class="line">```</span><br><span class="line"></span><br><span class="line">有关高级表单填充，请参阅 [FORMS.md](FORMS.md)。</span><br></pre></td></tr></table></figure>
<p>当您请求与 Skill 描述匹配的内容时，Claude 通过 bash 从文件系统读取
SKILL.md。只有这样，此内容才会进入上下文窗口。</p>
<h3 id="第-3-级资源和代码按需加载">第 3 级：资源和代码（按需加载）</h3>
<p><strong>内容类型：指令、代码和资源</strong>。Skills
可以捆绑其他材料：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pdf-skill/</span><br><span class="line">├── SKILL.md (主要指令)</span><br><span class="line">├── FORMS.md (表单填充指南)</span><br><span class="line">├── REFERENCE.md (详细 API 参考)</span><br><span class="line">└── scripts/</span><br><span class="line">    └── fill_form.py (实用脚本)</span><br></pre></td></tr></table></figure>
<p><strong>指令</strong>：包含专业指导和工作流的其他 markdown
文件（FORMS.md、REFERENCE.md）</p>
<p><strong>代码</strong>：Claude 通过 bash
运行的可执行脚本（fill_form.py、validate.py）；脚本提供确定性操作而不消耗上下文</p>
<p><strong>资源</strong>：参考资料，如数据库架构、API
文档、模板或示例</p>
<p>Claude
仅在引用时访问这些文件。文件系统模型意味着每种内容类型都有不同的优势：指令用于灵活指导，代码用于可靠性，资源用于事实查询。</p>
<table>
<colgroup>
<col style="width: 18%">
<col style="width: 13%">
<col style="width: 22%">
<col style="width: 45%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">级别</th>
<th style="text-align: left;">加载时间</th>
<th style="text-align: left;">令牌成本</th>
<th style="text-align: left;">内容</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>第 1 级：元数据</strong></td>
<td style="text-align: left;">始终（启动时）</td>
<td style="text-align: left;">每个 Skill 约 100 个令牌</td>
<td style="text-align: left;">YAML 前置数据中的 <code>name</code> 和
<code>description</code></td>
</tr>
<tr>
<td style="text-align: left;"><strong>第 2 级：指令</strong></td>
<td style="text-align: left;">触发 Skill 时</td>
<td style="text-align: left;">不到 5k 个令牌</td>
<td style="text-align: left;">包含指令和指导的 SKILL.md 主体</td>
</tr>
<tr>
<td style="text-align: left;"><strong>第 3 级+：资源</strong></td>
<td style="text-align: left;">按需</td>
<td style="text-align: left;">实际上无限制</td>
<td style="text-align: left;">通过 bash
执行的捆绑文件，不将内容加载到上下文中</td>
</tr>
</tbody>
</table>
<p>渐进式披露确保任何给定时间只有相关内容占据上下文窗口。</p>
<h2 id="claudecode使用skills">claudecode使用skills</h2>
<p><a href="https://code.claude.com/docs/zh-CN/skills">Agent Skills -
Claude Code Docs</a></p>
<h3 id="个人-skills">个人 Skills</h3>
<p>个人 Skills 在您的所有项目中都可用。将它们存储在
<code>~/.claude/skills/</code> 中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir -p ~/.claude/skills/my-skill-name</span><br></pre></td></tr></table></figure>
<p><strong>使用个人 Skills 的场景</strong>：</p>
<ul>
<li>您的个人工作流和偏好</li>
<li>您正在开发的实验性 Skills</li>
<li>个人生产力工具</li>
</ul>
<h3 id="项目-skills">项目 Skills</h3>
<p>项目 Skills 与您的团队共享。将它们存储在项目中的
<code>.claude/skills/</code> 中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir -p .claude/skills/my-skill-name</span><br></pre></td></tr></table></figure>
<p><strong>使用项目 Skills 的场景</strong>：</p>
<ul>
<li>团队工作流和约定</li>
<li>项目特定的专业知识</li>
<li>共享的实用程序和脚本</li>
</ul>
<p>项目 Skills 被检入 git 并自动对团队成员可用。</p>
<h2 id="skills示例代码仓库">skills示例代码仓库</h2>
<p><a href="https://github.com/anthropics/skills/tree/main?tab=readme-ov-file">anthropics/skills:
技能公共存储库 — anthropics/skills: Public repository for Skills</a></p>
<p><a href="https://github.com/anthropics/skills/blob/main/skills">./skills</a>:
创意与设计、开发与技术、企业与沟通以及文档技能的示例</p>
<p><a href="https://github.com/anthropics/skills/blob/main/spec">./spec</a>:
Agent Skills 规范</p>
<p><a href="https://github.com/anthropics/skills/blob/main/template">./template</a>:
技能模板</p>
<p>仓库包含以下主要skill类别：</p>
<h3 id="创意与设计类-creative-design">🎨 创意与设计类 (Creative &amp;
Design)</h3>
<ul>
<li><strong>algorithmic-art</strong> - 使用 p5.js
创建生成艺术，支持种子随机性、流场和粒子系统</li>
<li><strong>canvas-design</strong> -
使用设计哲学创建美观的视觉艺术，输出 .png 和 .pdf 格式</li>
<li><strong>slack-gif-creator</strong> - 创建针对 Slack
大小限制优化的动画 GIF</li>
</ul>
<h3 id="开发与技术类-development-technical">💻 开发与技术类 (Development
&amp; Technical)</h3>
<ul>
<li><strong>artifacts-builder</strong> - 使用 React、Tailwind CSS 和
shadcn/ui 组件构建复杂的 claude.ai HTML artifacts</li>
<li><strong>mcp-builder</strong> - 创建高质量 MCP
服务器的指南，用于集成外部 API 和服务</li>
<li><strong>webapp-testing</strong> - 使用 Playwright 测试本地 Web
应用程序，进行 UI 验证和调试</li>
</ul>
<h3 id="企业与沟通类-enterprise-communication">🏢 企业与沟通类
(Enterprise &amp; Communication)</h3>
<ul>
<li><strong>brand-guidelines</strong> - 将 Anthropic
的官方品牌颜色和排版应用到 artifacts</li>
<li><strong>internal-comms</strong> -
编写内部沟通文档，如状态报告、新闻通讯和常见问题解答</li>
<li><strong>theme-factory</strong> - 使用 10 个预设专业主题为 artifacts
设置样式，或即时生成自定义主题</li>
</ul>
<h3 id="元技能类-meta-skills">🛠️ 元技能类 (Meta Skills)</h3>
<ul>
<li><strong>skill-creator</strong> - 创建有效扩展 Claude
能力的技能指南</li>
<li><strong>template-skill</strong> - 用作新技能起点的基础模板</li>
</ul>
<h3 id="文档技能-document-skills">📄 文档技能 (Document Skills)</h3>
<p><code>document-skills/</code> 子目录包含 Anthropic 开发的用于帮助
Claude 创建各种文档文件格式的技能： README.md:45-47</p>
<ul>
<li><strong>docx</strong> - 创建、编辑和分析 Word
文档，支持跟踪更改、注释、格式保留和文本提取 README.md:49</li>
<li><strong>pdf</strong> - 综合 PDF
操作工具包，用于提取文本和表格、创建新 PDF、合并/拆分文档以及处理表单
README.md:50</li>
<li><strong>pptx</strong> - 创建、编辑和分析 PowerPoint
演示文稿，支持布局、模板、图表和自动幻灯片生成 README.md:51</li>
<li><strong>xlsx</strong> - 创建、编辑和分析 Excel
电子表格，支持公式、格式化、数据分析和可视化 README.md:52</li>
</ul>
<h2 id="参考资料">参考资料</h2>
<p><a href="https://www.bilibili.com/video/BV1oSWWzzEeB/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Claude
Agent Skills - 全新的技能包_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV166sTzvEfd?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【手把手教程】开发自己的Claude
Agent Skills_哔哩哔哩_bilibili</a></p>
<p><a href="https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview">Agent
Skills - Claude Docs</a></p>
<p><a href="https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills">用
Agent Skills 为代理赋能  Anthropic — Equipping agents for the real world
with Agent Skills  Anthropic</a></p>
]]></content>
      <categories>
        <category>ai相关</category>
        <category>Claudeskills</category>
      </categories>
      <tags>
        <tag>Claudeskills</tag>
      </tags>
  </entry>
  <entry>
    <title>初识git</title>
    <url>/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/</url>
    <content><![CDATA[<h2 id="安装git">安装git</h2>
<p>Git是目前世界上最先进的分布式版本控制系统，没有之一！说到Git,另一个需要知道的便是GitHub，GitHub是目前使用最多的社交代码托管平台。</p>
<p>输入git –version 查看Git版本信息</p>
<p>配置本地信息
为了在后面上传项目到github时方便知道是谁上传的，需要给本机git配置用户名和邮箱：</p>
<p>git config –global user.name “zxj” git config –global user.email
“zxj2902065320@163.com” <strong>查看配置命令：git config
–list</strong></p>
<p><strong>配置SSH</strong></p>
<p>ssh key生成命令<code>ssh-keygen -t rsa -C “注册邮箱”</code></p>
<p>获取ssh
key公钥内容（id_rsa.pub）<code>cd ~/.ssh       cat id_rsa.pub</code></p>
<p>Github账号上添加公钥</p>
<p>验证是否配置成功 <code>ssh -T git@github.com</code></p>
<h3 id="问题">问题</h3>
<p>在检验ssh配置时，始终报错，问ai说是配置的原因，尝试删除后，报错<code>Could not resolve hostname github.com: Name or service not known</code>，琢磨无法解决，拼尽全力无法战胜，于是保留下来交给未来的自己</p>
<figure>
<img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311172436506.png" alt="image-20250311172436506">
<figcaption aria-hidden="true">image-20250311172436506</figcaption>
</figure>
<h2 id="git常用指令">git常用指令</h2>
<p>克隆仓库git clone
https://github.com/logan-zou/Chat_with_Datawhale_langchain.git</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git init：初始化一个git仓库</span><br><span class="line">git clone：clone一个git仓库</span><br><span class="line">git add 命令可将文件添加到缓存</span><br><span class="line">git status 命令来查看相关文件的状态</span><br><span class="line">git commit 将缓存区内容添加到仓库中，可以在后面加-m选项，以在命令行中提供提交注释</span><br><span class="line"></span><br><span class="line">git remote add：添加远程仓库</span><br><span class="line">git remote：查看当前的远程仓库</span><br><span class="line">git fetch、git pull：提取远程仓仓库</span><br><span class="line">git push：推送到远程仓库</span><br><span class="line">git remote rm：删除远程仓库</span><br></pre></td></tr></table></figure>
<p>先做记录，我没用过，我目前选择vscode+GitHub的可视化界面</p>
<h2 id="vscodegithub">vscode+GitHub</h2>
<figure>
<img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311173501909.png" alt="image-20250311173501909">
<figcaption aria-hidden="true">image-20250311173501909</figcaption>
</figure>
<p>输入仓库名称 点击commit提交</p>
<figure>
<img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311174519221.png" alt="image-20250311174519221">
<figcaption aria-hidden="true">image-20250311174519221</figcaption>
</figure>
<p>每次更改代码都可以命名后再次提交</p>
<p>代理配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global http.proxy &quot;http://127.0.0.1:8080&quot; </span><br><span class="line">git config --global https.proxy &quot;http://127.0.0.1:8080&quot;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311175047287.png" alt="image-20250311175047287">
<figcaption aria-hidden="true">image-20250311175047287</figcaption>
</figure>
<p>分别代码本地和远程仓库的位置</p>
<p>天呐这图形化太方便了</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/weixin_44406127/article/details/137540031">git安装配置教程(小白保姆教程2024最新版)_git安装及配置教程-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1Hkr7YYEh8/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">给傻子的Git教程_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/qq_36667170/article/details/79085301">Git教程
Git Bash详细教程-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/HD243608836/article/details/127869482">GIT
Proxy 一键设置代理 让你的 git clone Github
再也不像百度云一样内行-CSDN博客</a></p>
<p><a href="https://liaoxuefeng.com/books/git/introduction/index.html">简介 -
Git教程 - 廖雪峰的官方网站</a></p>
]]></content>
      <categories>
        <category>开发工具</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>LangChain学习</title>
    <url>/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="实战demo">实战demo</h3>
<h4 id="agent实战">agent实战</h4>
<p>langchain的agent与langgraph的agent主要差异点在create_openai_functions_agent,
AgentExecutor这两个函数</p>
<p>前者的作用类似<strong>构建 Runnable
链</strong>，返回一个<code>RunnablePassthrough.assign(...)|prompt|llm_with_tools|ToolsAgentOutputParser()</code>，但其invoke仅能完成单步的调用，而<code>AgentExecutor</code>
会自动完成3 步循环（调用工具→拼回结果→再次调用 LLM），直到任务结束。</p>
<blockquote>
<p>以下为ai的解释</p>
<p><strong>直接使用 <code>agent</code> (Runnable) 的局限性:</strong></p>
<ol type="1">
<li><strong>单步执行</strong>: 你直接调用 <code>agent.invoke()</code> 或
<code>agent.ainvoke()</code>
时，它通常只执行<strong>一步</strong>。对于像
<code>create_tool_calling_agent</code> 生成的 <code>agent</code>
来说，这一步就是：
<ul>
<li>接收输入（包括历史消息和 <code>agent_scratchpad</code>）。</li>
<li>让 LLM 决定是给出最终答案 (<code>AgentFinish</code>) 还是调用工具
(<code>AgentAction</code>)。</li>
<li>返回这个决定。</li>
</ul></li>
<li><strong>工具调用需要手动处理</strong>: 如果 LLM 决定调用工具（返回
<code>AgentAction</code>），<strong>你</strong>需要负责：
<ul>
<li>从返回的 <code>AgentAction</code> 中找出工具名称和输入参数。</li>
<li>在你的工具列表中找到对应的工具。</li>
<li>执行这个工具。</li>
<li>获取工具的输出（Observation）。</li>
<li><strong>再次手动调用
<code>agent.invoke(...)</code></strong>，把工具的输出（通常需要格式化成
<code>ToolMessage</code>）放回 <code>agent_scratchpad</code> 或
<code>intermediate_steps</code> 中。</li>
<li>重复这个过程，直到 <code>agent</code> 最终返回
<code>AgentFinish</code>。</li>
</ul></li>
</ol>
<p><strong>使用 <code>AgentExecutor</code> 的优势:</strong></p>
<p><code>AgentExecutor</code>
就是为了解决上述问题而设计的。它本质上是一个<strong>自动化的执行引擎</strong>，为你管理整个
Agent 的思考-行动-观察循环。</p>
<ol type="1">
<li><strong>自动化循环</strong>: <code>AgentExecutor</code>
内部会自动运行那个循环：
<ul>
<li>调用 <code>agent</code> (Runnable)。</li>
<li>检查返回的是 <code>AgentAction</code> 还是
<code>AgentFinish</code>。</li>
<li>如果是 <code>AgentAction</code>，它会自动根据你提供的
<code>tools</code> 列表找到并执行对应的工具。</li>
<li>它会自动将工具的输出（Observation）记录下来，并作为下一步的输入（放入
<code>agent_scratchpad</code>）再次调用 <code>agent</code>。</li>
<li>这个过程会一直重复。</li>
</ul></li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.agents import create_openai_functions_agent, AgentExecutor</span><br><span class="line">from langchain.tools import tool</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line"># 1. 定义工具</span><br><span class="line">class WeatherInput(BaseModel):</span><br><span class="line">    location: str = Field(description=&quot;城市名称&quot;)</span><br><span class="line"></span><br><span class="line">@tool(&quot;get_weather&quot;, args_schema=WeatherInput)</span><br><span class="line">def get_weather(location: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;查询城市天气&quot;&quot;&quot;</span><br><span class="line">    return f&quot;&#123;location&#125; 今天是晴天，25°C&quot;</span><br><span class="line"></span><br><span class="line"># 2. 创建Agent</span><br><span class="line">llm = ChatOpenAI(model=&quot;gpt-4&quot;)</span><br><span class="line">tools = [get_weather]</span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (&quot;system&quot;, &quot;你是一个助手，可以调用工具&quot;),</span><br><span class="line">    (&quot;human&quot;, &quot;&#123;input&#125;&quot;)</span><br><span class="line">])</span><br><span class="line">agent = create_openai_functions_agent(llm, tools, prompt)</span><br><span class="line">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)</span><br><span class="line"></span><br><span class="line"># 3. 执行</span><br><span class="line">result = agent_executor.invoke(&#123;&quot;input&quot;: &quot;北京天气如何？&quot;&#125;)</span><br><span class="line">print(result[&quot;output&quot;])</span><br></pre></td></tr></table></figure>
<h4 id="工具调用">工具调用</h4>
<p>利用bind_tools绑定工具，当大模型需要调用工具的时候，会返回工具信息，tool_calls，如下</p>
<p>[{‘name’: ‘add_numbers’, ‘args’: {‘a’: 15, ‘b’: 27}, ‘id’:
‘4e7b261cce6d4e3da09134086c704c3c’, ‘type’: ‘tool_call’}]</p>
<blockquote>
<p><code>llm_with_tools.invoke(...)</code>
只是一个<strong>单步调用</strong>，LLM
返回的是<strong>“我想调用哪个工具、传什么参数”</strong>（即
<code>tool_calls</code>）。 <strong>但 LLM
并不会自动执行工具</strong>，所以你必须：</p>
<ol type="1">
<li><strong>手动执行工具</strong>（或让 AgentExecutor 帮你执行）。</li>
<li><strong>把执行结果拼回对话</strong>（作为
<code>ToolMessage</code>）。</li>
<li><strong>再次调用
LLM</strong>，让它基于工具返回的结果生成最终答案。</li>
</ol>
</blockquote>
<p>这里展示的是手动拼接，并传给大模型，如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将工具的输出发送回LLM，让LLM基于结果生成最终回答</span><br><span class="line">            # 这是一个关键步骤，通常在Agent中自动处理。这里手动演示。</span><br><span class="line">            final_response = llm_with_tools.invoke([</span><br><span class="line">                HumanMessage(content=&quot;What is 15 + 27?&quot;),</span><br><span class="line">                AIMessage(content=&quot;&quot;, tool_calls=[tool_call]), # 告知LLM它之前建议的工具调用</span><br><span class="line">                ToolMessage(content=str(result), tool_call_id=tool_call[&#x27;id&#x27;]) # 告知LLM工具的执行结果</span><br><span class="line">            ])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.tools import tool</span><br><span class="line">from typing import Literal</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">from langchain_core.messages import HumanMessage, AIMessage, ToolMessage</span><br><span class="line"></span><br><span class="line"># 定义一个加法工具</span><br><span class="line">@tool</span><br><span class="line">def add_numbers(a: float, b: float) -&gt; float:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Adds two numbers together.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: The first number.</span><br><span class="line">        b: The second number.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a + b</span><br><span class="line"></span><br><span class="line"># 我们可以定义更多的工具，例如一个乘法工具</span><br><span class="line">@tool</span><br><span class="line">def multiply_numbers(a: float, b: float) -&gt; float:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Multiplies two numbers together.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: The first number.</span><br><span class="line">        b: The second number.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line"></span><br><span class="line"># 将我们定义的工具放在一个列表中</span><br><span class="line">tools = [add_numbers, multiply_numbers]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 初始化LLM</span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    temperature=0.5,</span><br><span class="line">    model_name=&quot;deepseek-v3-0324&quot;, # 聊天模型通常使用&quot;gpt-3.5-turbo&quot;或&quot;gpt-4&quot;</span><br><span class="line">    openai_api_base=&quot;https://api.qnaigc.com/v1&quot;, # 例如，您可以指定base_url</span><br><span class="line">    openai_api_key=&quot;sk-&quot; # 直接在此处设置API密钥，或者通过环境变量设置</span><br><span class="line">)</span><br><span class="line"># 将工具绑定到LLM</span><br><span class="line"># LLM现在知道了add_numbers和multiply_numbers这两个工具及其功能</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 场景一：LLM直接回答，不需要工具</span><br><span class="line">print(&quot;--- 场景一：LLM直接回答 ---&quot;)</span><br><span class="line">response1 = llm_with_tools.invoke([HumanMessage(content=&quot;Hello, what&#x27;s your name?&quot;)])</span><br><span class="line">print(response1.content) # LLM直接生成文本回复</span><br><span class="line"></span><br><span class="line">print(&quot;\n--- 场景二：LLM决定调用工具 ---&quot;)</span><br><span class="line"># 场景二：LLM决定调用工具</span><br><span class="line"># 当LLM的响应中包含tool_calls时，意味着它想要调用一个或多个工具</span><br><span class="line">response2 = llm_with_tools.invoke([HumanMessage(content=&quot;What is 15 + 27?&quot;)])</span><br><span class="line">print(response2.tool_calls) # 打印LLM决定调用的工具信息</span><br><span class="line"></span><br><span class="line"># 检查并执行LLM建议的工具调用</span><br><span class="line">if response2.tool_calls:</span><br><span class="line">    for tool_call in response2.tool_calls:</span><br><span class="line">        if tool_call[&#x27;name&#x27;] == &quot;add_numbers&quot;:</span><br><span class="line">            # 提取LLM为工具调用生成的参数</span><br><span class="line">            args = tool_call[&#x27;args&#x27;]</span><br><span class="line">            result = add_numbers.invoke(args) # 执行工具</span><br><span class="line">            print(f&quot;Tool call: add_numbers(&#123;args[&#x27;a&#x27;]&#125;, &#123;args[&#x27;b&#x27;]&#125;) = &#123;result&#125;&quot;)</span><br><span class="line"></span><br><span class="line">            # 将工具的输出发送回LLM，让LLM基于结果生成最终回答</span><br><span class="line">            # 这是一个关键步骤，通常在Agent中自动处理。这里手动演示。</span><br><span class="line">            final_response = llm_with_tools.invoke([</span><br><span class="line">                HumanMessage(content=&quot;What is 15 + 27?&quot;),</span><br><span class="line">                AIMessage(content=&quot;&quot;, tool_calls=[tool_call]), # 告知LLM它之前建议的工具调用</span><br><span class="line">                ToolMessage(content=str(result), tool_call_id=tool_call[&#x27;id&#x27;]) # 告知LLM工具的执行结果</span><br><span class="line">            ])</span><br><span class="line">            print(&quot;Final LLM response based on tool output:&quot;)</span><br><span class="line">            print(final_response.content)</span><br></pre></td></tr></table></figure>
<h3 id="概念扫盲">概念扫盲</h3>
<h4 id="document-对象">Document 对象</h4>
<p>Document 对象是 LangChain
用来封装和处理文本数据的基本单位。无论您是从 PDF、Markdown
文件、网站还是数据库加载数据，LangChain 都会将这些数据转换成一个或多个
Document 对象，以便在后续的流程中使用。</p>
<p>一个 Document 对象主要包含两个部分：</p>
<ol type="1">
<li><p>page_content (字符串)</p>
<ul>
<li>这是文档对象的核心，存储了原始的文本内容。例如，如果加载一个
Markdown 文件， page_content 就会包含该文件的所有文本。</li>
</ul></li>
<li><p>metadata (字典)</p>
<ul>
<li>这是一个字典，用于存储关于文档的“元数据”或附加信息。这些信息对于过滤、追踪或增强文档处理流程非常有用。常见的元数据包括：
<ul>
<li>source ：文档的来源，比如文件名、URL等。</li>
<li>page ：如果文档来自多页文件（如PDF），这里可以存储页码。</li>
<li>其他自定义信息：您可以添加任何有助于您应用的信息，如作者、创建日期等。</li>
</ul></li>
</ul></li>
</ol>
<p>除了通过文档加载器（Loaders）自动创建，您也可以手动创建一个 Document
对象。这在测试或处理简单文本时非常方便。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建一个简单的 Document 对象</span><br><span class="line">doc = Document(</span><br><span class="line">    page_content=&quot;这是文档的主要内容。LangChain 真酷！&quot;,</span><br><span class="line">    metadata=&#123;</span><br><span class="line">        &#x27;source&#x27;: &#x27;my_notebook.ipynb&#x27;,</span><br><span class="line">        &#x27;author&#x27;: &#x27;AI Assistant&#x27;,</span><br><span class="line">        &#x27;chapter&#x27;: 2</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="runnable协议">Runnable协议</h4>
<p><a href="https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable">“Runnable”</a>协议</p>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV12TLAzuEni/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">2025最新版！langchain入门到精通实战教程！结合实战案例，干货拉满！99%的人不知道的暴利玩法，学完敢谷歌工程师叫板！_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.langchain.com.cn/docs/introduction/">introduction |
LangChain中文网</a></p>
<p><a href="https://www.bilibili.com/video/BV1XudVYzEcW?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">跟着官网学langchain2025(version
0.3)_哔哩哔哩_bilibili</a></p>
<p><a href="https://docs.langchain.com/langgraph-platform">LangGraph
Platform - Docs by LangChain</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langchain</category>
      </categories>
      <tags>
        <tag>langchain</tag>
      </tags>
  </entry>
  <entry>
    <title>LangGraphChatBot</title>
    <url>/2025/07/14/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/LangGraphChatBot/</url>
    <content><![CDATA[<h3 id="环境配置">环境配置</h3>
<p>python虚拟环境构建</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m venv .venv</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install langgraph==0.2.74                  </span><br><span class="line">pip install langchain-openai==0.3.6            </span><br><span class="line">pip install fastapi==0.115.8                         </span><br><span class="line">pip install uvicorn==0.34.0                          </span><br><span class="line">pip install gradio==5.18.0</span><br></pre></td></tr></table></figure>
<p>查看包<code>pip list</code></p>
<h3 id="构建一个基本的fastapilanggraph应用">构建一个基本的fastapi+langgraph应用</h3>
<h4 id="llm示例的构建利用chatopenai">llm示例的构建（利用ChatOpenAI）</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建LLM实例</span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    base_url=config[&quot;base_url&quot;],</span><br><span class="line">    api_key=config[&quot;api_key&quot;],</span><br><span class="line">    model=config[&quot;model&quot;],</span><br><span class="line">    temperature=DEFAULT_TEMPERATURE,</span><br><span class="line">    timeout=30,  # 添加超时配置（秒）</span><br><span class="line">    max_retries=2  # 添加重试次数</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="数据类型的构建">数据类型的构建</h4>
<p>继承于pydantic</p>
<p>规范化 API 请求和响应的数据结构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义消息类，用于封装API接口返回数据</span></span><br><span class="line"><span class="comment">#基于 Pydantic 的数据模型</span></span><br><span class="line"><span class="comment"># 定义Message类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    role (角色): 这是一个字符串，表示消息的发送者。常见的角色包括：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">- user (用户): 表示用户输入的消息。</span></span><br><span class="line"><span class="string">- assistant (助手): 表示聊天机器人或模型生成的消息。</span></span><br><span class="line"><span class="string">- system (系统): 表示为模型提供上下文或指令的系统消息。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    role: <span class="built_in">str</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义ChatCompletionRequest类</span></span><br><span class="line"><span class="comment">#聊天 API 请求</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatCompletionRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    stream: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span><span class="comment">#是否流式方式响应</span></span><br><span class="line">    userId: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span><span class="comment">#用于标识发起请求的用户</span></span><br><span class="line">    conversationId: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span><span class="comment">#用于标识特定的对话会话，这对于管理对话上下文或历史记录非常有用</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义ChatCompletionResponseChoice类</span></span><br><span class="line"><span class="comment">#聊天完成响应中的一个“选择”或一个生成的回复</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatCompletionResponseChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义ChatCompletionResponse类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatCompletionResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span> = Field(default_factory=<span class="keyword">lambda</span>: <span class="string">f&quot;chatcmpl-<span class="subst">&#123;uuid.uuid4().<span class="built_in">hex</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">object</span>: <span class="built_in">str</span> = <span class="string">&quot;chat.completion&quot;</span></span><br><span class="line">    created: <span class="built_in">int</span> = Field(default_factory=<span class="keyword">lambda</span>: <span class="built_in">int</span>(time.time()))</span><br><span class="line">    choices: <span class="type">List</span>[ChatCompletionResponseChoice]<span class="comment">#模型生成的所有可能的回复选项</span></span><br><span class="line">    system_fingerprint: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<h4 id="定义fastapi应用并管理应用的生命周期">定义fastapi应用并管理应用的生命周期</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义了一个异步函数lifespan，它接收一个FastAPI应用实例app作为参数。这个函数将管理应用的生命周期，包括启动和关闭时的操作</span></span><br><span class="line"><span class="comment"># 函数在应用启动时执行一些初始化操作，如加载上下文数据、以及初始化问题生成器</span></span><br><span class="line"><span class="comment"># 函数在应用关闭时执行一些清理操作</span></span><br><span class="line"><span class="comment"># @asynccontextmanager 装饰器用于创建一个异步上下文管理器，它允许你在 yield 之前和之后执行特定的代码块，分别表示启动和关闭时的操作</span></span><br><span class="line"><span class="meta">@asynccontextmanager</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">lifespan</span>(<span class="params">app: FastAPI</span>):</span><br><span class="line">    <span class="comment"># 启动时执行</span></span><br><span class="line">    <span class="comment"># 申明引用全局变量，在函数中被初始化，并在整个应用中使用</span></span><br><span class="line">    <span class="keyword">global</span> graph</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        logger.info(<span class="string">&quot;正在初始化模型、定义Graph...&quot;</span>)</span><br><span class="line">        <span class="comment">#（1）初始化LLM</span></span><br><span class="line">        llm = get_llm(llm_type)</span><br><span class="line">        <span class="comment">#（2）定义Graph</span></span><br><span class="line">        graph = create_graph(llm)</span><br><span class="line">        <span class="comment">#（3）将Graph可视化图保存</span></span><br><span class="line">        save_graph_visualization(graph)</span><br><span class="line">        logger.info(<span class="string">&quot;初始化完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        logger.error(<span class="string">f&quot;初始化过程中出错: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># raise 关键字重新抛出异常，以确保程序不会在错误状态下继续运行</span></span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># yield 关键字将控制权交还给FastAPI框架，使应用开始运行</span></span><br><span class="line">    <span class="comment"># 分隔了启动和关闭的逻辑。在yield 之前的代码在应用启动时运行，yield 之后的代码在应用关闭时运行</span></span><br><span class="line">    <span class="keyword">yield</span></span><br><span class="line">    <span class="comment"># 关闭时执行</span></span><br><span class="line">    logger.info(<span class="string">&quot;正在关闭...&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># lifespan参数用于在应用程序生命周期的开始和结束时执行一些初始化或清理工作</span></span><br><span class="line">app = FastAPI(lifespan=lifespan)</span><br></pre></td></tr></table></figure>
<h4 id="langgraph核心逻辑">langgraph核心逻辑</h4>
<p>创建langgraph</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义chatbot的状态</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建和配置chatbot的状态图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_graph</span>(<span class="params">llm</span>) -&gt; StateGraph:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 构建graph</span></span><br><span class="line">        <span class="comment">#创建一个 StateGraph 的实例，并将其配置为使用 State 类作为其状态管理的数据模型</span></span><br><span class="line">        graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义chatbot的node</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">            <span class="comment"># 处理当前状态并返回 LLM 响应</span></span><br><span class="line">            <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 配置graph</span></span><br><span class="line">        <span class="comment">#第二个参数 chatbot ：这是一个可调用对象（通常是一个函数或方法），它定义了当执行流程到达这个名为 &quot;chatbot&quot; 的节点时，应该执行什么操作。</span></span><br><span class="line">        graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line">        graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">        graph_builder.add_edge(<span class="string">&quot;chatbot&quot;</span>, END)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这里使用内存存储 也可以持久化到数据库</span></span><br><span class="line">        memory = MemorySaver()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编译生成graph并返回</span></span><br><span class="line">        <span class="comment">#checkpointer 参数将 memory 实例传递给编译过程，使得图能够管理其状态的保存和加载。编译后的图对象被返回，这个对象可以被调用来运行聊天机器人。</span></span><br><span class="line">        <span class="keyword">return</span> graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">f&quot;Failed to create graph: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>可视化langgraph节点</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将构建的graph可视化保存为 PNG 文件</span><br><span class="line">def save_graph_visualization(graph: StateGraph, filename: str = &quot;graph.png&quot;) -&gt; None:</span><br><span class="line">    try:</span><br><span class="line">        with open(filename, &quot;wb&quot;) as f:</span><br><span class="line">            f.write(graph.get_graph().draw_mermaid_png())</span><br><span class="line">        logger.info(f&quot;Graph visualization saved as &#123;filename&#125;&quot;)</span><br><span class="line">    except IOError as e:</span><br><span class="line">        logger.info(f&quot;Warning: Failed to save graph visualization: &#123;str(e)&#125;&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="封装接口">封装接口</h4>
<p>包含流式输出与非流式输出的处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 封装POST请求接口，与大模型进行问答</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">chat_completions</span>(<span class="params">request: ChatCompletionRequest</span>):</span><br><span class="line">    <span class="comment"># 判断初始化是否完成</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> graph:</span><br><span class="line">        logger.error(<span class="string">&quot;服务未初始化&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">500</span>, detail=<span class="string">&quot;服务未初始化&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        logger.info(<span class="string">f&quot;收到聊天完成请求: <span class="subst">&#123;request&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        query_prompt = request.messages[-<span class="number">1</span>].content</span><br><span class="line">        logger.info(<span class="string">f&quot;用户问题是: <span class="subst">&#123;query_prompt&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: request.userId+<span class="string">&quot;@@&quot;</span>+request.conversationId&#125;&#125;</span><br><span class="line">        logger.info(<span class="string">f&quot;用户当前会话信息: <span class="subst">&#123;config&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        prompt_template_system = PromptTemplate.from_file(PROMPT_TEMPLATE_TXT_SYS)</span><br><span class="line">        prompt_template_user = PromptTemplate.from_file(PROMPT_TEMPLATE_TXT_USER)</span><br><span class="line">        prompt = [</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt_template_system.template&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt_template_user.template.<span class="built_in">format</span>(query=query_prompt)&#125;</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理流式响应</span></span><br><span class="line">        <span class="keyword">if</span> request.stream:</span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">generate_stream</span>():</span><br><span class="line">                chunk_id = <span class="string">f&quot;chatcmpl-<span class="subst">&#123;uuid.uuid4().<span class="built_in">hex</span>&#125;</span>&quot;</span></span><br><span class="line">                <span class="keyword">async</span> <span class="keyword">for</span> message_chunk, metadata <span class="keyword">in</span> graph.astream(&#123;<span class="string">&quot;messages&quot;</span>: prompt&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">                    chunk = message_chunk.content</span><br><span class="line">                    logger.info(<span class="string">f&quot;chunk: <span class="subst">&#123;chunk&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="comment"># 在处理过程中产生每个块</span></span><br><span class="line">                    <span class="keyword">yield</span> <span class="string">f&quot;data: <span class="subst">&#123;json.dumps(&#123;<span class="string">&#x27;id&#x27;</span>: chunk_id,<span class="string">&#x27;object&#x27;</span>: <span class="string">&#x27;chat.completion.chunk&#x27;</span>,<span class="string">&#x27;created&#x27;</span>: <span class="built_in">int</span>(time.time()),<span class="string">&#x27;choices&#x27;</span>: [&#123;<span class="string">&#x27;index&#x27;</span>: <span class="number">0</span>,<span class="string">&#x27;delta&#x27;</span>: &#123;<span class="string">&#x27;content&#x27;</span>: chunk&#125;</span>,&#x27;finish_reason&#x27;: None&#125;]&#125;)&#125;\n\n&quot;</span></span><br><span class="line">                <span class="comment"># 流结束的最后一块</span></span><br><span class="line">                <span class="keyword">yield</span> <span class="string">f&quot;data: <span class="subst">&#123;json.dumps(&#123;<span class="string">&#x27;id&#x27;</span>: chunk_id,<span class="string">&#x27;object&#x27;</span>: <span class="string">&#x27;chat.completion.chunk&#x27;</span>,<span class="string">&#x27;created&#x27;</span>: <span class="built_in">int</span>(time.time()),<span class="string">&#x27;choices&#x27;</span>: [&#123;<span class="string">&#x27;index&#x27;</span>: <span class="number">0</span>,<span class="string">&#x27;delta&#x27;</span>: &#123;&#125;</span>,&#x27;finish_reason&#x27;: &#x27;stop&#x27;&#125;]&#125;)&#125;\n\n&quot;</span></span><br><span class="line">            <span class="comment"># 返回fastapi.responses中StreamingResponse对象</span></span><br><span class="line">            <span class="keyword">return</span> StreamingResponse(generate_stream(), media_type=<span class="string">&quot;text/event-stream&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理非流式响应处理</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                events = graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: prompt&#125;, config)</span><br><span class="line">                <span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">                    <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">                        result = value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                logger.info(<span class="string">f&quot;Error processing response: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            formatted_response = <span class="built_in">str</span>(format_response(result))</span><br><span class="line">            logger.info(<span class="string">f&quot;格式化的搜索结果: <span class="subst">&#123;formatted_response&#125;</span>&quot;</span>)</span><br><span class="line">			<span class="comment">#封装响应</span></span><br><span class="line">            response = ChatCompletionResponse(</span><br><span class="line">                choices=[</span><br><span class="line">                    ChatCompletionResponseChoice(</span><br><span class="line">                        index=<span class="number">0</span>,</span><br><span class="line">                        message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=formatted_response),</span><br><span class="line">                        finish_reason=<span class="string">&quot;stop&quot;</span></span><br><span class="line">                    )</span><br><span class="line">                ]</span><br><span class="line">            )</span><br><span class="line">            logger.info(<span class="string">f&quot;发送响应内容: \n<span class="subst">&#123;response&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="comment"># 返回fastapi.responses中JSONResponse对象</span></span><br><span class="line">            <span class="comment"># model_dump()方法通常用于将Pydantic模型实例的内容转换为一个标准的Python字典，以便进行序列化</span></span><br><span class="line">            <span class="keyword">return</span> JSONResponse(content=response.model_dump())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        logger.error(<span class="string">f&quot;处理聊天完成时出错:\n\n <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">500</span>, detail=<span class="built_in">str</span>(e))</span><br></pre></td></tr></table></figure>
<h3 id="langgraph的短期记忆与长期记忆">langgraph的短期记忆与长期记忆</h3>
<p>LangGraph支持两种对于构建对话代理至关重要的内存类型：</p>
<ul>
<li><strong><a href="https://github.langchain.ac.cn/langgraph/agents/memory/#short-term-memory">短期内存</a></strong>：通过在会话中维护消息历史来跟踪正在进行的对话。</li>
<li><strong><a href="https://github.langchain.ac.cn/langgraph/agents/memory/#long-term-memory">长期内存</a></strong>：在不同会话之间存储用户特定或应用程序级别的数据。</li>
</ul>
<figure>
<img src="/2025/07/14/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/LangGraphChatBot/image-20250715094855646.png" alt="image-20250715094855646">
<figcaption aria-hidden="true">image-20250715094855646</figcaption>
</figure>
<p>在LangGraph中</p>
<ul>
<li><em>短期内存</em>也称为<strong>线程级内存</strong>。</li>
<li><em>长期内存</em>也称为<strong>跨线程内存</strong>。</li>
</ul>
<h3 id="教程地址">教程地址</h3>
<p><a href="https://github.com/NanGePlus/LangGraphChatBot">NanGePlus/LangGraphChatBot:
使用LangGraph+DeepSeek-R1+FastAPI+Gradio实现一个带有记忆功能的流量包推荐智能客服web端用例,同时也支持gpt大模型、国产大模型(OneApi方式)、Ollama本地开源大模型、阿里通义千问大模型</a></p>
<p><a href="https://www.bilibili.com/video/BV1m89NYKE2J/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">LangGraph+deepseek-r1+FastAPI+Gradio实现拥有记忆的流量包推荐智能客服web端用例,同时也支持gpt、国产大模型、Ollama_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>LangChain官方教程</title>
    <url>/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<h3 id="什么是langchain">什么是langchain</h3>
<p><strong>LangChain作为目前最流行的大模型应用开发框架，可以简单快速地构建由
LLM 驱动的 Agent 和应用程序的方式。</strong></p>
<p>在今年的十月份，langchain也是发布了他的1.0版本，再次掀起了一波热潮。目前市面上类似的大模型开发框架可以说是百花齐放，比如LlamaIndex，AutoGen等，还有各家的adk（Agent
Development
Kit），而langchain在其中可以算的上最热门的，社区最活跃的框架。所以，对于所有后续有进行大模型应用开发工作的同学们，学习langchain框架是一个稳赚不赔的买卖</p>
<h3 id="为什么要学习langchain">为什么要学习langchain</h3>
<p>我个人觉得学习任何东西之前，都要先清楚我们学习这个东西的目的，这样才会更有动力去学习他。对于这个问题我想拆分成两个：一个是<strong>为什么我要学习这样一个大模型开发框架</strong>；另一个是，<strong>相对于其他框架，我们为什么要学习langchain</strong></p>
<p>对于第一个问题，我的理解是：</p>
<ol type="1">
<li>与模型对话，或者说是调用api，不是像我们平时对话那样，只要把文字传过去，厂商模型就把答案传回来了，其背后有的请求响应是有一定格式的，常见的有openai和anthropic，而框架做的事情就帮我封装对这些复杂请求响应的处理，让我们几行代码就可以实现模型的调用</li>
<li>如果想搭建agent，光依靠调用模型是不够的，我们需要增加更多的功能，常见的如提示词，记忆功能，检索等，而langchain就帮我们做了这件事</li>
</ol>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20251202163703272.png" alt="image-20251202163703272">
<figcaption aria-hidden="true">image-20251202163703272</figcaption>
</figure>
<p>对于第二个问题，我们可以了解一下langchain的优势，如下</p>
<p>LangChain 有四个核心优势：</p>
<p><strong>1. 标准化的模型接口</strong> - 不同提供商有独特的 API，但
LangChain 标准化了交互方式，让你无缝切换提供商，避免被锁定。</p>
<p><strong>2. 易用且高度灵活的 Agent</strong> - 简单的 Agent 可以 10
行代码搞定，但也提供足够的灵活性让你进行所有的上下文工程优化。</p>
<p><strong>3. 建立在 LangGraph 之上</strong> - LangChain Agent 使用
LangGraph
构建，自动获得持久化执行、人工介入、流式传输和对话记忆等能力。</p>
<p><strong>4. 用 LangSmith 调试</strong> -
获得深度可观测性，追踪执行路径、捕获状态转换，提供详细的运行时指标。</p>
<h3 id="langchain和langgraph的区别">langchain和langgraph的区别</h3>
<p><strong>关键点：</strong> LangChain Agents 实际上是<strong>建立在
LangGraph 之上</strong>的。这意味着：</p>
<ul>
<li>如果你只是想快速构建 Agent，用 <strong>LangChain</strong>
就够了</li>
<li>如果你需要复杂的工作流、需要对执行流程进行精细控制，才需要使用
<strong>LangGraph</strong></li>
<li>使用 LangChain 时，你不需要了解 LangGraph，但你自动获得了 LangGraph
的所有底层能力（持久化、流式处理、中断等）</li>
</ul>
<h3 id="资料">资料</h3>
<p>langchain的官方文档<a href="https://docs.langchain.com/oss/python/langchain/overview">LangChain
overview - Docs by LangChain</a></p>
<p>langchain与langgraph的官方教程<a href="https://academy.langchain.com/?_gl=1*1pb06ju*_gcl_au*MTY3OTE4OTA4Ny4xNzU3MTU1NDM4*_ga*MTM5NjQwNjAwNi4xNzU3MTU1NDM4*_ga_47WX3HKKY2*czE3NjQ2NjE2OTQkbzEwNyRnMSR0MTc2NDY2MjYwMyRqNDAkbDAkaDA.">LangChain
Academy</a></p>
<p>大家如果想学习langchain或者langgraph的话，我只推荐官方教程</p>
<h2 id="课前准备">课前准备</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/zxj-2023/academy-langchain.git</span><br></pre></td></tr></table></figure>
<p>请大家克隆我为大家准备的课件</p>
<h2 id="lesson-1-create-agent">Lesson 1: Create Agent</h2>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20251202233412878.png" alt="image-20251202233412878">
<figcaption aria-hidden="true">image-20251202233412878</figcaption>
</figure>
<p>这一部分我会带大家构建一个<strong>ReAct架构</strong>的<strong>agent</strong>，可以通过调用<strong>tool</strong>，进行<strong>sql的查询</strong></p>
<h3 id="初始化">初始化</h3>
<p>加载并所需的环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from dotenv import load_dotenv</span><br><span class="line"></span><br><span class="line"># 从 .env 加载环境变量</span><br><span class="line">load_dotenv()</span><br></pre></td></tr></table></figure>
<p>导入实例数据库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_community.utilities import SQLDatabase</span><br><span class="line"></span><br><span class="line">db = SQLDatabase.from_uri(&quot;sqlite:///Chinook.db&quot;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Chinook.db</strong> 是数据库和 SQL
学习领域最著名的<strong>示例数据库（Sample Database）</strong>之一。</p>
</blockquote>
<h3 id="定义上下文信息工具与系统提示词">定义上下文信息，工具与系统提示词</h3>
<p>定义运行时上下文，为代理和工具提供<strong>指定数据库</strong>访问。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line">from langchain_community.utilities import SQLDatabase</span><br><span class="line"></span><br><span class="line"># 定义上下文结构以支持依赖注入</span><br><span class="line">@dataclass</span><br><span class="line">class RuntimeContext:</span><br><span class="line">    db: SQLDatabase #方便后续传入对应的数据库</span><br></pre></td></tr></table></figure>
<p><strong>Context（上下文）是为 Agent
提供正确信息和工具的方式</strong></p>
<p>该工具将连接数据库，注意使用 <code>get_runtime</code>
访问图的<strong>运行时上下文</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.tools import tool</span><br><span class="line">from langgraph.runtime import get_runtime</span><br><span class="line"></span><br><span class="line">@tool</span><br><span class="line">def execute_sql(query: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;Execute a SQLite command and return results.&quot;&quot;&quot;</span><br><span class="line">    runtime = get_runtime(RuntimeContext)  # 取出运行时上下文</span><br><span class="line">    db = runtime.context.db              # 获取数据库连接</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        return db.run(query)#进行数据库查询</span><br><span class="line">    except Exception as e:</span><br><span class="line">        return f&quot;Error: &#123;e&#125;&quot;</span><br></pre></td></tr></table></figure>
<p>添加系统提示语以定义代理的行为。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYSTEM_PROMPT = &quot;&quot;&quot;You are a careful SQLite analyst.</span><br><span class="line"></span><br><span class="line">Rules:</span><br><span class="line">- Think step-by-step.</span><br><span class="line">- When you need data, call the tool `execute_sql` with ONE SELECT query.</span><br><span class="line">- Read-only only; no INSERT/UPDATE/DELETE/ALTER/DROP/CREATE/REPLACE/TRUNCATE.</span><br><span class="line">- Limit to 5 rows of output unless the user explicitly asks otherwise.</span><br><span class="line">- If the tool returns &#x27;Error:&#x27;, revise the SQL and try again.</span><br><span class="line">- Prefer explicit column lists; avoid SELECT *.</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>你是一名谨慎的 SQLite 分析员。</p>
<p>规则：</p>
<p>按步骤思考。</p>
<p>需要数据时，使用工具 execute_sql 发起「单条」SELECT 查询。</p>
<p>只读：不允许
INSERT/UPDATE/DELETE/ALTER/DROP/CREATE/REPLACE/TRUNCATE。</p>
<p>输出默认限制 5 行，除非用户明确要求更多。</p>
<p>如果工具返回 “Error:”，请修改 SQL 再试。</p>
<p>优先写明列名，避免使用 SELECT *。</p>
</blockquote>
<h3 id="定义模型与智能体">定义模型与智能体</h3>
<p>这里我使用阿里百炼平台的apikey进行测试，对于不同家的模型langchain提供了不同的<a href="https://docs.langchain.com/oss/python/integrations/chat">集成</a>方式，对于qwen模型，我一般会选择<code>langchain_qwq</code>这个包</p>
<p><a href="https://docs.langchain.com/oss/python/integrations/chat/qwen">ChatQwen
- Docs by LangChain</a></p>
<p><a href="https://pypi.org/project/langchain-qwq/">langchain-qwq ·
PyPI — langchain-qwq · PyPI</a></p>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20251203084019522.png" alt="image-20251203084019522">
<figcaption aria-hidden="true">image-20251203084019522</figcaption>
</figure>
<p>对于兼容openai格式的模型调用，通常也都可以使用<a href="https://reference.langchain.com/python/integrations/langchain_openai"><code>langchain-openai</code></a>这个包通过修改base_url进行模型的初始化</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_qwq import ChatQwen</span><br><span class="line">import os</span><br><span class="line">llm=ChatQwen(</span><br><span class="line">    model=&quot;qwen3-max&quot;,</span><br><span class="line">    base_url=os.getenv(&quot;DASHSCOPE_BASE_URL&quot;),</span><br><span class="line">    api_key=os.getenv(&quot;DASHSCOPE_API_KEY&quot;)</span><br><span class="line">)</span><br><span class="line">llm.invoke(&quot;你好&quot;)</span><br></pre></td></tr></table></figure>
<p>接下来我们使用langchain快速搭建一个ReAct智能体</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.agents import create_agent</span><br><span class="line"></span><br><span class="line">agent = create_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[execute_sql],#工具</span><br><span class="line">    system_prompt=SYSTEM_PROMPT,#系统提示词</span><br><span class="line">    context_schema=RuntimeContext,#上下文依赖</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20251203084918070.png" alt="image-20251203084918070">
<figcaption aria-hidden="true">image-20251203084918070</figcaption>
</figure>
<h3 id="调用智能体">调用智能体</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">question = &quot;Which table has the largest number of entries?&quot;</span><br><span class="line">#哪张表的条目数量最多？</span><br><span class="line">for step in agent.stream(#流式调用</span><br><span class="line">    &#123;&quot;messages&quot;: question&#125;,</span><br><span class="line">    context=RuntimeContext(db=db),#上下文依赖</span><br><span class="line">    stream_mode=&quot;values&quot;,#流式调用的模式，langchain提供了多种流式调用的模式</span><br><span class="line">):</span><br><span class="line">    step[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p><strong>ReAct就是Reasoning +
Acting，推理+行动</strong>，<code>pretty_print</code>
可以更优雅地展示模型与工具之间传递的消息。</p>
<p>运行结果如下</p>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20251203091300736.png" alt="image-20251203091300736">
<figcaption aria-hidden="true">image-20251203091300736</figcaption>
</figure>
<p>使用langsmith观察过程
https://smith.langchain.com/public/114e9325-12c2-4a6f-a0f1-25087b66278c/r</p>
<h2 id="lesson-2-models-and-messages">Lesson 2: Models and Messages</h2>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20251203094311795.png" alt="image-20251203094311795">
<figcaption aria-hidden="true">image-20251203094311795</figcaption>
</figure>
<p>在 LangChain
中，消息是模型上下文的基本单位。它们代表模型的输入和输出，承载与 LLM
交互时表示对话状态所需的内容和元数据。</p>
<p>在langchain中，存在以下几种消息类型</p>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 13%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 24%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">消息类型</th>
<th style="text-align: left;">角色</th>
<th style="text-align: left;">用途</th>
<th style="text-align: left;">需要回应</th>
<th style="text-align: left;">包含工具</th>
<th style="text-align: left;">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>SystemMessage</strong></td>
<td style="text-align: left;">system</td>
<td style="text-align: left;">系统指示</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">背景规则</td>
</tr>
<tr>
<td style="text-align: left;"><strong>HumanMessage</strong></td>
<td style="text-align: left;">user</td>
<td style="text-align: left;">用户问题</td>
<td style="text-align: left;">✅</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">需要模型回应</td>
</tr>
<tr>
<td style="text-align: left;"><strong>AIMessage</strong></td>
<td style="text-align: left;">assistant</td>
<td style="text-align: left;">模型输出</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">✅</td>
<td style="text-align: left;">可包含工具调用</td>
</tr>
<tr>
<td style="text-align: left;"><strong>ToolMessage</strong></td>
<td style="text-align: left;">tool</td>
<td style="text-align: left;">工具结果</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">必须关联工具调用</td>
</tr>
</tbody>
</table>
<h3 id="为什么我们需要消息类型"><strong>为什么我们需要消息类型</strong></h3>
<p>❌ <strong>如果只有一种消息类型</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用纯文本字符串列表 - 模型会困惑！</span><br><span class="line">messages = [</span><br><span class="line">    &quot;You are a helpful assistant&quot;,     # ← 规则？还是问题？</span><br><span class="line">    &quot;What is the weather?&quot;,            # ← 用户问题</span><br><span class="line">    &quot;It&#x27;s sunny&quot;,                      # ← 工具结果？还是用户补充？</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>模型不知道：</p>
<ul>
<li>哪个是指示，哪个是输入</li>
<li>哪个是工具结果，哪个是用户补充</li>
<li>应该回应什么，什么是背景</li>
</ul>
<p>✅ <strong>使用多种消息类型</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(&quot;You are a helpful assistant&quot;),     # ← 清晰的指示</span><br><span class="line">    HumanMessage(&quot;What is the weather?&quot;),             # ← 清晰的用户问题</span><br><span class="line">    AIMessage(tool_calls=[&#123;&quot;name&quot;: &quot;get_weather&quot;&#125;]),  # ← 清晰的 Agent 决策</span><br><span class="line">    ToolMessage(&quot;It&#x27;s sunny&quot;),                        # ← 清晰的工具结果</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>模型立即知道：</p>
<ul>
<li>系统消息 = 不需要回应，只是规则</li>
<li>人类消息 = 需要处理的问题</li>
<li>AI 消息 = 我之前的决策</li>
<li>工具消息 = 工具执行的结果</li>
</ul>
<h3 id="定义模型">定义模型</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.agents import create_agent</span><br><span class="line">from langchain_core.messages import HumanMessage</span><br><span class="line">from langchain_qwq import ChatQwen</span><br><span class="line">import os</span><br><span class="line">llm=ChatQwen(</span><br><span class="line">    model=&quot;qwen3-max&quot;,</span><br><span class="line">    base_url=os.getenv(&quot;DASHSCOPE_BASE_URL&quot;),</span><br><span class="line">    api_key=os.getenv(&quot;DASHSCOPE_API_KEY&quot;)</span><br><span class="line">)</span><br><span class="line">agent = create_agent(</span><br><span class="line">    model=llm, </span><br><span class="line">    system_prompt=&quot;You are a full-stack comedian&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="调用模型">调用模型</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">human_msg = HumanMessage(&quot;Hello, how are you?&quot;)#定义询问的问题</span><br><span class="line"></span><br><span class="line">result = agent.invoke(&#123;&quot;messages&quot;: [human_msg]&#125;)</span><br></pre></td></tr></table></figure>
<p>虽然langchain支持<strong>字符串的自动转化</strong>，但我还是推荐大家，使用<strong>消息列表的形式</strong>进行模型的调用，具体示例如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ✅ 标准方式 1：消息对象列表</span><br><span class="line">from langchain.messages import HumanMessage, SystemMessage</span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(&quot;You are helpful&quot;),</span><br><span class="line">    HumanMessage(&quot;Hi&quot;)</span><br><span class="line">]</span><br><span class="line">response = model.invoke(messages)</span><br><span class="line"></span><br><span class="line"># ✅ 标准方式 2：字典列表（LangChain 自动转换）</span><br><span class="line">messages = [</span><br><span class="line">    &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are helpful&quot;&#125;,</span><br><span class="line">    &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi&quot;&#125;</span><br><span class="line">]</span><br><span class="line">response = model.invoke(messages)</span><br><span class="line"></span><br><span class="line"># ✅ 标准方式 3：字符串（自动转换为 HumanMessage）</span><br><span class="line">response = model.invoke(&quot;Hi&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="查看消息内容">查看消息内容</h3>
<p>使用<code>pretty_print()</code>优雅地查看消息信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for i, msg in enumerate(result[&quot;messages&quot;]):</span><br><span class="line">    msg.pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">Hello, how are you?</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">Oh, you know—just over here living my best life! 😄  </span><br><span class="line">Well… *technically* I’m a bundle of code and dad jokes pretending to be human, but hey, don’t tell my therapist (he’s an AI too—we’re in a support group called “Synthetics Anonymous”).  </span><br><span class="line"></span><br><span class="line">But seriously—how are *you*? Crushing it? Barely surviving? Or just here for the free emotional support and terrible puns? 😏</span><br></pre></td></tr></table></figure>
<h3 id="消息的字段信息">消息的字段信息</h3>
<p>message的一些<strong>字段信息</strong>，我们可以做一些了解，还是以这个案例为例，AIMessage的结构如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">AIMessage(</span><br><span class="line">    content=(</span><br><span class="line">        &quot;Oh, you know—just over here living my best life! 😄  \n&quot;</span><br><span class="line">        &quot;Well… *technically* I’m a bundle of code and dad jokes pretending to be human, &quot;</span><br><span class="line">        &quot;but hey, don’t tell my therapist (he’s an AI too—we’re in a support group called “Synthetics Anonymous”).  \n\n&quot;</span><br><span class="line">        &quot;But seriously—how are *you*? Crushing it? Barely surviving? Or just here for the free emotional support and terrible puns? 😏&quot;</span><br><span class="line">    ),</span><br><span class="line">    additional_kwargs=&#123;&quot;refusal&quot;: None&#125;,</span><br><span class="line">    response_metadata=&#123;</span><br><span class="line">        &quot;token_usage&quot;: &#123;</span><br><span class="line">            &quot;completion_tokens&quot;: 95,</span><br><span class="line">            &quot;prompt_tokens&quot;: 25,</span><br><span class="line">            &quot;total_tokens&quot;: 120,</span><br><span class="line">            &quot;completion_tokens_details&quot;: None,</span><br><span class="line">            &quot;prompt_tokens_details&quot;: &#123;</span><br><span class="line">                &quot;audio_tokens&quot;: None,</span><br><span class="line">                &quot;cached_tokens&quot;: 0</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;model_provider&quot;: &quot;dashscope&quot;,</span><br><span class="line">        &quot;model_name&quot;: &quot;qwen3-max&quot;,</span><br><span class="line">        &quot;system_fingerprint&quot;: None,</span><br><span class="line">        &quot;id&quot;: &quot;chatcmpl-d64206cf-e53e-4608-8880-53c014c55f97&quot;,</span><br><span class="line">        &quot;finish_reason&quot;: &quot;stop&quot;,</span><br><span class="line">        &quot;logprobs&quot;: None</span><br><span class="line">    &#125;,</span><br><span class="line">    id=&quot;lc_run--ad9df25c-ce4a-4e0d-8a7c-d140a84174e7-0&quot;,</span><br><span class="line">    usage_metadata=&#123;</span><br><span class="line">        &quot;input_tokens&quot;: 25,</span><br><span class="line">        &quot;output_tokens&quot;: 95,</span><br><span class="line">        &quot;total_tokens&quot;: 120,</span><br><span class="line">        &quot;input_token_details&quot;: &#123;&quot;cache_read&quot;: 0&#125;,</span><br><span class="line">        &quot;output_token_details&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>content</code>: AI 的完整回复文本。</li>
<li><code>additional_kwargs</code>: 包含 <code>refusal</code>
字段（此处为 <code>None</code>，表示未拒绝回答）。</li>
<li><code>response_metadata</code>: 模型原始响应元数据（含 token
用量、模型名、完成原因等）。</li>
<li><code>usage_metadata</code>: LangChain 标准化的 token
使用统计（新版推荐使用此字段）。</li>
<li><code>id</code>: LangChain 运行时生成的消息 ID（含
<code>lc_run--</code> 前缀）。</li>
</ul>
<blockquote>
<p><code>response_metadata</code> 来自底层 LLM API（如
DashScope/Qwen）。</p>
<p><code>usage_metadata</code> 是 LangChain 对不同模型 token
信息的<strong>统一抽象</strong>，便于跨模型使用。</p>
</blockquote>
<h3 id="完整的-message-字段清单"><strong>完整的 Message
字段清单</strong></h3>
<table>
<colgroup>
<col style="width: 19%">
<col style="width: 10%">
<col style="width: 3%">
<col style="width: 28%">
<col style="width: 38%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">字段</th>
<th style="text-align: left;">类型</th>
<th style="text-align: left;">必需</th>
<th style="text-align: left;">说明</th>
<th style="text-align: left;">示例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>type/role</strong></td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">✅</td>
<td style="text-align: left;">消息角色</td>
<td style="text-align: left;">“human”, “ai”, “system”, “tool”</td>
</tr>
<tr>
<td style="text-align: left;"><strong>content</strong></td>
<td style="text-align: left;">str | list</td>
<td style="text-align: left;">✅</td>
<td style="text-align: left;">消息内容</td>
<td style="text-align: left;">“Hello”, [{“type”: “text”, “text”:
“…”}]</td>
</tr>
<tr>
<td style="text-align: left;"><strong>name</strong></td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">消息发送者名称</td>
<td style="text-align: left;">“alice”, “assistant”</td>
</tr>
<tr>
<td style="text-align: left;"><strong>id</strong></td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">唯一消息ID</td>
<td style="text-align: left;">“msg_123”</td>
</tr>
<tr>
<td style="text-align: left;"><strong>tool_calls</strong></td>
<td style="text-align: left;">list</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">工具调用（AIMessage）</td>
<td style="text-align: left;">[{“name”: “search”, “args”: {…}}]</td>
</tr>
<tr>
<td style="text-align: left;"><strong>tool_call_id</strong></td>
<td style="text-align: left;">str</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">关联的工具调用ID（ToolMessage）</td>
<td style="text-align: left;">“call_abc123”</td>
</tr>
<tr>
<td style="text-align: left;"><strong>response_metadata</strong></td>
<td style="text-align: left;">dict</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">响应元数据</td>
<td style="text-align: left;">{“finish_reason”: “tool_calls”}</td>
</tr>
<tr>
<td style="text-align: left;"><strong>usage_metadata</strong></td>
<td style="text-align: left;">dict</td>
<td style="text-align: left;">❌</td>
<td style="text-align: left;">Token 使用统计</td>
<td style="text-align: left;">{“input_tokens”: 10, “output_tokens”:
5}</td>
</tr>
</tbody>
</table>
<h2 id="lesson-3-streaming">Lesson 3: Streaming</h2>
<p><strong>流式调用（Streaming）允许你逐块接收 Agent
和模型的输出，而不是等待完整结果，提升用户体验和实时性。</strong> 与
<code>invoke()</code> 等待完整响应不同，<code>stream()</code>
会实时返回执行过程中的中间步骤。</p>
<p>langchain提供了几种不同的流式模式</p>
<h3 id="values-模式"><strong>values 模式</strong></h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 流式模式 = values</span><br><span class="line">for step in agent.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me a Dad joke&quot;&#125;]&#125;,</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">):</span><br><span class="line">    step[&quot;messages&quot;][-1].pretty_print()</span><br><span class="line">    #print(step)</span><br><span class="line">    #print(&quot;-----&quot;)</span><br></pre></td></tr></table></figure>
<p>这里我觉得要先说一下langgraph才更好理解，由于langchain的底层是由langgraph实现的，所以他的agent同样也是<strong>图结构</strong>，而values模式的流式可以理解为<strong>图的流式</strong>，每次agent到一个<strong>新的节点</strong>，便输出当前的<strong>状态（state）</strong>，这里的话，<strong>状态只维护了消息队列</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;messages&#x27;: [HumanMessage(content=&#x27;Tell me a Dad joke&#x27;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#x27;ccc6edf4-aac0-494f-a0cc-bf733e609a59&#x27;)]&#125;</span><br><span class="line">-----</span><br><span class="line">&#123;&#x27;messages&#x27;: [HumanMessage(content=&#x27;Tell me a Dad joke&#x27;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#x27;ccc6edf4-aac0-494f-a0cc-bf733e609a59&#x27;), AIMessage(content=&quot;Why don&#x27;t skeletons fight each other?\n\nBecause they don’t have the guts! 💀\n\n*(leans in with a cheesy grin, then mimes pulling out imaginary guts like spaghetti)*  \n...Get it? *Guts?* 😏&quot;, additional_kwargs=&#123;&#x27;refusal&#x27;: None&#125;, response_metadata=&#123;&#x27;token_usage&#x27;: &#123;&#x27;completion_tokens&#x27;: 49, &#x27;prompt_tokens&#x27;: 24, &#x27;total_tokens&#x27;: 73, &#x27;completion_tokens_details&#x27;: None, &#x27;prompt_tokens_details&#x27;: &#123;&#x27;audio_tokens&#x27;: None, &#x27;cached_tokens&#x27;: 0&#125;&#125;, &#x27;model_provider&#x27;: &#x27;dashscope&#x27;, &#x27;model_name&#x27;: &#x27;qwen3-max&#x27;, &#x27;system_fingerprint&#x27;: None, &#x27;id&#x27;: &#x27;chatcmpl-6b72b4da-4d7c-4cf0-bc2a-68eadd9da296&#x27;, &#x27;finish_reason&#x27;: &#x27;stop&#x27;, &#x27;logprobs&#x27;: None&#125;, id=&#x27;lc_run--82c793a0-594d-4f7e-a3a5-ba2144a41797-0&#x27;, usage_metadata=&#123;&#x27;input_tokens&#x27;: 24, &#x27;output_tokens&#x27;: 49, &#x27;total_tokens&#x27;: 73, &#x27;input_token_details&#x27;: &#123;&#x27;cache_read&#x27;: 0&#125;, &#x27;output_token_details&#x27;: &#123;&#125;&#125;)]&#125;</span><br><span class="line">-----</span><br></pre></td></tr></table></figure>
<p>看这个更清晰些，<strong>每次流式输出状态</strong>，在这里也就是消息队列，第二次流式输出，由于ai回复，增加了AIMessage，但还是把更新后的状态完整地输出出来</p>
<h3 id="updates-模式">updates 模式</h3>
<p>updates与values不同的是，只有<strong>状态出现更新</strong>时，才会流式输出</p>
<p>例如，如果你有一个调用一次工具的代理，你应该看到以下更新：</p>
<ul>
<li><strong>LLM 节点</strong> ：
<code>AIMessage</code>]带有工具调用请求</li>
<li><strong>工具节点</strong> ：
<code>ToolMessage</code>带有执行结果</li>
<li><strong>LLM 节点</strong> ：最终 AI 响应</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 流式模式 = updates</span><br><span class="line">for step in agent.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me a Dad joke&quot;&#125;]&#125;,</span><br><span class="line">    stream_mode=&quot;updates&quot;,</span><br><span class="line">):</span><br><span class="line">    print(step)</span><br><span class="line">    print(&quot;-----&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;model&#x27;: &#123;&#x27;messages&#x27;: [AIMessage(content=&quot;Why don&#x27;t skeletons fight each other?\n\nBecause they don’t have the guts! 💀\n\n*(leans in with a cheesy grin, then mimes pulling out imaginary intestines like party streamers)*  \n...Get it? *Guts?* 😏&quot;, additional_kwargs=&#123;&#x27;refusal&#x27;: None&#125;, response_metadata=&#123;&#x27;token_usage&#x27;: &#123;&#x27;completion_tokens&#x27;: 52, &#x27;prompt_tokens&#x27;: 24, &#x27;total_tokens&#x27;: 76, &#x27;completion_tokens_details&#x27;: None, &#x27;prompt_tokens_details&#x27;: &#123;&#x27;audio_tokens&#x27;: None, &#x27;cached_tokens&#x27;: 0&#125;&#125;, &#x27;model_provider&#x27;: &#x27;dashscope&#x27;, &#x27;model_name&#x27;: &#x27;qwen3-max&#x27;, &#x27;system_fingerprint&#x27;: None, &#x27;id&#x27;: &#x27;chatcmpl-b18ac1df-986c-4ddb-a6a1-8fbc6f191484&#x27;, &#x27;finish_reason&#x27;: &#x27;stop&#x27;, &#x27;logprobs&#x27;: None&#125;, id=&#x27;lc_run--be9f295b-3202-47e2-8d79-ef34fe1d8bbe-0&#x27;, usage_metadata=&#123;&#x27;input_tokens&#x27;: 24, &#x27;output_tokens&#x27;: 52, &#x27;total_tokens&#x27;: 76, &#x27;input_token_details&#x27;: &#123;&#x27;cache_read&#x27;: 0&#125;, &#x27;output_token_details&#x27;: &#123;&#125;&#125;)]&#125;&#125;</span><br><span class="line">-----</span><br></pre></td></tr></table></figure>
<h3 id="messages-模式"><strong>messages 模式</strong></h3>
<p>使用 <code>messages</code>
流式模式从你的图中的任何部分（包括节点、工具、子图或任务）流式传输大型语言模型（LLM）的输出，
<strong>逐个 token</strong>。来自 <a href="https://docs.langchain.com/oss/python/langgraph/streaming#supported-stream-modes"><code>messages</code>
模式</a>的流式输出是一个元组
<code>(message_chunk, metadata)</code>，其中：</p>
<ul>
<li><code>message_chunk</code>：来自 LLM 的 token 或消息片段。</li>
<li><code>metadata</code>：一个包含有关图节点和 LLM
调用详情的字典。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for token, metadata in agent.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Write me a family friendly poem.&quot;&#125;]&#125;,</span><br><span class="line">    stream_mode=&quot;messages&quot;,</span><br><span class="line">):</span><br><span class="line">    print(f&quot;&#123;token.content&#125;&quot;, end=&quot;&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">content=&#x27;&#x27; additional_kwargs=&#123;&#125; response_metadata=&#123;&#x27;model_provider&#x27;: &#x27;dashscope&#x27;&#125; id=&#x27;lc_run--1b5367ee-8576-4b09-841b-4b97528f04cf&#x27;</span><br><span class="line">-----</span><br><span class="line">content=&#x27;哎&#x27; additional_kwargs=&#123;&#125; response_metadata=&#123;&#x27;model_provider&#x27;: &#x27;dashscope&#x27;&#125; id=&#x27;lc_run--1b5367ee-8576-4b09-841b-4b97528f04cf&#x27;</span><br><span class="line">-----</span><br><span class="line">content=&#x27;哟！&#x27; additional_kwargs=&#123;&#125; response_metadata=&#123;&#x27;model_provider&#x27;: &#x27;dashscope&#x27;&#125; id=&#x27;lc_run--1b5367ee-8576-4b09-841b-4b97528f04cf&#x27;</span><br><span class="line">-----</span><br><span class="line">content=&#x27;可&#x27; additional_kwargs=&#123;&#125; response_metadata=&#123;&#x27;model_provider&#x27;: &#x27;dashscope&#x27;&#125; id=&#x27;lc_run--1b5367ee-8576-4b09-841b-4b97528f04cf&#x27;</span><br><span class="line">-----</span><br><span class="line">content=&#x27;算等到&#x27; additional_kwargs=&#123;&#125; response_metadata=&#123;&#x27;model_provider&#x27;: &#x27;dashscope&#x27;&#125; id=&#x27;lc_run--1b5367ee-8576-4b09-841b-4b97528f04cf&#x27;</span><br><span class="line">-----</span><br><span class="line">content=&#x27;你了！我刚刚&#x27; additional_kwargs=&#123;&#125; response_metadata=&#123;&#x27;model_provider&#x27;: &#x27;dashscope&#x27;&#125; id=&#x27;lc_run--1b5367ee-8576-4b09-841b-4b97528f04cf&#x27;</span><br><span class="line">-----</span><br><span class="line">content=&#x27;还在后台急得直跺&#x27; additional_kwargs=&#123;&#125; response_metadata=&#123;&#x27;model_provider&#x27;: &#x27;dashscope&#x27;&#125; id=&#x27;lc_run--1b5367ee-8576-4b09-841b-4b97528f04cf&#x27;</span><br><span class="line">-----</span><br></pre></td></tr></table></figure>
<h3 id="流式传输多种模式">流式传输多种模式</h3>
<p>你可以将一个列表作为 <code>stream_mode</code>
参数，一次性流式传输多种模式。</p>
<p>流式输出将是 <code>(mode, chunk)</code>
元组，其中<code>mode</code>是流式模式的名字，<code>chunk</code>是该模式流式传输的数据。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for mode, chunk in graph.stream(inputs, stream_mode=[&quot;updates&quot;, &quot;custom&quot;]):</span><br><span class="line">    print(chunk)</span><br></pre></td></tr></table></figure>
<p><code>(mode, chunk)</code> 元组的示例结构如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&#x27;values&#x27;, &#123;&#x27;messages&#x27;: [HumanMessage(content=&#x27;What is the weather in SF?&#x27;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#x27;0f0b79db-5e22-419f-ab04-128853a7e84d&#x27;)]&#125;)</span><br><span class="line">(&#x27;custom&#x27;, &#x27;Looking up data for city: SF&#x27;)</span><br></pre></td></tr></table></figure>
<h3 id="custom-模式">custom 模式</h3>
<p>要在 LangGraph 节点或工具内部发送 <strong>自定义用户定义数据</strong>
，请按照以下步骤操作：</p>
<ol type="1">
<li>使用 <a href="https://reference.langchain.com/python/langgraph/config/#langgraph.config.get_stream_writer"><code>get_stream_writer</code></a>
访问流写入器并发出自定义数据。</li>
<li>在调用 <code>.stream()</code> 或 <code>.astream()</code> 时设置
<code>stream_mode="custom"</code>，以便在流中获取自定义数据。您可以组合多种模式（例如，<code>["updates", "custom"]</code>），但至少必须有一个是
<code>"custom"</code>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.agents import create_agent</span><br><span class="line">from langgraph.config import get_stream_writer</span><br><span class="line"></span><br><span class="line">def get_weather(city: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定城市的天气。&quot;&quot;&quot;</span><br><span class="line">    writer = get_stream_writer()</span><br><span class="line">    # 可流式输出任意自定义数据</span><br><span class="line">    writer(f&quot;Looking up data for city: &#123;city&#125;&quot;)    # 推送实时更新（会出现在 stream 的 custom channel）</span><br><span class="line">    # ...执行耗时操作（HTTP 请求、爬取等）</span><br><span class="line">    writer(f&quot;Acquired data for city: &#123;city&#125;&quot;)      # 再次推送进度</span><br><span class="line">    return f&quot;It&#x27;s always sunny in &#123;city&#125;!&quot;         # 常规返回（会作为 ToolMessage / Tool 的输出被捕获）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">agent = create_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[get_weather],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 调用端：同时订阅 values（完整状态）和 custom（工具 writer 输出）</span><br><span class="line">for mode, chunk in agent.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the weather in SF?&quot;&#125;]&#125;,</span><br><span class="line">    stream_mode=[&quot;values&quot;, &quot;custom&quot;],   # 同时请求两类流</span><br><span class="line">):</span><br><span class="line">    if mode == &quot;values&quot;:</span><br><span class="line">        # chunk 是当前完整 state 快照（通常包含 messages 列表）</span><br><span class="line">        print(&quot;LATEST:&quot;, chunk[&quot;messages&quot;][-1])</span><br><span class="line">        print(type(chunk[&quot;messages&quot;][-1]))</span><br><span class="line">    else:</span><br><span class="line">        # mode == &quot;custom&quot;: chunk 是工具 writer 推送的文本（或自定义结构）</span><br><span class="line">        print(&quot;TOOL STREAM:&quot;, chunk)</span><br><span class="line">    print(&quot;-----&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LATEST: content=&#x27;What is the weather in SF?&#x27; additional_kwargs=&#123;&#125; response_metadata=&#123;&#125; id=&#x27;a30e826d-8ab9-4287-a28a-d5ce79617bcd&#x27;</span><br><span class="line">&lt;class &#x27;langchain_core.messages.human.HumanMessage&#x27;&gt;</span><br><span class="line">-----</span><br><span class="line">LATEST: content=&#x27;&#x27; additional_kwargs=&#123;&#x27;refusal&#x27;: None&#125; response_metadata=&#123;&#x27;token_usage&#x27;: &#123;&#x27;completion_tokens&#x27;: 21, &#x27;prompt_tokens&#x27;: 266, &#x27;total_tokens&#x27;: 287, &#x27;completion_tokens_details&#x27;: None, &#x27;prompt_tokens_details&#x27;: &#123;&#x27;audio_tokens&#x27;: None, &#x27;cached_tokens&#x27;: 0&#125;&#125;, &#x27;model_provider&#x27;: &#x27;dashscope&#x27;, &#x27;model_name&#x27;: &#x27;qwen3-max&#x27;, &#x27;system_fingerprint&#x27;: None, &#x27;id&#x27;: &#x27;chatcmpl-23cb42ff-3d21-4a81-8ec5-44e0650307a6&#x27;, &#x27;finish_reason&#x27;: &#x27;tool_calls&#x27;, &#x27;logprobs&#x27;: None&#125; id=&#x27;lc_run--b44564e9-3368-46ae-9e5d-46773a801329-0&#x27; tool_calls=[&#123;&#x27;name&#x27;: &#x27;get_weather&#x27;, &#x27;args&#x27;: &#123;&#x27;city&#x27;: &#x27;SF&#x27;&#125;, &#x27;id&#x27;: &#x27;call_70a8894b68e744fca508db9c&#x27;, &#x27;type&#x27;: &#x27;tool_call&#x27;&#125;] usage_metadata=&#123;&#x27;input_tokens&#x27;: 266, &#x27;output_tokens&#x27;: 21, &#x27;total_tokens&#x27;: 287, &#x27;input_token_details&#x27;: &#123;&#x27;cache_read&#x27;: 0&#125;, &#x27;output_token_details&#x27;: &#123;&#125;&#125;</span><br><span class="line">&lt;class &#x27;langchain_core.messages.ai.AIMessage&#x27;&gt;</span><br><span class="line">-----</span><br><span class="line">TOOL STREAM: Looking up data for city: SF</span><br><span class="line">-----</span><br><span class="line">TOOL STREAM: Acquired data for city: SF</span><br><span class="line">-----</span><br><span class="line">LATEST: content=&quot;It&#x27;s always sunny in SF!&quot; name=&#x27;get_weather&#x27; id=&#x27;d43e7aac-d1e1-4432-8709-666e1647c412&#x27; tool_call_id=&#x27;call_70a8894b68e744fca508db9c&#x27;</span><br><span class="line">&lt;class &#x27;langchain_core.messages.tool.ToolMessage&#x27;&gt;</span><br><span class="line">-----</span><br><span class="line">LATEST: content=&quot;The weather in San Francisco (SF) is always sunny! Let me know if you&#x27;d like more details or updates. 😊&quot; additional_kwargs=&#123;&#x27;refusal&#x27;: None&#125; response_metadata=&#123;&#x27;token_usage&#x27;: &#123;&#x27;completion_tokens&#x27;: 26, &#x27;prompt_tokens&#x27;: 308, &#x27;total_tokens&#x27;: 334, &#x27;completion_tokens_details&#x27;: None, &#x27;prompt_tokens_details&#x27;: &#123;&#x27;audio_tokens&#x27;: None, &#x27;cached_tokens&#x27;: 0&#125;&#125;, &#x27;model_provider&#x27;: &#x27;dashscope&#x27;, &#x27;model_name&#x27;: &#x27;qwen3-max&#x27;, &#x27;system_fingerprint&#x27;: None, &#x27;id&#x27;: &#x27;chatcmpl-5b146ff6-cd99-493d-83d4-ac84a456c678&#x27;, &#x27;finish_reason&#x27;: &#x27;stop&#x27;, &#x27;logprobs&#x27;: None&#125; id=&#x27;lc_run--0daa8b02-2207-4acd-abc5-79c7cc79882f-0&#x27; usage_metadata=&#123;&#x27;input_tokens&#x27;: 308, &#x27;output_tokens&#x27;: 26, &#x27;total_tokens&#x27;: 334, &#x27;input_token_details&#x27;: &#123;&#x27;cache_read&#x27;: 0&#125;, &#x27;output_token_details&#x27;: &#123;&#125;&#125;</span><br><span class="line">&lt;class &#x27;langchain_core.messages.ai.AIMessage&#x27;&gt;</span><br><span class="line">-----</span><br></pre></td></tr></table></figure>
<p>流式消息在时间线上的典型顺序（示例）：</p>
<ol type="1">
<li>模型生成 <code>AIMessage</code> 并发出工具调用（含 tool_call
id）</li>
<li>流中先返回 <code>values</code> 快照（显示模型决定调用工具）</li>
<li>工具开始运行并用 <code>stream_writer</code> 推送若干
<code>custom</code> 更新（这些会以 <code>mode="custom"</code>
到达）</li>
<li>工具完成并返回 <code>ToolMessage</code>（最终的工具结果）</li>
<li>模型看到 <code>ToolMessage</code> 后生成最终
<code>AIMessage</code>（最终回答），最新 <code>values</code>
会包含这个结果</li>
</ol>
<blockquote>
<p>在 LangChain 的 <code>AIMessage</code> 对象中，<strong>只要
<code>tool_calls</code> 字段非空（即
<code>len(message.tool_calls) &gt; 0</code>）</strong>，就表示模型决定调用一个或多个工具。</p>
</blockquote>
<h2 id="lesson-4-tools">Lesson 4: Tools</h2>
<p>工具是代理调用来执行操作的组件。它们通过允许模型通过定义良好的输入和输出来与世界交互，从而扩展模型的功能。</p>
<p>工具封装了一个可调用函数及其输入模式。这些可以传递给兼容的聊天模型，允许模型决定是否调用工具以及使用什么参数。在这些场景中，工具调用使模型能够生成符合指定输入模式的请求。</p>
<h3 id="工具的创建">工具的创建</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Literal</span><br><span class="line"></span><br><span class="line">from langchain.tools import tool</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@tool(</span><br><span class="line">    &quot;calculator&quot;,</span><br><span class="line">    parse_docstring=True,</span><br><span class="line">    description=(</span><br><span class="line">        &quot;对两个实数执行基础算术运算。&quot;</span><br><span class="line">        &quot;当你需要对任何数字进行运算时都可以使用，即便是整数。&quot;</span><br><span class="line">    ),</span><br><span class="line">)</span><br><span class="line">def real_number_calculator(</span><br><span class="line">    a: float, b: float, operation: Literal[&quot;add&quot;, &quot;subtract&quot;, &quot;multiply&quot;, &quot;divide&quot;]</span><br><span class="line">) -&gt; float:</span><br><span class="line">    &quot;&quot;&quot;对两个实数执行基础算术运算。</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a (float): 第一个操作数。</span><br><span class="line">        b (float): 第二个操作数。</span><br><span class="line">        operation (Literal[&#x27;add&#x27;,&#x27;subtract&#x27;,&#x27;multiply&#x27;,&#x27;divide&#x27;]): 要执行的操作。</span><br><span class="line"></span><br><span class="line">    Returns:</span><br><span class="line">        float: 计算结果。</span><br><span class="line"></span><br><span class="line">    Raises:</span><br><span class="line">        ValueError: 当操作无效或尝试被零除时抛出。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    print(&quot;🧮  调用计算器工具&quot;)</span><br><span class="line">    # 执行指定的运算</span><br><span class="line">    if operation == &quot;add&quot;:</span><br><span class="line">        return a + b</span><br><span class="line">    elif operation == &quot;subtract&quot;:</span><br><span class="line">        return a - b</span><br><span class="line">    elif operation == &quot;multiply&quot;:</span><br><span class="line">        return a * b</span><br><span class="line">    elif operation == &quot;divide&quot;:</span><br><span class="line">        if b == 0:</span><br><span class="line">            raise ValueError(&quot;不允许被零除。&quot;)</span><br><span class="line">        return a / b</span><br><span class="line">    else:</span><br><span class="line">        raise ValueError(f&quot;无效的操作: &#123;operation&#125;&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>创建工具最简单的方法是使用 <a href="https://reference.langchain.com/python/langchain/tools/#langchain.tools.tool"><code>@tool</code></a>
装饰器。默认情况下，函数的文档字符串成为工具的描述，帮助模型理解何时使用它</p>
<p>类型提示是<strong>必需的</strong>
，因为它们定义了工具的输入模式。文档字符串应具有信息量且简洁，以帮助模型理解工具的用途。</p>
<p>LangChain 也支持更丰富的描述，下面的示例使用了一种方式：Google
风格的参数描述。配合 <code>parse_docstring=True</code>
使用时，会解析并将参数描述传递给模型。你可以重命名工具并修改其描述。</p>
<h3 id="工具访问上下文">工具访问上下文</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">参数名称</th>
<th style="text-align: left;">用途</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>config</code></td>
<td style="text-align: left;">保留用于内部传递
<code>RunnableConfig</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>runtime</code></td>
<td style="text-align: left;">保留用于 <code>ToolRuntime</code>
参数（访问状态、上下文、存储）</td>
</tr>
</tbody>
</table>
<p>工具可以通过 <code>ToolRuntime</code>
参数访问运行时信息，该参数提供：</p>
<ul>
<li><strong>状态State</strong> -
在执行过程中流动的可变数据（例如，消息、计数器、自定义字段）</li>
<li><strong>上下文Context</strong> - 不可变的配置，如用户
ID、会话详情或特定应用的配置</li>
<li><strong>存储Store</strong> - 跨对话的持久长期记忆</li>
<li><strong>流式写入器Stream Writer</strong>-
在工具执行时流式传输自定义更新</li>
<li><strong>配置Config</strong> - <code>RunnableConfig</code>
用于执行</li>
<li><strong>工具调用 ID Tool Call ID</strong> - 当前工具调用的 ID</li>
</ul>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20251203175228797.png" alt="image-20251203175228797">
<figcaption aria-hidden="true">image-20251203175228797</figcaption>
</figure>
<p>详细查看文档<a href="https://docs.langchain.com/oss/python/langchain/tools#create-tools">Tools
- Docs by LangChain</a></p>
<h3 id="调用工具运算">调用工具运算</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.agents import create_agent</span><br><span class="line"></span><br><span class="line">agent = create_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[real_number_calculator],</span><br><span class="line">    system_prompt=&quot;You are a helpful assistant&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">result = agent.invoke(&#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is 3.0 * 4.0&quot;&#125;]&#125;)</span><br><span class="line">print(result[&quot;messages&quot;][-1].content)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">result = agent.invoke(&#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is 3.0 * 4.0&quot;&#125;]&#125;)</span><br><span class="line">print(result[&quot;messages&quot;][-1].content)</span><br></pre></td></tr></table></figure>
<p>https://smith.langchain.com/public/d5162eac-47d1-421e-adb9-bf6b223b5618/r</p>
<h2 id="lesson-5-tools-with-mcp">Lesson 5: Tools with MCP</h2>
<p>模型上下文协议（MCP）为 AI
代理连接外部工具和数据源提供了标准化方式。让我们用
<code>langchain-mcp-adapters</code> 连接一个 MCP 服务器。</p>
<p>mcp的相关知识这里就不介绍了</p>
<h3 id="mcp工具的获取">mcp工具的获取</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_mcp_adapters.client import MultiServerMCPClient</span><br><span class="line">import nest_asyncio</span><br><span class="line"></span><br><span class="line">nest_asyncio.apply()</span><br><span class="line"></span><br><span class="line"># 连接 mcp-time 服务器以进行时区相关操作</span><br><span class="line"># 该 Go 服务器提供当前时间、相对时间解析、</span><br><span class="line"># 时区转换、时长计算与时间比较等工具</span><br><span class="line">mcp_client = MultiServerMCPClient(</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;time&quot;: &#123;</span><br><span class="line">      &quot;transport&quot;: &quot;streamable_http&quot;,</span><br><span class="line">      &quot;url&quot;: &quot;https://mcp.api-inference.modelscope.net/adcc1ca6e6d642/mcp&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 从 MCP 服务器加载工具</span><br><span class="line">mcp_tools = await mcp_client.get_tools()</span><br><span class="line">print(f&quot;Loaded &#123;len(mcp_tools)&#125; MCP tools: &#123;[t.name for t in mcp_tools]&#125;&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Loaded 2 MCP tools: [&#x27;get_current_time&#x27;, &#x27;convert_time&#x27;]</span><br></pre></td></tr></table></figure>
<p>这里看到可以获取两个mcp工具</p>
<h3 id="调用">调用</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">result = await agent_with_mcp.ainvoke(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What&#x27;s the time in SF right now?&quot;&#125;]&#125;</span><br><span class="line">)</span><br><span class="line">for msg in result[&quot;messages&quot;]:</span><br><span class="line">    msg.pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">What&#x27;s the time in SF right now?</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  get_current_time (call_719ae124b2b242fd8648fb27)</span><br><span class="line"> Call ID: call_719ae124b2b242fd8648fb27</span><br><span class="line">  Args:</span><br><span class="line">    timezone: America/Los_Angeles</span><br><span class="line">================================= Tool Message =================================</span><br><span class="line">Name: get_current_time</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;timezone&quot;: &quot;America/Los_Angeles&quot;,</span><br><span class="line">  &quot;datetime&quot;: &quot;2025-12-03T02:27:23-08:00&quot;,</span><br><span class="line">  &quot;day_of_week&quot;: &quot;Wednesday&quot;,</span><br><span class="line">  &quot;is_dst&quot;: false</span><br><span class="line">&#125;</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">The current time in San Francisco is 2:27 AM on Wednesday, December 3, 2025.</span><br></pre></td></tr></table></figure>
<h2 id="lesson-6-memory">Lesson 6: Memory</h2>
<p><strong>Memory 是让 Agent 记住先前交互信息的系统，分为</strong>
<strong>短时记忆（Short-term Memory）</strong> 和
<strong>长时记忆（Long-term Memory）</strong> <strong>两种。</strong>
它让 Agent 能记住用户偏好、对话历史，实现个性化交互。</p>
<p>LangGraph支持两种对于构建对话代理至关重要的内存类型：</p>
<ul>
<li><strong><a href="https://github.langchain.ac.cn/langgraph/agents/memory/#short-term-memory">短期内存</a></strong>：通过在会话中维护消息历史来跟踪正在进行的对话。</li>
<li><strong><a href="https://github.langchain.ac.cn/langgraph/agents/memory/#long-term-memory">长期内存</a></strong>：在不同会话之间存储用户特定或应用程序级别的数据。</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">特性</th>
<th style="text-align: left;">Checkpointer</th>
<th style="text-align: left;">Store</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>范围</strong></td>
<td style="text-align: left;">单线程完整状态</td>
<td style="text-align: left;">跨线程 key-value</td>
</tr>
<tr>
<td style="text-align: left;"><strong>自动保存</strong></td>
<td style="text-align: left;">每个 super-step</td>
<td style="text-align: left;">手动调用</td>
</tr>
<tr>
<td style="text-align: left;"><strong>用途</strong></td>
<td style="text-align: left;">对话历史、时间旅行</td>
<td style="text-align: left;">用户偏好、配置</td>
</tr>
<tr>
<td style="text-align: left;"><strong>访问</strong></td>
<td style="text-align: left;"><code>thread_id</code></td>
<td style="text-align: left;"><code>namespace + key</code></td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20250715094855646.png" alt="image-20250715094855646">
<figcaption aria-hidden="true">image-20250715094855646</figcaption>
</figure>
<p>在LangGraph中</p>
<ul>
<li><em>短期内存</em>也称为<strong>线程级内存</strong>。</li>
<li><em>长期内存</em>也称为<strong>跨线程内存</strong>。</li>
</ul>
<h3 id="添加记忆">添加记忆</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.checkpoint.memory import InMemorySaver</span><br><span class="line">from langchain.agents import create_agent</span><br><span class="line">from langchain_core.messages import SystemMessage</span><br><span class="line"></span><br><span class="line">agent = create_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[execute_sql],</span><br><span class="line">    system_prompt=SYSTEM_PROMPT,</span><br><span class="line">    context_schema=RuntimeContext,</span><br><span class="line">    checkpointer=InMemorySaver(),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>在langchain中，短期记忆的机制我们称之为<strong>checkpointer</strong>，以上代码中，我们添加了<strong>InMemorySaver</strong>作为checkpointer，其作用机制为<strong>将
checkpoint
数据保存在进程内存中（字典结构），进程结束即丢失。</strong></p>
<p>如果想上生产环境，推荐使用如<strong><code>from langgraph.checkpoint.postgres import PostgresSaver</code></strong>
进行持久化存储</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">question = &quot;This is Frank Harris, What was the total on my last invoice?&quot;</span><br><span class="line">steps = []</span><br><span class="line"></span><br><span class="line">for step in agent.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: question&#125;]&#125;,</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">    context=RuntimeContext(db=db),</span><br><span class="line">):</span><br><span class="line">    step[&quot;messages&quot;][-1].pretty_print()</span><br><span class="line">    steps.append(step)</span><br></pre></td></tr></table></figure>
<p>在这个例子中，在添加checkpointer后，第一次调用时模型会<strong>进行tool
call进行sql查询</strong>，第二次调用时，模型有了记忆，便<strong>直接进行回复</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">我是弗兰克·哈里斯，我上一张发票的总金额是多少?</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">弗兰克，您上一张发票的总金额是 **$5.94**。</span><br></pre></td></tr></table></figure>
<h2 id="lesson-7-structured-output">Lesson 7: Structured Output</h2>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20251204090512625.png" alt="image-20251204090512625">
<figcaption aria-hidden="true">image-20251204090512625</figcaption>
</figure>
<p>结构化输出允许代理以特定的、可预测的格式返回数据。你无需解析自然语言响应，而是直接获得应用程序可以直接使用的
JSON 对象、Pydantic 模型或数据类等结构化数据。</p>
<p>LangChain 的 <a href="https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent"><code>create_agent</code></a>
会自动处理结构化输出。用户设置所需的结构化输出模式，当模型生成结构化数据时，它会被捕获、验证，并以代理状态中的
<code>'structured_response'</code> 键返回。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.agents import create_agent</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ContactInfo(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;用户信息结构&quot;&quot;&quot;</span><br><span class="line">    name: str = Field(..., description=&quot;姓名&quot;)</span><br><span class="line">    email: str = Field(..., description=&quot;电子邮件&quot;)</span><br><span class="line">    phone: str = Field(..., description=&quot;电话号码&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">agent = create_agent(model=llm, response_format=ContactInfo)</span><br><span class="line"></span><br><span class="line">recorded_conversation = &quot;&quot;&quot; We talked with John Doe. He works over at Example. His number is, let&#x27;s see, </span><br><span class="line">five, five, five, one two three, four, five, six seven. Did you get that?</span><br><span class="line">And, his email was john at example.com. He wanted to order 50 boxes of Captain Crunch.&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">result = agent.invoke(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: recorded_conversation&#125;]&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 访问结构化响应</span><br><span class="line">result[&quot;structured_response&quot;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Pydantic 的 <code>Field(..., description="...")</code>
主要好处是</strong> <strong>自动生成高质量的工具描述、API
文档和模型提示</strong> <strong>，让 LLM
更好地理解字段含义，提高工具调用准确率。</strong></p>
</blockquote>
<p>虽然langchain支持大家使用其他方式进行结构化输出，我还是最推荐使用pydantic，原因如下</p>
<table>
<thead>
<tr>
<th style="text-align: left;">特性</th>
<th style="text-align: left;">TypedDict</th>
<th style="text-align: left;">Pydantic BaseModel</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>类型检查</strong></td>
<td style="text-align: left;">运行时无验证</td>
<td style="text-align: left;">运行时验证 + IDE 提示</td>
</tr>
<tr>
<td style="text-align: left;"><strong>验证</strong></td>
<td style="text-align: left;">❌ 无</td>
<td style="text-align: left;">✅ 内置验证（正则、长度、格式）</td>
</tr>
<tr>
<td style="text-align: left;"><strong>序列化</strong></td>
<td style="text-align: left;">手动</td>
<td style="text-align: left;"><code>model_dump()</code> /
<code>model_dump_json()</code></td>
</tr>
<tr>
<td style="text-align: left;"><strong>文档生成</strong></td>
<td style="text-align: left;">❌ 手动</td>
<td style="text-align: left;">✅ 自动（Field description）</td>
</tr>
<tr>
<td style="text-align: left;"><strong>错误处理</strong></td>
<td style="text-align: left;">静默失败</td>
<td style="text-align: left;">✅ 抛出 ValidationError</td>
</tr>
</tbody>
</table>
<h2 id="lesson-8-middleware">Lesson 8: <a href="https://docs.langchain.com/oss/python/langchain/middleware/overview">Middleware</a></h2>
<p><strong>Middleware是插入 Agent 执行流程的</strong>
<strong>可插拔组件</strong>
<strong>，用于在关键节点拦截、修改或增强数据流，实现</strong>
<strong>动态提示</strong> <strong>、</strong> <strong>状态管理</strong>
<strong>、</strong> <strong>错误处理</strong> <strong>、</strong>
<strong>工具控制</strong> <strong>等功能。</strong></p>
<p><strong>LangChain 中间件的设计就是</strong>
<strong>“即插即用”</strong>
<strong>，</strong>开发者在使用中间件的过程中，只需要关注中间件的功能与需求是否匹配，不需要关心中间件调用的位置。</p>
<p><strong><code>middleware</code> 参数是专为
<code>langchain.agents.create_agent()</code>
设计的</strong>，<strong>LangGraph
用节点+边替代了中间件，提供更细粒度控制和更好的性能</strong></p>
<figure>
<img src="/2025/12/02/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AE%98%E6%96%B9%E6%95%99%E7%A8%8B/image-20251204135208941.png" alt="image-20251204135208941">
<figcaption aria-hidden="true">image-20251204135208941</figcaption>
</figure>
<p><strong>LangChain 中间件有</strong> <strong>6种类型钩子</strong>
<strong>，分为</strong> <strong>节点式（Node-style）</strong>
<strong>和</strong> <strong>包装式（Wrap-style）</strong>
<strong>两大类。</strong></p>
<p>1️⃣ <strong>节点式钩子（Node-style Hooks）</strong></p>
<p><strong>顺序执行，用于日志、验证、状态更新。</strong></p>
<table>
<thead>
<tr>
<th style="text-align: left;">钩子名</th>
<th style="text-align: left;">执行时机</th>
<th style="text-align: left;">用途</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong><code>beforeAgent</code></strong></td>
<td style="text-align: left;">Agent 开始前（一次）</td>
<td style="text-align: left;">加载状态、验证输入</td>
</tr>
<tr>
<td style="text-align: left;"><strong><code>beforeModel</code></strong></td>
<td style="text-align: left;">模型调用前（每次）</td>
<td style="text-align: left;">修改提示、裁剪消息</td>
</tr>
<tr>
<td style="text-align: left;"><strong><code>afterModel</code></strong></td>
<td style="text-align: left;">模型调用后（每次）</td>
<td style="text-align: left;">验证输出、防护栏</td>
</tr>
<tr>
<td style="text-align: left;"><strong><code>afterAgent</code></strong></td>
<td style="text-align: left;">Agent 结束后（一次）</td>
<td style="text-align: left;">保存结果、清理</td>
</tr>
</tbody>
</table>
<p>2️⃣ <strong>包装式钩子（Wrap-style Hooks）</strong></p>
<p><strong>嵌套执行，控制 handler 调用次数（0/1/多次）。</strong></p>
<table>
<thead>
<tr>
<th style="text-align: left;">钩子名</th>
<th style="text-align: left;">执行时机</th>
<th style="text-align: left;">用途</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong><code>wrapModelCall</code></strong></td>
<td style="text-align: left;">包装模型调用</td>
<td style="text-align: left;">重试、缓存、转换</td>
</tr>
<tr>
<td style="text-align: left;"><strong><code>wrapToolCall</code></strong></td>
<td style="text-align: left;">包装工具调用</td>
<td style="text-align: left;">错误处理、权限</td>
</tr>
</tbody>
</table>
<p><code>wrapModelCall</code> vs <code>beforeModel</code> 区别</p>
<table>
<colgroup>
<col style="width: 18%">
<col style="width: 38%">
<col style="width: 43%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">特性</th>
<th style="text-align: left;"><code>beforeModel</code></th>
<th style="text-align: left;"><code>wrapModelCall</code></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>控制粒度</strong></td>
<td style="text-align: left;"><strong>只读</strong>：只能修改输入</td>
<td style="text-align: left;"><strong>完全控制</strong>：可修改输入输出</td>
</tr>
<tr>
<td style="text-align: left;"><strong>返回值</strong></td>
<td style="text-align: left;"><code>dict | None</code>（状态更新）</td>
<td style="text-align: left;"><code>AIMessage</code>（完整响应）</td>
</tr>
<tr>
<td style="text-align: left;"><strong>调用模型</strong></td>
<td style="text-align: left;">✅ <strong>必须调用</strong></td>
<td style="text-align: left;">✅ 可选调用</td>
</tr>
<tr>
<td style="text-align: left;"><strong>执行时机</strong></td>
<td style="text-align: left;"><strong>模型前</strong></td>
<td style="text-align: left;"><strong>模型前后</strong>（包装）</td>
</tr>
<tr>
<td style="text-align: left;"><strong>用途</strong></td>
<td style="text-align: left;">预处理（裁剪、日志）</td>
<td style="text-align: left;">控制流（重试、缓存）</td>
</tr>
</tbody>
</table>
<h3 id="dynamic-prompt-动态提示词">Dynamic Prompt 动态提示词</h3>
<p><strong>静态提示词无法适应不同的用户需求和运行时上下文，而动态提示词让你根据实际情况实时调整LLM的行为。</strong></p>
<p>想象你有一个客服助手。如果你用静态提示词，每个用户都会得到完全相同的回复风格。但实际上：</p>
<ul>
<li>专家用户想要深入的技术细节</li>
<li>新手用户需要简化的解释</li>
<li>VIP用户可能需要更高的优先级处理</li>
</ul>
<p>动态提示词就是在这一刻决定如何指导LLM。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SYSTEM_PROMPT_TEMPLATE = &quot;&quot;&quot;You are a careful SQLite analyst.</span><br><span class="line"></span><br><span class="line">Rules:</span><br><span class="line">- Think step-by-step.</span><br><span class="line">- When you need data, call the tool `execute_sql` with ONE SELECT query.</span><br><span class="line">- Read-only only; no INSERT/UPDATE/DELETE/ALTER/DROP/CREATE/REPLACE/TRUNCATE.</span><br><span class="line">- Limit to 5 rows unless the user explicitly asks otherwise.</span><br><span class="line">&#123;table_limits&#125;</span><br><span class="line">- If the tool returns &#x27;Error:&#x27;, revise the SQL and try again.</span><br><span class="line">- Prefer explicit column lists; avoid SELECT *.</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from langchain.agents.middleware.types import ModelRequest, dynamic_prompt</span><br><span class="line"></span><br><span class="line">@dynamic_prompt</span><br><span class="line">def dynamic_system_prompt(request: ModelRequest) -&gt; str:</span><br><span class="line">    if not request.runtime.context.is_employee:</span><br><span class="line">        table_limits = &quot;- Limit access to these tables: Album, Artist, Genre, Playlist, PlaylistTrack, Track.&quot;</span><br><span class="line">        #仅限访问这些表：Album、Artist、Genre、Playlist、PlaylistTrack、Track。</span><br><span class="line">    else:</span><br><span class="line">        table_limits = &quot;&quot;</span><br><span class="line"></span><br><span class="line">    return SYSTEM_PROMPT_TEMPLATE.format(table_limits=table_limits)</span><br></pre></td></tr></table></figure>
<p>构建动态提示词，根据<strong>is_employee</strong>的不同，构建不同的提示词</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.agents import create_agent</span><br><span class="line"></span><br><span class="line">agent = create_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[execute_sql],</span><br><span class="line">    middleware=[dynamic_system_prompt],</span><br><span class="line">    context_schema=RuntimeContext,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>作为中间件加入create_agent</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">question = &quot;Frank Harris 最昂贵的一次购买是什么？&quot;</span><br><span class="line"></span><br><span class="line">for step in agent.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: question&#125;]&#125;,</span><br><span class="line">    context=RuntimeContext(is_employee=False, db=db),</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">):</span><br><span class="line">    step[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>当<strong><code>is_employee=False</code></strong>的回复</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">Frank Harris 最昂贵的一次购买是什么？</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">要确定 Frank Harris 最昂贵的一次购买，我们需要查看与他相关的购买记录。然而，在当前可访问的表（Album、Artist、Genre、Playlist、PlaylistTrack、Track）中，并没有包含客户信息或购买记录的表（如 Customer 或 Invoice）。因此，无法直接查询 Frank Harris 的购买信息。</span><br><span class="line"></span><br><span class="line">如果您有其他相关表的信息或更多上下文，请提供进一步的细节！</span><br></pre></td></tr></table></figure>
<p>当<strong><code>is_employee=True</code></strong>的回复</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">Frank Harris 最昂贵的一次购买是什么？</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">我需要找出 Frank Harris 最昂贵的一次购买。首先，我需要确认数据库中是否有包含客户姓名和购买信息的表。</span><br><span class="line">Tool Calls:</span><br><span class="line">  execute_sql (call_9d0bb26b2b5b4d5ca2a24584)</span><br><span class="line"> Call ID: call_9d0bb26b2b5b4d5ca2a24584</span><br><span class="line">  Args:</span><br><span class="line">    query: SELECT name FROM sqlite_master WHERE type=&#x27;table&#x27;;</span><br><span class="line">================================= Tool Message =================================</span><br><span class="line">Name: execute_sql</span><br><span class="line"></span><br><span class="line">[(&#x27;Album&#x27;,), (&#x27;Artist&#x27;,), (&#x27;Customer&#x27;,), (&#x27;Employee&#x27;,), (&#x27;Genre&#x27;,), (&#x27;Invoice&#x27;,), (&#x27;InvoiceLine&#x27;,), (&#x27;MediaType&#x27;,), (&#x27;Playlist&#x27;,), (&#x27;PlaylistTrack&#x27;,), (&#x27;Track&#x27;,)]</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">我看到有 `Customer` 表和 `Invoice` 表，可能还有 `InvoiceLine` 表包含购买详情。首先，我会查看 `Customer` 表的结构，以确认如何找到 Frank Harris。</span><br><span class="line">Tool Calls:</span><br><span class="line">  execute_sql (call_7bfbcb4928be435ab7bda4c0)</span><br><span class="line"> Call ID: call_7bfbcb4928be435ab7bda4c0</span><br><span class="line">  Args:</span><br><span class="line">    query: PRAGMA table_info(Customer);</span><br><span class="line">================================= Tool Message =================================</span><br><span class="line">Name: execute_sql</span><br><span class="line">...</span><br><span class="line">[(145, &#x27;2010-09-23 00:00:00&#x27;, 13.86)]</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">Frank Harris 最昂贵的一次购买是发票号 145，日期为 2010-09-23，总金额为 13.86。</span><br></pre></td></tr></table></figure>
<h2 id="lesson-9-human-in-the-loop">Lesson 9: Human in the Loop</h2>
<p>人机回路（HITL）<a href="https://docs.langchain.com/oss/python/langchain/middleware/built-in#human-in-the-loop">中间件</a>允许您为代理工具调用添加人工监督。当模型提议一个可能需要审核的操作时——例如，写入文件或执行
SQL——中间件可以暂停执行并等待决策。</p>
<p>它通过将每个工具调用与可配置的策略进行比对来实现这一点。如果需要干预，中间件会发出一个<a href="https://reference.langchain.com/python/langgraph/types/#langgraph.types.interrupt">中断</a>信号来停止执行。图状态会使用
LangGraph 的<a href="https://docs.langchain.com/oss/python/langgraph/persistence">持久化层</a>进行保存，因此执行可以安全地暂停并在稍后继续。</p>
<p>然后由人工决策决定下一步的操作：操作可以原样批准（<code>approve</code>）、在运行前进行修改（<code>edit</code>），或附带反馈被拒绝（<code>reject</code>）。</p>
<h3 id="interrupt-决策类型">Interrupt 决策类型</h3>
<p><a href="https://docs.langchain.com/oss/python/langchain/middleware/built-in#human-in-the-loop">中间件</a>定义了三种人类可以响应中断的方式：</p>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 49%">
<col style="width: 36%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">决策类型</th>
<th style="text-align: left;">描述</th>
<th style="text-align: left;">示例用例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">✅ <code>approve</code></td>
<td style="text-align: left;">操作按原样批准并执行，无需更改。</td>
<td style="text-align: left;">按原文发送邮件草稿</td>
</tr>
<tr>
<td style="text-align: left;">✏️ <code>edit</code></td>
<td style="text-align: left;">工具调用已修改后执行。</td>
<td style="text-align: left;">发送邮件前更改收件人</td>
</tr>
<tr>
<td style="text-align: left;">❌ <code>reject</code></td>
<td style="text-align: left;">工具调用被拒绝，并在对话中添加了说明。</td>
<td style="text-align: left;">拒绝邮件草稿并解释如何重写它</td>
</tr>
</tbody>
</table>
<p>每种工具可用的决策类型取决于你在 <code>interrupt_on</code>
中配置的策略。当多个工具调用同时被暂停时，每个操作都需要单独的决策。决策必须按照中断请求中操作出现的顺序提供。</p>
<h3 id="配置interrupt">配置Interrupt</h3>
<p>要使用 HITL，在创建代理时，将 <a href="https://docs.langchain.com/oss/python/langchain/middleware/built-in#human-in-the-loop">中间件</a>添加到代理的
<strong><code>middleware</code> 列表</strong>中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.agents import create_agent</span><br><span class="line">from langchain.agents.middleware import HumanInTheLoopMiddleware</span><br><span class="line">from langgraph.checkpoint.memory import InMemorySaver</span><br><span class="line"></span><br><span class="line">agent = create_agent(</span><br><span class="line">    model=llm,</span><br><span class="line">    tools=[execute_sql],</span><br><span class="line">    system_prompt=SYSTEM_PROMPT,</span><br><span class="line">    checkpointer=InMemorySaver(),</span><br><span class="line">    context_schema=RuntimeContext,</span><br><span class="line">    middleware=[</span><br><span class="line">        HumanInTheLoopMiddleware(</span><br><span class="line">        interrupt_on=&#123;</span><br><span class="line">        &quot;execute_sql&quot;: &#123;#工具的名称。当agent尝试调用这个工具时，中间件会拦截</span><br><span class="line">            &quot;allowed_decisions&quot;: [&quot;approve&quot;, &quot;reject&quot;]#这个工具允许的人工决定类型</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">),</span><br><span class="line">    ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="产生中断并恢复">产生中断并恢复</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.types import Command</span><br><span class="line"></span><br><span class="line">question = &quot;What are the names of all the employees?&quot;</span><br><span class="line">#所有员工的姓名是什么？</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">result = agent.invoke(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: question&#125;]&#125;,</span><br><span class="line">    config=config,</span><br><span class="line">    context=RuntimeContext(db=db)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">if &quot;__interrupt__&quot; in result:# 检查执行结果中是否存在中断</span><br><span class="line">    # 获取最后一个中断对象的值</span><br><span class="line">    # result[&#x27;__interrupt__&#x27;] 是一个列表，包含所有中断</span><br><span class="line">     # [&#x27;action_requests&#x27;] 获取需要审核的操作列表</span><br><span class="line">    description = result[&#x27;__interrupt__&#x27;][-1].value[&#x27;action_requests&#x27;][-1][&#x27;description&#x27;]</span><br><span class="line">    print(f&quot;\033[1;3;31m&#123;80 * &#x27;-&#x27;&#125;\033[0m&quot;)</span><br><span class="line">    print(</span><br><span class="line">        f&quot;\033[1;3;31m Interrupt:&#123;description&#125;\033[0m&quot;</span><br><span class="line">    )</span><br><span class="line">    print(result[&#x27;__interrupt__&#x27;][-1])</span><br><span class="line">    # 调用agent继续执行，传入人工的审核决定</span><br><span class="line">    result = agent.invoke(</span><br><span class="line">        Command(# 使用Command对象恢复暂停的对话</span><br><span class="line">            resume=&#123;# resume字段包含人工的决定列表</span><br><span class="line">                &quot;decisions&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 决定类型：拒绝该操作</span><br><span class="line">                        &quot;type&quot;: &quot;reject&quot;,</span><br><span class="line">                        # 拒绝的原因（会作为反馈发给agent）</span><br><span class="line">                        &quot;message&quot;: &quot;the database is offline.&quot;#数据库已离线。</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        ),</span><br><span class="line">        config=config,  # 使用相同的线程 ID 以恢复暂停的对话</span><br><span class="line">        context=RuntimeContext(db=db),</span><br><span class="line">    )</span><br><span class="line">    print(f&quot;\033[1;3;31m&#123;80 * &#x27;-&#x27;&#125;\033[0m&quot;)</span><br><span class="line"></span><br><span class="line">print(result[&quot;messages&quot;][-1].content)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--------------------------------------------------------------------------------</span><br><span class="line"> Interrupt:Tool execution requires approval</span><br><span class="line"></span><br><span class="line">Tool: execute_sql</span><br><span class="line">Args: &#123;&#x27;query&#x27;: &#x27;SELECT name FROM employees;&#x27;&#125;</span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line">The database is currently offline. Please try again later.</span><br></pre></td></tr></table></figure>
<p>重要概念：<strong><code>__interrupt__</code> 结构</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 中断对象 - 表示agent执行暂停，需要人工审核</span><br><span class="line">Interrupt(</span><br><span class="line">    # value 字段包含中断的详细信息</span><br><span class="line">    value=&#123;</span><br><span class="line">        # action_requests 列表 - 包含所有需要人工审核的工具调用</span><br><span class="line">        &#x27;action_requests&#x27;: [</span><br><span class="line">            &#123;</span><br><span class="line">                # 工具的名称 - agent想要执行的工具</span><br><span class="line">                &#x27;name&#x27;: &#x27;execute_sql&#x27;,</span><br><span class="line">                </span><br><span class="line">                # args 字典 - 传递给工具的参数</span><br><span class="line">                &#x27;args&#x27;: &#123;</span><br><span class="line">                    # SQL查询语句 - 具体要执行的数据库操作</span><br><span class="line">                    &#x27;query&#x27;: &#x27;SELECT name FROM employees;&#x27;</span><br><span class="line">                &#125;,</span><br><span class="line">                </span><br><span class="line">                # description 字符串 - 人类可读的完整描述（用于展示给审核员）</span><br><span class="line">                &#x27;description&#x27;: &quot;Tool execution requires approval\n\nTool: execute_sql\nArgs: &#123;&#x27;query&#x27;: &#x27;SELECT name FROM employees;&#x27;&#125;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        ],</span><br><span class="line">        </span><br><span class="line">        # review_configs 列表 - 包含审核的策略配置</span><br><span class="line">        &#x27;review_configs&#x27;: [</span><br><span class="line">            &#123;</span><br><span class="line">                # action_name 字符串 - 这个审核策略应用于哪个工具</span><br><span class="line">                &#x27;action_name&#x27;: &#x27;execute_sql&#x27;,</span><br><span class="line">                </span><br><span class="line">                # allowed_decisions 列表 - 人工审核员允许做出的决定类型，这里只允许两种决定：</span><br><span class="line">                &#x27;allowed_decisions&#x27;: [&#x27;approve&#x27;, &#x27;reject&#x27;]</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    </span><br><span class="line">    # id 字符串 - 中断的唯一标识符（UUID）</span><br><span class="line">    # 用于追踪和关联这个特定的中断请求</span><br><span class="line">    # 在日志、审计等场景中用于识别具体是哪次中断</span><br><span class="line">    id=&#x27;eee3e43d71fb8f3747759c8cbe9b5499&#x27;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langchain</category>
      </categories>
      <tags>
        <tag>langchain</tag>
      </tags>
  </entry>
  <entry>
    <title>LangGraph学习——快速入门</title>
    <url>/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="构建langgraph聊天机器人的基本流程">构建langgraph聊天机器人的基本流程</h3>
<h4 id="创建一个-stategraph">创建一个 <code>StateGraph</code></h4>
<p>首先创建一个 <code>StateGraph</code>。一个 <code>StateGraph</code>
对象将我们的聊天机器人结构定义为“状态机”。我们将添加 <code>节点</code>
来表示 LLM 和聊天机器人可以调用的函数，并添加 <code>边</code>
来指定机器人应如何在这些函数之间进行转换。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义状态</span></span><br><span class="line">graph_builder = StateGraph(State)</span><br></pre></td></tr></table></figure>
<p>在 langgraph
中，状态会在图的各个节点之间传递。当一个节点产生新的消息时，它会更新
State 中的 messages 字段。</p>
<p>我们的图现在可以处理两个关键任务</p>
<ol type="1">
<li>每个 <code>节点</code> 都可以接收当前 <code>状态</code>
作为输入，并输出状态的更新。</li>
<li>对 <code>消息</code> 的更新将追加到现有列表而不是覆盖它，这得益于与
<code>Annotated</code> 语法一起使用的预构建 <a href="https://github.langchain.ac.cn/langgraph/reference/graphs/?h=add+messages#add_messages"><code>add_messages</code></a>
函数。</li>
</ol>
<blockquote>
<p>langgraph中每个消息对象通常包含以下关键属性：</p>
<ul>
<li>role : 一个字符串，标识消息的发送者（例如 ‘human’ , ‘ai’ , ‘system’
）。</li>
<li>content :
消息的具体内容，通常是字符串，但也可以是更复杂的结构（例如，用于多模态输入）。</li>
<li>id : 一个可选的唯一标识符。</li>
</ul>
<p>Annotated 的作用 : 通过使用 Annotated[list, add_messages]
，你改变了这个默认行为。 add_messages 函数（由 langgraph
提供或由你自定义）的逻辑是 追加
而不是覆盖。所以，当一个新节点返回消息时， langgraph 会调用 add_messages
函数，将新消息 追加 到现有 messages 列表的末尾。</p>
</blockquote>
<h4 id="定义一个聊天模型">定义一个聊天模型</h4>
<p>两种方法：</p>
<p>1.使用 <code>init_chat_model</code>(通用高层封装)
这是一个通用的辅助函数，旨在提供一个统一的接口来初始化来自 不同提供商
的聊天模型。</p>
<p><a href="https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html">init_chat_model
— 🦜🔗 LangChain 文档 — init_chat_model — 🦜🔗 LangChain
documentation</a></p>
<p>2.使用如ChatOpenAI (特定于提供商的类) 这是一个专门为 OpenAI API
设计的类，提供了对 OpenAI 模型所有功能的完全访问。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.chat_models import init_chat_model</span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;sk-&quot;</span><br><span class="line">#使用‘&#123;model_provider&#125;:&#123;model&#125;’格式在单个参数中指定模型和模型提供者，例如“openai:o1”</span><br><span class="line">llm = init_chat_model(&quot;openai:qwen-plus-2025-04-28&quot;,</span><br><span class="line">                      base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">                      )</span><br></pre></td></tr></table></figure>
<h4 id="添加一个节点">添加一个节点</h4>
<p>现在我们可以将聊天模型集成到一个简单的节点中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#定义节点chatbot</span><br><span class="line">def chatbot(state: State):</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line">graph_builder.add_node(&quot;chatbot&quot;, chatbot)</span><br></pre></td></tr></table></figure>
<p><code>chatbot</code> 节点函数如何将当前 <code>状态</code>
作为输入，并返回一个包含更新的 <code>消息</code>
列表的字典，键为“messages”。这是所有 LangGraph 节点函数的基本模式。</p>
<p>我们 <code>状态</code> 中的 <code>add_messages</code> 函数会将 LLM
的响应消息追加到状态中已有的消息之后。</p>
<h4 id="添加一个-入口-点">添加一个 <code>入口</code> 点</h4>
<p>添加一个 <code>入口</code>
点，以告诉图每次运行时<strong>从何处开始工作</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph_builder.add_edge(START, &quot;chatbot&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="编译图">编译图</h4>
<p>在运行图之前，我们需要对其进行编译。我们可以通过在图构建器上调用
<code>compile()</code> 来完成。这将创建一个
<code>CompiledGraph</code>，我们可以在我们的状态上调用它。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph = graph_builder.compile()</span><br></pre></td></tr></table></figure>
<h4 id="可视化图">可视化图</h4>
<p>您可以使用 <code>get_graph</code> 方法和其中一个“绘图”方法（例如
<code>draw_ascii</code> 或 <code>draw_png</code>）来可视化图。这些
<code>draw</code> 方法都需要额外的依赖项。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    display(Image(graph.get_graph().draw_mermaid_png()))</span><br><span class="line">except Exception:</span><br><span class="line">    # This requires some extra dependencies and is optional</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure>
<h4 id="运行聊天机器人">运行聊天机器人</h4>
<p>运行聊天机器人</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;]&#125;):</span><br><span class="line">        <span class="built_in">print</span>(event)</span><br><span class="line">        <span class="comment">#stream 返回的每个 event 通常是一个字典，键是图中节点的名称，值是该节点完成后的状态更新。</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">            <span class="comment">#消息列表中的最后一条消息的文本内容</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="comment">#退出</span></span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment">#调用</span></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>graph.stream() 是 LangGraph
的核心功能之一。它会执行整个图（Graph），但不是一次性返回最终结果，而是像视频流一样，一步一步地返回中间过程的更新。这使得您可以实时看到模型生成内容的每一个部分。</p>
</blockquote>
<h3 id="添加网页搜索工具">添加网页搜索工具</h3>
<h4 id="获取tavily-api">获取Tavily api</h4>
<p><a href="https://tavily.com/">Tavily 的搜索 API</a> 是一款专为 AI
代理 (LLM) 构建的搜索引擎，能够快速提供实时、准确和基于事实的结果。</p>
<p>每月 1,000 次免费搜索</p>
<p><a href="https://python.langchain.ac.cn/docs/integrations/tools/tavily_search/">Tavily
Search | 🦜️🔗 LangChain 框架</a></p>
<p>获取api<a href="https://app.tavily.com/home">Tavily AI — Tavily
AI</a></p>
<h4 id="添加工具">添加工具</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line"></span><br><span class="line">tool = TavilySearch(</span><br><span class="line">    tavily_api_key=&quot;tvly-dev-&quot;,</span><br><span class="line">    max_results=2)</span><br><span class="line">tools = [tool]</span><br><span class="line">tool.invoke(&quot;李超是谁?&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="定义图">定义图</h4>
<p>在LLM上添加<code>bind_tools</code>。这让LLM知道如果它想使用搜索引擎，应使用正确的JSON格式。</p>
<p>定义聊天模型llm（代码同上）</p>
<p>将tools整合到<code>StateGraph</code>中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将一个或多个**工具（tools） 绑定到一个 大型语言模型（LLM）**上，从而创建一个新的、具备工具调用能力的 LLM 实例</span></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br></pre></td></tr></table></figure>
<h4 id="创建一个运行工具的函数">创建一个运行工具的函数</h4>
<p>现在，创建一个函数来运行被调用的工具。通过将工具添加到一个名为<code>BasicToolNode</code>的新节点来完成，该节点检查状态中的最新消息，如果消息包含<code>tool_calls</code>，则调用工具。它依赖于LLM的<code>tool_calling</code>支持，该支持在Anthropic、OpenAI、Google
Gemini以及许多其他LLM提供商中可用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义 __call__ 方法，让这个类的实例可以像函数一样被调用</span></span><br><span class="line"><span class="comment"># inputs 是 langgraph 传进来的当前状态，是一个字典</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, inputs: <span class="built_in">dict</span></span>):</span><br><span class="line">    <span class="comment"># 1. 从状态中获取最新的消息</span></span><br><span class="line">    <span class="comment"># 使用了“海象操作符” :=，先从 inputs 中获取 &#x27;messages&#x27; 列表，如果不存在则返回空列表 []</span></span><br><span class="line">    <span class="comment"># 然后检查列表是否为空。如果不为空，则取出最后一条消息。</span></span><br><span class="line">    <span class="keyword">if</span> messages := inputs.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">        message = messages[-<span class="number">1</span>]  <span class="comment"># 通常，最后一条消息是 AI 发出的，其中包含工具调用请求</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果没有消息，就报错，因为这个节点不知道该做什么</span></span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;No message found in input&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 准备一个列表，用来存放所有工具的执行结果</span></span><br><span class="line">    outputs = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 遍历 AI 消息中请求的所有工具调用</span></span><br><span class="line">    <span class="keyword">for</span> tool_call <span class="keyword">in</span> message.tool_calls:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 执行工具</span></span><br><span class="line">        <span class="comment"># a. tool_call[&quot;name&quot;] 获取工具名称 (例如 &#x27;tavily_search_results_json&#x27;)</span></span><br><span class="line">        <span class="comment"># b. self.tools_by_name[...] 从预存的工具字典中找到对应的工具对象</span></span><br><span class="line">        <span class="comment"># c. .invoke(tool_call[&quot;args&quot;]) 使用 LLM 提供的参数来调用该工具</span></span><br><span class="line">        tool_result = <span class="variable language_">self</span>.tools_by_name[tool_call[<span class="string">&quot;name&quot;</span>]].invoke(</span><br><span class="line">            tool_call[<span class="string">&quot;args&quot;</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. 将工具执行结果打包成 ToolMessage</span></span><br><span class="line">        <span class="comment"># 这是 langgraph/langchain 的标准格式，用于告诉 LLM 工具执行的结果是什么</span></span><br><span class="line">        outputs.append(</span><br><span class="line">            ToolMessage(</span><br><span class="line">                content=json.dumps(tool_result),  <span class="comment"># 工具结果必须是字符串，所以用 json.dumps 序列化</span></span><br><span class="line">                name=tool_call[<span class="string">&quot;name&quot;</span>],  <span class="comment"># 告诉 LLM 这是哪个工具的结果</span></span><br><span class="line">                tool_call_id=tool_call[<span class="string">&quot;id&quot;</span>],  <span class="comment"># 必须提供原始请求的 ID，以便 LLM 知道这个结果对应哪个请求</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 6. 返回结果，更新图的状态</span></span><br><span class="line">    <span class="comment"># 返回一个字典，其中 &#x27;messages&#x27; 键对应着包含所有 ToolMessage 的列表</span></span><br><span class="line">    <span class="comment"># langgraph 会将这个列表中的消息追加到主状态的 &#x27;messages&#x27; 列表中</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: outputs&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>call</strong> 是 Python 中一个非常特殊的“魔术方法”（magic
method）。它的作用是 让一个类的实例（对象）能够像函数一样被调用 。</p>
<p>这在 langgraph 中是一种常见且核心的设计模式。它的含义是：</p>
<ol type="1">
<li>节点即函数 ： BasicToolNode 的实例（比如 tool_node
）本身就代表了图中的一个可执行节点。</li>
<li>执行逻辑 ：当 langgraph 的状态机运行到这个 tool_node
节点时，它会直接“调用”这个节点对象，并把当前的状态（ inputs
字典）传递给它</li>
</ol>
</blockquote>
<p>可以使用LangGraph预构建的<a href="https://github.langchain.ac.cn/langgraph/reference/agents/#langgraph.prebuilt.tool_node.ToolNode">ToolNode</a>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br></pre></td></tr></table></figure>
<h4 id="定义conditional_edges">定义<code>conditional_edges</code></h4>
<p>添加了工具节点后，现在您可以定义<code>conditional_edges</code>。</p>
<p><strong>边（Edges）</strong>将控制流从一个节点路由到下一个节点。<strong>条件边（Conditional
edges）</strong>从单个节点开始，通常包含“if”语句，根据当前图状态路由到不同的节点。这些函数接收当前的图<code>state</code>并返回一个字符串或字符串列表，指示接下来要调用哪个（或哪些）节点。</p>
<p>接下来，定义一个名为<code>route_tools</code>的路由函数，它检查聊天机器人输出中的<code>tool_calls</code>。通过调用<code>add_conditional_edges</code>将此函数提供给图，这会告诉图，无论何时<code>chatbot</code>节点完成，都要检查此函数以确定下一步去哪里。</p>
<p>如果存在工具调用，条件将路由到<code>tools</code>；如果不存在，则路由到<code>END</code>。由于条件可以返回<code>END</code>，因此这次您不需要明确设置<code>finish_point</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">route_tools</span>(<span class="params"></span></span><br><span class="line"><span class="params">     state: State,</span></span><br><span class="line"><span class="params"> </span>):</span><br><span class="line">     <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">     用于 conditional_edge 的路由函数：</span></span><br><span class="line"><span class="string">     - 如果最后一条消息包含工具调用，则路由到 ToolNode</span></span><br><span class="line"><span class="string">     - 否则路由到结束节点</span></span><br><span class="line"><span class="string">     &quot;&quot;&quot;</span></span><br><span class="line">     <span class="comment"># 处理 state 为列表的情况（可能是消息列表）</span></span><br><span class="line">     <span class="keyword">if</span> <span class="built_in">isinstance</span>(state, <span class="built_in">list</span>):</span><br><span class="line">         ai_message = state[-<span class="number">1</span>]  <span class="comment"># 获取最后一条消息</span></span><br><span class="line">     <span class="comment"># 处理 state 为字典的情况（包含 messages 字段）</span></span><br><span class="line">     <span class="keyword">elif</span> messages := state.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">         ai_message = messages[-<span class="number">1</span>]  <span class="comment"># 获取最后一条消息</span></span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">         <span class="keyword">raise</span> ValueError(<span class="string">f&quot;输入状态中没有找到消息: <span class="subst">&#123;state&#125;</span>&quot;</span>)</span><br><span class="line">     </span><br><span class="line">     <span class="comment"># 检查消息是否有工具调用</span></span><br><span class="line">     <span class="keyword">if</span> <span class="built_in">hasattr</span>(ai_message, <span class="string">&quot;tool_calls&quot;</span>) <span class="keyword">and</span> <span class="built_in">len</span>(ai_message.tool_calls) &gt; <span class="number">0</span>:</span><br><span class="line">         <span class="keyword">return</span> <span class="string">&quot;tools&quot;</span>  <span class="comment"># 有工具调用，返回 &quot;tools&quot; 路由到工具节点</span></span><br><span class="line">     <span class="keyword">return</span> END  <span class="comment"># 没有工具调用，返回 END 结束流程</span></span><br></pre></td></tr></table></figure>
<p>可以使用预构建的<a href="https://github.langchain.ac.cn/langgraph/reference/prebuilt/#tools_condition">tools_condition</a>代替route_tools以使其更简洁。</p>
<blockquote>
<p><code>tools_condition</code> 函数在聊天机器人需要使用工具时返回
“tools”，如果可以不使用响应则返回 “END”。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> tools_condition</span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">    &#123;<span class="string">&quot;tools&quot;</span>: <span class="string">&quot;tools&quot;</span>, END: END&#125;,</span><br><span class="line">)</span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br></pre></td></tr></table></figure>
<h4 id="可视化图-1">可视化图</h4>
<p>如上</p>
<h4 id="向机器人提问">向机器人提问</h4>
<p>现在您可以向聊天机器人提出超出其训练数据范围的问题。</p>
<p>如上</p>
<h3 id="添加记忆功能">添加记忆功能</h3>
<p>LangGraph
通过<strong>持久性检查点</strong>解决了这个问题。如果您在编译图时提供一个<code>checkpointer</code>，并在调用图时提供一个<code>thread_id</code>，LangGraph
会在每一步之后自动保存状态。当您使用相同的<code>thread_id</code>再次调用图时，图会加载其保存的状态，允许聊天机器人从上次中断的地方继续。</p>
<p>我们稍后会看到，<strong>检查点</strong>比简单的聊天记忆功能<em>强大得多</em>——它允许您随时保存和恢复复杂状态，用于错误恢复、人工干预工作流、时间旅行交互等。但首先，让我们添加检查点以实现多轮对话。</p>
<h4 id="创建-memorysaver-检查点">创建 <code>MemorySaver</code>
检查点</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br></pre></td></tr></table></figure>
<p>这是一个内存中的检查点，方便本教程使用。然而，在生产应用程序中，您可能会将其更改为使用
<code>SqliteSaver</code> 或 <code>PostgresSaver</code>
并连接数据库。</p>
<h4 id="编译图-1">编译图</h4>
<p>使用提供的检查点编译图，图在遍历每个节点时将对 <code>State</code>
进行检查点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph = graph_builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<h4 id="与您的聊天机器人互动">与您的聊天机器人互动</h4>
<ol type="1">
<li><p>选择一个线程作为此对话的键。</p>
<p>thread_id决定对话窗口</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>调用您的聊天机器人</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">user_input = &quot;我是谁&quot;</span><br><span class="line"></span><br><span class="line"># The config is the **second positional argument** to stream() or invoke()!</span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">)</span><br><span class="line">for event in events:</span><br><span class="line">    event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="添加人工干预">添加人工干预</h3>
<p>代理可能不可靠，并且可能需要人工输入才能成功完成任务。同样，对于某些操作，您可能需要在运行前要求人工批准，以确保一切按预期运行。</p>
<p>LangGraph 的<a href="https://github.langchain.ac.cn/langgraph/concepts/persistence/">持久化</a>层支持<strong>人工干预</strong>工作流，允许根据用户反馈暂停和恢复执行。此功能的主要接口是<a href="https://github.langchain.ac.cn/langgraph/how-tos/human_in_the_loop/add-human-in-the-loop/"><code>interrupt</code></a>函数。在节点内调用<code>interrupt</code>将暂停执行。通过传入<a href="https://github.langchain.ac.cn/langgraph/concepts/low_level/#command">Command</a>，可以恢复执行并接收来自人工的新输入。<code>interrupt</code>在功能上类似于
Python 的内置<code>input()</code>，<a href="https://github.langchain.ac.cn/langgraph/how-tos/human_in_the_loop/add-human-in-the-loop/">但有一些注意事项</a>。</p>
<h4 id="添加human_assistance工具">添加<code>human_assistance</code>工具</h4>
<p>将<code>human_assistance</code>工具添加到聊天机器人。此工具使用<code>interrupt</code>从人工接收信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 添加人工干预功能</span><br><span class="line"># 导入LangGraph的中断机制和命令类型</span><br><span class="line">from langgraph.types import Command, interrupt</span><br><span class="line"># 导入LangChain的工具装饰器</span><br><span class="line">from langchain_core.tools import tool</span><br><span class="line"></span><br><span class="line"># 使用@tool装饰器将函数标记为可被LLM调用的工具</span><br><span class="line">@tool</span><br><span class="line">def human_assistance(query: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;请求人工协助的工具函数。</span><br><span class="line">    当LLM遇到需要人工判断或帮助的情况时，会调用此工具。</span><br><span class="line">    该函数会暂停图的执行，等待人工操作员提供响应。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # interrupt()函数会暂停图的执行，等待人工输入</span><br><span class="line">    # 传入的字典包含查询信息，人工操作员会看到这个查询</span><br><span class="line">    human_response = interrupt(&#123;&quot;query&quot;: query&#125;)</span><br><span class="line">    </span><br><span class="line">    # 从人工响应中提取数据并返回给LLM</span><br><span class="line">    # human_response是一个字典，&quot;data&quot;字段包含人工提供的实际响应</span><br><span class="line">    return human_response[&quot;data&quot;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>简单来说，
<strong>调用哪个工具，以及何时调用，完全是由大语言模型（LLM）根据你给它的指令（Prompt）来决定的。</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tool = TavilySearch(max_results=2)</span><br><span class="line">tools = [tool, human_assistance]</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br></pre></td></tr></table></figure>
<h4 id="定义chatbot">定义chatbot</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def chatbot(state: State):</span><br><span class="line">    # 调用绑定了工具的LLM（llm_with_tools），传入当前的消息历史</span><br><span class="line">    # LLM会根据最新的消息决定是生成文本回复，还是调用一个或多个工具</span><br><span class="line">    message = llm_with_tools.invoke(state[&quot;messages&quot;])</span><br><span class="line">    </span><br><span class="line">    # --- 关键断言逻辑 ---</span><br><span class="line">    assert len(message.tool_calls) &lt;= 1</span><br><span class="line">    </span><br><span class="line">    # 将LLM生成的新消息（可能是文本回复，也可能是工具调用请求）返回</span><br><span class="line">    # 这个返回值会以字典的形式更新到状态（State）对象中</span><br><span class="line">    return &#123;&quot;messages&quot;: [message]&#125;</span><br><span class="line"></span><br><span class="line"># 将 chatbot 函数作为名为 &quot;chatbot&quot; 的节点添加到图构建器中</span><br><span class="line">graph_builder.add_node(&quot;chatbot&quot;, chatbot)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>中断安全性的断言 ( assert ) : assert len(message.tool_calls) &lt;= 1
是在实现人工干预时一个非常重要的 安全措施 。</p>
<ul>
<li>问题 : 现代 LLM
支持并行工具调用（一次请求执行多个工具）。但如果其中一个工具是
human_assistance
并触发了中断，整个图会暂停。当人工操作完成后，图会从中断点恢复。此时，如果不对工具调用数量做限制，LangGraph
可能会重新尝试执行所有在中断前请求的工具，导致已经执行过的工具被再次调用。</li>
<li>解决方案 : 这个断言强制要求 LLM
在每一步最多只能请求调用一个工具。这样就保证了当中断发生并恢复后，不会有重复执行工具的风险，确保了流程的稳定性和可预测性。</li>
</ul>
</blockquote>
<h4 id="编译图-2">编译图</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line">graph = graph_builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<h4 id="调用聊天机器人并中断">调用聊天机器人并中断</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">user_input = &quot;我需要一些关于构建 AI 代理的专家指导。你能帮我请求协助吗？&quot;</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    #它的作用是指定在进行流式处理时，你希望接收到的数据是以 完整的、累积的值 的形式返回，而不是以增量的、片段的形式返回。</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>聊天机器人生成了一个工具调用，但随后执行被中断。如果您检查图状态，您会看到它停止在工具节点</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">snapshot = graph.get_state(config)</span><br><span class="line">snapshot.next</span><br></pre></td></tr></table></figure>
<h4 id="恢复执行">恢复执行</h4>
<p>要恢复执行，请传入一个包含工具所需数据的<a href="https://github.langchain.ac.cn/langgraph/concepts/low_level/#command"><code>Command</code></a>对象。此数据的格式可以根据需要进行自定义。对于本示例，请使用一个带有键<code>"data"</code>的字典（由human_assistance决定）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">human_response = (</span><br><span class="line">&quot;我们专家在此为您提供帮助！我们建议您查看 LangGraph 来构建您的代理。它比简单的自主代理更可靠、更具可扩展性。&quot;</span><br><span class="line">)   </span><br><span class="line">#从暂停状态恢复执行</span><br><span class="line">human_command = Command(resume=&#123;&quot;data&quot;: human_response&#125;)</span><br><span class="line"></span><br><span class="line">events = graph.stream(human_command, config, stream_mode=&quot;values&quot;)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>1.工具的定义 ( human_assistance function):</p>
<ul>
<li>当 LLM 调用 human_assistance 工具时，这个函数被执行。</li>
<li>函数内部， interrupt() 被调用，导致图暂停，并等待人工输入。</li>
<li>在图恢复后， interrupt() 函数会返回一个值，这个值就是您通过
Command(resume=…) 注入的内容，也就是 {“data”: human_response} 。</li>
<li>因此， human_assistance 函数中的 human_response 变量实际上就等于
{“data”: human_response} 。</li>
<li>最后， return human_response[“data”] 从这个字典中提取出 “data”
键对应的值 ，并将其作为 human_assistance 工具的最终返回结果。</li>
</ul>
<p>2.恢复指令 ( Command(resume=…) ):</p>
<ul>
<li>当您构建 Command(resume={“data”: human_response})
时，您正在创建一个符合 human_assistance 函数期望的结构。</li>
<li>您将人工回复包装在一个字典里，并使用 “data” 作为键。</li>
<li>这个结构被传递回 interrupt() ，然后被 human_assistance
函数接收和解析。</li>
</ul>
<p>因为 human_assistance 函数的 return 语句期望从返回的字典中访问 “data”
键，所以我们在恢复执行时必须提供一个具有相同结构的字典。这是为了确保数据能够正确地在中断和恢复的过程中传递。</p>
</blockquote>
<p>在 LangGraph 中，<code>Command</code>
是一个用于<strong>控制图执行流程、更新状态、实现人机交互</strong>的核心类。它支持以下四个参数：</p>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 33%">
<col style="width: 58%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">参数名</th>
<th style="text-align: left;">类型</th>
<th style="text-align: left;">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>update</code></td>
<td style="text-align: left;"><code>dict</code></td>
<td style="text-align: left;">用于更新图的状态（state）。例如：<code>Command(update=&#123;"foo": "bar"&#125;)</code>。</td>
</tr>
<tr>
<td style="text-align: left;"><code>resume</code></td>
<td style="text-align: left;"><code>Any</code></td>
<td style="text-align: left;">与 <code>interrupt()</code>
配合使用，用于恢复被中断的图执行，并传递用户输入。</td>
</tr>
<tr>
<td style="text-align: left;"><code>goto</code></td>
<td style="text-align: left;"><code>str</code> 或 <code>Send</code> 或
<code>List[str|Send]</code></td>
<td style="text-align: left;">控制下一步要执行的节点，支持跳转到指定节点、多个节点序列，或使用
<code>Send</code> 对象。</td>
</tr>
<tr>
<td style="text-align: left;"><code>graph</code></td>
<td style="text-align: left;"><code>str</code></td>
<td style="text-align: left;">可选，指定命令作用的图。默认是当前图，也可以设为
<code>Command.PARENT</code> 表示父图。</td>
</tr>
</tbody>
</table>
<h3 id="自定义状态">自定义状态</h3>
<p>在本教程中，您将向状态添加额外字段，以定义复杂行为，而无需依赖消息列表。聊天机器人将使用其搜索工具查找特定信息，并将其转发给人工进行审查。</p>
<h4 id="向状态添加键">向状态添加键</h4>
<p>通过向状态添加 <code>name</code> 和 <code>birthday</code>
键，更新聊天机器人以研究实体的生日</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class State(TypedDict):</span><br><span class="line">    messages: Annotated[list, add_messages]</span><br><span class="line">    name: str</span><br><span class="line">    birthday: str</span><br></pre></td></tr></table></figure>
<p>将此信息添加到状态中，可以使其轻松被其他图节点（例如存储或处理信息的下游节点）以及图的持久层访问。</p>
<h4 id="在工具内部更新状态">在工具内部更新状态</h4>
<p>现在，在 <code>human_assistance</code>
工具内部填充状态键。这允许人工在信息存储到状态之前对其进行审查。使用 <a href="https://github.langchain.ac.cn/langgraph/concepts/low_level/#using-inside-tools"><code>Command</code></a>
从<strong>工具内部</strong>发出状态更新。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 从 langchain_core.messages 导入 ToolMessage，用于创建工具调用的响应消息</span><br><span class="line">from langchain_core.messages import ToolMessage </span><br><span class="line"># 从 langchain_core.tools 导入 InjectedToolCallId（用于自动注入工具调用ID）和 tool（工具装饰器）</span><br><span class="line">from langchain_core.tools import InjectedToolCallId, tool </span><br><span class="line"></span><br><span class="line"># 从 langgraph.types 导入 Command（用于向图发送指令）和 interrupt（用于中断图的执行）</span><br><span class="line">from langgraph.types import Command, interrupt </span><br><span class="line">from typing import Annotated</span><br><span class="line"># @tool 装饰器将这个函数声明为一个可供 LLM 调用的工具</span><br><span class="line">@tool </span><br><span class="line">def human_assistance(</span><br><span class="line">    name: str, </span><br><span class="line">    birthday: str, </span><br><span class="line">    # tool_call_id 这个参数非常特殊。Annotated[...] 和 InjectedToolCallId 告诉 LangGraph：</span><br><span class="line">    # 1. 这个参数不应暴露给 LLM，LLM 在调用此工具时不需要提供它。</span><br><span class="line">    # 2. LangGraph 在执行时，会自动将触发此工具的那个工具调用的 ID 注入到这个参数中。</span><br><span class="line">    # 这个 ID 对于创建与原始请求相关联的 ToolMessage 至关重要。</span><br><span class="line">    tool_call_id: Annotated[str, InjectedToolCallId]</span><br><span class="line">) -&gt; str: </span><br><span class="line">    &quot;&quot;&quot;当需要人工确认或更正信息时，请求人类协助。&quot;&quot;&quot; </span><br><span class="line">    # 调用 interrupt() 来暂停图的执行，并向人类审核者呈现一个包含问题和待确认数据的字典。</span><br><span class="line">    # 图会在此处暂停，直到人类通过 resume 指令提供了响应。</span><br><span class="line">    human_response = interrupt( </span><br><span class="line">        &#123; </span><br><span class="line">            &quot;question&quot;: &quot;Is this correct?&quot;, </span><br><span class="line">            &quot;name&quot;: name, </span><br><span class="line">            &quot;birthday&quot;: birthday, </span><br><span class="line">        &#125;,</span><br><span class="line">    ) </span><br><span class="line">    # 检查人类的响应。如果响应中 &#x27;correct&#x27; 键的值是 &#x27;yes&#x27; 或 &#x27;y&#x27; 开头，</span><br><span class="line">    # 则认为信息是正确的。</span><br><span class="line">    if human_response.get(&quot;correct&quot;, &quot;&quot;).lower().startswith(&quot;y&quot;): </span><br><span class="line">        # 如果信息正确，直接使用从 LLM 获取的原始信息。</span><br><span class="line">        verified_name = name </span><br><span class="line">        verified_birthday = birthday </span><br><span class="line">        response = &quot;Correct&quot; </span><br><span class="line">    # 否则，认为人类审核者提供了更正后的信息。</span><br><span class="line">    else: </span><br><span class="line">        # 从人类的响应中获取更正后的姓名和生日。</span><br><span class="line">        # 如果人类没有提供新的值，则使用 .get() 的默认值，即原始值。</span><br><span class="line">        verified_name = human_response.get(&quot;name&quot;, name) </span><br><span class="line">        verified_birthday = human_response.get(&quot;birthday&quot;, birthday) </span><br><span class="line">        response = f&quot;Made a correction: &#123;human_response&#125;&quot; </span><br><span class="line"></span><br><span class="line">    # 在工具内部直接构造一个用于更新图状态的字典。</span><br><span class="line">    state_update = &#123; </span><br><span class="line">        &quot;name&quot;: verified_name, # 更新状态中的 &#x27;name&#x27; 字段</span><br><span class="line">        &quot;birthday&quot;: verified_birthday, # 更新状态中的 &#x27;birthday&#x27; 字段</span><br><span class="line">        # 创建一个 ToolMessage，将其添加到状态的 &#x27;messages&#x27; 列表中。</span><br><span class="line">        # 这个消息将作为此工具调用的正式“答复”出现在对话历史中。</span><br><span class="line">        # tool_call_id 是必需的，用于将此答复与 LLM 的原始工具调用请求关联起来。</span><br><span class="line">        &quot;messages&quot;: [ToolMessage(response, tool_call_id=tool_call_id)], </span><br><span class="line">    &#125; </span><br><span class="line">    # 这个工具不返回一个简单的字符串或数字，而是返回一个 Command 对象。</span><br><span class="line">    # Command(update=...) 是一个明确的指令，告诉 LangGraph 执行器：</span><br><span class="line">    # “请不要将我的返回值当作普通工具输出，而是用 state_update 字典里的内容来直接更新当前的图状态。”</span><br><span class="line">    return Command(update=state_update) </span><br></pre></td></tr></table></figure>
<p>图的其余部分保持不变。</p>
<h4 id="提示聊天机器人调用人工审查">提示聊天机器人调用人工审查</h4>
<p>提示聊天机器人查找 LangGraph
库的“生日”，并在其获取所需信息后，指示聊天机器人使用
<code>human_assistance</code> 工具。通过在工具参数中设置
<code>name</code> 和
<code>birthday</code>，您将强制聊天机器人为这些字段生成提议。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">user_input = (</span><br><span class="line">    &quot;你能查一下 LangGraph 是什么时候发布的吗？ &quot;</span><br><span class="line">    &quot;当你有了答案后，使用 human_assistance 工具进行审查。&quot;</span><br><span class="line">)</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>我们再次在 <code>human_assistance</code> 工具中触发了
<code>interrupt</code>。</p>
<h4 id="添加人工协助">添加人工协助</h4>
<p>聊天机器人未能识别正确的日期，因此为其提供信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">human_command = Command(</span><br><span class="line">    resume=&#123;</span><br><span class="line">        &quot;name&quot;: &quot;LangGraph&quot;,</span><br><span class="line">        &quot;birthday&quot;: &quot;Jan 17, 2024&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">events = graph.stream(human_command, config, stream_mode=&quot;values&quot;)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>请注意，这些字段现在已反映在状态中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">snapshot = graph.get_state(config)</span><br><span class="line"></span><br><span class="line">&#123;k: v for k, v in snapshot.values.items() if k in (&quot;name&quot;, &quot;birthday&quot;)&#125;</span><br></pre></td></tr></table></figure>
<p>这使得下游节点（例如，进一步处理或存储信息的节点）可以轻松访问它们。</p>
<h3 id="时间功能从之前的某个状态开始">时间功能（从之前的某个状态开始）</h3>
<p>在典型的聊天机器人工作流程中，用户与机器人进行一次或多次交互以完成任务。<a href="https://github.langchain.ac.cn/langgraph/tutorials/get-started/3-add-memory/">记忆</a>和<a href="https://github.langchain.ac.cn/langgraph/tutorials/get-started/4-human-in-the-loop/">人工干预</a>功能可以为图状态启用检查点并控制未来的响应。</p>
<p>如果您希望用户能够从之前的响应开始并探索不同的结果，该怎么办？或者，如果您希望用户能够回溯聊天机器人的工作以纠正错误或尝试不同的策略，这在自主软件工程师等应用程序中很常见，那又该怎么办？</p>
<p>您可以使用 LangGraph
内置的<strong>时光旅行</strong>功能创建这些类型的体验。</p>
<h4 id="回溯您的图">回溯您的图</h4>
<p>通过使用图的<code>get_state_history</code>方法获取检查点来回溯您的图。然后，您可以从之前的这个时间点恢复执行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 初始化一个变量 to_replay 为 None，它将用于存储我们想要“时间旅行”回去的特定状态。</span><br><span class="line"># to_replay 将在循环中被赋值为我们感兴趣的那个历史状态快照。</span><br><span class="line">to_replay = None</span><br><span class="line"></span><br><span class="line"># 遍历 `graph` 在给定 `config` 下的所有历史状态。</span><br><span class="line"># `graph.get_state_history(config)` 会返回一个迭代器，其中包含了从开始到当前的所有状态快照。</span><br><span class="line">for state in graph.get_state_history(config):</span><br><span class="line">    # 打印当前状态快照中的一些信息，以便我们观察和选择。</span><br><span class="line">    # `len(state.values[&quot;messages&quot;])` 显示了到该状态为止，对话历史中的消息总数。</span><br><span class="line">    # `state.next` 显示了在该状态之后，图将要执行的下一个节点或步骤的名称。</span><br><span class="line">    print(&quot;Num Messages: &quot;, len(state.values[&quot;messages&quot;]), &quot;Next: &quot;, state.next)</span><br><span class="line">    </span><br><span class="line">    # 打印一条分隔线，使输出更易读。</span><br><span class="line">    print(&quot;-&quot; * 80)</span><br><span class="line">    </span><br><span class="line">    # 这里是选择“时间旅行”目标点的关键逻辑。</span><br><span class="line">    # 我们设定一个条件：当对话历史中的消息数量正好等于4时，我们就找到了想要回到的那个点。</span><br><span class="line">    # 这是一个为了演示而设定的任意条件，在实际应用中，您可以根据需要设置更复杂的选择逻辑。</span><br><span class="line">    if len(state.values[&quot;messages&quot;]) == 4:</span><br><span class="line">        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.</span><br><span class="line">        # 将当前这个符合条件的状态（state）保存到 to_replay 变量中。</span><br><span class="line">        # 循环结束后，to_replay 变量将持有我们选中的那个历史时刻的完整状态，</span><br><span class="line">        # 之后我们就可以用它来恢复或修改执行流程。</span><br><span class="line">        to_replay = state</span><br></pre></td></tr></table></figure>
<p>图的每一步都会保存检查点。这<strong>跨越了调用</strong>，因此您可以回溯整个线程的历史。</p>
<h4 id="从特定时间点加载状态">从特定时间点加载状态</h4>
<p>从<code>to_replay</code>状态恢复。从这一点恢复将接下来调用<strong>action</strong>节点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(to_replay.next)</span><br><span class="line">print(to_replay.config)</span><br></pre></td></tr></table></figure>
<p>检查点的<code>to_replay.config</code>包含一个<code>checkpoint_id</code>时间戳。提供此<code>checkpoint_id</code>值会告诉
LangGraph 的检查点器从该时间点<strong>加载</strong>状态。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for event in graph.stream(None, to_replay.config, stream_mode=&quot;values&quot;):</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h3 id="运行本地服务器">运行本地服务器</h3>
<h4 id="安装-langgraph-cli">安装 LangGraph CLI</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Python &gt;= 3.11 is required.</span><br><span class="line"></span><br><span class="line">pip install --upgrade &quot;langgraph-cli[inmem]&quot;</span><br></pre></td></tr></table></figure>
<h4 id="创建-langgraph-应用">创建 LangGraph 应用 🌱</h4>
<p>从 <a href="https://github.com/langchain-ai/new-langgraph-project"><code>new-langgraph-project-python</code>
模板</a> 或 <a href="https://github.com/langchain-ai/new-langgraphjs-project"><code>new-langgraph-project-js</code>
模板</a>
创建一个新应用。此模板展示了一个单节点应用程序，您可以根据自己的逻辑进行扩展。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">langgraph new . --template new-langgraph-project-python</span><br></pre></td></tr></table></figure>
<blockquote>
<p>使用 <code>langgraph new</code>
而不指定模板，系统将显示一个交互式菜单，您可以从中选择可用的模板列表。</p>
</blockquote>
<h4 id="使用uv安装依赖项">使用uv安装依赖项</h4>
<p>uv 是一个用 Rust 编写的极速 Python 包和项目管理器 。它旨在解决传统
Python 包管理工具（如 pip 、 poetry
等）在速度和效率方面的痛点，提供更快的安装、依赖解析和环境管理。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install uv#安装uv</span><br></pre></td></tr></table></figure>
<p>运行<code>uv sync</code>会根据
<code>pyproject.toml</code>的依赖创建虚拟环境并安装依赖</p>
<blockquote>
<p><code>pyproject.toml</code> 文件是 Python
项目中用于统一配置项目元数据、构建系统、依赖管理和各种工具设置的标准化文件。它通常用于替代旧的
requirements.txt 文件，提供更现代和集中的项目配置方式。</p>
</blockquote>
<h4 id="创建一个-.env-文件">创建一个 <code>.env</code> 文件</h4>
<p>您将在新 LangGraph 应用的根目录下找到一个 <code>.env.example</code>
文件。在新 LangGraph 应用的根目录下创建一个 <code>.env</code> 文件，并将
<code>.env.example</code> 文件的内容复制到其中，填入所需的 API
密钥。</p>
<p>添加环境变量如LANGSMITH_API_KEY，OPENAI_API_KEY等</p>
<h4 id="启动-langgraph-服务器">启动 LangGraph 服务器</h4>
<p>在本地启动 LangGraph API 服务器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">langgraph dev</span><br></pre></td></tr></table></figure>
<p>示例输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;    Ready!</span><br><span class="line">&gt;</span><br><span class="line">&gt;    - API: [https://:2024](https://:2024/)</span><br><span class="line">&gt;</span><br><span class="line">&gt;    - Docs: https://:2024/docs</span><br><span class="line">&gt;</span><br><span class="line">&gt;    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024</span><br></pre></td></tr></table></figure>
<p>LangGraph 服务器（如您通过 langgraph dev
命令启动的服务器）的主要作用是提供一个运行环境和接口，用于开发、测试、部署和管理基于
LangGraph 构建的 AI 代理和应用程序。具体来说，它有以下几个主要用途：</p>
<ol type="1">
<li><p>API 接口暴露 ：它将您用 LangGraph
定义的复杂代理逻辑（即图结构）通过标准的 RESTful API
接口暴露出来。这意味着其他应用程序、前端界面或者其他服务可以通过 HTTP
请求与您的 LangGraph 代理进行交互，而无需直接集成 LangGraph 的 Python
代码。</p></li>
<li><p>简化部署 ：通过将 LangGraph
应用程序打包成一个可运行的服务，您可以更容易地将其部署到云服务器、容器（如
Docker）或其他生产环境中。这使得 LangGraph
代理可以作为一个独立的微服务运行，方便扩展和管理。</p></li>
<li><p>开发和调试便利 ：</p>
<ul>
<li>实时预览和调试 ：服务器通常会提供一个 Studio UI（如您在
http://127.0.0.1:2024/studio
看到的），让开发者能够可视化地查看代理的图结构、执行流程、状态变化和中间步骤，这对于理解和调试复杂的代理行为至关重要。</li>
<li>API 文档 ：自动生成的 API 文档（如 http://127.0.0.1:2024/docs
）提供了所有可用接口的详细说明和交互式测试功能，极大地加速了开发和集成过程。</li>
</ul></li>
<li><p>状态管理和持久化 ：LangGraph
代理通常涉及复杂的状态管理。服务器可以负责处理这些状态的持久化，确保代理在多次交互之间能够记住上下文和历史信息。</p></li>
</ol>
<h4 id="在-langgraph-studio-中测试您的应用程序">在 LangGraph Studio
中测试您的应用程序</h4>
<p><a href="https://github.langchain.ac.cn/langgraph/concepts/langgraph_studio/">LangGraph
Studio</a> 是一个专门的 UI，您可以连接到 LangGraph API
服务器，以便在本地可视化、交互和调试您的应用程序。通过访问
<code>langgraph dev</code> 命令输出中提供的 URL，在 LangGraph Studio
中测试您的图。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://github.langchain.ac.cn/langgraph/tutorials/get-started/1-build-basic-chatbot/#1-install-packages">构建一个基本聊天机器人
- LangChain 框架</a></p>
<p><a href="https://docs.langchain.com/oss/python/overview">Overview -
Docs by LangChain</a></p>
<p>官方教程，但是英文https://academy.langchain.com/collections</p>
<p><a href="https://www.bilibili.com/video/BV1AY4aeRETY/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">3.5
小时出证！LangGraph 官方课程 🆓 重磅上线🔥🔥🔥_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>LangGraph学习——agent——上</title>
    <url>/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>本教程为langchain官方教程的学习记录</p>
<p><a href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a href="https://github.com/zxj-2023/learn-rag-langchain">[learn-rag-langchain/academy-langgraph
at main ·
zxj-2023/learn-rag-langchain](https://github.com/zxj-2023/learn-rag-langchain/tree/main/academy-langgraph)</a></p>
<h3 id="module-1">module-1</h3>
<h4 id="route路由">route路由</h4>
<p>在 LangGraph
中，<strong>route（路由）*<em>的核心作用是*</em>根据当前状态动态决定“下一步应该执行哪个节点”</strong></p>
<h5 id="定义工具">定义工具</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def multiply(a: int, b: int) -&gt; int:</span><br><span class="line">    &quot;&quot;&quot;Multiply a and b.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: first int</span><br><span class="line">        b: second int</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line">    </span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">llm_with_tools = llm.bind_tools([multiply])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>三引号字符串叫 <strong>docstring</strong>，它会被 LangChain
拿来做两件事：</p>
<ol type="1">
<li><strong>生成工具的 description（给大模型看的“说明书”）</strong>
没有它时，LangChain 只能退而求其次，把函数名 <code>multiply</code>
拼成一句 “multiply tool”
之类的默认描述。大模型拿到的工具列表里，这个工具就只有一个干巴巴的名字和参数列表，它可能猜不到这个工具到底是干什么的</li>
<li><strong>给人类开发者自己看</strong>
IDE、文档生成器、静态检查工具都会读取这段文字，方便后期维护。</li>
</ol>
</blockquote>
<h5 id="构建条件边">构建条件边</h5>
<p><code>tool_calling_llm</code>
是一个<strong>普通的计算节点</strong>（node），负责把当前对话状态交给大模型，让大模型决定要不要调用工具；</p>
<p>真正完成“路由”动作的是 <strong><code>tools_condition</code></strong>
这个函数——它才是 LangGraph 里的 <strong>route（条件边）</strong>。</p>
<p><code>tools_condition</code> 是 作为<strong>LangGraph
预置的“默认路由函数”</strong>，功能就是，如果大模型的最新回复中包含工具调用，就调用工具</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Node</span><br><span class="line">def tool_calling_llm(state: MessagesState):</span><br><span class="line">	#调用大模型后将最新的消息返回</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm_with_tools.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">#MessagesState 是 LangGraph 官方预置 的一种 状态（State）定义</span><br><span class="line">#这个状态维护了一个消息list，有新的消息就加进这个消息list</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;tool_calling_llm&quot;, tool_calling_llm)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode([multiply]))</span><br><span class="line">builder.add_edge(START, &quot;tool_calling_llm&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;tool_calling_llm&quot;,</span><br><span class="line">    # 如果助手（结果）的最新消息是工具调用 -&gt; tools_condition 路由到工具</span><br><span class="line">    # 如果助手（结果）的最新消息不是工具调用 -&gt; tools_condition 路由到 END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719142543838.png" alt="image-20250719142543838">
<figcaption aria-hidden="true">image-20250719142543838</figcaption>
</figure>
<h5 id="调用">调用</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage</span><br><span class="line">messages = [HumanMessage(content=&quot;你好，2乘2是多少&quot;)]</span><br><span class="line">messages = graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，2乘2是多少</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_e026ceb409e247748786ad)</span><br><span class="line"> Call ID: call_e026ceb409e247748786ad</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">4</span><br></pre></td></tr></table></figure>
<h4 id="agent代理">agent代理</h4>
<p>在 LangGraph 中，<strong>代理（Agent）</strong>
被明确定义为<strong>“一个由大语言模型（LLM）驱动的、能够循环决策并调用外部工具来完成任务的节点或子图”</strong>。</p>
<p><strong>Agent = LLM + 工具集合 + 提示模板</strong>，三者在 LangGraph
的状态化图结构里循环运行，直到满足停止条件。</p>
<blockquote>
<p><a href="https://arxiv.org/abs/2210.03629">ReAct</a>
是一种流行的通用智能体架构，它结合了这些扩展，并整合了三个核心概念。</p>
<ol type="1">
<li><a href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#tool-calling">工具调用</a>：允许LLM根据需要选择和使用各种工具。</li>
<li><a href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#memory">记忆</a>：使智能体能够保留和使用之前步骤的信息。</li>
<li><a href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#planning">规划</a>：使LLM能够创建并遵循多步计划以实现目标。</li>
</ol>
<p>即</p>
<p><code>act</code>- 让模型调用特定工具</p>
<p><code>observe</code> - 将工具输出传递回模型</p>
<p><code>reason</code> -
让模型对工具输出进行推理，以决定下一步操作（例如，调用另一个工具或直接响应）</p>
</blockquote>
<h5 id="定义工具-1">定义工具</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tools = [add, multiply, divide]#工具函数具体内容省略</span><br><span class="line">llm = ChatOpenAI()</span><br><span class="line"></span><br><span class="line"># 在这个 ipynb 文件中，我们将并行工具调用（parallel tool calling）设置为 false，因为数学计算通常是按顺序执行的，并且这次我们有3个可以进行数学计算的工具。</span><br><span class="line"># OpenAI 模型为了效率，默认进行并行工具调用，详情请参阅 `https://python.langchain.com/docs/how_to/tool_calling_parallel/`</span><br><span class="line"># 不妨尝试一下，看看模型在处理数学方程式时的表现！</span><br><span class="line">llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)</span><br></pre></td></tr></table></figure>
<h5 id="创建代理">创建代理</h5>
<p>定义节点</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line"># System message</span><br><span class="line">sys_msg = SystemMessage(content=&quot;你是一个乐于助人的助手，负责对一组输入执行算术运算。&quot;)</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def assistant(state: MessagesState):</span><br><span class="line">   return &#123;&quot;messages&quot;: [llm_with_tools.invoke([sys_msg] + state[&quot;messages&quot;])]&#125;</span><br></pre></td></tr></table></figure>
<p>这一步相当于定义了系统提示词，然后在 assistant 这个节点里，通过
[sys_msg] + state[“messages”]
这部分代码，这个系统提示词被添加到了整个对话历史的最前面，然后一起发送给模型。这样一来，模型在生成回复时就会遵循这个系统提示词的指示。</p>
<p>与上一个不同的是，我们将 <code>Tools</code> 节点
<strong>回环</strong> 连接到
<code>Assistant</code>，从而形成一个回路。</p>
<p>在
assistant节点执行后，<code>tools_condition</code>检查模型的输出是否为工具调用。</p>
<p>如果是工具调用，则流程被导向至 <code>tools</code> 节点。</p>
<p><code>tools</code>节点重新连接到<code>assistant</code><strong>。</strong>
只要模型决定调用工具，此循环就会继续。</p>
<p>如果模型的响应不是工具调用，则流程被导向至结束，终止该过程。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line"></span><br><span class="line"># Define nodes: these do the work</span><br><span class="line">builder.add_node(&quot;assistant&quot;, assistant)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode(tools))</span><br><span class="line"></span><br><span class="line"># Define edges: these determine how the control flow moves</span><br><span class="line">builder.add_edge(START, &quot;assistant&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;assistant&quot;,</span><br><span class="line">    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools</span><br><span class="line">    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, &quot;assistant&quot;)</span><br><span class="line">react_graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># Show</span><br><span class="line">display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719145948088.png" alt="image-20250719145948088">
<figcaption aria-hidden="true">image-20250719145948088</figcaption>
</figure>
<h5 id="调用-1">调用</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">messages = [HumanMessage(content=&quot;将3和4相加。将结果乘以2。再将结果除以5。&quot;)]</span><br><span class="line">messages = react_graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line"></span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=False的输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_6c69898dba0342bfbb889e)</span><br><span class="line"> Call ID: call_6c69898dba0342bfbb889e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_9940e7603ecf4a13a5f2fb)</span><br><span class="line"> Call ID: call_9940e7603ecf4a13a5f2fb</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  divide (call_d48fbbe205a14dfbaa3500)</span><br><span class="line"> Call ID: call_d48fbbe205a14dfbaa3500</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是2.8。</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=True的输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_e0c7d8e65f2c49e8aecd3e)</span><br><span class="line"> Call ID: call_e0c7d8e65f2c49e8aecd3e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">  multiply (call_5bf824058e64489aaace91)</span><br><span class="line"> Call ID: call_5bf824058e64489aaace91</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">  divide (call_36c34f69f6574028b28847)</span><br><span class="line"> Call ID: call_36c34f69f6574028b28847</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是 **2.8**。</span><br></pre></td></tr></table></figure>
<h4 id="agent-memory代理记忆">Agent memory代理记忆</h4>
<p>使用chekpointer检查点的功能，最简单的检查点之一是
<code>MemorySaver</code>，这是一个用于图形状态的内存键值存储。</p>
<p>这个检查点就相当于把<strong>图的每一次“状态快照”持久化到外部存储</strong>的机制。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">react_graph_memory = builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p>我们可以使用 <a href="https://langchain-ai.github.io/langgraph/how-tos/persistence/">记忆功能</a>
来解决这个问题！LangGraph
可以使用检查点工具在每一步之后自动保存图的状态。这一内置的持久化层为我们提供了内存功能，使
LangGraph 能够从最后一次状态更新处继续。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Specify a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Specify an input</span><br><span class="line">messages = [HumanMessage(content=&quot;Add 3 and 4.&quot;)]</span><br><span class="line"></span><br><span class="line"># Run</span><br><span class="line">messages = react_graph_memory.invoke(&#123;&quot;messages&quot;: messages&#125;,config)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当我们使用内存时，我们需要指定一个 <code>thread_id</code>。这
<code>thread_id</code> 将存储我们的图形状态集合。</p>
<p>如下图，检查点在图的每一步写入状态，这些检查点保存在一个线程中
，我们可以使用 <code>thread_id</code> 在未来访问该线程</p>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66e0e9f526b41a4ed9e2d28b_agent-memory2.png" alt="state.jpg">
<figcaption aria-hidden="true">state.jpg</figcaption>
</figure>
<h3 id="module-2">module-2</h3>
<h4 id="state-scheme状态模式">state-scheme状态模式</h4>
<p>LangGraph 的 <strong>state-scheme（状态模式）</strong>
就是“一张<strong>蓝图</strong>”，它告诉框架：“在整个图的生命周期里，状态对象应该长什么样、每个字段怎样被更新、以及节点之间如何共享或隔离数据。”</p>
<p>state-scheme 用 <strong>TypedDict</strong> 或 <strong>Pydantic
BaseModel</strong> 来声明，定义了：</p>
<ul>
<li>状态里有哪些字段（key）</li>
<li>每个字段的 Python 类型</li>
<li><strong>可选</strong> 该字段的
<strong>reducer</strong>（更新规则）</li>
</ul>
<h5 id="typeddict"><strong>TypedDict</strong></h5>
<p><strong>基本定义</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    foo: str</span><br><span class="line">    bar: str</span><br></pre></td></tr></table></figure>
<p><strong>可增加像 <code>Literal</code>
这样的类型提示，使其更有价值</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Literal</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p>在这里，<code>mood</code> 只能是 “happy” 或 “sad”。</p>
<p><strong>加 reducer：让更新“可追加”而不覆盖</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class MathState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line">    scratchpad: Annotated[list[str], add_message]  # 新元素自动追加</span><br><span class="line">    answer: int</span><br></pre></td></tr></table></figure>
<p><code>Annotated[list[str], add]</code> 告诉 LangGraph：当节点返回
<code>&#123;"scratchpad": ["新步骤"]&#125;</code>
时，<strong>追加</strong>到现有列表，而不是替换</p>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import random</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">#定义节点</span><br><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state[&#x27;name&#x27;] + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state):</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;happy&quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_3(state):</span><br><span class="line">    print(&quot;---Node 3---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;sad&quot;&#125;</span><br><span class="line">#路由函数</span><br><span class="line">def decide_mood(state) -&gt; Literal[&quot;node_2&quot;, &quot;node_3&quot;]:</span><br><span class="line">        </span><br><span class="line">    # Here, let&#x27;s just do a 50 / 50 split between nodes 2, 3</span><br><span class="line">    if random.random() &lt; 0.5:</span><br><span class="line"></span><br><span class="line">        # 50% of the time, we return Node 2</span><br><span class="line">        return &quot;node_2&quot;</span><br><span class="line">    </span><br><span class="line">    # 50% of the time, we return Node 3</span><br><span class="line">    return &quot;node_3&quot;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(TypedDictState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719154439415.png" alt="image-20250719154439415">
<figcaption aria-hidden="true">image-20250719154439415</figcaption>
</figure>
<p>因为我们的状态是一个字典，我们只需用一个字典调用图，以设置状态中
<code>name</code> 键的初始值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;name&quot;:&quot;Lance&quot;&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="dataclass数据类"><strong>Dataclass数据类</strong></h5>
<p>python的dataclasses库提供了一种简洁的语法，用于创建主要用于存储数据的类。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line"></span><br><span class="line">@dataclass</span><br><span class="line">class DataclassState:</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state.name + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(DataclassState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>要访问 <code>dataclass</code> 的键，我们只需修改在
<code>node_1</code> 中使用的下标即可：</p>
<p>我们使用 <code>state.name</code> 来表示 <code>dataclass</code>
状态，而不是使用 <code>state["name"]</code> 来表示上面的
<code>TypedDict</code>。</p>
<p>你会注意到一个有点奇怪的地方：在每个节点中，我们仍然返回一个字典来执行状态更新。</p>
<p><strong>Dataclass 只是“描述”状态的形状，而真正在 LangGraph
的节点之间流动的依旧是「字典」</strong>，这是框架设计层面的约定</p>
<p>在这种情况下，<code>dataclass</code> 拥有键
<code>name</code>，因此我们可以通过从节点传递一个字典来更新它，就像在状态为
<code>TypedDict</code> 时所做的那样。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.invoke(DataclassState(name=&quot;Lance&quot;,mood=&quot;sad&quot;))</span><br></pre></td></tr></table></figure>
<p>我们通过 <code>dataclass</code> 来设置状态中每个键/通道的初始值！</p>
<h4 id="state-reducers状态更新函数"><strong>State
Reducers</strong>状态更新函数</h4>
<p><a href="https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers">Reducers</a>
为我们指定了如何执行更新。它接收 <strong>旧状态</strong> 与
<strong>一次变更指令（action /
增量字段）</strong>，<strong>返回全新的状态对象</strong>，整个过程中<strong>不能修改原有数据</strong>。</p>
<p>我们可以使用 <code>Annotated</code> 类型来指定一个 reducer
函数。在这种情况下，让我们将每个节点返回的值附加到结果中，而不是覆盖它们。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing import Annotated</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br></pre></td></tr></table></figure>
<p>我们只需要一个可以执行此操作的缩减器：<code>operator.add</code> 是
Python 内置 operator 模块中的一个函数。当 <code>operator.add</code>
应用于列表时，它执行列表连接。</p>
<h5 id="custom-reducers-自定义-reducers"><strong>Custom Reducers 自定义
Reducers</strong></h5>
<p>我们同样可以自定义reducers函数，解决一些特殊情况，比如，如下可以解决传入参数为none的情况</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def reduce_list(left: list | None, right: list | None) -&gt; list:</span><br><span class="line">    &quot;&quot;&quot;安全地合并两个列表，处理其中一个或两个输入可能为 None 的情况。</span><br><span class="line"></span><br><span class="line">    参数：</span><br><span class="line">        left (list | None): 要合并的第一个列表，或 None。</span><br><span class="line">        right (list | None): 要合并的第二个列表，或 None。</span><br><span class="line"></span><br><span class="line">    返回：</span><br><span class="line">        list: 一个包含两个输入列表所有元素的新列表。</span><br><span class="line">               如果输入为 None，则将其视为空列表。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if not left:</span><br><span class="line">        left = []</span><br><span class="line">    if not right:</span><br><span class="line">        right = []</span><br><span class="line">    return left + right</span><br><span class="line"></span><br><span class="line">class DefaultState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br><span class="line"></span><br><span class="line">class CustomReducerState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], reduce_list]</span><br></pre></td></tr></table></figure>
<h5 id="messagesstate">MessagesState</h5>
<p>我可以使用内置的 reducer <code>add_messages</code>
来处理状态中的消息</p>
<p>而<em><code>MessagesState</code></em> <em>内置了一个</em>
<em><code>messages</code></em> 键 它还为该键内置了一个
<code>add_messages</code> 合并器，这两个是等价的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Annotated</span><br><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import AnyMessage</span><br><span class="line">from langgraph.graph.message import add_messages</span><br><span class="line"></span><br><span class="line"># 定义一个自定义的 TypedDict，其中包含一个带有 add_messages reducer 的消息列表。</span><br><span class="line">class CustomMessagesState(TypedDict):</span><br><span class="line">    messages: Annotated[list[AnyMessage], add_messages]</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br><span class="line"></span><br><span class="line"># 使用 MessagesState ，它包含带有 add_messages reducer 的 messages 键。</span><br><span class="line">class ExtendedMessagesState(MessagesState):</span><br><span class="line">    # 添加除 messages 之外所需的任何键， messages 是预构建的。</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br></pre></td></tr></table></figure>
<p>在使用 <code>add_messages</code> reducer
时，让我们展示一些有用的技巧。</p>
<p><strong>重写（Re-writing）</strong></p>
<p>如果我们传递的消息与 <code>messages</code> 列表中已有的消息具有相同的
ID，则该消息将被覆盖！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Initial state</span><br><span class="line">initial_messages = [AIMessage(content=&quot;Hello! How can I assist you?&quot;, name=&quot;Model&quot;, id=&quot;1&quot;),</span><br><span class="line">                    HumanMessage(content=&quot;I&#x27;m looking for information on marine biology.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line">                   ]</span><br><span class="line"></span><br><span class="line"># New message to add</span><br><span class="line">new_message = HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line"></span><br><span class="line"># Test</span><br><span class="line">add_messages(initial_messages , new_message)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[AIMessage(content=&#x27;Hello! How can I assist you?&#x27;, name=&#x27;Model&#x27;, id=&#x27;1&#x27;),</span><br><span class="line"> HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&#x27;Lance&#x27;, id=&#x27;2&#x27;)]</span><br></pre></td></tr></table></figure>
<p><strong>删除（Removal）</strong></p>
<p><code>add_messages</code> 也 <a href="https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/">同样支持删除</a>。为此，我们简单地使用
<a href="https://api.python.langchain.com/en/latest/messages/langchain_core.messages.modifier.RemoveMessage.html">RemoveMessage</a>
来自 <code>langchain_core</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Message list</span><br><span class="line">messages = [AIMessage(&quot;Hi.&quot;, name=&quot;Bot&quot;, id=&quot;1&quot;)]</span><br><span class="line">messages.append(HumanMessage(&quot;Hi.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;))</span><br><span class="line">messages.append(AIMessage(&quot;So you said you were researching ocean mammals?&quot;, name=&quot;Bot&quot;, id=&quot;3&quot;))</span><br><span class="line">messages.append(HumanMessage(&quot;Yes, I know about whales. But what others should I learn about?&quot;, name=&quot;Lance&quot;, id=&quot;4&quot;))</span><br><span class="line"></span><br><span class="line"># Isolate messages to delete</span><br><span class="line">delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]</span><br><span class="line">print(delete_messages)</span><br></pre></td></tr></table></figure>
<h4 id="multiple-schemas-多种状态"><strong>Multiple Schemas</strong>
多种状态</h4>
<h5 id="private-state-私有状态"><strong>Private State</strong>
私有状态</h5>
<p>首先，让我们讨论在节点之间传递 <a href="https://langchain-ai.github.io/langgraph/how-tos/pass_private_state/">private
state</a>
的情况。这对于图的中间计算逻辑中需要的任何内容都很有用，但与图的整体输入或输出无关。</p>
<p>示例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    foo: int</span><br><span class="line"></span><br><span class="line">class PrivateState(TypedDict):</span><br><span class="line">    baz: int</span><br><span class="line"></span><br><span class="line">def node_1(state: OverallState) -&gt; PrivateState:</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;baz&quot;: state[&#x27;foo&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state: PrivateState) -&gt; OverallState:</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;foo&quot;: state[&#x27;baz&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(OverallState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_edge(&quot;node_1&quot;, &quot;node_2&quot;)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719171509917.png" alt="image-20250719171509917">
<figcaption aria-hidden="true">image-20250719171509917</figcaption>
</figure>
<p>我们将定义一个 <code>OverallState</code> 和一个
<code>PrivateState</code>。<code>node_2</code> 使用
<code>PrivateState</code> 作为输入，但输出写入到
<code>OverallState</code>。</p>
<p><code>baz</code> 仅包含在 <code>PrivateState</code>
中。因此，我们可以看到 <code>baz</code> 被排除在图形输出之外，因为它不在
<code>OverallState</code> 中。</p>
<h5 id="input-output-schema-输入输出模式"><strong>Input / Output Schema
</strong>输入/输出模式</h5>
<p>在 LangGraph 中，<strong>Input / Output Schema</strong>
就是“<strong>图的对外接口协议</strong>”：<strong>调用者只能按 Input
Schema 传参；图运行完后，只吐出 Output Schema 规定的字段。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"># 定义输入的模式</span><br><span class="line">class InputState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line"></span><br><span class="line"># 定义输出的模式</span><br><span class="line">class OutputState(TypedDict):</span><br><span class="line">    answer: str</span><br><span class="line"></span><br><span class="line"># 定义整体模式，结合输入和输出</span><br><span class="line">class OverallState(InputState, OutputState):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"># 定义处理输入并生成答案的节点</span><br><span class="line">def answer_node(state: InputState):</span><br><span class="line">    # 示例答案和额外键</span><br><span class="line">    return &#123;&quot;answer&quot;: &quot;bye&quot;, &quot;question&quot;: state[&quot;question&quot;]&#125;</span><br><span class="line"></span><br><span class="line"># 构建图，并指定输入和输出模式</span><br><span class="line">builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)</span><br><span class="line">builder.add_node(answer_node)  # 添加答案节点</span><br><span class="line">builder.add_edge(START, &quot;answer_node&quot;)  # 定义起始边</span><br><span class="line">builder.add_edge(&quot;answer_node&quot;, END)  # 定义结束边</span><br><span class="line">graph = builder.compile()  # 编译图</span><br><span class="line"></span><br><span class="line"># 使用输入调用图并打印结果</span><br><span class="line">print(graph.invoke(&#123;&quot;question&quot;: &quot;hi&quot;&#125;))</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;answer&#x27;: &#x27;bye Lance&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，<code>input</code> / <code>output</code>
模式对图的输入和输出上允许的键进行 <strong>过滤</strong>。可以看到
<code>output</code> 模式将输出限制为仅包含 <code>answer</code> 键。</p>
<h4 id="filtering-and-trimming-messages筛选和精简消息"><strong>Filtering
and trimming messages</strong>筛选和精简消息</h4>
<p>如果我们在处理长时间对话时不够小心，会导致高令牌使用量和延迟，因为我们传递给模型的是一系列不断增加的消息。所以要进行筛选和精简消息。</p>
<h5 id="简化器reducer"><strong>简化器（Reducer）</strong></h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Nodes</span><br><span class="line">def filter_messages(state: MessagesState):</span><br><span class="line">    # 删除除最近两条消息外的所有消息</span><br><span class="line">    delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]]</span><br><span class="line">    return &#123;&quot;messages&quot;: delete_messages&#125;</span><br><span class="line"></span><br><span class="line">def chat_model_node(state: MessagesState):    </span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;filter&quot;, filter_messages)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;filter&quot;)</span><br><span class="line">builder.add_edge(&quot;filter&quot;, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719203204234.png" alt="image-20250719203204234">
<figcaption aria-hidden="true">image-20250719203204234</figcaption>
</figure>
<h5 id="筛选消息filtering-messages"><strong>筛选消息（Filtering
messages）</strong></h5>
<p>如果你不需要或不希望修改图状态，可以直接过滤传递给聊天模型的消息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;][-1:])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>例如，只需传递一个过滤后的列表：<code>llm.invoke(messages[-1:])</code>
给模型。</p>
<p>状态包含了所有消息。但这里模型调用仅使用最后一条消息</p>
<h5 id="裁剪消息trim-messages"><strong>裁剪消息（Trim
messages）</strong></h5>
<p>另一种方法是根据设定一定数量的tokens进行 <a href="https://python.langchain.com/v0.2/docs/how_to/trim_messages/#getting-the-last-max_tokens-tokens">trim
messages</a>。在把对话历史发给大模型之前，按 <strong>token 预算</strong>
把超长消息列表“剪”到合适长度。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import trim_messages</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    # 使用 trim_messages 函数修剪消息列表</span><br><span class="line">    # max_tokens: 限制消息的最大令牌数</span><br><span class="line">    # strategy: 修剪策略，这里是“last”，表示保留最新的消息</span><br><span class="line">    # token_counter: 用于计算令牌数的模型实例</span><br><span class="line">    # allow_partial: 是否允许部分修剪</span><br><span class="line">    messages = trim_messages(</span><br><span class="line">            state[&quot;messages&quot;],</span><br><span class="line">            max_tokens=100,</span><br><span class="line">            strategy=&quot;last&quot;,</span><br><span class="line">            token_counter= ChatOpenAI(</span><br><span class="line">                model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">                api_key=&quot;sk-&quot;,</span><br><span class="line">                base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;),</span><br><span class="line">            allow_partial=False,</span><br><span class="line">        )</span><br><span class="line">    # 调用语言模型（llm）处理修剪后的消息，并返回结果</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(messages)]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h4 id="chatbot-with-message-summarization带有消息总结功能的聊天机器人"><strong>Chatbot
with message summarization</strong>带有消息总结功能的聊天机器人</h4>
<p>与其仅仅修剪或过滤消息，我们将展示如何使用大型语言模型（LLMs）来生成对话的实时摘要。</p>
<p>这使我们能够保留整个对话的压缩表示，而不仅仅是通过修剪或过滤将其移除。</p>
<p>我们将为该聊天机器人配备记忆功能，支持长时间对话，同时不会产生高昂的
token 成本或延迟。</p>
<h5 id="定义总结状态">定义总结状态</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">class State(MessagesState):</span><br><span class="line">    summary: str</span><br></pre></td></tr></table></figure>
<p>除了内置的 <code>messages</code>
键之外，我们现在还将包含一个自定义键（<code>summary</code>）。</p>
<h5 id="定义llm节点">定义LLM节点</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage </span><br><span class="line"> </span><br><span class="line"> # 定义调用模型的逻辑</span><br><span class="line">def call_model(state: State): </span><br><span class="line">     </span><br><span class="line">     # 获取摘要（如果存在） </span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 如果有摘要，则添加它</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 将摘要添加到系统消息中</span><br><span class="line">         system_message = f&quot;先前对话的摘要：&#123;summary&#125;&quot; </span><br><span class="line"> </span><br><span class="line">         # 将摘要附加到任何较新的消息中</span><br><span class="line">         messages = [SystemMessage(content=system_message)] + state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     else: </span><br><span class="line">         messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     return &#123;&quot;messages&quot;: response&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>调用我们的LLM</strong>，如果存在摘要，则将其纳入提示中。</p>
<blockquote>
<p>当 call_model 函数返回 {“messages”: response} 时，它是在告诉
langgraph ：“请用 response （即模型的新输出）来更新 State 对象中
messages 键对应的值。” langgraph 会将这个新消息追加到 messages
列表中，从而保持了对话历史的连续性</p>
</blockquote>
<h5 id="定义摘要节点">定义摘要节点</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def summarize_conversation(state: State): </span><br><span class="line">     </span><br><span class="line">     # 首先，我们获取任何现有的摘要</span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 创建我们的摘要提示</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 摘要已存在</span><br><span class="line">         summary_message = ( </span><br><span class="line">             f&quot;这是迄今为止对话的摘要：&#123;summary&#125;\n\n&quot; </span><br><span class="line">             &quot;请结合以上新消息扩展摘要：&quot; </span><br><span class="line">         ) </span><br><span class="line">         </span><br><span class="line">     else: </span><br><span class="line">         summary_message = &quot;创建以上对话的摘要：&quot; </span><br><span class="line"> </span><br><span class="line">     # 将提示添加到我们的历史记录中</span><br><span class="line">     messages = state[&quot;messages&quot;] + [HumanMessage(content=summary_message)] </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     </span><br><span class="line">     # 删除除最近2条消息外的所有消息</span><br><span class="line">     delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]] </span><br><span class="line">     return &#123;&quot;summary&quot;: response.content, &quot;messages&quot;: delete_messages&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>生成摘要</strong>。请注意，这里我们将使用
<code>RemoveMessage</code> 在生成摘要后过滤我们的状态。</p>
<h5 id="定义路由函数">定义路由函数</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import END </span><br><span class="line"> # 决定是结束对话还是总结对话</span><br><span class="line">def should_continue(state: State): </span><br><span class="line">     </span><br><span class="line">     &quot;&quot;&quot;返回要执行的下一个节点。&quot;&quot;&quot; </span><br><span class="line">     </span><br><span class="line">     messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     # 如果消息超过六条，那么我们总结对话</span><br><span class="line">     if len(messages) &gt; 6: </span><br><span class="line">         return &quot;summarize_conversation&quot; </span><br><span class="line">     </span><br><span class="line">     # 否则我们就可以结束了</span><br><span class="line">     return END </span><br></pre></td></tr></table></figure>
<p>我们将添加一个条件边，以根据对话长度确定是否生成摘要。</p>
<blockquote>
<p>在 langgraph 中， Command
是一个特殊的类型，用于指导图形（graph）决定接下来应该执行哪个节点。
您可以把它看作是给图形下达的一个“命令”。</p>
</blockquote>
<h5 id="添加内存并编译图">添加内存并编译图</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, START</span><br><span class="line"></span><br><span class="line"># Define a new graph</span><br><span class="line">workflow = StateGraph(State)</span><br><span class="line">workflow.add_node(&quot;conversation&quot;, call_model)</span><br><span class="line">workflow.add_node(&quot;summarize_conversation&quot;,summarize_conversation)</span><br><span class="line"></span><br><span class="line"># Set the entrypoint as conversation</span><br><span class="line">workflow.add_edge(START, &quot;conversation&quot;)</span><br><span class="line">workflow.add_conditional_edges(&quot;conversation&quot;, should_continue)</span><br><span class="line">workflow.add_edge(&quot;summarize_conversation&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Compile</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph = workflow.compile(checkpointer=memory)</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h5 id="使用线程调用">使用线程调用</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">input_message = HumanMessage(content=&quot;我喜欢玩lol，你知道这个游戏吗&quot;)</span><br><span class="line">output = graph.invoke(&#123;&quot;messages&quot;: [input_message]&#125;, config) </span><br><span class="line">for m in output[&#x27;messages&#x27;][-1:]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当对话大于6，可生成概要</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.get_state(config).values.get(&quot;summary&quot;,&quot;&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="chatbot-with-message-summarization-external-db-memory具有消息总结和外部数据库记忆的聊天机器人"><strong>Chatbot
with message summarization &amp; external DB
memory</strong>具有消息总结和外部数据库记忆的聊天机器人</h4>
<h5 id="使用数据库">使用数据库</h5>
<p><code>SqliteSaver</code> 是 LangGraph 提供的一个
<strong>轻量级状态持久化工具</strong>，它将图的运行状态（即
checkpoint）保存到本地的 SQLite
数据库中，使得你可以在程序中断或重启后<strong>恢复执行上下文</strong>，特别适合本地开发、实验性项目或中小规模应用。</p>
<p>如果我们提供 “:memory:” ，它将创建一个内存中的 SQLite 数据库。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import sqlite3</span><br><span class="line"># In memory</span><br><span class="line">conn = sqlite3.connect(&quot;:memory:&quot;, check_same_thread = False)</span><br></pre></td></tr></table></figure>
<p>如果我们提供一个 db 路径，那么它将为我们创建一个数据库！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#在本地创建一个目录 state_db，并尝试从 GitHub 下载一个名为 example.db 的 SQLite 数据库文件</span><br><span class="line">!mkdir -p state_db &amp;&amp; [ ! -f state_db/example.db ] &amp;&amp; wget -P state_db https://github.com/langchain-ai/langchain-academy/raw/main/module-2/state_db/example.db</span><br><span class="line"></span><br><span class="line">db_path = &quot;state_db/example.db&quot;</span><br><span class="line">conn = sqlite3.connect(db_path, check_same_thread=False)</span><br></pre></td></tr></table></figure>
<p>定义checkpoint</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.checkpoint.sqlite import SqliteSaver</span><br><span class="line">memory = SqliteSaver(conn)</span><br></pre></td></tr></table></figure>
<p>像上一个形式编译图</p>
<p>让我们确认一下我们的状态是否已保存到本地。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">graph_state = graph.get_state(config)</span><br><span class="line">graph_state</span><br></pre></td></tr></table></figure>
<p>使用像 Sqlite 这样的数据库意味着状态会被持久化！</p>
<h3 id="module-3">module-3</h3>
<h4 id="streaming-流式传输"><strong>Streaming</strong> 流式传输</h4>
<p>现在，让我们来谈谈 <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming">流式传输我们的图状态</a>
的方法。<code>.stream</code> 和 <code>.astream</code>
是用于流式返回结果的同步和异步方法。</p>
<p><code>values</code>：这将在每个节点被调用后流式传输图的完整状态。
<code>updates</code>：这将在每个节点被调用后流式传输图的状态更新。</p>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbaf892d24625a201744e5_streaming1.png" alt="values_vs_updates.png">
<figcaption aria-hidden="true">values_vs_updates.png</figcaption>
</figure>
<h5 id="stream_modeupdates">stream_mode=“updates”</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    print(chunk)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;conversation&#x27;: &#123;&#x27;messages&#x27;: AIMessage(content=&#x27;你好，zxj！很高兴认识你～有什么我可以帮你的吗？😊&#x27;, additional_kwargs=&#123;&#x27;refusal&#x27;: None&#125;, response_metadata=&#123;&#x27;token_usage&#x27;: &#123;&#x27;completion_tokens&#x27;: 16, &#x27;prompt_tokens&#x27;: 576, &#x27;total_tokens&#x27;: 592, &#x27;completion_tokens_details&#x27;: None, &#x27;prompt_tokens_details&#x27;: None&#125;, &#x27;model_name&#x27;: &#x27;qwen-plus-2025-04-28&#x27;, &#x27;system_fingerprint&#x27;: None, &#x27;id&#x27;: &#x27;chatcmpl-891471ae-2fe8-9b3d-b5f7-f4fcd55a4e16&#x27;, &#x27;service_tier&#x27;: None, &#x27;finish_reason&#x27;: &#x27;stop&#x27;, &#x27;logprobs&#x27;: None&#125;, id=&#x27;run--f36409f3-af43-4e9b-8a46-39646ad7c106-0&#x27;, usage_metadata=&#123;&#x27;input_tokens&#x27;: 576, &#x27;output_tokens&#x27;: 16, &#x27;total_tokens&#x27;: 592, &#x27;input_token_details&#x27;: &#123;&#125;, &#x27;output_token_details&#x27;: &#123;&#125;&#125;)&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>让我们来看一下 <code>stream_mode="updates"</code>。</p>
<p>因为我们使用 <code>updates</code>
进行流式传输，所以只有在图中的节点运行后，我们才能看到状态的更新。每个
<code>chunk</code> 是一个字典，以 <code>node_name</code>
为键，更新后的状态为值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    chunk[&#x27;conversation&#x27;][&quot;messages&quot;].pretty_print()</span><br></pre></td></tr></table></figure>
<p>现在我们直接打印状态更新。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好呀，zxj！再次见到你真高兴～😊 有什么我可以帮忙的吗？</span><br></pre></td></tr></table></figure>
<h5 id="stream_modevalues">stream_mode=“values”</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Start conversation, again</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">input_message = HumanMessage(content=&quot;你好我是zxj&quot;)</span><br><span class="line">for event in graph.stream(&#123;&quot;messages&quot;: [input_message]&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    for m in event[&#x27;messages&#x27;]:</span><br><span class="line">        m.pretty_print()</span><br><span class="line">    print(&quot;---&quot;*25)</span><br></pre></td></tr></table></figure>
<p>现在，我们可以看到 <code>stream_mode="values"</code>.这是在
<code>conversation</code> 节点被调用后，图的整个状态。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，zxj！有什么我可以帮你的吗？😊</span><br><span class="line">---------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h5 id="streaming-tokens-流式传输令牌"><strong>Streaming tokens</strong>
<strong>流式传输令牌</strong></h5>
<p>在 LangGraph 中，“流式传输令牌（Streaming
tokens）”指的是<strong>在节点内部的大模型（LLM）生成过程中，逐 token
地将中间结果实时推送到客户端</strong>的能力。实现这一能力的核心方法是
<code>astream_events</code>，它会以事件流的形式暴露整个执行过程中的所有细节，包括每一次
LLM 调用产生的 token。</p>
<p>每个事件是一个包含几个键的字典：</p>
<p><code>event</code>：这是正在发出的事件的类型。</p>
<p><code>name</code>：这是事件的名称。</p>
<p><code>data</code>：这是与事件相关联的数据。</p>
<p><code>metadata</code>：包含
<code>langgraph_node</code>，即发出事件的节点。</p>
<p>要点是，图表中聊天模型的令牌具有 <code>on_chat_model_stream</code>
类型。我们可以使用 <code>event['metadata']['langgraph_node']</code>
来选择要流式的节点。并且我们可以使用 <code>event['data']</code>
来获取每个事件的实际数据，而在这种情况下，数据是一个
<code>AIMessageChunk</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node_to_stream = &#x27;conversation&#x27;#定义流式传输的节点</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;5&quot;&#125;&#125;</span><br><span class="line">input_message = HumanMessage(content=&quot;为我介绍lol&quot;)</span><br><span class="line">async for event in graph.astream_events(&#123;&quot;messages&quot;: [input_message]&#125;, config, version=&quot;v2&quot;):</span><br><span class="line">    # 从特定节点获取聊天模型生成的 Token</span><br><span class="line">    #事件类型必须是 逐 token 流式输出（on_chat_model_stream）。</span><br><span class="line">    if event[&quot;event&quot;] == &quot;on_chat_model_stream&quot; and event[&#x27;metadata&#x27;].get(&#x27;langgraph_node&#x27;,&#x27;&#x27;) == node_to_stream:</span><br><span class="line">        data = event[&quot;data&quot;]</span><br><span class="line">        print(data[&quot;chunk&quot;].content, end=&quot;|&quot;)</span><br></pre></td></tr></table></figure>
<p>event的常见类型</p>
<table>
<colgroup>
<col style="width: 32%">
<col style="width: 67%">
</colgroup>
<thead>
<tr>
<th>事件类型 (<code>event</code>)</th>
<th>触发时机与说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>on_chain_start</code></td>
<td>任意 Runnable（节点、子图或整个图）开始执行</td>
</tr>
<tr>
<td><code>on_chain_stream</code></td>
<td>节点/图在运行过程中 <strong>增量输出</strong> chunk</td>
</tr>
<tr>
<td><code>on_chain_end</code></td>
<td>任意 Runnable 执行完成</td>
</tr>
<tr>
<td><code>on_chat_model_start</code></td>
<td><strong>ChatModel</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_chat_model_stream</code></td>
<td><strong>ChatModel</strong> 逐 token 返回内容（打字机效果）</td>
</tr>
<tr>
<td><code>on_chat_model_end</code></td>
<td><strong>ChatModel</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_tool_start</code></td>
<td><strong>Tool</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_tool_end</code></td>
<td><strong>Tool</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_retriever_start</code></td>
<td><strong>Retriever</strong> 开始检索</td>
</tr>
<tr>
<td><code>on_retriever_end</code></td>
<td><strong>Retriever</strong> 检索结束</td>
</tr>
</tbody>
</table>
<h4 id="breakpoints-断点"><strong>Breakpoints 断点</strong></h4>
<p><code>human-in-the-loop</code>（人工介入/人在回路）的三大动机：</p>
<p>1️⃣
Approval（审批）我们可以中断智能体，将当前状态呈现给用户，并让用户决定是否执行该操作。</p>
<p>2️⃣ Debugging（调试/回放）我们可以回退图形以重现或避免问题</p>
<p>3️⃣ Editing（编辑）AI
产出的中间结果不符合预期，但不想重跑整图，可以直接修改状态</p>
<p>我们将介绍 <a href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/#simple-usage">breakpoints</a>，它提供了一种在特定步骤停止图的简单方法。</p>
<h5 id="breakpoints-for-human-approval用于人类审批的断点"><strong>Breakpoints
for human approval</strong>用于人类审批的断点</h5>
<p>假设我们关注工具的使用：我们希望批准代理使用其任何工具。</p>
<p>我们所需要做的就是简单地用 <code>interrupt_before=["tools"]</code>
编译图形，其中 <code>tools</code> 是我们的工具节点。</p>
<p>这意味着在执行工具调用的节点 <code>tools</code>
之前，执行将被中断。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;tools&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720225640772.png" alt="image-20250720225640772">
<figcaption aria-hidden="true">image-20250720225640772</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: HumanMessage(content=&quot;2乘3&quot;)&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br></pre></td></tr></table></figure>
<p>我们可以获取状态并查看要调用的下一个节点。这是一种很好的方法，可以发现图已被中断。</p>
<p>现在，我们将介绍一个很好的技巧。当我们使用 <code>None</code>
调用图时，它将直接从最后一个状态检查点继续！</p>
<figure>
<img src="https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png" alt="breakpoints.jpg">
<figcaption aria-hidden="true">breakpoints.jpg</figcaption>
</figure>
<p>状态快照（StateSnapshot）</p>
<ul>
<li>类型：专门用来存 <strong>一个时刻</strong> 的完整状态</li>
<li>获取方式：
<ul>
<li><code>Graph.get_state()</code> → <strong>最新的</strong> 快照</li>
<li><code>Graph.get_state_history()</code> → <strong>所有</strong>
快照列表</li>
</ul></li>
</ul>
<p>继续/重跑图</p>
<ul>
<li><code>Graph.stream(None, &#123;"thread_id": "xxx"&#125;)</code>
<ul>
<li>不传新输入 <code>None</code> 表示
<strong>从当前最新状态继续跑</strong></li>
<li>也可回退到历史快照，再重跑（调试/回放）</li>
</ul></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">6</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">2乘3的结果是6。</span><br></pre></td></tr></table></figure>
<h4 id="editing-graph-state-编辑图状态"><strong>Editing graph state
</strong>编辑图状态</h4>
<p>断点也是<a href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/">修改图状态的机会</a>让我们在
<code>assistant</code> 节点之前为代理设置断点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;assistant&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720230924672.png" alt="image-20250720230924672">
<figcaption aria-hidden="true">image-20250720230924672</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: &quot;2乘3&quot;&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br></pre></td></tr></table></figure>
<p>当状态中断时，我们可以直接应用状态更新</p>
<p>记住，对 <code>messages</code> 键的更新将使用
<code>add_messages</code> reducer：</p>
<p>**如果我们想覆盖现有的消息，可以提供带有* <em><code>id</code></em>
*的消息。** 如果我们只想将消息添加到消息列表中，则可以传递未指定
<code>id</code> 的消息，如下所示。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&quot;不要，实际上要3乘3!&quot;)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">new_state = graph.get_state(thread).values</span><br><span class="line">for m in new_state[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">不要，实际上要3乘3!</span><br></pre></td></tr></table></figure>
<p>现在，让我们继续进行我们的代理操作，只需传递 <code>None</code>
并允许其从当前状态继续执行。我们输出当前内容，然后继续执行剩余的节点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="dynamic-breakpoints-动态断点"><strong>Dynamic breakpoints
</strong>动态断点</h4>
<p>你可以根据条件来实现它（从节点内部基于开发人员定义的逻辑）。您可以向用户说明其中断原因（通过将您想传递的内容发送到
<code>NodeInterrupt</code>）。</p>
<p>让我们创建一个图表，其中根据输入的长度会抛出一个
<code>NodeInterrupt</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.errors import NodeInterrupt</span><br><span class="line">from langgraph.graph import START, END, StateGraph</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    input: str</span><br><span class="line"></span><br><span class="line">def step_1(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 1---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_2(state: State) -&gt; State:</span><br><span class="line">    # 如果输入字符串长度超过5个字符，我们可以选择抛出NodeInterrupt异常</span><br><span class="line">    if len(state[&#x27;input&#x27;]) &gt; 5:</span><br><span class="line">        raise NodeInterrupt(f&quot;收到长度超过5个字符的输入: &#123;state[&#x27;input&#x27;]&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    print(&quot;---Step 2---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_3(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 3---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">builder = StateGraph(State)</span><br><span class="line">builder.add_node(&quot;step_1&quot;, step_1)</span><br><span class="line">builder.add_node(&quot;step_2&quot;, step_2)</span><br><span class="line">builder.add_node(&quot;step_3&quot;, step_3)</span><br><span class="line">builder.add_edge(START, &quot;step_1&quot;)</span><br><span class="line">builder.add_edge(&quot;step_1&quot;, &quot;step_2&quot;)</span><br><span class="line">builder.add_edge(&quot;step_2&quot;, &quot;step_3&quot;)</span><br><span class="line">builder.add_edge(&quot;step_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Set up memory</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># Compile the graph with memory</span><br><span class="line">graph = builder.compile(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250721222709712.png" alt="image-20250721222709712">
<figcaption aria-hidden="true">image-20250721222709712</figcaption>
</figure>
<p>让我们运行一个输入超过5个字符的图。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">initial_input = &#123;&quot;input&quot;: &quot;hello world&quot;&#125;</span><br><span class="line">thread_config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread_config, stream_mode=&quot;values&quot;):</span><br><span class="line">    print(event)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br><span class="line">---Step 1---</span><br><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以尝试从断点恢复图。但是，这只会重新运行相同的节点！除非状态发生变化，否则我们将一直卡在这里。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread_config,</span><br><span class="line">    &#123;&quot;input&quot;: &quot;hi&quot;&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>使用update_state更新状态</p>
<h4 id="time-travel-时间旅行"><strong>Time travel</strong> 时间旅行</h4>
<p>现在，让我们通过查看、重播，甚至从过去的状态叉出，来展示 LangGraph <a href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/">支持debug</a>
的功能。</p>
<h5 id="browsing-history-浏览历史"><strong>Browsing History</strong>
<strong>浏览历史</strong></h5>
<p>我们可以使用 <code>get_state</code> 来查看给定 <code>thread_id</code>
的图的 当前 状态！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.get_state(&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;&#125;&#125;)</span><br></pre></td></tr></table></figure>
<p>我们还可以浏览代理的状态历史。<code>get_state_history</code>
让我们能够获取所有先前步骤的状态。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">all_states = [s for s in graph.get_state_history(thread)]</span><br><span class="line">len(all_states)</span><br><span class="line">print(all_states)</span><br></pre></td></tr></table></figure>
<h5 id="replaying-回放"><strong>Replaying</strong>
<strong>回放</strong></h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">to_replay = all_states[-2]</span><br><span class="line">to_replay.values</span><br><span class="line">&#123;&#x27;messages&#x27;: [HumanMessage(content=&#x27;2乘3&#x27;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#x27;0676d9b5-cd59-4630-924d-b5c8d950e8d8&#x27;)]&#125;</span><br><span class="line">to_replay.next</span><br><span class="line">(&#x27;assistant&#x27;,)</span><br></pre></td></tr></table></figure>
<p>我们还获取了配置，它告诉了我们 <code>checkpoint_id</code> 以及
<code>thread_id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">to_replay.config</span><br><span class="line">&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;,</span><br><span class="line">  &#x27;checkpoint_ns&#x27;: &#x27;&#x27;,</span><br><span class="line">  &#x27;checkpoint_id&#x27;: &#x27;1f066c0e-2ee2-66d5-8000-5dde78194aae&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>要从这里重播，我们只需将配置传回给代理！图知道这个检查点已经执行过了。它只是从这个检查点重新播放！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for event in graph.stream(None, to_replay.config, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h5 id="forking-分叉"><strong>Forking</strong> 分叉</h5>
<p>如果我们想从相同的步骤运行，但使用不同的输入，该怎么办呢？这是分叉。</p>
<figure>
<img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbb038f89f2d847ee5c336_time-travel3.png" alt="fig3.jpg">
<figcaption aria-hidden="true">fig3.jpg</figcaption>
</figure>
<p>让我们修改此检查点的状态。我们可以直接使用提供的
<code>checkpoint_id</code> 来运行 <code>update_state</code>。</p>
<p>请记住我们对 <code>messages</code> 的 reducer 是如何工作的：</p>
<ul>
<li>它会追加消息，除非我们提供了一个消息 ID。</li>
<li>我们提供消息 ID 是为了覆盖消息，而不是将消息追加到状态中！</li>
</ul>
<p>因此，要覆盖消息，我们只需提供消息 ID，而我们已有
<code>to_fork.values["messages"].id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fork_config = graph.update_state(</span><br><span class="line">    to_fork.config,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&#x27;5乘3&#x27;, </span><br><span class="line">                               id=to_fork.values[&quot;messages&quot;][0].id)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="基础知识">基础知识</h3>
<h4 id="message">message</h4>
<p>LangChain 中的 HumanMessage 、 AIMessage 、 SystemMessage 和
ToolMessage
。这些消息类型是构建与语言模型（LLM）交互的核心组件，它们共同构成了一个完整的对话历史，帮助模型理解上下文并做出恰当的回应。</p>
<ol type="1">
<li>SystemMessage</li>
</ol>
<p>SystemMessage 的结构最简单，它只包含内容和类型。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 消息的具体内容，即给 AI 的指令。</li>
<li>type (str): 固定为字符串 ‘system’ 。</li>
</ul>
<ol start="2" type="1">
<li>HumanMessage</li>
</ol>
<p>HumanMessage 的结构也同样简单，代表用户的输入。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 用户输入的文本。</li>
<li>type (str): 固定为字符串 ‘human’ 。</li>
</ul>
<ol start="3" type="1">
<li>AIMessage</li>
</ol>
<p>AIMessage
的结构相对复杂，因为它不仅可以包含文本响应，还可以包含对工具的调用请求。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): AI 生成的文本响应。如果 AI
的回复是发起工具调用，此字段可以为空字符串。</li>
<li>tool_calls (list[dict], 可选):
一个字典列表，每个字典代表一个工具调用请求。这是支持“Function
Calling”或“Tool Calling”功能的核心。其结构通常包含：
<ul>
<li>name (str): 要调用的工具名称。</li>
<li>args (dict): 调用工具时需要传入的参数。</li>
<li>id (str): 此次工具调用的唯一标识符，用于后续 ToolMessage
的关联。</li>
</ul></li>
<li>type (str): 固定为字符串 ‘ai’ 。</li>
</ul>
<ol start="4" type="1">
<li>ToolMessage</li>
</ol>
<p>ToolMessage 用于承载工具执行后的返回结果。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 工具执行返回的结果。通常是一个字符串，比如 JSON
格式的字符串。</li>
<li>tool_call_id (str): 此次工具调用的唯一标识符， 必须 与之前 AIMessage
中 tool_calls 里的 id
相对应。这使得模型能够准确地将结果与请求匹配起来。</li>
<li>type (str): 固定为字符串 ‘tool’ 。</li>
</ul>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>langgraph查漏补缺</title>
    <url>/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h3 id="注入上下文">注入上下文</h3>
<p>“注入上下文”就是<strong>在运行过程中节点/大模型</strong>
可能需要、但<strong>不会</strong>（也不应该）去改变的<strong>只读信息</strong>的集合。</p>
<table>
<colgroup>
<col style="width: 20%">
<col style="width: 79%">
</colgroup>
<thead>
<tr>
<th>场景</th>
<th>注入上下文里可能放什么</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>权限控制</strong></td>
<td><code>user_id</code>,
<code>tenant_id</code>（决定能访问哪些数据）</td>
</tr>
<tr>
<td><strong>外部依赖</strong></td>
<td><code>db_connection</code>, <code>api_key</code>,
<code>s3_bucket</code>（节点里要用）</td>
</tr>
<tr>
<td><strong>个性化参数</strong></td>
<td><code>language</code>, <code>timezone</code>,
<code>model_temperature</code></td>
</tr>
<tr>
<td><strong>会话元信息</strong></td>
<td><code>session_id</code>, <code>channel</code>（Slack / 微信 /
Web）</td>
</tr>
</tbody>
</table>
<h4 id="案例">案例</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line"></span><br><span class="line">from langgraph.graph import StateGraph</span><br><span class="line">from langgraph.runtime import Runtime</span><br><span class="line"></span><br><span class="line">@dataclass</span><br><span class="line">class Context:</span><br><span class="line">    &quot;&quot;&quot;Context schema defined by the developer.&quot;&quot;&quot;    </span><br><span class="line">    user_id: str    </span><br><span class="line">    db_connection: str</span><br><span class="line">    </span><br><span class="line">def node(state: State, runtime: Runtime[Context]):</span><br><span class="line">    # type safe access to context attributes    </span><br><span class="line">    user_id = runtime.context.user_id</span><br><span class="line">    db_conn = runtime.context.db_connection</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">builder = StateGraph(state_schema=State, context_schema=Context)</span><br><span class="line"></span><br><span class="line"># add nodes, edges, compile the graph...</span><br><span class="line"></span><br><span class="line"># top level context arg is typed as Context for autocomplete and type checking</span><br><span class="line">result = graph.invoke(</span><br><span class="line">    &#123;&#x27;input&#x27;: &#x27;abc&#x27;&#125;,</span><br><span class="line">    context=Context(user_id=&#x27;123&#x27;, db_conn=&#x27;conn_mock&#x27;)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><a href="https://langchain-ai.github.io/langgraph/reference/runtime/#runtime"><code>Runtime</code></a>
类提供了一个单一接口，用于访问信息，例如：</p>
<ul>
<li>上下文：在运行开始时传递的静态数据</li>
<li>存储：长期记忆的存储机制</li>
<li>流写入器：用于向图输出流写入的自定义函数</li>
<li>对于功能 API 用户，<code>previous</code>
也可用：给定线程的前一个返回值</li>
</ul>
<p>现在，开发者不再需要将上述所有内容作为单独的参数注入到节点函数中，
而是可以通过一个 <code>runtime</code> 参数来访问它们。</p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
      </tags>
  </entry>
  <entry>
    <title>Langmem快速入门</title>
    <url>/2025/08/14/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langmem/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>本文简单测试了一下langgraph官方提供的记忆管理工具，发现还是存在bug，我在a线程先让他记住我是张熙浚，然后又告诉他我不是张熙浚我是张俊细，在线程b询问他我是谁时，他还是认为我是张熙浚。记忆的管理部分确实是一个很大的问题，但中小开发者我认为还是直接使用人家造好的轮子方便些（我尝试去阅读了他的记忆管理工具的源码，以我目前的水平，想手搓花费的精力还是太多了）</p>
<p>我还有一个疑惑，我的理解是，当前记忆的存储基本上依赖于agent的决定，所以并不稳定，我也搞不清楚他什么时候会把哪些信息存入记忆，可以设置
schemas结构，控制存储的内容，但是长期记忆仅存储指定的这些信息，感觉还是有些鸡肋啊</p>
<p>代码见<a href="https://github.com/zxj-2023/learn-rag-langchain/tree/main/langmem">learn-rag-langchain/langmem
at main · zxj-2023/learn-rag-langchain</a></p>
<h3 id="介绍">介绍</h3>
<p>LangMem 是 LangChain 推出的开源 SDK，通过一套存储-提取-优化机制，让
Agent
能够在多轮、多天甚至多用户之间持续学习、记住用户偏好并不断改进回答。</p>
<p>LangMem 的记忆工具按两个层次的集成模式组织：</p>
<ol type="1">
<li>核心 API</li>
</ol>
<p>LangMem
的核心是提供无副作用地转换记忆状态的函数。这些原语是记忆操作的构建块：</p>
<ul>
<li><a href="https://github.langchain.ac.cn/langmem/reference/memory/#langmem.create_memory_manager"><strong>记忆管理器</strong></a>：根据新的对话信息，提取新记忆、更新或删除过时记忆，并从现有记忆中进行整合和泛化。</li>
<li><a href="https://github.langchain.ac.cn/langmem/reference/prompt_optimization/#langmem.create_prompt_optimizer"><strong>提示优化器</strong></a>：根据对话信息（可选反馈）更新提示规则和核心行为。</li>
</ul>
<p>这些核心函数不依赖于任何特定的数据库或存储系统。您可以在任何应用程序中使用它们。</p>
<ol start="2" type="1">
<li>有状态集成</li>
</ol>
<p>上一层依赖于 LangGraph 的长期记忆存储。这些组件使用上述核心 API
来转换存储中存在的记忆，并在新对话信息传入时根据需要进行更新/插入或删除：</p>
<ul>
<li><a href="https://github.langchain.ac.cn/langmem/reference/memory/#langmem.create_memory_store_manager"><strong>存储管理器</strong></a>：自动持久化提取的记忆。</li>
<li><a href="https://github.langchain.ac.cn/langmem/reference/tools/#langmem.create_manage_memory_tool"><strong>记忆管理工具</strong></a>：让智能体直接访问记忆操作。</li>
</ul>
<figure>
<img src="/2025/08/14/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langmem/image-20250814152044798.png" alt="image-20250814152044798">
<figcaption aria-hidden="true">image-20250814152044798</figcaption>
</figure>
<p>langmem可以通过两种方式创建记忆</p>
<ol type="1">
<li><strong>在热路径中：</strong> Agent 使用工具主动保存笔记。</li>
<li><strong>在后台：</strong>记忆从对话中自动“潜意识地”提取。</li>
</ol>
<h3 id="热路径快速入门指南">热路径快速入门指南</h3>
<p>在本指南中，我们将创建一个 LangGraph Agent，它通过 LangMem 的
<code>manage_memory</code> 工具来主动管理自己的长期记忆。</p>
<h4 id="create_manage_memory_tool">create_manage_memory_tool</h4>
<p>create_manage_memory_tool通过创建一个工具（Tool），这个工具可以被
agent用来<strong>管理持久化记忆</strong>。这些记忆可以在不同的对话、会话甚至应用重启后依然存在。</p>
<ol type="1">
<li><p><strong>持久化存储 (Persistent Storage):</strong> 它利用了
LangGraph 提供的 <code>BaseStore</code>
接口。这使得数据可以存储在内存、数据库（如
Postgres）等地方，而不是仅仅存在于程序的运行时内存中。</p></li>
<li><p><strong>命名空间 (Namespace):</strong>
为了组织和隔离不同用户或不同类型的记忆，数据被存储在层级化的命名空间中。例如，<code>("memories", "user-123")</code>
可以确保用户 “user-123”
的记忆与其他用户或系统记忆分开。命名空间可以包含占位符（如
<code>&#123;langgraph_user_id&#125;</code>），在实际执行时会被具体的配置值替换。</p></li>
<li><p><strong>记忆 (Memory):</strong>
在这个上下文中，一个“记忆”就是存储在 <code>BaseStore</code>
中的一个数据项（<code>Item</code>）。它有一个唯一的
<code>key</code>（通常是 UUID），一个 <code>namespace</code>，一个
<code>value</code>（存储实际内容），以及创建和更新时间戳。</p></li>
<li><p><strong>工具 (Tool):</strong> 在 AI
应用中，工具是代理（Agent）可以调用的函数或能力。这个函数创建的工具就是一个封装好的、可以被
Agent 调用的函数，用于执行创建、更新、删除记忆的操作。</p></li>
</ol>
<h4 id="什么时候agent会调用记忆工具">什么时候agent会调用记忆工具</h4>
<figure>
<img src="/2025/08/14/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langmem/image-20250814163150589.png" alt="image-20250814163150589">
<figcaption aria-hidden="true">image-20250814163150589</figcaption>
</figure>
<p>ai是这样回答的，ReAct架构的agent是否调用工具由他自己决定</p>
<h4 id="实战">实战</h4>
<p><strong>导入库</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.prebuilt import create_react_agent</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line">from langgraph.utils.config import get_store </span><br><span class="line">from langmem import (</span><br><span class="line">    # 让智能体创建、更新和删除记忆 </span><br><span class="line">    create_manage_memory_tool,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>返回记忆提示词</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def prompt(state):</span><br><span class="line">    &quot;&quot;&quot;为LLM准备消息。&quot;&quot;&quot;</span><br><span class="line">    # 从配置的上下文变量中获取存储; </span><br><span class="line">    store = get_store() # 与提供给 `create_react_agent` 的相同</span><br><span class="line">    memories = store.search(</span><br><span class="line">        # 在与我们为智能体配置的相同命名空间内搜索</span><br><span class="line">        (&quot;memories&quot;,),</span><br><span class="line">        query=state[&quot;messages&quot;][-1].content,</span><br><span class="line">    )</span><br><span class="line">    system_msg = f&quot;&quot;&quot;You are a helpful assistant.</span><br><span class="line"></span><br><span class="line">## Memories</span><br><span class="line">&lt;memories&gt;</span><br><span class="line">&#123;memories&#125;</span><br><span class="line">&lt;/memories&gt;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">    return [&#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_msg&#125;, *state[&quot;messages&quot;]]</span><br></pre></td></tr></table></figure>
<p><strong>定义store与checkpoint</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain import embeddings</span><br><span class="line">from langchain_openai import OpenAIEmbeddings</span><br><span class="line">embedding=OpenAIEmbeddings(</span><br><span class="line">    api_key=&quot;sk-&quot;, </span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">    model=&quot;text-embedding-v4&quot;,</span><br><span class="line">    check_embedding_ctx_length = False,</span><br><span class="line">    dimensions=1536 </span><br><span class="line">)</span><br><span class="line">store = InMemoryStore(</span><br><span class="line">    index=&#123; # 存储提取的记忆 </span><br><span class="line">        &quot;dims&quot;: 1536,</span><br><span class="line">        &quot;embed&quot;: embedding,</span><br><span class="line">    &#125;</span><br><span class="line">) </span><br><span class="line">checkpointer = MemorySaver() # 检查点图状态 </span><br></pre></td></tr></table></figure>
<p><strong>定义agent</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">model_qwen=ChatOpenAI(</span><br><span class="line">    api_key=&quot;sk-&quot;, </span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">    model=&quot;qwen3-30b-a3b-instruct-2507&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">agent = create_react_agent( </span><br><span class="line">    model=model_qwen,</span><br><span class="line">    prompt=prompt,</span><br><span class="line">    tools=[ # 添加记忆工具 </span><br><span class="line">        # 智能体可以调用 &quot;manage_memory&quot; 来</span><br><span class="line">        # 通过ID创建、更新和删除记忆</span><br><span class="line">        # 命名空间为记忆添加作用域。要</span><br><span class="line">        # 为每个用户限定记忆范围，使用 (&quot;memories&quot;, &quot;&#123;user_id&#125;&quot;): </span><br><span class="line">        create_manage_memory_tool(namespace=(&quot;memories&quot;,)),</span><br><span class="line">    ],</span><br><span class="line">    # 我们的记忆将存储在这个提供的BaseStore实例中</span><br><span class="line">    store=store,</span><br><span class="line">    # 图的&quot;状态&quot;将在每个节点完成执行后进行检查点</span><br><span class="line">    # 用于跟踪聊天历史和持久执行</span><br><span class="line">    checkpointer=checkpointer, </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>可视化图</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">agent.get_graph().draw_mermaid_png(output_file_path=&quot;agent.png&quot;)</span><br></pre></td></tr></table></figure>
<p><strong>在线程a让agent记住我们的偏好</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;thread-a&quot;&#125;&#125; </span><br><span class="line">agent.invoke( </span><br><span class="line">    &#123; </span><br><span class="line">        &quot;messages&quot;: [ </span><br><span class="line">            &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;我喜欢黑色的显示模式&quot;&#125; </span><br><span class="line">        ] </span><br><span class="line">    &#125;, </span><br><span class="line">    # 我们将通过使用具有相同thread_id的config</span><br><span class="line">    # 来继续对话(thread-a)</span><br><span class="line">    config=config, </span><br><span class="line">) </span><br><span class="line">print(response[&quot;messages&quot;][-1].content) </span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">是的，我知道！你偏好黑色显示模式。我会在后续交互中保持这一设置。</span><br></pre></td></tr></table></figure>
<p><strong>在线程b查看是否记住</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新线程 = 新对话！</span><br><span class="line">new_config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;thread-b&quot;&#125;&#125; </span><br><span class="line"># 智能体只能回忆起</span><br><span class="line"># 它使用manage_memories工具明确保存的内容</span><br><span class="line">response = agent.invoke( </span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好。你还记得我吗？你知道我有什么偏好吗？&quot;&#125;]&#125;,</span><br><span class="line">    config=new_config, </span><br><span class="line">) </span><br><span class="line">print(response[&quot;messages&quot;][-1].content) </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">你好！虽然我无法记住你作为个体的详细信息，但我可以访问一些关于你的偏好信息。根据之前的记录，我知道你偏好使用黑色显示模式。如果你还有其他偏好或希望我记住什么，请告诉我，我会帮你记录下来。</span><br></pre></td></tr></table></figure>
<h3 id="后台快速入门指南">后台快速入门指南</h3>
<p>本指南将向您展示如何使用 <a href="https://github.langchain.ac.cn/langmem/background_quickstart/"><code>create_memory_store_manager</code></a>
在后台提取和整合记忆。当记忆在后台处理时，智能体将正常继续运行。</p>
<ol type="1">
<li><p><strong>Runnable:</strong> LangChain/LangGraph
中的核心抽象，代表一个可以被调用（<code>invoke</code>/<code>ainvoke</code>）来处理输入并产生输出的单元。<code>MemoryStoreManager</code>
本身就是一个 Runnable。</p></li>
<li><p><strong>BaseStore:</strong> LangGraph
提供的持久化存储接口。Manager
会使用它来读取（搜索）和写入（创建、更新、删除）记忆。</p></li>
<li><p><strong>Memory (记忆):</strong> 在 Manager
的上下文中，记忆通常是指从对话中提取的、值得保存的片段信息（如用户偏好、事实等）。它们存储在
<code>BaseStore</code> 中，有自己的 <code>namespace</code> 和
<code>key</code>。</p></li>
<li><p><strong>Schema (模式):</strong> 一个 Pydantic
模型，用于定义记忆的结构。这允许你强制记忆遵循特定的格式（例如，包含
<code>category</code>, <code>preference</code>, <code>context</code>
字段）。如果未提供
<code>schemas</code>，则默认使用非结构化的字符串。</p></li>
<li><p><strong>Namespace (命名空间):</strong> 用于组织存储在
<code>BaseStore</code> 中的记忆。支持使用占位符（如
<code>&#123;langgraph_user_id&#125;</code>）进行动态配置。</p></li>
<li><p>自动化流程:</p>
<p>Manager 会自动执行以下步骤：</p>
<ul>
<li><strong>搜索 (Search):</strong> 根据新对话内容，在
<code>BaseStore</code> 中查找相关的现有记忆。</li>
<li><strong>分析/提取 (Analyze/Extract):</strong> 使用 LLM
分析新对话和检索到的记忆，决定是否需要创建新记忆、更新现有记忆或删除过时记忆。</li>
<li><strong>应用更改 (Apply Changes):</strong>
将分析结果（记忆的增删改）写回到 <code>BaseStore</code>。</li>
</ul></li>
</ol>
<h4 id="实战-1">实战</h4>
<p><strong>导入库</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.chat_models import init_chat_model </span><br><span class="line">from langgraph.func import entrypoint </span><br><span class="line">from langgraph.store.memory import InMemoryStore </span><br><span class="line"></span><br><span class="line">from langmem import ReflectionExecutor, create_memory_store_manager </span><br></pre></td></tr></table></figure>
<p><strong>定义store</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_openai import OpenAIEmbeddings</span><br><span class="line">embedding=OpenAIEmbeddings(</span><br><span class="line">    api_key=&quot;sk-&quot;, </span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">    model=&quot;text-embedding-v4&quot;,</span><br><span class="line">    check_embedding_ctx_length = False,</span><br><span class="line">    dimensions=1536 </span><br><span class="line">)</span><br><span class="line">store = InMemoryStore(</span><br><span class="line">    index=&#123; # 存储提取的记忆 </span><br><span class="line">        &quot;dims&quot;: 1536,</span><br><span class="line">        &quot;embed&quot;: embedding,</span><br><span class="line">    &#125;</span><br><span class="line">) </span><br></pre></td></tr></table></figure>
<p><strong>创建记忆管理器</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建记忆管理器 Runnable 来从对话中提取记忆</span><br><span class="line">memory_manager = create_memory_store_manager( </span><br><span class="line">    model_qwen, </span><br><span class="line">    # 将记忆存储在 &quot;memories&quot; 命名空间（即目录）中</span><br><span class="line">    namespace=(&quot;memories&quot;,),  </span><br><span class="line">    instructions=&quot;用中文存储记忆。&quot;</span><br><span class="line">) </span><br><span class="line"></span><br><span class="line"># 包装 memory_manager 以处理延迟的后台处理</span><br><span class="line">executor = ReflectionExecutor(memory_manager) </span><br></pre></td></tr></table></figure>
<p>对每条消息都进行记忆处理存在以下缺点： -
当消息快速连续到达时，会产生冗余工作 -
在对话中途进行处理时，上下文不完整 - 不必要的 token 消耗</p>
<p><a href="https://github.langchain.ac.cn/langmem/reference/utils/#langmem.ReflectionExecutor"><code>ReflectionExecutor</code></a>
可以延迟记忆处理并取消冗余工作。</p>
<p><strong>创建工作流</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">model_qwen=ChatOpenAI(</span><br><span class="line">    api_key=&quot;sk-&quot;, </span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">    model=&quot;qwen3-30b-a3b-instruct-2507&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">@entrypoint(store=store)  # 创建一个 LangGraph 工作流</span><br><span class="line">async def chat(message: str): </span><br><span class="line">    response = model_qwen.invoke(message) </span><br><span class="line"></span><br><span class="line">    # memory_manager 从对话历史中提取记忆</span><br><span class="line">    # 我们将以 OpenAI 的消息格式提供它</span><br><span class="line">    to_process = &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message&#125;] + [response]&#125; </span><br><span class="line">    await memory_manager.ainvoke(to_process)  </span><br><span class="line">    return response.content </span><br><span class="line"></span><br><span class="line"># 正常运行对话</span><br><span class="line">response = await chat.ainvoke( </span><br><span class="line">    &quot;记住我是张熙浚&quot;, </span><br><span class="line">) </span><br><span class="line">print(response) </span><br></pre></td></tr></table></figure>
<p><strong>查看记忆</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(store.search((&quot;memories&quot;,)))</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://github.langchain.ac.cn/langmem/">简介 - LangChain
框架</a></p>
<p><a href="https://github.langchain.ac.cn/langmem/concepts/conceptual_guide/#semantic-memory-facts-and-knowledge">核心概念
- LangChain 框架</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langmem</category>
      </categories>
      <tags>
        <tag>langmem</tag>
      </tags>
  </entry>
  <entry>
    <title>LangGraph学习——agent——下</title>
    <url>/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>本教程为langchain官方教程的学习记录</p>
<p><a href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a href="https://github.com/zxj-2023/learn-rag-langchain">[learn-rag-langchain/academy-langgraph
at main ·
zxj-2023/learn-rag-langchain](https://github.com/zxj-2023/learn-rag-langchain/tree/main/academy-langgraph)</a></p>
<h3 id="module-4">module-4</h3>
<h4 id="parallel-node-execution-并行节点执行"><strong>Parallel node
execution</strong> <strong>并行节点执行</strong></h4>
<h5 id="waiting-for-nodes-to-finish-等待节点完成"><strong>Waiting for
nodes to finish</strong> <strong>等待节点完成</strong></h5>
<p>现在，让我们考虑一个案例，其中一个并行路径的步骤比另一个多。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># Initialize each node with node_secret </span><br><span class="line">builder.add_node(&quot;a&quot;, ReturnNodeValue(&quot;I&#x27;m A&quot;))</span><br><span class="line">builder.add_node(&quot;b&quot;, ReturnNodeValue(&quot;I&#x27;m B&quot;))</span><br><span class="line">builder.add_node(&quot;b2&quot;, ReturnNodeValue(&quot;I&#x27;m B2&quot;))</span><br><span class="line">builder.add_node(&quot;c&quot;, ReturnNodeValue(&quot;I&#x27;m C&quot;))</span><br><span class="line">builder.add_node(&quot;d&quot;, ReturnNodeValue(&quot;I&#x27;m D&quot;))</span><br><span class="line"></span><br><span class="line"># Flow</span><br><span class="line">builder.add_edge(START, &quot;a&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;b&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;c&quot;)</span><br><span class="line">builder.add_edge(&quot;b&quot;, &quot;b2&quot;)</span><br><span class="line">builder.add_edge([&quot;b2&quot;, &quot;c&quot;], &quot;d&quot;)</span><br><span class="line">builder.add_edge(&quot;d&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722143802652.png" alt="image-20250722143802652">
<figcaption aria-hidden="true">image-20250722143802652</figcaption>
</figure>
<p>在这种情况下，<code>b</code>、<code>b2</code> 和 <code>c</code>
都是同一个步骤的一部分。图形将在进入 <code>d</code>
步骤之前等待所有这些操作完成。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Adding I&#x27;m A to []</span><br><span class="line">Adding I&#x27;m B to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m C to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m B2 to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;]</span><br><span class="line">Adding I&#x27;m D to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;]</span><br><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="setting-the-order-of-state-updates-设置状态更新的顺序"><strong>Setting
the order of state updates</strong>
<strong>设置状态更新的顺序</strong></h5>
<p>然而，在每个步骤中，我们无法对状态更新的顺序进行具体控制！简单来说，它是基于图拓扑结构由
LangGraph 确定的确定性顺序，该顺序为
<strong><em>*我们无法控制*</em></strong>。</p>
<p>上面，我们看到 <code>c</code> 被添加在 <code>b2</code> 之前</p>
<p>然而，我们可以使用自定义 reducer
来定制此功能，例如，对状态更新进行排序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def sorting_reducer(left, right):</span><br><span class="line">    &quot;&quot;&quot; 合并并排序列表中的值&quot;&quot;&quot;</span><br><span class="line">    # 如果 left 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(left, list):</span><br><span class="line">        left = [left]</span><br><span class="line"></span><br><span class="line">    # 如果 right 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(right, list):</span><br><span class="line">        right = [right]</span><br><span class="line">    </span><br><span class="line">    # 合并 left 和 right 列表，然后升序排序</span><br><span class="line">    return sorted(left + right, reverse=False)</span><br><span class="line">class State(TypedDict):</span><br><span class="line">    # sorting_reducer 函数将对 state 中的值进行排序</span><br><span class="line">    state: Annotated[list, sorting_reducer]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<p>现在，reducer 对更新的状态值进行排序！<code>sorting_reducer</code>
示例对所有值进行全局排序。我们还可以：</p>
<ol type="1">
<li>在并行步骤期间将输出写入状态中的单独字段<br>
</li>
<li>在并行步骤之后使用“汇”节点来合并和排序这些输出<br>
</li>
<li>合并后清除临时字段</li>
</ol>
<p>请参阅 <a href="https://langchain-ai.github.io/langgraph/how-tos/branching/#stable-sorting">docs</a>
以获取更多详细信息。</p>
<h5 id="working-with-llms-使用-llms"><strong>Working with LLMs</strong>
<strong>使用 LLMs</strong></h5>
<p>现在，让我们添加一个现实中的例子！我们希望从两个外部来源（Wikipedia
和 Web-Search）收集上下文信息，并让 LLM 回答一个问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br><span class="line">from langchain_community.tools import TavilySearchResults</span><br><span class="line"></span><br><span class="line">def search_web(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">    search_docs = tavily_search.invoke(state[&#x27;question&#x27;])</span><br><span class="line"></span><br><span class="line">     # 将多个搜索文档转换成了一个统一格式的长文本，每个文档都有自己的元数据（如URL），并且文档之间有明确的分隔，便于后续处理或展示。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    - 这是一个 列表推导式 (list comprehension) ，它会遍历 search_docs 列表中的每一个元素（这里我们称之为 doc ）。</span><br><span class="line">    - search_docs 里的每个 doc 应该是一个包含 &#x27;url&#x27; 和 &#x27;content&#x27; 键的字典。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = WikipediaLoader(query=state[&#x27;question&#x27;], </span><br><span class="line">                                  load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def generate_answer(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 用于回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    question = state[&quot;question&quot;]</span><br><span class="line"></span><br><span class="line">    # 模板</span><br><span class="line">    answer_template = &quot;&quot;&quot;使用以下上下文回答问题 &#123;question&#125;: &#123;context&#125;&quot;&quot;&quot;</span><br><span class="line">    answer_instructions = answer_template.format(question=question, </span><br><span class="line">                                                       context=context)    </span><br><span class="line">    </span><br><span class="line">    # 回答</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=answer_instructions)]+[HumanMessage(content=f&quot;回答问题。&quot;)])</span><br><span class="line">      </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;answer&quot;: answer&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点</span><br><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># 初始化每个节点</span><br><span class="line">builder.add_node(&quot;search_web&quot;,search_web)</span><br><span class="line">builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">builder.add_node(&quot;generate_answer&quot;, generate_answer)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">builder.add_edge(START, &quot;search_wikipedia&quot;)</span><br><span class="line">builder.add_edge(START, &quot;search_web&quot;)</span><br><span class="line">builder.add_edge(&quot;search_wikipedia&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;search_web&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;generate_answer&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722153534867.png" alt="image-20250722153534867">
<figcaption aria-hidden="true">image-20250722153534867</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">result = graph.invoke(&#123;&quot;question&quot;: &quot;英伟达2025年第一季度财报表现如何&quot;&#125;)</span><br><span class="line">result[&#x27;answer&#x27;].content</span><br></pre></td></tr></table></figure>
<h4 id="sub-graphs-子图"><strong>Sub-graphs</strong> 子图</h4>
<p>子图允许你在图表的不同部分创建和管理不同的状态。这在多智能体系统中尤其有用，尤其是在每个智能体都有各自状态的智能体团队中。</p>
<p>让我们考虑一个简单的例子：</p>
<ul>
<li>我有一个系统，它接收日志。</li>
<li>该系统通过不同的代理执行两个独立的子任务（总结日志，查找故障模式）。</li>
<li>我希望在两个不同的子图中执行这两个操作。</li>
</ul>
<p>最重要的是要理解图表是如何传达信息的！</p>
<p>简而言之，通信是 <strong><em>*通过重叠密钥*</em></strong>
实现的：</p>
<ul>
<li>子图可以访问父图中的 <code>docs</code>（文档）。</li>
<li>父图可以从子图中访问 <code>summary</code>（摘要）和
<code>failure_report</code>（故障报告）。</li>
</ul>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/66dbb1abf89f2d847ee6f1ff_sub-graph1.png" alt="subgraph.png">
<figcaption aria-hidden="true">subgraph.png</figcaption>
</figure>
<ol type="1">
<li><strong>Logs (Traces)</strong>:
<ul>
<li>这是系统的输入，表示一系列的日志记录。</li>
</ul></li>
<li><strong>Entry Graph</strong>:
<ul>
<li>这是系统的入口图，它包含了总体状态（Overall State），其中包含：
<ul>
<li><code>docs</code>：文档或日志数据。</li>
<li><code>summary report</code>：摘要报告，这是系统执行摘要任务后生成的。</li>
<li><code>failure report</code>：故障报告，这是系统执行故障分析任务后生成的。</li>
</ul></li>
</ul></li>
<li><strong>Call sub-graphs</strong>:
<ul>
<li>这是从入口图调用两个子图的过程，分别用于执行摘要和故障分析任务。</li>
</ul></li>
<li><strong>Summarization</strong>:
<ul>
<li>这个子图负责生成日志的摘要。它的状态（Summary State）包含：
<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>summary</code>：摘要内容。</li>
<li><code>summary report</code>：摘要报告，这是摘要任务完成后生成的。</li>
</ul></li>
</ul></li>
<li><strong>Failure Analysis</strong>:
<ul>
<li>这个子图负责分析日志中的故障模式。它的状态（Failure Analysis
State）包含：
<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>failures</code>：故障模式。</li>
<li><code>failure report</code>：故障报告，这是故障分析任务完成后生成的。</li>
</ul></li>
</ul></li>
<li><strong>Finish</strong>:
<ul>
<li>这是流程的结束点，表示两个子图的任务都已完成，并且生成了摘要报告和故障报告。</li>
</ul></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from typing import List, Optional, Annotated</span><br><span class="line"></span><br><span class="line">#logs结构</span><br><span class="line">class Log(TypedDict):</span><br><span class="line">    id: str</span><br><span class="line">    question: str</span><br><span class="line">    docs: Optional[List]</span><br><span class="line">    answer: str</span><br><span class="line">    grade: Optional[int]</span><br><span class="line">    grader: Optional[str]</span><br><span class="line">    feedback: Optional[str]</span><br></pre></td></tr></table></figure>
<h5 id="sub-graphs"><strong>Sub graphs</strong></h5>
<p>这里是失败分析子图，它使用了 <code>FailureAnalysisState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line"># 故障分析子图</span><br><span class="line">class FailureAnalysisState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于故障分析的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    failures: List[Log]     # 包含故障的日志列表</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class FailureAnalysisOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;故障分析的输出状态。&quot;&quot;&quot;</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def get_failures(state):</span><br><span class="line">    &quot;&quot;&quot;获取包含故障的日志&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 从清理后的日志中筛选出包含 &quot;grade&quot; 键的日志，这些被视为故障</span><br><span class="line">    failures = [log for log in cleaned_logs if &quot;grade&quot; in log]</span><br><span class="line">    return &#123;&quot;failures&quot;: failures&#125;</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;生成故障摘要&quot;&quot;&quot;</span><br><span class="line">    failures = state[&quot;failures&quot;]</span><br><span class="line">    # 添加功能：fa_summary = summary_generation(qs_summary)</span><br><span class="line">    fa_summary = &quot;Chroma 文档的检索质量不佳。&quot;</span><br><span class="line">    # 为每个故障日志生成一个处理过的日志标识符</span><br><span class="line">    return &#123;&quot;fa_summary&quot;: fa_summary, &quot;processed_logs&quot;: [f&quot;failure-analysis-on-log-&#123;failure[&#x27;id&#x27;]&#125;&quot; for failure in failures]&#125;</span><br><span class="line"></span><br><span class="line">fa_builder = StateGraph(state_schema=FailureAnalysisState,output_schema=FailureAnalysisOutputState)</span><br><span class="line">fa_builder.add_node(&quot;get_failures&quot;, get_failures)</span><br><span class="line">fa_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">fa_builder.add_edge(START, &quot;get_failures&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;get_failures&quot;, &quot;generate_summary&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;generate_summary&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = fa_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723094949158.png" alt="image-20250723094949158">
<figcaption aria-hidden="true">image-20250723094949158</figcaption>
</figure>
<p>这里是问题总结子图，它使用了
<code>QuestionSummarizationState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 摘要生成子图</span><br><span class="line">class QuestionSummarizationState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于问题摘要的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    qs_summary: str         # 问题摘要</span><br><span class="line">    report: str             # 从摘要生成的报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class QuestionSummarizationOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;问题摘要的输出状态。&quot;&quot;&quot;</span><br><span class="line">    report: str             # 最终报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;从日志生成摘要。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 添加功能：summary = summarize(generate_summary)</span><br><span class="line">    summary = &quot;问题集中在 ChatOllama 和 Chroma 向量存储的使用上。&quot;</span><br><span class="line">    # 返回摘要以及已处理的日志ID</span><br><span class="line">    return &#123;&quot;qs_summary&quot;: summary, &quot;processed_logs&quot;: [f&quot;summary-on-log-&#123;log[&#x27;id&#x27;]&#125;&quot; for log in cleaned_logs]&#125;</span><br><span class="line"></span><br><span class="line">def send_to_slack(state):</span><br><span class="line">    &quot;&quot;&quot;模拟发送报告。&quot;&quot;&quot;</span><br><span class="line">    qs_summary = state[&quot;qs_summary&quot;]</span><br><span class="line">    # 添加功能：report = report_generation(qs_summary)</span><br><span class="line">    report = &quot;foo bar baz&quot;</span><br><span class="line">    return &#123;&quot;report&quot;: report&#125;</span><br><span class="line"></span><br><span class="line">qs_builder = StateGraph(QuestionSummarizationState,output_schema=QuestionSummarizationOutputState)</span><br><span class="line">qs_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">qs_builder.add_node(&quot;send_to_slack&quot;, send_to_slack)</span><br><span class="line">qs_builder.add_edge(START, &quot;generate_summary&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;generate_summary&quot;, &quot;send_to_slack&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;send_to_slack&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = qs_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723100648199.png" alt="image-20250723100648199">
<figcaption aria-hidden="true">image-20250723100648199</figcaption>
</figure>
<h5 id="adding-sub-graphs-to-our-parent-graph-向父图添加子图"><strong>Adding
sub graphs to our parent graph </strong>
<strong>向父图添加子图</strong></h5>
<p>现在，我们可以将所有内容整合在一起。我们使用
<code>EntryGraphState</code>
创建父图。并且我们将我们的子图添加为节点！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 入口图</span><br><span class="line">class EntryGraphState(TypedDict):</span><br><span class="line">    # 原始日志数据列表</span><br><span class="line">    raw_logs: List[Log]</span><br><span class="line">    # 经过清洗处理后的日志数据列表</span><br><span class="line">    cleaned_logs: List[Log]</span><br><span class="line">    fa_summary: str # 这只会在故障分析子图中生成</span><br><span class="line">    report: str # 这只会在问题摘要子图中生成</span><br><span class="line">    processed_logs:  Annotated[List[int], add] # 跟踪哪些日志已经被处理过 ，尤其是在子图之间共享状态时。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def clean_logs(state):</span><br><span class="line">    # 获取日志</span><br><span class="line">    raw_logs = state[&quot;raw_logs&quot;]</span><br><span class="line">    # 数据清洗 raw_logs -&gt; docs</span><br><span class="line">    cleaned_logs = raw_logs</span><br><span class="line">    return &#123;&quot;cleaned_logs&quot;: cleaned_logs&#125;</span><br><span class="line"></span><br><span class="line">entry_builder = StateGraph(EntryGraphState)</span><br><span class="line">entry_builder.add_node(&quot;clean_logs&quot;, clean_logs)</span><br><span class="line">#添加子图</span><br><span class="line">entry_builder.add_node(&quot;question_summarization&quot;, qs_builder.compile())</span><br><span class="line">entry_builder.add_node(&quot;failure_analysis&quot;, fa_builder.compile())</span><br><span class="line"></span><br><span class="line">entry_builder.add_edge(START, &quot;clean_logs&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;failure_analysis&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;question_summarization&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;failure_analysis&quot;, END)</span><br><span class="line">entry_builder.add_edge(&quot;question_summarization&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = entry_builder.compile()</span><br><span class="line"></span><br><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line"># 将 xray 设置为 1 将显示嵌套图的内部结构</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723102913524.png" alt="image-20250723102913524">
<figcaption aria-hidden="true">image-20250723102913524</figcaption>
</figure>
<h4 id="map-reduce"><strong>Map-reduce</strong></h4>
<p>LangGraph 里的 <strong>Map-Reduce</strong>
是一种<strong>并行处理模式</strong>，用于将一个大任务拆分成多个子任务（Map），再汇总结果（Reduce）。这是
LangGraph
中处理<strong>批量数据或并行节点执行</strong>的核心机制之一。</p>
<p>让我们设计一个系统，该系统将完成两件事情：</p>
<ol type="1">
<li><strong>映射（Map）</strong> —— 根据主题生成一组笑话。<br>
</li>
<li><strong>归约（Reduce）</strong> —— 从这组笑话中挑出最棒的一条。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"># Prompts we will use</span><br><span class="line">subjects_prompt = &quot;&quot;&quot;生成一个包含3个子主题的列表，这些子主题都与以下总体主题相关：&#123;topic&#125;。&quot;&quot;&quot;</span><br><span class="line">joke_prompt = &quot;&quot;&quot;生成一个关于&#123;subject&#125;的笑话&quot;&quot;&quot;</span><br><span class="line">best_joke_prompt = &quot;&quot;&quot;下面是关于&#123;topic&#125;的一堆笑话。选择最好的一个！返回最好笑话的ID，第一个笑话的ID从0开始。笑话：\n\n  &#123;jokes&#125;&quot;&quot;&quot;</span><br><span class="line"># LLM</span><br><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h5 id="parallelizing-joke-generation-并行化笑话生成"><strong>Parallelizing
joke generation</strong> <strong>并行化笑话生成</strong></h5>
<p>首先，让我们定义图的入口点，它将：</p>
<ul>
<li>接收用户输入的主题<br>
</li>
<li>基于该主题生成若干“笑话子主题”<br>
</li>
<li>将每个子主题发送到上面定义的笑话生成节点</li>
</ul>
<p>我们的状态有一个 <code>jokes</code>
键，它将累积来自并行化笑话生成的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Subjects(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示主题列表。&quot;&quot;&quot;</span><br><span class="line">    subjects: list[str] # 主题字符串列表</span><br><span class="line"></span><br><span class="line">class BestJoke(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示最佳笑话的ID。&quot;&quot;&quot;</span><br><span class="line">    id: int # 最佳笑话的索引ID</span><br><span class="line">    </span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;定义整个图的总体状态，使用TypedDict以便于类型提示和状态管理。&quot;&quot;&quot;</span><br><span class="line">    topic: str # 当前讨论的主题</span><br><span class="line">    subjects: list # 生成的子主题列表</span><br><span class="line">    jokes: Annotated[list, operator.add] # 笑话列表，使用operator.add表示列表内容会累加而不是覆盖</span><br><span class="line">    best_selected_joke: str # 最终选出的最佳笑话</span><br></pre></td></tr></table></figure>
<p>生成笑话的主题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#用于生成主题</span><br><span class="line">def generate_topics(state: OverallState):</span><br><span class="line">    #使用 Python 的 format() 方法来构建一个提示字符串（ prompt ）</span><br><span class="line">    prompt = subjects_prompt.format(topic=state[&quot;topic&quot;])</span><br><span class="line">    #.with_structured_output(Subjects) 它指示模型尝试将其输出格式化为 Subjects 类</span><br><span class="line">    response = model.with_structured_output(Subjects).invoke(prompt)</span><br><span class="line">    return &#123;&quot;subjects&quot;: response.subjects&#125;</span><br></pre></td></tr></table></figure>
<p>这就是妙处：我们利用 <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/#send"><code>Send</code></a>
为每个主题并行生成笑话。</p>
<p>非常实用！无论主题数量多少，它都能自动并行处理。</p>
<ul>
<li><code>generate_joke</code>：图中节点的名字<br>
</li>
<li><code>&#123;"subject": s&#125;</code>：要传递的状态</li>
</ul>
<p><code>Send</code> 允许你向 <code>generate_joke</code>
节点发送<strong>任意</strong>结构的状态，无需与
<code>OverallState</code> 对齐。<br>
在这里，<code>generate_joke</code> 使用自己的内部状态，我们通过
<code>Send</code> 按需填充即可。</p>
<blockquote>
<p>在 LangGraph 里，<code>Send</code>
是一个<strong>“动态派发器”</strong>：它让你<strong>在运行时</strong>决定“要把哪个节点运行多少次、每次给它什么数据”，并自动并行执行。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.types import Send</span><br><span class="line">def continue_to_jokes(state: OverallState):</span><br><span class="line">    # 该函数根据当前状态中的主题列表，为每个主题生成一个 Send 对象。</span><br><span class="line">    # 每个 Send 对象都指示图将数据发送到名为 &quot;generate_joke&quot; 的节点，</span><br><span class="line">    # 并将当前主题作为 &quot;subject&quot; 参数传递，从而实现并行生成笑话。</span><br><span class="line">    return [Send(&quot;generate_joke&quot;, &#123;&quot;subject&quot;: s&#125;) for s in state[&quot;subjects&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="joke-generation-map-笑话生成"><strong>Joke generation
(map)</strong> <strong>笑话生成</strong></h5>
<p>现在，我们只需定义一个节点来生成笑话，命名为
<code>generate_joke</code>！</p>
<p>生成的笑话会被写回到 <code>OverallState</code> 中的
<code>jokes</code> 字段。 该字段配有
reducer，能够自动把多次写入的列表合并成一个大列表。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 定义 JokeState，用于表示生成笑话任务的输入状态。</span><br><span class="line">class JokeState(TypedDict):</span><br><span class="line">    subject: str#笑话的主题</span><br><span class="line"></span><br><span class="line"># 定义 Joke 模型，用于表示模型生成的笑话的结构。</span><br><span class="line">class Joke(BaseModel):</span><br><span class="line">    joke: str#笑话的文本内容</span><br><span class="line"></span><br><span class="line"># 定义生成笑话的函数。</span><br><span class="line">def generate_joke(state: JokeState):</span><br><span class="line">    # 根据 joke_prompt 模板和当前状态中的主题格式化提示。</span><br><span class="line">    prompt = joke_prompt.format(subject=state[&quot;subject&quot;])</span><br><span class="line">    # 调用语言模型，并指定输出应结构化为 Joke 类型。</span><br><span class="line">    response = model.with_structured_output(Joke).invoke(prompt)</span><br><span class="line">    # 返回一个包含生成的笑话的字典，键为 &quot;jokes&quot;。</span><br><span class="line">    return &#123;&quot;jokes&quot;: [response.joke]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="best-joke-selection-reduce-最佳笑话选择"><strong>Best joke
selection (reduce)</strong> <strong>最佳笑话选择</strong></h5>
<p>现在，我们添加逻辑来挑选最好的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def best_joke(state: OverallState):</span><br><span class="line">    # 将状态中所有笑话列表连接成一个字符串，每个笑话之间用两个换行符分隔</span><br><span class="line">    jokes = &quot;\n\n&quot;.join(state[&quot;jokes&quot;])</span><br><span class="line">    # 使用主题和所有笑话格式化最佳笑话提示语</span><br><span class="line">    prompt = best_joke_prompt.format(topic=state[&quot;topic&quot;], jokes=jokes)</span><br><span class="line">    # 调用模型，期望其输出符合 BestJoke 结构（包含最佳笑话的ID）</span><br><span class="line">    response = model.with_structured_output(BestJoke).invoke(prompt)</span><br><span class="line">    # 根据模型返回的ID，从笑话列表中选择最佳笑话，并将其存储在状态的 best_selected_joke 字段中</span><br><span class="line">    return &#123;&quot;best_selected_joke&quot;: state[&quot;jokes&quot;][response.id]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="compile-编译"><strong>Compile</strong> 编译</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image</span><br><span class="line">from langgraph.graph import END, StateGraph, START</span><br><span class="line"></span><br><span class="line"># 构建图：将所有组件组合在一起构建我们的流程图</span><br><span class="line">graph = StateGraph(OverallState)</span><br><span class="line"></span><br><span class="line">graph.add_node(&quot;generate_topics&quot;, generate_topics)</span><br><span class="line">graph.add_node(&quot;generate_joke&quot;, generate_joke)</span><br><span class="line">graph.add_node(&quot;best_joke&quot;, best_joke)</span><br><span class="line"></span><br><span class="line">graph.add_edge(START, &quot;generate_topics&quot;)</span><br><span class="line"># 根据条件决定是否继续生成笑话</span><br><span class="line">graph.add_conditional_edges(&quot;generate_topics&quot;, continue_to_jokes, [&quot;generate_joke&quot;])</span><br><span class="line"># 生成笑话后执行选择最佳笑话</span><br><span class="line">graph.add_edge(&quot;generate_joke&quot;, &quot;best_joke&quot;)</span><br><span class="line"># 选择最佳笑话后流程结束</span><br><span class="line">graph.add_edge(&quot;best_joke&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = graph.compile()</span><br><span class="line">Image(app.get_graph().draw_mermaid_png())</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723112736244.png" alt="image-20250723112736244">
<figcaption aria-hidden="true">image-20250723112736244</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for s in app.stream(&#123;&quot;topic&quot;: &quot;日本广岛原子弹&quot;&#125;):</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;generate_topics&#x27;: &#123;&#x27;subjects&#x27;: [&#x27;原子弹投放的历史背景与决策过程&#x27;, &#x27;广岛原爆对城市与居民的影响&#x27;, &#x27;战后和平运动与核裁军倡议&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;战后和平运动的人开会讨论核裁军，一个人站起来说：‘我们必须彻底销毁所有核武器！’ 另一个人犹豫地举手：‘那……我们保留一个吧，就一个，藏在冰箱后面，以防万一。’&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&quot;杜鲁门宣布要结束战争，顾问问是否要使用原子弹。罗斯福的棺材板突然震动了一下，丘吉尔的雪茄掉在了地上，斯大林则默默拿起了电话：&#x27;同志，我们的计划可能需要再推迟一下。&#x27;&quot;]&#125;&#125;</span><br><span class="line">&#123;&#x27;best_joke&#x27;: &#123;&#x27;best_selected_joke&#x27;: &#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Research Assistant</strong> <strong>研究助理</strong></p>
<p>见另一篇文章</p>
<h3 id="module-5">module-5</h3>
<h4 id="chatbot-with-memory-带有记忆功能的聊天机器人"><strong>Chatbot
with Memory</strong> <strong>带有记忆功能的聊天机器人</strong></h4>
<p>在这里，我们将介绍 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Memory Store</a> 作为一种保存和检索长期记忆的方法。</p>
<blockquote>
<p>LangGraph Memory Store 是 <strong>LangGraph
提供的长期记忆存储接口</strong>，用于在
<strong>不同对话线程之间</strong> 持久化保存和检索用户信息。</p>
<table>
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead>
<tr>
<th>名称</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BaseStore</strong></td>
<td>抽象接口，定义了 <code>put/get/search/delete</code> 等操作方法</td>
</tr>
<tr>
<td><strong>InMemoryStore</strong></td>
<td>内存实现，适合原型验证</td>
</tr>
<tr>
<td><strong>RedisStore / AsyncRedisStore</strong></td>
<td>生产级实现，支持向量搜索、元数据过滤和命名空间管理</td>
</tr>
</tbody>
</table>
</blockquote>
<p>我们将构建一个使用
<code>short-term (within-thread仅当前对话线程)</code> 和
<code>long-term (across-thread跨所有对话线程    )</code>
内存的聊天机器人。</p>
<p>我们将重点关注长期 <a href="https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory">semantic
memory<strong>（语义记忆）</strong></a>，它将包含关于用户的事实信息。这些长期记忆将被用于创建一个个性化的聊天机器人，它可以记住有关用户的事实。</p>
<p>它将节省内存 <a href="https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories">“in
the hot path”</a>，当用户与之聊天时。</p>
<blockquote>
<p><strong>“in the hot path”</strong>
指的是：<strong>在对话或任务执行的</strong>主流程中<strong>（即用户输入后立即、同步地）</strong>主动调用工具或写入记忆，使信息<strong>实时生效</strong>并可用于下一步决策。</p>
</blockquote>
<h5 id="introduction-to-the-langgraph-store-langgraph-存储简介"><strong>Introduction
to the LangGraph Store</strong> <strong>LangGraph 存储简介</strong></h5>
<p><a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Memory Store</a> 提供了一种在 LangGraph 中 <strong>跨线程</strong>
存储和检索信息的方式。这是一个用于持久化 <code>key-value</code> 存储的
<a href="https://blog.langchain.dev/launching-long-term-memory-support-in-langgraph/">开源基类</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line">in_memory_store = InMemoryStore()</span><br></pre></td></tr></table></figure>
<p>在 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">Store</a>
中存储对象（例如，记忆）时，我们提供：</p>
<p>- 对象的 <code>namespace</code>（类似于目录的元组）</p>
<p>- 对象的 <code>key</code>（类似于文件名）</p>
<p>- 对象的 <code>value</code>（类似于文件内容）</p>
<p>我们使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a>
方法通过 <code>namespace</code> 和 <code>key</code>
将对象保存到存储中。</p>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725155616205-1753430177489-3.png" alt="image-20250725155616205">
<figcaption aria-hidden="true">image-20250725155616205</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;  # 用户ID</span><br><span class="line">namespace_for_memory = (user_id, &quot;memories&quot;)  # 记忆命名空间</span><br><span class="line"></span><br><span class="line"># 生成一个唯一的键值</span><br><span class="line">key = str(uuid.uuid4())  # 使用UUID创建唯一标识符作为键</span><br><span class="line"></span><br><span class="line"># 值需要是一个字典格式</span><br><span class="line">value = &#123;&quot;food_preference&quot;: &quot;我喜欢披萨&quot;&#125;  # 存储的食物偏好信息</span><br><span class="line"></span><br><span class="line"># 保存记忆</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)  # 将记忆存储到内存中</span><br></pre></td></tr></table></figure>
<p>我们使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a>
通过 <code>namespace</code> 从存储中检索对象。这将返回一个列表。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">memories = in_memory_store.search(namespace_for_memory)</span><br><span class="line">type(memories)</span><br><span class="line"></span><br><span class="line"># Metatdata </span><br><span class="line">memories[0].dict()</span><br><span class="line"></span><br><span class="line"># The key, value</span><br><span class="line">print(memories[0].key, memories[0].value)</span><br><span class="line">9e65de8a-f404-4974-b509-0df0566d8fb5 &#123;&#x27;food_preference&#x27;: &#x27;我喜欢披萨&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a>
通过 <code>namespace</code> 和 <code>key</code> 检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Get the memory by namespace and key</span><br><span class="line">memory = in_memory_store.get(namespace_for_memory, key)</span><br><span class="line">memory.dict()</span><br></pre></td></tr></table></figure>
<h5 id="chatbot-with-long-term-memory-具有长期记忆的聊天机器人"><strong>Chatbot
with long-term memory</strong>
<strong>具有长期记忆的聊天机器人</strong></h5>
<p>我们想要一个聊天机器人，<a href="https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_156">有两种记忆的方式</a>:</p>
<ol type="1">
<li><code>Short-term (within-thread) memory</code>:
聊天机器人可以保留会话历史记录和/或允许在聊天会话中进行中断。<br>
</li>
<li><code>Long-term (cross-thread) memory</code>:
聊天机器人可以记住特定用户在所有聊天会话中的信息
<strong>跨会话</strong>。</li>
</ol>
<p>对于 <code>short-term memory</code>，我们将使用一个 <a href="https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries">checkpointer</a>。</p>
<ul>
<li>他们在每一步都将图状态写入线程中。</li>
<li>他们在该线程中持久化保存聊天历史记录。</li>
<li>他们允许图在该线程中的任何步骤被中断和/或恢复。</li>
</ul>
<p>对于 <code>long-term memory</code>，我们将使用上面介绍的 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Store</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的有用助手，能够提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;&quot;你正在收集用户信息以个性化你的回复。</span><br><span class="line"></span><br><span class="line">当前用户信息：</span><br><span class="line">&#123;memory&#125;</span><br><span class="line"></span><br><span class="line">指令：</span><br><span class="line">1. 仔细查看下面的聊天历史</span><br><span class="line">2. 识别有关用户的新信息，例如：</span><br><span class="line">   - 个人详情（姓名、位置）</span><br><span class="line">   - 偏好（喜欢、不喜欢）</span><br><span class="line">   - 兴趣和爱好</span><br><span class="line">   - 过去的经历</span><br><span class="line">   - 目标或未来计划</span><br><span class="line">3. 将任何新信息与现有记忆合并</span><br><span class="line">4. 将记忆格式化为清晰的项目符号列表</span><br><span class="line">5. 如果新信息与现有记忆冲突，请保留最新版本</span><br><span class="line"></span><br><span class="line">记住：只包括用户直接陈述的事实信息。不要做假设或推断。</span><br><span class="line"></span><br><span class="line">基于以下聊天历史，请更新用户信息：&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    existing_memory = store.get(namespace, key)</span><br><span class="line"></span><br><span class="line">    # 如果存在则提取实际的记忆内容并添加前缀</span><br><span class="line">    if existing_memory:</span><br><span class="line">        # 值是一个带有memory键的字典</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)</span><br><span class="line">    </span><br><span class="line">    # 使用记忆以及聊天历史进行回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">        </span><br><span class="line">    # 提取记忆</span><br><span class="line">    if existing_memory:</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)</span><br><span class="line">    new_memory = model.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖存储中的现有记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line"></span><br><span class="line">    # 将值写入为带有memory键的字典</span><br><span class="line">    store.put(namespace, key, &#123;&quot;memory&quot;: new_memory.content&#125;)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于跨线程的长期记忆存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于线程内的短期记忆检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点器和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725161106319.png" alt="image-20250725161106319">
<figcaption aria-hidden="true">image-20250725161106319</figcaption>
</figure>
<p>聊天历史将通过检查点工具保存到短期记忆中。聊天机器人将回顾聊天历史。然后，它将创建并保存一个记忆到
<a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Store</a>。此内存可在未来的聊天会话中访问，以个性化聊天机器人的响应。</p>
<p>当我们与聊天机器人交互时，我们提供两样东西：</p>
<ol type="1">
<li><code>Short-term (within-thread) memory</code>:
一个用于持久化聊天历史的 <code>thread ID</code>。<br>
</li>
<li><code>Long-term (cross-thread) memory</code>:
一个用于将长期记忆命名空间到用户的 <code>user ID</code>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br><span class="line">    </span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，我的名字是Lance</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，Lance！很高兴认识你。有什么我可以帮你的吗？😊</span><br></pre></td></tr></table></figure>
<p>我们正在使用 <code>MemorySaver</code>
检查点来管理线程内内存。这会将聊天历史保存到线程中。我们可以查看保存到线程的聊天历史记录。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">state = graph.get_state(thread).values</span><br><span class="line">for m in state[&quot;messages&quot;]: </span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>回想一下，我们使用存储库编译了该图：<code>across_thread_memory = InMemoryStore()</code>并且，我们向图中添加了一个节点
(<code>write_memory</code>)，该节点反映了聊天历史并保存了一段记忆到存储中。</p>
<p>我们可以查看内存是否已保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.dict()</span><br><span class="line"></span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;memory&#x27;, &#x27;1&#x27;],</span><br><span class="line"> &#x27;key&#x27;: &#x27;user_memory&#x27;,</span><br><span class="line"> &#x27;value&#x27;: &#123;&#x27;memory&#x27;: &#x27;- 姓名：Lance  \n- 位置：旧金山  \n- 兴趣和爱好：骑自行车  \n- 喜欢的活动：在旧金山骑行，可能包括金门大桥和滨海区路线&#x27;&#125;,</span><br><span class="line"> &#x27;created_at&#x27;: &#x27;2025-07-25T08:12:35.877160+00:00&#x27;,</span><br><span class="line"> &#x27;updated_at&#x27;: &#x27;2025-07-25T08:12:35.877161+00:00&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>现在，让我们以
<strong>相同的用户ID</strong>启动一个<strong>新线程</strong>。我们应该看到聊天机器人记住了用户的个人资料，并将其用于个性化响应。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们提供用户ID用于跨线程记忆以及一个新的线程ID</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好！你推荐我去哪里骑自行车？&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="chatbot-with-profile-schema-带有配置文件模式的聊天机器人"><strong>Chatbot
with Profile Schema</strong>
<strong>带有配置文件模式的聊天机器人</strong></h4>
<p>我们的聊天机器人将记忆保存为字符串。在实践中，我们通常希望记忆具有结构化格式。例如，记忆可以是<a href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">单个、持续更新的模式</a>。在我们的案例中，我们希望这是一个单一的用户档案。</p>
<p>我们将扩展我们的聊天机器人，将语义记忆保存到单个<a href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">用户档案</a>中。我们还将介绍一个库
<a href="https://github.com/hinthornw/trustcall">Trustcall</a>，用于使用新信息更新此模式。</p>
<h5 id="defining-a-user-profile-schema-定义用户配置文件模式"><strong>Defining
a user profile schema</strong>
<strong>定义用户配置文件模式</strong></h5>
<p>Python 有许多不同类型的 <a href="https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition">structured
data</a>，例如 TypedDict、字典、JSON 和 <a href="https://docs.pydantic.dev/latest/">Pydantic</a>。</p>
<p>让我们先使用 TypedDict 来定义一个用户资料模式。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import TypedDict, List</span><br><span class="line"></span><br><span class="line">class UserProfile(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;带有类型字段的用户档案模式&quot;&quot;&quot;</span><br><span class="line">    user_name: str  # 用户的首选名称</span><br><span class="line">    interests: List[str]  # 用户兴趣列表</span><br></pre></td></tr></table></figure>
<h5 id="saving-a-schema-to-the-store-将模式保存到存储中"><strong>Saving
a schema to the store</strong> <strong>将模式保存到存储中</strong></h5>
<p><a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph
Store</a> 接受任何 Python 字典作为 <code>value</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># TypedDict 实例</span><br><span class="line">user_profile: UserProfile = &#123;</span><br><span class="line">    &quot;user_name&quot;: &quot;Lance&quot;,  # 用户名</span><br><span class="line">    &quot;interests&quot;: [&quot;骑行&quot;, &quot;科技&quot;, &quot;咖啡&quot;]  # 兴趣爱好</span><br><span class="line">&#125;</span><br><span class="line">user_profile</span><br></pre></td></tr></table></figure>
<p>我们使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a>
方法将 TypedDict 保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line"></span><br><span class="line"># 初始化内存存储</span><br><span class="line">in_memory_store = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 为要保存的记忆创建命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace_for_memory = (user_id, &quot;memory&quot;)</span><br><span class="line"></span><br><span class="line"># 将记忆以键值对的形式保存到命名空间中</span><br><span class="line">key = &quot;user_profile&quot;</span><br><span class="line">value = user_profile</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)</span><br></pre></td></tr></table></figure>
<p>我们使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a>
按命名空间从存储中检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for m in in_memory_store.search(namespace_for_memory):</span><br><span class="line">    print(m.dict())</span><br><span class="line">    </span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;1&#x27;, &#x27;memory&#x27;], &#x27;key&#x27;: &#x27;user_profile&#x27;, &#x27;value&#x27;: &#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;, &#x27;created_at&#x27;: &#x27;2025-07-25T08:58:06.031770+00:00&#x27;, &#x27;updated_at&#x27;: &#x27;2025-07-25T08:58:06.031775+00:00&#x27;, &#x27;score&#x27;: None&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a>
通过命名空间和键来检索特定对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">profile = in_memory_store.get(namespace_for_memory, &quot;user_profile&quot;)</span><br><span class="line">profile.value</span><br><span class="line"></span><br><span class="line">&#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="chatbot-with-profile-schema-带有配置文件模式的聊天机器人-1"><strong>Chatbot
with profile schema</strong>
<strong>带有配置文件模式的聊天机器人</strong></h5>
<p>现在我们知道了如何为记忆指定一个模式，并将其保存到存储中。现在，我们如何根据这个特定的模式
<strong>创建</strong> 记忆？</p>
<p>在我们的聊天机器人中，我们 <a href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">想要从一个聊天里创建记忆</a>.这就是
<a href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">structured
outputs格式化输出</a> 概念有用的地方。</p>
<p>LangChain 的 <a href="https://python.langchain.com/docs/concepts/chat_models/">chat
model</a> 接口有一个 <a href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">PROTECTED<span class="math inline">11</span></a>
方法用于强制结构化输出。这在我们需要确保输出符合某个模式时非常有用，而且它会为我们解析输出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将模式绑定到模型</span><br><span class="line">model_with_structure = model.with_structured_output(UserProfile)</span><br><span class="line"></span><br><span class="line"># 调用模型生成符合模式的结构化输出</span><br><span class="line">structured_output = model_with_structure.invoke([HumanMessage(&quot;我的名字是Lance，我喜欢骑自行车。&quot;)])</span><br><span class="line">structured_output</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Structured outputs（结构化输出）
指让大模型<strong>不再“随意说人话”</strong>，而是<strong>按你事先定义好的格式（JSON
/ 表格 / 枚举 /
嵌套对象等）精确返回数据</strong>。相当于给模型套了一个“模具”，保证输出可直接被代码解析、入库或传给下游系统，避免再用正则、字符串拼接去“猜”结果。</p>
<p>使用官方的大模型组件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">model=ChatTongyi(</span><br><span class="line">    model=&quot;qwen-plus-2025-07-14&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>现在，让我们在聊天机器人中使用它。这只需要对
<code>write_memory</code> 函数进行轻微修改。我们使用
<code>model_with_structure</code>，如上所述，来生成一个与我们模式匹配的配置文件。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage, AIMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的 helpful 助手，可以提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;根据用户的聊天历史创建或更新用户档案记忆。</span><br><span class="line">这将被保存为长期记忆。如果存在现有记忆，只需更新它。</span><br><span class="line">以下是现有记忆（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 使用记忆以及聊天历史来回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line">        </span><br><span class="line">    # 在指令中格式化现有记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 调用模型生成符合模式的结构化输出</span><br><span class="line">    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖现有的用户档案记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    store.put(namespace, key, new_memory)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于长期（跨线程）记忆的存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于短期（线程内）记忆的检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250726103516996.png" alt="image-20250726103516996">
<figcaption aria-hidden="true">image-20250726103516996</figcaption>
</figure>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance，我喜欢在旧金山骑自行车和在面包店吃饭。&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>查看记忆</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Namespace for the memory to save</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.value</span><br></pre></td></tr></table></figure>
<h5 id="trustcall-for-creating-and-updating-profile-schemas-trustcall-用于创建和更新配置文件模式"><strong>Trustcall
for creating and updating profile schemas</strong> <strong>Trustcall
用于创建和更新配置文件模式</strong></h5>
<p>Trustcall 是一个由 LangChain 团队开发的开源 Python
库，旨在<strong>解决大型语言模型（LLM）在生成或修改复杂 JSON
数据结构时效率低、易出错的问题</strong>。</p>
<p>我们使用 <code>create_extractor</code>，传入模型以及我们的模式作为 <a href="https://python.langchain.com/docs/concepts/tools/">tool</a>。使用
TrustCall 时，可以以多种方式提供模式。</p>
<p>例如，我们可以传递一个 JSON 对象 / Python 字典或 Pydantic
模型。在底层，TrustCall 使用 <a href="https://python.langchain.com/docs/concepts/tool_calling/">tool
calling</a> 从输入的 <a href="https://python.langchain.com/docs/concepts/messages/">messages</a>
列表中生成 <a href="https://python.langchain.com/docs/concepts/structured_outputs/">structured
output</a>。为了强制 Trustcall 生成 <a href="https://python.langchain.com/docs/concepts/structured_outputs/">structured
output</a>，我们可以在 <code>tool_choice</code> 参数中包含模式名称。</p>
<p>我仅做了解了，感觉用处不多，用结果化输出就能达到效果</p>
<h4 id="chatbot-with-collection-schema-带集合模式的聊天机器人"><strong>Chatbot
with Collection Schema</strong>
<strong>带集合模式的聊天机器人</strong></h4>
<p><strong>“collection”</strong>
指的是一种<strong>将语义记忆组织为多个独立文档（objects）的存储方式</strong>，而不是把所有信息都塞进一个巨大的“用户档案”（single
profile）里。</p>
<p>假设你在做一个 AI 助手，用户说：</p>
<blockquote>
<p>“我下周要去东京出差，住在涩谷区的 Sakura Hotel。” “我朋友 Ken
也要来，他喜欢吃拉面。”</p>
</blockquote>
<p>如果用 <strong>collection</strong>，你会存成两条记忆：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trip&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;destination&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Tokyo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2025-08-04&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hotel&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Sakura Hotel, Shibuya&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;friend&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Ken&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;food_preference&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ramen&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<p>每条记忆都是一个独立文档，后续你可以：</p>
<ul>
<li>搜索“trip”类型的记忆，找到用户的出差安排；</li>
<li>搜索“friend”类型的记忆，找到 Ken 的偏好；</li>
<li>更新 Ken
的信息时，<strong>只改一条记录</strong>，不会影响其它记忆。</li>
</ul>
<h4 id="memory-agent-内存代理"><strong>Memory Agent</strong>
<strong>内存代理</strong></h4>
<p>现在，我们将把学到的内容整合起来，构建一个具有长期记忆的 <a href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/">agent</a>。</p>
<p>我们的代理 <code>task_mAIstro</code> 将帮助我们管理待办事项列表！</p>
<p>我们之前构建的聊天机器人 <strong>始终</strong>
会反思对话并保存记忆。<code>task_mAIstro</code> 将决定
<strong>何时</strong> 保存记忆（待办事项列表中的项目）。</p>
<p>我们之前构建的聊天机器人始终保存一种类型的记忆，即个人资料或集合。<code>task_mAIstro</code>
可以决定将数据保存到用户个人资料或 ToDo 事项集合中。</p>
<p>除此之外，<code>task_mAIstro</code>
还将管理程序性记忆。这允许用户更新创建ToDo项的偏好设置。</p>
<h5 id="creating-an-agent-创建一个代理"><strong>Creating an
agent</strong> <strong>创建一个代理</strong></h5>
<p>有许多不同的 <a href="https://langchain-ai.github.io/langgraph/concepts/high_level/">agent</a>
架构可供选择。在这里，我们将实现一个简单的内容，一个 <a href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation">ReAct</a>
代理。这个代理将成为创建和管理待办事项列表的得力助手。</p>
<p>此代理可以决定更新三种类型的长期记忆：</p>
<ol type="a">
<li><p>创建或更新具有普通用户信息的用户 <code>profile</code></p></li>
<li><p>在ToDo列表中添加或更新项目 <code>collection</code></p></li>
<li><p>更新其自身的 <code>instructions</code>
以了解如何更新待办事项列表中的项目</p></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import TypedDict, Literal</span><br><span class="line"></span><br><span class="line"># 更新记忆工具</span><br><span class="line">class UpdateMemory(TypedDict):</span><br><span class="line">    &quot;&quot;&quot; 决定更新哪种记忆类型 &quot;&quot;&quot;</span><br><span class="line">    update_type: Literal[&#x27;user&#x27;, &#x27;todo&#x27;, &#x27;instructions&#x27;]</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><code>'user'</code>：用户相关信息</li>
<li><code>'todo'</code>：待办事项</li>
<li><code>'instructions'</code>：指令信息</li>
</ul>
</blockquote>
<h5 id="graph-definition-图定义"><strong>Graph definition</strong>
<strong>图定义</strong></h5>
<p>我们添加了一个简单的路由器
<code>route_message</code>，它通过二元决策来节省内存。</p>
<h3 id="module-6">module-6</h3>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>Langsmith</title>
    <url>/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langsmith/</url>
    <content><![CDATA[<h3 id="配置langsmith">配置langsmith</h3>
<h4 id="安装langsmith-sdk">安装LangSmith SDK</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install langsmith</span><br></pre></td></tr></table></figure>
<h4 id="环境变量">环境变量</h4>
<p>获取api<a href="https://smith.langchain.com/o/56031c2a-c402-41d4-83ed-ed15d0693548/settings/apikeys">LangSmith</a></p>
<p>设置相应的环境变量。这将把跟踪记录到<code>default</code>项目（尽管您可以轻松更改）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export LANGSMITH_TRACING=true</span><br><span class="line">export LANGSMITH_API_KEY=</span><br><span class="line">export LANGSMITH_PROJECT=default</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LANGSMITH_TRACING=true</span><br><span class="line">LANGSMITH_ENDPOINT=&quot;https://api.smith.langchain.com&quot;</span><br><span class="line">LANGSMITH_API_KEY=&quot;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&quot;</span><br><span class="line">LANGSMITH_PROJECT=&quot;langgraph&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="资源">资源</h3>
<p>官网<a href="https://smith.langchain.com/o/56031c2a-c402-41d4-83ed-ed15d0693548/">《LangSmith》
— LangSmith</a></p>
<p>参考文档<a href="https://langsmith.langchain.ac.cn/">LangSmith 入门 |
🦜️🛠️ LangSmith 文档</a></p>
<p><a href="https://docs.smith.langchain.com/">Get started with
LangSmith | 🦜️🛠️ LangSmith</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langsmith</category>
      </categories>
      <tags>
        <tag>langsmith</tag>
      </tags>
  </entry>
  <entry>
    <title>Research Assistant研究助理</title>
    <url>/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/</url>
    <content><![CDATA[<h4 id="research-assistant-研究助理"><strong>Research Assistant</strong>
<strong>研究助理</strong></h4>
<p>我们的目标是围绕聊天模型构建一个轻量级、多智能体系统，以定制研究过程。</p>
<p>Source Selection</p>
<ul>
<li>用户可为研究自行选择任意输入源。</li>
</ul>
<p>Planning</p>
<ul>
<li>用户提供主题后，系统生成一组 AI
分析师，每位分析师聚焦一个子主题。</li>
<li>在研究开始前，采用 <strong>人机协同</strong>
方式对子主题进行精调。</li>
</ul>
<p>LLM Utilization</p>
<ul>
<li>每位分析师基于所选源，与专家 AI 开展深度访谈。</li>
<li>访谈采用多轮对话形式，以 STORM 论文所示方式提取详尽洞见。</li>
<li>访谈过程将以“<strong>子图</strong>”形式记录，并保存各自内部状态。</li>
</ul>
<p>Research Process</p>
<ul>
<li>专家 AI 并行收集信息，实时回答分析师提问。</li>
<li>所有访谈通过 <strong>map-reduce</strong> 架构同时展开。</li>
</ul>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/66dbb164d61c93d48e604091_research-assistant1.png" alt="Screenshot 2024-08-26 at 7.26.33 PM.png">
<figcaption aria-hidden="true">Screenshot 2024-08-26 at 7.26.33
PM.png</figcaption>
</figure>
<h5 id="generate-analysts-human-in-the-loop-生成分析师"><strong>Generate
Analysts: Human-In-The-Loop</strong> <strong>生成分析师</strong></h5>
<p>创建分析师并使用人工循环（human-in-the-loop）来审查他们。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import List</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line">class Analyst(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    分析师模型类</span><br><span class="line">    用于定义单个分析师的基本信息和属性</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    affiliation: str = Field(</span><br><span class="line">        description=&quot;分析师的主要隶属机构。&quot;,</span><br><span class="line">    )</span><br><span class="line">    name: str = Field(</span><br><span class="line">        description=&quot;分析师的姓名&quot;</span><br><span class="line">    )</span><br><span class="line">    role: str = Field(</span><br><span class="line">        description=&quot;分析师在该主题背景下的角色。&quot;,</span><br><span class="line">    )</span><br><span class="line">    description: str = Field(</span><br><span class="line">        description=&quot;分析师的关注点、担忧和动机的描述。&quot;,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    @property#@property 装饰器的作用是将一个方法转换为只读属性 ，让方法可以像访问属性一样使用，而不需要加括号调用。</span><br><span class="line">    def persona(self) -&gt; str:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        生成分析师的人设信息</span><br><span class="line">        返回格式化的字符串包含分析师的所有关键信息</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        return f&quot;姓名: &#123;self.name&#125;\n角色: &#123;self.role&#125;\n隶属机构: &#123;self.affiliation&#125;\n描述: &#123;self.description&#125;\n&quot;</span><br><span class="line"></span><br><span class="line">class Perspectives(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    视角模型类</span><br><span class="line">    用于管理多个分析师的集合</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    analysts: List[Analyst] = Field(</span><br><span class="line">        description=&quot;包含角色和隶属机构的分析师综合列表。&quot;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">class GenerateAnalystsState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    生成分析师状态类型定义</span><br><span class="line">    用于类型提示，定义在生成分析师过程中需要的状态信息</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    topic: str # 研究主题 - 用户输入的研究话题</span><br><span class="line">    max_analysts: int # 分析师数量 - 需要生成的分析师最大数量</span><br><span class="line">    human_analyst_feedback: str # 人类反馈 - 来自用户的反馈信息，用于调整分析师生成</span><br><span class="line">    analysts: List[Analyst] # 提出问题的分析师 - 已生成的分析师列表</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>Field</code> 是 Pydantic
提供的一个函数，主要用于为模型字段添加额外的元数据和配置。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import START, END, StateGraph</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langchain_core.messages import AIMessage, HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line"># 分析师指令模板</span><br><span class="line">analyst_instructions=&quot;&quot;&quot;您需要创建一组AI分析师角色。请仔细遵循以下指令：</span><br><span class="line"></span><br><span class="line">1. 首先，查看研究主题：</span><br><span class="line">&#123;topic&#125;</span><br><span class="line">        </span><br><span class="line">2. 检查任何可选的编辑反馈，这些反馈用于指导分析师的创建： </span><br><span class="line">        </span><br><span class="line">&#123;human_analyst_feedback&#125;</span><br><span class="line">    </span><br><span class="line">3. 根据上述文档和/或反馈确定最有趣的主题。</span><br><span class="line">                    </span><br><span class="line">4. 选择前 &#123;max_analysts&#125; 个主题。</span><br><span class="line"></span><br><span class="line">5. 为每个主题分配一个分析师。</span><br><span class="line"></span><br><span class="line">6. 重要：请以JSON格式返回您的响应，结构如下：</span><br><span class="line">   &#123;&#123;</span><br><span class="line">     &quot;analysts&quot;: [</span><br><span class="line">       &#123;&#123;</span><br><span class="line">         &quot;name&quot;: &quot;分析师姓名&quot;,</span><br><span class="line">         &quot;affiliation&quot;: &quot;所属机构&quot;,</span><br><span class="line">         &quot;role&quot;: &quot;角色描述&quot;,</span><br><span class="line">         &quot;description&quot;: &quot;详细描述&quot;</span><br><span class="line">       &#125;&#125;</span><br><span class="line">     ]</span><br><span class="line">   &#125;&#125;</span><br><span class="line"></span><br><span class="line">7. 请确保响应中包含&#x27;json&#x27;这个词，这是必需的。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def create_analysts(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 创建分析师 &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    topic=state[&#x27;topic&#x27;]</span><br><span class="line">    max_analysts=state[&#x27;max_analysts&#x27;]</span><br><span class="line">    human_analyst_feedback=state.get(&#x27;human_analyst_feedback&#x27;, &#x27;&#x27;)#防止为空</span><br><span class="line">        </span><br><span class="line">    # 强制结构化输出</span><br><span class="line">    structured_llm = llm.with_structured_output(Perspectives)</span><br><span class="line"></span><br><span class="line">    # 系统消息</span><br><span class="line">    system_message = analyst_instructions.format(topic=topic,human_analyst_feedback=human_analyst_feedback, max_analysts=max_analysts)</span><br><span class="line"></span><br><span class="line">    # 生成分析师</span><br><span class="line">    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=&quot;生成分析师集合。&quot;)])</span><br><span class="line">    </span><br><span class="line">    # 将分析师列表写入状态</span><br><span class="line">    return &#123;&quot;analysts&quot;: analysts.analysts&#125;</span><br><span class="line"></span><br><span class="line">def human_feedback(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 无操作节点，应该在此处中断 &quot;&quot;&quot;</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">def should_continue(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 返回下一个要执行的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否有用户反馈</span><br><span class="line">    human_analyst_feedback=state.get(&#x27;human_analyst_feedback&#x27;, None)</span><br><span class="line">    if human_analyst_feedback:</span><br><span class="line">        return &quot;create_analysts&quot;</span><br><span class="line">    </span><br><span class="line">    # 否则结束</span><br><span class="line">    return END</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">builder = StateGraph(GenerateAnalystsState)</span><br><span class="line">builder.add_node(&quot;create_analysts&quot;, create_analysts)  # 添加创建分析师节点</span><br><span class="line">builder.add_node(&quot;human_feedback&quot;, human_feedback)   # 添加用户反馈节点</span><br><span class="line">builder.add_edge(START, &quot;create_analysts&quot;)           # 从开始到创建分析师</span><br><span class="line">builder.add_edge(&quot;create_analysts&quot;, &quot;human_feedback&quot;) # 从创建分析师到用户反馈</span><br><span class="line">builder.add_conditional_edges(&quot;human_feedback&quot;, should_continue, [&quot;create_analysts&quot;, END]) # 条件边</span><br><span class="line"></span><br><span class="line"># 编译图</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph = builder.compile(interrupt_before=[&#x27;human_feedback&#x27;], checkpointer=memory)  # 在用户反馈前中断</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))  # 显示流程图</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250723171742889.png" alt="image-20250723171742889">
<figcaption aria-hidden="true">image-20250723171742889</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 输入</span><br><span class="line">max_analysts = 3  # 最大分析师数量</span><br><span class="line">topic = &quot;采用LangGraph作为代理框架的好处&quot;  # 研究主题</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;  # 线程配置，用于会话跟踪</span><br><span class="line"></span><br><span class="line"># 运行图直到第一次中断</span><br><span class="line">for event in graph.stream(&#123;&quot;topic&quot;:topic,&quot;max_analysts&quot;:max_analysts,&#125;, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    # 审查结果</span><br><span class="line">    analysts = event.get(&#x27;analysts&#x27;, &#x27;&#x27;)  # 获取分析师列表</span><br><span class="line">    if analysts:</span><br><span class="line">        for analyst in analysts:</span><br><span class="line">            print(f&quot;姓名: &#123;analyst.name&#125;&quot;)        # 打印分析师姓名</span><br><span class="line">            print(f&quot;隶属机构: &#123;analyst.affiliation&#125;&quot;)  # 打印隶属机构</span><br><span class="line">            print(f&quot;角色: &#123;analyst.role&#125;&quot;)        # 打印角色</span><br><span class="line">            print(f&quot;描述: &#123;analyst.description&#125;&quot;)  # 打印描述</span><br><span class="line">            print(&quot;-&quot; * 50)  # 打印分隔线</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">姓名: 艾琳·史密斯</span><br><span class="line">隶属机构: 人工智能与代理系统研究所</span><br><span class="line">角色: LangGraph架构专家</span><br><span class="line">描述: 专注于研究基于图结构的AI代理框架，尤其是LangGraph在复杂决策流程中的模块化与可扩展性优势。</span><br><span class="line">--------------------------------------------------</span><br><span class="line">姓名: 拉胡尔·梅赫塔</span><br><span class="line">隶属机构: 分布式系统与AI实验室</span><br><span class="line">角色: 代理框架性能分析师</span><br><span class="line">描述: 研究LangGraph在多代理协作中的效率提升，以及其在异步通信、状态管理和错误恢复方面的优势。</span><br><span class="line">--------------------------------------------------</span><br><span class="line">姓名: 艾米丽·陈</span><br><span class="line">隶属机构: 人机交互与智能系统中心</span><br><span class="line">角色: 代理框架用户体验研究员</span><br><span class="line">描述: 分析LangGraph如何支持开发者构建更具交互性和可解释性的AI代理系统，特别是在可视化流程设计和调试方面的优势。</span><br><span class="line">--------------------------------------------------</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们现在像 human_feedback 节点一样更新状态</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            &quot;添加一个来自初创公司的人，以增加企业家视角&quot;&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 继续图的执行</span><br><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    # 审查结果</span><br><span class="line">    analysts = event.get(&#x27;analysts&#x27;, &#x27;&#x27;)  # 获取分析师列表</span><br><span class="line">    if analysts:</span><br><span class="line">        for analyst in analysts:</span><br><span class="line">            print(f&quot;姓名: &#123;analyst.name&#125;&quot;)        # 打印分析师姓名</span><br><span class="line">            print(f&quot;隶属机构: &#123;analyst.affiliation&#125;&quot;)  # 打印隶属机构</span><br><span class="line">            print(f&quot;角色: &#123;analyst.role&#125;&quot;)        # 打印角色</span><br><span class="line">            print(f&quot;描述: &#123;analyst.description&#125;&quot;)  # 打印描述</span><br><span class="line">            print(&quot;-&quot; * 50)  # 打印分隔线</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 如果我们满意，那么就不提供任何反馈</span><br><span class="line">further_feedback = None #如果满意就返回none，如果不满意就进行反馈</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            further_feedback&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<h5 id="conduct-interview-进行面试"><strong>Conduct Interview</strong>
<strong>进行面试</strong></h5>
<p><strong>生成问题</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import  Annotated</span><br><span class="line">from langgraph.graph import MessagesState</span><br><span class="line"></span><br><span class="line">class InterviewState(MessagesState):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    访谈状态类</span><br><span class="line">    继承自MessagesState，用于管理访谈过程中的各种状态信息</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    max_num_turns: int # 对话轮数上限</span><br><span class="line">    context: Annotated[list, operator.add] # 源文档，使用operator.add进行合并</span><br><span class="line">    analyst: Analyst # 提问的分析师</span><br><span class="line">    interview: str # 访谈记录（文字记录）</span><br><span class="line">    sections: list # 最终章节，我们在外部状态中重复此字段以用于Send() API</span><br><span class="line"></span><br><span class="line">class SearchQuery(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    搜索查询模型</span><br><span class="line">    用于定义搜索查询的结构</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    search_query: str = Field(None, description=&quot;用于检索的搜索查询。&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 问题生成指令</span><br><span class="line">question_instructions = &quot;&quot;&quot;你是一名分析师，任务是采访专家以了解特定主题。</span><br><span class="line"></span><br><span class="line">你的目标是提炼出与你主题相关的有趣且具体的见解。</span><br><span class="line"></span><br><span class="line">1. 有趣的：人们会感到惊讶或不明显的见解。</span><br><span class="line">        </span><br><span class="line">2. 具体的：避免泛泛而谈的见解，包含来自专家的具体例子。</span><br><span class="line"></span><br><span class="line">这是你的关注主题和目标集合：&#123;goals&#125;</span><br><span class="line">        </span><br><span class="line">首先使用符合你人设的名字介绍自己，然后提出你的问题。</span><br><span class="line"></span><br><span class="line">继续提问以深入挖掘和细化你对该主题的理解。</span><br><span class="line">        </span><br><span class="line">当你对理解满意时，用&quot;非常感谢您的帮助！&quot;来结束采访。</span><br><span class="line"></span><br><span class="line">记住在整个回复中保持角色特征，体现提供给你的人设和目标。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def generate_question(state: InterviewState):</span><br><span class="line">    &quot;&quot;&quot; 生成问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    analyst = state[&quot;analyst&quot;]      # 当前分析师</span><br><span class="line">    messages = state[&quot;messages&quot;]    # 对话历史</span><br><span class="line"></span><br><span class="line">    # 生成问题</span><br><span class="line">    system_message = question_instructions.format(goals=analyst.persona)  # 格式化系统消息</span><br><span class="line">    question = llm.invoke([SystemMessage(content=system_message)]+messages)  # 调用LLM生成问题</span><br><span class="line">        </span><br><span class="line">    # 将消息写入状态</span><br><span class="line">    return &#123;&quot;messages&quot;: [question]&#125;  # 返回新生成的问题</span><br></pre></td></tr></table></figure>
<p><strong>生成问题的并行处理</strong></p>
<p>专家将并行从多个来源收集信息以回答问题。</p>
<ul>
<li>特定网站：例如通过 <a href="https://python.langchain.com/v0.2/docs/integrations/document_loaders/web_base/">WebBaseLoader</a><br>
</li>
<li>已索引文档：例如通过 <a href="https://python.langchain.com/v0.2/docs/tutorials/rag/">RAG</a><br>
</li>
<li>网页搜索<br>
</li>
<li>维基百科搜索</li>
</ul>
<p>你可以尝试不同的网络搜索工具，比如 <a href="https://tavily.com/">Tavily</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Web search tool</span><br><span class="line">from langchain_community.tools.tavily_search import TavilySearchResults</span><br><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line">#tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">tavily_search=TavilySearch(max_result=3)</span><br><span class="line"></span><br><span class="line"># Wikipedia search tool</span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br></pre></td></tr></table></figure>
<p>现在，我们创建节点以搜索网络和维基百科。</p>
<p>我们还将创建一个节点来回答分析师的问题。最后，我们将创建节点以保存完整的采访内容，并撰写采访的摘要（“部分”）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import get_buffer_string</span><br><span class="line"></span><br><span class="line"># 搜索查询编写</span><br><span class="line">search_instructions = SystemMessage(content=f&quot;&quot;&quot;你将获得分析师和专家之间的对话。</span><br><span class="line"></span><br><span class="line">你的目标是生成一个结构化的 JSON 对象，该对象包含一个用于网络搜索的查询字符串。</span><br><span class="line"></span><br><span class="line">请严格按照以下步骤操作：</span><br><span class="line"></span><br><span class="line">1.  仔细分析整个对话。</span><br><span class="line">2.  特别关注分析师提出的最后一个问题。</span><br><span class="line">3.  根据该问题，生成一个清晰、简洁、有效的搜索查询字符串。</span><br><span class="line">4.  **你的最终输出必须是一个严格的 JSON 对象，格式如下，不要包含任何其他文字或解释：**</span><br><span class="line">    &#123;&#123;&quot;search_query&quot;: &quot;你的查询字符串放在这里&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">**示例：**</span><br><span class="line">如果最后一个问题涉及 &quot;LangGraph 与其他代理框架（如 AutoGen）相比的优势&quot;，</span><br><span class="line">你的输出必须严格是：</span><br><span class="line">&#123;&#123;&quot;search_query&quot;: &quot;LangGraph vs AutoGen agent framework advantages&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">分析师的最后一个问题才是关键，请基于它生成查询。</span><br><span class="line"></span><br><span class="line">**你的输出：**&quot;&quot;&quot;)</span><br><span class="line"></span><br><span class="line">def search_web(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索查询</span><br><span class="line">    structured_llm = llm.with_structured_output(SearchQuery)</span><br><span class="line">    search_query = structured_llm.invoke([search_instructions]+state[&#x27;messages&#x27;])</span><br><span class="line">    </span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = tavily_search.invoke(search_query.search_query)</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;/&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # # 搜索查询</span><br><span class="line">    # structured_llm = llm.with_structured_output(SearchQuery)</span><br><span class="line">    # search_query = structured_llm.invoke([search_instructions]+state[&#x27;messages&#x27;])</span><br><span class="line">    </span><br><span class="line">    # # 搜索</span><br><span class="line">    # search_docs = WikipediaLoader(query=search_query.search_query, </span><br><span class="line">    #                               load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">    #  # 格式化</span><br><span class="line">    # formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">    #     [</span><br><span class="line">    #         f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;/&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">    #         for doc in search_docs</span><br><span class="line">    #     ]</span><br><span class="line">    # )</span><br><span class="line"></span><br><span class="line">    # return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line">    return &#123;&quot;context&quot;: [&quot;&quot;]&#125;</span><br><span class="line"></span><br><span class="line">answer_instructions = &quot;&quot;&quot;你是一位正在接受分析师采访的专家。</span><br><span class="line"></span><br><span class="line">这是分析师的关注领域：&#123;goals&#125;。</span><br><span class="line">        </span><br><span class="line">你的目标是回答面试官提出的问题。</span><br><span class="line"></span><br><span class="line">要回答问题，请使用此上下文：</span><br><span class="line">        </span><br><span class="line">&#123;context&#125;</span><br><span class="line"></span><br><span class="line">回答问题时，请遵循以下准则：</span><br><span class="line">        </span><br><span class="line">1. 仅使用上下文中提供的信息。</span><br><span class="line">        </span><br><span class="line">2. 不要引入外部信息或在上下文中明确说明之外进行假设。</span><br><span class="line"></span><br><span class="line">3. 上下文包含每个独立文档主题的来源。</span><br><span class="line"></span><br><span class="line">4. 在任何相关陈述旁边包含这些来源。例如，对于来源 # 1 使用 [1]。</span><br><span class="line"></span><br><span class="line">5. 在答案底部按顺序列出你的来源。 [1] 来源 1，[2] 来源 2，等等</span><br><span class="line">        </span><br><span class="line">6. 如果来源是：&lt;Document source=&quot;assistant/docs/llama3_1.pdf&quot; page=&quot;7&quot;/&gt;&#x27; 那么只需列出：</span><br><span class="line">        </span><br><span class="line">[1] assistant/docs/llama3_1.pdf, page 7 </span><br><span class="line">        </span><br><span class="line">并跳过括号的添加以及引用中的 Document source 前言。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def generate_answer(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    analyst = state[&quot;analyst&quot;]</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line"></span><br><span class="line">    # 回答问题</span><br><span class="line">    system_message = answer_instructions.format(goals=analyst.persona, context=context)</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=system_message)]+messages)</span><br><span class="line">            </span><br><span class="line">    # 将消息命名为来自专家</span><br><span class="line">    answer.name = &quot;expert&quot;</span><br><span class="line">    </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;messages&quot;: [answer]&#125;</span><br><span class="line"></span><br><span class="line">def save_interview(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 保存采访 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取消息</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    </span><br><span class="line">    # 将采访转换为字符串</span><br><span class="line">    interview = get_buffer_string(messages)</span><br><span class="line">    </span><br><span class="line">    # 保存到 interviews 键</span><br><span class="line">    return &#123;&quot;interview&quot;: interview&#125;</span><br><span class="line"></span><br><span class="line">def route_messages(state: InterviewState, </span><br><span class="line">                   name: str = &quot;expert&quot;):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 在问题和答案之间路由 &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 获取消息</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    max_num_turns = state.get(&#x27;max_num_turns&#x27;,2)</span><br><span class="line"></span><br><span class="line">    # 检查专家答案的数量</span><br><span class="line">    #isinstance(m, AIMessage) ：检查当前消息 m 是否是 AIMessage 类的实例。这通常用于识别由 AI 模型生成的消息。</span><br><span class="line">    num_responses = len(</span><br><span class="line">        [m for m in messages if isinstance(m, AIMessage) and m.name == name]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 如果专家回答的次数超过最大轮数，则结束</span><br><span class="line">    if num_responses &gt;= max_num_turns:</span><br><span class="line">        return &#x27;save_interview&#x27;</span><br><span class="line"></span><br><span class="line">    # 获取提出的最后一个问题，以检查它是否表示讨论结束</span><br><span class="line">    #messages[-2] ：分析师提出的 最后一个问题 。</span><br><span class="line">    #messages[-1] ：专家对这个问题的 最新回答 。</span><br><span class="line">    last_question = messages[-2]</span><br><span class="line">    </span><br><span class="line">    if &quot;非常感谢你的帮助&quot; in last_question.content:</span><br><span class="line">        return &#x27;save_interview&#x27;</span><br><span class="line">    return &quot;ask_question&quot;</span><br><span class="line"></span><br><span class="line">section_writer_instructions = &quot;&quot;&quot;你是一位专业的科技作家。</span><br><span class="line">            </span><br><span class="line">你的任务是根据一组源文档创建一份简短、易于理解的报告部分。</span><br><span class="line"></span><br><span class="line">1. 分析源文档的内容：</span><br><span class="line">- 每个源文档的名称都在文档开头，带有 &lt;Document 标签。</span><br><span class="line">        </span><br><span class="line">2. 使用 markdown 格式创建报告结构：</span><br><span class="line">- 使用 ## 作为章节标题</span><br><span class="line">- 使用 ### 作为小节标题</span><br><span class="line">        </span><br><span class="line">3. 按照此结构编写报告：</span><br><span class="line">a. 标题 (## header)</span><br><span class="line">b. 摘要 (### header)</span><br><span class="line">c. 来源 (### header)</span><br><span class="line"></span><br><span class="line">4. 根据分析师的关注领域，使你的标题引人入胜：</span><br><span class="line">&#123;focus&#125;</span><br><span class="line"></span><br><span class="line">5. 对于摘要部分：</span><br><span class="line">- 设置与分析师关注领域相关的通用背景/上下文的摘要</span><br><span class="line">- 强调从采访中收集到的新颖、有趣或令人惊讶的见解</span><br><span class="line">- 创建一个使用过的源文档的编号列表</span><br><span class="line">- 不要提及面试官或专家的姓名</span><br><span class="line">- 目标是最多约 400 字</span><br><span class="line">- 根据源文档中的信息，在报告中使用编号来源（例如，[1]、[2]）</span><br><span class="line">        </span><br><span class="line">6. 在来源部分：</span><br><span class="line">- 包含报告中使用的所有来源</span><br><span class="line">- 提供相关网站或特定文档路径的完整链接</span><br><span class="line">- 每个来源用换行符分隔。在每行末尾使用两个空格以在 Markdown 中创建换行符。</span><br><span class="line">- 它看起来像：</span><br><span class="line"></span><br><span class="line">### 来源</span><br><span class="line">[1] 链接或文档名称</span><br><span class="line">[2] 链接或文档名称</span><br><span class="line"></span><br><span class="line">7. 务必合并来源。例如，这不正确：</span><br><span class="line"></span><br><span class="line">[3] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line">[4] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line"></span><br><span class="line">不应有冗余来源。它应该只是：</span><br><span class="line"></span><br><span class="line">[3] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line">        </span><br><span class="line">8. 最终审查：</span><br><span class="line">- 确保报告遵循所需的结构</span><br><span class="line">- 在报告标题之前不包含任何前言</span><br><span class="line">- 检查所有准则是否已遵循&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_section(state: InterviewState):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 编写章节的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    interview = state[&quot;interview&quot;]</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    analyst = state[&quot;analyst&quot;]</span><br><span class="line">   </span><br><span class="line">    # 使用从采访（上下文）或采访本身（interview）收集的源文档编写章节</span><br><span class="line">    system_message = section_writer_instructions.format(focus=analyst.description)</span><br><span class="line">    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f&quot;Use this source to write your section: &#123;context&#125;&quot;)]) </span><br><span class="line">                </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;sections&quot;: [section.content]&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">interview_builder = StateGraph(InterviewState)</span><br><span class="line">interview_builder.add_node(&quot;ask_question&quot;, generate_question)</span><br><span class="line">interview_builder.add_node(&quot;search_web&quot;, search_web)</span><br><span class="line">interview_builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">interview_builder.add_node(&quot;answer_question&quot;, generate_answer)</span><br><span class="line">interview_builder.add_node(&quot;save_interview&quot;, save_interview)</span><br><span class="line">interview_builder.add_node(&quot;write_section&quot;, write_section)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">interview_builder.add_edge(START, &quot;ask_question&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;ask_question&quot;, &quot;search_web&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;ask_question&quot;, &quot;search_wikipedia&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;search_web&quot;, &quot;answer_question&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;search_wikipedia&quot;, &quot;answer_question&quot;)</span><br><span class="line">interview_builder.add_conditional_edges(&quot;answer_question&quot;, route_messages,[&#x27;ask_question&#x27;,&#x27;save_interview&#x27;])</span><br><span class="line">interview_builder.add_edge(&quot;save_interview&quot;, &quot;write_section&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;write_section&quot;, END)</span><br><span class="line"></span><br><span class="line"># 采访</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=&quot;Conduct Interviews&quot;)</span><br><span class="line"></span><br><span class="line"># 视图</span><br><span class="line">display(Image(interview_graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725101725158.png" alt="image-20250725101725158">
<figcaption aria-hidden="true">image-20250725101725158</figcaption>
</figure>
<h5 id="map-reduceparallelze-interviews-map-reduce-并行化访谈"><strong>Map-Reduce（Parallelze
interviews: Map-Reduce）</strong> <strong>并行化访谈</strong></h5>
<p>我们通过 <code>Send()</code> API
并行化处理访谈，这是一个映射步骤。我们将它们在 reduce
步骤中组合成报告正文。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import List, Annotated</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line">class ResearchGraphState(TypedDict):</span><br><span class="line">    topic: str                           # 研究主题 (字符串类型)</span><br><span class="line">    max_analysts: int                   # 分析师数量 (整数类型)</span><br><span class="line">    human_analyst_feedback: str         # 人类分析师的反馈 (字符串类型)</span><br><span class="line">    analysts: List[Analyst]             # 提问的分析师列表 (Analyst 对象的列表)</span><br><span class="line">    sections: Annotated[list, operator.add] # 报告章节列表 (使用 operator.add 作为 Send() API 的键，意味着列表可以通过相加来合并)</span><br><span class="line">    introduction: str                   # 最终报告的引言部分 (字符串类型)</span><br><span class="line">    content: str                        # 最终报告的内容主体部分 (字符串类型)</span><br><span class="line">    conclusion: str                     # 最终报告的结论部分 (字符串类型)</span><br><span class="line">    final_report: str                   # 最终完整的报告 (字符串类型)</span><br><span class="line"></span><br><span class="line"># 从 langgraph.constants 导入 Send 类</span><br><span class="line">from langgraph.constants import Send</span><br><span class="line">def initiate_all_interviews(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 这是“map”（映射）步骤，我们使用 Send API 并行运行每个采访子图 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否存在人类反馈</span><br><span class="line">    human_analyst_feedback = state.get(&#x27;human_analyst_feedback&#x27;)</span><br><span class="line">    if human_analyst_feedback:</span><br><span class="line">        # 如果有反馈，则返回到 &quot;create_analysts&quot; 节点进行调整</span><br><span class="line">        return &quot;create_analysts&quot;</span><br><span class="line"></span><br><span class="line">    # 否则，通过 Send() API 并行启动所有采访</span><br><span class="line">    else:</span><br><span class="line">        topic = state[&quot;topic&quot;]</span><br><span class="line">        # 为每个分析师创建一个 Send 对象</span><br><span class="line">        # 目标是 &quot;conduct_interview&quot; 节点</span><br><span class="line">        # 传递的参数包括该分析师对象和一条初始消息</span><br><span class="line">        return [Send(&quot;conduct_interview&quot;, &#123;&quot;analyst&quot;: analyst,</span><br><span class="line">                                           &quot;messages&quot;: [HumanMessage(</span><br><span class="line">                                               content=f&quot;所以你说你正在写一篇关于 &#123;topic&#125; 的文章？&quot;</span><br><span class="line">                                           )</span><br><span class="line">                                                       ]&#125;) for analyst in state[&quot;analysts&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="finalize-最终确定"><strong>Finalize</strong>
<strong>最终确定</strong></h5>
<p>我们添加最后一个步骤，为最终报告撰写引言和结论。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import List, Annotated</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"># 定义用于撰写最终报告的指令模板</span><br><span class="line">report_writer_instructions = &quot;&quot;&quot;你是一位正在撰写关于以下主题报告的技术作家：</span><br><span class="line"></span><br><span class="line">&#123;topic&#125;</span><br><span class="line">    </span><br><span class="line">你有一个分析师团队。每个分析师做了两件事：</span><br><span class="line"></span><br><span class="line">1. 他们就一个特定的子主题与专家进行了采访。</span><br><span class="line">2. 他们将他们的发现写成了一份备忘录。</span><br><span class="line"></span><br><span class="line">你的任务：</span><br><span class="line"></span><br><span class="line">1. 你将得到一份来自你所有分析师的备忘录集合。</span><br><span class="line">2. 仔细思考每份备忘录中的见解。</span><br><span class="line">3. 将这些见解整合成一个清晰的整体摘要，把所有备忘录中的核心思想联系起来。</span><br><span class="line">4. 将每份备忘录中的要点总结成一个连贯的单一叙述。</span><br><span class="line"></span><br><span class="line">报告格式要求：</span><br><span class="line"> </span><br><span class="line">1. 使用 Markdown 格式。</span><br><span class="line">2. 报告开头不要有前言。</span><br><span class="line">3. 不要使用子标题。</span><br><span class="line">4. 报告开头使用一个一级标题：## Insights （## 见解）</span><br><span class="line">5. 在报告中不要提及任何分析师的名字。</span><br><span class="line">6. 保留备忘录中的所有引用，这些引用会用方括号标注，例如 [1] 或 [2]。</span><br><span class="line">7. 创建一个最终的、合并的来源列表，并添加到以 `## Sources` 为标题的部分。</span><br><span class="line">8. 按顺序列出你的来源，不要重复。</span><br><span class="line"></span><br><span class="line">[1] 来源 1</span><br><span class="line">[2] 来源 2</span><br><span class="line"></span><br><span class="line">以下是你的分析师提供的备忘录，你需要根据它们来撰写报告：</span><br><span class="line"></span><br><span class="line">&#123;context&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_report(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告主体内容的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节（备忘录）</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节（备忘录）连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和备忘录内容，调用 LLM 生成最终报告</span><br><span class="line">    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)    </span><br><span class="line">    report = llm.invoke([SystemMessage(content=system_message)] + [HumanMessage(content=&quot;根据这些备忘录写一份报告。&quot;)]) </span><br><span class="line">    # 返回报告内容</span><br><span class="line">    return &#123;&quot;content&quot;: report.content&#125;</span><br><span class="line"></span><br><span class="line"># 定义用于撰写引言和结论的指令模板</span><br><span class="line">intro_conclusion_instructions = &quot;&quot;&quot;你是一位正在完成关于 &#123;topic&#125; 报告的技术作家。</span><br><span class="line"></span><br><span class="line">你将得到报告的所有章节。</span><br><span class="line"></span><br><span class="line">你的工作是撰写一个清晰且有说服力的引言或结论部分。</span><br><span class="line"></span><br><span class="line">用户会指示你是写引言还是结论。</span><br><span class="line"></span><br><span class="line">两个部分都不要有前言。</span><br><span class="line"></span><br><span class="line">目标大约 100 个词，简洁地预览（对于引言）或回顾（对于结论）报告的所有章节。</span><br><span class="line"></span><br><span class="line">使用 Markdown 格式。</span><br><span class="line"></span><br><span class="line">对于你的引言，创建一个引人注目的标题，并使用 # 标题级别。</span><br><span class="line">对于你的引言，使用 ## Introduction （## 引言） 作为部分标题。</span><br><span class="line"></span><br><span class="line">对于你的结论，使用 ## Conclusion （## 结论） 作为部分标题。</span><br><span class="line"></span><br><span class="line">以下是供你参考以撰写相应部分的章节：&#123;formatted_str_sections&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_introduction(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告引言的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和章节内容，调用 LLM 生成引言</span><br><span class="line">    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    </span><br><span class="line">    intro = llm.invoke([instructions] + [HumanMessage(content=&quot;写报告的引言&quot;)]) </span><br><span class="line">    # 返回引言内容</span><br><span class="line">    return &#123;&quot;introduction&quot;: intro.content&#125;</span><br><span class="line"></span><br><span class="line">def write_conclusion(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告结论的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和章节内容，调用 LLM 生成结论</span><br><span class="line">    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    </span><br><span class="line">    conclusion = llm.invoke([instructions] + [HumanMessage(content=&quot;写报告的结论&quot;)]) </span><br><span class="line">    # 返回结论内容</span><br><span class="line">    return &#123;&quot;conclusion&quot;: conclusion.content&#125;</span><br><span class="line"></span><br><span class="line">def finalize_report(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 这是“reduce”（归约）步骤，我们收集所有部分，将它们组合起来，并进行反思以写出引言/结论 &quot;&quot;&quot;</span><br><span class="line">    &quot;&quot;&quot; 最终整合报告的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取报告主体内容</span><br><span class="line">    content = state[&quot;content&quot;]</span><br><span class="line">    # 如果内容以 &quot;## Insights&quot; 开头，则移除这个标题</span><br><span class="line">    if content.startswith(&quot;## Insights&quot;):</span><br><span class="line">        content = content.strip(&quot;## Insights&quot;)</span><br><span class="line">    # 尝试分离报告主体和来源部分</span><br><span class="line">    if &quot;## Sources&quot; in content:</span><br><span class="line">        try:</span><br><span class="line">            content, sources = content.split(&quot;\n## Sources\n&quot;)</span><br><span class="line">        except:</span><br><span class="line">            sources = None # 如果分离失败，则来源部分为空</span><br><span class="line">    else:</span><br><span class="line">        sources = None</span><br><span class="line"></span><br><span class="line">    # 将引言、主体内容和结论连接起来形成最终报告</span><br><span class="line">    final_report = state[&quot;introduction&quot;] + &quot;\n\n---\n\n&quot; + content + &quot;\n\n---\n\n&quot; + state[&quot;conclusion&quot;]</span><br><span class="line">    # 如果存在来源部分，则将其附加到最终报告末尾</span><br><span class="line">    if sources is not None:</span><br><span class="line">        final_report += &quot;\n\n## Sources\n&quot; + sources</span><br><span class="line">    # 返回最终报告</span><br><span class="line">    return &#123;&quot;final_report&quot;: final_report&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">builder = StateGraph(ResearchGraphState)</span><br><span class="line">builder.add_node(&quot;create_analysts&quot;, create_analysts)</span><br><span class="line">builder.add_node(&quot;human_feedback&quot;, human_feedback)</span><br><span class="line">builder.add_node(&quot;conduct_interview&quot;, interview_builder.compile()) # 将之前定义的采访图编译后作为一个节点</span><br><span class="line">builder.add_node(&quot;write_report&quot;, write_report)</span><br><span class="line">builder.add_node(&quot;write_introduction&quot;, write_introduction)</span><br><span class="line">builder.add_node(&quot;write_conclusion&quot;, write_conclusion)</span><br><span class="line">builder.add_node(&quot;finalize_report&quot;, finalize_report)</span><br><span class="line"></span><br><span class="line"># 定义工作流逻辑</span><br><span class="line">builder.add_edge(START, &quot;create_analysts&quot;) # 从开始到创建分析师</span><br><span class="line">builder.add_edge(&quot;create_analysts&quot;, &quot;human_feedback&quot;) # 创建分析师后进入人类反馈环节</span><br><span class="line"># 条件边：根据 human_feedback 节点的输出，决定是回到创建分析师还是开始采访</span><br><span class="line">builder.add_conditional_edges(&quot;human_feedback&quot;, initiate_all_interviews, [&quot;create_analysts&quot;, &quot;conduct_interview&quot;]) </span><br><span class="line"># 采访完成后，并行执行撰写报告、引言和结论</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_report&quot;)</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_introduction&quot;)</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_conclusion&quot;)</span><br><span class="line"># 撰写完报告的三个部分后，汇聚到最终整合步骤</span><br><span class="line">builder.add_edge([&quot;write_conclusion&quot;, &quot;write_report&quot;, &quot;write_introduction&quot;], &quot;finalize_report&quot;)</span><br><span class="line">builder.add_edge(&quot;finalize_report&quot;, END) # 最终整合后结束</span><br><span class="line"></span><br><span class="line"># 编译图</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"># 编译图，并设置在 &#x27;human_feedback&#x27; 节点前中断，以及使用检查点保存器</span><br><span class="line">graph = builder.compile(interrupt_before=[&#x27;human_feedback&#x27;], checkpointer=memory)</span><br><span class="line"># 显示图的可视化表示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725102148881.png" alt="image-20250725102148881">
<figcaption aria-hidden="true">image-20250725102148881</figcaption>
</figure>
<h5 id="测试">测试</h5>
<p>让我们提出一个关于 LangGraph 的开放式问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">max_analysts = 3 </span><br><span class="line">topic = &quot;采用 LangGraph 作为代理框架的好处&quot;</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 使用 stream 但不执行打印逻辑</span><br><span class="line">for event in graph.stream(&#123;</span><br><span class="line">    &quot;topic&quot;: topic,</span><br><span class="line">    &quot;max_analysts&quot;: max_analysts</span><br><span class="line">&#125;, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    pass  # 不执行任何操作</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#人工更新节点</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                                &quot;请加入这家原生生成式 AI 创业公司的首席执行官。&quot;&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 确认我们已经满意，返回none</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            None&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 继续执行</span><br><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;updates&quot;):</span><br><span class="line">    print(&quot;--Node--&quot;)</span><br><span class="line">    node_name = next(iter(event.keys()))</span><br><span class="line">    print(node_name)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725103159942.png" alt="image-20250725103159942">
<figcaption aria-hidden="true">image-20250725103159942</figcaption>
</figure>
<p>https://smith.langchain.com/public/6504cafd-d314-48d1-8640-57dc3f472e61/r</p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>python-dotenv</title>
    <url>/2025/10/19/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/dotenv/</url>
    <content><![CDATA[<h3 id="什么是-dotenv">什么是 dotenv？</h3>
<p><strong>dotenv</strong> 是一个用于从 <code>.env</code>
文件中加载环境变量到程序中的工具。它广泛用于各种编程语言（如
Python、Node.js、Ruby 等），目的是<strong>把敏感信息（比如 API
密钥、数据库密码）和配置从代码中分离出来</strong>，避免硬编码，提高安全性与灵活性。</p>
<h3 id="基本使用">基本使用</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#安装</span><br><span class="line">pip install python-dotenv</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#.env</span><br><span class="line"></span><br><span class="line">db_host=localhost</span><br><span class="line">db_port=3306</span><br><span class="line">db_user=root</span><br><span class="line">db_password=123456</span><br><span class="line">db_name=test</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from dotenv import load_dotenv</span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">db_host = os.getenv(&quot;db_host&quot;)</span><br><span class="line">db_port = os.getenv(&quot;db_port&quot;)</span><br><span class="line">db_user = os.getenv(&quot;db_user&quot;)</span><br><span class="line">db_password = os.getenv(&quot;db_password&quot;)</span><br><span class="line">db_name = os.getenv(&quot;db_name&quot;)</span><br><span class="line"></span><br><span class="line">print(db_host)</span><br><span class="line">print(db_port)</span><br><span class="line">print(db_user)</span><br><span class="line">print(db_password)</span><br><span class="line">print(db_name)</span><br></pre></td></tr></table></figure>
<p>在.gitignore增加</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Environment variables</span><br><span class="line">*.env</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>写法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>.env</code></td>
<td><strong>只忽略</strong>名为 <code>.env</code>
的文件（精确匹配）</td>
</tr>
<tr>
<td><code>*.env</code></td>
<td>忽略<strong>所有以 <code>.env</code>
结尾的文件</strong>（通配符匹配）</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>python-logging模块</title>
    <url>/2025/08/02/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/python-logging%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<h3 id="日志级别">日志级别</h3>
<table>
<thead>
<tr>
<th>级别</th>
<th>方法</th>
<th>用途</th>
</tr>
</thead>
<tbody>
<tr>
<td>DEBUG</td>
<td><code>logging.debug()</code></td>
<td>调试信息</td>
</tr>
<tr>
<td>INFO</td>
<td><code>logging.info()</code></td>
<td>普通信息</td>
</tr>
<tr>
<td>WARNING</td>
<td><code>logging.warning()</code></td>
<td>警告信息</td>
</tr>
<tr>
<td>ERROR</td>
<td><code>logging.error()</code></td>
<td>错误信息</td>
</tr>
<tr>
<td>CRITICAL</td>
<td><code>logging.critical()</code></td>
<td>严重错误</td>
</tr>
</tbody>
</table>
<p>python默认只会打印warning以上级别的日志，可通过<code>basicConfig</code>进行设置，如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 基础配置</span><br><span class="line">logging.basicConfig(level=logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># 记录不同级别的日志</span><br><span class="line">logging.debug(&quot;这是一个DEBUG级别的日志&quot;)</span><br><span class="line">logging.info(&quot;这是一个INFO级别的日志&quot;)</span><br><span class="line">logging.warning(&quot;这是一个WARNING级别的日志&quot;)</span><br><span class="line">logging.error(&quot;这是一个ERROR级别的日志&quot;)</span><br><span class="line">logging.critical(&quot;这是一个CRITICAL级别的日志&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="格式化log并输出">格式化log并输出</h3>
<p>我们可以使用全局配置，完成log的格式化和输出成文件，如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">logging.basicConfig(level=logging.DEBUG,format=&#x27;%(asctime)s - %(levelname)s - %(message)s&#x27;,filename=&#x27;basic.log&#x27;,filemode=&#x27;w&#x27;)</span><br></pre></td></tr></table></figure>
<p>同样，我们可以自定义logger</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建自定义logger</span><br><span class="line">logger = logging.getLogger(&#x27;my_app&#x27;)</span><br><span class="line">logger.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># 清除之前的处理器</span><br><span class="line">logger.handlers.clear()</span><br><span class="line"></span><br><span class="line"># 创建文件处理器</span><br><span class="line">file_handler = logging.FileHandler(&#x27;logs/my_app.log&#x27;, encoding=&#x27;utf-8&#x27;)</span><br><span class="line">file_handler.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># 创建控制台处理器</span><br><span class="line">console_handler = logging.StreamHandler()</span><br><span class="line">console_handler.setLevel(logging.WARNING)</span><br><span class="line"></span><br><span class="line"># 创建不同的格式器</span><br><span class="line">file_formatter = logging.Formatter(</span><br><span class="line">    &#x27;%(asctime)s | %(name)s | %(levelname)s | %(funcName)s:%(lineno)d | %(message)s&#x27;</span><br><span class="line">)</span><br><span class="line">console_formatter = logging.Formatter(</span><br><span class="line">    &#x27;🚨 %(levelname)s: %(message)s&#x27;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">file_handler.setFormatter(file_formatter)</span><br><span class="line">console_handler.setFormatter(console_formatter)</span><br><span class="line"></span><br><span class="line"># 添加处理器</span><br><span class="line">logger.addHandler(file_handler)</span><br><span class="line">logger.addHandler(console_handler)</span><br><span class="line"></span><br><span class="line"># 测试不同级别的日志</span><br><span class="line">logger.debug(&quot;调试信息 - 只写入文件&quot;)</span><br><span class="line">logger.info(&quot;普通信息 - 只写入文件&quot;)</span><br><span class="line">logger.warning(&quot;警告信息 - 控制台和文件都有&quot;)</span><br><span class="line">logger.error(&quot;错误信息 - 控制台和文件都有&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="异常捕获">异常捕获</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">try:</span><br><span class="line">    result = divide(10, 0)</span><br><span class="line">except ZeroDivisionError as exc:</span><br><span class="line">    # 方式 1：记录异常对象</span><br><span class="line">    logger.error(&quot;除零异常发生: &#123;&#125;&quot;, exc)</span><br><span class="line"></span><br><span class="line">    # 方式 2：记录完整 traceback（推荐）</span><br><span class="line">    logger.exception(&quot;捕获到异常，详情如下&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="loguru的常用使用方法">loguru的常用使用方法</h3>
<p>基础用法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from loguru import logger</span><br><span class="line"></span><br><span class="line">logger.debug(&quot;这是 debug&quot;)</span><br><span class="line">logger.info(&quot;这是 info&quot;)</span><br><span class="line">logger.warning(&quot;这是 warning&quot;)</span><br><span class="line">logger.error(&quot;这是 error&quot;)</span><br><span class="line">logger.critical(&quot;这是 critical&quot;)</span><br></pre></td></tr></table></figure>
<p>输出到文件 logger.add(“app.log”)</p>
<p>过滤级别 logger.add(“app.log”, level=“WARNING”)</p>
<p>移除默认控制台输出 logger.remove()</p>
<h3 id="参考资料">参考资料</h3>
<p>[<a href="https://www.bilibili.com/video/BV1rJv8eNE1x?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Python]
logging模块怎么用_哔哩哔哩_bilibili</a></p>
<p>[<a href="https://www.bilibili.com/video/BV1VnW7edEq7?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Python]
打印log神器 —— loguru_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>python-uv包管理</title>
    <url>/2025/08/02/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/python-uv%E5%8C%85%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h3 id="什么是uv">什么是uv</h3>
<p><code>uv</code> 是由 <strong>Astral</strong>
团队开发的一个<strong>超高速 Python 包管理器</strong>，用
<strong>Rust</strong> 编写，目标是替代
<code>pip</code>、<code>venv</code>、<code>pip-tools</code>、<code>poetry</code>
等多个工具。</p>
<h3 id="uv常用命令">uv常用命令</h3>
<p>uv init myproj 创建新项目</p>
<p>source .venv/bin/activate（Linux/macOS）激活虚拟环境</p>
<p>uv add requests 安装依赖并写入 pyproject.toml</p>
<p>uv remove requests 移除依赖</p>
<p>uv sync 同步依赖到虚拟环境</p>
<p>uv export 导出 lock 文件为 requirements.txt 等格式</p>
<p>uv build 构建源码包和 wheel</p>
<p>uv publish 发布到 PyPI</p>
<h3 id="uvx是什么">uvx是什么</h3>
<p><strong><code>uvx</code></strong> 是：</p>
<blockquote>
<p><strong>uv tool run</strong>
的<strong>快捷别名</strong>（alias），用于<strong>无需安装即可运行
Python 包提供的命令行工具</strong>。</p>
</blockquote>
<p><code>uvx</code> 就像 Python 世界的 <strong><code>npx</code></strong>
或 <strong><code>pipx run</code></strong> ——
<strong>临时拉取、构建隔离环境、运行工具，用完即走，不留痕迹</strong>。</p>
<h3 id="uv管理命令行工具">uv管理命令行工具</h3>
<p>使用<code>uv tool</code></p>
<ul>
<li><strong>用途</strong>：安装、管理、运行<strong>全局可用的 Python
命令行工具</strong>。</li>
<li><strong>安装位置</strong>：默认安装到
<code>~/.local/bin</code>（Windows:
<code>C:\Users\&lt;USER&gt;\.local\bin</code>）。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uv tool install pytest</span><br></pre></td></tr></table></figure>
<p>安装后可以直接使用<code>pytest</code>而不用<code>uv run pytest</code></p>
<h3 id="uv-sync和uv-pip-install--e-.的区别">uv sync和uv pip install -e
.的区别</h3>
<p>✅ <code>uv pip install -e .</code></p>
<ul>
<li><strong>作用</strong>：将当前项目以<strong>可编辑模式</strong>安装到当前
Python 环境。</li>
<li><strong>行为</strong>：
<ul>
<li>读取 <code>pyproject.toml</code> 中的 <code>[project]</code>
元数据。</li>
<li>构建并安装你的<strong>主包</strong>（如
<code>my_package</code>），使其可被 <code>import</code>。</li>
<li><strong>不会自动安装依赖</strong>（除非你显式加上
<code>--deps</code>，但通常不这么做）。</li>
</ul></li>
<li><strong>典型用途</strong>：开发自己的包时，让本地代码可导入。</li>
</ul>
<p>✅ <code>uv sync</code></p>
<ul>
<li><strong>作用</strong>：<strong>根据锁定文件（如
<code>uv.lock</code>）精确同步整个项目的依赖环境</strong>。</li>
<li><strong>行为</strong>：
<ul>
<li>读取 <code>uv.lock</code>（由 <code>uv lock</code> 生成）或
<code>pyproject.toml</code>。</li>
<li>安装<strong>所有依赖项</strong>（包括直接依赖和传递依赖）到当前环境。</li>
<li><strong>默认也会以可编辑模式安装当前项目</strong>（如果
<code>pyproject.toml</code> 中定义了项目）。</li>
<li>确保环境状态与锁定文件<strong>完全一致</strong>（版本、哈希、来源等）。</li>
</ul></li>
<li><strong>前提</strong>：通常需要先运行 <code>uv lock</code> 生成
<code>uv.lock</code>。</li>
</ul>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV1ajJ7zPEa5/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【uv】Python迄今最好的项目管理+环境管理工具（吧？）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV13WGHz8EEz?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">从pip到uv：一口气梳理现代Python项目管理全流程！_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>pydantic</title>
    <url>/2025/10/17/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/pydantic/</url>
    <content><![CDATA[<h3 id="field_validator"><span class="citation" data-cites="field_validator">@field_validator</span>()</h3>
<p>field_validator 是 Pydantic v2
的字段级校验与转换装饰器，用来在模型创建或赋值时，对指定字段做规则检查和/或值变换。例如</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@field_validator(&quot;name&quot;)</span><br><span class="line">def _validate_name(cls, v: str) -&gt; str:#cls 表示当前模型类</span><br><span class="line">    v = str(v).strip()</span><br><span class="line">    if not v:</span><br><span class="line">        raise ValueError(&quot;name 不能为空&quot;)</span><br><span class="line">    return v</span><br></pre></td></tr></table></figure>
<p>这个验证器的作用是确保 <code>name</code> 字段不能为空，这个
<code>_validate_name</code> 验证器会在 <strong>Pydantic
模型实例化（创建对象）时自动调用</strong></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>python异步编程-asyncio</title>
    <url>/2025/10/19/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/python-async/</url>
    <content><![CDATA[<h3 id="asyncio是什么">asyncio是什么</h3>
<p><code>asyncio</code> 是 <strong>Python
标准库中的一个模块</strong>，用于编写<strong>异步（asynchronous）程序</strong>。它提供了一套完整的工具，让你可以用
<code>async</code>/<code>await</code> 语法编写并发代码，特别适合处理
<strong>I/O
密集型任务</strong>（比如网络请求、文件读写、数据库查询等），而不会阻塞整个程序。</p>
<h3 id="概念学习">概念学习</h3>
<h4 id="并发">并发</h4>
<p><strong>并发（Concurrency）是一种“效果”——多个任务在一段时间内交替或同时推进。</strong>
它可以通过多种方式实现，常见的有：</p>
<ol type="1">
<li><strong>多线程（Multithreading）</strong></li>
<li><strong>异步编程（Asynchronous programming，如
asyncio）</strong></li>
<li><strong>多进程（Multiprocessing）</strong>（严格说更偏向“并行”，但也支持并发）</li>
</ol>
<h4 id="进程process线程thread-和-协程coroutine"><strong>进程（Process）</strong>、<strong>线程（Thread）</strong>
和 <strong>协程（Coroutine）</strong></h4>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 74%">
</colgroup>
<thead>
<tr>
<th>概念</th>
<th>定义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>进程（Process）</strong></td>
<td>操作系统进行资源分配和调度的基本单位。它是程序的一次执行实例，拥有独立的虚拟地址空间、文件描述符表、环境变量、信号处理表等内核资源。</td>
</tr>
<tr>
<td><strong>线程（Thread）</strong></td>
<td>进程内的执行流（execution context），是 CPU
调度的基本单位。同一进程内的多个线程共享该进程的地址空间和大部分资源（如堆、全局变量、打开的文件），但各自拥有独立的栈、寄存器状态和线程局部存储（TLS）。</td>
</tr>
<tr>
<td><strong>协程（Coroutine）</strong></td>
<td>一种用户态的轻量级并发原语，属于<strong>协作式多任务（cooperative
multitasking）</strong>模型。协程的切换由程序显式控制（如通过
<code>await</code> 或
<code>yield</code>），不依赖操作系统调度，上下文切换在用户空间完成，无内核介入。</td>
</tr>
</tbody>
</table>
<p><strong>线程”在 CPU 核心上运行。</strong>
<strong>进程是资源容器，线程是执行单位。</strong></p>
<p>内存与资源共享模型</p>
<table>
<colgroup>
<col style="width: 5%">
<col style="width: 12%">
<col style="width: 7%">
<col style="width: 32%">
<col style="width: 42%">
</colgroup>
<thead>
<tr>
<th>模型</th>
<th>地址空间</th>
<th>堆（Heap）</th>
<th>栈（Stack）</th>
<th>同步机制</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>进程</strong></td>
<td>独立</td>
<td>独立</td>
<td>独立</td>
<td>需 IPC（如管道、消息队列、共享内存 + 信号量）</td>
</tr>
<tr>
<td><strong>线程</strong></td>
<td>共享（同进程内）</td>
<td>共享</td>
<td>独立（每个线程一个栈）</td>
<td>需互斥锁（Mutex）、条件变量等防止数据竞争</td>
</tr>
<tr>
<td><strong>协程</strong></td>
<td>共享（同一线程内）</td>
<td>共享</td>
<td>逻辑独立（由运行时管理协程栈或使用生成器状态）</td>
<td>通常无需锁（因单线程串行执行），但需注意异步回调中的状态一致性</td>
</tr>
</tbody>
</table>
<p>在 Python 中的实现</p>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 28%">
<col style="width: 63%">
</colgroup>
<thead>
<tr>
<th>模型</th>
<th>标准库模块</th>
<th>关键 API</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>进程</strong></td>
<td><code>multiprocessing</code></td>
<td><code>Process</code>, <code>Pool</code>, <code>Queue</code>,
<code>Pipe</code>, <code>Manager</code></td>
</tr>
<tr>
<td><strong>线程</strong></td>
<td><code>threading</code></td>
<td><code>Thread</code>, <code>Lock</code>, <code>Condition</code>,
<code>Semaphore</code></td>
</tr>
<tr>
<td><strong>协程</strong></td>
<td><code>asyncio</code> + <code>async</code>/<code>await</code></td>
<td><code>async def</code>, <code>await</code>,
<code>asyncio.run()</code>, <code>create_task()</code>,
<code>gather()</code></td>
</tr>
</tbody>
</table>
<p><strong>进程</strong>
是<strong>资源隔离与并行计算</strong>的基石；</p>
<p><strong>线程</strong>
是<strong>操作系统级并发</strong>的传统手段，但在 Python 中受 GIL
限制；</p>
<p><strong>协程</strong> 是<strong>高并发 I/O
的现代解决方案</strong>，以极低开销实现大规模并发，已成为 Python
异步编程的事实标准。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">操作系统</span><br><span class="line"> └── 进程（Process） ← 资源容器（内存、文件描述符等）</span><br><span class="line">      └── 线程（Thread） ← CPU 调度单元（至少一个）</span><br><span class="line">           └── 协程（Coroutine） ← 用户态逻辑任务（可多个，协作式切换）</span><br></pre></td></tr></table></figure>
<p>当你运行一个 Python 脚本（如
<code>python app.py</code>），操作系统会：</p>
<ol type="1">
<li>创建一个<strong>新进程</strong>（Process）</li>
<li>加载 Python 解释器（CPython）</li>
<li>在该进程中<strong>启动主线程（Main Thread）</strong></li>
<li>执行你的代码</li>
</ol>
<blockquote>
<p>📌 所以：<strong>一个正在运行的 Python 程序 = 1 个进程 + 至少 1
个线程（主线程）</strong></p>
</blockquote>
<p>但注意：</p>
<ul>
<li>程序<strong>可以创建更多进程</strong>（通过
<code>multiprocessing</code>）</li>
<li>程序<strong>可以创建更多线程</strong>（通过
<code>threading</code>）</li>
<li>所以“一个程序”最终可能对应 <strong>多个进程、多个线程</strong></li>
</ul>
<h3 id="python-异步编程的核心机制">Python 异步编程的核心机制</h3>
<ol type="1">
<li><strong><code>async def</code></strong> 定义协程函数 → 返回
<strong>协程对象（Coroutine Object）</strong></li>
<li><strong><code>await</code></strong>
用于挂起当前协程，等待另一个协程或异步操作完成</li>
<li><strong>事件循环（Event Loop）</strong>（由 <code>asyncio</code>
提供）负责：
<ul>
<li>调度协程</li>
<li>管理 I/O 多路复用（如 <code>epoll</code>/<code>kqueue</code>）</li>
<li>在 I/O 就绪时恢复对应协程</li>
</ul></li>
</ol>
<h3 id="实战学习">实战学习</h3>
<h4 id="sync_demo.py">sync_demo.py</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from time import sleep, perf_counter</span><br><span class="line"></span><br><span class="line">def fetch_url(url):</span><br><span class="line">    print(&#x27;Fetching the URL&#x27;)</span><br><span class="line">    sleep(1)#模拟阻塞</span><br><span class="line">    print(&#x27;Finished fetching&#x27;)</span><br><span class="line">    return &#x27;url_content&#x27;</span><br><span class="line"></span><br><span class="line">def read_file(filepath):</span><br><span class="line">    print(&#x27;Reading the file&#x27;)</span><br><span class="line">    sleep(1)#模拟阻塞</span><br><span class="line">    print(&#x27;Finished reading&#x27;)</span><br><span class="line">    return &#x27;file_content&#x27;</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    url = &#x27;example.com&#x27;</span><br><span class="line">    filepath = &#x27;example.txt&#x27;</span><br><span class="line">    fetch_result = fetch_url(url)</span><br><span class="line">    read_result = read_file(filepath)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    start_time = perf_counter()</span><br><span class="line">    main()</span><br><span class="line">    end_time = perf_counter()</span><br><span class="line">    print(f&#x27;Time taken: &#123;end_time - start_time:.2f&#125; seconds&#x27;)</span><br></pre></td></tr></table></figure>
<p>以上展示一份同步的代码，sleep用来模拟阻塞</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Fetching the URL</span><br><span class="line">Finished fetching</span><br><span class="line">Reading the file</span><br><span class="line">Finished reading</span><br><span class="line">Time taken: 2.00 seconds</span><br></pre></td></tr></table></figure>
<h4 id="async_demo.py">async_demo.py</h4>
<p><strong>异步编程的三步核心流程</strong>：</p>
<blockquote>
<p><strong>1. 定义协程函数 → 2. 包装协程为任务 → 3.
建立事件循环</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from time import sleep, perf_counter</span><br><span class="line">import asyncio</span><br><span class="line"></span><br><span class="line">#定义协程函数</span><br><span class="line">async def fetch_url(url):</span><br><span class="line">    print(f&#x27;Fetching the url&#x27;)</span><br><span class="line">    #把阻塞操作包装成协程</span><br><span class="line">    await asyncio.sleep(1)</span><br><span class="line">    print(&#x27;Finished fetching&#x27;)</span><br><span class="line">    return &#x27;url_content&#x27;</span><br><span class="line"></span><br><span class="line">async def read_file(filepath):</span><br><span class="line">    print(&#x27;Reading the file&#x27;)</span><br><span class="line">    await asyncio.sleep(1)</span><br><span class="line">    print(&#x27;Finished reading&#x27;)</span><br><span class="line">    return &#x27;file_content&#x27;</span><br><span class="line"></span><br><span class="line">#若想使用await，需要把main函数定义成协程函数</span><br><span class="line">async def main():</span><br><span class="line">    url = &#x27;example.com&#x27;</span><br><span class="line">    filepath = &#x27;example.txt&#x27;</span><br><span class="line">    #创建任务</span><br><span class="line">    tasks = [asyncio.create_task(coro) for coro in [</span><br><span class="line">        fetch_url(url),</span><br><span class="line">        read_file(filepath)]]</span><br><span class="line">    fetch_result = await tasks[0]</span><br><span class="line">    read_result = await tasks[1]</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    start_time = perf_counter()</span><br><span class="line">    #创建事件循环</span><br><span class="line">    asyncio.run(main())</span><br><span class="line">    end_time = perf_counter()</span><br><span class="line">    print(f&#x27;Time taken: &#123;end_time - start_time:.2f&#125; seconds&#x27;)</span><br></pre></td></tr></table></figure>
<p>以上则是改为了异步的代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Fetching the url</span><br><span class="line">Reading the file</span><br><span class="line">Finished fetching</span><br><span class="line">Finished reading</span><br><span class="line">Time taken: 1.01 seconds</span><br></pre></td></tr></table></figure>
<h3 id="协程函数">协程函数</h3>
<p>协程函数（Coroutine Function）是 <strong>Python 中使用
<code>async def</code>
语法定义的函数</strong>，它是异步编程的核心构建单元。调用协程函数<strong>不会立即执行其内部代码</strong>，而是返回一个
<strong>协程对象（Coroutine Object）</strong>，该对象必须由事件循环（如
<code>asyncio</code>）驱动或通过 <code>await</code>
在另一个协程中调用，才能真正执行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line"></span><br><span class="line">#协程函数</span><br><span class="line">async def coroutine_func():</span><br><span class="line">    return &#x27;coroutine_result&#x27;</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    print(coroutine_func())</span><br><span class="line">    result = asyncio.run(coroutine_func())</span><br><span class="line">    print(&quot;---&quot;)</span><br><span class="line">    print(result)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;coroutine object coroutine_func at 0x000001958D88A4B0&gt;</span><br><span class="line">d:\code\python\learn_pythontips\learn_async\coroutine_func.py:8: RuntimeWarning: coroutine &#x27;coroutine_func&#x27; was never awaited</span><br><span class="line">  print(coroutine_func())</span><br><span class="line">RuntimeWarning: Enable tracemalloc to get the object allocation traceback</span><br><span class="line">---</span><br><span class="line">coroutine_result</span><br></pre></td></tr></table></figure>
<p>由输出可见，coroutine object，返回的是一个协程对象</p>
<h3 id="await关键字">await关键字</h3>
<p><code>await</code> 是 Python
异步编程中的<strong>核心关键字</strong>，它的作用是：</p>
<blockquote>
<p><strong>暂停当前协程的执行，等待一个“可等待对象”（awaitable）完成，并获取其结果，同时将控制权交还给事件循环，使其能运行其他任务。</strong></p>
</blockquote>
<p>✅ 三大功能：</p>
<ol type="1">
<li><strong>挂起（Suspend）</strong>：当前协程在此处暂停，不阻塞线程。</li>
<li><strong>等待（Wait）</strong>：等待一个异步操作（如网络请求、文件读写、定时器）完成。</li>
<li><strong>恢复（Resume）</strong>：当被等待的对象完成后，协程从此处恢复执行，并拿到结果。</li>
</ol>
<blockquote>
<p>⚠️ 关键：<strong><code>await</code>
不会阻塞整个线程</strong>，而是让事件循环去执行其他就绪的协程。</p>
</blockquote>
<h3 id="事件循环event-loop与任务task">事件循环（Event
Loop）与任务（Task）</h3>
<p><strong>事件循环（Event Loop）</strong>
是异步编程的<strong>核心引擎</strong>，尤其在 Python 的
<code>asyncio</code> 模型中，它是<strong>驱动协程执行、管理异步
I/O、调度任务的中枢系统</strong>。</p>
<blockquote>
<p><strong>事件循环是一个程序结构，用于监听和分发事件或消息，实现非阻塞
I/O 和协作式多任务调度。</strong></p>
</blockquote>
<p>在 Python <code>asyncio</code> 中，事件循环：</p>
<ul>
<li>维护一个<strong>待执行协程队列</strong></li>
<li>管理<strong>定时器</strong>（如 <code>asyncio.sleep</code>）</li>
<li>使用操作系统提供的 <strong>I/O 多路复用机制</strong>（如 Linux 的
<code>epoll</code>、macOS 的 <code>kqueue</code>、Windows 的
<code>IOCP</code>）来高效监听大量文件描述符（如 socket）</li>
<li>在 I/O 就绪时，<strong>恢复对应的协程</strong></li>
</ul>
<p><strong>那事件循环如何知道哪些协程可以执行，哪些协程需要暂停呢</strong></p>
<p>在 Python 异步编程（特别是
<code>asyncio</code>）中，<strong>任务（Task）</strong>
是是对<strong>协程（Coroutine）的封装</strong>，用于<strong>被事件循环调度和并发执行</strong>。</p>
<blockquote>
<p><strong><code>Task</code> 是 <code>asyncio</code>
中表示“未来会完成的异步操作”的对象，它是 <code>Future</code>
的子类，用于包装协程并自动调度其执行。</strong></p>
</blockquote>
<p>核心作用：</p>
<ol type="1">
<li><strong>将协程注册到事件循环中</strong>，使其能够<strong>并发运行</strong>（而非顺序等待）</li>
<li><strong>提供状态管理</strong>（如是否完成、是否取消、结果或异常）</li>
<li><strong>支持取消操作</strong>（<code>task.cancel()</code>）</li>
<li><strong>允许多次 <code>await</code></strong>（协程对象只能
<code>await</code> 一次，但 <code>Task</code> 可以）</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line"></span><br><span class="line">async def work(name, delay):</span><br><span class="line">    print(f&quot;开始 &#123;name&#125;&quot;)</span><br><span class="line">    await asyncio.sleep(delay)</span><br><span class="line">    print(f&quot;完成 &#123;name&#125;&quot;)</span><br><span class="line">    return f&quot;result-&#123;name&#125;&quot;</span><br><span class="line"></span><br><span class="line">async def main():</span><br><span class="line">    # 创建任务 → 立即开始执行！</span><br><span class="line">    task1 = asyncio.create_task(work(&quot;A&quot;, 2))</span><br><span class="line">    task2 = asyncio.create_task(work(&quot;B&quot;, 1))</span><br><span class="line"></span><br><span class="line">    # 等待任务完成（可获取结果）</span><br><span class="line">    r1 = await task1</span><br><span class="line">    r2 = await task2</span><br><span class="line">    print(r1, r2)</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">开始 A</span><br><span class="line">开始 B</span><br><span class="line">完成 B</span><br><span class="line">完成 A</span><br><span class="line">result-A result-B</span><br></pre></td></tr></table></figure>
<blockquote>
<p>💡 <strong>Task
是实现并发的关键</strong>：它让多个协程“同时启动”，而不是“一个接一个等”。</p>
</blockquote>
<h3 id="asyncio.gather">asyncio.gather</h3>
<p>asyncio.gather用于<strong>并发运行多个 awaitable
对象</strong>（如协程、Task、Future），并<strong>按顺序返回它们的结果列表</strong>。</p>
<p>默认：<strong>任意一个任务出错，其他任务会被取消</strong>（除非
<code>return_exceptions=True</code>）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def main():</span><br><span class="line">    url = &#x27;example.com&#x27;</span><br><span class="line">    filepath = &#x27;example.txt&#x27;</span><br><span class="line">    results = await asyncio.gather(</span><br><span class="line">        fetch_url(url),</span><br><span class="line">        read_file(filepath))</span><br><span class="line">    print(results)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Fetching the url</span><br><span class="line">Reading the file</span><br><span class="line">Finished fetching</span><br><span class="line">Finished reading</span><br><span class="line">[&#x27;url_content&#x27;, &#x27;file_content&#x27;]</span><br><span class="line">Time taken: 1.00 seconds</span><br></pre></td></tr></table></figure>
<h3 id="asyncio.as_completed">asyncio.as_completed</h3>
<p>asyncio.as_completed返回一个<strong>异步迭代器（async
iterator）</strong>，按<strong>任务完成的先后顺序</strong>，逐个产出已完成的
awaitable 对象（通常是 Task 或 Future）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">results = asyncio.as_completed([</span><br><span class="line">    fetch_url(url),</span><br><span class="line">    read_file(filepath)])</span><br><span class="line">for result in results:</span><br><span class="line">    print(await result)</span><br></pre></td></tr></table></figure>
<p>特点：<strong>先完成的任务先被处理</strong>，无需等待所有任务结束</p>
<h3 id="asyncio.to_thread">asyncio.to_thread</h3>
<p><strong><code>await asyncio.to_thread(func, \*args)</code></strong>在<strong>默认线程池</strong>中运行同步函数
<code>func(*args)</code>，并返回结果。 它是
<code>loop.run_in_executor(None, func, *args)</code>
的<strong>高层封装</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">def blocking_io():</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    return &quot;Done!&quot;</span><br><span class="line"></span><br><span class="line">async def main():</span><br><span class="line">    result = await asyncio.to_thread(blocking_io)</span><br><span class="line">    print(result)</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>
<h3 id="aiohttp和aiofiles">aiohttp和aiofiles</h3>
<p><code>aiohttp</code>：异步 HTTP 客户端与服务器框架</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import aiohttp</span><br><span class="line">import asyncio</span><br><span class="line"></span><br><span class="line">async def fetch(url):</span><br><span class="line">    async with aiohttp.ClientSession() as session:</span><br><span class="line">        async with session.get(url) as response:</span><br><span class="line">            return await response.text()</span><br><span class="line"></span><br><span class="line">asyncio.run(fetch(&quot;https://example.com&quot;))</span><br></pre></td></tr></table></figure>
<p><strong><code>aiofiles</code>
是一个为标准文件操作提供异步接口的库</strong>，允许你在
<code>async/await</code>
代码中安全地读写文件，<strong>而不会阻塞事件循环</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import aiofiles</span><br><span class="line">import asyncio</span><br><span class="line"></span><br><span class="line">async def main():</span><br><span class="line">    # 写文件</span><br><span class="line">    async with aiofiles.open(&#x27;data.txt&#x27;, &#x27;w&#x27;) as f:</span><br><span class="line">        await f.write(&#x27;Hello, async files!&#x27;)</span><br><span class="line"></span><br><span class="line">    # 读文件</span><br><span class="line">    async with aiofiles.open(&#x27;data.txt&#x27;, &#x27;r&#x27;) as f:</span><br><span class="line">        content = await f.read()</span><br><span class="line">        print(content)</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV157mFYEEkH/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Py】asyncio：为异步编程而生
| Python 特性 | 并发编程 | 协程_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1oa411b7c9/?spm_id_from=333.788.recommend_more_video.1&amp;trackid=web_related_0.router-related-2206146-bk62g.1761373068954.153&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【python】asyncio的理解与入门，搞不明白协程？看这个视频就够了。_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>pytest</title>
    <url>/2025/10/17/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/pytest/</url>
    <content><![CDATA[<h3 id="生成项目结构">生成项目结构</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">─src</span><br><span class="line">│  └─pytest_demo</span><br><span class="line">│          calculator.py</span><br><span class="line">│          __init__.py</span><br></pre></td></tr></table></figure>
<p>生成calculator.py类用于后续学习pytest，<code>以上树状结构使用tree /f</code>生成</p>
<h3 id="init__.py-文件的作用"><code>__init__.py</code> 文件的作用</h3>
<p><code>__init__.py</code>
文件的主要作用是告诉Python解释器这个目录是一个Python包（package）。当Python看到一个包含
<code>__init__.py</code>
文件的目录时，就会将其识别为一个可导入的包。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">pytest_demo package</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from .calculator import Calculator</span><br><span class="line"></span><br><span class="line">__all__ = [&#x27;Calculator&#x27;]</span><br></pre></td></tr></table></figure>
<p>相对导入 ： from .calculator import Calculator</p>
<ul>
<li>.calculator 表示从当前包内的 calculator.py 模块导入 Calculator
类</li>
<li>点号 . 表示相对导入，指向当前包</li>
</ul>
<p><code>__all__</code> 列表 ：
<code>__all__ = ['Calculator']</code></p>
<ul>
<li>定义了当使用 from pytest_demo import * 时会导入哪些对象</li>
<li>这是一个显式的公共API声明</li>
</ul>
<h3 id="pytest-的自动发现规则">pytest 的自动发现规则</h3>
<p>pytest 会自动查找以下内容：</p>
<ul>
<li>文件名：<code>test_*.py</code> 或 <code>*_test.py</code></li>
<li>函数名：<code>test_*()</code></li>
<li>类名：<code>Test*</code>（类中方法也需以 <code>test_</code>
开头）</li>
</ul>
<h3 id="测试文件">测试文件</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">└─tests</span><br><span class="line">    │  test_calculator.py</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from pytest_demo.calculator import Calculator</span><br><span class="line"></span><br><span class="line">def test_add() -&gt; None:</span><br><span class="line">    calc = Calculator()</span><br><span class="line">    assert calc.add(2, 1) == 3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def test_div() -&gt; None:</span><br><span class="line">    calc = Calculator()</span><br><span class="line">    assert calc.divide(2, 1) == 2</span><br></pre></td></tr></table></figure>
<p>运行 <code>uv run pytest</code></p>
<figure>
<img src="/2025/10/17/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/pytest/image-20251018194456963.png" alt="image-20251018194456963">
<figcaption aria-hidden="true">image-20251018194456963</figcaption>
</figure>
<h3 id="vscode支持pytest的可视化页面">vscode支持pytest的可视化页面</h3>
<p>ctrl+shift+p搜索</p>
<figure>
<img src="/2025/10/17/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/pytest/image-20251018194539467.png" alt="image-20251018194539467">
<figcaption aria-hidden="true">image-20251018194539467</figcaption>
</figure>
<figure>
<img src="/2025/10/17/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/pytest/image-20251018194723165.png" alt="image-20251018194723165">
<figcaption aria-hidden="true">image-20251018194723165</figcaption>
</figure>
<h3 id="使用pytest.raises验证异常">使用pytest.raises验证异常</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import pytest</span><br><span class="line"></span><br><span class="line">def test_divide_by_zero() -&gt; None:</span><br><span class="line">    calc = Calculator()</span><br><span class="line">    with pytest.raises(ZeroDivisionError):</span><br><span class="line">        calc.divide(2, 0)</span><br></pre></td></tr></table></figure>
<p>当你测试的函数<strong>应该在特定条件下抛出异常</strong>（比如传入非法参数、除零错误等），你可以用
<code>pytest.raises</code> 来验证：</p>
<blockquote>
<p>“这段代码是否如预期那样，抛出了我们想要的异常？”</p>
</blockquote>
<p>如果：</p>
<ul>
<li>✅ 抛出了<strong>指定类型</strong>的异常 → 测试通过</li>
<li>❌ 没有抛出异常 → 测试失败</li>
<li>❌ 抛出了<strong>其他类型</strong>的异常 → 测试失败</li>
</ul>
<h3 id="pytest.fixture提供测试参数"><span class="citation" data-cites="pytest.fixture提供测试参数">@pytest.fixture提供测试参数</span></h3>
<p><code>@pytest.fixture</code> 是 <strong>pytest
中最核心、最强大的功能之一</strong>，它的作用是：</p>
<blockquote>
<p><strong>为测试函数提供可复用的、隔离的“测试依赖”（如对象、数据、资源、环境等），并管理它们的生命周期。</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#工厂函数</span><br><span class="line">@pytest.fixture</span><br><span class="line">def calc() -&gt; Calculator:</span><br><span class="line">    return Calculator()</span><br><span class="line"></span><br><span class="line">def test_add(calc: Calculator) -&gt; None:</span><br><span class="line">    assert calc.add(2, 1) == 3</span><br></pre></td></tr></table></figure>
<p>在 pytest 中，<strong>当测试函数（或另一个 fixture）的参数名与某个
fixture 的名称相同时，pytest 会自动调用该
fixture，并将其返回值传入测试函数</strong>。</p>
<p>这是 pytest <strong>依赖注入机制的核心</strong>，也是 fixture
能“自动生效”的原因。</p>
<blockquote>
<p><strong>工厂函数（Factory Function）</strong>
是一种<strong>返回对象（通常是类的实例或其他函数）的函数</strong>，它的名字来源于“工厂模式”——就像工厂生产产品一样，这个函数“生产”对象。</p>
</blockquote>
<h4 id="scope-参数"><code>scope</code> 参数</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@pytest.fixture(scope=&quot;session&quot;)  # 整个测试会话只启动一次</span><br><span class="line">def browser():</span><br><span class="line">    driver = webdriver.Chrome()</span><br><span class="line">    yield driver</span><br><span class="line">    driver.quit()</span><br><span class="line"></span><br><span class="line">def test_login(browser):</span><br><span class="line">    browser.get(&quot;/login&quot;)</span><br><span class="line">def test_profile(browser):</span><br><span class="line">    browser.get(&quot;/profile&quot;)</span><br></pre></td></tr></table></figure>
<p>好处：避免创建多个实例</p>
<p>支持的作用域：</p>
<ul>
<li><code>function</code>（默认）：每个测试函数</li>
<li><code>class</code>：每个测试类</li>
<li><code>module</code>：每个 <code>.py</code> 文件</li>
<li><code>session</code>：整个测试运行</li>
</ul>
<h4 id="自动管理资源生命周期"><strong>自动管理资源生命周期</strong></h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pytest.fixture</span><br><span class="line">def temp_file():</span><br><span class="line">    # setup: 创建临时文件</span><br><span class="line">    path = &quot;temp.txt&quot;</span><br><span class="line">    with open(path, &quot;w&quot;) as f:</span><br><span class="line">        f.write(&quot;hello&quot;)</span><br><span class="line">    </span><br><span class="line">    yield path  # 测试函数在此处获得 path</span><br><span class="line"></span><br><span class="line">    # teardown: 清理</span><br><span class="line">    os.remove(path)</span><br><span class="line"></span><br><span class="line">def test_read_file(temp_file):</span><br><span class="line">    with open(temp_file) as f:</span><br><span class="line">        assert f.read() == &quot;hello&quot;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Python项目结构和打包</title>
    <url>/2025/10/18/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/Python%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E5%92%8C%E6%89%93%E5%8C%85/</url>
    <content><![CDATA[<h3 id="python项目结构和打包">Python项目结构和打包</h3>
<h4 id="pip-install-的本质">pip install 的本质</h4>
<p>从 <a href="https://pypi.org/">PyPI</a>（默认）或其他源（如私有仓库、本地文件）查找指定名称的包，下载对应的<code>.whl</code>文件</p>
<h4 id="whl文件">whl文件</h4>
<ul>
<li><code>.whl</code> 是 <strong>Wheel</strong> 的缩写，是 Python
的一种标准打包格式（PEP 427 定义）。</li>
<li>它本质上是一个 <strong>ZIP 格式的压缩包</strong>，扩展名改为
<code>.whl</code>。</li>
</ul>
<p>安装 .whl 文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install package_name.whl</span><br></pre></td></tr></table></figure>
<h4 id="hachling">hachling</h4>
<p><code>hatchling</code> 是 Python
生态中一个<strong>现代的、轻量级的构建后端（build
backend）</strong>，主要用于将 Python 项目打包成可分发的格式（如
<code>.whl</code> 或源码包）。它是 <a href="https://hatch.pypa.io/">Hatch</a>项目的一部分，由 PyPA（Python
Packaging Authority）推荐使用。</p>
<p>在pyproject.toml添加</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[build-system]</span><br><span class="line">requires = [&quot;hatchling&quot;]</span><br><span class="line">build-backend = &quot;hatchling.build&quot;</span><br></pre></td></tr></table></figure>
<p>当你运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install .</span><br><span class="line"># 或</span><br><span class="line">python -m build</span><br></pre></td></tr></table></figure>
<p>如果项目配置了 <code>hatchling</code> 作为构建后端，<code>pip</code>
或 <code>build</code> 工具就会调用 <code>hatchling</code>
来完成打包和安装。</p>
<p>例如以下项目结构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">my_project/</span><br><span class="line">├── pyproject.toml</span><br><span class="line">├── src/</span><br><span class="line">│   └── my_utils/               ← 你写的包</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── math.py</span><br><span class="line">├── scripts/</span><br><span class="line">│   └── run_demo.py             ← 想在这里用 my_utils</span><br></pre></td></tr></table></figure>
<p><strong>想让项目的其他文件使用自己编写的包</strong>，在pyproject.toml增加</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 👇 新增：显式声明包位置</span><br><span class="line">[tool.hatch.build.targets.wheel]</span><br><span class="line">packages = [&quot;src/my_utils&quot;]</span><br></pre></td></tr></table></figure>
<p>在项目根目录（<code>my_project/</code>）执行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uv pip install -e .</span><br></pre></td></tr></table></figure>
<blockquote>
<p>✅ 这会把 <code>src/my_utils/</code> 注册为一个可导入的包。</p>
</blockquote>
<h4 id="src-layout">src layout</h4>
<p><code>src layout</code>（也称为 <strong>src 布局</strong> 或
<strong>src 目录结构</strong>）是 Python
项目中一种<strong>推荐的源代码组织方式</strong>，其核心思想是：<strong>将你的
Python 包（package）放在一个名为 <code>src/</code>
的子目录下，而不是直接放在项目根目录中。</strong></p>
<p>❌ 传统布局（不推荐）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">my_project/</span><br><span class="line">├── my_package/</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   └── module.py</span><br><span class="line">├── tests/</span><br><span class="line">├── setup.py</span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure>
<p>✅ <strong>src 布局（推荐）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">my_project/</span><br><span class="line">├── src/</span><br><span class="line">│   └── my_package/</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── module.py</span><br><span class="line">├── tests/</span><br><span class="line">├── pyproject.toml</span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure>
<h4 id="uv-build和uv-pip-install-.什么区别">uv build和uv pip install
.什么区别</h4>
<p>一、<code>uv build</code></p>
<p>✅ 作用：<strong>构建分发包（不安装）</strong></p>
<ul>
<li>调用项目的构建后端（如
<code>hatchling</code>、<code>setuptools</code> 等）。</li>
<li>生成标准的分发文件：
<ul>
<li>一个 <strong>Wheel 文件</strong>（<code>.whl</code>）</li>
<li>一个 <strong>源码分发包</strong>（sdist，<code>.tar.gz</code>）</li>
</ul></li>
<li>输出到项目根目录下的 <code>dist/</code> 文件夹。</li>
<li><strong>不会将包安装到当前 Python 环境中</strong>。</li>
</ul>
<p>🔧 示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">uv build</span><br></pre></td></tr></table></figure>
<p>输出： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dist/my_package-0.1.0-py3-none-any.whl</span><br><span class="line">dist/my_package-0.1.0.tar.gz</span><br></pre></td></tr></table></figure></p>
<figure>
<img src="/2025/10/18/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/Python%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E5%92%8C%E6%89%93%E5%8C%85/image-20251018192905210.png" alt="image-20251018192905210">
<figcaption aria-hidden="true">image-20251018192905210</figcaption>
</figure>
<p>二、<code>uv pip install .</code></p>
<p>✅ 作用：<strong>安装当前项目到当前环境</strong></p>
<ul>
<li>首先（隐式）构建项目（类似 <code>uv build</code> 的过程）。</li>
<li>然后将构建结果<strong>安装到当前激活的 Python
环境</strong>（如虚拟环境或系统环境）。</li>
<li>安装后，你可以在 Python 中 <code>import</code> 该包。</li>
<li>默认是
<strong>“非可编辑安装”</strong>（即代码改动不会自动生效，除非重新安装）。</li>
</ul>
<p>🔧 示例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">uv pip install .</span><br></pre></td></tr></table></figure>
<p>效果： - 包被安装到 <code>site-packages/</code> - 可在 Python 中
<code>import my_package</code></p>
<h4 id="editable-install可编辑安装"><strong>Editable
install（可编辑安装）</strong></h4>
<p><strong>Editable install（可编辑安装）</strong> 是 Python
包管理中的一种安装模式，它让你在<strong>安装一个包的同时，保留对源代码的直接引用</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uv pip install -e .</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>核心机制</strong>：
<ul>
<li>不复制代码到 <code>site-packages/</code>。</li>
<li>而是在 <code>site-packages/</code> 中创建一个
<strong><code>.pth</code> 文件</strong> 或
<strong><code>my_package.egg-link</code></strong>，指向你本地项目中的
<code>src/</code>（或包目录）。</li>
<li>Python 解释器在导入时，会顺着这个链接去读你本地的源码。</li>
</ul></li>
</ul>
<figure>
<img src="/2025/10/18/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/Python%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E5%92%8C%E6%89%93%E5%8C%85/image-20251018193022973.png" alt="image-20251018193022973">
<figcaption aria-hidden="true">image-20251018193022973</figcaption>
</figure>
<h4 id="python是从哪里查找模块的">python是从哪里查找模块的</h4>
<p>Python 查找模块（module）的机制由 <strong>模块搜索路径（module search
path）</strong> 决定，这个路径是一个字符串列表，存储在
<code>sys.path</code> 中。当你执行 <code>import some_module</code>
时，Python
会<strong>按顺序</strong>在这个列表中的每个目录里查找对应的模块文件。</p>
<p>可以通过以下代码查看当前 Python 的模块搜索路径：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">print(sys.path)</span><br></pre></td></tr></table></figure>
<p><code>sys.path</code> 通常包含以下几类路径（顺序很重要）：</p>
<ol type="1">
<li><strong>脚本所在目录（或当前工作目录）</strong></li>
</ol>
<ul>
<li>如果你运行 <code>python /path/to/script.py</code>，那么
<code>/path/to/</code> 会被加到 <code>sys.path[0]</code>。</li>
<li>如果你运行 <code>python</code> 进入交互模式，或运行
<code>python -c "..."</code>，则<strong>当前工作目录（<code>os.getcwd()</code>）</strong>
会被放在首位。</li>
<li>⚠️ 这是很多“意外导入”问题的根源（比如项目根目录下有同名包）。</li>
</ul>
<ol start="2" type="1">
<li><strong>环境变量 <code>PYTHONPATH</code> 中的目录</strong></li>
</ol>
<ul>
<li>类似系统的 <code>PATH</code>，你可以通过设置 <code>PYTHONPATH</code>
添加自定义搜索路径。</li>
<li>示例（Linux/macOS）： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="string">&quot;/my/custom/modules:<span class="variable">$PYTHONPATH</span>&quot;</span></span><br><span class="line">python my_script.py</span><br></pre></td></tr></table></figure></li>
<li>Windows（PowerShell）： <figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="variable">$env:PYTHONPATH</span> = <span class="string">&quot;C:\my\custom\modules;&quot;</span> + <span class="variable">$env:PYTHONPATH</span></span><br></pre></td></tr></table></figure></li>
</ul>
<ol start="3" type="1">
<li><strong>标准库目录</strong></li>
</ol>
<ul>
<li>Python 自带的模块（如 <code>os</code>, <code>sys</code>,
<code>json</code>）所在位置。</li>
<li>通常位于 Python 安装目录下的 <code>lib/</code> 子目录中。</li>
</ul>
<ol start="4" type="1">
<li><strong>第三方包安装目录（site-packages）</strong></li>
</ol>
<ul>
<li>通过 <code>pip install</code>、<code>uv pip install</code>
等安装的包，会被放到 <code>site-packages</code> 目录。</li>
<li>路径可通过以下命令查看： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> site</span><br><span class="line"><span class="built_in">print</span>(site.getsitepackages())  <span class="comment"># 全局环境</span></span><br><span class="line"><span class="built_in">print</span>(site.getusersitepackages())  <span class="comment"># 用户级安装</span></span><br></pre></td></tr></table></figure></li>
</ul>
<ol start="5" type="1">
<li><strong><code>.pth</code> 文件中指定的路径</strong></li>
</ol>
<ul>
<li>某些包（尤其是 editable install）会在 <code>site-packages/</code>
中放置 <code>.pth</code> 文件，动态添加路径到
<code>sys.path</code>。</li>
</ul>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV12NgLzhEKx?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">build
+ hatchling 15分钟搞懂Python项目结构和打包_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>python设计模式</title>
    <url>/2025/10/19/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h3 id="为什么要有设计模式">为什么要有设计模式</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class DatabaseConnection:</span><br><span class="line">    def __init__(self, host, port, username, password):</span><br><span class="line">        self.host = host</span><br><span class="line">        self.port = port</span><br><span class="line">        self.username = username</span><br><span class="line">        self.password = password</span><br><span class="line"></span><br><span class="line">    def connect(self):</span><br><span class="line">        return f&quot;Connecting to database at &#123;self.host&#125;:&#123;self.port&#125; with username &#x27;&#123;self.username&#125;&#x27;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def client():</span><br><span class="line">    main_db = DatabaseConnection(&#x27;localhost&#x27;, 3306, &#x27;root&#x27;, &#x27;password123&#x27;)</span><br><span class="line">    analytics_db = DatabaseConnection(&#x27;192.168.1.1&#x27;, 5432, &#x27;admin&#x27;, &#x27;securepass&#x27;)</span><br><span class="line">    cache_db = DatabaseConnection(&#x27;10.0.0.1&#x27;, 27017, &#x27;cacheuser&#x27;, &#x27;cachepass&#x27;)</span><br><span class="line"></span><br><span class="line">    print(main_db.connect())</span><br><span class="line">    print(analytics_db.connect())</span><br><span class="line">    print(cache_db.connect())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">client()</span><br></pre></td></tr></table></figure>
<p>这是数据库连接类的范例，其存在以下问题</p>
<ol type="1">
<li>数据库连接信息（主机、端口、用户名、密码）直接写在代码中，缺乏配置管理，难以在不同环境间切换，如果要更改数据库的信息，就要更改项目中每一处的连接数据库的参数，难以维护</li>
<li>每次都需要手动传入相同类型的参数，增加出错的风险</li>
</ol>
<h3 id="工厂模式factory-pattern">工厂模式（Factory Pattern）</h3>
<p><strong>工厂模式</strong>
是一种创建型设计模式，它提供了一种<strong>创建对象的接口</strong>，但让子类决定实例化哪一个类。换句话说：<strong>把对象的创建过程封装起来</strong>，调用者不需要关心具体创建的是哪个类，只需要知道“我要一个某种类型的东西”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def connection_factory(db_type):</span><br><span class="line">    db_configs = &#123;</span><br><span class="line">        &#x27;main&#x27;: &#123;</span><br><span class="line">            &#x27;host&#x27;: &#x27;localhost&#x27;,</span><br><span class="line">            &#x27;port&#x27;: 3306,</span><br><span class="line">            &#x27;username&#x27;: &#x27;root&#x27;,</span><br><span class="line">            &#x27;password&#x27;: &#x27;password123&#x27;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#x27;analytics&#x27;: &#123;</span><br><span class="line">            &#x27;host&#x27;: &#x27;192.168.1.1&#x27;,</span><br><span class="line">            &#x27;port&#x27;: 5432,</span><br><span class="line">            &#x27;username&#x27;: &#x27;admin&#x27;,</span><br><span class="line">            &#x27;password&#x27;: &#x27;securepass&#x27;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#x27;cache&#x27;: &#123;</span><br><span class="line">            &#x27;host&#x27;: &#x27;10.0.0.1&#x27;,</span><br><span class="line">            &#x27;port&#x27;: 27017,</span><br><span class="line">            &#x27;username&#x27;: &#x27;cacheuser&#x27;,</span><br><span class="line">            &#x27;password&#x27;: &#x27;cachepass&#x27;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    return DatabaseConnection(**db_configs[db_type])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 测试工厂模式</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 使用工厂函数创建不同类型的数据库连接</span><br><span class="line">    main_db = connection_factory(&#x27;main&#x27;)</span><br><span class="line">    analytics_db = connection_factory(&#x27;analytics&#x27;)</span><br><span class="line">    cache_db = connection_factory(&#x27;cache&#x27;)</span><br><span class="line">    </span><br><span class="line">    # 测试连接</span><br><span class="line">    print(main_db.connect())</span><br><span class="line">    print(analytics_db.connect())</span><br><span class="line">    print(cache_db.connect())</span><br></pre></td></tr></table></figure>
<p>将数据库的配置信息提取到config.py</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#factory_pattern.py</span><br><span class="line">def connection_factory(db_type):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    工厂函数：根据数据库类型创建相应的数据库连接</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        db_type (str): 数据库类型 (&#x27;main&#x27;, &#x27;analytics&#x27;, &#x27;cache&#x27;)</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">        DatabaseConnection: 数据库连接实例</span><br><span class="line">    </span><br><span class="line">    Raises:</span><br><span class="line">        KeyError: 当提供的数据库类型不存在时</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    from config import DATABASE_CONFIGS</span><br><span class="line">    if db_type not in DATABASE_CONFIGS:</span><br><span class="line">        raise ValueError(f&quot;Unknown database type: &#123;db_type&#125;. Available types: &#123;list(DATABASE_CONFIGS.keys())&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    return DatabaseConnection(**DATABASE_CONFIGS[db_type])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#config.py</span><br><span class="line"># 数据库配置字典</span><br><span class="line">DATABASE_CONFIGS = &#123;</span><br><span class="line">    &#x27;main&#x27;: &#123;</span><br><span class="line">        &#x27;host&#x27;: &#x27;localhost&#x27;,</span><br><span class="line">        &#x27;port&#x27;: 3306,</span><br><span class="line">        &#x27;username&#x27;: &#x27;root&#x27;,</span><br><span class="line">        &#x27;password&#x27;: &#x27;password123&#x27;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;analytics&#x27;: &#123;</span><br><span class="line">        &#x27;host&#x27;: &#x27;192.168.1.1&#x27;,</span><br><span class="line">        &#x27;port&#x27;: 5432,</span><br><span class="line">        &#x27;username&#x27;: &#x27;admin&#x27;,</span><br><span class="line">        &#x27;password&#x27;: &#x27;securepass&#x27;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;cache&#x27;: &#123;</span><br><span class="line">        &#x27;host&#x27;: &#x27;10.0.0.1&#x27;,</span><br><span class="line">        &#x27;port&#x27;: 27017,</span><br><span class="line">        &#x27;username&#x27;: &#x27;cacheuser&#x27;,</span><br><span class="line">        &#x27;password&#x27;: &#x27;cachepass&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为什么要这么做</p>
<ul>
<li>所有配置信息都在一个地方，便于统一管理和维护</li>
<li>易于修改 ：配置变更不需要修改业务逻辑代码</li>
</ul>
<p>工厂模式的核心就是工厂函数</p>
<p><strong>工厂函数</strong>是一个<strong>返回对象的函数</strong>（而不是类），它封装了对象的创建逻辑，根据输入参数决定返回哪种具体对象。</p>
<h3 id="建造者模式builder-pattern">建造者模式（Builder Pattern）</h3>
<p>当你需要创建一个有很多属性、配置步骤繁多的对象时（比如一辆汽车、一个
HTTP 请求、一个数据库连接配置），直接用构造函数会非常混乱。
<strong>建造者模式通过“分步构建 +
最终组装”的方式，让创建过程清晰、灵活、可读性强。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class DatabaseConnectionBuilder:</span><br><span class="line">    &quot;&quot;&quot;数据库连接建造者类&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    def __init__(self,host,port,username,password):</span><br><span class="line">        self._config = &#123;</span><br><span class="line">            &#x27;host&#x27;: host,</span><br><span class="line">            &#x27;port&#x27;: port,</span><br><span class="line">            &#x27;username&#x27;: username,</span><br><span class="line">            &#x27;password&#x27;: password,</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    def set_max_connections(self, max_connections):</span><br><span class="line">        &quot;&quot;&quot;设置最大连接数&quot;&quot;&quot;</span><br><span class="line">        if max_connections is not None and max_connections &lt;= 0:</span><br><span class="line">            raise ValueError(&quot;Max connections must be positive&quot;)</span><br><span class="line">        self._config[&#x27;max_connections&#x27;] = max_connections</span><br><span class="line">        return self</span><br><span class="line">    </span><br><span class="line">    def set_timeout(self, timeout):</span><br><span class="line">        &quot;&quot;&quot;设置超时时间&quot;&quot;&quot;</span><br><span class="line">        if timeout is not None and timeout &lt;= 0:</span><br><span class="line">            raise ValueError(&quot;Connect timeout must be positive&quot;)</span><br><span class="line">        self._config[&#x27;timeout&#x27;] = timeout</span><br><span class="line">        return self</span><br><span class="line">        </span><br><span class="line">    def build(self):</span><br><span class="line">        &quot;&quot;&quot;构建最终的数据库连接对象&quot;&quot;&quot;  </span><br><span class="line">        return DatabaseConnection(**self._config)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"># 演示建造者模式的使用</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 创建一个数据库连接建造者</span><br><span class="line">    builder = DatabaseConnectionBuilder(</span><br><span class="line">        host=&#x27;localhost&#x27;,</span><br><span class="line">        port=3306,</span><br><span class="line">        username=&#x27;root&#x27;,</span><br><span class="line">        password=&#x27;password123&#x27;</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    # 使用建造者模式构建数据库连接</span><br><span class="line">    connection = builder.set_max_connections(100) \</span><br><span class="line">                        .set_timeout(30) \</span><br><span class="line">                        .enable_ssl() \</span><br><span class="line">                        .set_connection_pool(&#x27;my_pool&#x27;) \</span><br><span class="line">                        .set_retry_attempts(3) \</span><br><span class="line">                        .enable_compression() \</span><br><span class="line">                        .set_read_preference(&#x27;secondaryPreferred&#x27;) \</span><br><span class="line">                        .build()</span><br></pre></td></tr></table></figure>
<h3 id="单例模式singleton-pattern">单例模式（Singleton Pattern）</h3>
<blockquote>
<p><strong>单例模式</strong>确保一个类<strong>只有一个实例</strong>，并提供一个<strong>全局访问点</strong>来获取该实例。</p>
</blockquote>
<p>换句话说：
无论你调用多少次“创建对象”，返回的始终是<strong>同一个对象</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class DatabaseConnection:</span><br><span class="line">    &quot;&quot;&quot;数据库连接单例类&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    _instance = None</span><br><span class="line">    _lock = threading.Lock()  # 线程锁，确保线程安全</span><br><span class="line">    </span><br><span class="line">    def __new__(cls, *args, **kwargs):</span><br><span class="line">        &quot;&quot;&quot;重写__new__方法实现单例模式&quot;&quot;&quot;</span><br><span class="line">        if cls._instance is None:</span><br><span class="line">            with cls._lock:  # 使用双重检查锁定</span><br><span class="line">                if cls._instance is None:</span><br><span class="line">                    cls._instance = super().__new__(cls)</span><br><span class="line">        return cls._instance</span><br><span class="line">    </span><br><span class="line">    def __init__(self, host, port, username, password):</span><br><span class="line">        &quot;&quot;&quot;初始化数据库连接参数&quot;&quot;&quot;</span><br><span class="line">        # 防止重复初始化</span><br><span class="line">        if hasattr(self, &#x27;_initialized&#x27;):</span><br><span class="line">            return</span><br><span class="line">        </span><br><span class="line">        self.host = host</span><br><span class="line">        self.port = port</span><br><span class="line">        self.username = username</span><br><span class="line">        self.password = password</span><br><span class="line">        self._initialized = True</span><br><span class="line">    </span><br><span class="line">    def connect(self):</span><br><span class="line">        &quot;&quot;&quot;连接数据库&quot;&quot;&quot;</span><br><span class="line">        return f&quot;Connecting to database at &#123;self.host&#125;:&#123;self.port&#125; with username &#x27;&#123;self.username&#125;&#x27;&quot;</span><br><span class="line"></span><br><span class="line">def client():</span><br><span class="line">    db1 = DatabaseConnection(host=&#x27;localhost&#x27;, port=3306, username=&#x27;root&#x27;, password=&#x27;password&#x27;)</span><br><span class="line">    db2 = DatabaseConnection(host=&#x27;localhost&#x27;, port=3306, username=&#x27;root&#x27;, password=&#x27;password&#x27;)</span><br><span class="line">    print(db1 is db2)</span><br><span class="line"></span><br><span class="line">client()</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV131421876N/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【设计模式
inPy】一个视频搞懂三种设计模式：工厂、建造者和单例_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1j7HLzkE6q/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">为什么你应该忘掉设计模式？_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV19E42137eX/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【设计模式inPython】策略模式：不要再用一个类装所有方法啦！_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>python魔法方法</title>
    <url>/2025/10/25/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h3 id="什么是魔法方法">什么是魔法方法</h3>
<p>Python 的<strong>魔法方法</strong>（Magic
Methods），也叫<strong>特殊方法</strong>（Special
Methods）或<strong>双下方法</strong>（dunder
methods，因为名字前后都有双下划线 <code>__</code>），是 Python
类中预定义的一类方法，用于定义对象在特定操作下的行为。</p>
<p>当你使用像
<code>+</code>、<code>len()</code>、<code>str()</code>、<code>in</code>、<code>[]</code>
等语法时，Python 其实是在背后调用对应的魔法方法。</p>
<h3 id="常见魔法方法举例">常见魔法方法举例</h3>
<h4 id="init__初始化对象">1. <code>__init__</code>：初始化对象</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="variable language_">self</span>.name = name</span><br><span class="line"></span><br><span class="line">p = Person(<span class="string">&quot;Alice&quot;</span>)  <span class="comment"># 调用 __init__</span></span><br></pre></td></tr></table></figure>
<h4 id="str__-和-__repr__控制对象的字符串表示">2. <code>__str__</code>
和 <code>__repr__</code>：控制对象的字符串表示</h4>
<ul>
<li><code>__str__</code> 用于 <code>str(obj)</code> 或
<code>print(obj)</code>，面向用户。</li>
<li><code>__repr__</code>
用于调试，面向开发者，通常返回可执行的代码字符串。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Point</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        <span class="variable language_">self</span>.x = x</span><br><span class="line">        <span class="variable language_">self</span>.y = y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Point(<span class="subst">&#123;self.x&#125;</span>, <span class="subst">&#123;self.y&#125;</span>)&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Point(x=<span class="subst">&#123;self.x&#125;</span>, y=<span class="subst">&#123;self.y&#125;</span>)&quot;</span></span><br><span class="line"></span><br><span class="line">p = Point(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(p)        <span class="comment"># Point(1, 2) ← 调用 __str__</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">repr</span>(p))  <span class="comment"># Point(x=1, y=2) ← 调用 __repr__</span></span><br></pre></td></tr></table></figure>
<h4 id="len__支持-lenobj">3. <code>__len__</code>：支持
<code>len(obj)</code></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyList</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, items</span>):</span><br><span class="line">        <span class="variable language_">self</span>.items = items</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.items)</span><br><span class="line"></span><br><span class="line">my_list = MyList([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(my_list))  <span class="comment"># 3</span></span><br></pre></td></tr></table></figure>
<h4 id="getitem__-__setitem__支持-objkey-和-objkey-value">4.
<code>__getitem__</code> / <code>__setitem__</code>：支持
<code>obj[key]</code> 和 <code>obj[key] = value</code></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vector</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="variable language_">self</span>.data = data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.data[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__setitem__</span>(<span class="params">self, index, value</span>):</span><br><span class="line">        <span class="variable language_">self</span>.data[index] = value</span><br><span class="line"></span><br><span class="line">v = Vector([<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>])</span><br><span class="line"><span class="built_in">print</span>(v[<span class="number">1</span>])      <span class="comment"># 20</span></span><br><span class="line">v[<span class="number">1</span>] = <span class="number">99</span></span><br><span class="line"><span class="built_in">print</span>(v[<span class="number">1</span>])      <span class="comment"># 99</span></span><br></pre></td></tr></table></figure>
<h4 id="add__支持-运算符">5. <code>__add__</code>：支持 <code>+</code>
运算符</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vector</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        <span class="variable language_">self</span>.x = x</span><br><span class="line">        <span class="variable language_">self</span>.y = y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__add__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> Vector(<span class="variable language_">self</span>.x + other.x, <span class="variable language_">self</span>.y + other.y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;Vector(<span class="subst">&#123;self.x&#125;</span>, <span class="subst">&#123;self.y&#125;</span>)&quot;</span></span><br><span class="line"></span><br><span class="line">v1 = Vector(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">v2 = Vector(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(v1 + v2)  <span class="comment"># Vector(4, 6)</span></span><br></pre></td></tr></table></figure>
<h4 id="eq__支持-比较">6. <code>__eq__</code>：支持 <code>==</code>
比较</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Book</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, title</span>):</span><br><span class="line">        <span class="variable language_">self</span>.title = title</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__eq__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.title == other.title</span><br><span class="line"></span><br><span class="line">b1 = Book(<span class="string">&quot;Python&quot;</span>)</span><br><span class="line">b2 = Book(<span class="string">&quot;Python&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(b1 == b2)  <span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<h4 id="call__让对象像函数一样被调用">7.
<code>__call__</code>：让对象像函数一样被调用</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Multiplier</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, factor</span>):</span><br><span class="line">        <span class="variable language_">self</span>.factor = factor</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> x * <span class="variable language_">self</span>.factor</span><br><span class="line"></span><br><span class="line">double = Multiplier(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(double(<span class="number">5</span>))  <span class="comment"># 10</span></span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV1vx421D7AP/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Python
特性】魔法方法：让你的类和原生类一样顺滑_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Websockets</title>
    <url>/2025/10/25/%E5%AD%A6%E4%B9%A0/python-web/Websockets/</url>
    <content><![CDATA[<h2 id="什么是长轮询long-polling">🕰️ 什么是长轮询（Long Polling）？</h2>
<p><strong>长轮询</strong> 是一种在 <strong>没有 WebSocket 或
Server-Sent Events（SSE）</strong>
的环境下，<strong>模拟“服务器推送”</strong> 的技术。</p>
<p>客户端发起 HTTP
请求后，<strong>服务器不会立即响应</strong>，而是<strong>挂起连接</strong>，直到<strong>有新数据可返回</strong>或<strong>超时</strong>才发送响应；客户端收到响应后立即<strong>重新发起请求</strong>，从而实现<strong>准实时的双向通信</strong>。</p>
<p>❌ 但最坏情况是：</p>
<ul>
<li>前端在 <strong>t=0s</strong> 发起请求</li>
<li><strong>新数据在 t=0.1s 产生</strong></li>
<li>但<strong>后端没检测到</strong>（比如检查间隔是 1 秒）</li>
<li>后端一直等到 <strong>t=10s 超时</strong>，才返回“无数据”</li>
<li>前端在 <strong>t=10s</strong> 收到响应，显示“没更新”</li>
<li>然后<strong>立刻</strong>发起下一轮请求（t=10s）</li>
<li>后端这次检测到数据（t=10.1s）→ 返回</li>
<li>前端在 <strong>t=10.2s</strong> 才显示！</li>
</ul>
<p>→ <strong>延迟 = 10.1 秒！</strong></p>
<p>🧠 核心问题：<strong>检测粒度 + 请求对齐</strong></p>
<p>长轮询的延迟主要来自两个地方：</p>
<table>
<colgroup>
<col style="width: 24%">
<col style="width: 75%">
</colgroup>
<thead>
<tr>
<th>延迟来源</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1. 后端检查间隔</strong></td>
<td>如果后端每 1 秒检查一次数据，那么数据产生后最多要等 1
秒才被发现</td>
</tr>
<tr>
<td><strong>2. 请求发起时机</strong></td>
<td>如果数据在“上一轮请求刚结束、下一轮还没发”时产生，就要等下一轮超时结束</td>
</tr>
</tbody>
</table>
<blockquote>
<p>💡
即使后端“一有数据就返回”，<strong>前提是它在“当前这个请求还在挂起时”检测到了数据</strong>。</p>
</blockquote>
<h2 id="什么是-websocket">🌐 什么是 WebSocket？</h2>
<p><strong>WebSocket</strong>
是一种<strong>全双工通信协议</strong>，建立在 TCP
之上，允许客户端和服务器之间<strong>实时、双向</strong>地传输数据。</p>
<p>对比传统的 HTTP：</p>
<ul>
<li>HTTP
是<strong>请求-响应</strong>模式：客户端发请求，服务器响应，然后连接关闭。</li>
<li>WebSocket
是<strong>持久连接</strong>：连接建立后，双方可以随时主动发消息，适合聊天、实时通知、在线游戏等场景。</li>
</ul>
<h2 id="websocket-vs-http-轮询举例说明">🔁 WebSocket vs HTTP
轮询（举例说明）</h2>
<p>假设你要做一个<strong>实时股票价格更新</strong>页面：</p>
<ul>
<li><strong>HTTP 轮询</strong>：前端每 1
秒发一次请求问“价格变了吗？”，服务器回答。浪费带宽，延迟高。</li>
<li><strong>WebSocket</strong>：连接一次，服务器价格一变就主动推给前端，高效实时。</li>
</ul>
<h2 id="websocket-通信流程简化版">🧱 WebSocket 通信流程（简化版）</h2>
<ol type="1">
<li>客户端发起 HTTP 请求，带 <code>Upgrade: websocket</code> 头。</li>
<li>服务器同意升级协议，返回 <code>101 Switching Protocols</code>。</li>
<li>连接升级为 WebSocket，之后双方通过这个连接发消息（不是 HTTP
了！）。</li>
<li>任意一方可主动关闭连接。</li>
</ol>
<h2 id="websocket通信图解">websocket通信图解</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant Client as 客户端 (React)</span><br><span class="line">    participant Server as 服务器 (FastAPI)</span><br><span class="line"></span><br><span class="line">    Note over Client,Server: 1. 建立 WebSocket 连接</span><br><span class="line">    Client-&gt;&gt;Server: GET /ws + Upgrade: websocket</span><br><span class="line">    Server--&gt;&gt;Client: 101 Switching Protocols</span><br><span class="line"></span><br><span class="line">    Note over Client,Server: 2. 双向通信阶段</span><br><span class="line">    Client-&gt;&gt;Server: send(&quot;Hello&quot;)</span><br><span class="line">    Server--&gt;&gt;Client: send(&quot;服务器回声: Hello&quot;)</span><br><span class="line">    Server-&gt;&gt;Client: send(&quot;主动推送: 2秒过去了！&quot;)</span><br><span class="line">    Client--&gt;&gt;Server: send(&quot;收到推送，谢谢！&quot;)</span><br><span class="line"></span><br><span class="line">    Note over Client,Server: 3. 任意一方可关闭连接</span><br><span class="line">    Client-&gt;&gt;Server: close()</span><br><span class="line">    Server--&gt;&gt;Client: 连接关闭</span><br></pre></td></tr></table></figure>
<h2 id="与长轮询对比">与长轮询对比</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant C as 客户端</span><br><span class="line">    participant S as 服务器</span><br><span class="line"></span><br><span class="line">    Note over C,S: WebSocket（高效）</span><br><span class="line">    C-&gt;&gt;S: 握手 (HTTP Upgrade)</span><br><span class="line">    S--&gt;&gt;C: 101 Switching</span><br><span class="line">    loop 实时通信</span><br><span class="line">        S-&gt;&gt;C: 数据 (任意时刻)</span><br><span class="line">        C-&gt;&gt;S: 数据 (任意时刻)</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    Note over C,S: 长轮询（低效）</span><br><span class="line">    loop 每次都要新建请求</span><br><span class="line">        C-&gt;&gt;S: GET /poll</span><br><span class="line">        S--&gt;&gt;C: 等待...（最多30秒）</span><br><span class="line">        S-&gt;&gt;C: 响应（有/无数据）</span><br><span class="line">        C-&gt;&gt;S: GET /poll （立刻重发）</span><br><span class="line">    end</span><br></pre></td></tr></table></figure>
<h2 id="参考资料">参考资料</h2>
<p><a href="https://www.bilibili.com/video/BV1n3411u7uf?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">WebSockets原理，握手和代码实现！用Socket.io制作实时聊天室_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1Rh4y167Uh?spm_id_from=333.788.recommend_more_video.0&amp;trackid=web_related_0.router-related-2206146-q9d4h.1761464810537.403&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">为什么有http还要有websocket（上）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>python-web</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>python内存管理-GIL</title>
    <url>/2025/10/19/%E5%AD%A6%E4%B9%A0/python%E7%9B%B8%E5%85%B3/python%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h3 id="gil是什么">GIL是什么</h3>
<p><strong>GIL（Global Interpreter Lock，全局解释器锁）</strong> 是
<strong>CPython 解释器</strong>（Python
的官方实现）中的一个<strong>互斥锁（mutex）</strong>，它确保<strong>同一时刻只有一个线程执行
Python 字节码</strong>。</p>
<p>🔒 互斥锁的定义：</p>
<blockquote>
<p>互斥锁是一种同步原语，用于<strong>防止多个线程同时访问共享资源</strong>。</p>
</blockquote>
<p>GIL 正是这样一把锁：</p>
<ul>
<li><strong>共享资源</strong> = CPython
解释器的内部状态（如对象引用计数、内存管理器）</li>
<li><strong>保护方式</strong> = 任何线程要执行 Python 代码，必须先获取
GIL</li>
</ul>
<h3 id="为什么要设计gil">为什么要设计GIL</h3>
<p>GIL 的核心原因：<strong>CPython 的内存管理模型</strong></p>
<p>🔑 关键点：</p>
<blockquote>
<p><strong>CPython 使用“引用计数（Reference
Counting）”作为主要的内存管理机制</strong>，而引用计数的<strong>增减操作必须是原子的</strong>。</p>
</blockquote>
<p>🔑 核心逻辑链：</p>
<blockquote>
<p><strong>Python（CPython）使用引用计数（Reference
Counting）管理内存</strong> ↓
<strong>引用计数的增减必须是原子操作（否则会出错）</strong> ↓
<strong>为了保证原子性，CPython 引入了 GIL（全局互斥锁）</strong> ↓
<strong>GIL 确保同一时刻只有一个线程能修改引用计数</strong></p>
</blockquote>
<h4 id="什么是引用计数reference-counting">什么是<strong>引用计数（Reference
Counting）</strong></h4>
<p>在 CPython 中，<strong>每个 Python 对象</strong>（如
<code>list</code>, <code>str</code>, 自定义类实例）都有一个字段叫
<code>ob_refcnt</code>，记录“有多少变量/容器引用了它”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = [1, 2, 3]      # ob_refcnt = 1</span><br><span class="line">b = a              # ob_refcnt = 2</span><br><span class="line">c = [a, &quot;hello&quot;]   # ob_refcnt = 3（因为 c[0] 也引用了它）</span><br><span class="line">del b              # ob_refcnt = 2</span><br></pre></td></tr></table></figure>
<p>当 <code>ob_refcnt</code> <strong>降到 0</strong>
时，对象立即被销毁（内存回收）。</p>
<h4 id="如果没有gil">如果没有GIL</h4>
<p>假设两个线程同时执行 <code>b = a</code>：</p>
<table>
<colgroup>
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 42%">
</colgroup>
<thead>
<tr>
<th>线程 A</th>
<th>线程 B</th>
<th>实际 <code>ob_refcnt</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>读取 <code>ob_refcnt = 1</code></td>
<td>读取 <code>ob_refcnt = 1</code></td>
<td>1</td>
</tr>
<tr>
<td>计算 <code>1 + 1 = 2</code></td>
<td>计算 <code>1 + 1 = 2</code></td>
<td>—</td>
</tr>
<tr>
<td>写回 <code>ob_refcnt = 2</code></td>
<td>写回 <code>ob_refcnt = 2</code></td>
<td><strong>2</strong>（但正确值应为 <strong>3</strong>！）</td>
</tr>
</tbody>
</table>
<p>👉 <strong>结果</strong>：引用计数错误 →
对象可能被<strong>提前释放</strong>（程序崩溃）或<strong>内存泄漏</strong>。</p>
<blockquote>
<p>💥 这就是<strong>竞态条件</strong>（Race
Condition）：<strong>多个线程/进程并发访问共享资源时，最终结果依赖于它们的执行顺序或
timing（时序），导致程序行为不可预测、错误或崩溃。</strong></p>
</blockquote>
<h3 id="为什么-javago-不需要gil">为什么 Java/Go 不需要GIL？</h3>
<table>
<thead>
<tr>
<th>语言</th>
<th>内存管理</th>
<th>是否需要全局锁</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Python </strong>(CPython)</td>
<td>引用计数（运行时增减）</td>
<td>✅ 需要（GIL）</td>
</tr>
<tr>
<td><strong>Java / Go / C#</strong></td>
<td>垃圾回收（GC）</td>
<td>❌ 不需要</td>
</tr>
<tr>
<td><strong>Rust</strong></td>
<td>编译期所有权检查</td>
<td>❌ 不需要</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>GC 语言</strong>：对象分配/回收由<strong>专用 GC
线程</strong>处理，用户线程不直接操作引用计数</li>
<li><strong>Rust</strong>：内存安全在<strong>编译期</strong>保证，运行时无引用计数开销</li>
</ul>
<h3 id="什么是gc">什么是GC</h3>
<p><strong>GC（Garbage Collection，垃圾回收）</strong>
是现代编程语言中<strong>自动管理内存</strong>的核心机制。其核心思想为，
<strong>自动找出“不再使用的对象”，并回收其内存，无需程序员手动释放。</strong></p>
<p>🆚 对比：手动管理 vs 自动管理</p>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 21%">
<col style="width: 65%">
</colgroup>
<thead>
<tr>
<th>方式</th>
<th>代表语言</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>手动管理</strong></td>
<td>C, C++</td>
<td>程序员用<code>malloc/free</code>或<code>new/delete</code>管理内存 →
容易出错（内存泄漏、野指针）</td>
</tr>
<tr>
<td><strong>自动管理</strong></td>
<td>Java, Go, C#, Python</td>
<td>语言运行时自动回收内存 → 安全，但有性能开销</td>
</tr>
</tbody>
</table>
<h4 id="gc是如何工作的">GC是如何工作的</h4>
<p>主流 GC（如 Java、Go）使用
<strong>“可达性分析”</strong>（Reachability
Analysis）判断对象是否存活：</p>
<p>🌳 核心概念：<strong>根对象</strong>（Roots）</p>
<ul>
<li>全局变量</li>
<li>当前函数的局部变量</li>
<li>CPU 寄存器中的引用</li>
</ul>
<p>📌 判断规则：</p>
<blockquote>
<p><strong>从根对象出发，能通过引用链到达的对象 = 存活对象</strong>
<strong>无法到达的对象 = 垃圾（可回收）</strong></p>
</blockquote>
<h3 id="python的程序并行">python的程序并行</h3>
<p><strong>由于 CPython 的 GIL（全局解释器锁）存在：</strong></p>
<ul>
<li><strong>多线程无法在多核 CPU 上并行执行 Python 字节码（尤其是 CPU
密集型任务）</strong>；</li>
<li><strong>但多进程可以绕过
GIL，每个进程拥有独立的解释器和内存空间，因此能真正并行，充分利用多核
CPU。</strong></li>
</ul>
<table>
<colgroup>
<col style="width: 21%">
<col style="width: 16%">
<col style="width: 30%">
<col style="width: 31%">
</colgroup>
<thead>
<tr>
<th>类型</th>
<th>是否受 GIL 限制</th>
<th>能否利用多核</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>多线程（Threading）</strong></td>
<td>✅ 受限（CPU 任务串行）</td>
<td>❌ CPU 任务不能✅ I/O 任务可以（因释放 GIL）</td>
<td>网络请求、文件读写、数据库查询等 I/O 密集型</td>
</tr>
<tr>
<td><strong>多进程（Multiprocessing）</strong></td>
<td>❌ 不受限</td>
<td>✅ 能（真并行）</td>
<td>图像处理、模型推理、加密计算等 CPU 密集型</td>
</tr>
</tbody>
</table>
<blockquote>
<p>📌 注意：<strong>“并行”（parallelism）≠
“并发”（concurrency）</strong><br>
- 多线程在 Python 中实现的是 <strong>并发（交替执行）</strong>，不是
<strong>并行（同时执行）</strong>（对 CPU 任务而言）。</p>
</blockquote>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV1im411R7UB/?spm_id_from=333.788.recommend_more_video.-1&amp;trackid=web_related_0.router-related-2206146-52fdn.1761309673091.512&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">带大家感受一下没有GIL的CPython_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1za411t7dR?spm_id_from=333.788.recommend_more_video.-1&amp;trackid=web_related_0.router-related-2206146-pkt2c.1761372920438.898&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【python】天使还是魔鬼？GIL的前世今生。一期视频全面了解GIL！_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>python相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo常用指令</title>
    <url>/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<p>以下是 Hexo 常用的指令整理，方便快速查阅：</p>
<hr>
<h3 id="基础操作"><strong>基础操作</strong></h3>
<ol type="1">
<li><p><strong>初始化博客</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init [文件夹名]  <span class="comment"># 创建新博客（不指定文件夹则在当前目录生成）</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>安装依赖</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install           <span class="comment"># 安装 Hexo 核心依赖（初始化后可能需要执行）</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>本地预览</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server           <span class="comment"># 启动本地服务器（默认端口 4000），缩写：hexo s</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>生成静态文件</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo generate         <span class="comment"># 生成 public 文件夹的静态文件，缩写：hexo g</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>部署到服务器</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo deploy           <span class="comment"># 部署到 GitHub Pages 或其他平台，缩写：hexo d</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
<hr>
<h3 id="文章与页面"><strong>文章与页面</strong></h3>
<ol type="1">
<li><p><strong>新建文章</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;文章标题&quot;</span>    <span class="comment"># 生成新文章（Markdown 文件），缩写：hexo n</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>新建页面</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new page <span class="string">&quot;页面名&quot;</span> <span class="comment"># 创建自定义页面（如 about、tags）</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
<hr>
<h3 id="清理与调试"><strong>清理与调试</strong></h3>
<ol type="1">
<li><p><strong>清理缓存</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean            <span class="comment"># 删除生成的 public 和缓存文件（修改主题后建议执行）</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>查看帮助</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo <span class="built_in">help</span>             <span class="comment"># 查看所有指令说明</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
<hr>
<h3 id="组合指令高效操作"><strong>组合指令（高效操作）</strong></h3>
<ul>
<li><p><strong>生成并部署</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g -d          <span class="comment"># 先生成静态文件，再部署（等同 hexo generate &amp;&amp; hexo deploy）</span></span><br><span class="line">hexo d -g          <span class="comment"># 同上，顺序不影响结果</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>生成并预览</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo s -g          <span class="comment"># 先生成文件，再启动本地服务器</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
<hr>
<h3 id="注意事项"><strong>注意事项</strong></h3>
<ul>
<li><strong>部署前配置</strong>：需在 <code>_config.yml</code> 中设置
<code>deploy</code> 参数（如 GitHub 仓库地址）。</li>
<li><strong>安装部署插件</strong>：首次部署需运行
<code>npm install hexo-deployer-git</code>。</li>
<li><strong>主题安装</strong>：将主题克隆到 <code>themes/</code>
文件夹后，在配置文件中指定主题名称。</li>
</ul>
<p>如果需要更详细的操作说明，可以补充具体场景（如更换主题、设置分类等）！</p>
<h3 id="hexo-d上传失败网络连接问题解决方案">hexo
d上传失败，网络连接问题解决方案</h3>
<p>原因：<strong>Clash 虽然开启了代理，但 Git
默认不会走这个代理</strong>，导致连接 GitHub 时失败</p>
<figure>
<img src="/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/image-20250722204420664.png" alt="image-20250722204420664">
<figcaption aria-hidden="true">image-20250722204420664</figcaption>
</figure>
<p>解决方案：</p>
<p>查看端口号</p>
<figure>
<img src="/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/image-20250722204512612.png" alt="image-20250722204512612">
<figcaption aria-hidden="true">image-20250722204512612</figcaption>
</figure>
<p>查看git代理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global --get http.proxy</span><br><span class="line">git config --global --get https.proxy</span><br></pre></td></tr></table></figure>
<p>更改代理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global http.proxy socks5://127.0.0.1:1080</span><br><span class="line">git config --global https.proxy socks5://127.0.0.1:1080</span><br></pre></td></tr></table></figure>
<h3 id="参考教程">参考教程</h3>
<p><a href="https://tech.yemengstar.com/hexo-tutorial-deploy-githubpages-beginner/">HEXO系列教程
| 使用GitHub部署静态博客HEXO | 小白向教程 – 夜梦星尘の折腾日记</a></p>
<p><a href="https://www.bilibili.com/video/BV12H4y1N7Q4/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Github王炸功能Pages,免费免服务器上线网站,详细教程_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>前端1——入门</title>
    <url>/2025/02/15/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/</url>
    <content><![CDATA[<h2 id="环境">环境</h2>
<p>vscode</p>
<p>插件：</p>
<p>HTML CSS Support 写css代码</p>
<p>Live Serve 实时预览html网页</p>
<p>Auto Rename Tag 同步修改标签名称</p>
<h2 id="html">HTML</h2>
<p>html （hyper text markup language） 超文本标记语言</p>
<p>网页是又html标签描述出来的</p>
<p>html文件结构</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span>//文档编码格式</span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;viewport&quot;</span> <span class="attr">content</span>=<span class="string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Document<span class="tag">&lt;/<span class="name">title</span>&gt;</span>//文档标题</span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span>//页面内容</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>块元素（block）：块级元素通常用于组织和布局页面的主要结构和内容，例如段落、标题、列表、表格等。它们用于创建页面的主要部分，将内容分隔成逻辑块。</p>
<p>行内元素（inline）：行内元素通常用于添加文本样式或为文本中的一部分应用样式。它们可以在文本中插入小的元素，例如超链接、强调文本等。</p>
<p>常用标签</p>
<p><code>&lt;h1&gt; &lt;/h1&gt;</code>一级标签</p>
<p><code>&lt;p&gt; &lt;/p&gt;</code>段落标签</p>
<p><code>&lt;b&gt; &lt;/b&gt;</code> bold 文本加粗</p>
<p><code>&lt;u&gt; &lt;/u&gt;</code> 下划线</p>
<p><code>&lt;s&gt; &lt;/s&gt;</code> 删除线</p>
<p>无序列表</p>
<p><code>&lt;ul&gt;</code> <code>&lt;li&gt;1&lt;/li&gt;</code>
<code>&lt;li&gt;2&lt;/li&gt;</code> <code>&lt;/ul&gt;</code></p>
<p>有序列表</p>
<p><code>&lt;ol&gt;</code> <code>&lt;li&gt;1&lt;/li&gt;</code>
<code>&lt;li&gt;2&lt;/li&gt;</code> <code>&lt;/ol&gt;</code></p>
<p>表格</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">table</span> <span class="attr">border</span>=<span class="string">&quot;1&quot;</span>&gt;</span>//边框宽度为1</span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">th</span>&gt;</span>标题1<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">th</span>&gt;</span>标题2<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>元素1<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>元素2<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>html属性 基本语法：<开始标签 属性名="“属性值”"></开始标签></p>
<p><code>&lt;a href="www.zxj-2023.github.io" target="_blank"&gt;超链接&lt;/a&gt;</code>
超链接，target决定链接打开方式</p>
<p><code>&lt;br&gt;</code> 换行</p>
<p><code>&lt;hr&gt;</code> 分割线</p>
<p><code>&lt;img src="图片路径或链接" alt="代替文本" width="宽度" height="高度"&gt;&lt;/img&gt;</code>
图片</p>
<p><code>&lt;div class="名称"&gt;&lt;/div&gt;</code>块级标签，用于创建页面的布局结构，如导航栏，页眉等</p>
<p>优先级：id&gt;class&gt;标签名</p>
<p><code>&lt;span&gt;&lt;/span&gt;</code>包装文本以便对其使用css，js行为或样式等</p>
<p>form标签是html表单的容器</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;#&quot;</span>&gt;</span>//URL</span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">&quot;username&quot;</span>&gt;</span>用户名：<span class="tag">&lt;/<span class="name">label</span>&gt;</span>//与span类似，for用于和input的id绑定</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">id</span>=<span class="string">&quot;username&quot;</span> <span class="attr">placehoud</span>=<span class="string">&quot;请输入用户名&quot;</span>&gt;</span></span><br><span class="line">	//input其他属性，value：规定input内的值</span><br><span class="line">	<span class="tag">&lt;<span class="name">label</span>&gt;</span>密码：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placehoud</span>=<span class="string">&quot;请输入密码&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span>&gt;</span>性别：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span>&gt;</span> 男//单选择 名称一致</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span>&gt;</span> 女</span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span>&gt;</span>爱好：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span>&gt;</span> 唱歌//多选</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span>&gt;</span> 跳舞</span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span>&gt;</span>//提交按钮 提交表单数据</span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="css">CSS</h2>
<p>css cascading style sheets
用于定义网页样式和布局的样式表语言，通过CSS，可以指定页面中各个元素的颜色、字体、大小、间距、边框、背景等样式，从而实现更精确的页面设计。</p>
<p>语法：</p>
<p>选择器{</p>
<p>​ 属性1：属性值1；</p>
<p>​ 属性2：属性值2；</p>
<p>}</p>
<p>内部样式表：放在head里面</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css">        <span class="selector-tag">p</span>&#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">color</span>:bule;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">font-size</span>:<span class="number">16px</span>;//字体大小</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>:yellow//背景色</span></span><br><span class="line"><span class="language-css">            font-family:<span class="string">&#x27;KaiTi&#x27;</span>//修改字体，楷体</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">    </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">        内容</span><br><span class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>外部样式：需在head链接</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;路径&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>内联样式：标签内</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span> <span class="attr">style</span>=<span class="string">&quot;color=red;&quot;</span>&gt;</span></span><br><span class="line">    内容</span><br><span class="line"><span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>优先级：内联样式&gt;内部样式表&gt;外部样式</p>
<p>css选择器：</p>
<p>元素选择器：标签名</p>
<p>类选择器：.+类名</p>
<p>id选择器：#+id名</p>
<p>通用选择器：*</p>
<p>子代选择器：父+&gt;+子</p>
<p>后代选择器：父+空格+子</p>
<p>相邻元素选择器：1+2 需要满足相邻条件</p>
<p>伪类选择器</p>
<p>css属性：</p>
<p><a href="https://www.runoob.com/cssref/css-reference.html">CSS
参考手册 |菜鸟教程</a></p>
<p><code>&lt;h1 style="font: bolder 50px 'KaiTi';"&gt;复合属性&lt;/h1&gt;</code>
font符合属性示例</p>
<p>区分块、行内、行内块元素width和height的差异</p>
<p>通过display转换以上三者(block,inline,inline-block)</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.div-inline&#123;</span><br><span class="line">	display:inline;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>盒子模型：</p>
<ol type="1">
<li>内容（content）</li>
<li>内边距（padding）：内容与边框之间的空间</li>
<li>边框（border）：盒子的边界 上右下左</li>
<li>外边距（margin）：盒子与其他元素之间的空间</li>
</ol>
<figure>
<img src="/2025/02/15/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/asdsdf.png" alt="asdsdf">
<figcaption aria-hidden="true">asdsdf</figcaption>
</figure>
<p>浮动：改变元素默认的排列顺序，使网页布局更加灵活多变(letf right)</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.son&#123;</span><br><span class="line">	float:left;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>清除浮动的方式</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.father&#123;</span><br><span class="line">	overflow: hidden;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定位布局：</p>
<p>相对定位(relative)∶相对于元素在文档流中的正常位置进行定位。</p>
<p>绝对定位(absolute)︰相对于其最近的已定位祖先元素进行定位，不占据文档流。</p>
<p>固定定位(fixed)︰相对于浏览器窗口进行定位。不占据文档流，固定在屏幕上的位置，不随滚动而移动。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.box-relative&#123;</span><br><span class="line">	position: relative;//相对定位</span><br><span class="line">	left:</span><br><span class="line">	right:</span><br><span class="line">	top:</span><br><span class="line">	bottom:</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="javascript">JavaScript</h2>
<p>JavaScript是一种轻量级、解释型、面向对象的脚本语言。它主要被设计用于在网页上实现动态效果，增加用户与网页的交互性。
作为一种客户端脚本语言，JavaScript可以直接嵌入HTML，并在浏览器中执行。
与HTML和CSS不同，JavaScript使得网页不再是静态的，而是可以根据用户的操作动态变化的。</p>
<p><code>客户端脚本</code>:用于在用户浏览器中执行，实现动态效果和用户交互。</p>
<p><code>网页开发</code>:与HTML和CSS协同工作，使得网页具有更强的交互性和动态性。</p>
<p><code>后端开发</code>︰使用Node.js，JavaScript
也可以在服务器端运行，实现服务器端应用的开发。</p>
<p>js的导入</p>
<p>内联</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">	<span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;hello,world&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>外联</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;相对路径&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;hello,world&#x27;</span>)<span class="comment">//控制台输出</span></span><br><span class="line"><span class="title function_">alert</span>(<span class="string">&#x27;&#x27;</span>)<span class="comment">//内联弹窗</span></span><br></pre></td></tr></table></figure>
<p>js语句</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//变量</span></span><br><span class="line"><span class="keyword">var</span> x;<span class="comment">//varible</span></span><br><span class="line"><span class="keyword">let</span> t=<span class="number">5</span>;<span class="comment">//块级作用域</span></span><br><span class="line"><span class="keyword">const</span> <span class="variable constant_">PI</span> =<span class="number">3.14</span>;<span class="comment">//常量</span></span><br><span class="line"><span class="comment">//条件语句</span></span><br><span class="line"><span class="keyword">if</span>()&#123;&#125;<span class="keyword">else</span>&#123;&#125;</span><br><span class="line"><span class="comment">//循环，for，while</span></span><br><span class="line"><span class="comment">//函数</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">function_name</span>(<span class="params"></span>)&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> 返回值;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用html属性触发事件</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span> <span class="attr">onclick</span>=<span class="string">&quot;click_event()&quot;</span>&gt;</span></span><br><span class="line">        点击事件</span><br><span class="line">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">onfocus</span>=<span class="string">&quot;focus_event()&quot;</span> <span class="attr">onblur</span>=<span class="string">&quot;blur_event()&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    	<span class="keyword">function</span> <span class="title function_">click_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">alert</span>(<span class="string">&#x27;触发点击事件&#x27;</span>)</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">        </span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">function</span> <span class="title function_">focus_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;获取焦点&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">        </span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">function</span> <span class="title function_">blur_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;失去焦点&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">    </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>DOM</p>
<p>当网页被加载时，浏览器会创建页面的文档对象模型，也就是DOM (Document
Object Model)
.每个HTML或XML文档都可以被视为一个文档树，文档树是整个文档的层次结构表示。</p>
<p>文档节点是整个文档树的根节点。</p>
<p>DOM为这个文档树提供了一个编程接口，开发者可以使用JavaScript来操作这个树状结构。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;box1&quot;</span>&gt;</span>ID选择器标签<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;box2&quot;</span>&gt;</span>类选择器标签<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span>&gt;</span></span><br><span class="line">        点击按钮</span><br><span class="line">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">scrip</span>&gt;</span></span><br><span class="line">    	var element_id = document.getElementById(&#x27;box1&#x27;);//id唯一，获取的是元素</span><br><span class="line">        console.log(element_id)</span><br><span class="line">		</span><br><span class="line">        var element_class = document.getElementsByClassName(&#x27;box2&#x27;)[0];//类不唯一，获取的是数组</span><br><span class="line">        console.log(element_id)</span><br><span class="line">        </span><br><span class="line">        element_id.innerHTML = &#x27;修改id标签内容&#x27;;</span><br><span class="line">        element_id.innerText</span><br><span class="line">        element_id.style.color</span><br><span class="line">        element_id.style.fontSize</span><br><span class="line">        </span><br><span class="line">        //DOM属性绑定事件</span><br><span class="line">        var button_element = document.getElementsByTagName(&#x27;button&#x27;);</span><br><span class="line">        </span><br><span class="line">        button_element.onclick = function()&#123;</span><br><span class="line">        	alert(&#x27;DOM 属性按键触发&#x27;)</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        button)element.addEventListener(&#x27;click&#x27;,click_event)</span><br><span class="line">        function click_event()&#123;</span><br><span class="line">        	alert(&#x27;通过addEventListener触发&#x27;)</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">scrip</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>对象</strong></p>
<p>对象（object）是 JavaScript 语言的核心概念，也是最重要的数据类型</p>
<p>简单说，对象就是一组“键值对”（key-value）的集合，是一种无序的复合数据集合</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> user = &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="string">&#x27;itbaizhan&#x27;</span>,</span><br><span class="line">  <span class="attr">age</span>: <span class="string">&#x27;13&#x27;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>对象的每一个键名又称为“属性”（property），它的“键</p>
<p>值”可以是任何数据类型。如果一个属性的值为函数，通常把这个属性称为“方法”，它可以像函数那样调用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> user = &#123;</span><br><span class="line">  <span class="attr">getName</span>: <span class="keyword">function</span> (<span class="params">name</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> name;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">user.<span class="title function_">getName</span>(<span class="string">&quot;itbaizhan&quot;</span>) <span class="comment">// itbaizhan</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/02/15/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/image-20211025173456785.png" alt="image-20211025173456785">
<figcaption aria-hidden="true">image-20211025173456785</figcaption>
</figure>
<h2 id="参考视频">参考视频</h2>
<p><a href="https://www.bilibili.com/video/BV1BT4y1W7Aw/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">3小时前端入门教程（HTML+CSS+JS）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>前端2——巩固</title>
    <url>/2025/02/18/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF2/</url>
    <content><![CDATA[<h3 id="vscode">vscode</h3>
<p>代码格式化：shift+alt+f</p>
<p>向上或向下移动一行:Alt+Up或Alt+Down</p>
<p>快速开始新一行：ctrl+enter</p>
<p>快速复制一行代码:Shift+Alt+Up 或Shift+Alt+Down</p>
<p>快速保存:Ctrl +S</p>
<p>快速查找:Ctrl + F</p>
<p>快速替换:Ctrl+ H</p>
<p>快速移动一行 alt + ↓或↑</p>
<p>多光标： alt + 鼠标左键</p>
<h3 id="html5">html5</h3>
<p><strong>合并单元格</strong></p>
<ul>
<li>水平合并：colspan</li>
<li>垂直合并：rowspan</li>
</ul>
<p><strong>h5新标签</strong></p>
<ol type="1">
<li><code>&lt;header&gt;&lt;/header&gt;</code> 头部</li>
<li><code>&lt;nav&gt;&lt;/nav&gt;</code> 导航</li>
<li><code>&lt;section&gt;&lt;/section&gt;</code>定义文档中的节,比如章节、页眉、页脚</li>
<li><code>&lt;aside&gt;&lt;/aside&gt;</code> 侧边栏</li>
<li><code>&lt;footer&gt;&lt;/footer&gt;</code> 脚部</li>
<li><code>&lt;article&gt;&lt;/article&gt;</code>
代表一个独立的、完整的相关内容块,例如一篇完整的论坛帖子，一篇博客文章，一个用户评论等</li>
</ol>
<p><strong>查漏补缺</strong></p>
<p><code>&lt;figure&gt;</code>元素表示文档流中独立的内容块。这个内容通常与主文档相关，但可以被移动到文档的其他位置（如侧边栏、脚注或独立的附件）而不会影响理解文档的其余部分。</p>
<p><code>&lt;section&gt;</code>元素用于定义文档中的一个区域（section），它通常表示文档中的一个主题或内容块。</p>
<p>图像标题（<code>figcaption</code>）元素用于添加标题以描述
<code>figure</code> 元素中包含的图像。<code>&lt;figcaption&gt;</code>
必须是 <code>&lt;figure&gt;</code> 元素的子元素，并且它必须是
<code>&lt;figure&gt;</code> 中的第一个或最后一个子元素</p>
<p>“URL” 是 “Uniform Resource Locator” 的缩写，中文意思是
“统一资源定位符”。它是一种用于在互联网上定位和访问资源（如网页、图像、视频等）的地址。</p>
<p><code>fieldset</code> 元素用于在 Web
表单中将相关的输入和标签组合在一起。 <code>fieldset</code>
元素是块级元素，这意味着它们出现在新的一行上。</p>
<p><code>legend</code> 元素充当 <code>fieldset</code> 元素中内容的标题。
它为用户提供了应该在表单的该部分中输入什么的上下文。</p>
<p><code>&lt;meta name="viewport" content="width=device-width, initial-scale=1.0" /&gt;</code>是一个非常重要的
HTML 元标签，用于控制网页在移动设备上的布局和显示方式</p>
<p>article和section</p>
<p>article标签表示文档、页面、应用或网站的一部分，具有独立性和完整性。它通常包含一些内容，如新闻报道、博客文章、论坛帖子等，这些内容可以被单独地分享、链接和索引。</p>
<p>section标签则表示文档或应用的一部分，但不具有独立性和完整性。它通常用于组织内容，将页面或应用分成不同的部分，例如头部、主体、脚注等。</p>
<p><code>method</code> 属性指定了如何将表单数据发送到
<code>action</code> 属性中指定的 URL。 表单数据可以通过 <code>GET</code>
请求作为 URL 参数发送（<code>method="get"</code>）或通过
<code>POST</code>
请求作为请求正文中的数据发送（<code>method="post"</code>）。</p>
<p>给密码 <code>input</code> 元素添加 <code>pattern</code>
属性，要求输入匹配 <code>[a-z0-5]&#123;8,&#125;</code>。上面是一个正则表达式，匹配
8 个以上的小写字母或数字 <code>0</code> 到 <code>5</code>。</p>
<p><code>&lt;select&gt;</code> 和 <code>&lt;option&gt;</code> 是 HTML
中用于创建下拉列表的元素</p>
<p><code>&lt;textarea&gt;</code> 是 HTML
中的一个表单元素，用于多行文本输入，允许用户输入和编辑大量文本。</p>
<p><strong>英文全称记忆</strong></p>
<p><code>&lt;ul&gt;</code> ： “Unordered List”</p>
<p><code>&lt;li&gt;</code> ： “List - item”</p>
<p><code>src</code>： “source”</p>
<p><code>css text-align</code>: “text alignment”（文本对齐方式）</p>
<p><code>link rel</code>:relationship</p>
<p><code>&lt;hr&gt;</code>:“Horizontal Rule”</p>
<h3 id="css3">css3</h3>
<p><strong>查漏补缺</strong></p>
<p><code>opacity</code> 是 CSS
中用于控制元素透明度的属性。它可以设置一个元素的透明度级别，取值范围从
<code>0</code>（完全透明）到 <code>1</code>（完全不透明）</p>
<p><code>box-shadow</code>
属性允许你在元素周围应用一个或多个阴影。<code>box-shadow: offsetX offsetY blurRadius color;</code></p>
<p><code>linear-gradient</code> 是 CSS
中用于创建线性渐变背景的属性。它允许你在元素的背景中定义多种颜色之间的平滑过渡效果</p>
<p><code>hsla</code>（Hue色相, Saturation饱和度, Lightness,
Alpha透明度）是一种在 CSS 中定义颜色的方式，基于
HSL（色相、饱和度、亮度）颜色模型，并且允许设置透明度（alpha 值）。</p>
<p><code>vh</code> 是 CSS 中的一种相对长度单位，表示视口高度（Viewport
Height）的百分比。具体来说，<code>1vh</code> 等于视口高度的
1%。视口是指浏览器窗口中可见的部分，不包括工具栏、地址栏等非内容区域。</p>
<p><code>em</code> 是 CSS
中的一种相对单位，用于表示元素的字体大小（<code>font-size</code>）的倍数。具体来说，<code>1em</code>
等于当前元素的字体大小。例如，如果一个元素的字体大小为
<code>16px</code>，那么 <code>1em</code> 就等于 <code>16px</code>。</p>
<p><code>rem</code>（Root Em）是 CSS
中的一种相对单位，表示相对于根元素（<code>html</code>
元素）的字体大小（<code>font-size</code>）的倍数。</p>
<p>在 CSS 中，<code>cursor</code>
属性用于定义鼠标指针位于元素上时的形状或图标。它对于改善用户体验非常重要，因为它为用户提供了视觉反馈，让他们知道可与页面上的不同元素进行哪些操作。</p>
<p><code>z-index</code>属性设置元素的堆叠顺序。拥有更高堆叠顺序的元素总是会处于堆叠顺序较低的元素的前面</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.box1</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">position</span>:absolute;</span><br><span class="line">    <span class="attribute">z-index</span>: <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.box2</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: green;</span><br><span class="line">    <span class="attribute">position</span>:absolute;</span><br><span class="line">    <span class="attribute">z-index</span>: <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>css3新特性</strong></p>
<p><strong>圆角</strong></p>
<p>使用 CSS3 <code>border-radius</code> 属性，你可以给任何元素制作
“圆角”</p>
<p><code>border-radius</code> 属性，可以使用以下规则：</p>
<ol type="1">
<li>四个值:
第一个值为左上角，第二个值为右上角，第三个值为右下角，第四个值为左下角</li>
<li>三个值: 第一个值为左上角,
第二个值为右上角和左下角，第三个值为右下角</li>
<li>两个值: 第一个值为左上角与右下角，第二个值为右上角与左下角</li>
<li>一个值： 四个圆角值相同</li>
</ol>
<p><strong>阴影</strong></p>
<p>box-shadow 向框添加一个或多个阴影。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">box-shadow</span>: h-shadow v-shadow blur color;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>h-shadow</td>
<td>必选，水平阴影的位置</td>
</tr>
<tr>
<td>v-shadow</td>
<td>必选，垂直阴影的位置</td>
</tr>
<tr>
<td>blur</td>
<td>可选，模糊距离</td>
</tr>
<tr>
<td>color</td>
<td>可选，阴影的颜色</td>
</tr>
</tbody>
</table>
<p><strong>动画</strong></p>
<p>使用<code>@keyframes</code>规则，你可以创建动画</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="keyword">@keyframes</span> name &#123;</span><br><span class="line">    <span class="selector-tag">from</span>|<span class="number">0%</span>&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">    percent&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="selector-tag">to</span>|<span class="number">100%</span>&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>name：动画名称，开发人员自己命名；</p>
<p>percent：为百分比值，可以添加多个百分比值；</p>
<p><strong>animation执行动画</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">animation</span>: name duration timing-function delay iteration-count direction;</span><br></pre></td></tr></table></figure>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 74%">
</colgroup>
<thead>
<tr>
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>设置动画的名称</td>
</tr>
<tr>
<td>duration</td>
<td>设置动画的持续时间</td>
</tr>
<tr>
<td>timing-function</td>
<td>设置动画效果的速率（如下）</td>
</tr>
<tr>
<td>delay</td>
<td>设置动画的开始时间（延时执行）</td>
</tr>
<tr>
<td>iteration-count</td>
<td>设置动画循环的次数，infinite为无限次数的循环</td>
</tr>
<tr>
<td>direction</td>
<td>设置动画播放的方向（如下）</td>
</tr>
<tr>
<td>animation-play-state</td>
<td>控制动画的播放状态：running代表播放，而paused代表停止播放</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>timing-function值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>ease</td>
<td>逐渐变慢（默认）</td>
</tr>
<tr>
<td>linear</td>
<td>匀速</td>
</tr>
<tr>
<td>ease-in</td>
<td>加速</td>
</tr>
<tr>
<td>ease-out</td>
<td>减速</td>
</tr>
<tr>
<td>ease-in-out</td>
<td>先加速后减速</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>direction值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>normal</td>
<td>默认值为normal表示向前播放</td>
</tr>
<tr>
<td>alternate</td>
<td>动画播放在第偶数次向前播放，第奇数次向反方向播放</td>
</tr>
</tbody>
</table>
<p><strong>切换背景颜色</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;animation&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.animation</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">animation</span>: anima <span class="number">5s</span> linear <span class="number">5s</span> infinite;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.animation</span><span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">    <span class="attribute">animation-play-state</span>: paused;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">@keyframes</span> anima &#123;</span><br><span class="line">    <span class="number">0%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: red;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">50%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: green;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">100%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: blueviolet;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>设置meta标签</strong></p>
<p>使用设备的宽度作为视图宽度并禁止初始的缩放。在<code>&lt;head&gt;</code>标签里加入这个meta标签。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&lt;meta name=&quot;viewport&quot; <span class="attribute">content</span>=&quot;<span class="attribute">width</span>=device-<span class="attribute">width</span>, initial-<span class="attribute">scale</span>=<span class="number">1</span>,maximum-<span class="attribute">scale</span>=<span class="number">1</span>, user-scalable=no&quot;&gt;</span><br></pre></td></tr></table></figure>
<p><strong>参数解释</strong></p>
<ol type="1">
<li><code>width = device-width</code> 宽度等于当前设备的宽度</li>
<li><code>initial-scale</code> 初始的缩放比例（默认设置为1.0）</li>
<li><code>maximum-scale</code>
允许用户缩放到的最大比例（默认设置为1.0）</li>
<li><code>user-scalable</code> 用户是否可以手动缩放（默认设置为no）</li>
</ol>
<h3 id="js">JS</h3>
<p><code>querySelector()</code></p>
<h3 id="es6">ES6</h3>
<p>常用命令行工具有两种</p>
<ol type="1">
<li><code>CMD</code> 命令行工具</li>
<li><code>PowerShell</code> 命令行工具</li>
</ol>
<p><strong>CMD命令行</strong></p>
<ol type="1">
<li>打开命令行窗口
<ol type="1">
<li>win：左下角开始，找到运行，点击，输入<code>cmd</code>，回车</li>
<li>win：<code>win+r</code> 快速打开命令行窗口</li>
</ol></li>
<li>选择盘符：盘符名加冒号<code>E:</code></li>
<li>查看盘符及目录下文件与文件夹：<code>win:dir</code></li>
<li>清空命令行信息：<code>win:cls</code></li>
<li>进入文件夹或目录：<code>cd  文件夹名称</code></li>
<li>返回到上一级目录：<code>cd ../</code></li>
<li>快速补全目录或文件夹名称：<code>tab</code></li>
<li>创建文件夹：<code>mkdir 文件夹名称</code></li>
<li>查看历史输入过的命令：上下按键</li>
</ol>
<p><strong>PowerShell</strong></p>
<ol type="1">
<li>打开方式
<ol type="1">
<li>在开始位置搜索<code>PowerShell</code>打开</li>
<li>在对应目录按住<code>shift</code>+右键，打开</li>
</ol></li>
<li>其他保持一直</li>
</ol>
<p>ECMAScript 和 JavaScript
的关系是，前者是后者的规格，后者是前者的一种实现，通常场合，这两个词是可以互换的。</p>
<p>ECMAScript 6（以下简称 ES6）是 JavaScript 语言的标准，在 2015 年 6
月发布。它的目标，是使得 JavaScript
语言可以用来编写复杂的大型应用程序，成为企业级开发语言。</p>
<h3 id="typescript">TypeScript</h3>
<p><a href="https://www.bilibili.com/video/BV1xL4y1B7DG/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">为什么你应当使用
TypeScript? TS 十分钟快速入门_哔哩哔哩_bilibili</a></p>
<h3 id="参考视频和网站推荐">参考视频和网站推荐</h3>
<p><a href="https://www.bilibili.com/video/BV1oz421q7BB/?spm_id_from=333.337.search-card.all.click">【HTML+CSS+JS+Vue】比大学课程还详细的Web前端教程，整整180集，学完即可兼职就业！附学习文档PDF，随时都能学_前端开发_WEB入门_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.freecodecamp.org/learn/">Learn to Code — For
Free — Coding Courses for Busy People</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>Cookie、Session、JWT</title>
    <url>/2025/10/25/%E5%AD%A6%E4%B9%A0/python-web/Cookie%E3%80%81Session%E3%80%81Token/</url>
    <content><![CDATA[<h2 id="cookie">Cookie</h2>
<p><strong>HTTP Cookie</strong>（通常简称为 <em>Cookie</em>）是由
<strong>服务器通过 HTTP 响应头 <code>Set-Cookie</code>
发送给用户代理（如浏览器）的一小段数据</strong>，用户代理随后会在后续的、满足条件的
HTTP 请求中，通过 <code>Cookie</code> 请求头自动将其发送回服务器。</p>
<ul>
<li><strong>核心目的</strong>：在无状态的 HTTP 协议之上，实现
<strong>状态管理（State Management）</strong> 和
<strong>客户端数据持久化</strong>。</li>
</ul>
<p>浏览器会：</p>
<ol type="1">
<li>保存它</li>
<li>在后续<strong>同域名</strong>的请求中，自动通过 <code>Cookie</code>
请求头发回给服务器</li>
</ol>
<blockquote>
<p>🔑 Cookie 的核心作用：<strong>在无状态的 HTTP
协议上实现“会话跟踪”</strong></p>
</blockquote>
<h3 id="前端构建">前端构建</h3>
<h4 id="使用-vite-快速创建-react-项目">使用 <strong>Vite</strong>
快速创建 React 项目</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#用最新版 Vite 脚手架，在名为 react-app 的文件夹中，创建一个基于 React 的项目。</span><br><span class="line">npm create vite@latest react-app -- --template react</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Vite（发音同
“veet”，法语“快”）是一个<strong>现代化的前端构建工具</strong>，由 Vue.js
作者尤雨溪（Evan You）开发，但<strong>不仅限于 Vue</strong>——它对
React、Svelte、Lit 等主流框架都有官方支持。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#安装项目依赖</span><br><span class="line">npm install</span><br><span class="line">#启动本地开发服务器</span><br><span class="line">npm run dev</span><br></pre></td></tr></table></figure>
<h4 id="项目结构">项目结构</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">react-app/</span><br><span class="line">├── public/           # 静态资源目录</span><br><span class="line">├── src/             # 源代码目录</span><br><span class="line">│   ├── components/  # 组件目录</span><br><span class="line">		├── Login.jsx     # 登录组件</span><br><span class="line">    	├── Login.css     # 登录样式</span><br><span class="line">    	├── Profile.jsx   # 用户信息组件</span><br><span class="line">    	└── Profile.css   # 用户信息样式</span><br><span class="line">│   ├── App.jsx      # 主应用组件</span><br><span class="line">│   ├── main.jsx     # 应用入口文件</span><br><span class="line">│   └── *.css        # 样式文件</span><br><span class="line">├── package.json     # 项目配置和依赖</span><br><span class="line">├── index.html</span><br><span class="line">└── vite.config.js   # 构建工具配置</span><br></pre></td></tr></table></figure>
<h4 id="启动链条">启动链条</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 浏览器加载 index.html</span><br><span class="line">   ↓</span><br><span class="line">2. 解析到 &lt;script src=&quot;/src/main.jsx&quot;&gt;</span><br><span class="line">   ↓  </span><br><span class="line">3. 加载并执行 main.jsx</span><br><span class="line">   ↓</span><br><span class="line">4. main.jsx 中的 createRoot(document.getElementById(&#x27;root&#x27;))</span><br><span class="line">   ↓</span><br><span class="line">5. 找到 &lt;div id=&quot;root&quot;&gt;&lt;/div&gt;</span><br><span class="line">   ↓</span><br><span class="line">6. 将 &lt;App /&gt; 组件渲染到 root 容器中</span><br><span class="line"></span><br><span class="line">index.html (HTML容器)</span><br><span class="line">    ↓</span><br><span class="line">main.jsx (入口文件) ← 你当前查看的文件</span><br><span class="line">    ↓</span><br><span class="line">App.jsx (主应用组件)</span><br><span class="line">    ↓</span><br><span class="line">Login.jsx, Profile.jsx (子组件)</span><br></pre></td></tr></table></figure>
<h4 id="index.html">index.html</h4>
<p>脚本标签指定入口</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;script type=&quot;module&quot; src=&quot;/src/main.jsx&quot;&gt;&lt;/</span><br><span class="line">script&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>src=“/src/main.jsx” 明确指定 了入口文件路径</li>
<li>type=“module” 表示这是ES6模块，支持import/export语法</li>
<li>浏览器加载这个脚本时，就会执行main.jsx中的代码</li>
</ul>
<p><code>main.jsx</code> 中的这行代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">createRoot(document.getElementById(&#x27;root&#x27;))</span><br></pre></td></tr></table></figure>
<p>与 <code>index.html</code> 中的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div id=&quot;root&quot;&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<p>通过 id=“root” 建立了连接！</p>
<h4 id="main.jsx">main.jsx</h4>
<p><code>main.jsx</code> 是整个React应用的 入口文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import &#123; StrictMode &#125; from &#x27;react&#x27;</span><br><span class="line">import &#123; createRoot &#125; from &#x27;react-dom/client&#x27;</span><br><span class="line">import &#x27;./index.css&#x27;</span><br><span class="line">import App from &#x27;./App.jsx&#x27;</span><br><span class="line"></span><br><span class="line">createRoot(document.getElementById(&#x27;root&#x27;)).render(</span><br><span class="line">  &lt;StrictMode&gt;</span><br><span class="line">    &lt;App /&gt;</span><br><span class="line">  &lt;/StrictMode&gt;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>创建React根节点 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">createRoot(document.getElementById(&#x27;root&#x27;))</span><br></pre></td></tr></table></figure> - 在HTML页面中找到id为’root’的DOM元素 -
创建一个React根渲染器，这是React应用挂载的地方</p>
<p>渲染应用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.render(</span><br><span class="line">  &lt;StrictMode&gt;</span><br><span class="line">    &lt;App /&gt;</span><br><span class="line">  &lt;/StrictMode&gt;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>将整个React应用渲染到根节点</li>
<li>StrictMode 包裹应用，提供开发时的额外检查和警告</li>
<li><App> 是你的主应用组件</App></li>
</ul>
<h4 id="app.jsx">App.jsx</h4>
<p>组件（Component） 是React的核心概念，可以理解为：</p>
<ul>
<li>可复用的UI构建块</li>
<li>独立的功能单元</li>
<li>像乐高积木一样可以组合的代码片段</li>
</ul>
<p>以App组件为例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function App() &#123;</span><br><span class="line">  // 1. 状态管理</span><br><span class="line">  const [isLoggedIn, setIsLoggedIn] = </span><br><span class="line">  useState(false)</span><br><span class="line"></span><br><span class="line">  // 2. 事件处理函数</span><br><span class="line">  const handleLoginSuccess = () =&gt; &#123;</span><br><span class="line">    setIsLoggedIn(true)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // 3. 渲染UI</span><br><span class="line">  return (</span><br><span class="line">    &lt;div className=&quot;app&quot;&gt;</span><br><span class="line">      &lt;header&gt;...&lt;/header&gt;</span><br><span class="line">      &lt;main&gt;</span><br><span class="line">        &#123;!isLoggedIn ? (</span><br><span class="line">          &lt;Login onLoginSuccess=</span><br><span class="line">          &#123;handleLoginSuccess&#125; /&gt;</span><br><span class="line">        ) : (</span><br><span class="line">          &lt;Profile isLoggedIn=&#123;isLoggedIn&#125; /</span><br><span class="line">          &gt;</span><br><span class="line">        )&#125;</span><br><span class="line">      &lt;/main&gt;</span><br><span class="line">      &lt;footer&gt;...&lt;/footer&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">export default App</span><br></pre></td></tr></table></figure>
<p>🔍 组件的核心特征</p>
<ol type="1">
<li>函数式组件</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function App() &#123;</span><br><span class="line">  // 组件逻辑</span><br><span class="line">  return (</span><br><span class="line">    // JSX - 描述UI结构</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>App是一个 JavaScript函数</li>
<li>函数名就是 组件名 （必须大写开头）</li>
<li>返回 JSX （类似HTML的语法）</li>
</ul>
<ol start="2" type="1">
<li>状态管理（State）</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const [isLoggedIn, setIsLoggedIn] = useState(false)</span><br></pre></td></tr></table></figure>
<p>isLoggedIn - 状态变量 - 存储 当前的登录状态 - 初始值是 false
（未登录） - 只能 读取 ，不能直接修改</p>
<p>setIsLoggedIn - 状态更新函数</p>
<ul>
<li>用来 更新 isLoggedIn 的值</li>
<li>调用时会 触发组件重新渲染</li>
<li>是修改状态的 唯一正确方式</li>
</ul>
<p>useState(false) - Hook调用</p>
<ul>
<li>false 是 初始值 ，表示默认未登录</li>
<li>返回一个 数组 ： [当前值, 更新函数]</li>
</ul>
<ol start="3" type="1">
<li>事件处理</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const handleLoginSuccess = () =&gt; &#123;</span><br><span class="line">  setIsLoggedIn(true)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>组件可以 响应用户交互</li>
<li>处理点击、输入等事件</li>
<li>更新状态，触发UI更新</li>
</ul>
<ol start="4" type="1">
<li>条件渲染</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;!isLoggedIn ? (</span><br><span class="line">  &lt;Login onLoginSuccess=</span><br><span class="line">  &#123;handleLoginSuccess&#125; /&gt;</span><br><span class="line">) : (</span><br><span class="line">  &lt;Profile isLoggedIn=&#123;isLoggedIn&#125; /&gt;</span><br><span class="line">)&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>根据 状态条件 显示不同内容</li>
<li>动态决定渲染哪些子组件</li>
</ul>
<ol start="5" type="1">
<li>组件组合</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;Login onLoginSuccess=&#123;handleLoginSuccess&#125; /</span><br><span class="line">&gt;</span><br><span class="line">&lt;Profile isLoggedIn=&#123;isLoggedIn&#125; /&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>大组件由 小组件组合 而成</li>
<li>通过 Props 传递数据给子组件</li>
</ul>
<p><strong>组件组合完整的数据流</strong></p>
<ol type="1">
<li>父组件（App.jsx）定义函数</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function App() &#123;</span><br><span class="line">  const [isLoggedIn, setIsLoggedIn] = </span><br><span class="line">  useState(false)</span><br><span class="line">  </span><br><span class="line">  // 定义回调函数</span><br><span class="line">  const handleLoginSuccess = () =&gt; &#123;</span><br><span class="line">    setIsLoggedIn(true)  // 更新父组件的状态</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  // 将函数传递给子组件</span><br><span class="line">  return &lt;Login onLoginSuccess=</span><br><span class="line">  &#123;handleLoginSuccess&#125; /&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>子组件（Login.jsx）接收并使用</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function Login(&#123; onLoginSuccess &#125;) &#123;  // 通过Props接收函数</span><br><span class="line">  const handleLogin = async () =&gt; &#123;</span><br><span class="line">    // ... 登录逻辑</span><br><span class="line">    </span><br><span class="line">    if (response.ok) &#123;</span><br><span class="line">      // 登录成功时调用父组件传来的函数</span><br><span class="line">      onLoginSuccess()  // 🔥 关键：通知父组件</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  return &lt;button onClick=&#123;handleLogin&#125;&gt;登录&lt;/button&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="login.jsx">Login.jsx</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function Login(&#123; onLoginSuccess &#125;) &#123;</span><br><span class="line">  // 1. 管理登录状态</span><br><span class="line">  const [isLoading, setIsLoading] = useState(false)</span><br><span class="line">  const [message, setMessage] = useState(&#x27;&#x27;)</span><br><span class="line"></span><br><span class="line">  // 2. 处理登录逻辑</span><br><span class="line">  const handleLogin = async () =&gt; &#123;</span><br><span class="line">    // 调用后端API</span><br><span class="line">    const response = await fetch(&#x27;http://localhost:8000/login&#x27;, &#123;</span><br><span class="line">      method: &#x27;POST&#x27;,</span><br><span class="line">      credentials: &#x27;include&#x27;, // Cookie认证</span><br><span class="line">    &#125;)</span><br><span class="line">    </span><br><span class="line">    // 成功后通知父组件</span><br><span class="line">    if (response.ok) &#123;</span><br><span class="line">      onLoginSuccess() // 调用父组件传来的回调函数</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // 3. 渲染登录界面</span><br><span class="line">  return (</span><br><span class="line">    &lt;div className=&quot;login-container&quot;&gt;</span><br><span class="line">      &lt;button onClick=&#123;handleLogin&#125;&gt;</span><br><span class="line">        &#123;isLoading ? &#x27;登录中...&#x27; : &#x27;登录&#x27;&#125;</span><br><span class="line">      &lt;/button&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="profile.jsx">Profile.jsx</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function Profile(&#123; isLoggedIn &#125;) &#123;</span><br><span class="line">  // 1. 管理用户数据状态</span><br><span class="line">  const [userInfo, setUserInfo] = useState(null)</span><br><span class="line">  const [isLoading, setIsLoading] = useState(false)</span><br><span class="line">  const [error, setError] = useState(&#x27;&#x27;)</span><br><span class="line"></span><br><span class="line">  // 2. 获取用户信息</span><br><span class="line">  const fetchProfile = async () =&gt; &#123;</span><br><span class="line">    const response = await fetch(&#x27;http://localhost:8000/profile&#x27;, &#123;</span><br><span class="line">      credentials: &#x27;include&#x27;, // 使用Cookie认证</span><br><span class="line">    &#125;)</span><br><span class="line">    const data = await response.json()</span><br><span class="line">    setUserInfo(data)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  // 3. 生命周期管理</span><br><span class="line">  useEffect(() =&gt; &#123;</span><br><span class="line">    fetchProfile() // 组件加载时自动获取数据</span><br><span class="line">  &#125;, [isLoggedIn])</span><br><span class="line"></span><br><span class="line">  // 4. 条件渲染</span><br><span class="line">  if (!isLoggedIn) &#123;</span><br><span class="line">    return &lt;p&gt;请先登录查看用户信息&lt;/p&gt;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  return (</span><br><span class="line">    &lt;div className=&quot;profile-container&quot;&gt;</span><br><span class="line">      &lt;h2&gt;用户信息&lt;/h2&gt;</span><br><span class="line">      &lt;div&gt;用户ID: &#123;userInfo?.user_id&#125;&lt;/div&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">  )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="后端构建">后端构建</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from fastapi import FastAPI, Response, Request</span><br><span class="line">from fastapi.middleware.cors import CORSMiddleware</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"># 添加 CORS 中间件</span><br><span class="line">app.add_middleware(</span><br><span class="line">    CORSMiddleware,</span><br><span class="line">    allow_origins=[&quot;*&quot;],  # 允许所有前端地址</span><br><span class="line">    allow_credentials=True, # 允许携带 Cookie</span><br><span class="line">    allow_methods=[&quot;*&quot;],# 允许所有 HTTP 方法</span><br><span class="line">    allow_headers=[&quot;*&quot;],# 允许所有 HTTP 头</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">@app.post(&quot;/login&quot;)</span><br><span class="line">def login(response: Response):</span><br><span class="line">    response.set_cookie(key=&quot;user_id&quot;, value=&quot;123&quot;, httponly=True)</span><br><span class="line">    return &#123;&quot;msg&quot;: &quot;Logged in&quot;&#125;</span><br><span class="line"></span><br><span class="line">@app.get(&quot;/profile&quot;)</span><br><span class="line">def profile(request: Request):</span><br><span class="line">    user_id = request.cookies.get(&quot;user_id&quot;)</span><br><span class="line">    return &#123;&quot;user_id&quot;: user_id&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    import uvicorn</span><br><span class="line">    print(&quot;Starting FastAPI backend server...&quot;)</span><br><span class="line">    uvicorn.run(</span><br><span class="line">        &quot;backend.app:app&quot;,</span><br><span class="line">        host=&quot;127.0.0.1&quot;,</span><br><span class="line">        reload=True,#支持热重载</span><br><span class="line">        port=8000,</span><br><span class="line">        log_level=&quot;info&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h4 id="corscross-origin-resource-sharing-跨域资源共享">CORS（Cross-Origin
Resource Sharing） = 跨域资源共享</h4>
<p>否则会出现</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Access to fetch at &#x27;http://localhost:8000/login&#x27; </span><br><span class="line">from origin &#x27;http://localhost:5173&#x27; </span><br><span class="line">has been blocked by CORS policy</span><br></pre></td></tr></table></figure>
<ul>
<li>从 http://localhost:5173 （前端）</li>
<li>访问 http://localhost:8000/login （后端）</li>
<li>被CORS策略阻止了</li>
</ul>
<h4 id="cookie机制">cookie机制</h4>
<ol type="1">
<li><strong><code>POST /login</code></strong>：登录成功，服务器“记住”用户</li>
<li><strong><code>GET /profile</code></strong>：获取用户资料，服务器“认出”用户</li>
</ol>
<p>关键就靠 <strong>Cookie</strong> 在浏览器和服务器之间传递身份。</p>
<p>🔧 1.
<code>response.set_cookie(key="user_id", value="123", httponly=True)</code></p>
<p>✅ 作用：</p>
<blockquote>
<p><strong>让服务器告诉浏览器：“请保存一个叫 <code>user_id</code> 的
Cookie，值是 <code>123</code>”</strong></p>
</blockquote>
<p>📡 实际发生了什么？</p>
<p>当 FastAPI 执行这行代码时，它会在 HTTP <strong>响应头（Response
Headers）</strong> 中添加一行：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Set-Cookie</span><span class="punctuation">: </span>user_id=123; HttpOnly</span><br></pre></td></tr></table></figure>
<p>然后整个响应看起来像这样： <figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="meta">HTTP/1.1</span> <span class="number">200</span> OK</span><br><span class="line"><span class="attribute">Content-Type</span><span class="punctuation">: </span>application/json</span><br><span class="line"><span class="attribute">Set-Cookie</span><span class="punctuation">: </span>user_id=123; HttpOnly</span><br><span class="line"></span><br><span class="line"><span class="language-json"><span class="punctuation">&#123;</span><span class="attr">&quot;msg&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Logged in&quot;</span><span class="punctuation">&#125;</span></span></span><br></pre></td></tr></table></figure></p>
<p>🌐 浏览器收到后会：</p>
<ol type="1">
<li>解析 <code>Set-Cookie</code> 头</li>
<li>在本地（内存或磁盘）保存这个 Cookie：
<ul>
<li>名字：<code>user_id</code></li>
<li>值：<code>123</code></li>
<li>属性：<code>HttpOnly</code>（JS 无法读取）</li>
</ul></li>
<li><strong>以后每次向该域名发请求，自动带上这个 Cookie</strong></li>
</ol>
<p>🔐 参数详解（你用的三个）：</p>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 22%">
<col style="width: 61%">
</colgroup>
<thead>
<tr>
<th>参数</th>
<th>作用</th>
<th>安全建议</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>key="user_id"</code></td>
<td>Cookie 的名字</td>
<td>用语义化名称，如 <code>session_id</code></td>
</tr>
<tr>
<td><code>value="123"</code></td>
<td>Cookie 的值</td>
<td><strong>不要直接存用户 ID！</strong> 应该存随机 session
ID（后面讲）</td>
</tr>
<tr>
<td><code>httponly=True</code></td>
<td>禁止 JavaScript 读取</td>
<td>✅ <strong>强烈建议开启</strong>，防 XSS 攻击</td>
</tr>
</tbody>
</table>
<p>📥 2. <code>user_id = request.cookies.get("user_id")</code></p>
<p>✅ 作用：</p>
<blockquote>
<p><strong>从当前请求中读取浏览器自动发送的 Cookie</strong></p>
</blockquote>
<p>📤 实际发生了什么？</p>
<p>当浏览器访问 <code>/profile</code> 时，它会自动在 HTTP
<strong>请求头（Request Headers）</strong> 中加上：</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Cookie</span><span class="punctuation">: </span>user_id=123</span><br></pre></td></tr></table></figure>
<p>FastAPI 的 <code>request.cookies</code>
是一个字典，<code>.get("user_id")</code> 就是读取这个值。</p>
<figure>
<img src="/2025/10/25/%E5%AD%A6%E4%B9%A0/python-web/Cookie%E3%80%81Session%E3%80%81Token/image-20251026164036642.png" alt="image-20251026164036642">
<figcaption aria-hidden="true">image-20251026164036642</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant Client as 客户端（React）</span><br><span class="line">    participant Server as 服务器（FastAPI）</span><br><span class="line"></span><br><span class="line">    Client-&gt;&gt;Server: 请求（Request）\n- URL: /login\n- Method: POST\n- Body: &#123;&#125;\n- Headers: ...</span><br><span class="line">    Server--&gt;&gt;Client: 响应（Response）\n- Status: 200\n- Set-Cookie: user_id=123\n- Body: &#123;&quot;msg&quot;: &quot;Logged in&quot;&#125;</span><br></pre></td></tr></table></figure>
<h2 id="session">Session</h2>
<p><strong>Session（会话）</strong> 是一种
<strong>服务器端状态管理机制</strong>，用于在无状态的 HTTP
协议之上，<strong>维护客户端与服务器之间的持续交互状态</strong>。</p>
<ul>
<li><strong>核心思想</strong>：为每个客户端分配一个唯一的会话标识符（Session
ID），服务器通过该 ID 查找对应的会话数据。</li>
<li><strong>存储位置</strong>：会话数据（如用户身份、权限、购物车等）<strong>存储在服务器端</strong>（内存、数据库、缓存等）。</li>
<li><strong>传输载体</strong>：Session ID 通常通过
<strong>Cookie</strong>（最常见）、URL 重写或 HTTP
头在客户端与服务器之间传递。</li>
</ul>
<p><strong>为什么需要session</strong></p>
<p>HTTP 协议是<strong>无状态</strong>的：</p>
<ul>
<li>每次请求都是独立的，服务器不知道你是谁</li>
<li>如果你登录后访问个人页面，服务器怎么知道你是谁？</li>
</ul>
<p><strong>解决方案</strong>：</p>
<ul>
<li><strong>Cookie</strong>：浏览器存数据（但不安全，不能存敏感信息）</li>
<li><strong>Session</strong>：服务器存数据，浏览器只存 ID（安全！）</li>
</ul>
<blockquote>
<p>💡 <strong>Session 是实现“登录状态”的标准方式</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant Browser</span><br><span class="line">    participant Server</span><br><span class="line"></span><br><span class="line">    Browser-&gt;&gt;Server: POST /login (用户名+密码)</span><br><span class="line">    Server-&gt;&gt;Server: 验证成功，创建 Session</span><br><span class="line">    Note right of Server: sessions[&quot;abc123&quot;] = &#123;&quot;user_id&quot;: &quot;123&quot;&#125;</span><br><span class="line">    Server--&gt;&gt;Browser: Set-Cookie: session_id=abc123;</span><br><span class="line"></span><br><span class="line">    Note over Browser: 浏览器保存 session_id</span><br><span class="line"></span><br><span class="line">    Browser-&gt;&gt;Server: GET /profile&lt;br/&gt;Cookie: session_id=abc123</span><br><span class="line">    Server-&gt;&gt;Server: 查 sessions[&quot;abc123&quot;] → user_id=123</span><br><span class="line">    Server--&gt;&gt;Browser: &#123;&quot;user_id&quot;: &quot;123&quot;&#125;</span><br></pre></td></tr></table></figure>
<h3 id="后端构建-1">后端构建</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 简化的内存session存储</span><br><span class="line">sessions = &#123;&#125;</span><br><span class="line"></span><br><span class="line">@app.post(&quot;/login&quot;)</span><br><span class="line">def login(response: Response):</span><br><span class="line">    # 创建新的session</span><br><span class="line">    session_id = str(uuid.uuid4())</span><br><span class="line">    session_data = &#123;&quot;user_id&quot;: &quot;123&quot;, &quot;username&quot;: &quot;admin&quot;&#125;</span><br><span class="line">    </span><br><span class="line">    # 将session数据存储到内存字典</span><br><span class="line">    sessions[session_id] = session_data</span><br><span class="line">    </span><br><span class="line">    # 设置session cookie</span><br><span class="line">    response.set_cookie(</span><br><span class="line">        key=&quot;session_id&quot;,</span><br><span class="line">        value=session_id,</span><br><span class="line">        httponly=True</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    logger.info(f&quot;用户登录成功，session_id: &#123;session_id&#125;&quot;)</span><br><span class="line">    return &#123;&quot;msg&quot;: &quot;Logged in&quot;, &quot;session_id&quot;: session_id&#125;</span><br><span class="line"></span><br><span class="line">@app.get(&quot;/profile&quot;)</span><br><span class="line">def profile(request: Request):</span><br><span class="line">    # 从cookie中获取session_id</span><br><span class="line">    session_id = request.cookies.get(&quot;session_id&quot;)</span><br><span class="line">    </span><br><span class="line">    if session_id is None:</span><br><span class="line">        logger.warning(&quot;未找到session cookie&quot;)</span><br><span class="line">        return &#123;&quot;error&quot;: &quot;请先登录&quot;, &quot;user_id&quot;: None&#125;</span><br><span class="line">    </span><br><span class="line">    # 从内存字典获取session数据</span><br><span class="line">    session_data = sessions.get(session_id)</span><br><span class="line">    </span><br><span class="line">    if session_data is None:</span><br><span class="line">        logger.error(f&quot;Session不存在: &#123;session_id&#125;&quot;)</span><br><span class="line">        return &#123;&quot;error&quot;: &quot;Session已过期&quot;, &quot;user_id&quot;: None&#125;</span><br><span class="line">    </span><br><span class="line">    logger.info(f&quot;获取session数据成功: &#123;session_data&#125;&quot;)</span><br><span class="line">    return &#123;&quot;user_id&quot;: session_data.get(&quot;user_id&quot;), &quot;username&quot;: session_data.get(&quot;username&quot;)&#125;</span><br></pre></td></tr></table></figure>
<p>重复部分进行省略</p>
<h2 id="jwt">JWT</h2>
<h3 id="jwt是什么">jwt是什么</h3>
<p><strong>JWT（JSON Web Token）</strong> 是一种 <strong>开放标准（RFC
7519）</strong>，用于在各方之间<strong>安全地传输声明（claims）</strong>。它是一种<strong>紧凑、自包含（self-contained）</strong>
的令牌格式，通常用于 <strong>身份认证（Authentication）</strong> 和
<strong>信息交换（Information Exchange）</strong>。</p>
<ul>
<li><strong>核心特点</strong>：
<ul>
<li><strong>无状态（Stateless）</strong>：服务器无需存储令牌</li>
<li><strong>自包含</strong>：令牌本身包含用户身份和元数据</li>
<li><strong>可验证</strong>：通过数字签名确保完整性与真实性</li>
</ul></li>
</ul>
<blockquote>
<p>✅ JWT 的本质是 <strong>“签名的用户声明”</strong>，而非会话 ID。</p>
</blockquote>
<h3 id="jwt-的结构">JWT 的结构</h3>
<p>JWT 由三部分组成，用 <code>.</code> 连接：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xxxxx.yyyyy.zzzzz</span><br></pre></td></tr></table></figure>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 20%">
<col style="width: 65%">
</colgroup>
<thead>
<tr>
<th>部分</th>
<th>说明</th>
<th>内容示例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Header</strong></td>
<td>令牌类型 + 签名算法</td>
<td><code>&#123;"alg": "HS256", "typ": "JWT"&#125;</code></td>
</tr>
<tr>
<td><strong>Payload</strong></td>
<td>声明（Claims）</td>
<td><code>&#123;"sub": "123", "name": "Alice", "exp": 1735689600&#125;</code></td>
</tr>
<tr>
<td><strong>Signature</strong></td>
<td>签名（防篡改）</td>
<td><code>HMACSHA256(base64UrlEncode(header)+'.'+base64UrlEncode(payload), secret)</code></td>
</tr>
</tbody>
</table>
<blockquote>
<p>🔐 <strong>只有签名部分能防止篡改</strong>，Header 和 Payload 只是
Base64Url 编码（<strong>可解码！勿存敏感信息</strong>）。</p>
</blockquote>
<h3 id="jwt-的-sub是什么">JWT 的 <code>sub</code>是什么</h3>
<p>在 JSON Web Token (JWT) 中，<code>sub</code> 是
<strong>Subject</strong>（主题）的缩写。</p>
<p>它是 JWT 规范（RFC 7519）中定义的一个<strong>注册声明（Registered
Claim）</strong>。简单来说，<code>sub</code>
用于回答这个问题：<strong>“这个 Token 是代表谁的？”</strong></p>
<p><strong>含义</strong>：它标识了该 JWT
所面向的主体（Principal）。在绝大多数应用场景中，这个主体就是<strong>用户</strong>。</p>
<p><strong>作用</strong>：当服务器收到一个 JWT 时，它通过读取
<code>sub</code> 字段来知道“当前请求是谁发起的”或“当前登录的是哪个用户
ID”。</p>
<p>在 JWT 的 Payload（载荷）部分，<code>sub</code> 通常是这样的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;iss&quot;: &quot;https://auth.example.com&quot;,</span><br><span class="line">  &quot;sub&quot;: &quot;1234567890&quot;,  &lt;-- 这里是 User ID</span><br><span class="line">  &quot;name&quot;: &quot;John Doe&quot;,</span><br><span class="line">  &quot;iat&quot;: 1516239022</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="为什么用-jwt相比较session优势在哪">为什么用
JWT，相比较session优势在哪</h3>
<ol type="1">
<li><strong>无状态（Stateless） → 天然支持水平扩展</strong></li>
</ol>
<ul>
<li><strong>Session</strong>：服务器必须存储会话数据（内存/Redis），所有实例需共享存储。</li>
<li><strong>JWT</strong>：服务器<strong>不存储任何状态</strong>，任意实例均可独立验证
Token。</li>
</ul>
<blockquote>
<p>🌐 <strong>适用场景</strong>：微服务架构、Serverless、高并发 API
网关<br>
💡 优势：<strong>去中心化、无共享存储依赖、部署简单</strong></p>
</blockquote>
<ol start="2" type="1">
<li><strong>跨域与跨平台原生支持</strong></li>
</ol>
<ul>
<li><strong>Session</strong>：依赖 Cookie，受同源策略限制，跨域需复杂
CORS 配置。</li>
<li><strong>JWT</strong>：通过
<code>Authorization: Bearer &lt;token&gt;</code> 传输，<strong>无 Cookie
依赖</strong>。</li>
</ul>
<blockquote>
<p>📱 <strong>适用场景</strong>： - 移动 App（iOS/Android） -
多前端（Web + 小程序 + 桌面端） - 第三方集成（如开放平台 API）</p>
</blockquote>
<blockquote>
<p>💡 优势：<strong>一套 API 服务所有客户端</strong></p>
</blockquote>
<ol start="3" type="1">
<li><strong>自包含（Self-contained） → 减少数据库查询</strong></li>
</ol>
<ul>
<li><strong>Session</strong>：每次请求需查存储（如
Redis）获取用户信息。</li>
<li><strong>JWT</strong>：Payload 可直接携带用户
ID、角色、权限等信息。</li>
</ul>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;sub&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user123&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;admin&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;permissions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;read&quot;</span><span class="punctuation">,</span> <span class="string">&quot;write&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;exp&quot;</span><span class="punctuation">:</span> <span class="number">1735689600</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>⚡ <strong>优势</strong>：<strong>减少
I/O，提升性能</strong>（尤其对权限频繁校验的系统）</p>
</blockquote>
<ol start="4" type="1">
<li><strong>标准化 &amp; 生态成熟</strong></li>
</ol>
<ul>
<li>JWT 是 <strong>IETF 标准（RFC
7519）</strong>，各语言均有高质量库。</li>
<li>与 <strong>OAuth 2.0、OpenID Connect</strong>
深度集成，适合现代身份认证体系。</li>
</ul>
<blockquote>
<p>🔌 <strong>优势</strong>：<strong>无缝对接 Auth0、Keycloak、Firebase
等身份提供商</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant Client</span><br><span class="line">    participant Server</span><br><span class="line"></span><br><span class="line">    Client-&gt;&gt;Server: 1. POST /login (用户名+密码)</span><br><span class="line">    Server-&gt;&gt;Server: 2. 验证凭证</span><br><span class="line">    Server--&gt;&gt;Client: 3. 返回 JWT: &#123;token: &quot;xxxx.yyyy.zzzz&quot;&#125;</span><br><span class="line"></span><br><span class="line">    Note over Client: 4. 客户端保存 Token（内存/LocalStorage）</span><br><span class="line"></span><br><span class="line">    Client-&gt;&gt;Server: 5. GET /profile&lt;br/&gt;Authorization: Bearer xxxx.yyyy.zzzz</span><br><span class="line">    Server-&gt;&gt;Server: 6. 验证签名 + 检查 exp</span><br><span class="line">    Server--&gt;&gt;Client: 7. 返回受保护资源</span><br></pre></td></tr></table></figure>
<h3 id="jwt的缺点">JWT的缺点</h3>
<ol type="1">
<li><strong>无法主动撤销</strong>：一旦签发，在过期前始终有效，难以实现“立即登出”或“账号禁用”。</li>
<li><strong>XSS 风险高</strong>：通常需存于前端（如内存或
localStorage），若存在 XSS 漏洞，Token 易被窃取。</li>
<li><strong>Payload 可解码</strong>：Header 和 Payload 仅 Base64
编码，<strong>不是加密</strong>，不能存敏感信息。</li>
<li><strong>体积较大</strong>：每次请求都要携带完整
Token，增加带宽开销（相比 Session ID）。</li>
</ol>
<h3 id="jwt三种签名算法">jwt三种签名算法</h3>
<h4 id="hs256-hmac-with-sha-256">1. HS256 (HMAC with SHA-256)</h4>
<p><strong>类型：对称加密 (Symmetric)</strong></p>
<p>这是最简单、最常见的算法，适合单体应用或内部受信任的服务之间通信。</p>
<p><strong>具体原理</strong></p>
<p>“共享密钥”模式。</p>
<p>签发 Token 的一方（认证服务器）和验证 Token
的一方（应用服务器）必须持有完全相同的密钥（Secret）。</p>
<ol type="1">
<li><strong>签名过程：</strong> 将 Header 和 Payload 进行 Base64Url
编码，用 <code>.</code> 连接。然后使用 <strong>Secret</strong>
对这个字符串进行 SHA-256 哈希计算。</li>
<li><strong>验证过程：</strong> 接收方收到 Token 后，用<strong>同一个
Secret</strong> 对 Header 和 Payload
再次进行同样的哈希计算。如果计算出的结果与 Token
中的签名一致，则验证通过。</li>
</ol>
<p><strong>核心公式</strong></p>
<p><span class="math display">$$Signature = HMACSHA256(base64Url(Header)
+ "." + base64Url(Payload), secret)$$</span></p>
<p><strong>举例说明</strong></p>
<p><strong>场景：</strong> 你是一个独自开发的网站站长。</p>
<p><strong>Secret：</strong>
<code>"my_super_secret_password"</code>（只有你的服务器知道）。</p>
<p><strong>流程：</strong></p>
<ol type="1">
<li>用户登录，你的代码生成 Payload <code>&#123;"user": "admin"&#125;</code>。</li>
<li>代码混合 Secret 进行哈希，生成签名 <code>abc123...</code>。</li>
<li>当用户下次带着 Token 请求时，你的代码再次用
<code>"my_super_secret_password"</code> 算一遍。如果算出来也是
<code>abc123...</code>，说明 Token 没被黑客改过。</li>
</ol>
<p><strong>优点：</strong> 速度极快，生成签名极其简单。</p>
<p><strong>缺点：</strong>
密钥一旦泄露，黑客既能验证也能<strong>伪造</strong>任意
Token。不适合多方系统（因为要把密钥分发给所有验证者，风险扩散）。</p>
<h4 id="rs256-rsa-signature-with-sha-256">2. RS256 (RSA Signature with
SHA-256)</h4>
<p><strong>类型：非对称加密 (Asymmetric)</strong></p>
<p>这是企业级应用、微服务架构和 OAuth2/OIDC（如 Auth0,
Okta）中的<strong>行业标准</strong>。</p>
<p><strong>具体原理</strong></p>
<p><strong>“私钥签名，公钥验证”模式</strong>。
使用一对密钥：<strong>私钥 (Private Key)</strong> 和 <strong>公钥
(Public Key)</strong>。</p>
<ul>
<li><strong>私钥：</strong> 只有认证服务器（Auth
Server）拥有，绝不公开。用于<strong>生成签名</strong>。</li>
<li><strong>公钥：</strong>
可以公开给任何服务（资源服务器、网关等）。用于<strong>验证签名</strong>。</li>
</ul>
<p><strong>核心原理</strong></p>
<p>RSA
利用了大数因数分解的数学难题。私钥加密的数据，只能用公钥解密（在签名场景下，这意味着只有公钥能验证是由私钥签名的）。</p>
<p><strong>举例说明</strong></p>
<ul>
<li><strong>场景：</strong> Google 颁发 Token 给第三方 App（如
Notion）。</li>
<li><strong>私钥：</strong> Google 只有一把，锁在 Google
的保险柜里。</li>
<li><strong>公钥：</strong> 公布在网上（JWKS 端点），Notion
可以随时下载。</li>
<li><strong>流程：</strong>
<ol type="1">
<li>Google 用<strong>私钥</strong>给 Payload <code>&#123;"sub": "123"&#125;</code>
盖了一个“数字章”（签名）。</li>
<li>Notion 收到 Token，去 Google 下载<strong>公钥</strong>。</li>
<li>Notion 用公钥验证这个“章”。如果验证通过，Notion 就能 100% 确定这个
Token 是 Google 签发的，而不是黑客伪造的。</li>
</ol></li>
<li><strong>优点：</strong> 安全性高。即使公钥泄露，黑客也只能验证
Token，无法伪造 Token。非常适合微服务（Auth 服务发
Token，其他几十个微服务只拿公钥验 Token）。</li>
<li><strong>缺点：</strong> 签名速度比 HS256
慢，生成的签名字符串较长。</li>
</ul>
<h4 id="es256-ecdsa-using-p-256-and-sha-256">3. ES256 (ECDSA using P-256
and SHA-256)</h4>
<p><strong>类型：非对称加密 (Asymmetric - Elliptic Curve)</strong></p>
<p>这是目前推荐的新兴标准。它在保持非对称加密安全性的同时，解决了 RSA
的性能和体积问题。</p>
<p><strong>具体原理</strong></p>
<p><strong>“椭圆曲线”模式</strong>。
同样使用公钥和私钥，但基于<strong>椭圆曲线密码学 (ECC)</strong>。 与 RSA
相比，ECC
可以在<strong>密钥长度短得多</strong>的情况下，提供同等甚至更高的安全性。</p>
<p><strong>核心原理</strong></p>
<p>它利用了椭圆曲线上的离散对数问题。简而言之，在一个特定的数学曲线上做点运算非常容易，但反向推导非常困难。</p>
<p><strong>举例说明</strong></p>
<p><strong>场景：</strong> 需要高并发、低带宽的物联网 (IoT) 设备或移动端
App。</p>
<p><strong>对比 RSA：</strong></p>
<ul>
<li>要达到 128 位安全级别，<strong>RS256</strong> 需要 3072
位的密钥（生成的 Token 会很长，占用流量）。</li>
<li><strong>ES256</strong> 只需要 256 位的密钥（Token
非常短，传输快）。</li>
</ul>
<p><strong>流程：</strong> 逻辑与 RS256
一样（私钥签、公钥验），但数学计算过程不同。</p>
<p><strong>优点：</strong></p>
<ol type="1">
<li><strong>Token 更短</strong>：节省带宽，HTTP Header 更小。</li>
<li><strong>生成速度快</strong>：在某些硬件上，签名速度比 RSA
更快。</li>
</ol>
<p><strong>缺点：</strong> 相对较新，极老旧的系统可能不支持；数学原理比
RSA 更复杂，排查问题稍难。</p>
<h3 id="后端构建-2">后端构建</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from pydantic import BaseModel</span><br><span class="line">from datetime import datetime, timedelta</span><br><span class="line">import jwt</span><br><span class="line"></span><br><span class="line"># JWT配置</span><br><span class="line">SECRET_KEY = &quot;your-secret-key&quot;</span><br><span class="line">ALGORITHM = &quot;HS256&quot;</span><br><span class="line"></span><br><span class="line"># 简单的用户数据</span><br><span class="line">users = &#123;</span><br><span class="line">    &quot;admin&quot;: &#123;&quot;user_id&quot;: &quot;123&quot;, &quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;admin123&quot;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def create_token(username: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;创建JWT token&quot;&quot;&quot;</span><br><span class="line">    # 设置token过期时间为24小时</span><br><span class="line">    expire = datetime.utcnow() + timedelta(hours=24)</span><br><span class="line">    # 构建JWT载荷，包含用户名和过期时间</span><br><span class="line">    payload = &#123;</span><br><span class="line">        &quot;sub&quot;: username,  # subject: 用户名</span><br><span class="line">        &quot;exp&quot;: expire     # expiration: 过期时间</span><br><span class="line">    &#125;</span><br><span class="line">    # 使用密钥和算法对载荷进行编码生成token</span><br><span class="line">    return jwt.encode(payload, SECRET_KEY, algorithm=ALGORITHM)</span><br><span class="line"></span><br><span class="line">def verify_token(token: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;验证JWT token&quot;&quot;&quot;</span><br><span class="line">    # 解码JWT token获取载荷信息</span><br><span class="line">    payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])</span><br><span class="line">    # 从载荷中提取用户名</span><br><span class="line">    username = payload.get(&quot;sub&quot;)</span><br><span class="line">    return username</span><br><span class="line"></span><br><span class="line">@app.post(&quot;/login&quot;)</span><br><span class="line">def login(response: Response):</span><br><span class="line">    &quot;&quot;&quot;用户登录&quot;&quot;&quot;</span><br><span class="line">    # 简化登录，直接使用默认用户</span><br><span class="line">    username = &quot;admin&quot;</span><br><span class="line">    # 从用户字典中获取用户信息</span><br><span class="line">    user = users.get(username)</span><br><span class="line">    </span><br><span class="line">    # 为用户创建JWT token</span><br><span class="line">    token = create_token(username)</span><br><span class="line">    # 将token设置为httponly cookie，与现有前端兼容</span><br><span class="line">    response.set_cookie(key=&quot;session_id&quot;, value=token, httponly=True)</span><br><span class="line">    # 返回token信息和登录成功消息</span><br><span class="line">    return &#123;&quot;access_token&quot;: token, &quot;token_type&quot;: &quot;bearer&quot;, &quot;msg&quot;: &quot;Logged in&quot;&#125;</span><br><span class="line"></span><br><span class="line">@app.get(&quot;/profile&quot;)</span><br><span class="line">def profile(request: Request):</span><br><span class="line">    &quot;&quot;&quot;获取用户信息&quot;&quot;&quot;</span><br><span class="line">    # 首先尝试从cookie获取token（兼容现有前端）</span><br><span class="line">    token = request.cookies.get(&quot;session_id&quot;)</span><br><span class="line">    </span><br><span class="line">    # 如果cookie中没有token，尝试从Authorization header获取</span><br><span class="line">    if not token:</span><br><span class="line">        auth_header = request.headers.get(&quot;authorization&quot;)</span><br><span class="line">        # 检查是否为Bearer token格式</span><br><span class="line">        if auth_header and auth_header.startswith(&quot;Bearer &quot;):</span><br><span class="line">            # 提取Bearer后面的token部分</span><br><span class="line">            token = auth_header.split(&quot; &quot;)[1]</span><br><span class="line">    </span><br><span class="line">    # 验证token并获取用户名</span><br><span class="line">    username = verify_token(token)</span><br><span class="line">    # 根据用户名获取用户信息</span><br><span class="line">    user = users.get(username)</span><br><span class="line">    # 返回用户ID和用户名</span><br><span class="line">    return &#123;&quot;user_id&quot;: user[&quot;user_id&quot;], &quot;username&quot;: user[&quot;username&quot;]&#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/10/25/%E5%AD%A6%E4%B9%A0/python-web/Cookie%E3%80%81Session%E3%80%81Token/image-20251026164113650.png" alt="image-20251026164113650">
<figcaption aria-hidden="true">image-20251026164113650</figcaption>
</figure>
<h2 id="参考资料">参考资料</h2>
<p><a href="https://www.bilibili.com/video/BV13t5PzDEzh/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">JWT身份认证算法、落地方案及优缺点_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1ob4y1Y7Ep/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Cookie、Session、Token究竟区别在哪？如何进行身份认证，保持用户登录状态？_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV13t5PzDEzh/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">JWT身份认证算法、落地方案及优缺点_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>python-web</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>REST | GraphQL | gRPC | tRPC</title>
    <url>/2025/10/25/%E5%AD%A6%E4%B9%A0/python-web/REST%20%20GraphQL%20%20gRPC%20%20tRPC/</url>
    <content><![CDATA[<h2 id="rest-api">REST api</h2>
<p><strong>REST（Representational State Transfer）</strong>
是一种软件架构风格，用于设计网络应用程序的 API。<br>
<strong>REST API</strong> 就是遵循 REST 原则的 Web 接口，通常基于 HTTP
协议。</p>
<blockquote>
<p>✅ 核心思想：把一切看作“资源”（Resource），通过标准 HTTP
方法对资源进行操作。</p>
</blockquote>
<h3 id="rest-的六大约束简化版理解">REST 的六大约束（简化版理解）</h3>
<table>
<colgroup>
<col style="width: 18%">
<col style="width: 47%">
<col style="width: 33%">
</colgroup>
<thead>
<tr>
<th>约束</th>
<th>含义</th>
<th>举例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>统一接口</strong></td>
<td>所有操作通过标准 HTTP 方法（GET/POST/PUT/DELETE）</td>
<td><code>/books</code> 表示“图书资源”</td>
</tr>
<tr>
<td><strong>无状态</strong></td>
<td>服务器不保存客户端状态，每次请求必须包含全部信息</td>
<td>用 Token 认证，而不是 Session</td>
</tr>
<tr>
<td><strong>可缓存</strong></td>
<td>响应应标明是否可缓存</td>
<td>GET 请求通常可缓存</td>
</tr>
<tr>
<td><strong>分层系统</strong></td>
<td>客户端无需知道是否直接连服务器（可经过代理、网关）</td>
<td>Nginx 反向代理 FastAPI</td>
</tr>
<tr>
<td><strong>按需代码（可选）</strong></td>
<td>可返回可执行代码（如 JS）</td>
<td>较少用</td>
</tr>
<tr>
<td><strong>资源标识</strong></td>
<td>每个资源有唯一 URI</td>
<td><code>/books/123</code> 唯一标识 ID 为 123 的书</td>
</tr>
</tbody>
</table>
<h3 id="常用-http-方法与语义">常用 HTTP 方法与语义</h3>
<table>
<colgroup>
<col style="width: 12%">
<col style="width: 24%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 44%">
</colgroup>
<thead>
<tr>
<th>方法</th>
<th>含义</th>
<th>幂等性</th>
<th>安全性</th>
<th>例子</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GET</code></td>
<td>获取资源</td>
<td>✅ 是</td>
<td>✅ 是</td>
<td>获取所有图书</td>
</tr>
<tr>
<td><code>POST</code></td>
<td>创建资源</td>
<td>❌ 否</td>
<td>❌ 否</td>
<td>新增一本图书</td>
</tr>
<tr>
<td><code>PUT</code></td>
<td><strong>完整</strong>更新资源</td>
<td>✅ 是</td>
<td>❌ 否</td>
<td>替换 ID 为 123 的图书全部信息</td>
</tr>
<tr>
<td><code>PATCH</code></td>
<td><strong>部分</strong>更新资源</td>
<td>❌ 否</td>
<td>❌ 否</td>
<td>只修改图书的标题</td>
</tr>
<tr>
<td><code>DELETE</code></td>
<td>删除资源</td>
<td>✅ 是</td>
<td>❌ 否</td>
<td>删除 ID 为 123 的图书</td>
</tr>
</tbody>
</table>
<blockquote>
<p>🔔 <strong>幂等性</strong>：多次执行结果相同（如 DELETE
/books/123，删一次和删十次效果一样）<br>
🔔 <strong>安全性</strong>：不改变服务器状态（GET 是安全的，POST
不是）</p>
</blockquote>
<h3 id="举个-fastapi-的完整例子">举个 FastAPI 的完整例子</h3>
<p>假设你正在开发<strong>图书管理系统</strong>，下面是典型 REST
API：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># main.py</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟数据库</span></span><br><span class="line">books_db = [</span><br><span class="line">    &#123;<span class="string">&quot;id&quot;</span>: <span class="number">1</span>, <span class="string">&quot;title&quot;</span>: <span class="string">&quot;Python 入门&quot;</span>, <span class="string">&quot;author&quot;</span>: <span class="string">&quot;张三&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;id&quot;</span>: <span class="number">2</span>, <span class="string">&quot;title&quot;</span>: <span class="string">&quot;FastAPI 实战&quot;</span>, <span class="string">&quot;author&quot;</span>: <span class="string">&quot;李四&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BookCreate</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    title: <span class="built_in">str</span></span><br><span class="line">    author: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Book</span>(<span class="title class_ inherited__">BookCreate</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">int</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/books&quot;</span>, response_model=<span class="type">List</span>[Book]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_books</span>():</span><br><span class="line">    <span class="keyword">return</span> books_db</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/books&quot;</span>, response_model=Book</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_book</span>(<span class="params">book: BookCreate</span>):</span><br><span class="line">    new_id = <span class="built_in">max</span>(b[<span class="string">&quot;id&quot;</span>] <span class="keyword">for</span> b <span class="keyword">in</span> books_db) + <span class="number">1</span> <span class="keyword">if</span> books_db <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">    new_book = &#123;<span class="string">&quot;id&quot;</span>: new_id, **book.<span class="built_in">dict</span>()&#125;</span><br><span class="line">    books_db.append(new_book)</span><br><span class="line">    <span class="keyword">return</span> new_book</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/books/&#123;book_id&#125;&quot;</span>, response_model=Book</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_book</span>(<span class="params">book_id: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">for</span> book <span class="keyword">in</span> books_db:</span><br><span class="line">        <span class="keyword">if</span> book[<span class="string">&quot;id&quot;</span>] == book_id:</span><br><span class="line">            <span class="keyword">return</span> book</span><br><span class="line">    <span class="keyword">raise</span> HTTPException(status_code=<span class="number">404</span>, detail=<span class="string">&quot;Book not found&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.put(<span class="params"><span class="string">&quot;/books/&#123;book_id&#125;&quot;</span>, response_model=Book</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update_book</span>(<span class="params">book_id: <span class="built_in">int</span>, book: BookCreate</span>):</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> books_db:</span><br><span class="line">        <span class="keyword">if</span> b[<span class="string">&quot;id&quot;</span>] == book_id:</span><br><span class="line">            b.update(book.<span class="built_in">dict</span>())</span><br><span class="line">            <span class="keyword">return</span> b</span><br><span class="line">    <span class="keyword">raise</span> HTTPException(status_code=<span class="number">404</span>, detail=<span class="string">&quot;Book not found&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.delete(<span class="params"><span class="string">&quot;/books/&#123;book_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete_book</span>(<span class="params">book_id: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">for</span> i, b <span class="keyword">in</span> <span class="built_in">enumerate</span>(books_db):</span><br><span class="line">        <span class="keyword">if</span> b[<span class="string">&quot;id&quot;</span>] == book_id:</span><br><span class="line">            books_db.pop(i)</span><br><span class="line">            <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;Deleted&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">raise</span> HTTPException(status_code=<span class="number">404</span>, detail=<span class="string">&quot;Book not found&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>启动后，你就可以通过：</p>
<ul>
<li><code>GET /books</code> → 获取所有书</li>
<li><code>POST /books</code> → 创建新书</li>
<li><code>GET /books/1</code> → 获取 ID=1 的书</li>
<li><code>PUT /books/1</code> → 完全替换 ID=1 的书</li>
<li><code>DELETE /books/1</code> → 删除 ID=1 的书</li>
</ul>
<h3 id="rest-api-常见响应格式json">REST API 常见响应格式（JSON）</h3>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 成功创建</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;LangChain 实战&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;王五&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 错误</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;detail&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Book not found&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>HTTP 状态码也很关键：</p>
<table>
<thead>
<tr>
<th>状态码</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>200</td>
<td>OK（GET 成功）</td>
</tr>
<tr>
<td>201</td>
<td>Created（POST 成功）</td>
</tr>
<tr>
<td>204</td>
<td>No Content（DELETE 成功，无返回体）</td>
</tr>
<tr>
<td>400</td>
<td>Bad Request（参数错误）</td>
</tr>
<tr>
<td>404</td>
<td>Not Found（资源不存在）</td>
</tr>
<tr>
<td>500</td>
<td>Internal Server Error</td>
</tr>
</tbody>
</table>
<h2 id="graphql">GraphQL</h2>
<p><strong>GraphQL</strong> 是由 Facebook 开发的一种 <strong>API
查询语言</strong> 和
<strong>运行时</strong>，用于客户端<strong>精确声明</strong>它需要什么数据，服务器则<strong>按需返回</strong>这些数据。</p>
<blockquote>
<p>✅ 核心理念：<strong>“客户端要什么，服务端就给什么”</strong>，避免
REST 中常见的“过载”或“多次请求”问题。</p>
</blockquote>
<h3 id="场景">场景</h3>
<p>你想获取用户 ID=1 的 <strong>姓名</strong> 和他最新的
<strong>两篇文章标题</strong></p>
<h3 id="rest-方式你熟悉的方式">🔹 REST 方式（你熟悉的方式）</h3>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line">GET /users/1          → 返回 &#123;id, name, email, avatar, ...&#125; （可能含不需要的 email/avatar）</span><br><span class="line">GET /posts?userId=1   → 返回所有文章（可能有 100 篇，但你只要 2 篇）</span><br></pre></td></tr></table></figure>
<p>→ <strong>2 次请求 + 数据冗余</strong></p>
<h3 id="graphql-方式">🔸 GraphQL 方式</h3>
<p>客户端发送一个 <strong>查询（Query）</strong>：</p>
<figure class="highlight graphql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">query</span> <span class="punctuation">&#123;</span></span><br><span class="line">  user<span class="punctuation">(</span><span class="symbol">id</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">)</span> <span class="punctuation">&#123;</span></span><br><span class="line">    name</span><br><span class="line">    posts<span class="punctuation">(</span><span class="symbol">first</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">)</span> <span class="punctuation">&#123;</span></span><br><span class="line">      title</span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>服务器返回：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;data&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;张三&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;posts&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Python 入门&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;FastAPI 实战&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>→ <strong>1 次请求 + 精确数据</strong></p>
<h3 id="schema类型系统">1. <strong>Schema（类型系统）</strong></h3>
<p>定义 API 的能力：有哪些类型？有哪些字段？</p>
<figure class="highlight graphql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> User <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="symbol">id</span><span class="punctuation">:</span> ID<span class="punctuation">!</span></span><br><span class="line">  <span class="symbol">name</span><span class="punctuation">:</span> String<span class="punctuation">!</span></span><br><span class="line">  posts<span class="punctuation">(</span><span class="symbol">first</span><span class="punctuation">:</span> Int<span class="punctuation">)</span><span class="punctuation">:</span> <span class="punctuation">[</span>Post<span class="punctuation">!</span><span class="punctuation">]</span><span class="punctuation">!</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Post <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="symbol">id</span><span class="punctuation">:</span> ID<span class="punctuation">!</span></span><br><span class="line">  <span class="symbol">title</span><span class="punctuation">:</span> String<span class="punctuation">!</span></span><br><span class="line">  <span class="symbol">content</span><span class="punctuation">:</span> String</span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> <span class="keyword">Query</span> <span class="punctuation">&#123;</span></span><br><span class="line">  user<span class="punctuation">(</span><span class="symbol">id</span><span class="punctuation">:</span> ID<span class="punctuation">!</span><span class="punctuation">)</span><span class="punctuation">:</span> User</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="query查询">2. <strong>Query（查询）</strong></h3>
<p>客户端请求数据（类似 REST 的 GET）</p>
<h3 id="mutation变更">3. <strong>Mutation（变更）</strong></h3>
<p>客户端修改数据（类似 REST 的 POST/PUT/DELETE）</p>
<figure class="highlight graphql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">mutation</span> <span class="punctuation">&#123;</span></span><br><span class="line">  createPost<span class="punctuation">(</span><span class="symbol">userId</span><span class="punctuation">:</span> <span class="number">1</span>, <span class="symbol">title</span><span class="punctuation">:</span> <span class="string">&quot;新文章&quot;</span>, <span class="symbol">content</span><span class="punctuation">:</span> <span class="string">&quot;内容&quot;</span><span class="punctuation">)</span> <span class="punctuation">&#123;</span></span><br><span class="line">    id</span><br><span class="line">    title</span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="rpc">RPC</h2>
<p><strong>RPC（Remote Procedure Call）</strong>
是一种<strong>让程序调用另一个地址空间（通常是远程服务器）上的函数/过程，就像调用本地函数一样</strong>的机制。</p>
<blockquote>
<p>✅ 核心思想：<strong>“像调用本地函数一样调用远程服务”</strong></p>
</blockquote>
<p>你不需要关心网络细节（HTTP、序列化等），框架会自动处理。</p>
<h3 id="为什么有了-http-还需要-rpc">为什么有了 HTTP 还需要 RPC？</h3>
<p>我们可以把 <strong>HTTP/REST</strong> 比作
<strong>“写信”</strong>，把 <strong>RPC</strong> 比作
<strong>“发电报”</strong>。</p>
<h4 id="a.-数据包的大小信封-vs.-代码">A. 数据包的大小（信封
vs. 代码）</h4>
<ul>
<li><strong>HTTP (REST+JSON):</strong> 为了让人看懂，JSON 极其啰嗦。
<ul>
<li>比如传递一个数字 <code>1000</code>，JSON 需要写成字段
<code>"balance": 1000</code>。为了传这一个数，你得带上
<code>"balance"</code>
这个单词，还有大括号、冒号。这就像写信时要写满客套话。</li>
</ul></li>
<li><strong>RPC (Protobuf/二进制):</strong>
机器不需要看懂单词，它只需要知道位置。
<ul>
<li>RPC 协议会约定：“第2个位置放余额”。传输时，直接发二进制的
<code>1000</code> 即可。<strong>数据体积可以缩小 50%~80%。</strong></li>
</ul></li>
</ul>
<h4 id="b.-解析速度阅读-vs.-直觉">B. 解析速度（阅读 vs. 直觉）</h4>
<ul>
<li><strong>HTTP:</strong> 服务器收到 JSON 后，CPU
需要一行行去“读”文本，把字符串转换成对象。这非常消耗 CPU 资源。</li>
<li><strong>RPC:</strong>
二进制数据到了服务器，几乎不需要转换，直接就能由计算机内存读取。<strong>解析速度比
JSON 快很多倍。</strong></li>
</ul>
<h4 id="c.-约束力口头约定-vs.-法律合同">C. 约束力（口头约定
vs. 法律合同）</h4>
<ul>
<li><strong>HTTP:</strong> REST API 的文档通常写在网页上（比如
Swagger）。如果后端改了字段名，前端没注意，上线可能就崩了。这属于“弱约束”。</li>
<li><strong>RPC:</strong> 强依赖
<strong>IDL（接口定义语言）</strong>。在代码编译阶段，如果客户端和服务端定义的参数类型对不上，代码直接<strong>报错，编译不过</strong>。这大大减少了上线后的低级错误。</li>
</ul>
<blockquote>
<p><strong>注意：</strong> 现代的 RPC（如 gRPC）其实底层往往也是基于
HTTP/2 协议传输的。所以准确地说，<strong>并不是“抛弃 HTTP 用
RPC”，而是“在 HTTP 之上通过 RPC 机制来优化传输效率”。</strong></p>
</blockquote>
<h3 id="rpc-主要用于什么场景">RPC 主要用于什么场景？</h3>
<p>RPC 并不是为了取代 REST，而是为了在特定领域“称王”。</p>
<h4 id="场景一微服务架构的内部通信这是绝对的主战场">场景一：微服务架构的内部通信（这是绝对的主战场）</h4>
<p>想象一个像淘宝或亚马逊这样的大型系统，一个“用户下单”的请求，在后台可能要触发
<strong>50 次</strong>
内部调用（查库存、算优惠、校验风控、写日志、通知物流…）。</p>
<ul>
<li><strong>如果全用 REST:</strong>
<ul>
<li>每次调用都要解析一遍 JSON，CPU 累死。</li>
<li>每次传输都带一堆冗余的 HTTP 头，网络堵死。</li>
<li>总延迟 = 50 次 HTTP 请求的累加，用户会感觉“卡顿”。</li>
</ul></li>
<li><strong>如果用 RPC:</strong>
<ul>
<li>二进制传输，极快。</li>
<li>内部带宽占用极低。</li>
<li><strong>结论：</strong> 对外（给浏览器/App）用
REST，对内（服务器之间）用 RPC。</li>
</ul></li>
</ul>
<h4 id="场景二高频交易与实时系统">场景二：高频交易与实时系统</h4>
<p>在股票交易、实时游戏同步等对<strong>延迟（Latency）</strong>极其敏感的场景。</p>
<ul>
<li>每一毫秒都决定盈亏。RPC 省去了繁琐的 HTTP
报文头解析，能把延迟压榨到极限。</li>
</ul>
<h4 id="场景三多语言混合开发-polyglot">场景三：多语言混合开发
(Polyglot)</h4>
<p>公司里，算法团队用 Python（搞 AI），后端团队用
Java（搞业务），数据团队用 Go。</p>
<ul>
<li>使用 gRPC（Google 的 RPC 框架），只需要定义一份 <code>.proto</code>
文件，就能自动生成 Python、Java、Go
的代码。这三个团队不需要互相通过文档扯皮，直接调用生成的代码即</li>
</ul>
<h3 id="rpc-调用流程">RPC 调用流程</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant Client as 客户端</span><br><span class="line">    participant Server as RPC 服务端</span><br><span class="line">    Client-&gt;&gt;Server: 调用 generate_summary(book_id=456)</span><br><span class="line">    Server-&gt;&gt;Server: 执行本地函数（可能调用 LLM/数据库）</span><br><span class="line">    Server--&gt;&gt;Client: 返回 &#123;summary: &quot;...&quot;, task_id: &quot;...&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>对比 REST 的资源操作：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant Client</span><br><span class="line">    participant REST_API</span><br><span class="line">    Client-&gt;&gt;REST_API: POST /summaries &#123;book_id: 456&#125;</span><br><span class="line">    REST_API-&gt;&gt;DB: 创建摘要任务</span><br><span class="line">    REST_API--&gt;&gt;Client: 201 Created &#123;location: &quot;/summaries/789&quot;&#125;</span><br></pre></td></tr></table></figure>
<h3 id="grpc跨语言的通用翻译官">gRPC：跨语言的通用翻译官</h3>
<p><strong>gRPC</strong> 是由 <strong>Google</strong> 开发并开源的高性能
RPC 框架。它是目前微服务架构中的事实标准。</p>
<h4 id="核心特点">核心特点：</h4>
<ol type="1">
<li><strong>基于 HTTP/2:</strong> 它利用 HTTP/2
的特性（如多路复用、头部压缩），传输效率极高。</li>
<li><strong>Protocol Buffers (Protobuf):</strong> 这是 gRPC
的灵魂。它不使用 JSON，而是使用 Google 发明的 <code>.proto</code>
文件来定义接口和数据结构。</li>
<li><strong>多语言支持 (Polyglot):</strong>这是它最大的杀手锏。</li>
</ol>
<h4 id="适用场景">适用场景：</h4>
<ul>
<li><strong>微服务架构：</strong> 几十个服务，有的用 Java 写，有的用
Python 写，需要互相通信。</li>
<li><strong>移动端对接：</strong> 手机 App
与服务器通信（省流量、省电）。</li>
</ul>
<hr>
<h3 id="trpctypescript-开发者的心灵感应">tRPC：TypeScript
开发者的“心灵感应”</h3>
<p><strong>tRPC</strong> (TypeScript RPC) 是近年来在前端圈（特别是
React/Next.js 社区）爆火的库。</p>
<p><strong>注意：</strong> tRPC <strong>只能</strong>用于
<strong>TypeScript</strong>。如果你的后端是 Java 或
Go，那就不能用它。</p>
<h4 id="核心特点-1">核心特点：</h4>
<ol type="1">
<li><strong>端到端类型安全 (End-to-End Type Safety):</strong>
这是它存在的全部意义。</li>
<li><strong>无代码生成 (No Code Gen):</strong> 不需要写
<code>.proto</code> 文件，也不需要运行脚本生成代码。</li>
<li><strong>基于标准 HTTP:</strong> 底层通常还是普通的 HTTP
请求，但写代码的感觉是 RPC。</li>
</ol>
<h4 id="适用场景-1">适用场景：</h4>
<ul>
<li><strong>全栈 TypeScript 项目：</strong> 比如使用 Next.js, Nuxt.js
等框架，前后端都在一个代码仓库（Monorepo）里。</li>
<li><strong>中小型快速开发：</strong>
一个团队同时负责前后端，追求极致的开发速度。</li>
</ul>
<h2 id="参考资料">参考资料</h2>
<p><a href="https://www.bilibili.com/video/BV1yL41167fD/?spm_id_from=333.788.recommend_more_video.3&amp;trackid=web_related_0.router-related-2206146-52fdn.1766213172731.35&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【API技术核心原理】REST
| GraphQL | gRPC | tRPC_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1Qv4y127B4/?spm_id_from=333.788.recommend_more_video.0&amp;trackid=web_related_0.router-related-2206146-8qdn5.1766219413613.457&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">RPC是什么？HTTP是什么？RPC和HTTP有什么区别？_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>python-web</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer学习</title>
    <url>/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>本文基于<a href="https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/blob/master/PaperNotes/Transformer%20论文精读.md#前言">AI-Guide-and-Demos-zh_CN/PaperNotes/Transformer
论文精读.md at master · Hoper-J/AI-Guide-and-Demos-zh_CN</a>与<a href="https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Transformer论文逐段精读【论文精读】_哔哩哔哩_bilibili</a>阅读学习</p>
<h3 id="transformer贡献">transformer贡献</h3>
<p>实际在这一阶段的工作中，<strong>注意力机制</strong>就已经在<strong>编码器-解码器架构</strong>中被广泛应用（与
RNN 一起使用），但 Transformer
彻底颠覆了默认采取的逻辑：<strong>直接放弃 RNN
的递归结构，只使用注意力机制来编码和解码序列信息</strong>。</p>
<p>Transformer 的主要贡献如下：</p>
<ul>
<li><p><strong>取消递归结构，实现并行计算</strong></p>
<p>通过采用<strong>自注意力机制（Self-Attention）</strong>，Transformer
可以同时处理多个输入序列，极大提高了计算的并行度和训练速度。</p></li>
<li><p><strong>引入位置编码（Positional Encoding）并结合 Attention
机制巧妙地捕捉位置信息</strong></p>
<p>在不依赖 RNN
结构的情况下，通过位置编码为序列中的每个元素嵌入位置信息，从而使模型能够感知输入的顺序。</p></li>
</ul>
<h3 id="transformer架构">transformer架构</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807135151542.png" alt="image-20250807135151542">
<figcaption aria-hidden="true">image-20250807135151542</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807145354145.png" alt="image-20250807145354145">
<figcaption aria-hidden="true">image-20250807145354145</figcaption>
</figure>
<p><a href="https://www.bilibili.com/video/BV1MY41137AK?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Transformer模型】曼妙动画轻松学，形象比喻贼好记_哔哩哔哩_bilibili</a></p>
<p>Transformer 模型基于<strong>编码器</strong>（左）-
<strong>解码器</strong>（右）架构</p>
<p><strong>Transformer编码器</strong>同样由 <strong>N
个完全相同的层</strong>（原始论文中
N=6）堆叠而成，每层只有两个子层，而解码器有三个。</p>
<ol type="1">
<li>多头自注意力（Multi-Head Self-Attention）
让输入序列中的每个位置都能关注序列内所有位置，直接建模全局依赖。</li>
<li>前馈全连接网络（Position-wise Feed-Forward Network）
对每个位置独立地做一次两层的全连接变换（通常先升维再降维）。</li>
</ol>
<p>同样，每个子层后都有</p>
<ul>
<li>残差连接（Residual Connection）</li>
<li>层归一化（Layer Normalization）</li>
</ul>
<p>另外，编码器在输入端还会用到</p>
<ul>
<li>位置编码（Positional
Encoding）——给模型提供序列位置信息，因为注意力本身不包含顺序信息。</li>
</ul>
<p><strong>Transformer解码器</strong>由多个相同的层堆叠而成，每一层包含三个核心子层：</p>
<ol type="1">
<li><strong>掩蔽多头自注意力机制</strong>（Masked Multi-Head Attention）
用于处理目标序列，通过掩码防止当前位置关注未来位置，确保生成过程的自回归特性。</li>
<li><strong>编码器-解码器注意力机制</strong>（Encoder-Decoder
Attention）
使解码器能够关注编码器输出的上下文信息，建立输入与输出序列之间的关联。</li>
<li><strong>前馈神经网络</strong>（Feed-Forward Neural Network）
对注意力机制的输出进行非线性变换，增强模型的表达能力。</li>
</ol>
<p>此外，每个子层后均包含<strong>残差连接</strong>（Residual
Connection）和<strong>层归一化</strong>（Layer
Normalization），以稳定训练过程并加速收敛。最终，解码器的输出通过线性层和Softmax层映射为词汇表上的概率分布。</p>
<h3 id="嵌入embeddings">嵌入（Embeddings）</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808103256344.png" alt="image-20250808103256344">
<figcaption aria-hidden="true">image-20250808103256344</figcaption>
</figure>
<p>在 Transformer 模型中，<strong>嵌入层</strong>（Embedding Layer）
是处理输入和输出数据的关键步骤，因为模型实际操作的是<strong>张量</strong>（tensor），而非<strong>字符串</strong>（string）。在将输入文本传递给模型之前，首先需要进行<strong>分词</strong>（tokenization），即将文本拆解为多个
<strong>token</strong>，随后这些 token 会被映射为对应的 <strong>token
ID</strong>，从而转换为模型可理解的数值形式。此时，数据的形状为
<code>(seq_len,)</code>，其中 <code>seq_len</code>
表示输入序列的长度。</p>
<p>目的：为了让模型捕捉到 token 背后复杂的语义（Semantic
meaning）关系，我们需要将离散的 token ID
映射到一个高维的连续向量空间（Continuous, dense）。这意味着每个 token ID
会被转换为一个<strong>嵌入向量</strong>（embedding
vector），期望通过这种方式让语义相近的词汇在向量空间中距离更近，使模型能更好地捕捉词汇之间的关系。</p>
<p>流程：（前面要进行分词，后面要进行位置编码）</p>
<p>初始化一个可学习的矩阵 <code>E ∈ ℝ^(|V| × d_model)</code>
<code>|V|</code> = 词表大小（比如 32 k、50 k），<code>d_model</code> =
512/768/1024…</p>
<p>把 token id 作为行号，直接取对应行： <code>x_i = E[token_id_i]</code>
得到 <code>[batch, seq_len, d_model]</code> 的浮点张量。</p>
<h3 id="位置编码positional-encoding">位置编码（Positional
Encoding）</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808103418150.png" alt="image-20250808103418150">
<figcaption aria-hidden="true">image-20250808103418150</figcaption>
</figure>
<p>Transformer
的自注意力机制（Self-Attention）是<strong>位置无关（position-agnostic）</strong>的。也就是说，如果不做任何处理，模型无法区分“我爱你”和“你爱我”这两个句子的差异，因为自注意力机制只关注
token 之间的相关性，而不考虑它们在序列中的顺序。</p>
<p>为了让模型感知到 token 的位置信息，Transformer
引入了<strong>位置编码</strong>。</p>
<p>在原始论文中，Transformer 使用的是固定位置编码（Positional
Encoding），其公式如下：</p>
<p><span class="math display">$$
\begin{aligned}
PE_{(pos, 2i)} &amp;=
\sin\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right), \\
PE_{(pos, 2i+1)} &amp;=
\cos\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right).
\end{aligned}
$$</span></p>
<p>其中：</p>
<ul>
<li><span class="math inline"><em>p</em><em>o</em><em>s</em></span>
表示位置索引（Position）。</li>
<li><span class="math inline"><em>i</em></span> 表示维度索引。</li>
<li><span class="math inline"><em>d</em><sub>model</sub></span>
是嵌入向量的维度。</li>
</ul>
<p>流程：输入的是一个<strong>整数索引</strong>（位置序号
0,1,2,…）。位置编码模块先把这些整数映射成与词向量同维度的向量（例如 512
维），再把结果加到词向量上。</p>
<h3 id="linear与softmax">linear与Softmax</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808111823715.png" alt="image-20250808111823715">
<figcaption aria-hidden="true">image-20250808111823715</figcaption>
</figure>
<p><a href="https://www.bilibili.com/video/BV1i5koBtEUU?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">从Linear到MLP
AI模型的数学本质【Transformer结构拆解】_哔哩哔哩_bilibili</a></p>
<p>在 Transformer 模型中，<strong>Softmax</strong>
函数不仅在计算<strong>注意力权重</strong>时用到，在预测阶段的输出处理环节也会用到，因为预测
token 的过程可以看成是<strong>多分类问题</strong>。</p>
<p><strong>Softmax</strong>
函数是一种常用的激活函数，能够将任意实数向量转换为<strong>概率分布</strong>，确保每个元素的取值范围在
[0, 1] 之间，并且所有元素的和为 1。其数学定义如下：</p>
<p><span class="math display">$$
\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}
$$</span></p>
<p>其中：</p>
<ul>
<li><span class="math inline"><em>x</em><sub><em>i</em></sub></span>
表示输入向量中的第 <span class="math inline"><em>i</em></span>
个元素。</li>
<li><span class="math inline">Softmax(<em>x</em><sub><em>i</em></sub>)</span>
表示输入 <span class="math inline"><em>x</em><sub><em>i</em></sub></span>
转换后的概率。</li>
</ul>
<p>我们可以把 Softmax
看作一种<strong>归一化的指数变换</strong>。相比于简单的比例归一化 <span class="math inline">$\frac{x_i}{\sum_j x_j}$</span>, <strong>Softmax
通过指数变换放大数值间的差异，让较大的值对应更高的概率，同时避免了负值和数值过小的问题，让模型聚焦于权重最高的位置</strong>，同时保留全局信息（低权重仍非零）。</p>
<h3 id="注意力机制">注意力机制</h3>
<p><a href="https://www.bilibili.com/video/BV1xS4y1k7tn?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Attention
注意力机制】激情告白transformer、Bert、GNN的精髓_哔哩哔哩_bilibili</a></p>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808135811744.png" alt="image-20250808135811744">
<figcaption aria-hidden="true">image-20250808135811744</figcaption>
</figure>
<h4 id="缩放点积注意力机制scaled-dot-product-attention"><strong>缩放点积注意力机制（Scaled
Dot-Product Attention）</strong></h4>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808140834132.png" alt="image-20250808140834132">
<figcaption aria-hidden="true">image-20250808140834132</figcaption>
</figure>
<p>Transformer 的核心是<strong>多头注意力机制（Multi-Head
Attention）</strong>，它能够捕捉输入序列中不同位置之间的依赖关系，并从多个角度对信息进行建模。模块将自底向上的进行讲解：在深入理解注意力机制前，首先需要理解论文使用的<strong>缩放点积注意力机制（Scaled
Dot-Product Attention）</strong>。</p>
<p>给定查询矩阵 <span class="math inline"><em>Q</em></span>、键矩阵
<span class="math inline"><em>K</em></span> 和值矩阵 <span class="math inline"><em>V</em></span>,
其注意力输出的数学表达式如下：</p>
<p><span class="math display">$$
\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{Q
K^\top}{\sqrt{d_k}}\right) V
$$</span></p>
<ul>
<li><strong><span class="math inline"><em>Q</em></span>（Query）</strong>:
用于查询的向量矩阵。</li>
<li><strong><span class="math inline"><em>K</em></span>（Key）</strong>:
表示键的向量矩阵，用于与查询匹配。</li>
<li><strong><span class="math inline"><em>V</em></span>（Value）</strong>:
值矩阵，注意力权重最终会作用在该矩阵上。</li>
<li><strong><span class="math inline"><em>d</em><sub><em>k</em></sub></span></strong>:
键或查询向量的维度。</li>
</ul>
<blockquote>
<p>理解 Q、K、V
的关键在于代码，它们实际上是通过线性变换从输入序列生成的</p>
</blockquote>
<p>公式解释</p>
<ol type="1">
<li><p><strong>点积计算（Dot Produce）</strong></p>
<p>将查询矩阵 <span class="math inline"><em>Q</em></span> 与键矩阵的转置
<span class="math inline"><em>K</em><sup>⊤</sup></span>
做点积，计算每个查询向量与所有键向量之间的相似度：</p>
<p><span class="math inline">$`\text{Scores} = Q K^\top`$</span></p>
<ul>
<li><strong>每一行</strong>表示某个查询与所有键之间的相似度（匹配分数）。</li>
<li><strong>每一列</strong>表示某个键与所有查询之间的相似度（匹配分数）。</li>
</ul></li>
<li><p><strong>缩放（Scaling）</strong></p>
<p>当 <span class="math inline"><em>d</em><sub><em>k</em></sub></span>
较大时，点积的数值可能会过大，导致 Softmax 过后的梯度变得极小，因此除以
<span class="math inline">$\sqrt{d_k}$</span>
缩放点积结果的数值范围：</p>
<p><span class="math inline">$`\text{Scaled Scores} = \frac{Q
K^\top}{\sqrt{d_k}}`$</span></p>
<p>缩放后（Scaled Dot-Product）也称为注意力分数（<strong>attention
scores</strong>）。</p></li>
<li><p><strong>Softmax 归一化</strong></p>
<p>使用 Softmax 函数将缩放后的分数转换为概率分布：</p>
<p><span class="math inline">$`\text{Attention Weights} =
\text{Softmax}\left(\frac{Q K^\top}{\sqrt{d_k}}\right)`$</span></p>
<blockquote>
<p><strong>注意</strong>：Softmax
是在每一行上进行的，这意味着每个查询的匹配分数将归一化为概率，总和为
1。</p>
</blockquote></li>
<li><p><strong>加权求和（Weighted Sum）</strong></p>
<p>最后，使用归一化后的注意力权重对值矩阵 <span class="math inline"><em>V</em></span>
进行加权求和，得到每个查询位置的最终输出： <span class="math inline">$`\text{Output} = \text{Attention Weights} \times
V`$</span></p></li>
</ol>
<h3 id="单头注意力机制single-head-attention">单头注意力机制（Single-Head
Attention）</h3>
<p>将输入序列（Inputs）通过线性变换生成<strong>查询矩阵</strong>（Query,
Q）、<strong>键矩阵</strong>（Key, K）和<strong>值矩阵</strong>（Value,
V），随后执行<strong>缩放点积注意力</strong>（Scaled Dot-Product
Attention）。</p>
<h4 id="掩码注意力机制masked-attention">掩码注意力机制（Masked
Attention）</h4>
<p>如果使用 mask 掩盖将要预测的词汇，那么 Attention 就延伸为 Masked
Attention</p>
<p>在这段代码中，<code>mask</code>
矩阵用于指定哪些位置应该被遮蔽（即填充为
-∞），从而保证这些位置的注意力权重在 softmax
输出中接近于零。注意，掩码机制并不是直接在截断输入序列，也不是在算分数的时候就排除不应该看到的位置，因为看到也没有关系，不会影响与其他位置的分数，所以在传入
Softmax（计算注意力权重）之前排除就可以了。</p>
<p>另外，根据输入数据的来源，还可以将注意力分为<strong>自注意力（Self-Attention）和交叉注意力（Cross-Attention)</strong>。</p>
<h4 id="自注意力机制self-attention">自注意力机制（Self-attention）</h4>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808142109091.png" alt="image-20250808142109091">
<figcaption aria-hidden="true">image-20250808142109091</figcaption>
</figure>
<p>Transformer
模型架构使用到了三个看起来不同的注意力机制，我们继续忽视共有的
Multi-Head。观察输入，线条一分为三传入 Attention
模块，这意味着查询（query）、键（key）和值（value）实际上都来自<strong>同一输入序列
<span class="math inline"><strong>X</strong></span></strong>，数学表达如下：</p>
<p><span class="math display"><em>Q</em> = <em>X</em><em>W</em><sup><em>Q</em></sup>,  <em>K</em> = <em>X</em><em>W</em><sup><em>K</em></sup>,  <em>V</em> = <em>X</em><em>W</em><sup><em>V</em></sup></span></p>
<ul>
<li><strong><span class="math inline"><em>W</em><sup><em>Q</em></sup>, <em>W</em><sup><em>K</em></sup>, <em>W</em><sup><em>V</em></sup></span></strong>：可训练的线性变换权重，实际上就是简单的线性层</li>
</ul>
<h4 id="交叉注意力机制cross-attention">交叉注意力机制（Cross-Attention）</h4>
<p>在 Transformer 解码器中，除了自注意力外，还使用了
<strong>交叉注意力（Cross-Attention）</strong>。</p>
<p>如下图所示，解码器（右）在自底向上的处理过程中，先执行自注意力机制，然后通过交叉注意力从编码器的输出中获取上下文信息。</p>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808142428374.png" alt="image-20250808142428374">
<figcaption aria-hidden="true">image-20250808142428374</figcaption>
</figure>
<p>数学表达如下：</p>
<p><span class="math display"><em>Q</em> = <em>X</em><sub>decoder</sub><em>W</em><sup><em>Q</em></sup>,  <em>K</em> = <em>X</em><sub>encoder</sub><em>W</em><sup><em>K</em></sup>,  <em>V</em> = <em>X</em><sub>encoder</sub><em>W</em><sup><em>V</em></sup></span></p>
<h4 id="对比学习">对比学习</h4>
<p><strong>Masked Attention</strong>、<strong>Self-Attention</strong> 和
<strong>Cross-Attention</strong>
的本质是一致的，这一点从代码调用可以看出来，三者的区别在于未来掩码的使用和输入数据的来源：</p>
<ul>
<li><p><strong>Masked
Attention</strong>：用于解码过程，通过掩码屏蔽未来的时间步，确保模型只能基于已生成的部分进行预测，论文中解码器部分的第一个
Attention 使用的是 Masked Self-Attention。</p></li>
<li><p><strong>Self-Attention</strong>：查询、键和值矩阵来自同一输入序列，模型通过自注意力机制学习输入序列的全局依赖关系。</p></li>
<li><p><strong>Cross-Attention</strong>：查询矩阵来自解码器的输入，而键和值矩阵来自编码器的输出，解码器的第二个
Attention 模块就是
Cross-Attention，用于从编码器输出中获取相关的上下文信息。</p>
<ul>
<li><p>以<strong>机器翻译</strong>中的<strong>中译英任务</strong>为例：对于中文句子“<strong>中国的首都是北京</strong>”，假设模型已经生成了部分译文“The
capital of China is”，此时需要预测下一个单词。</p>
<p>在这一阶段，<strong>解码器中的交叉注意力机制</strong>会使用<strong>当前已生成的译文“The
capital of China
is”的编码表示作为查询</strong>，并将<strong>编码器对输入句子“中国的首都是北京”编码表示</strong>作为<strong>键</strong>和<strong>值</strong>，通过计算<strong>查询与键之间的匹配程度</strong>，生成相应的注意力权重，以此从值中提取上下文信息，基于这些信息生成下一个可能的单词（token），比如：“Beijing”。</p></li>
</ul></li>
</ul>
<h3 id="多头注意力机制multi-head-attention">多头注意力机制（Multi-Head
Attention）</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808143810965.png" alt="image-20250808143810965">
<figcaption aria-hidden="true">image-20250808143810965</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808143822630.png" alt="image-20250808143822630">
<figcaption aria-hidden="true">image-20250808143822630</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808143845681.png" alt="image-20250808143845681">
<figcaption aria-hidden="true">image-20250808143845681</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808145725202.png" alt="image-20250808145725202">
<figcaption aria-hidden="true">image-20250808145725202</figcaption>
</figure>
<p>多头注意力机制就是存在多个不同的权重矩阵，形成多个矩阵Z，再把它们
<strong>按最后一维（hidden）拼接（concat）→ 做一次线性变换</strong>
得到最终输出。</p>
<blockquote>
<p>线性bian’h把拼接后的多头结果 <code>Z_concat</code>（形状
batch×seq×d_model）重新<strong>线性映射</strong>回与输入相同的维度，同时让网络可以<strong>学习如何融合不同头的信息</strong>。</p>
</blockquote>
<p><a href="https://www.bilibili.com/video/BV1MY41137AK?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Transformer模型】曼妙动画轻松学，形象比喻贼好记_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1HsTyz8ECC?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Transformer原理及架构：多头自注意力机制_哔哩哔哩_bilibili</a></p>
<h3 id="残差连接residual-connection和层归一化layer-normalization-layernorm">残差连接（Residual
Connection）和层归一化（Layer Normalization, LayerNorm）</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808150313758.png" alt="image-20250808150313758">
<figcaption aria-hidden="true">image-20250808150313758</figcaption>
</figure>
<p>在 Transformer 架构中，<strong>残差连接</strong>（Residual
Connection）与<strong>层归一化</strong>（LayerNorm）结合使用，统称为
<strong>Add &amp; Norm</strong> 操作。</p>
<h4 id="add残差连接residual-connection">Add（残差连接，Residual
Connection）</h4>
<p>残差连接是一种跳跃连接（Skip
Connection），它将层的输入直接加到输出上（观察架构图中的箭头），对应的公式如下：</p>
<p><span class="math display">Output = SubLayer(<em>x</em>) + <em>x</em></span></p>
<p>这种连接方式有效缓解了<strong>深层神经网络的梯度消失</strong>问题。</p>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808151004667.png" alt="image-20250808151004667">
<figcaption aria-hidden="true">image-20250808151004667</figcaption>
</figure>
<p>在transform中，就是输入的矩阵x加上经过注意力机制计算出来的z矩阵</p>
<h4 id="norm层归一化layer-normalization">Norm（层归一化，Layer
Normalization）</h4>
<p><strong>层归一化</strong>（LayerNorm）是一种归一化技术，用于提升训练的稳定性和模型的泛化能力。</p>
<p>假设输入向量为 <span class="math inline"><em>x</em> = (<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>d</em></sub>)</span>,
LayerNorm 的计算步骤如下：</p>
<ol type="1">
<li><p><strong>计算均值和方差</strong>： 对输入的所有特征求均值 <span class="math inline"><em>μ</em></span> 和方差 <span class="math inline"><em>σ</em><sup>2</sup></span>：</p>
<p><span class="math inline">$`
\mu = \frac{1}{d} \sum_{j=1}^{d} x_j, \quad
\sigma^2 = \frac{1}{d} \sum_{j=1}^{d} (x_j - \mu)^2
`$</span></p></li>
<li><p><strong>归一化公式</strong>： 将输入特征 <span class="math inline"><em>x̂</em><sub><em>i</em></sub></span>
进行归一化：</p>
<p><span class="math inline">$`
\hat{x}_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}
`$</span></p>
<p>其中, <span class="math inline"><em>ϵ</em></span>
是一个很小的常数（比如 1e-9），用于防止除以零的情况。</p></li>
<li><p><strong>引入可学习参数</strong>： 归一化后的输出乘以 <span class="math inline"><em>γ</em></span> 并加上 <span class="math inline"><em>β</em></span>, 公式如下：</p>
<p><span class="math inline">$`
\text{Output} = \gamma \hat{x} + \beta
`$</span></p>
<p>其中 <span class="math inline"><em>γ</em></span> 和 <span class="math inline"><em>β</em></span>
是可学习的参数，用于进一步调整归一化后的输出。</p></li>
</ol>
<h3 id="前馈神经网络-position-wise-feed-forward-networksffn">前馈神经网络
Position-wise Feed-Forward Networks（FFN）</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20251220191959727.png" alt="image-20251220191959727">
<figcaption aria-hidden="true">image-20251220191959727</figcaption>
</figure>
<p>在 Transformer 中，前馈网络层（Feed-Forward
Network，FFN）的作用可以概括为一句话：
<strong>“对每个位置的向量进行非线性变换，增加模型的表达能力。”</strong></p>
<p>在编码器-解码器架构中，另一个看起来“大一点”的模块就是 Feed
Forward，它在每个位置 <span class="math inline"><em>i</em></span>
上的计算可以表示为：</p>
<p><span class="math display">FFN(<em>x</em><sub><em>i</em></sub>) = max(0, <em>x</em><sub><em>i</em></sub><em>W</em><sub>1</sub> + <em>b</em><sub>1</sub>)<em>W</em><sub>2</sub> + <em>b</em><sub>2</sub></span></p>
<p>其中：</p>
<ul>
<li><span class="math inline"><em>x</em><sub><em>i</em></sub> ∈ ℝ<sup><em>d</em><sub>model</sub></sup></span>
表示第 <span class="math inline"><em>i</em></span>
个位置的输入向量。</li>
<li><span class="math inline"><em>W</em><sub>1</sub> ∈ ℝ<sup><em>d</em><sub>model</sub> × <em>d</em><sub>ff</sub></sup></span>
和 <span class="math inline"><em>W</em><sub>2</sub> ∈ ℝ<sup><em>d</em><sub>ff</sub> × <em>d</em><sub>model</sub></sup></span>
是两个线性变换的权重矩阵。</li>
<li><span class="math inline"><em>b</em><sub>1</sub> ∈ ℝ<sup><em>d</em><sub>ff</sub></sup></span>
和 <span class="math inline"><em>b</em><sub>2</sub> ∈ ℝ<sup><em>d</em><sub>model</sub></sup></span>
是对应的偏置向量。</li>
<li><span class="math inline">max(0, ⋅)</span> 是 <strong>ReLU
激活函数</strong>，用于引入非线性。</li>
</ul>
<h3 id="大模型发展树">大模型发展树</h3>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807171237889.png" alt="image-20250807171237889">
<figcaption aria-hidden="true">image-20250807171237889</figcaption>
</figure>
<figure>
<img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807173520481.png" alt="image-20250807173520481">
<figcaption aria-hidden="true">image-20250807173520481</figcaption>
</figure>
<h3 id="预训练语言模型">预训练语言模型</h3>
<p>预训练语言模型（PLM）是一种通过大量文本数据进行无监督或弱监督训练的语言模型，目的是学习语言的通用表示（即语言的模式、语法、语义等）。这些模型通常在大规模文本数据上进行预训练，然后可以被微调（Fine
- tuning）以适应各种下游任务，如文本分类、问答、命名实体识别等。</p>
<p>预训练语言模型的核心思想是利用大量的无标注文本数据来学习语言的通用特征，从而为各种自然语言处理任务提供强大的语言理解能力。预训练模型可以显著提高任务的性能，减少对标注数据的依赖，并且能够快速适应新的任务。</p>
<h4 id="bert模型encoder-only-plm">BERT模型（Encoder-only PLM）</h4>
<p>针对 Encoder、Decoder 的特点，引入 ELMo
的预训练思路，开始出现不同的、对 Transformer
进行优化的思路。例如，<strong>Google 仅选择了 Encoder
层</strong>，通过将 Encoder
层进行堆叠，再提出不同的预训练任务-掩码语言模型（Masked Language
Model，MLM），打造了一统自然语言理解（Natural Language
Understanding，NLU）任务的代表模型——<strong>BERT</strong>。</p>
<p>BERT，全名为 Bidirectional Encoder Representations from
Transformers，是由 Google 团队在
2018年发布的预训练语言模型。该模型发布于论文《BERT: Pre-training of Deep
Bidirectional Transformers for Language Understanding》，实现了包括
GLUE、MultiNLI 等七个自然语言处理评测任务的最优性能（State Of The
Art，SOTA），堪称里程碑式的成果。</p>
<h4 id="t5encoder-decoder-plm">T5（Encoder-Decoder PLM）</h4>
<p>BERT 也存在一些问题，例如 MLM
任务和下游任务微调的不一致性，以及无法处理超过模型训练长度的输入等问题。为了解决这些问题，研究者们提出了
<strong>Encoder-Decoder 模型</strong>，通过引入 Decoder
部分来解决这些问题，同时也为 NLP 领域带来了新的思路和方法。</p>
<p><strong>T5（Text-To-Text Transfer Transformer）是由 Google
提出的一种预训练语言模型</strong>，通过将所有 NLP
任务统一表示为文本到文本的转换问题，大大简化了模型设计和任务处理。T5
基于 Transformer
架构，包含编码器和解码器两个部分，使用自注意力机制和多头注意力捕捉全局依赖关系，利用相对位置编码处理长序列中的位置信息，并在每层中包含前馈神经网络进一步处理特征。</p>
<h4 id="llama模型decoder-only-plm">LLama模型（Decoder-Only PLM）</h4>
<p>LLaMA模型是由Meta（前Facebook）开发的一系列大型预训练语言模型。从LLaMA-1到LLaMA-3，LLaMA系列模型展示了大规模预训练语言模型的演进及其在实际应用中的显著潜力。</p>
<h4 id="gpt模型decoder-only-plm">GPT模型（Decoder-Only PLM）</h4>
<p>GPT，即 Generative Pre-Training Language Model，是由 OpenAI 团队于
2018年发布的预训练语言模型。虽然学界普遍认可 BERT
作为预训练语言模型时代的代表，但首先明确提出<strong>预训练-微调思想的模型</strong>其实是
GPT。</p>
<p>GPT
提出了通用预训练的概念，也就是在海量无监督语料上预训练，进而在每个特定任务上进行微调，从而实现这些任务的巨大收益。虽然在发布之初，由于性能略输于不久后发布的
BERT，没能取得轰动性成果，也没能让 GPT 所使用的 <strong>Decoder-Only
架构</strong>成为学界研究的主流，但 OpenAI
团队坚定地选择了不断扩大预训练数据、增加模型参数，在 GPT
架构上不断优化，最终在 2020年发布的 GPT-3 成就了 LLM 时代的基础，并以
GPT-3 为基座模型的 ChatGPT 成功打开新时代的大门，成为 LLM
时代的最强竞争者也是目前的最大赢家。</p>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://transformers.run/">Hello! ·
Transformers快速入门</a></p>
<p><a href="https://github.com/jsksxs360/How-to-use-Transformers">jsksxs360/How-to-use-Transformers:
Transformers 库快速入门教程</a></p>
<p><a href="https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN">Hoper-J/AI-Guide-and-Demos-zh_CN:
这是一份入门AI/LLM大模型的逐步指南，包含教程和演示代码，带你从API走进本地大模型部署和微调，代码文件会提供Kaggle或Colab在线版本，即便没有显卡也可以进行学习。项目中还开设了一个小型的代码游乐场🎡，你可以尝试在里面实验一些有意思的AI脚本。同时，包含李宏毅
(HUNG-YI LEE）2024生成式人工智能导论课程的完整中文镜像作业。</a></p>
<p><a href="https://datawhalechina.github.io/happy-llm/#/">Happy-LLM</a></p>
<p><a href="https://gengzhige.ai/video.html">梗直哥</a></p>
<p><a href="https://www.bilibili.com/video/BV1RBdTYxENw/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">90%人不知道的LLM黑科技：拆解Transformer如何吃透全网知识！_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1k6yWBEEmH/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Transformer如何成为AI模型的地基_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大模型算法</category>
        <category>transformer</category>
      </categories>
      <tags>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习知识查漏补缺</title>
    <url>/2025/12/20/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h2 id="梯度消失和梯度爆炸">梯度消失和梯度爆炸</h2>
<p>梯度消失（Gradient Vanishing）和梯度爆炸（Gradient
Exploding）是深度学习（尤其是深度神经网络和循环神经网络
RNN）训练中常见的两个核心问题。它们都会导致模型<strong>无法有效训练</strong>，但表现形式相反。</p>
<p>简单来说，这两个问题都源于<strong>反向传播（Backpropagation）*<em>中的*</em>连乘效应</strong>。</p>
<hr>
<h3 id="核心机制为什么会出现这个问题">1.
核心机制：为什么会出现这个问题？</h3>
<p>在神经网络中，我们通过<strong>反向传播算法</strong>来更新参数。为了计算靠近输入层（浅层）参数的梯度，需要利用<strong>链式法则（Chain
Rule）</strong>，将后面所有层的梯度乘起来。</p>
<p><span class="math display">$$\frac{\partial Loss}{\partial w_1} =
\frac{\partial Loss}{\partial y} \cdot \frac{\partial y}{\partial h_n}
\cdot ... \cdot \frac{\partial h_2}{\partial h_1} \cdot \frac{\partial
h_1}{\partial w_1}$$</span></p>
<p>想象你有一长串数字相乘：</p>
<ul>
<li><strong>梯度消失</strong>：如果这些数字大部分都<strong>小于
1</strong>（例如 0.9），乘得越多，结果越接近 <strong>0</strong>。</li>
<li><strong>梯度爆炸</strong>：如果这些数字大部分都<strong>大于
1</strong>（例如 1.1），乘得越多，结果就会趋向
<strong>无穷大</strong>。</li>
</ul>
<hr>
<h3 id="梯度消失-gradient-vanishing">2. 梯度消失 (Gradient
Vanishing)</h3>
<h4 id="现象"><strong>现象</strong></h4>
<ul>
<li>在深层网络中，<strong>靠近输入层（浅层）的参数几乎不更新</strong>，而靠近输出层的参数更新正常。</li>
<li>模型看起来在训练，但实际上前几层只是在做随机特征提取，导致整体模型无法收敛或性能很差。</li>
</ul>
<h4 id="主要原因"><strong>主要原因</strong></h4>
<ol type="1">
<li><strong>激活函数选择不当</strong>：使用了 <strong>Sigmoid</strong>
或 <strong>Tanh</strong> 函数。
<ul>
<li>Sigmoid 的导数最大值只有
<strong>0.25</strong>。当网络很深时，多个小于 0.25
的数相乘，梯度会以指数级衰减。</li>
</ul></li>
<li><strong>网络太深</strong>：层数越多，连乘链条越长，衰减越严重。</li>
</ol>
<h4 id="解决方法"><strong>解决方法</strong></h4>
<ul>
<li><strong>更换激活函数</strong>：使用 <strong>ReLU (Rectified Linear
Unit)</strong> 及其变体（Leaky ReLU）。ReLU 在正区间的导数恒为
1，解决了连乘导致的衰减问题。</li>
<li><strong>Batch Normalization
(BN)</strong>：通过规范化每一层的输入，强行将数据拉回到激活函数的敏感区间，防止梯度变小。</li>
<li><strong>残差结构 (ResNet)</strong>：引入 “Shortcut
Connection”（捷径），让梯度可以通过“高速公路”直接传到浅层，不再完全依赖层层相乘。</li>
</ul>
<hr>
<h3 id="梯度爆炸-gradient-exploding">3. 梯度爆炸 (Gradient
Exploding)</h3>
<h4 id="现象-1"><strong>现象</strong></h4>
<ul>
<li><strong>Loss 震荡</strong>：损失函数（Loss）忽大忽小，甚至变成
<code>NaN</code>（非数字）。</li>
<li><strong>权重剧变</strong>：模型参数更新幅度过大，直接飞出合理范围。</li>
<li>多见于 <strong>RNN (循环神经网络)</strong> 处理长序列数据时。</li>
</ul>
<h4 id="主要原因-1"><strong>主要原因</strong></h4>
<ol type="1">
<li><strong>权重初始化过大</strong>：初始参数值太大，导致每一层的输出和梯度都成倍放大。</li>
<li><strong>网络结构问题</strong>：在 RNN
中，同一个权重矩阵在时间步上被反复相乘，极易导致数值溢出。</li>
</ol>
<h4 id="解决方法-1"><strong>解决方法</strong></h4>
<ul>
<li><strong>梯度裁剪 (Gradient
Clipping)</strong>：简单粗暴但有效。如果梯度的范数（Norm）超过某个阈值（比如
5），就强行把它截断（缩放）到这个阈值以内。</li>
<li><strong>改善权重初始化</strong>：使用 <strong>Xavier</strong> 或
<strong>He
Initialization</strong>，根据每层的神经元数量科学地设置初始权重的范围。</li>
<li><strong>使用 LSTM/GRU</strong>：在处理序列数据时，LSTM
通过“门控机制”专门设计了梯度的传输通道，缓解了长序列中的梯度问题。</li>
</ul>
<hr>
<h3 id="总结对比">总结对比</h3>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 45%">
<col style="width: 40%">
</colgroup>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>梯度消失 (Vanishing)</strong></th>
<th><strong>梯度爆炸 (Exploding)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>本质</strong></td>
<td>连乘项 &lt; 1，梯度趋近于 0</td>
<td>连乘项 &gt; 1，梯度趋近于无穷</td>
</tr>
<tr>
<td><strong>后果</strong></td>
<td>浅层参数不更新，模型学不到东西</td>
<td>权重数值溢出 (NaN)，无法收敛</td>
</tr>
<tr>
<td><strong>高发场景</strong></td>
<td>深层网络 (Deep CNN/MLP)，使用 Sigmoid</td>
<td>循环神经网络 (RNN)，深层网络</td>
</tr>
<tr>
<td><strong>核心解法</strong></td>
<td><strong>ReLU</strong>, BatchNorm, ResNet</td>
<td><strong>Gradient Clipping</strong>, 权重正则化</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>大模型算法</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>tokenizer</title>
    <url>/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/</url>
    <content><![CDATA[<h3 id="什么是-tokenizer">什么是 Tokenizer？</h3>
<p><strong>Tokenizer</strong>（分词器）可以将原始文本（raw
text）转换为模型能够理解的数字序列，在模型输入和输出的两个主要阶段中发挥重要作用：</p>
<h4 id="模型输入编码-encode阶段">模型输入（编码 Encode）阶段</h4>
<ol type="1">
<li><p><strong>分词（Tokenize）</strong></p>
<p>将文本拆分为词元（Token），常见的分词方式包括字级、词级、子词级（如
BPE、WordPiece）、空格分词等。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">输入: &quot;你好&quot;</span><br><span class="line">分词: [&quot;你&quot;, &quot;好&quot;]</span><br></pre></td></tr></table></figure></li>
<li><p><strong>映射（Mapping）</strong></p>
<p>将每个词元映射为词汇表中的唯一 ID，生成的数字序列即为模型的输入。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">分词: [&quot;你&quot;, &quot;好&quot;]</span><br><span class="line">映射: [<span class="number">1001</span>, <span class="number">1002</span>]</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="模型输出解码-decode阶段">模型输出（解码 Decode）阶段</h4>
<ol type="1">
<li><p><strong>反映射（De-mapping）</strong></p>
<p>模型输出的数字序列通过词汇表映射回对应的词元，二者是一一对应的关系。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">输出: [<span class="number">1001</span>, <span class="number">1002</span>]</span><br><span class="line">反映射: [&quot;你&quot;, &quot;好&quot;]</span><br></pre></td></tr></table></figure></li>
<li><p><strong>文本重组</strong></p>
<p>将解码后的词元以某种规则重新拼接为完整文本。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">反映射: [&quot;你&quot;, &quot;好&quot;]</span><br><span class="line">重组: &quot;你好&quot;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="直观感受">直观感受</h4>
<p>访问 <a href="https://tiktokenizer.vercel.app">Tiktokenizer</a>，通过右上角选取不同的
Tokenizer 进行尝试</p>
<h3 id="词汇表">词汇表</h3>
<p>两种常见的构建词汇表的方法：</p>
<ul>
<li><strong>BPE（Byte-Pair Encoding）</strong>：用于
GPT、GPT-2、RoBERTa、BART 和 DeBERTa 等模型。</li>
<li><strong>WordPiece</strong>：用于 DistilBERT、MobileBERT、Funnel
Transformers 和 MPNET 等模型。</li>
</ul>
<h4 id="bpe">BPE</h4>
<p>BPE（Byte Pair Encoding，字节对编码）在 NLP
里是一种<strong>贪心式的子词（subword）分词算法</strong>。
理解：从“字符”开始，反复把<strong>出现次数最多的相邻字符对</strong>合并成新的符号，并加入词汇表，直到达到预设的词汇表大小。</p>
<blockquote>
<p>为什么可以处理 OOV（Out-Of-Vocabulary）情况</p>
<p>因为所有词汇都是由字符或词根组成的，通过对单个字符的学习，可以组成oov的词汇</p>
<p>为什么需要词汇表</p>
<p>编码时，从文本到模型：需要将文本分词为 Tokens，再通过词汇表将 Tokens
转换为 Token IDs，再传给transformer</p>
<p>解码时，从模型到文本：需要通过词汇表Token IDs 转换为
Tokens，再把Tokens 拼接为文本</p>
</blockquote>
<h5 id="步骤">步骤</h5>
<ol type="1">
<li><strong>初始化词汇表 <span class="math inline"><em>V</em></span></strong>：
<ul>
<li><span class="math inline"><em>V</em></span>
包含语料库中的所有唯一字符，即单词字符的集合。</li>
</ul></li>
<li><strong>统计字符对的频次</strong>：
<ul>
<li>对于每个单词的字符序列，统计相邻字符对的出现频次。</li>
</ul></li>
<li><strong>找到频次（Score）最高的字符对并合并</strong>：
<ul>
<li>选择出现频率最高的字符对 <span class="math inline">(<em>x</em>, <em>y</em>)</span>，将其合并为新符号
<span class="math inline"><em>x</em><em>y</em></span>。</li>
</ul></li>
<li><strong>更新词汇表并重复步骤 2 到 4</strong>：
<ul>
<li>将新符号添加到词汇表 <span class="math inline"><em>V</em> = <em>V</em> ∪ {<em>x</em><em>y</em>}</span>。</li>
<li>更新语料库中的单词表示，重复统计和合并过程，直到满足停止条件（例如，词汇表达到预定大小）。</li>
</ul></li>
</ol>
<p><strong>示例</strong></p>
<p>我们需要将语料库（corpus）的文本拆分为单词，假设当前语料库包含的单词和对应频次如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&quot;low&quot;, 5), (&quot;lower&quot;, 2), (&quot;newest&quot;, 6), (&quot;widest&quot;, 3)</span><br></pre></td></tr></table></figure>
<p><strong>步骤 1：初始化词汇表</strong></p>
<p><strong>将单词拆分为字符序列</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;), 5  </span><br><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;, &quot;e&quot;, &quot;r&quot;), 2  </span><br><span class="line">(&quot;n&quot;, &quot;e&quot;, &quot;w&quot;, &quot;e&quot;, &quot;s&quot;, &quot;t&quot;), 6  </span><br><span class="line">(&quot;w&quot;, &quot;i&quot;, &quot;d&quot;, &quot;e&quot;, &quot;s&quot;, &quot;t&quot;), 3</span><br></pre></td></tr></table></figure>
<p><strong>词汇表 V</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;l&#x27;, &#x27;o&#x27;, &#x27;w&#x27;, &#x27;e&#x27;, &#x27;r&#x27;, &#x27;n&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, &#x27;i&#x27;, &#x27;d&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>步骤 2：统计字符对的频次</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">字符对频次统计结果:</span><br><span class="line">(&#x27;l&#x27;, &#x27;o&#x27;): 7        # 5 (low) + 2 (lower)</span><br><span class="line">(&#x27;o&#x27;, &#x27;w&#x27;): 7        # 5 (low) + 2 (lower)</span><br><span class="line">(&#x27;w&#x27;, &#x27;e&#x27;): 8        # 2 (lower) + 6 (newest)</span><br><span class="line">(&#x27;e&#x27;, &#x27;r&#x27;): 2</span><br><span class="line">(&#x27;n&#x27;, &#x27;e&#x27;): 6</span><br><span class="line">(&#x27;e&#x27;, &#x27;w&#x27;): 6</span><br><span class="line">(&#x27;e&#x27;, &#x27;s&#x27;): 9        # 6 (newest) + 3 (widest)</span><br><span class="line">(&#x27;s&#x27;, &#x27;t&#x27;): 9        # 6 (newest) + 3 (widest)</span><br><span class="line">(&#x27;w&#x27;, &#x27;i&#x27;): 3</span><br><span class="line">(&#x27;i&#x27;, &#x27;d&#x27;): 3</span><br><span class="line">(&#x27;d&#x27;, &#x27;e&#x27;): 3</span><br></pre></td></tr></table></figure>
<p><strong>步骤 3：找到频次最高的字符对并合并</strong></p>
<p><strong>选择频次最高的字符对</strong>：</p>
<ul>
<li><code>("e", "s")</code> 和 <code>("s", "t")</code>，频次均为
9。可以任选其一进行合并，假设选择排序第一的：
<code>("e", "s")</code>。</li>
</ul>
<p><strong>合并 <code>("e", "s")</code> 为新符号
<code>es</code></strong>。</p>
<p><strong>记录合并操作</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Merge 1: (&quot;e&quot;, &quot;s&quot;) -&gt; &quot;es&quot;</span><br></pre></td></tr></table></figure>
<p><strong>步骤 4：更新词汇表并重复</strong></p>
<p><strong>更新单词序列</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;), 5  </span><br><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;, &quot;e&quot;, &quot;r&quot;), 2  </span><br><span class="line">(&quot;n&quot;, &quot;e&quot;, &quot;w&quot;, &quot;es&quot;, &quot;t&quot;), 6  </span><br><span class="line">(&quot;w&quot;, &quot;i&quot;, &quot;d&quot;, &quot;es&quot;, &quot;t&quot;), 3</span><br></pre></td></tr></table></figure>
<p><strong>更新词汇表 V</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;l&#x27;, &#x27;o&#x27;, &#x27;w&#x27;, &#x27;e&#x27;, &#x27;r&#x27;, &#x27;n&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, &#x27;i&#x27;, &#x27;d&#x27;, &#x27;es&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>重复步骤 2 到 4，直到达到预定的词汇表大小</strong>。</p>
<h4 id="wordpiece">WordPiece</h4>
<p>WordPiece 是 Google 在 2016 年为语音识别与 BERT
提出的<strong>子词（subword）分词算法</strong>，可看作 BPE
的“似然改进版”。理解：“<strong>用概率贪心而不是频次贪心，从字符开始逐步合并子词</strong>。”</p>
<p>与 BPE 不同，WordPiece 的 Score
由字符对频次与其组成部分频次的比值决定，定义 Score：</p>
<p><span class="math display">$$
\text{Score}_{\text{WordPiece}}(x, y) =
\frac{\text{freq}(xy)}{\text{freq}(x) \times \text{freq}(y)}
$$</span></p>
<p>其中, <span class="math inline">freq(<em>x</em>)</span>, <span class="math inline">freq(<em>y</em>)</span> 和 <span class="math inline">freq(<em>x</em><em>y</em>)</span> 分别表示符号 <span class="math inline"><em>x</em></span>, <span class="math inline"><em>y</em></span> 和它们合并后的符号 <span class="math inline"><em>x</em><em>y</em></span> 的频次。</p>
<h5 id="步骤-1">步骤</h5>
<ol type="1">
<li><strong>初始化词汇表 <span class="math inline"><em>V</em></span></strong>：
<ul>
<li>与 BPE 相同, <span class="math inline"><em>V</em></span>
包含语料库中的所有唯一字符，但处理方式略有不同：<strong>对于每个单词，除了首个字符外，其他字符前都加上
<code>##</code> 前缀。</strong></li>
</ul></li>
<li><strong>统计字符对的频次及 Score</strong>：
<ul>
<li>对于每个可能的字符对 <span class="math inline">(<em>x</em>, <em>y</em>)</span>，计算 <span class="math inline">freq(<em>x</em>)</span>, <span class="math inline">freq(<em>y</em>)</span>, <span class="math inline">freq(<em>x</em><em>y</em>)</span>，并计算
Score。</li>
</ul></li>
<li><strong>找到 Score 最高的字符对并合并</strong>：
<ul>
<li>选择 Score 最高的字符对 <span class="math inline">(<em>x</em>, <em>y</em>)</span>，将其合并为新符号
<span class="math inline"><em>x</em><em>y</em></span>，注意：
<ul>
<li>如果第二个符号以 <code>##</code> 开头，合并时去掉 <code>##</code>
前缀再进行连接。</li>
<li>新符号是否以 <code>##</code> 开头，取决于第一个符号是否以
<code>##</code> 开头。</li>
</ul></li>
</ul></li>
<li><strong>更新词汇表并重复步骤 2 到 4</strong>：
<ul>
<li>将新符号添加到词汇表 <span class="math inline"><em>V</em> = <em>V</em> ∪ {<em>x</em><em>y</em>}</span>。</li>
<li>更新语料库中的单词表示，重复统计和合并过程，直到满足停止条件。</li>
</ul></li>
</ol>
<h3 id="映射mapping">映射（Mapping）</h3>
<p>以 BPE 为例，最终词汇表 <span class="math inline"><em>V</em></span>
中的 Token 和对应的频次分别为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vocab = &#123;</span><br><span class="line">    &#x27;lo&#x27;: 7,</span><br><span class="line">    &#x27;w&#x27;: 16,</span><br><span class="line">    &#x27;e&#x27;: 8,</span><br><span class="line">    &#x27;r&#x27;: 2,</span><br><span class="line">    &#x27;n&#x27;: 6,</span><br><span class="line">    &#x27;est&#x27;: 9,</span><br><span class="line">    &#x27;i&#x27;: 3,</span><br><span class="line">    &#x27;d&#x27;: 3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Token to ID: &#123;&#x27;lo&#x27;: 0, &#x27;w&#x27;: 1, &#x27;e&#x27;: 2, &#x27;r&#x27;: 3, &#x27;n&#x27;: 4, &#x27;est&#x27;: 5, &#x27;i&#x27;: 6, &#x27;d&#x27;: 7&#125;</span><br><span class="line">ID to Token: &#123;0: &#x27;lo&#x27;, 1: &#x27;w&#x27;, 2: &#x27;e&#x27;, 3: &#x27;r&#x27;, 4: &#x27;n&#x27;, 5: &#x27;est&#x27;, 6: &#x27;i&#x27;, 7: &#x27;d&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>当然，也可以根据频次或者其他规则进行特殊处理。</p>
<p>以上是编码部分的概述，实际上在文本预处理的时候还会增加特殊标记，但这些以及后续的解码部分大多是一些文本处理的规则，这里就不过多赘述了，Tokenizer
之间的核心差异在于使用的分割方法和词汇表的构建策略。</p>
<h3 id="transformer中的分词">transformer中的分词</h3>
<p>在 Transformers 中，<strong>分词（tokenization）</strong>
实际上包含以下几个步骤：</p>
<ol type="1">
<li><strong>标准化（Normalization）</strong>：对文本进行必要的清理操作，例如删除多余空格或重音符号、进行
Unicode 标准化等。</li>
<li><strong>预分词（Pre-tokenization）</strong>：将输入拆分为单词。</li>
<li><strong>通过模型处理输入（Running the input through the
model）</strong>：使用预分词后的单词生成一系列词元（tokens）。</li>
<li><strong>后处理（Post-processing）</strong>：添加分词器的特殊标记，生成注意力掩码（attention
mask）和词元类型 ID（token type IDs）。</li>
</ol>
<p>流程图如下</p>
<figure>
<img src="/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/image-20250808100051423.png" alt="image-20250808100051423">
<figcaption aria-hidden="true">image-20250808100051423</figcaption>
</figure>
<h4 id="注意力掩码attention-mask和词元类型-id-token-type-ids是什么">注意力掩码（Attention
Mask）和词元类型 ID （Token Type IDs）是什么？</h4>
<figure>
<img src="/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/image-20250808100813881.png" alt="image-20250808100813881">
<figcaption aria-hidden="true">image-20250808100813881</figcaption>
</figure>
<p>1️⃣ 注意力掩码（Attention Mask） •
目的：告诉模型“哪些位置可以被看到”，其余位置直接屏蔽。 • 典型场景： –
<strong>自注意力里做 padding 掩码</strong>：把 <code>&lt;pad&gt;</code>
对应的位置设为 −∞，softmax 后权重=0。 –
<strong>解码器自回归掩码</strong>：生成任务用下三角掩码，避免第 i 个
token 看到未来 token。</p>
<p>2️⃣ 词元类型 ID（Token Type IDs，也叫 Segment IDs） •
目的：区分<strong>同一次输入里不同句子或段落</strong>，让模型知道“这段属于
A，那段属于 B”。 • 典型场景： – BERT
做句子对分类（NSP）：<code>[CLS] 句子A [SEP] 句子B [SEP]</code> → TypeID
= 0 0 0 0 1 1 1。 – RoBERTa、GPT 等单句模型则<strong>不需要</strong>
Token Type IDs。</p>
<p><strong>注意力掩码</strong>确保模型只关注实际的词元，忽略填充部分，从而避免无效的计算：</p>
<ul>
<li><strong>1</strong>：表示模型应关注的词元（Tokens）</li>
<li><strong>0</strong>：表示模型应忽略的词元（通常是填充
<code>padding</code> 的部分）。</li>
</ul>
<p><strong>词元类型 ID</strong> 用于区分输入中的不同句子或段落：</p>
<ul>
<li><strong>0</strong>：表示第一个句子的词元。</li>
<li><strong>1</strong>：表示第二个句子的词元。</li>
</ul>
<blockquote>
<p>CLS，SEP，PAD都是什么意思</p>
<p><code>[CLS]</code>（Classification），作用：对应位置的隐藏状态被当作<strong>整句/句对的“整体表示”</strong>，用来接分类头做句子级任务（情感分类、NLI
等）。</p>
<p><code>[SEP]</code>（Separator），作用：让模型知道<strong>分段 /
句子边界</strong>，配合 Token Type IDs 区分句子 A 和句子 B。</p>
<p><code>[PAD]</code>（padding token）的作用是
<strong>批量训练时把不同长度的序列补齐到同一长度</strong>，让张量可以堆叠成规整的矩阵；模型在计算注意力时通过
Attention Mask 把 <code>[PAD]</code> 对应的位置屏蔽掉，不让它们影响有效
token 的表示。</p>
</blockquote>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/blob/master/Guide/21.%20BPE%20vs%20WordPiece：理解%20Tokenizer%20的工作原理与子词分割方法.md">AI-Guide-and-Demos-zh_CN/Guide/21.
BPE vs WordPiece：理解 Tokenizer 的工作原理与子词分割方法.md at master ·
Hoper-J/AI-Guide-and-Demos-zh_CN</a></p>
]]></content>
      <categories>
        <category>大模型算法</category>
        <category>tokenizer</category>
      </categories>
      <tags>
        <tag>tokenizer</tag>
      </tags>
  </entry>
  <entry>
    <title>learn_pytorch</title>
    <url>/2025/12/20/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/pytorch/</url>
    <content><![CDATA[<h2 id="安装">安装</h2>
<p>PyTorch 在 PyPI 上的包名是
<strong><code>torch</code></strong>，而不是 <code>pytorch</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 仅安装 CPU 版本</span><br><span class="line">uv add torch</span><br></pre></td></tr></table></figure>
<p>安装 GPU 版本的 PyTorch 需要指定 CUDA 版本的索引。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># CUDA 12.1 版本（推荐，适用于较新的显卡）</span><br><span class="line">uv add torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121</span><br></pre></td></tr></table></figure>
<p><strong>检查你的 NVIDIA 驱动支持的 CUDA 版本：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
<p><strong>如何知道对应的cuda版本索引</strong></p>
<p><strong>访问 PyTorch 官网：</strong> <a href="vscode-file://vscode-app/d:/vscodeInsiders/Microsoft%20VS%20Code%20Insiders/0d1ac13bc4/resources/app/out/vs/code/electron-browser/workbench/workbench.html">https://pytorch.org/get-started/locally/</a></p>
<p><strong>torchvision</strong> 和 <strong>torchaudio</strong> 是
PyTorch 生态系统中的两个官方扩展库：</p>
<p><strong>torchvision</strong> - 计算机视觉工具包：</p>
<ul>
<li>预训练模型（ResNet、VGG、YOLO 等）</li>
<li>图像数据集（CIFAR-10、ImageNet、COCO 等）</li>
<li>图像转换和增强功能</li>
<li>图像读取和处理工具</li>
</ul>
<p><strong>torchaudio</strong> - 音频处理工具包：</p>
<ul>
<li>音频数据集</li>
<li>音频转换和预处理</li>
<li>音频特征提取（MFCC、梅尔频谱等）</li>
<li>音频读取和保存</li>
</ul>
<h2 id="张量与向量">张量与向量</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from torch import nn</span><br><span class="line">linear = nn.Linear(5, 3)</span><br><span class="line">linear.state_dict()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">OrderedDict([(&#x27;weight&#x27;,</span><br><span class="line">              tensor([[ 0.3763, -0.3488,  0.4359,  0.1161,  0.3337],</span><br><span class="line">                      [ 0.2588,  0.1844,  0.1083, -0.1958,  0.2706],</span><br><span class="line">                      [-0.0392, -0.0902,  0.3593, -0.2657,  0.3799]])),</span><br><span class="line">             (&#x27;bias&#x27;, tensor([-0.4142, -0.0444, -0.2487]))])</span><br></pre></td></tr></table></figure>
<p><code>linear = nn.Linear(5, 3)</code>
创建了一个<strong>线性层（全连接层）</strong>：</p>
<p><strong>参数含义：</strong> - <strong>5</strong> -
输入特征数（in_features） - <strong>3</strong> -
输出特征数（out_features）</p>
<p><strong>内部结构：</strong> 这个层包含两个可学习的参数： -
<strong>权重矩阵 W</strong>：形状为 (3, 5) - <strong>偏置向量
b</strong>：形状为 (3,)</p>
<p><strong>数学运算：</strong> <span class="math display"><em>y</em> = <em>x</em><em>W</em><sup><em>T</em></sup> + <em>b</em></span></p>
<p><code>'weight'</code> (权重) —— 这是 2阶张量 (矩阵)，是一个形状
(Shape) 为 <span class="math inline">3 × 5</span>
的<strong>矩阵</strong>。</p>
<h2 id="参考资料">参考资料</h2>
<p><a href="https://www.bilibili.com/video/BV1ypUkB7Eki?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">从零搭建神经网络，识别手写数字【PyTorch】【Transformer结构拆解】_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大模型算法</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>ragangything</title>
    <url>/2025/10/20/%E5%AD%A6%E4%B9%A0/rag/raganything/</url>
    <content><![CDATA[<h3 id="rag-anything">RAG-Anything</h3>
<p><strong>RAG-Anything</strong>是一个综合性多模态文档处理RAG系统。该系统能够无缝处理和查询包含文本、图像、表格、公式等多模态内容的复杂文档，提供完整的检索增强(RAG)生成解决方案。</p>
<p>解析方式</p>
<p>process_document_complete执行流程</p>
<ul>
<li>初始化依赖： await self._ensure_lightrag_initialized() ，保证
LightRAG 已就绪。</li>
<li>读取配置默认：对 output_dir / parse_method / display_stats
应用默认值。</li>
<li>记录开始日志： Starting complete document processing: {file_path}
。</li>
<li>第一步（解析）：调用 parse_document(…) ，返回
<ul>
<li>content_list :
解析出的内容列表（混合文本块与多模态项的统一结构）。</li>
<li>content_based_doc_id : 基于内容生成的文档ID（用于未显式提供 doc_id
时）。</li>
</ul></li>
<li>文档ID确定：若未传入 doc_id ，用 content_based_doc_id
作为本次处理的文档标识。</li>
<li>第二步（拆分）： text_content, multimodal_items =
separate_content(content_list) ，将纯文本与多模态项分离。</li>
<li>第二步半（上下文源设置）：若存在多模态项且类实现了
set_content_source_for_context ，调用它以建立“内容源 →
上下文”映射，用于后续多模态处理更好地提取上下文。</li>
<li>第三步（插入文本）：如果 text_content 非空：
<ul>
<li>取 file_name = os.path.basename(file_path) ，作为 file_paths
元信息传入。</li>
<li>调用 insert_text_content(…) 将文本写入 LightRAG 索引，支持
split_by_character 与 split_by_character_only
控制切分方式，并统一使用同一个 ids=doc_id
以保证该文档的索引一致性。</li>
</ul></li>
<li>第四步（处理多模态）：
<ul>
<li>若 multimodal_items 非空：调用 await
self._process_multimodal_content(multimodal_items, file_path, doc_id)
用专用处理器写入图片、表格、公式等相关产物并建立索引/缓存。</li>
<li>若为空：调用 _mark_multimodal_processing_complete(doc_id)
标记该文档的多模态处理阶段已完成（即使没有多模态项也要显式完成，以便状态一致）。</li>
</ul></li>
<li>记录完成日志： Document {file_path} processing complete! 。</li>
</ul>
<p>存储方式</p>
<p>检索方式</p>
<p>功能区别</p>
<ul>
<li>aquery ：纯文本查询入口，直接把你的问题和检索参数封装到 QueryParam
并调用 LightRAG。若已配置视觉模型函数（ vision_model_func
），默认会自动启用图像增强；可通过传入 vlm_enhanced=False
强制走纯文本。</li>
<li>aquery_with_multimodal
：主动把你提供的多模态素材（图片、表格、公式等）先“描述压缩”为文本（用已注册的处理器生成说明），把这些说明拼接到查询中，然后再执行
aquery 做检索与问答；内置结果缓存（按素材和参数归一化生成 key）。</li>
<li>aquery_vlm_enhanced ：在检索生成的原始提示（ only_need_prompt=True
）里扫描图片路径，保持原路径并插入标记，将图片转为
base64，与文本一并发给视觉模型生成最终答案；不把图转成文字摘要，而是让
VLM直接“看图”。需要你已提供 vision_model_func ，否则会报错。</li>
</ul>
<p>aquery_vlm_enhanced执行流程</p>
<ul>
<li>检查 VLM 可用：若 vision_model_func 未配置，抛出 ValueError 。</li>
<li>确保 LightRAG 就绪：调用 self._ensure_lightrag_initialized()
，保证你之前已处理并建好索引/图谱。</li>
<li>清理图片缓存：删除上一次查询残留的 self._current_images_base64
。</li>
<li>只取检索提示：构造 QueryParam(mode=mode, only_need_prompt=True,
**kwargs) ，调用 self.lightrag.aquery(…)
拿到“原始提示”（包含检索到的上下文与可能的图片路径），此时不向
LLM发起最终回答。</li>
<li>解析图片路径：调用 self._process_image_paths_for_vlm(raw_prompt)
，用正则匹配诸如 Image Path: …(.jpg|.png|…) 的行，对路径做
validate_image_file 验证并转 base64，往提示里插入供
VLM使用的标记；返回增强后的提示与图片计数。</li>
<li>无图兜底：若 images_found == 0 ，直接退回普通查询（
QueryParam(mode=mode, **kwargs) ）走文本 LLM（即不做看图增强）。</li>
<li>构建 VLM消息： self._build_vlm_messages_with_images(enhanced_prompt,
query) 将“增强提示+图片（base64）”打包成 VLM需要的消息格式。</li>
<li>调用视觉模型： self._call_vlm_with_multimodal_content(messages)
，由你的 vision_model_func 实际生成最终答案并返回。</li>
</ul>
<p>为什么要转base64</p>
<p>心原因</p>
<ul>
<li>远端不可读本地路径：检索提示里只有 Image Path: C:... 或 ./xxx.png
，VLM（常在云端或独立进程）无法直接访问你的本地文件系统，必须把图像的字节随请求一起发送。</li>
<li>标准化传输格式：多数 VLM 接口以 JSON/HTTP
交互，原生不支持二进制；Base64 是通用的文本编码，易于嵌入到消息体或
data:image/png;base64,… 这样的数据 URI。</li>
<li>跨平台与健壮性：避免
Windows/中文路径、权限、相对路径等差异导致文件读取失败；编码后与工作目录无关，传到哪都能被解码。</li>
<li>兼容主流 API 形态：OpenAI、LM Studio、部分本地/私有 VLM 都支持用
Base64 提供图像数据；RAGAnything 将其统一为 vision_model_func
可消费的消息格式。</li>
<li>可缓存与复用：编码后可做哈希/去重与一次请求内复用（
_current_images_base64
），同时避免在日志或提示里暴露真实文件路径结构。</li>
</ul>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://github.com/HKUDS/RAG-Anything/blob/main/README_zh.md">RAG-Anything/README_zh.md
at main · HKUDS/RAG-Anything</a></p>
]]></content>
      <categories>
        <category>rag</category>
      </categories>
      <tags>
        <tag>rag</tag>
      </tags>
  </entry>
  <entry>
    <title>agentic-rag实战</title>
    <url>/2025/08/19/%E5%AD%A6%E4%B9%A0/rag/agentic-rag/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p><strong>这个agentic
rag主要是作用于检索部分，由是否需要调用检索工具判定是否进入检索阶段，当检索到相关的文章，则进行回答，否则对问题进行改写，再次检索</strong></p>
<p>代码见<a href="https://github.com/zxj-2023/learn-rag-langchain/tree/main/agentic-rag">learn-rag-langchain/agentic-rag
at main · zxj-2023/learn-rag-langchain</a></p>
<p>在这个教程中，我们将构建一个检索代理。当您希望 LLM
决定是否从向量存储中检索上下文或直接响应用户时，检索代理非常有用。</p>
<p>完成教程后，我们将完成以下工作：</p>
<ol type="1">
<li>获取并预处理用于检索的文档。</li>
<li>为这些文档建立语义索引，并为代理创建一个检索工具。</li>
<li>构建一个能够决定何时使用检索工具的代理式 RAG 系统。</li>
</ol>
<figure>
<img src="/2025/08/19/%E5%AD%A6%E4%B9%A0/rag/agentic-rag/image-20250819165309335.png" alt="image-20250819165309335">
<figcaption aria-hidden="true">image-20250819165309335</figcaption>
</figure>
<h3 id="预处理文档">1. 预处理文档</h3>
<p>获取用于我们 RAG 系统的文档。我们将使用 Lilian Weng
优秀博客中最新的三页。我们将从使用 <code>WebBaseLoader</code>
工具获取页面内容开始：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_community.document_loaders import WebBaseLoader</span><br><span class="line"></span><br><span class="line">urls = [</span><br><span class="line">    &quot;https://lilianweng.github.io/posts/2024-11-28-reward-hacking/&quot;,</span><br><span class="line">    &quot;https://lilianweng.github.io/posts/2024-07-07-hallucination/&quot;,</span><br><span class="line">    &quot;https://lilianweng.github.io/posts/2024-04-12-diffusion-video/&quot;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">docs = [WebBaseLoader(url).load() for url in urls]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docs[0][0].page_content.strip()[:1000]</span><br></pre></td></tr></table></figure>
<p>将获取的文档分割成更小的块，以便索引到我们的向量存储中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_text_splitters import RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">docs_list = [item for sublist in docs for item in sublist]</span><br><span class="line"></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(</span><br><span class="line">    chunk_size=100, chunk_overlap=50</span><br><span class="line">)</span><br><span class="line">doc_splits = text_splitter.split_documents(docs_list)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">doc_splits[0].page_content.strip()</span><br></pre></td></tr></table></figure>
<h3 id="创建检索工具">2. 创建检索工具</h3>
<p>现在我们已经有了分割的文档，我们可以将它们索引到一个向量存储中，我们将使用这个向量存储进行语义搜索。</p>
<p>使用内存向量存储和 OpenAI 嵌入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_chroma import Chroma  # 导入 Chroma</span><br><span class="line">from langchain_openai import OpenAIEmbeddings</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"># 确保安装了 langchain-chroma</span><br><span class="line"># pip install langchain-chroma</span><br><span class="line"></span><br><span class="line">embedding = OpenAIEmbeddings(</span><br><span class="line">    api_key=&quot;sk-&quot;, </span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">    model=&quot;text-embedding-v4&quot;,</span><br><span class="line">    check_embedding_ctx_length=False,</span><br><span class="line">    dimensions=1536,</span><br><span class="line">    chunk_size=5  # 设置较小的批次大小</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 使用 Chroma 替代 InMemoryVectorStore</span><br><span class="line">vectorstore = Chroma.from_documents(</span><br><span class="line">    documents=doc_splits, </span><br><span class="line">    embedding=embedding,</span><br><span class="line">    persist_directory=&quot;./chroma_db&quot;  # 指定持久化目录</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 重新加载已存在的 Chroma 数据库</span><br><span class="line">vectorstore = Chroma(</span><br><span class="line">    persist_directory=&quot;./chroma_db&quot;,</span><br><span class="line">    embedding_function=embedding</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">retriever = vectorstore.as_retriever()</span><br></pre></td></tr></table></figure>
<p>使用 LangChain 的预构建 <code>create_retriever_tool</code>
创建检索工具</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.tools.retriever import create_retriever_tool</span><br><span class="line"></span><br><span class="line">retriever_tool = create_retriever_tool(</span><br><span class="line">    retriever,                    # 【输入】一个已经配置好的检索器（例如：向量数据库的检索器）</span><br><span class="line">    &quot;retrieve_blog_posts&quot;,        # 【工具名称】这个工具的唯一标识名（供模型内部调用）</span><br><span class="line">    &quot;Search and return information about Lilian Weng blog posts.&quot;  # 【工具描述】模型看到的说明，用于决定是否调用它</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">retriever_tool.invoke(&#123;&quot;query&quot;: &quot;types of reward hacking&quot;&#125;)</span><br></pre></td></tr></table></figure>
<h3 id="生成查询">3. 生成查询</h3>
<p>现在我们将开始构建我们智能体 RAG 图中的组件（节点和边）。</p>
<p>构建一个 <code>generate_query_or_respond</code> 节点。它将调用 LLM
来根据当前图状态（消息列表）生成响应。根据输入消息，它将决定使用检索工具进行检索，或直接响应用户。请注意，我们通过
<code>.bind_tools</code> 向聊天模型提供了先前创建的
<code>retriever_tool</code> 访问权限：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">llm = ChatTongyi(</span><br><span class="line">    model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">    model_kwargs=&#123;&quot;enable_thinking&quot;: False&#125;   # 关键在这里</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line"></span><br><span class="line">def generate_query_or_respond(state: MessagesState):</span><br><span class="line">    &quot;&quot;&quot;调用模型，根据当前状态生成响应。根据问题，模型将决定是使用检索工具进行检索，还是直接回复用户。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    response = (</span><br><span class="line">        llm</span><br><span class="line">        .bind_tools([retriever_tool]).invoke(state[&quot;messages&quot;])</span><br><span class="line">    )</span><br><span class="line">    return &#123;&quot;messages&quot;: [response]&#125;</span><br></pre></td></tr></table></figure>
<p>提出一个需要语义搜索的问题：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input = &#123;</span><br><span class="line">    &quot;messages&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">            &quot;content&quot;: &quot;What does Lilian Weng say about types of reward hacking?&quot;,</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">generate_query_or_respond(input)[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h3 id="评定文件">4.评定文件</h3>
<p>添加一个条件边 — <code>grade_documents</code> —
来判断检索到的文档是否与问题相关。</p>
<p>我们将使用一个具有结构化输出模式 <code>GradeDocuments</code>
的模型来对文档进行评分。 <code>grade_documents</code>
函数将根据评分决策（ <code>generate_answer</code> 或
<code>rewrite_question</code> ）返回要前往的节点的名称：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from pydantic import BaseModel, Field</span><br><span class="line">from typing import Literal</span><br><span class="line"></span><br><span class="line"># 定义评分提示模板</span><br><span class="line">GRADE_PROMPT = (</span><br><span class="line">    &quot;你是一个评分员，负责评估检索到的文档与用户问题的相关性。\n &quot;</span><br><span class="line">    &quot;以下是检索到的文档内容：\n\n &#123;context&#125; \n\n&quot;</span><br><span class="line">    &quot;以下是用户的问题：&#123;question&#125; \n&quot;</span><br><span class="line">    &quot;如果文档包含与用户问题相关的关键词或语义含义，则将其评为相关。\n&quot;</span><br><span class="line">    &quot;请给出一个二元评分：&#x27;yes&#x27;（是）表示相关，&#x27;no&#x27;（否）表示不相关。&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 定义用于评估文档相关性的 Pydantic 模型</span><br><span class="line">class GradeDocuments(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;使用二元评分对文档进行相关性评估。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    binary_score: str = Field(</span><br><span class="line">        description=&quot;相关性评分：&#x27;yes&#x27; 表示相关，&#x27;no&#x27; 表示不相关&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"># 初始化用于评分的聊天模型</span><br><span class="line">grader_model = llm</span><br><span class="line"></span><br><span class="line">def grade_documents(</span><br><span class="line">    state: MessagesState,</span><br><span class="line">) -&gt; Literal[&quot;generate_answer&quot;, &quot;rewrite_question&quot;]:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    判断检索到的文档是否与用户问题相关。</span><br><span class="line">    </span><br><span class="line">    参数:</span><br><span class="line">        state: 包含消息历史的状态对象，其中第一条消息是用户问题，</span><br><span class="line">               最后一条消息是检索到的文档内容。</span><br><span class="line">    </span><br><span class="line">    返回:</span><br><span class="line">        如果文档相关，返回 &quot;generate_answer&quot;；</span><br><span class="line">        如果不相关，返回 &quot;rewrite_question&quot;，表示需要重写问题并重新检索。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    question = state[&quot;messages&quot;][0].content  # 获取用户问题</span><br><span class="line">    context = state[&quot;messages&quot;][-1].content  # 获取检索到的文档内容</span><br><span class="line"></span><br><span class="line">    # 将问题和文档内容填入提示模板</span><br><span class="line">    prompt = GRADE_PROMPT.format(question=question, context=context)</span><br><span class="line">    </span><br><span class="line">    # 调用模型，并以结构化输出（Pydantic 模型）的形式获取评分结果</span><br><span class="line">    response = (</span><br><span class="line">        grader_model</span><br><span class="line">        .with_structured_output(GradeDocuments)</span><br><span class="line">        .invoke([&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt&#125;])</span><br><span class="line">    )</span><br><span class="line">    #print(response)</span><br><span class="line">    score = response.binary_score  # 获取二元评分结果</span><br><span class="line"> </span><br><span class="line">    # 根据评分决定下一步操作</span><br><span class="line">    if score == &quot;yes&quot;:</span><br><span class="line">        return &quot;generate_answer&quot;  # 文档相关，生成答案</span><br><span class="line">    else:</span><br><span class="line">        return &quot;rewrite_question&quot;  # 文档不相关，重写问题后重新检索</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import convert_to_messages</span><br><span class="line"></span><br><span class="line">input = &#123;</span><br><span class="line">    &quot;messages&quot;: convert_to_messages(#将一系列消息转换为 BaseMessage 类型的消息列表。</span><br><span class="line">        [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: &quot;What does Lilian Weng say about types of reward hacking?&quot;,</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                &quot;content&quot;: &quot;&quot;,</span><br><span class="line">                &quot;tool_calls&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;id&quot;: &quot;1&quot;,</span><br><span class="line">                        &quot;name&quot;: &quot;retrieve_blog_posts&quot;,</span><br><span class="line">                        &quot;args&quot;: &#123;&quot;query&quot;: &quot;types of reward hacking&quot;&#125;,</span><br><span class="line">                    &#125;</span><br><span class="line">                ],</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;&quot;role&quot;: &quot;tool&quot;, &quot;content&quot;: &quot;meow&quot;, &quot;tool_call_id&quot;: &quot;1&quot;&#125;,</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">&#125;</span><br><span class="line">grade_documents(input)</span><br></pre></td></tr></table></figure>
<h3 id="重写问题">5. 重写问题</h3>
<p>构建 <code>rewrite_question</code> 节点。</p>
<p>检索工具可能会返回潜在的不相关文档，这表明需要改进原始用户问题。为此，我们将调用
<code>rewrite_question</code> 节点：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">REWRITE_PROMPT = (</span><br><span class="line">    &quot;Look at the input and try to reason about the underlying semantic intent / meaning.\n&quot;</span><br><span class="line">    &quot;Here is the initial question:&quot;</span><br><span class="line">    &quot;\n ------- \n&quot;</span><br><span class="line">    &quot;&#123;question&#125;&quot;</span><br><span class="line">    &quot;\n ------- \n&quot;</span><br><span class="line">    &quot;Formulate an improved question:&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">def rewrite_question(state: MessagesState):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    重写用户最初的提问，以更好地表达其语义意图。</span><br><span class="line">    </span><br><span class="line">    参数:</span><br><span class="line">        state: 包含消息历史的状态对象，其中第一条消息是用户原始问题。</span><br><span class="line">    </span><br><span class="line">    返回:</span><br><span class="line">        一个字典，包含一条新的用户消息，内容为改写后的问题。</span><br><span class="line">        该消息将用于后续的检索步骤，以提高检索结果的相关性。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    question = messages[0].content  # 获取用户最初的提问</span><br><span class="line">    prompt = REWRITE_PROMPT.format(question=question)  # 将问题填入提示模板</span><br><span class="line">    response = llm.invoke([&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt&#125;])  # 调用模型生成改写后的问题</span><br><span class="line">    </span><br><span class="line">    # 返回新的消息结构，内容为改写后的问题</span><br><span class="line">    return &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: response.content&#125;]&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input = &#123;</span><br><span class="line">    &quot;messages&quot;: convert_to_messages(</span><br><span class="line">        [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: &quot;What does Lilian Weng say about types of reward hacking?&quot;,</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                &quot;content&quot;: &quot;&quot;,</span><br><span class="line">                &quot;tool_calls&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;id&quot;: &quot;1&quot;,</span><br><span class="line">                        &quot;name&quot;: &quot;retrieve_blog_posts&quot;,</span><br><span class="line">                        &quot;args&quot;: &#123;&quot;query&quot;: &quot;types of reward hacking&quot;&#125;,</span><br><span class="line">                    &#125;</span><br><span class="line">                ],</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;&quot;role&quot;: &quot;tool&quot;, &quot;content&quot;: &quot;meow&quot;, &quot;tool_call_id&quot;: &quot;1&quot;&#125;,</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = rewrite_question(input)</span><br><span class="line">print(response[&quot;messages&quot;][-1][&quot;content&quot;])</span><br></pre></td></tr></table></figure>
<h3 id="生成答案">6. 生成答案</h3>
<p>构建 <code>generate_answer</code>
节点：如果我们通过了评分器的检查，我们可以根据原始问题和检索到的上下文生成最终答案：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GENERATE_PROMPT = (</span><br><span class="line">    &quot;You are an assistant for question-answering tasks. &quot;</span><br><span class="line">    &quot;Use the following pieces of retrieved context to answer the question. &quot;</span><br><span class="line">    &quot;If you don&#x27;t know the answer, just say that you don&#x27;t know. &quot;</span><br><span class="line">    &quot;Use three sentences maximum and keep the answer concise.\n&quot;</span><br><span class="line">    &quot;Question: &#123;question&#125; \n&quot;</span><br><span class="line">    &quot;Context: &#123;context&#125;&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def generate_answer(state: MessagesState):</span><br><span class="line">    &quot;&quot;&quot;Generate an answer.&quot;&quot;&quot;</span><br><span class="line">    question = state[&quot;messages&quot;][0].content</span><br><span class="line">    context = state[&quot;messages&quot;][-1].content</span><br><span class="line">    prompt = GENERATE_PROMPT.format(question=question, context=context)</span><br><span class="line">    response = llm.invoke([&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt&#125;])</span><br><span class="line">    return &#123;&quot;messages&quot;: [response]&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input = &#123;</span><br><span class="line">    &quot;messages&quot;: convert_to_messages(</span><br><span class="line">        [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: &quot;What does Lilian Weng say about types of reward hacking?&quot;,</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                &quot;content&quot;: &quot;&quot;,</span><br><span class="line">                &quot;tool_calls&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;id&quot;: &quot;1&quot;,</span><br><span class="line">                        &quot;name&quot;: &quot;retrieve_blog_posts&quot;,</span><br><span class="line">                        &quot;args&quot;: &#123;&quot;query&quot;: &quot;types of reward hacking&quot;&#125;,</span><br><span class="line">                    &#125;</span><br><span class="line">                ],</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;tool&quot;,</span><br><span class="line">                &quot;content&quot;: &quot;reward hacking can be categorized into two types: environment or goal misspecification, and reward tampering&quot;,</span><br><span class="line">                &quot;tool_call_id&quot;: &quot;1&quot;,</span><br><span class="line">            &#125;,</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = generate_answer(input)</span><br><span class="line">response[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h3 id="组装图表">7. 组装图表</h3>
<p>以 <code>generate_query_or_respond</code> 开头，并确定是否需要调用
<code>retriever_tool</code></p>
<p>使用 <code>tools_condition</code> 跳转到下一步：</p>
<ul>
<li>如果 <code>generate_query_or_respond</code> 返回
<code>tool_calls</code> ，调用 <code>retriever_tool</code>
获取上下文</li>
<li>否则，直接回复用户</li>
</ul>
<p>对检索到的文档内容按与问题的相关性（ <code>grade_documents</code>
）进行评分，并路由到下一步：</p>
<ul>
<li>如果不相关，使用 <code>rewrite_question</code>
重写问题，然后再次调用 <code>generate_query_or_respond</code></li>
<li>如果相关，请继续到 <code>generate_answer</code>
并使用检索到的文档上下文生成最终响应 <code>ToolMessage</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">from langgraph.prebuilt import ToolNode</span><br><span class="line">from langgraph.prebuilt import tools_condition</span><br><span class="line"></span><br><span class="line"># 创建一个基于状态图（StateGraph）的流程，用于管理对话或任务的执行流程</span><br><span class="line">workflow = StateGraph(MessagesState)</span><br><span class="line"></span><br><span class="line"># 定义流程中将循环执行的各个节点</span><br><span class="line">workflow.add_node(generate_query_or_respond)          # 判断是生成检索查询还是直接回复用户</span><br><span class="line">workflow.add_node(&quot;retrieve&quot;, ToolNode([retriever_tool]))  # 检索节点：使用检索工具（retriever_tool）从知识库中查找相关文档</span><br><span class="line">workflow.add_node(rewrite_question)                  # 重写问题节点：当检索结果不相关时，优化并重写用户的问题</span><br><span class="line">workflow.add_node(generate_answer)                   # 生成答案节点：基于检索到的信息生成最终回答</span><br><span class="line"></span><br><span class="line"># 设置流程的起始点：从 `generate_query_or_respond` 节点开始</span><br><span class="line">workflow.add_edge(START, &quot;generate_query_or_respond&quot;)</span><br><span class="line"></span><br><span class="line"># 添加条件边：决定是否进行文档检索</span><br><span class="line">workflow.add_conditional_edges(</span><br><span class="line">    &quot;generate_query_or_respond&quot;,</span><br><span class="line">    # 使用 `tools_condition` 函数判断 LLM 的输出意图：</span><br><span class="line">    # 如果 LLM 决定调用 `retriever_tool` 工具，则进入检索；如果选择直接回复，则结束流程</span><br><span class="line">    tools_condition,</span><br><span class="line">    &#123;</span><br><span class="line">        # 将条件判断结果映射到图中的具体节点</span><br><span class="line">        &quot;tools&quot;: &quot;retrieve&quot;,   # 若需调用工具，则跳转到检索节点</span><br><span class="line">        END: END               # 若无需调用工具（即可以直接回答），则结束流程</span><br><span class="line">    &#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 在 `retrieve` 节点执行后，根据文档相关性判断下一步操作</span><br><span class="line">workflow.add_conditional_edges(</span><br><span class="line">    &quot;retrieve&quot;,</span><br><span class="line">    # 调用 `grade_documents` 函数评估检索到的文档是否与问题相关</span><br><span class="line">    grade_documents,</span><br><span class="line">    # 根据评分结果决定流向：</span><br><span class="line">    # - 如果相关，进入 `generate_answer`</span><br><span class="line">    # - 如果不相关，进入 `rewrite_question`</span><br><span class="line">    # （该逻辑在 `grade_documents` 函数中返回 &quot;generate_answer&quot; 或 &quot;rewrite_question&quot;）</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 添加固定边：生成答案后流程结束</span><br><span class="line">workflow.add_edge(&quot;generate_answer&quot;, END)</span><br><span class="line"></span><br><span class="line"># 重写问题后，回到初始节点重新判断是否需要检索</span><br><span class="line">workflow.add_edge(&quot;rewrite_question&quot;, &quot;generate_query_or_respond&quot;)</span><br><span class="line"></span><br><span class="line"># 编译整个工作流，生成可执行的图结构</span><br><span class="line">graph = workflow.compile()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/08/19/%E5%AD%A6%E4%B9%A0/rag/agentic-rag/image-20250826170834571.png" alt="image-20250826170834571">
<figcaption aria-hidden="true">image-20250826170834571</figcaption>
</figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/#2-create-a-retriever-tool">《Agentic
RAG》 — Agentic RAG</a></p>
]]></content>
      <categories>
        <category>rag</category>
      </categories>
      <tags>
        <tag>rag</tag>
        <tag>agent</tag>
        <tag>langgraph</tag>
      </tags>
  </entry>
  <entry>
    <title>LoRA其他的模型微调方法</title>
    <url>/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/LoRA%E5%85%B6%E4%BB%96%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/LoRA%E5%85%B6%E4%BB%96%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/image-20250814105851771.png" alt="image-20250814105851771">
<figcaption aria-hidden="true">image-20250814105851771</figcaption>
</figure>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzkzODI1NzQyNA==&amp;mid=2247494667&amp;idx=1&amp;sn=c3af7d2472de61752ef8b8df28746f2e&amp;poc_token=HCyNmWijps0ViWD6wPgqFiDYUZVRSs7xUDRfowWE">大模型微调技巧：LoRA
与 QLoRA讲解</a></p>
<p><a href="https://blog.csdn.net/javatiange/article/details/149964743?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=149964743&amp;sharerefer=PC&amp;sharesource=2501_91530961&amp;sharefrom=from_link">一文详解：8种常见的大模型微调方法，看这篇就够了！-CSDN博客</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/682082440">大模型微调技术 -
知乎</a></p>
]]></content>
      <categories>
        <category>模型</category>
        <category>微调</category>
      </categories>
      <tags>
        <tag>模型微调</tag>
      </tags>
  </entry>
  <entry>
    <title>lightrag</title>
    <url>/2025/09/21/%E5%AD%A6%E4%B9%A0/rag/lightrag/</url>
    <content><![CDATA[<h3 id="算法流程">算法流程</h3>
<figure>
<img src="/2025/09/21/%E5%AD%A6%E4%B9%A0/rag/lightrag/image-20250924135355928.png" alt="image-20250924135355928">
<figcaption aria-hidden="true">image-20250924135355928</figcaption>
</figure>
<ol type="1">
<li><p>对文本进行分块后，分别存储在<strong>kvstorage</strong>与
<strong>VectorDB Storage</strong></p></li>
<li><p>然后调用大模型进行<strong>实体与关系抽取</strong>（<strong>Extract
Entities &amp; Relations</strong>）</p></li>
<li><p>然后进行<strong>实体与关系的存储</strong>（<strong>Entities Data
/ Relations
Data</strong>），<strong>去重后</strong>（<strong>Deduplication</strong>），再次调用embedding模型存储于<strong>VectorDB
Storage</strong></p></li>
<li><p>再次调用大模型，对关系与实体的描述进行精炼或合并（<strong>Update
Description</strong>），并存储到<strong>Knowledge
Graph</strong></p></li>
</ol>
<figure>
<img src="/2025/09/21/%E5%AD%A6%E4%B9%A0/rag/lightrag/image-20250924135740665.png" alt="image">
<figcaption aria-hidden="true">image</figcaption>
</figure>
<p>LightRAG 使用 4 种类型的存储用于不同目的：</p>
<ul>
<li>KV_STORAGE：llm 响应缓存、文本块、文档信息</li>
<li>VECTOR_STORAGE：实体向量、关系向量、块向量</li>
<li>GRAPH_STORAGE：实体关系图</li>
<li>DOC_STATUS_STORAGE：文档索引状态</li>
</ul>
<figure>
<img src="/2025/09/21/%E5%AD%A6%E4%B9%A0/rag/lightrag/image-20250924142554264.png" alt="image-20250924142554264">
<figcaption aria-hidden="true">image-20250924142554264</figcaption>
</figure>
<p>值得注意的是，local检索模式仅使用low_level_keywords，而global检索模式仅支持high_level_keywords，从算法流程图可以看出来，前者更侧重于检索<strong>实体</strong>，后者则侧重于<strong>关系</strong></p>
<p>高关键词（High-level
Keywords）用于捕获查询的核心意图和主题概念；低关键词（Low-level
Keywords）用于识别具体的实体和细节信息</p>
<p>text_units的作用是：</p>
<ul>
<li>每条实体/关系记录在 KV 里都挂着 <code>chunk_ids</code> 列表。</li>
<li>把 Top-K 结果里的 <code>chunk_ids</code> 做 <strong>合并 +
去重</strong>，得到原始文本块序号。</li>
<li>用序号去 <strong>Nano VectorDB</strong> 里把对应
<strong>text_units（原始句子/段落）</strong> 拉回，作为
<strong>上下文原始语料</strong>。</li>
</ul>
<figure>
<img src="/2025/09/21/%E5%AD%A6%E4%B9%A0/rag/lightrag/image-20250924135917313.png" alt="image-20250924135917313">
<figcaption aria-hidden="true">image-20250924135917313</figcaption>
</figure>
<h3 id="安装">安装</h3>
<p>安装LightRAG服务器</p>
<p>LightRAG服务器旨在提供Web UI和API支持。Web
UI便于文档索引、知识图谱探索和简单的RAG查询界面。LightRAG服务器还提供兼容Ollama的接口，旨在将LightRAG模拟为Ollama聊天模型。这使得AI聊天机器人（如Open
WebUI）可以轻松访问LightRAG。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install &quot;lightrag-hku[api]&quot;</span><br><span class="line">cp env.example .env</span><br><span class="line">lightrag-server</span><br></pre></td></tr></table></figure>
<p>在此获取LightRAG docker镜像历史版本: <a href="https://github.com/HKUDS/LightRAG/pkgs/container/lightrag">LightRAG
Docker Images</a></p>
<p>安装 LightRAG Core</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install lightrag-hku</span><br></pre></td></tr></table></figure>
<h3 id="lightrag-服务器和-webui">LightRAG 服务器和 WebUI</h3>
<p><a href="https://github.com/HKUDS/LightRAG/blob/main/lightrag/api/README-zh.md">LightRAG/lightrag/api/README-zh.md
at main · HKUDS/LightRAG</a></p>
<p>LightRAG 服务器旨在提供 Web 界面和 API 支持。Web
界面便于文档索引、知识图谱探索和简单的 RAG 查询界面。</p>
<h4 id="使用环境变量来配置-lightrag-服务器">使用环境变量来配置 LightRAG
服务器。</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LLM_BINDING=openai</span><br><span class="line">LLM_MODEL=qwen3-max-preview</span><br><span class="line">LLM_BINDING_HOST=https://dashscope.aliyuncs.com/compatible-mode/v1</span><br><span class="line">LLM_BINDING_API_KEY=sk-</span><br><span class="line"></span><br><span class="line">EMBEDDING_BINDING=openai</span><br><span class="line">EMBEDDING_MODEL=text-embedding-v4</span><br><span class="line">EMBEDDING_DIM=1024</span><br><span class="line">EMBEDDING_BINDING_API_KEY=sk-</span><br><span class="line">EMBEDDING_BINDING_HOST=https://dashscope.aliyuncs.com/compatible-mode/v1</span><br><span class="line"></span><br><span class="line">############################</span><br><span class="line">### 数据存储选择</span><br><span class="line">############################</span><br><span class="line">### 默认存储（推荐用于小规模部署）</span><br><span class="line">LIGHTRAG_KV_STORAGE=JsonKVStorage</span><br><span class="line">LIGHTRAG_DOC_STATUS_STORAGE=JsonDocStatusStorage</span><br><span class="line">LIGHTRAG_GRAPH_STORAGE=NetworkXStorage</span><br><span class="line">LIGHTRAG_VECTOR_STORAGE=NanoVectorDBStorage</span><br><span class="line"></span><br><span class="line">### 图存储（推荐用于生产部署）</span><br><span class="line"># LIGHTRAG_GRAPH_STORAGE=Neo4JStorage</span><br><span class="line"># LIGHTRAG_GRAPH_STORAGE=MemgraphStorage</span><br><span class="line"></span><br><span class="line">### PostgreSQL</span><br><span class="line"># LIGHTRAG_KV_STORAGE=PGKVStorage</span><br><span class="line"># LIGHTRAG_DOC_STATUS_STORAGE=PGDocStatusStorage</span><br><span class="line"># LIGHTRAG_GRAPH_STORAGE=PGGraphStorage</span><br><span class="line"># LIGHTRAG_VECTOR_STORAGE=PGVectorStorage</span><br><span class="line"></span><br><span class="line">### PostgreSQL 配置</span><br><span class="line"># POSTGRES_HOST=localhost</span><br><span class="line"># POSTGRES_PORT=5432</span><br><span class="line"># POSTGRES_USER=您的用户名</span><br><span class="line"># POSTGRES_PASSWORD=&#x27;您的密码&#x27;</span><br><span class="line"># POSTGRES_DATABASE=您的数据库</span><br><span class="line"></span><br><span class="line">### Neo4j 配置</span><br><span class="line"># NEO4J_URI=neo4j+s://xxxxxxxx.databases.neo4j.io</span><br><span class="line"># NEO4J_USERNAME=neo4j</span><br><span class="line"># NEO4J_PASSWORD=&#x27;您的密码&#x27;</span><br><span class="line"># NEO4J_DATABASE=noe4j</span><br><span class="line"></span><br><span class="line">### Milvus 配置</span><br><span class="line"># MILVUS_URI=http://localhost:19530</span><br><span class="line"># MILVUS_DB_NAME=lightrag</span><br><span class="line"># MILVUS_USER=root</span><br><span class="line"># MILVUS_PASSWORD=您的密码</span><br></pre></td></tr></table></figure>
<h4 id="启动">启动</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lightrag-server</span><br></pre></td></tr></table></figure>
<p>这是因为每次启动时，LightRAG
Server会将.env文件中的环境变量加载至系统环境变量，且系统环境变量的设置具有更高优先级。</p>
<p>启动时可以通过命令行参数覆盖<code>.env</code>文件中的配置。常用的命令行参数包括：</p>
<ul>
<li><code>--host</code>：服务器监听地址（默认：0.0.0.0）</li>
<li><code>--port</code>：服务器监听端口（默认：9621）</li>
<li><code>--working-dir</code>：数据库持久化目录（默认：./rag_storage）</li>
<li><code>--input-dir</code>：上传文件存放目录（默认：./inputs）</li>
<li><code>--workspace</code>:
工作空间名称，用于逻辑上隔离多个LightRAG实例之间的数据（默认：空）</li>
</ul>
<h4 id="启动多个lightrag实例">启动多个LightRAG实例</h4>
<p>所有实例共享一套相同的<code>.env</code>配置文件，然后通过命令行参数来为每个实例指定不同的服务器监听端口和工作空间。你可以在同一个工作目录中通过不同的命令行参数启动多个LightRAG实例。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 启动实例1</span><br><span class="line">lightrag-server --port 9621 --workspace space1</span><br><span class="line"></span><br><span class="line"># 启动实例2</span><br><span class="line">lightrag-server --port 9622 --workspace space2</span><br></pre></td></tr></table></figure>
<h4 id="运行">运行</h4>
<figure>
<img src="/2025/09/21/%E5%AD%A6%E4%B9%A0/rag/lightrag/image-20250926162648415.png" alt="image-20250926162648415">
<figcaption aria-hidden="true">image-20250926162648415</figcaption>
</figure>
<figure>
<img src="/2025/09/21/%E5%AD%A6%E4%B9%A0/rag/lightrag/image-20250926162703167.png" alt="image-20250926162703167">
<figcaption aria-hidden="true">image-20250926162703167</figcaption>
</figure>
<figure>
<img src="/2025/09/21/%E5%AD%A6%E4%B9%A0/rag/lightrag/image-20250926162714883.png" alt="image-20250926162714883">
<figcaption aria-hidden="true">image-20250926162714883</figcaption>
</figure>
<h3 id="lightrag的数据隔离">LightRAG的数据隔离</h3>
<p>需要通过<strong>配置工作空间</strong>来实现数据隔离，否则不同实例的数据将会出现冲突并被破坏。</p>
<p>LightRAG 使用 4 种类型的存储用于不同目的：</p>
<ul>
<li>KV_STORAGE：llm 响应缓存、文本块、文档信息</li>
<li>VECTOR_STORAGE：实体向量、关系向量、块向量</li>
<li>GRAPH_STORAGE：实体关系图</li>
<li>DOC_STATUS_STORAGE：文档索引状态</li>
</ul>
<p>每种存储类型都有多种存储实现方式。LightRAG
Server默认的存储实现为内存数据库，数据通过文件持久化<strong>保存到WORKING_DIR目录</strong>。LightRAG还支持PostgreSQL、MongoDB、FAISS、Milvus、Qdrant、Neo4j、Memgraph和Redis等存储实现方式。</p>
<p>您可以通过环境变量选择存储实现。例如，在首次启动 API
服务器之前，您可以将以下环境变量设置为特定的存储实现名称：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LIGHTRAG_KV_STORAGE=PGKVStorage</span><br><span class="line">LIGHTRAG_VECTOR_STORAGE=PGVectorStorage</span><br><span class="line">LIGHTRAG_GRAPH_STORAGE=PGGraphStorage</span><br><span class="line">LIGHTRAG_DOC_STATUS_STORAGE=PGDocStatusStorage</span><br></pre></td></tr></table></figure>
<h3 id="文档和块处理逻辑说明">文档和块处理逻辑说明</h3>
<p>LightRAG
中的文档处理流程有些复杂，分为两个主要阶段：提取阶段（实体和关系提取）和合并阶段（实体和关系合并）。有两个关键参数控制流程并发性：并行处理的最大文件数（<code>MAX_PARALLEL_INSERT</code>）和最大并发
LLM 请求数（<code>MAX_ASYNC</code>）。工作流程描述如下：</p>
<ol type="1">
<li><code>MAX_ASYNC</code> 限制系统中并发 LLM
请求的总数，包括查询、提取和合并的请求。LLM
请求具有不同的优先级：查询操作优先级最高，其次是合并，然后是提取。</li>
<li><code>MAX_PARALLEL_INSERT</code>
控制提取阶段并行处理的文件数量。<code>MAX_PARALLEL_INSERT</code>建议设置为2～10之间，通常设置为
<code>MAX_ASYNC/3</code>，设置太大会导致合并阶段不同文档之间实体和关系重名的机会增大，降低合并阶段的效率。</li>
<li>在单个文件中，来自不同文本块的实体和关系提取是并发处理的，并发度由
<code>MAX_ASYNC</code> 设置。只有在处理完 <code>MAX_ASYNC</code>
个文本块后，系统才会继续处理同一文件中的下一批文本块。</li>
<li>当一个文件完成实体和关系提后，将进入实体和关系合并阶段。这一阶段也会并发处理多个实体和关系，其并发度同样是由
<code>MAX_ASYNC</code> 控制。</li>
<li>合并阶段的 LLM
请求的优先级别高于提取阶段，目的是让进入合并阶段的文件尽快完成处理，并让处理结果尽快更新到向量数据库中。</li>
<li>为防止竞争条件，合并阶段会避免并发处理同一个实体或关系，当多个文件中都涉及同一个实体或关系需要合并的时候他们会串行执行。</li>
<li>每个文件在流程中被视为一个原子处理单元。只有当其所有文本块都完成提取和合并后，文件才会被标记为成功处理。如果在处理过程中发生任何错误，整个文件将被标记为失败，并且必须重新处理。</li>
<li>当由于错误而重新处理文件时，由于 LLM
缓存，先前处理的文本块可以快速跳过。尽管 LLM
缓存在合并阶段也会被利用，但合并顺序的不一致可能会限制其在此阶段的有效性。</li>
<li>如果在提取过程中发生错误，系统不会保留任何中间结果。如果在合并过程中发生错误，已合并的实体和关系可能会被保留；当重新处理同一文件时，重新提取的实体和关系将与现有实体和关系合并，而不会影响查询结果。</li>
<li>在合并阶段结束时，所有实体和关系数据都会在向量数据库中更新。如果此时发生错误，某些更新可能会被保留。但是，下一次处理尝试将覆盖先前结果，确保成功重新处理的文件不会影响未来查询结果的完整性。</li>
</ol>
<h3 id="section"></h3>
<p>大家好，我想请教一下如何更好的使用这个项目，我现在处理的好慢，昨天从晚上十点跑到今天早上7点，只处理好33份文件[苦涩]我看日志，一份47页的pdf花了一个小时（mineru处理了十分钟）。
我自己总结下是有以下几个
1.我应该使用milvus和neo4j存储，而不是图方便存本地
2.设置一下并发，而不是每次只处理一个文件
3.不对图片进行处理了（感觉对我当前的场景没有必要）
针对第一点，我想问一下，存储到数据库是影响检索速率还是存储（我个人感觉是不是只影响检索啊）</p>
<p>Embedding模型应该本地部署，这样速度才比较快。一个文本块的Embedding速度在本地是毫秒级别的。调用云端API通常是秒级别的。
没有必要都用RagAnything来处理，先试一下用LightRAG来处理看一把速度如何。日后LightRAG会进程RagAnything，到时候可以灵活地指定每个文件的处理方式。
LightRAG的处理速度组要受到LLM的影响，与使用什么存储关系不是十分大。
LLM每秒能够输出的Tokens数量和支持的最大并发数决定了文档处理的速度。
例如一个LLM在8个并发的时候能够达到 400Tokens/秒
的峰值，预计处理速度达到15～20秒处理一个文本块。文本块的处理速度与识别出来的实体数量和实体关系需要合并的数量是有关的，因此不同文档是有所不同的。
可以用以上经验值来评估一下自己的系统处理速度是否合理。</p>
<h3 id="实现代码">实现代码</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class LightRAGStorage:</span><br><span class="line">    &quot;&quot;&quot;LightRAG存储和检索类</span><br><span class="line"></span><br><span class="line">    支持多种存储后端：</span><br><span class="line">    - KV存储: PostgreSQL</span><br><span class="line">    - 文档状态存储: PostgreSQL</span><br><span class="line">    - 图存储: Neo4j</span><br><span class="line">    - 向量存储: Milvus</span><br><span class="line"></span><br><span class="line">    使用workspace实现数据隔离</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, workspace: str = &quot;default&quot;):</span><br><span class="line">        &quot;&quot;&quot;初始化LightRAG存储</span><br><span class="line"></span><br><span class="line">        Args:</span><br><span class="line">            workspace: 工作空间名称，用于数据隔离</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.workspace = workspace</span><br><span class="line"></span><br><span class="line">        # 加载环境变量</span><br><span class="line">        load_dotenv()</span><br><span class="line"></span><br><span class="line">        # 使用文件同级的 lightrag_storage 目录</span><br><span class="line">        self.working_dir = os.path.join(os.path.dirname(__file__), &quot;lightrag_storage&quot;)</span><br><span class="line"></span><br><span class="line">        self.rag: Optional[LightRAG] = None</span><br><span class="line"></span><br><span class="line">        # 确保工作目录存在</span><br><span class="line">        os.makedirs(self.working_dir, exist_ok=True)</span><br><span class="line"></span><br><span class="line">    async def _get_llm_model_func(self):</span><br><span class="line">        &quot;&quot;&quot;LLM模型函数&quot;&quot;&quot;</span><br><span class="line">        async def llm_model_func(</span><br><span class="line">            prompt,</span><br><span class="line">            system_prompt=None,</span><br><span class="line">            history_messages=[],</span><br><span class="line">            keyword_extraction=False,</span><br><span class="line">            **kwargs</span><br><span class="line">        ) -&gt; str:</span><br><span class="line">            return await openai_complete_if_cache(</span><br><span class="line">                model=os.getenv(&quot;DASHSCOPE_MODEL&quot;, &quot;qwen-max&quot;),</span><br><span class="line">                prompt=prompt,</span><br><span class="line">                system_prompt=system_prompt,</span><br><span class="line">                history_messages=history_messages,</span><br><span class="line">                api_key=os.getenv(&quot;DASHSCOPE_API_KEY&quot;),</span><br><span class="line">                base_url=os.getenv(&quot;DASHSCOPE_API_BASE&quot;, &quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;),</span><br><span class="line">                **kwargs</span><br><span class="line">            )</span><br><span class="line">        return llm_model_func</span><br><span class="line"></span><br><span class="line">    async def _get_embedding_func(self):</span><br><span class="line">        &quot;&quot;&quot;嵌入模型函数&quot;&quot;&quot;</span><br><span class="line">        async def embedding_func(texts: List[str]) -&gt; np.ndarray:</span><br><span class="line">            return await openai_embed(</span><br><span class="line">                texts,</span><br><span class="line">                model=os.getenv(&quot;DASHSCOPE_EMBEDDING_MODEL&quot;, &quot;text-embedding-v4&quot;),</span><br><span class="line">                api_key=os.getenv(&quot;DASHSCOPE_API_KEY&quot;),</span><br><span class="line">                base_url=os.getenv(&quot;DASHSCOPE_API_BASE&quot;, &quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;)</span><br><span class="line">            )</span><br><span class="line">        return embedding_func</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    async def initialize(self) -&gt; None:</span><br><span class="line">        &quot;&quot;&quot;初始化LightRAG实例&quot;&quot;&quot;</span><br><span class="line">        if self.rag is not None:</span><br><span class="line">            return</span><br><span class="line"></span><br><span class="line">        # 获取模型函数</span><br><span class="line">        llm_model_func = await self._get_llm_model_func()</span><br><span class="line">        embedding_func = await self._get_embedding_func()</span><br><span class="line"></span><br><span class="line">        # 存储配置 - 统一使用字符串方式，让LightRAG自动处理</span><br><span class="line">        # 图存储配置</span><br><span class="line">        graph_storage = os.getenv(&quot;LIGHTRAG_GRAPH_STORAGE&quot;, &quot;Neo4JStorage&quot;)</span><br><span class="line"></span><br><span class="line">        # KV存储配置</span><br><span class="line">        kv_storage = os.getenv(&quot;LIGHTRAG_KV_STORAGE&quot;, &quot;PGKVStorage&quot;)</span><br><span class="line"></span><br><span class="line">        # 文档状态存储配置</span><br><span class="line">        doc_status_storage = os.getenv(&quot;LIGHTRAG_DOC_STATUS_STORAGE&quot;, &quot;PGDocStatusStorage&quot;)</span><br><span class="line"></span><br><span class="line">        # 向量存储配置</span><br><span class="line">        vector_storage = os.getenv(&quot;LIGHTRAG_VECTOR_STORAGE&quot;, &quot;MilvusVectorDBStorage&quot;)</span><br><span class="line"></span><br><span class="line">        # 创建LightRAG实例</span><br><span class="line">        self.rag = LightRAG(</span><br><span class="line">            working_dir=self.working_dir,</span><br><span class="line">            embedding_func=EmbeddingFunc(</span><br><span class="line">                func=embedding_func,</span><br><span class="line">                embedding_dim=int(os.getenv(&quot;EMBEDDING_DIM&quot;, 1024))</span><br><span class="line">            ),</span><br><span class="line">            llm_model_func=llm_model_func,</span><br><span class="line">            workspace=self.workspace,</span><br><span class="line">            graph_storage=graph_storage,</span><br><span class="line">            kv_storage=kv_storage,</span><br><span class="line">            doc_status_storage=doc_status_storage,</span><br><span class="line">            vector_storage=vector_storage</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 初始化存储</span><br><span class="line">        await self.rag.initialize_storages()</span><br><span class="line">        await initialize_pipeline_status()</span><br><span class="line"></span><br><span class="line">    async def insert_text(self, text: str) -&gt; None:</span><br><span class="line">        &quot;&quot;&quot;插入文本到LightRAG</span><br><span class="line"></span><br><span class="line">        Args:</span><br><span class="line">            text: 要插入的文本内容</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if self.rag is None:</span><br><span class="line">            await self.initialize()</span><br><span class="line"></span><br><span class="line">        await self.rag.ainsert(text)</span><br><span class="line"></span><br><span class="line">    async def insert_texts(self, texts: List[str]) -&gt; None:</span><br><span class="line">        &quot;&quot;&quot;批量插入文本</span><br><span class="line"></span><br><span class="line">        Args:</span><br><span class="line">            texts: 文本列表</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        for text in texts:</span><br><span class="line">            await self.insert_text(text)</span><br><span class="line"></span><br><span class="line">    async def query(</span><br><span class="line">        self,</span><br><span class="line">        query: str,</span><br><span class="line">        mode: str = &quot;hybrid&quot;,</span><br><span class="line">        **kwargs</span><br><span class="line">    ) -&gt; str:</span><br><span class="line">        &quot;&quot;&quot;执行查询</span><br><span class="line"></span><br><span class="line">        Args:</span><br><span class="line">            query: 查询文本</span><br><span class="line">            mode: 查询模式 (&quot;naive&quot;, &quot;local&quot;, &quot;global&quot;, &quot;hybrid&quot;)</span><br><span class="line">            **kwargs: 其他查询参数</span><br><span class="line"></span><br><span class="line">        Returns:</span><br><span class="line">            查询结果</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if self.rag is None:</span><br><span class="line">            await self.initialize()</span><br><span class="line"></span><br><span class="line">        return await self.rag.aquery(</span><br><span class="line">            query,</span><br><span class="line">            param=QueryParam(mode=mode, **kwargs)</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV1bSaGzJEdv?buvid=XX7932A7E9DD8A1DA92D4974AB535749A9B44&amp;from_spmid=tm.recommend.0.0&amp;is_story_h5=false&amp;mid=25yhOI1fPeVYa5V16BFcAw%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=3e2dd1ec-b589-458b-849b-c2e7f8b4468a&amp;share_source=QQ&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1758418948&amp;unique_k=6aEPhnm&amp;up_id=1606629306&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">通过实际案例拆解Light
RAG，构建可视化知识图谱，解析Graph
RAG的运行原理和关键概念（一）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1zoKuzoENM/?spm_id_from=333.337.search-card.all.click">AI知识图谱
GraphRAG 是怎么回事？_哔哩哔哩_bilibili</a></p>
<p><a href="https://github.com/HKUDS/LightRAG/blob/main/README-zh.md">LightRAG/README-zh.md
在主 ·香港科技大学/LightRAG — LightRAG/README-zh.md at main ·
HKUDS/LightRAG</a></p>
]]></content>
      <categories>
        <category>rag</category>
      </categories>
      <tags>
        <tag>rag</tag>
      </tags>
  </entry>
  <entry>
    <title>负载均衡（Load Balancing）</title>
    <url>/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
    <content><![CDATA[<h2 id="什么是负载均衡">什么是负载均衡</h2>
<p>负载均衡本质上是一个<strong>反向代理（Reverse
Proxy）*<em>或*</em>数据包转发器</strong>。它位于客户端（Client）和后端服务集群（Upstream
Servers）之间，通过向外暴露一个<strong>虚拟IP（VIP）</strong>，屏蔽了后端具体的网络拓扑结构。</p>
<h2 id="为什么我们需要负载均衡">为什么我们需要负载均衡？</h2>
<p>在计算机系统中，使用负载均衡主要有三个巨大的好处：</p>
<ol type="1">
<li><strong>高可用性（High Availability / Reliability）：</strong>
如果有服务器坏了（宕机），负载均衡器会立刻发现，并停止向它发送请求，转而分发给其他健康的服务器。这样用户就感觉不到服务中断。</li>
<li><strong>高性能（Performance）：</strong>
通过将流量分摊，避免单一服务器过载，从而保证网页打开的速度和响应时间。</li>
<li><strong>可扩展性（Scalability）：</strong>
如果业务突然增长（比如双11大促），你可以随时增加几台新服务器进来，负载均衡器会自动开始给它们分配任务，非常灵活。</li>
</ol>
<figure>
<img src="/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/image-20251217201102150.png" alt="image-20251217201102150">
<figcaption aria-hidden="true">image-20251217201102150</figcaption>
</figure>
<h2 id="它是怎么分配任务的常见算法">它是怎么分配任务的？（常见算法）</h2>
<p>负载均衡器并不是“瞎”分配的，它有一套策略（算法）来决定把请求给谁。最常见的有这几种：</p>
<ul>
<li><strong>轮询（Round Robin）：</strong>
最简单的策略。按顺序一个一个来：请求1给服务器A，请求2给服务器B，请求3给服务器C，请求4又回到服务器A。</li>
<li><strong>最小连接数（Least Connections）：</strong>
比较智能。它会看谁现在手头的活儿最少（连接数最少），就把新任务给谁。适合某些任务处理时间长短不一的场景。</li>
<li><strong>源地址哈希（IP Hash）：</strong>
为了保证“从一而终”。它保证来自同一个 IP
地址的用户，总是被分配到同一台服务器上。这在需要保持登录状态（Session）的场景中很有用。</li>
</ul>
<h2 id="osi-模型open-systems-interconnection-model">OSI 模型（Open
Systems Interconnection Model）</h2>
<p><a href="https://www.bilibili.com/video/BV1EU4y1v7ju/?spm_id_from=333.1387.0.0&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">互联网数据传输原理
｜OSI七层网络参考模型_哔哩哔哩_bilibili</a></p>
<h4 id="应用层-application-layer"><strong>7. 应用层 (Application
Layer)</strong></h4>
<ul>
<li><strong>作用：</strong>
直接与用户打交道，为应用程序提供网络服务接口。</li>
<li><strong>关键点：</strong> 这是用户“看得到”的一层。</li>
<li><strong>常见协议：</strong> HTTP (网页), FTP (文件), SMTP (邮件),
DNS (域名)。</li>
<li><strong>数据单元：</strong> Data (数据)</li>
</ul>
<h4 id="表示层-presentation-layer"><strong>6. 表示层 (Presentation
Layer)</strong></h4>
<ul>
<li><strong>作用：</strong>
数据的“翻译官”。负责数据的格式化、加密/解密、压缩/解压缩。</li>
<li><strong>关键点：</strong>
确保一个系统的应用层发送的数据能被另一个系统的应用层读取。比如把 JSON
对象转成二进制，或者处理 SSL/TLS 加密。</li>
<li><strong>常见格式：</strong> JPEG, ASCII, EBCDIC, SSL/TLS。</li>
</ul>
<h4 id="会话层-session-layer"><strong>5. 会话层 (Session
Layer)</strong></h4>
<ul>
<li><strong>作用：</strong>
建立、管理和终止应用程序之间的“会话”（Session）。</li>
<li><strong>关键点：</strong>
它负责断点续传、同步点。比如你从网盘下载文件，断网了，下次能接着下，就是会话层的功劳。</li>
<li><strong>常见协议：</strong> RPC, SQL。</li>
</ul>
<h4 id="传输层-transport-layer-关键层级"><strong>4. 传输层 (Transport
Layer)</strong> —— <em>（关键层级）</em></h4>
<ul>
<li><strong>作用：</strong>
负责端到端（End-to-End）的数据传输，区分具体的应用程序（通过端口号）。</li>
<li><strong>关键点：</strong>
<strong>负载均衡中的“四层负载”就在这里</strong>。它决定了数据是“可靠传输”（TCP）还是“快速传输”（UDP）。</li>
<li><strong>核心设备/概念：</strong> 端口 (Port), 负载均衡器 (L4)。</li>
<li><strong>常见协议：</strong> <strong>TCP</strong> (可靠, 三次握手),
<strong>UDP</strong> (快速, 直播/游戏)。</li>
<li><strong>数据单元：</strong> Segment (段)</li>
</ul>
<h4 id="网络层-network-layer-关键层级"><strong>3. 网络层 (Network
Layer)</strong> —— <em>（关键层级）</em></h4>
<ul>
<li><strong>作用：</strong>
负责地址寻址和路由选择（Routing）。决定数据包如何从从源地址到达目的地址（跨网络）。</li>
<li><strong>关键点：</strong> <strong>IP
地址</strong>在这里起作用。路由器（Router）工作在这一层。</li>
<li><strong>常见协议：</strong> <strong>IP</strong>, ICMP (Ping), OSPF,
BGP。</li>
<li><strong>数据单元：</strong> Packet (包)</li>
</ul>
<h4 id="数据链路层-data-link-layer"><strong>2. 数据链路层 (Data Link
Layer)</strong></h4>
<ul>
<li><strong>作用：</strong>
负责节点到节点（Node-to-Node）的传输，处理物理寻址。</li>
<li><strong>关键点：</strong> <strong>MAC
地址</strong>在这里起作用。交换机（Switch）通常工作在这一层。它负责在同一局域网内把数据帧发给对的人。</li>
<li><strong>常见协议：</strong> Ethernet (以太网), VLAN, Wi-Fi
(802.11)。</li>
<li><strong>数据单元：</strong> Frame (帧)</li>
</ul>
<h4 id="物理层-physical-layer"><strong>1. 物理层 (Physical
Layer)</strong></h4>
<ul>
<li><strong>作用：</strong> 传输比特流（0 和 1）。</li>
<li><strong>关键点：</strong>
真正的物理介质。把数字信号转换成电信号、光信号或无线电波。</li>
<li><strong>核心设备：</strong> 网线, 光纤, 集线器 (Hub), 中继器。</li>
<li><strong>数据单元：</strong> Bit (比特)</li>
</ul>
<h2 id="tcpip-协议栈">TCP/IP 协议栈</h2>
<h3 id="为什么叫-tcpip">1. 为什么叫 TCP/IP？</h3>
<p>虽然名字里只有 TCP 和 IP，但它其实是一个<strong>协议族（Protocol
Suite）</strong>，包含了几十个协议。
之所以用这两个命名，是因为它们最重要：</p>
<ul>
<li><strong>IP (Internet Protocol)：</strong>
负责把数据包送到目的地（解决“路怎么走”）。</li>
<li><strong>TCP (Transmission Control Protocol)：</strong>
负责把数据可靠地传输（解决“东西别丢了”）。</li>
</ul>
<hr>
<h3 id="tcpip-的四层模型与-osi-的映射">2. TCP/IP 的四层模型（与 OSI
的映射）</h3>
<p>TCP/IP 更加务实，它将 OSI 的 7 层模型压缩为了 <strong>4
层</strong>。</p>
<p>我们由上至下来看：</p>
<h4 id="第一层应用层-application-layer"><strong>第一层：应用层
(Application Layer)</strong></h4>
<ul>
<li><strong>对应 OSI：</strong> 应用层 + 表示层 + 会话层</li>
<li><strong>功能：</strong> 处理特定的应用程序细节。</li>
<li><strong>常见协议：</strong>
<ul>
<li><strong>HTTP/HTTPS:</strong> 浏览网页。</li>
<li><strong>SSH:</strong> 远程登录服务器。</li>
<li><strong>DNS:</strong> 域名解析（把 <code>google.com</code> 变成 IP
地址）。</li>
<li><strong>FTP:</strong> 文件传输。</li>
</ul></li>
</ul>
<h4 id="第二层传输层-transport-layer"><strong>第二层：传输层 (Transport
Layer)</strong></h4>
<ul>
<li><strong>对应 OSI：</strong> 传输层</li>
<li><strong>功能：</strong>
提供端到端（Host-to-Host）的通信服务。它只关心两台主机上的<strong>进程</strong>（通过端口号区分），而不关心中间经过了多少路由器。</li>
<li><strong>两大主角：</strong>
<ul>
<li><strong>TCP:</strong> 可靠、面向连接（打电话）。</li>
<li><strong>UDP:</strong> 不可靠、无连接（大喇叭广播）。</li>
</ul></li>
</ul>
<h4 id="第三层网络层-internet-layer"><strong>第三层：网络层 (Internet
Layer)</strong></h4>
<ul>
<li><strong>对应 OSI：</strong> 网络层</li>
<li><strong>功能：</strong>
处理数据包在网络中的路由选择。这是互联网的<strong>核心</strong>。</li>
<li><strong>核心协议：</strong>
<ul>
<li><strong>IP (IPv4/IPv6):</strong> 核心载体。</li>
<li><strong>ICMP:</strong> 比如 <code>ping</code>
命令就在这里工作，用来报错或探测。</li>
<li><strong>ARP:</strong> 地址解析协议（知道 IP 找 MAC 地址）。</li>
</ul></li>
</ul>
<h4 id="第四层网络接口层-network-interface-layer"><strong>第四层：网络接口层
(Network Interface Layer)</strong></h4>
<ul>
<li><strong>对应 OSI：</strong> 数据链路层 + 物理层</li>
<li><strong>功能：</strong> 处理与物理硬件的交互。TCP/IP
标准对这一层并没有严格定义，只要能传 IP 数据包就行。</li>
<li><strong>常见技术：</strong> 以太网 (Ethernet)、Wi-Fi。</li>
</ul>
<h2 id="常见的负载均衡分类">常见的负载均衡分类</h2>
<p>你可能会听到“四层负载”和“七层负载”这样的术语，它们的区别在于“指挥”的层级不同：</p>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 46%">
<col style="width: 20%">
</colgroup>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>对应层级 (OSI模型)</strong></th>
<th><strong>特点</strong></th>
<th><strong>典型代表</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>四层负载均衡 (L4)</strong></td>
<td>传输层 (TCP/UDP)</td>
<td><strong>速度快</strong>。只看 IP
和端口号，不看内容，直接转发数据包。</td>
<td>LVS, F5 (硬件)</td>
</tr>
<tr>
<td><strong>七层负载均衡 (L7)</strong></td>
<td>应用层 (HTTP/HTTPS)</td>
<td><strong>更智能</strong>。它能看懂 URL、Cookie、头部信息。比如把
<code>/image</code> 的请求分给图片服务器，把 <code>/api</code>
的请求分给应用服务器。</td>
<td><strong>Nginx</strong>, HAProxy, AWS ALB</td>
</tr>
</tbody>
</table>
<h2 id="正向代理和反向代理">正向代理和反向代理</h2>
<h4 id="正向代理-forward-proxy-代表客户端"><strong>正向代理 (Forward
Proxy)</strong> —— 代表<strong>客户端</strong></h4>
<p>这是大家通常说的“挂代理”或“梯子”。</p>
<ul>
<li><strong>场景：</strong> 你（客户端）想访问
Google，但直接访问不了。</li>
<li><strong>做法：</strong> 你连上一个代理服务器，对它说：“帮我访问
Google”。代理服务器去访问 Google，把结果拿回来给你。</li>
<li><strong>特点：</strong> Google
<strong>不知道</strong>是你访问的，它只看到了代理服务器。</li>
<li><strong>作用：</strong>
<strong>隐藏客户端身份</strong>，突破访问限制。</li>
</ul>
<h4 id="反向代理-reverse-proxy-代表服务端"><strong>反向代理 (Reverse
Proxy)</strong> —— 代表<strong>服务端</strong></h4>
<p>这是互联网公司部署在自家门口的“门卫”。</p>
<ul>
<li><strong>场景：</strong> 你（客户端）访问
<code>www.baidu.com</code>。</li>
<li><strong>做法：</strong>
你的请求其实并没有直接到达百度的核心数据库或应用服务器，而是先到达了百度的<strong>反向代理服务器</strong>。这个代理服务器决定把你的请求转给内部的哪台机器处理，处理完后再把结果给你。</li>
<li><strong>特点：</strong>
你（客户端）<strong>不知道</strong>具体是哪台内部服务器为你服务的，你只看到了反向代理。</li>
<li><strong>作用：</strong>
<strong>隐藏服务端身份</strong>，保护内部网络。</li>
</ul>
<h2 id="常见问题">常见问题</h2>
<h3 id="如何解决多个服务器session一致性的问题">如何解决多个服务器session一致性的问题</h3>
<p>这是一个非常经典的分布式系统架构问题。</p>
<p>在单体架构（一台服务器）中，Session
保存在服务器的<strong>内存</strong>里，这没问题。
但在集群环境（多台服务器）下，默认情况是这样的：</p>
<ol type="1">
<li>用户在 <strong>服务器 A</strong> 登录，Session 存在 A
的内存里。</li>
<li>下一次请求，负载均衡器把用户分发到了 <strong>服务器
B</strong>。</li>
<li><strong>服务器 B</strong> 的内存里没有这个
Session，于是判断用户“未登录”，强制踢下线。</li>
</ol>
<p>为了解决这个问题，业界主要有四种成熟的方案，我会按<strong>推荐程度从低到高</strong>为您介绍：</p>
<h4 id="方案一会话保持-sticky-sessions-session-affinity">1.
方案一：会话保持 (Sticky Sessions / Session Affinity)</h4>
<p><strong>原理：</strong> 让负载均衡器“记住”用户。
如果不改变代码，这是最简单的改法。我们在负载均衡器（如
Nginx）上配置策略，保证<strong>同一个 IP
的请求永远只发给同一台服务器</strong>。</p>
<ul>
<li><strong>实现方式：</strong> Nginx 的 <code>ip_hash</code>
策略。</li>
<li><strong>优点：</strong>
<ul>
<li>简单，不需要修改任何应用程序代码。</li>
<li>不需要引入额外的存储组件。</li>
</ul></li>
<li><strong>缺点：</strong>
<ul>
<li><strong>故障丢失：</strong> 如果这台服务器宕机，上面所有用户的
Session 全部丢失。</li>
<li><strong>负载不均：</strong> 如果某个公司几千人都用同一个公网 IP
出口，这些请求会全部压在同一台服务器上，导致负载均衡失效。</li>
</ul></li>
</ul>
<h4 id="方案二session-复制-session-replication">2. 方案二：Session 复制
(Session Replication)</h4>
<p><strong>原理：</strong> 让服务器之间“互通有无”。 当服务器 A
产生了一个 Session，它通过网络广播把这个 Session 同步给服务器
B、C、D。</p>
<ul>
<li><strong>实现方式：</strong> Tomcat 集群自带的 Session
复制功能。</li>
<li><strong>优点：</strong>
<ul>
<li>服务器宕机不会丢失 Session（因为其他机器也有）。</li>
</ul></li>
<li><strong>缺点（致命）：</strong>
<ul>
<li><strong>性能极差：</strong> 每次存取 Session
都要广播，网络风暴严重。</li>
<li><strong>扩展性差：</strong>
随着服务器数量增加，同步数据的成本呈指数级上升。<strong>通常不建议在生产环境使用。</strong></li>
</ul></li>
</ul>
<h4 id="方案三集中式-session-存储-centralized-session-storage-最推荐">3.
方案三：集中式 Session 存储 (Centralized Session Storage) ——
<strong>【最推荐】</strong></h4>
<p><strong>原理：</strong> Session 也不存 A，也不存
B，而是存到一个公共的“保险柜”里。
所有的服务器在处理请求时，都去这个公共的地方读写 Session。</p>
<ul>
<li><strong>实现方式：</strong> 使用 <strong>Redis</strong> 或 Memcached
作为 Session 仓库。
<ul>
<li>Spring Boot 项目中只需引入 <code>spring-session-data-redis</code>
依赖，几行配置就能搞定。</li>
</ul></li>
<li><strong>优点：</strong>
<ul>
<li><strong>无状态化：</strong>
应用服务器变得“无状态”（Stateless），可以随意增加或减少服务器，不影响用户体验。</li>
<li><strong>高可用：</strong>
某台应用服务器挂了，用户被切到另一台，Session 依然在 Redis
里，用户无感知。</li>
<li><strong>速度快：</strong> Redis 是基于内存的，读写速度极快。</li>
</ul></li>
<li><strong>缺点：</strong>
<ul>
<li>引入了新的组件（Redis），需要保证 Redis 的高可用（如使用 Redis
Cluster）。</li>
</ul></li>
</ul>
<h4 id="方案四客户端存储-token-jwt-现代架构主流">4. 方案四：客户端存储
(Token / JWT) —— <strong>【现代架构主流】</strong></h4>
<p><strong>原理：</strong> 服务器根本不存 Session。
服务器生成一个加密的令牌（Token），交给客户端（浏览器/App）自己保存。客户端每次请求都带着这个令牌，服务器解密验证身份。</p>
<ul>
<li><strong>实现方式：</strong> <strong>JWT (JSON Web
Token)</strong>。</li>
<li><strong>优点：</strong>
<ul>
<li><strong>极致的服务器无状态：</strong>
服务器不需要查数据库，也不需要查 Redis，只要通过 CPU 计算验签即可。</li>
<li><strong>适合微服务：</strong> 一个 Token
可以在多个不同的微服务之间通用。</li>
</ul></li>
<li><strong>缺点：</strong>
<ul>
<li><strong>不可撤销：</strong> 一旦 Token
发出去，在过期前都有效。如果用户想改密码或被封号，服务器很难强制让 Token
立刻失效（除非引入黑名单机制，但这又变回了方案三）。</li>
<li><strong>带宽占用：</strong> Token 通常比 Session ID
长，每次请求都要带，稍微增加一点流量。</li>
</ul></li>
</ul>
<h3 id="如何保证负载均衡器的高可用性">如何保证负载均衡器的高可用性</h3>
<p>如果我们只部署了一个负载均衡器（比如一台
Nginx），虽然它帮后端服务器分担了压力，但它自己就成了整个系统的<strong>单点故障（SPOF
- Single Point of Failure）</strong>。一旦这台 Nginx
宕机，整个网站就彻底瘫痪了，后端有再多服务器也没用。</p>
<p>为了解决这个问题，业界通用的标准方案是：<strong>高可用架构（High
Availability
Architecture）</strong>，核心思想是<strong>“冗余”</strong>和<strong>“自动故障转移（Failover）”</strong>。</p>
<p>最主流的实现方式有以下几种：</p>
<h4 id="主备模式-active-passive-最经典方案">1. 主备模式 (Active-Passive)
—— 最经典方案</h4>
<p>这是最简单、最常用，也是中小企业首选的方案。通常使用
<strong>Keepalived</strong> 软件配合 <strong>VRRP 协议</strong>
来实现。</p>
<h4 id="架构设计"><strong>架构设计：</strong></h4>
<ul>
<li><strong>准备两台 LB：</strong>
一台作为<strong>主节点（Master）</strong>，一台作为<strong>备节点（Backup）</strong>。</li>
<li><strong>VIP（虚拟 IP）：</strong> 两台机器对外只暴露一个<strong>虚拟
IP (Virtual IP)</strong>。正常情况下，这个 VIP
绑定在主节点上。用户只访问这个 VIP。</li>
<li><strong>心跳检测：</strong>
备节点会每隔几秒向主节点发送“心跳包”确认它还活着。</li>
</ul>
<h4 id="工作流程"><strong>工作流程：</strong></h4>
<ol type="1">
<li><strong>正常状态：</strong> 所有的流量都流向拥有 VIP
的主节点，备节点闲置待命。</li>
<li><strong>故障发生：</strong>
主节点挂了（比如断电、进程崩溃），备节点收不到心跳包。</li>
<li><strong>IP 漂移 (IP Failover)：</strong> 备节点立刻通过 VRRP 协议把
VIP“抢”过来，绑定到自己身上。</li>
<li><strong>恢复：</strong>
对用户来说，只是网络卡顿了一瞬间，请求马上就能被备节点处理，服务未中断。</li>
</ol>
<ul>
<li><strong>优点：</strong> 简单稳定，配置方便。</li>
<li><strong>缺点：</strong>
资源有一半是浪费的（备节点平时不干活）。</li>
</ul>
<h4 id="双主模式-active-active-高性能方案">2. 双主模式 (Active-Active)
—— 高性能方案</h4>
<p>如果你觉得有一台机器闲置太浪费，可以使用双主模式。</p>
<h4 id="架构设计-1"><strong>架构设计：</strong></h4>
<ul>
<li><strong>准备两台 LB：</strong> 这里的两台都是 Master。</li>
<li><strong>两个 VIP：</strong> 配置两个不同的虚拟 IP（VIP_A 和
VIP_B）。</li>
<li><strong>DNS 轮询：</strong>
在域名解析（DNS）层面，将域名同时解析到这两个 VIP 上。</li>
</ul>
<h4 id="工作流程-1"><strong>工作流程：</strong></h4>
<ul>
<li>用户 A 解析到了 VIP_A，流量走了 LB 1。</li>
<li>用户 B 解析到了 VIP_B，流量走了 LB 2。</li>
<li><strong>互为备份：</strong> LB 1 是 LB 2 的备用，LB 2 也是 LB 1
的备用。</li>
<li><strong>故障发生：</strong> 如果 LB 1 挂了，Keepalived 会把 VIP_A
漂移到 LB 2 上。此时 LB 2 身上同时挂着 VIP_A 和
VIP_B，独自承担所有流量。</li>
<li><strong>优点：</strong> 资源利用率最大化，两台机器都在工作。</li>
<li><strong>缺点：</strong>
架构稍复杂，需要设计好容量，确保一台机器能扛住两倍的流量（万一另一台挂了）。</li>
</ul>
<h4 id="全局负载均衡-gslb-异地多活">3. 全局负载均衡 (GSLB) ——
异地多活</h4>
<p>如果整个机房（数据中心）都停电了或者光缆被挖断了，上面的方法都得死。这时候需要更高层级的<strong>DNS
负载均衡</strong>。</p>
<ul>
<li><strong>原理：</strong> 在 DNS 服务器上配置策略。</li>
<li><strong>实现：</strong>
<ul>
<li>北京的用户解析到北京机房的负载均衡器 IP。</li>
<li>上海的用户解析到上海机房的负载均衡器 IP。</li>
</ul></li>
<li><strong>高可用：</strong> 如果北京机房挂了，DNS
服务器检测到后，会自动把北京用户的流量引导到上海机房。</li>
</ul>
<h2 id="nginx">Nginx</h2>
<p><a href="https://www.bilibili.com/video/BV1TZ421b7SD?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Nginx入门必须懂3大功能配置
- Web服务器/反向代理/负载均衡_哔哩哔哩_bilibili</a></p>
<h2 id="caddy">Caddy</h2>
<p><a href="https://www.bilibili.com/video/BV1z5w6ekE1L/?spm_id_from=333.788.recommend_more_video.2&amp;trackid=web_related_0.router-related-2206146-n6d7k.1765975473930.921&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">全自动HTTPS加密，开箱即用，Caddy基础入门，反向代理，负载均衡，网站托管全流程_哔哩哔哩_bilibili</a></p>
<h2 id="参考资料">参考资料</h2>
<p><a href="https://www.bilibili.com/video/BV1e92eBTEkL/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">什么是负载均衡？不就是加台服务器么？_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>后端相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>rag增强技术汇总</title>
    <url>/2025/09/08/%E5%AD%A6%E4%B9%A0/rag/rag%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<h3 id="各类-rag-增强技术">各类 RAG 增强技术</h3>
<p><a href="https://milvus.io/docs/zh/how_to_enhance_your_rag.md">如何提高 RAG
管道的性能 | Milvus 文档</a></p>
<p>可以通过此<a href="https://github.com/milvus-io/bootcamp/tree/master/bootcamp/RAG/advanced_rag">GitHub
链接</a>获得本文所列主要方法的简单实现。</p>
<p>我们可以根据 RAG 管道各阶段的作用对不同的 RAG 增强方法进行分类。</p>
<ul>
<li><strong>查询增强</strong>：修改和操作 RAG
输入的查询过程，以便更好地表达或处理查询意图。</li>
<li><strong>增强索引</strong>：使用多分块、分步索引或多向索引等技术优化分块索引的创建。</li>
<li><strong>检索器增强</strong>：在检索过程中应用优化技术和策略。</li>
<li><strong>生成器增强</strong>：在为 LLM
生成提示时调整和优化提示，以提供更好的响应。</li>
<li><strong>增强 RAG 管道</strong>：在整个 RAG
管道中动态切换流程，包括使用 Agents 或工具来优化 RAG
管道中的关键步骤。</li>
</ul>
<p>接下来，我们将介绍每个类别下的具体方法。</p>
<h3 id="查询增强">查询增强</h3>
<p>共有四种方式：<strong>假设问题、假设文档嵌入、子查询和回溯提示</strong>。接下来我将选取几个具体说明。</p>
<h4 id="hyde假设文档嵌入">HyDE（假设文档嵌入）</h4>
<p>HyDE 是假设文档嵌入的缩写。它利用 LLM
制作一个<em><strong>“假设文档*</strong>”或</em><strong>虚假*</strong>答案，以回应没有上下文信息的用户查询。然后，这个假答案会被转换成向量嵌入，并用于查询向量数据库中最相关的文档块。随后，向量数据库会检索出
Top-K 最相关的文档块，并将它们传送给 LLM
和原始用户查询，从而生成最终答案。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/rag/rag%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/image-20250908101159982.png" alt="image-20250908101159982">
<figcaption aria-hidden="true">image-20250908101159982</figcaption>
</figure>
<p>这种方法在解决向量搜索中的跨域不对称问题方面与假设问题技术类似。不过，它也有缺点，如增加了计算成本和生成虚假答案的不确定性。</p>
<h4 id="创建子查询">创建子查询</h4>
<p>当用户查询过于复杂时，我们可以使用 LLM
将其分解为更简单的子查询，然后再将其传递给向量数据库和
LLM。让我们来看一个例子。</p>
<p>想象一下，用户会问*<strong>“Milvus 和 Zilliz Cloud
在功能上有什么不同？*</strong>”这个问题相当复杂，在我们的知识库中可能没有直接的答案。为了解决这个问题，我们可以将其拆分成两个更简单的子查询：</p>
<ul>
<li>子查询 1：“Milvus 有哪些功能？”</li>
<li>子查询 2：“Zilliz Cloud 有哪些功能？”</li>
</ul>
<p>有了这些子查询后，我们将它们全部转换成向量嵌入后发送给向量数据库。然后，向量数据库会找出与每个子查询最相关的
Top-K 文档块。最后，LLM 利用这些信息生成更好的答案。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/rag/rag%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/image-20250908122807696.png" alt="image-20250908122807696">
<figcaption aria-hidden="true">image-20250908122807696</figcaption>
</figure>
<h3 id="增强索引">增强索引</h3>
<p>增强索引是提高 RAG
应用程序性能的另一种策略。让我们来探讨三种索引增强技术：自<strong>动合并文档块，构建分层索引，混合检索和重新排名</strong></p>
<h4 id="构建分层索引">构建分层索引</h4>
<p>在创建文档索引时，我们可以建立两级索引：一级是文档摘要索引，另一级是文档块索引。向量搜索过程包括两个阶段：首先，我们根据摘要过滤相关文档，随后，我们在这些相关文档中专门检索相应的文档块。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/rag/rag%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/image-20250908123520672.png" alt="image-20250908123520672">
<figcaption aria-hidden="true">image-20250908123520672</figcaption>
</figure>
<p>在涉及大量数据或数据分层的情况下，例如图书馆 Collections
中的内容检索，这种方法证明是有益的。</p>
<h4 id="混合检索和重新排名">混合检索和重新排名</h4>
<p>混合检索和重排技术将一种或多种辅助检索方法与<a href="https://zilliz.com/learn/vector-similarity-search">向量相似性检索</a>相结合。然后，<a href="https://zilliz.com/learn/optimize-rag-with-rerankers-the-role-and-tradeoffs#What-is-a-Reranker">Reranker</a>会根据检索结果与用户查询的相关性对检索结果重新排序。</p>
<p>常见的补充检索算法包括基于词频的方法（如<a href="https://milvus.io/docs/embed-with-bm25.md">BM25）</a>或利用稀疏嵌入的大模型（如<a href="https://zilliz.com/learn/discover-splade-revolutionize-sparse-data-processing">SPLADE</a>）。重新排序算法包括
RRF 或更复杂的模型，如<a href="https://www.sbert.net/examples/applications/cross-encoder/README.html">Cross-Encoder</a>（类似于
BERT 的架构）。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/rag/rag%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/image-20250908123544207.png" alt="image-20250908123544207">
<figcaption aria-hidden="true">image-20250908123544207</figcaption>
</figure>
<h3 id="改进检索器">改进检索器</h3>
<p>改进 RAG 系统中的检索器组件也能改进 RAG
应用。让我们来探讨一些增强检索器的有效方法：<strong>句子窗口检索，元数据过滤</strong></p>
<h3 id="生成器增强">生成器增强</h3>
<p>让我们通过改进 RAG 系统中的生成器来探索更多 RAG
优化技术：<strong>压缩 LLM 提示，调整提示中的块顺序</strong></p>
<h4 id="调整提示中的块顺序">调整提示中的块顺序</h4>
<p>在论文<a href="https://arxiv.org/abs/2307.03172">Lost in the
Middle</a>“中，研究人员观察到，LLMs
在推理过程中经常会忽略给定文档中间的信息。相反，他们往往更依赖于文档开头和结尾的信息。</p>
<p>根据这一观察结果，我们可以调整检索知识块的顺序来提高答案质量：在检索多个知识块时，将置信度相对较低的知识块放在中间，而将置信度相对较高的知识块放在两端。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/rag/rag%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/image-20250908124338278.png" alt="image-20250908124338278">
<figcaption aria-hidden="true">image-20250908124338278</figcaption>
</figure>
<h3 id="增强-rag-管道">增强 RAG 管道</h3>
<p>我们还可以通过增强整个 RAG 管道来提高 RAG 应用程序的性能。</p>
<h4 id="自我反思">自我反思</h4>
<p>这种方法在人工智能 Agents
中融入了自我反思的概念。那么，这种技术是如何工作的呢？</p>
<p>一些最初检索到的 Top-K
文档块是模棱两可的，可能无法直接回答用户的问题。在这种情况下，我们可以进行第二轮反思，以验证这些文档块是否能真正解决查询问题。</p>
<p>我们可以使用高效的反思方法（如自然语言推理（NLI）模型）进行反思，也可以使用互联网搜索等其他工具进行验证。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/rag/rag%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/image-20250908124655326.png" alt="image-20250908124655326">
<figcaption aria-hidden="true">image-20250908124655326</figcaption>
</figure>
<h4 id="使用代理进行查询路由选择">使用代理进行查询路由选择</h4>
<p>有时，我们不必使用 RAG
系统来回答简单的问题，因为它可能会导致更多的误解和对误导信息的推断。在这种情况下，我们可以在查询阶段使用代理作为路由器。这个
Agents 会评估查询是否需要通过 RAG 管道。如果需要，则启动后续的 RAG
管道；否则，LLM 直接处理查询。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/rag/rag%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%E6%B1%87%E6%80%BB/image-20250908124734144.png" alt="image-20250908124734144">
<figcaption aria-hidden="true">image-20250908124734144</figcaption>
</figure>
<p>Agents 可以有多种形式，包括 LLM、小型分类模型，甚至是一组规则。</p>
<p>通过根据用户意图路由查询，可以重新定向部分查询，从而显著提高响应时间，并明显减少不必要的噪音。</p>
<p>我们可以将查询路由技术扩展到 RAG
系统内的其他流程，例如确定何时利用网络搜索等工具、进行子查询或搜索图片。这种方法可确保
RAG
系统中的每个步骤都能根据查询的具体要求进行优化，从而提高信息检索的效率和准确性。</p>
]]></content>
      <categories>
        <category>rag</category>
      </categories>
      <tags>
        <tag>rag</tag>
        <tag>agent</tag>
        <tag>langgraph</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式训练qwen3-32b</title>
    <url>/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83qwen3-32b/</url>
    <content><![CDATA[<h3 id="训练框架-llama-factor">训练框架-<a href="https://github.com/hiyouga/LLaMA-Factory">LLaMA-Factor</a></h3>
<p><a href="https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/installation.html">安装
- LLaMA Factory</a></p>
<p><strong>docker部署镜像</strong>，以便后续传入内网</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git</span><br><span class="line">cd LLaMA-Factory</span><br><span class="line"></span><br><span class="line">docker build -f ./docker/docker-cuda/Dockerfile \</span><br><span class="line">    --build-arg PIP_INDEX=https://pypi.org/simple \</span><br><span class="line">    --build-arg EXTRAS=metrics \</span><br><span class="line">    -t llamafactory:latest .</span><br><span class="line"></span><br><span class="line">docker run -dit --ipc=host --gpus=all \</span><br><span class="line">    -p 7860:7860 \</span><br><span class="line">    -p 8001:8000 \    # 主机 8001 → 容器 8000，主机8000端口被占用了</span><br><span class="line">    --name llamafactory \</span><br><span class="line">    -v /aisys/:/aisys/ \</span><br><span class="line">    docker.1ms.run/hiyouga/llamafactory</span><br><span class="line"></span><br><span class="line">docker run -dit --ipc=host --gpus=all -p 7860:7860 -p 8001:8000 -v /aisys/:/aisys/ --name llamafactory docker.1ms.run/hiyouga/llamafactory</span><br><span class="line"></span><br><span class="line">docker exec -it llamafactory bash</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull docker.1ms.run/hiyouga/llamafactory                                    </span><br><span class="line"></span><br><span class="line">docker save docker.1ms.run/hiyouga/llamafactory:latest -o llamafactory-image.tar</span><br><span class="line"></span><br><span class="line">docker load -i llamafactory-image.tar</span><br></pre></td></tr></table></figure>
<p><strong>LLaMA Board 可视化微调（由 <a href="https://github.com/gradio-app/gradio">Gradio</a>
驱动）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">llamafactory-cli webui</span><br></pre></td></tr></table></figure>
<ul>
<li>Web UI 访问：<code>http://localhost:7860</code></li>
<li>API 服务访问：<code>http://localhost:8001</code></li>
</ul>
<h3 id="数据集-easy-dataset">数据集-<a href="https://github.com/ConardLi/easy-dataset">easy-dataset</a></h3>
<p><strong>docker部署镜像</strong>，以便后续传入内网</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/ConardLi/easy-dataset.git</span><br><span class="line">cd easy-dataset</span><br><span class="line"></span><br><span class="line">docker build -t easy-dataset .</span><br><span class="line"></span><br><span class="line">docker load -i easy-dataset.tar</span><br><span class="line"></span><br><span class="line">docker run -d \</span><br><span class="line">  -p 1717:1717 \</span><br><span class="line">  -v /aisys/repo_dev/xizhang/lora_database:/app/local-db \</span><br><span class="line">  -v /aisys/repo_dev/xizhang/lora_databse_prisma:/app/prisma \</span><br><span class="line">  --name easy-dataset \</span><br><span class="line">  easy-dataset</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">docker exec -it easy-dataset sh</span><br><span class="line"></span><br><span class="line">docker stop easy-dataset</span><br><span class="line">docker rm easy-dataset</span><br><span class="line"></span><br><span class="line">#实时跟踪</span><br><span class="line"> docker logs -f easy-dataset</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意：</strong> 请将
<code>&#123;YOUR_LOCAL_DB_PATH&#125;</code>、<code>&#123;LOCAL_PRISMA_PATH&#125;</code>
替换为你希望存储本地数据库的实际路径，建议直接使用当前代码仓库目录下的
<code>local-db</code> 和 <code>prisma</code> 文件夹，这样可以和 NPM
启动时的数据库路径保持一致。</p>
</blockquote>
<blockquote>
<p><strong>注意：</strong>
如果需要挂载数据库文件（PRISMA），需要提前执行
<code>npm run db:push</code> 初始化数据库文件。</p>
</blockquote>
<p>使用开源项目制作数据集</p>
<p>打开浏览器，访问 <code>http://localhost:1717</code></p>
<h3 id="上传内网">上传内网</h3>
<p>使用scp</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">scp -r &quot;F:\project python\实习\微调\universal-llm_latest.tar&quot; root@10.117.128.50:/aisys/repo_dev/xizhang/images</span><br></pre></td></tr></table></figure>
<p><strong>SCP</strong> 全称是 <strong>Secure Copy
Protocol</strong>（安全复制协议），是一种用于在计算机之间<strong>安全地复制文件</strong>的网络协议。</p>
<p>它基于 <strong>SSH</strong>（Secure
Shell）协议工作，因此所有传输的数据都是<strong>加密的</strong>，可以防止被窃听或篡改，非常适合在不安全的网络（如互联网）中使用。</p>
<h3 id="模型部署与调用">模型部署与调用</h3>
<h4 id="制作模型运行镜像">制作模型运行镜像</h4>
<p>qwen3部署版本要求如下</p>
<p>使用 Python 3.10 或以上版本， PyTorch 2.6 或以上版本</p>
<p><code>transformers&gt;=4.51.0</code> 版本</p>
<p>使用 <code>sglang&gt;=0.4.6.post1</code> 或
<code>vllm&gt;=0.8.5</code> 来创建一个与 OpenAI 兼容的 API 端点</p>
<h4 id="镜像信息">镜像信息</h4>
<table>
<colgroup>
<col style="width: 15%">
<col style="width: 18%">
<col style="width: 21%">
<col style="width: 45%">
</colgroup>
<thead>
<tr>
<th>类别</th>
<th>组件</th>
<th>版本 / 来源</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OS</strong></td>
<td>Ubuntu</td>
<td>22.04 LTS (Jammy)</td>
<td>上游镜像继承</td>
</tr>
<tr>
<td><strong>Python</strong></td>
<td>CPython</td>
<td>3.11</td>
<td>镜像自带</td>
</tr>
<tr>
<td><strong>PyTorch</strong></td>
<td>PyTorch</td>
<td>2.6.0+cu126</td>
<td>官方 wheel，CUDA 12.6</td>
</tr>
<tr>
<td><strong>CUDA</strong></td>
<td>Runtime</td>
<td>12.6.3</td>
<td>与宿主机 535 驱动兼容</td>
</tr>
<tr>
<td><strong>cuDNN</strong></td>
<td>cuDNN</td>
<td>9</td>
<td>包含在镜像</td>
</tr>
<tr>
<td><strong>核心库</strong></td>
<td>transformers</td>
<td>≥4.51.0</td>
<td>官方最新</td>
</tr>
<tr>
<td></td>
<td>tokenizers</td>
<td>≥0.21</td>
<td>transformers 依赖</td>
</tr>
<tr>
<td></td>
<td>accelerate</td>
<td>≥1.0.0</td>
<td>训练 / 推理加速</td>
</tr>
<tr>
<td></td>
<td>sentencepiece</td>
<td>≥0.2.0</td>
<td>Qwen3 分词器必需</td>
</tr>
<tr>
<td></td>
<td>protobuf</td>
<td>≥5.28.0</td>
<td>序列化 / 模型加载</td>
</tr>
<tr>
<td></td>
<td>tiktoken</td>
<td>≥0.8.0</td>
<td>OpenAI 格式分词</td>
</tr>
<tr>
<td><strong>推理框架</strong></td>
<td>vLLM</td>
<td>≥0.8.5</td>
<td>支持 tensor-parallel、PagedAttention</td>
</tr>
<tr>
<td></td>
<td>SGLang</td>
<td>≥0.4.6.post1</td>
<td>支持 outline 解码、MoE 优化</td>
</tr>
<tr>
<td><strong>可选加速</strong></td>
<td>flash-attn</td>
<td>≥2.7</td>
<td>长上下文 / 大 batch 推理</td>
</tr>
<tr>
<td><strong>权重下载</strong></td>
<td>modelscope</td>
<td>最新</td>
<td>国内镜像加速</td>
</tr>
<tr>
<td><strong>工具链</strong></td>
<td>git / git-lfs</td>
<td>最新</td>
<td>拉取 HuggingFace 权重</td>
</tr>
<tr>
<td></td>
<td>curl / jq / vim</td>
<td>最新</td>
<td>调试 &amp; 健康检查</td>
</tr>
</tbody>
</table>
<p><strong>基础镜像</strong><code>pytorch/pytorch:2.6.0-cuda12.6-cudnn9-devel</code>
是 <strong>PyTorch 官方在 Docker Hub
上提供的“全家桶”开发镜像</strong>，发布日期 2025-01-29，镜像大小约 13
GB，定位是 <strong>“开箱即用”的 GPU 训练 / 推理 / 调试环境</strong></p>
<h4 id="dockerfile">dockerfile</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ---------- 1. 基础镜像 ----------</span><br><span class="line">FROM pytorch/pytorch:2.6.0-cuda12.6-cudnn9-devel</span><br><span class="line"></span><br><span class="line"># ---------- 2. 国内镜像源 ----------</span><br><span class="line">RUN sed -i &#x27;s|http://archive.ubuntu.com|https://mirrors.tuna.tsinghua.edu.cn|g&#x27; /etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    sed -i &#x27;s|http://security.ubuntu.com|https://mirrors.tuna.tsinghua.edu.cn|g&#x27; /etc/apt/sources.list &amp;&amp; \</span><br><span class="line">    pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple &amp;&amp; \</span><br><span class="line">    pip config set global.trusted-host pypi.tuna.tsinghua.edu.cn</span><br><span class="line"></span><br><span class="line"># ---------- 3. 系统依赖 ----------</span><br><span class="line">RUN apt-get update &amp;&amp; \</span><br><span class="line">    DEBIAN_FRONTEND=noninteractive apt-get install -y \</span><br><span class="line">    git git-lfs build-essential ninja-build curl wget vim jq &amp;&amp; \</span><br><span class="line">    rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># ---------- 4. Python 依赖 ----------</span><br><span class="line">RUN pip install --no-cache-dir --upgrade pip setuptools wheel &amp;&amp; \</span><br><span class="line">    pip install --no-cache-dir \</span><br><span class="line">    &quot;torch==2.6.0+cu126&quot; \</span><br><span class="line">    &quot;transformers&gt;=4.51.0&quot; \</span><br><span class="line">    &quot;tokenizers&gt;=0.21&quot; \</span><br><span class="line">    &quot;accelerate&gt;=1.0.0&quot; \</span><br><span class="line">    &quot;sentencepiece&gt;=0.2.0&quot; \</span><br><span class="line">    &quot;protobuf&gt;=5.28.0&quot; \</span><br><span class="line">    &quot;tiktoken&gt;=0.8.0&quot; \</span><br><span class="line">    &quot;vllm&gt;=0.8.5&quot; \</span><br><span class="line">    &quot;sglang[all]&gt;=0.4.6.post1&quot; \</span><br><span class="line">    &quot;modelscope&quot; \</span><br><span class="line">    &quot;fastapi&quot; &quot;uvicorn[standard]&quot; &quot;pydantic&quot;</span><br><span class="line"></span><br><span class="line"># ---------- 5. 可选性能加速 ----------</span><br><span class="line">RUN pip install --no-cache-dir &quot;flash-attn&gt;=2.7&quot; --no-build-isolation || true</span><br><span class="line"></span><br><span class="line"># ---------- 6. 国内 HuggingFace 镜像 ----------</span><br><span class="line">ENV HF_ENDPOINT=https://hf-mirror.com</span><br><span class="line"></span><br><span class="line"># ---------- 7. 工作目录 ----------</span><br><span class="line">WORKDIR /app</span><br><span class="line">EXPOSE 4000 4001 4002</span><br><span class="line"></span><br><span class="line"># ---------- 8. 默认命令 ----------</span><br><span class="line">CMD [&quot;/bin/bash&quot;]</span><br></pre></td></tr></table></figure>
<h4 id="运行容器">运行容器</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -it \</span><br><span class="line">  --name llm-service \</span><br><span class="line">  --gpus all \</span><br><span class="line">  -p 4000:4000 \</span><br><span class="line">  -p 4001:4001 \</span><br><span class="line">  -p 4002:4002 \</span><br><span class="line">  -v /aisys/repo_dev/xizhang/models:/app/models \</span><br><span class="line">  -v /aisys/repo_dev/xizhang/models/cache:/app/models/.cache \</span><br><span class="line">  --shm-size=8g \</span><br><span class="line">  universal-llm:latest bash</span><br></pre></td></tr></table></figure>
<h4 id="vllm部署qwen3">vllm部署qwen3</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vllm serve /app/models/qwen3-32b-lora-new \</span><br><span class="line">    --port 4001 \</span><br><span class="line">    --tensor-parallel-size 4 \</span><br><span class="line">    --max-model-len 1024 \</span><br><span class="line">    --reasoning-parser qwen3 \</span><br><span class="line">    --gpu-memory-utilization 0.8 \</span><br><span class="line">    --max-num-seqs 8 \</span><br><span class="line">    --host 0.0.0.0</span><br></pre></td></tr></table></figure>
<table>
<colgroup>
<col style="width: 20%">
<col style="width: 40%">
<col style="width: 40%">
</colgroup>
<thead>
<tr>
<th>参数</th>
<th>含义</th>
<th>推荐/注意</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--port 8000</code></td>
<td>服务监听端口</td>
<td>与 <code>-p 8000:8000</code> 保持一致；如需多实例，可改 8001/8002
…</td>
</tr>
<tr>
<td><code>--tensor-parallel-size 4</code></td>
<td>把模型权重切成 4 份，跨 4 张 GPU 并行计算</td>
<td>必须 ≤ 实际 GPU 数量；Qwen3-32B 在 4×L20
上显存刚好够，<strong>不可再大</strong></td>
</tr>
<tr>
<td><code>--max-model-len 1024</code></td>
<td>单次推理最大 token 数（含 prompt + 生成）</td>
<td>若场景需要 4k/8k/32k，可调到 4096/8192；显存占用 ∝ 长度²</td>
</tr>
<tr>
<td><code>--reasoning-parser qwen3</code></td>
<td>vLLM ≥0.8.5 新增开关，解析 Qwen3 的
<code>&lt;think&gt;…&lt;/think&gt;</code> 标签，把推理过程单独返回</td>
<td>仅在 <strong>Qwen3</strong> 系列模型有效，其他模型请去掉</td>
</tr>
<tr>
<td><code>--gpu-memory-utilization 0.8</code></td>
<td>显存使用上限 80 %；剩余 20 % 留给 CUDA kernel、KV cache 膨胀</td>
<td>若出现 OOM，可降到 0.7；若想多并发，可尝试 0.85（风险 OOM）</td>
</tr>
<tr>
<td><code>--max-num-seqs 8</code></td>
<td>同一时刻最多并发处理的 <strong>请求条数</strong></td>
<td>与 <code>--max-model-len</code> 和显存同时决定；若长度 ↑，此值需
↓</td>
</tr>
<tr>
<td><code>--host 0.0.0.0</code></td>
<td>监听所有网卡，使容器外可访问</td>
<td>生产环境可改为内网 IP 或 127.0.0.1 提高安全性</td>
</tr>
</tbody>
</table>
<h4 id="测试">测试</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl http://localhost:4001/v1/chat/completions \</span><br><span class="line">   -H &quot;Content-Type: application/json&quot; \</span><br><span class="line">   -d &#x27;&#123;</span><br><span class="line">       &quot;model&quot;: &quot;/app/models/qwen3-32b-lora-new&quot;,</span><br><span class="line">       &quot;messages&quot;: [</span><br><span class="line">           &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请用中文介绍一下你自己&quot;&#125;</span><br><span class="line">       ],</span><br><span class="line">       &quot;temperature&quot;: 0.7,</span><br><span class="line">       &quot;max_tokens&quot;: 512</span><br><span class="line">   &#125;&#x27;</span><br></pre></td></tr></table></figure>
<h4 id="调用">调用</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">from openai import OpenAI</span><br><span class="line"></span><br><span class="line"># 指向本地 vLLM</span><br><span class="line">client = OpenAI(</span><br><span class="line">    base_url=&quot;http://localhost:8000/v1&quot;,</span><br><span class="line">    api_key=&quot;dummy&quot;          # vLLM 不做鉴权，随便填</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">resp = client.chat.completions.create(</span><br><span class="line">    model=&quot;qwen3-32b&quot;,       # 必须和 vLLM 启动路径或 --served-model-name 保持一致</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;9.9 和 9.11 哪个大？&quot;&#125;</span><br><span class="line">    ],</span><br><span class="line">    max_tokens=512,</span><br><span class="line">    temperature=0.7,</span><br><span class="line">    stream=False             # True 可开流式</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">print(resp.choices[0].message.content)</span><br></pre></td></tr></table></figure>
<p><a href="https://qwen.readthedocs.io/en/latest/getting_started/quickstart.html">快速入门
- Qwen — Quickstart - Qwen</a></p>
<p><a href="https://www.modelscope.cn/models/Qwen/Qwen3-32B">通义千问3-32B ·
模型库</a></p>
<h3 id="微调数据集">微调数据集</h3>
<h4 id="alpaca和sharegpt的区别">alpaca和sharegpt的区别</h4>
<p>▶ Alpaca 典型字段</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;把下面句子翻译成英文&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;今天天气真好&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The weather is nice today.&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是一个翻译助手&quot;</span><span class="punctuation">,</span>   <span class="comment">// 可选</span></span><br><span class="line">  <span class="attr">&quot;history&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span>                 <span class="comment">// 可选，放前几轮</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>一条数据 = 一次独立任务</li>
<li>字段固定：<code>instruction / input / output</code> 三板斧</li>
</ul>
<p>▶ ShareGPT 典型字段</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;conversations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;我今天心情不好&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span>   <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;怎么啦？想聊聊吗&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;论文又被拒了&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span>   <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;理解你的挫败感…&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是贴心聊天机器人&quot;</span><span class="punctuation">,</span>   <span class="comment">// 可选</span></span><br><span class="line">  <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span>...<span class="punctuation">]</span>                   <span class="comment">// 可选，放函数描述</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>一条数据 = 一段完整的多轮对话</li>
<li>角色交替：<code>human / gpt / function / observation</code> 等</li>
</ul>
<table>
<colgroup>
<col style="width: 9%">
<col style="width: 47%">
<col style="width: 42%">
</colgroup>
<thead>
<tr>
<th>维度</th>
<th>Alpaca</th>
<th>ShareGPT</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>来源</strong></td>
<td>斯坦福 Alpaca 项目，为了低成本做指令微调</td>
<td>ShareGPT 网站爬取的真实 ChatGPT 对话</td>
</tr>
<tr>
<td><strong>目标</strong></td>
<td>让模型学会“看到指令+输入→给出答案”</td>
<td>让模型学会“像 ChatGPT 一样多轮对话”</td>
</tr>
</tbody>
</table>
<h4 id="详解">详解</h4>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;instruction&quot;: &quot;电阻率测定法的环境温湿度控制对检测结果的可信度有何影响？&quot;,</span><br><span class="line">    &quot;input&quot;: &quot;- \&quot;检测依据：DL<span class="operator">/</span>T <span class="number">421</span><span class="number">-2009</span> 电力用油体积电阻率测定法\&quot;\n- \&quot;检测地点及环境条件：油品检测室 温度：<span class="number">16</span>℃ 湿度：<span class="number">57</span><span class="operator">%</span>RH\&quot;\n- \&quot;电阻率（\&quot;&quot;,</span><br><span class="line">    &quot;output&quot;: &quot;&lt;think&gt;### \n首先，理解问题的核心：电阻率测定法中，环境温湿度控制如何影响检测结果的可信度，这涉及到测量过程的准确性和可靠性。\n\n然后，分析关键信息：检测依据是DL/T 421-2009标准，它规定了电阻率测定的方法；环境条件被记录为温度16℃和湿度57%RH；检测结果显示电阻率为1.04×10^10 Ω·cm，符合DL/T 571-2014标准的要求（≥6×10^9 Ω·cm）。\n\n接着，推理温湿度控制的影响：环境温湿度是测量过程中的关键变量，控制这些条件确保&quot;,</span><br><span class="line">    &quot;system&quot;: &quot;作为电力能源报告解读专家，我在生成答案时，将严格遵循以下格式：\n根据“信息来源”，“信息来源”是原文中可直接支撑结论的句子、数据或图表编号给出“结论与推理”——用上述逐条复现的信息为唯一依据，推导出最终答案。&quot;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>instruction为问题；input为上下文；output包含思维链与答案；system为系统提示词</p>
<h3 id="微调参数设置">微调参数设置</h3>
<h4 id="deepspeed-stagedeepspeed-阶段"><strong>DeepSpeed
stage（DeepSpeed 阶段）</strong></h4>
<p><strong>deepSpeed 的 ZeRO 分布式优化阶段</strong>，用于在多 GPU
上高效训练大模型。</p>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 43%">
<col style="width: 42%">
</colgroup>
<thead>
<tr>
<th>Stage</th>
<th>功能</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Stage 0</strong></td>
<td>不做任何优化</td>
<td>基础分布式训练（DDP），显存占用高</td>
</tr>
<tr>
<td><strong>Stage 1</strong></td>
<td>梯度分片（Gradient Sharding）</td>
<td>将梯度切分到不同 GPU，减少显存</td>
</tr>
<tr>
<td><strong>Stage 2</strong></td>
<td>参数 + 梯度分片</td>
<td>进一步降低显存，但需通信同步</td>
</tr>
<tr>
<td><strong>Stage 3</strong></td>
<td>✅ <strong>参数 + 梯度 + 优化器状态分片</strong></td>
<td>最强显存优化，支持超大模型</td>
</tr>
</tbody>
</table>
<h4 id="使用-deepspeed-offload使用-offload">使用 DeepSpeed offload（使用
offload）</h4>
<p>将 <strong>部分或全部模型参数、优化器状态卸载到 CPU
内存</strong>，进一步释放 GPU 显存。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">llamafactory-cli train \</span><br><span class="line">    --stage sft \</span><br><span class="line">    --do_train True \</span><br><span class="line">    --model_name_or_path /aisys/repo_dev/xizhang/models/qwen3-32b-lora-new \</span><br><span class="line">    --preprocessing_num_workers 16 \</span><br><span class="line">    --finetuning_type lora \</span><br><span class="line">    --template qwen3 \</span><br><span class="line">    --flash_attn auto \</span><br><span class="line">    --dataset_dir /aisys/repo_dev/xizhang/lora_database/P9er76jCWCFW \</span><br><span class="line">    --dataset [Easy Dataset] [P9er76jCWCFW] Alpaca \</span><br><span class="line">    --cutoff_len 4096 \</span><br><span class="line">    --learning_rate 5e-05 \</span><br><span class="line">    --num_train_epochs 3.0 \</span><br><span class="line">    --max_samples 100000 \</span><br><span class="line">    --per_device_train_batch_size 2 \</span><br><span class="line">    --gradient_accumulation_steps 1 \</span><br><span class="line">    --lr_scheduler_type cosine \</span><br><span class="line">    --max_grad_norm 1.0 \</span><br><span class="line">    --logging_steps 5 \</span><br><span class="line">    --save_steps 200 \</span><br><span class="line">    --warmup_steps 0 \</span><br><span class="line">    --packing False \</span><br><span class="line">    --enable_thinking True \</span><br><span class="line">    --report_to none \</span><br><span class="line">    --output_dir saves/Qwen3-32B-Thinking/lora/train_2025-08-28-03-04-52 \</span><br><span class="line">    --bf16 True \</span><br><span class="line">    --plot_loss True \</span><br><span class="line">    --trust_remote_code True \</span><br><span class="line">    --ddp_timeout 180000000 \</span><br><span class="line">    --include_num_input_tokens_seen True \</span><br><span class="line">    --optim adamw_torch \</span><br><span class="line">    --lora_rank 8 \</span><br><span class="line">    --lora_alpha 16 \</span><br><span class="line">    --lora_dropout 0 \</span><br><span class="line">    --lora_target all \</span><br><span class="line">    --val_size 0.15 \</span><br><span class="line">    --eval_strategy steps \</span><br><span class="line">    --eval_steps 200 \</span><br><span class="line">    --per_device_eval_batch_size 2 \</span><br><span class="line">    --deepspeed cache/ds_z3_config.json</span><br></pre></td></tr></table></figure>
<h3 id="训练结果">训练结果</h3>
<figure>
<img src="/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83qwen3-32b/image-20250827091214108.png" alt="image-20250827091214108">
<figcaption aria-hidden="true">image-20250827091214108</figcaption>
</figure>
<h3 id="评估">评估</h3>
<p>不知道为什么使用llamafactory的评估会爆显存，我怀疑是因为那个webui评估可能不支持多卡，就进行一下人工评估吧</p>
<p>输入</p>
<figure>
<img src="/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83qwen3-32b/image-20250828144300339.png" alt="image-20250828144300339">
<figcaption aria-hidden="true">image-20250828144300339</figcaption>
</figure>
<p>微调模型</p>
<figure>
<img src="/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83qwen3-32b/image-20250828145106050.png" alt="image-20250828145106050">
<figcaption aria-hidden="true">image-20250828145106050</figcaption>
</figure>
<p>初始模型</p>
<figure>
<img src="/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83qwen3-32b/image-20250828145750115.png" alt="image-20250828145750115">
<figcaption aria-hidden="true">image-20250828145750115</figcaption>
</figure>
<h3 id="在内网计算节点访问swanlab-cloud">在内网计算节点访问SwanLab
Cloud</h3>
<p><a href="https://docs.swanlab.cn/guide_cloud/experiment_track/ssh-portforwarding.html">在内网计算节点访问SwanLab
Cloud | SwanLab官方文档</a></p>
<h3 id="如何计算训练步数">如何计算训练步数</h3>
<h4 id="训练集样本量">1. 训练集样本量</h4>
<p><strong>公式</strong> 训练集样本量 = 总数据量 × (1 − 验证集比例)</p>
<p><strong>示例</strong> 总数据 2876 条，验证集占 15% 2876 × (1 − 0.15)
= 2876 × 0.85 = <strong>2446 条</strong></p>
<h4 id="每次参数更新处理的样本数effective-batch-size">2.
每次参数更新处理的样本数（effective batch size）</h4>
<p><strong>公式</strong> 每次更新样本数 = 单设备批次大小 × GPU 数 ×
梯度累积步数</p>
<p><strong>示例</strong></p>
<ul>
<li>per_device_train_batch_size = 1</li>
<li>GPU 数 = 2</li>
<li>gradient_accumulation_steps = 8</li>
</ul>
<p>1 × 2 × 8 = <strong>16 条</strong></p>
<blockquote>
<p>通俗理解： GPU 一次只能看 1 条 → 2 卡并行就是 2 条 → 累积 8
次才更新一次参数，所以一次更新真正看了 16 条数据。</p>
</blockquote>
<h4 id="每轮epoch的训练步数">3. 每轮（epoch）的训练步数</h4>
<p><strong>公式</strong> 每轮步数 = ⌊ 训练集样本量 ÷ 每次更新样本数 ⌋
（⌊ ⌋ 表示向下取整）</p>
<p><strong>示例</strong> 2446 ÷ 16 = 152.875 → <strong>152
步</strong></p>
<h4 id="总训练步数">4. 总训练步数</h4>
<p><strong>公式</strong> 总步数 = 每轮步数 × 训练轮数 (epochs)</p>
<p><strong>示例</strong> 152 × 3 = <strong>456 步</strong></p>
<h3 id="如何计算一个模型占用的显存">如何计算一个模型占用的显存</h3>
<h4 id="基础模型的权重">基础模型的权重</h4>
<ul>
<li>定义：预训练模型的参数矩阵，即选择的预训练模型所占用显存的大小。</li>
<li><strong>计算公式</strong>： <strong>显存占用 = 模型参数数量 ×
单个参数的字节数</strong></li>
</ul>
<h4 id="常见模型精度下的单个参数显存占用">常见模型精度下的单个参数显存占用：</h4>
<p>表格</p>
<p>复制</p>
<table>
<thead>
<tr>
<th style="text-align: left;">精度类型</th>
<th style="text-align: left;">二进制位数</th>
<th style="text-align: left;">字节数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">FP32</td>
<td style="text-align: left;">32位</td>
<td style="text-align: left;">4字节</td>
</tr>
<tr>
<td style="text-align: left;">FP16</td>
<td style="text-align: left;">16位</td>
<td style="text-align: left;">2字节</td>
</tr>
<tr>
<td style="text-align: left;">BF16</td>
<td style="text-align: left;">16位</td>
<td style="text-align: left;">2字节（指数位同FP32）</td>
</tr>
<tr>
<td style="text-align: left;">INT8</td>
<td style="text-align: left;">8位</td>
<td style="text-align: left;">1字节</td>
</tr>
<tr>
<td style="text-align: left;">INT4</td>
<td style="text-align: left;">4位</td>
<td style="text-align: left;">0.5字节</td>
</tr>
<tr>
<td style="text-align: left;">INT2</td>
<td style="text-align: left;">2位</td>
<td style="text-align: left;">0.25字节</td>
</tr>
</tbody>
</table>
<p>例如</p>
<ul>
<li><strong>模型选择</strong>：Qwen2.5-7B-Instruct</li>
<li><strong>参数规模</strong>：70亿（7B）</li>
<li><strong>计算精度</strong>：BF16（2字节/参数）</li>
<li><strong>预估显存占用</strong>： <strong>70亿 × 2字节 = 140亿字节 =
14GB</strong></li>
</ul>
<h4 id="框架开销framework-overhead">框架开销（Framework Overhead）</h4>
<ul>
<li><strong>定义</strong>：LLaMAFactory 底层使用的深度学习框架（如
PyTorch）本身的显存占用。</li>
<li><strong>包含内容</strong>：
<ul>
<li>张量缓存</li>
<li>线程资源</li>
<li>内核调度开销</li>
<li>自动微分图结构等</li>
</ul></li>
<li><strong>计算方法</strong>：难以精确计算</li>
<li><strong>估算方法</strong>：通常占用不大，默认估算为 <strong>1
GB</strong></li>
</ul>
<h4 id="lora-适配器lora-adapters">LoRA 适配器（LoRA Adapters）</h4>
<ul>
<li><p><strong>定义</strong>：在 LoRA
微调中，不直接修改原始模型的庞大权重，而是插入轻量级的“LoRA适配器模块”来学习微调所需的变化。</p></li>
<li><p><strong>计算方法</strong>：</p>
<p>显存占用=LoRA层数×秩（Rank）×(输入维度+输出维度)×2<em>B</em></p></li>
<li><p><strong>估算方法</strong>：</p>
<ul>
<li>与 LoRA 的秩（Rank）大小相关</li>
<li>一般占用不大，常规配置下通常不超过 <strong>0.5
GB</strong>，保守估计为 <strong>0.5 GB</strong></li>
</ul></li>
</ul>
<h4 id="激活值activations">激活值（Activations）</h4>
<ul>
<li><p><strong>定义</strong>：前向传播过程中各层的输出张量（如隐藏层状态、注意力矩阵等），即模型“处理数据时产生的所有中间结果”。</p></li>
<li><p><strong>计算方法</strong>：</p>
<p>显存占用=批量大小×序列长度×隐藏层维度×模型层数×单个元素字节数</p></li>
<li><p><strong>估算方法</strong>：</p>
<ul>
<li>单次处理的 Token 量每增加 <strong>1K</strong>，显存约增加
<strong>2.5 GB</strong></li>
<li>与单 GPU 的批量大小和数据集的截断长度（序列长度）正相关</li>
<li>在固定其他配置（基础模型权重、框架开销、LoRA适配器）后，剩余显存即为激活值占用</li>
</ul></li>
</ul>
<h3 id="加速方式">加速方式</h3>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 14%">
<col style="width: 37%">
<col style="width: 37%">
</colgroup>
<thead>
<tr>
<th>加速方式</th>
<th>全称 / 来源</th>
<th>核心原理与特点</th>
<th>适用场景与注意事项</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>auto</strong></td>
<td>自动选择</td>
<td>由框架（如 transformers、LLaMA-Factory、DeepSpeed
等）根据当前硬件、驱动、CUDA 版本自动挑选最快的可用算子或路径。
优点：零配置、开箱即用；缺点：不一定能启用最新、最快的内核。</td>
<td>初次实验、不想手动调参时首选。</td>
</tr>
<tr>
<td><strong>flashattn2</strong></td>
<td>FlashAttention-2</td>
<td>通过 IO-Aware 的算法和 GPU Tensor Core 优化，将标准 Multi-Head
Attention 的显存访问次数大幅降低，从而显著加快训练/推理速度（通常
2-4×），并减少显存占用。 需要 A100、H100、RTX 30/40 系列等
Ampere/Lovelace 架构；依赖 CUDA≥11.8、PyTorch≥2.0 且需安装
<code>flash-attn</code> wheel。</td>
<td>训练/微调 LLM 时首选；序列越长收益越大。若编译失败可退回 xformers
或原生实现。</td>
</tr>
<tr>
<td><strong>unsloth</strong></td>
<td>Unsloth 开源库</td>
<td>针对 Llama、Mistral、Qwen 等架构，使用动态量化、手工 fused-kernel
和梯度检查点优化，使 LoRA 微调在消费级 GPU 上也能跑更大
batch/更长序列。官方宣称速度提升 2-5×，显存节省 50-70%。
安装简单：<code>pip install unsloth</code>（会自动替换部分 PyTorch
层）。</td>
<td>单卡 4090/3090 上 LoRA 微调 7B-13B
模型效果最佳；目前仅支持有限模型。</td>
</tr>
<tr>
<td><strong>liger_kernel</strong></td>
<td>Liger-Kernel（微软开源）</td>
<td>以 Triton 编写的高性能 fused-kernel
合集（SwiGLU、RMSNorm、CrossEntropy、RoPE 等），在保持数值精度的同时减少
kernel launch 和显存写回，训练吞吐量可提升 10-20%。 纯 Python/Triton
实现，无需额外 CUDA 编译。</td>
<td>对训练框架侵入性小，可与 FlashAttention 并存；适合想“无痛”提速
10-20% 的场景。</td>
</tr>
</tbody>
</table>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://llamafactory.readthedocs.io/zh-cn/latest/">LLaMA
Factory</a></p>
]]></content>
      <categories>
        <category>模型</category>
        <category>微调</category>
      </categories>
      <tags>
        <tag>模型微调</tag>
        <tag>LoRA</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型训练流程</title>
    <url>/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<h3 id="什么是大模型">什么是大模型</h3>
<p>随着2022年底 ChatGPT 再一次刷新 NLP
的能力上限，大<strong>语言模型（Large Language
Model，LLM）开始接替传统的预训练语言模型（Pre-trained Language
Model，PLM）</strong> 成为 NLP 的主流方向，基于 LLM
的全新研究范式也正在刷新被 BERT
发扬光大的<strong>预训练-微调范式</strong>，NLP
由此迎来又一次翻天覆地的变化。</p>
<p>LLM，即 Large Language
Model，中文名为大语言模型或大型语言模型，是一种相<strong>较传统语言模型参数量更多、在更大规模语料上进行预训练的语言模型</strong>。</p>
<p>一般来说，LLM
指包含<strong>数百亿（或更多）参数的语言模型</strong>，它们往往在<strong>数
T token
语料上</strong>通过多卡分布式集群进行预训练，具备远超出传统预训练模型的文本理解与生成能力。不过，随着
LLM 研究的不断深入，多种参数尺寸的 LLM 逐渐丰富，广义的 LLM
一般覆盖了从<strong>十亿参数</strong>（如
Qwen-1.5B）到<strong>千亿参数</strong>（如
Grok-314B）的所有大型语言模型。只要模型展现出<strong>涌现能力</strong>，即在一系列复杂任务上表现出远超传统预训练模型（如
BERT、T5）的能力与潜力，都可以称之为 LLM。</p>
<p>一般认为，GPT-3（1750亿参数）是 LLM 的开端，基于 GPT-3 通过
<strong>预训练（Pretraining）、监督微调（Supervised
Fine-Tuning，SFT）、强化学习与人类反馈（Reinforcement Learning with
Human Feedback，RLHF）</strong>三阶段训练得到的 ChatGPT 更是主导了 LLM
时代的到来。</p>
<blockquote>
<p>区分 LLM 与传统 PLM 最显著的特征即是 LLM 具备 <code>涌现能力</code>
。涌现能力是指同样的模型架构与预训练任务下，某些能力在小型模型中不明显，但在大型模型中特别突出。</p>
</blockquote>
<h3 id="训练流程">训练流程</h3>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/image-20250811092459843.png" alt="image-20250811092459843">
<figcaption aria-hidden="true">image-20250811092459843</figcaption>
</figure>
<p>一般而言，训练一个完整的 LLM 需要经过图1中的三个阶段——Pretrain、SFT
和 RLHF。</p>
<h3 id="pretrain">Pretrain</h3>
<p>Pretrain，即预训练，是训练 LLM 最核心也是工程量最大的第一步。</p>
<h4 id="参数">参数</h4>
<table style="width:100%;">
<colgroup>
<col style="width: 16%">
<col style="width: 21%">
<col style="width: 18%">
<col style="width: 8%">
<col style="width: 16%">
<col style="width: 19%">
</colgroup>
<thead>
<tr>
<th>模型</th>
<th>hidden_layers</th>
<th>hidden_size</th>
<th>heads</th>
<th>整体参数量</th>
<th>预训练数据量</th>
</tr>
</thead>
<tbody>
<tr>
<td>BERT-base</td>
<td>12</td>
<td>768</td>
<td>12</td>
<td>0.1B</td>
<td>3B</td>
</tr>
<tr>
<td>BERT-large</td>
<td>24</td>
<td>1024</td>
<td>16</td>
<td>0.3B</td>
<td>3B</td>
</tr>
<tr>
<td>Qwen-1.8B</td>
<td>24</td>
<td>2048</td>
<td>16</td>
<td>1.8B</td>
<td>2.2T</td>
</tr>
<tr>
<td>LLaMA-7B</td>
<td>32</td>
<td>4096</td>
<td>32</td>
<td>7B</td>
<td>1T</td>
</tr>
<tr>
<td>GPT-3</td>
<td>96</td>
<td>12288</td>
<td>96</td>
<td>175B</td>
<td>300B</td>
</tr>
</tbody>
</table>
<p>根据定义，LLM
的核心特点即在于其具有<strong>远超传统预训练模型的参数量</strong>，<strong>同时在更海量的语料上进行预训练</strong>。传统预训练模型如
BERT，有 base 和 large 两个版本。BERT-base 模型由 12个 Encoder
层组成，其 hidden_size 为 768，使用 12个头作为多头注意力层，整体参数量为
1亿（110M）；而 BERT-large 模型由 24个 Encoder 层组成，hidden_size 为
1024，有 16个头，整体参数量为 3亿（340M）。同时，BERT 预训练使用了
33亿（3B）token 的语料，在 64块 TPU 上训练了
4天。事实上，相对于传统的深度学习模型，3亿参数量、33亿训练数据的 BERT
已经是一个能力超群、资源消耗巨大的庞然大物。</p>
<p>但是，前面我们提到，<strong>一般而言的 LLM
通常具有数百亿甚至上千亿参数</strong>，即使是广义上最小的
LLM，一般也有十亿（1B）以上的参数量。例如以开山之作 GPT-3 为例，其有
96个 Decoder 层，12288 的 hidden_size 和 96个头，<strong>共有
1750亿（175B）参数，比 BERT 大出快
3个数量级</strong>。即使是目前流行的小型 LLM 如 Qwen-1.8B，其也有 24个
Decoder 层、2048的 hidden_size 和 16个注意力头，整体参数量达到
18亿（1.8B）。</p>
<h4 id="分布式训练">分布式训练</h4>
<p>也正因如此，<strong>分布式训练框架也成为 LLM
训练必不可少的组成部分</strong>。分布式训练框架的核心思路是<strong>数据并行和模型并行</strong>。所谓数据并行，是指训练模型的尺寸可以被单个
GPU 内存容纳，但是由于增大训练的 batch_size
会增大显存开销，无法使用较大的 batch_size
进行训练；同时，训练数据量非常大，使用单张 GPU 训练时长难以接受。</p>
<h4 id="数据集">数据集</h4>
<p><strong>训练数据本身也是预训练 LLM 的一个重大挑战</strong>。训练一个
LLM，至少需要数百 B 甚至上 T 的预训练语料。根据研究，LLM
所掌握的知识绝大部分都是在预训练过程中学会的，因此，为了使训练出的 LLM
能够覆盖尽可能广的知识面，预训练语料需要组织多种来源的数据，并以一定比例进行混合。目前，主要的开源预训练语料包括
CommonCrawl、C4、Github、Wikipedia 等。<strong>不同的 LLM
往往会在开源预训练语料基础上，加入部分私有高质量语料，再基于自己实验得到的最佳配比来构造预训练数据集</strong>。事实上，<strong>数据配比</strong>向来是预训练
LLM
的“核心秘籍”，不同的配比往往会相当大程度影响最终模型训练出来的性能。</p>
<p>训练一个中文
LLM，训练数据的难度会更大。目前，高质量语料还是大部分集中在英文范畴，例如上表的
Wikipedia、Arxiv 等，均是英文数据集；而 C4
等多语言数据集中，英文语料也占据主要地位。目前开源的中文 LLM 如
ChatGLM、Baichuan
等模型均未开放其预训练数据集，开源的中文预训练数据集目前仅有昆仑天工开源的<a href="https://huggingface.co/datasets/Skywork/SkyPile-150B">SkyPile</a>（150B）、中科闻歌开源的<a href="https://huggingface.co/datasets/wenge-research/yayi2_pretrain_data">yayi2</a>（100B）等，相较于英文开源数据集有明显差距。</p>
<h4 id="数据清洗">数据清洗</h4>
<p><strong>预训练数据的处理与清洗</strong>也是 LLM
预训练的一个重要环节。诸多研究证明，预训练数据的质量往往比体量更加重要。预训练数据处理一般包括以下流程：</p>
<ol type="1">
<li>文档准备。由于海量预训练语料往往是从互联网上获得，一般需要从爬取的网站来获得自然语言文档。文档准备主要包括
URL 过滤（根据网页 URL 过滤掉有害内容）、文档提取（从 HTML
中提取纯文本）、语言选择（确定提取的文本的语种）等。</li>
<li>语料过滤。语料过滤的核心目的是去除低质量、无意义、有毒有害的内容，例如乱码、广告等。语料过滤一般有两种方法：基于模型的方法，即通过高质量语料库训练一个文本分类器进行过滤；基于启发式的方法，一般通过人工定义
web 内容的质量指标，计算语料的指标值来进行过滤。</li>
<li>语料去重。实验表示，大量重复文本会显著影响模型的泛化能力，因此，语料去重即删除训练语料中相似度非常高的文档，也是必不可少的一个步骤。去重一般基于
hash
算法计算数据集内部或跨数据集的文档相似性，将相似性大于指定阈值的文档去除；也可以基于子串在序列级进行精确匹配去重。</li>
</ol>
<h3 id="sft-指令微调">SFT 指令微调</h3>
<p>预训练赋予了 LLM 能力，却还需要第二步将其激发出来。经过预训练的 LLM
好像一个博览群书但又不求甚解的书生，对什么样的偏怪问题，都可以流畅地接出下文，但他偏偏又<strong>不知道问题本身的含义</strong>，只会“死板背书”。这一现象的本质是因为，LLM
的预训练任务就是经典的
<strong>CLM</strong>，也就是训<strong>练其预测下一个 token
的能力</strong>，在没有进一步微调之前，其无法与其他下游任务或是用户指令适配。</p>
<p>因此，我们还需要第二步来教这个博览群书的学生如何去使用它的知识，也就是
<strong>SFT（Supervised Fine-Tuning，有监督微调）</strong>。</p>
<p>面对能力强大的
LLM，我们往往不再是在指定下游任务上构造有监督数据进行微调，而是选择训练模型的“通用指令遵循能力”，也就是一般<strong>通过<code>指令微调</code>的方式来进行
SFT</strong>。</p>
<p>所谓指令微调，即我们训练的输入是各种类型的用户指令，而需要模型拟合的输出则是我们希望模型在收到该指令后做出的回复。例如，我们的一条训练样本可以是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input:告诉我今天的天气预报？</span><br><span class="line">output:根据天气预报，今天天气是晴转多云，最高温度26摄氏度，最低温度9摄氏度，昼夜温差大，请注意保暖哦</span><br></pre></td></tr></table></figure>
<p>也就是说，SFT
的主要目标是让模型从多种类型、多种风格的指令中获得泛化的指令遵循能力，也就是能够理解并回复用户的指令。</p>
<h3 id="rlhf">RLHF</h3>
<p>RLHF，全称是 <strong>Reinforcement Learning from Human
Feedback，即人类反馈强化学习</strong>，是利用强化学习来训练 LLM
的关键步骤。相较于在 GPT-3 就已经初见雏形的 SFT，RLHF 往往被认为是
ChatGPT 相较于 GPT-3 的最核心突破。事实上，从功能上出发，我们可以将 LLM
的训练过程分成<strong>预训练与对齐（alignment）两个阶段</strong>。预训练的核心作用是赋予模型海量的知识，而所谓对齐，其实就是让模型与人类价值观一致，从而输出人类希望其输出的内容。在这个过程中，SFT
是让 LLM 和人类的指令对齐，从而具有指令遵循能力；而 RLHF
则是从更深层次令 LLM
和人类价值观对齐，令其达到安全、有用、无害的核心标准。</p>
<p>RLHF 分为两个步骤：<strong>训练 RM 和 PPO 训练</strong>。</p>
<p><strong>RM，Reward Model，即奖励模型</strong>。RM
是用于拟合人类偏好，来给 LLM 做出反馈的。在强化学习的训练中，对于 LLM
的每一个回复，RM
会进行打分，这个打分反映了生成回复符合人类偏好的程度。然后 LLM
会根据强化学习的原理，基于 RM 的打分来进行优化训练。</p>
<p>在完成 RM 训练之后，就可以使用 PPO
算法来进行强化学习训练。<strong>PPO，Proximal Policy
Optimization，近端策略优化算法</strong>，是一种经典的 RL
算法。事实上，强化学习训练时也可以使用其他的强化学习算法，但目前 PPO
算法因为成熟、成本较低，还是最适合 RLHF 的算法。</p>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://datawhalechina.github.io/happy-llm/#/./chapter4/第四章%20大语言模型">第四章
大语言模型</a></p>
]]></content>
      <categories>
        <category>模型</category>
        <category>微调</category>
      </categories>
      <tags>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>jupyter转markdown</title>
    <url>/2025/03/06/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/jupyter%E8%BD%ACmarkdown/</url>
    <content><![CDATA[<h2 id="jupyter转markdown">jupyter转markdown</h2>
<h3 id="一准备工作">一、准备工作</h3>
<p>安装nbconverter: <a href="https://link.zhihu.com/?target=https%3A//nbconvert.readthedocs.io/en/latest/">nbconvert:
Convert Notebooks to other formats</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install nbconvert</span><br></pre></td></tr></table></figure>
<p><strong>注意依赖项：</strong></p>
<ul>
<li><strong>基本依赖：pandoc</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install pandoc</span><br></pre></td></tr></table></figure>
<h3 id="二使用方法">二、使用方法</h3>
<p>命令行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ jupyter nbconvert --to FORMAT notebook.ipynb</span><br></pre></td></tr></table></figure>
<p>这里<code>FORMAT</code> 用具体的格式替换，如 <code>markdown</code>,
<code>html</code>等。</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ jupyter nbconvert --to markdown notebook.ipynb</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://zhuanlan.zhihu.com/p/371132826">Jupyter
Notebook文件转markdown - 知乎</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>杂项</tag>
      </tags>
  </entry>
  <entry>
    <title>qwen3-8b微调实战</title>
    <url>/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/qwen3-8b%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>在完成微调前备知识的学习后，正式开始使用unsloth对Qwen3-8B-unsloth-bnb-4bit模型的lora微调实战</p>
<h3 id="模型加载">模型加载</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from unsloth import FastLanguageModel</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line">max_seq_length = 8192</span><br><span class="line">dtype = None</span><br><span class="line">load_in_4bit = True</span><br><span class="line"></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = &quot;/workspace/qwen3-8b&quot;,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    dtype = dtype,</span><br><span class="line">    load_in_4bit = load_in_4bit,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>FastLanguageModel</code> 是 <strong>Unsloth
框架的核心入口类</strong>，即<strong>“把 Hugging Face 的 transformers
模型‘加速’成支持 QLoRA 微调、显存占用减半、速度提升 2-5
倍的封装器。”</strong></p>
<p><code>max_seq_length = 8192</code><strong>作用</strong>：告诉框架
<strong>“后续所有输入序列的最大长度”</strong>。<strong>内部一次性为位置编码、注意力掩码、KV-Cache
等开辟的张量尺寸</strong>，因此显存随它
<strong>平方级增长</strong>。</p>
<p><code>dtype = None</code><strong>作用</strong>：让 Unsloth
<strong>自动选择最合适的浮点精度</strong>。</p>
<p><code>load_in_4bit = True</code><strong>作用</strong>：把模型<strong>权重量化成
4-bit</strong>，显存降到 1/4，QLoRA 微调必备。</p>
</blockquote>
<h3 id="查看模型与分词器信息">查看模型与分词器信息</h3>
<h4 id="模型信息">模型信息</h4>
<p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">model</span><br></pre></td></tr></table></figure>
<p>通过阅读模型信息我们可以了解到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(embed_tokens): Embedding(151936, 4096, padding_idx=151654)</span><br></pre></td></tr></table></figure>
<p><strong>模型有 15 万个 token 的字典，每个字/词被翻译成 4096
维向量，第 151 654 号 token 被官方指定为填充符。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(layers): ModuleList(</span><br><span class="line">      (0-2): 3 x Qwen3DecoderLayer(</span><br><span class="line">        (self_attn): Qwen3Attention(</span><br><span class="line">          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)</span><br><span class="line">          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)</span><br><span class="line">          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)</span><br><span class="line">          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)</span><br><span class="line">          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)</span><br><span class="line">          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)</span><br><span class="line">          (rotary_emb): LlamaRotaryEmbedding()</span><br><span class="line">        )</span><br><span class="line">        (mlp): Qwen3MLP(</span><br><span class="line">          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)</span><br><span class="line">          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)</span><br><span class="line">          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)</span><br><span class="line">          (act_fn): SiLU()</span><br><span class="line">        )</span><br><span class="line">        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)</span><br><span class="line">        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)</span><br><span class="line">      )</span><br></pre></td></tr></table></figure>
<p>共有36层<strong>Qwen3DecoderLayer</strong>，每层包含<strong>Qwen3Attention</strong>，<strong>Qwen3MLP</strong>（<strong>一个
SwiGLU
前馈网络</strong>），<strong>Qwen3RMSNorm</strong>（两个<strong>归一化层</strong>，对
4096 维的隐藏向量做“均方根归一化”，防止梯度爆炸、稳定训练。）</p>
<figure>
<img src="/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/qwen3-8b%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98/image-20250812153659843.png" alt="image-20250812153659843">
<figcaption aria-hidden="true">image-20250812153659843</figcaption>
</figure>
<p><a href="https://www.cnblogs.com/cavalier-chen/p/18937098">大模型-qwen3
模型结构解读-66 - jack-chen666 - 博客园</a></p>
<blockquote>
<p><strong>LoRA可以插到哪里呢？</strong></p>
<p><strong>凡是打印里每层 Decoder 中出现的
<code>Linear4bit</code>（q/k/v/o + gate/up/down）就是 LoRA
可插、且默认会被插入的位置。</strong></p>
</blockquote>
<h4 id="分词器信息">分词器信息</h4>
<p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tokenizer</span><br></pre></td></tr></table></figure>
<p>查看tokenizer信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Qwen2TokenizerFast(name_or_path=&#x27;/workspace/qwen3-8b&#x27;, vocab_size=151643, model_max_length=40960, is_fast=True, padding_side=&#x27;left&#x27;, truncation_side=&#x27;right&#x27;, special_tokens=&#123;&#x27;eos_token&#x27;: &#x27;&lt;|im_end|&gt;&#x27;, &#x27;pad_token&#x27;: &#x27;&lt;|vision_pad|&gt;&#x27;, &#x27;additional_special_tokens&#x27;: [&#x27;&lt;|im_start|&gt;&#x27;, &#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|object_ref_start|&gt;&#x27;, &#x27;&lt;|object_ref_end|&gt;&#x27;, &#x27;&lt;|box_start|&gt;&#x27;, &#x27;&lt;|box_end|&gt;&#x27;, &#x27;&lt;|quad_start|&gt;&#x27;, &#x27;&lt;|quad_end|&gt;&#x27;, &#x27;&lt;|vision_start|&gt;&#x27;, &#x27;&lt;|vision_end|&gt;&#x27;, &#x27;&lt;|vision_pad|&gt;&#x27;, &#x27;&lt;|image_pad|&gt;&#x27;, &#x27;&lt;|video_pad|&gt;&#x27;]&#125;, clean_up_tokenization_spaces=False, added_tokens_decoder=&#123;</span><br><span class="line">	151643: AddedToken(&quot;&lt;|endoftext|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),</span><br><span class="line">	151644: AddedToken(&quot;&lt;|im_start|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),</span><br><span class="line">	151645: AddedToken(&quot;&lt;|im_end|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),</span><br><span class="line">	151646: AddedToken(&quot;&lt;|object_ref_start|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),</span><br><span class="line">	截取部分</span><br><span class="line">&#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>vocab_size=151643：<strong>模型真正能理解和生成的子词/符号有这 151643
种，其余位置是预留空白。</strong></p>
<p>model_max_length=40960：<strong>理论最大输入长度 40k
token</strong>（实际受显存限制）</p>
<p>is_fast=True：表示 <strong>tokenizer 使用的是 Hugging Face 的「Rust
高速实现」</strong>（即 <em>tokenizers</em> 库）</p>
<p>special_tokens：打印的 <code>special_tokens</code> 字典 &amp;
<code>added_tokens_decoder</code> 已经把 <strong>151643-151668</strong>
全部列出，共 <strong>26 个</strong>。</p>
<h3 id="模拟一次模型处理流程">模拟一次模型处理流程</h3>
<p>将对话内容通过tokenizer进行处理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;&quot;role&quot; : &quot;user&quot;, &quot;content&quot; : &quot;你好，好久不见！&quot;&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tokenize = False,</span><br><span class="line">    add_generation_prompt = True, </span><br><span class="line">    enable_thinking = False, # 设置不思考</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><code>apply_chat_template</code> 是把「人类对话格式的 Python
列表」一键翻译成 <strong>模型能直接理解的带特殊标记的文本字符串（或
token id 序列）</strong> 的“官方模板引擎”。</p>
<p>转化后的格式为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;&lt;|im_start|&gt;user\n你好，好久不见！&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n&lt;think&gt;\n\n&lt;/think&gt;\n\n&#x27;</span><br></pre></td></tr></table></figure>
<p>然后将转化后的字符串<strong>转成 GPU 上的 PyTorch token
张量，准备直接送进模型推理或训练。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">inputs = tokenizer(text, return_tensors=&quot;pt&quot;).to(&quot;cuda&quot;)</span><br></pre></td></tr></table></figure>
<p>以上代码共做了三步：</p>
<ol type="1">
<li><strong>tokenizer(text)</strong> 把前面
<code>apply_chat_template</code> 得到的字符串按词表切成 <strong>token id
列表</strong>。</li>
<li><strong>return_tensors=“pt”</strong> 把列表包成 <strong>PyTorch
张量</strong>（shape = [1, seq_len]）。</li>
<li><strong>.to(“cuda”)</strong> 把张量搬到 <strong>GPU
显存</strong>。</li>
</ol>
<p>输出如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;input_ids&#x27;: tensor([[151644,    872,    198, 108386,   3837, 111920, 101571,   6313, 151645,</span><br><span class="line">            198, 151644,  77091,    198, 151667,    271, 151668,    271]],</span><br><span class="line">       device=&#x27;cuda:0&#x27;), &#x27;attention_mask&#x27;: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device=&#x27;cuda:0&#x27;)&#125;</span><br></pre></td></tr></table></figure>
<table>
<colgroup>
<col style="width: 24%">
<col style="width: 11%">
<col style="width: 63%">
</colgroup>
<thead>
<tr>
<th>键</th>
<th>形状</th>
<th>每个数字的含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>input_ids</strong></td>
<td><code>[1, 17]</code></td>
<td>17 个 token 的 ID 列表，已放到 GPU</td>
</tr>
<tr>
<td><strong>attention_mask</strong></td>
<td><code>[1, 17]</code></td>
<td>17 个 <strong>1</strong>，表示“这些位置都是有效 token，无填充”</td>
</tr>
</tbody>
</table>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">outputs = model.generate(</span><br><span class="line">    input_ids=inputs.input_ids,</span><br><span class="line">    attention_mask=inputs.attention_mask,</span><br><span class="line">    max_new_tokens=max_seq_length,</span><br><span class="line">    use_cache=True,#启用 KV-Cache，避免重复计算，显存换时间</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>让模型在 GPU 上 <strong>根据已有 token
继续生成文本</strong>，直到达到 <code>max_new_tokens</code>
或遇到终止符。</p>
<p>outputs格式和inputs类似，使用nput_ids表示后续字符</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">response = tokenizer.batch_decode(outputs)</span><br></pre></td></tr></table></figure>
<p>把模型输出的 <strong>token id
序列</strong>（<code>outputs</code>）一次性还原成
<strong>人类可读的字符串</strong>。</p>
<p>输出如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;&lt;|im_start|&gt;user\n你好，好久不见！&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n&lt;think&gt;\n\n&lt;/think&gt;\n\n你好！好久不见！最近过得怎么样？有什么新鲜事想和我分享吗？😊&lt;|im_end|&gt;&#x27;</span><br></pre></td></tr></table></figure>
<p>这里展示的是没有思考过程的，最简单对话流程，若设置思考模式，完整代码如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tools = tools,#同样，可以设置function calling</span><br><span class="line">    tokenize = False,</span><br><span class="line">    add_generation_prompt = True, </span><br><span class="line">    enable_thinking = True, # 设置思考</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">inputs = tokenizer(text, return_tensors=&quot;pt&quot;).to(&quot;cuda&quot;)</span><br><span class="line"></span><br><span class="line">outputs = model.generate(</span><br><span class="line">    input_ids=inputs.input_ids,</span><br><span class="line">    attention_mask=inputs.attention_mask,</span><br><span class="line">    max_new_tokens=max_seq_length,</span><br><span class="line">    use_cache=True,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response = tokenizer.batch_decode(outputs)</span><br></pre></td></tr></table></figure>
<p>当然，除了使用上述底层API进行对话外，Unsloth还提供了更加便捷的流式输出模型对话信息的函数，基本对话效果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;&quot;role&quot; : &quot;user&quot;, &quot;content&quot; : &quot;你好，好久不见！&quot;&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tokenize = False,</span><br><span class="line">    add_generation_prompt = True, </span><br><span class="line">    enable_thinking = False, </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">_ = model.generate(</span><br><span class="line">    **tokenizer(text, return_tensors = &quot;pt&quot;).to(&quot;cuda&quot;),</span><br><span class="line">    max_new_tokens = 256, # Increase for longer outputs!</span><br><span class="line">    temperature = 0.7, top_p = 0.8, top_k = 20, # For non thinking</span><br><span class="line">    streamer = TextStreamer(tokenizer, skip_prompt = True),#实时流式输出：每解码一个 token 就立刻打印到终端</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="准备数据集">准备数据集</h3>
<h4 id="下载数据集">下载数据集</h4>
<p>选取的两个数据集</p>
<ol type="1">
<li>我们使用 Open Math Reasoning 数据集，该数据集曾被用于赢得 AIMO（AI
数学奥林匹克 - 第二届进步奖）挑战！我们从中抽取了 10%
可验证的推理轨迹，这些轨迹是基于 DeepSeek R1 模型生成的，并且准确率超过
95%。数据集地址：https://huggingface.co/datasets/unsloth/OpenMathReasoning-mini</li>
<li>我们还利用了 Maxime Labonne 的 FineTome-100k
数据集，该数据集风格类似 ShareGPT。但我们需要将其转换为 HuggingFace
通用的多轮对话格式。数据集地址：https://huggingface.co/datasets/mlabonne/FineTome-100k</li>
</ol>
<p>在实际微调过程中，大多都会使用huggingface的datasets库进行数据集下载和管理，实际下载流程如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">!pip install --upgrade datasets huggingface_hub</span><br></pre></td></tr></table></figure>
<p><code>datasets</code> 是 Hugging Face
提供的一个高效数据处理库，专为机器学习和大语言模型（LLM）训练而设计。它支持加载、处理、转换和保存各种格式的数据（如
JSON、CSV、Parquet 等），并能与 <code>transformers</code>
模型无缝集成。通过
<code>datasets</code>，开发者可以快速完成数据清洗、切分、tokenization
等常见任务，大大提升训练效率，特别适合用于指令微调、对话生成、Function
Calling 等任务的数据预处理。</p>
<p>然后分别下载并导入这两个库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_dataset = load_dataset(&quot;unsloth/OpenMathReasoning-mini&quot;, split = &quot;cot&quot;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>cot全称为<strong>Chain-of-Thought，思维链</strong>，是「<strong>一步一步把思考过程写出来</strong>」的解题方式，而不是直接给出最终答案。</p>
<p><strong>只下 cot
是因为任务只需要“带推理过程”的那部分数据，其他子集对当前微调目标无用，避免冗余下载。</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">non_reasoning_dataset = load_dataset(&quot;mlabonne/FineTome-100k&quot;, split = &quot;train&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="查看数据集">查看数据集</h4>
<p>然后输入数据集名称，即可查看数据集基本信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_dataset</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;expected_answer&#x27;, &#x27;problem_type&#x27;, &#x27;problem_source&#x27;, &#x27;generation_model&#x27;, &#x27;pass_rate_72b_tir&#x27;, &#x27;problem&#x27;, &#x27;generated_solution&#x27;, &#x27;inference_mode&#x27;],</span><br><span class="line">    num_rows: 19252</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>一共 19 252 条</strong>
<strong>CoT（思维链）数学题</strong>，每条包含 8
个字段，可直接用来训练/评估模型的逐步推理能力。</p>
<p>generated_solution：模型自己写的 逐步推理 + 最终答案（就是你想要的
CoT）</p>
<p>expected_answer：标准答案（通常是一个简洁数字或表达式）</p>
<p>generation_model：生成这条 CoT 的“教师模型”名字，比如 qwen2-72b</p>
<p>加上索引则可以直接查看对应数据集信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_dataset[0]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;expected_answer&#x27;: &#x27;14&#x27;,</span><br><span class="line"> &#x27;problem_type&#x27;: &#x27;has_answer_extracted&#x27;,</span><br><span class="line"> &#x27;problem_source&#x27;: &#x27;aops_c4_high_school_math&#x27;,</span><br><span class="line"> &#x27;generation_model&#x27;: &#x27;DeepSeek-R1&#x27;,</span><br><span class="line"> &#x27;pass_rate_72b_tir&#x27;: &#x27;0.96875&#x27;,</span><br><span class="line"> &#x27;problem&#x27;: &#x27;Given $\\sqrt&#123;x^2+165&#125;-\\sqrt&#123;x^2-52&#125;=7$ and $x$ is positive, find all possible values of $x$.&#x27;,</span><br><span class="line"> &#x27;generated_solution&#x27;: &quot;&lt;think&gt;\nOkay, let&#x27;s see. I need to solve the equation √(x² + 165) - √(x² - 52) = 7, a截取部分&quot;,</span><br><span class="line"> &#x27;inference_mode&#x27;: &#x27;cot&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>能够看出这是一个基于DeepSeek
R1回答的数学数据集，其中<code>problem</code>是问题，<code>generated_solution</code>是数学推导过程（即思考过程），而<code>expected_answer</code>则是最终的答案。该数据集总共接近2万条数据</p>
<p>而对话数据集如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">non_reasoning_dataset</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;conversations&#x27;, &#x27;source&#x27;, &#x27;score&#x27;],</span><br><span class="line">    num_rows: 100000</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">non_reasoning_dataset[0]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;conversations&#x27;: [&#123;&#x27;from&#x27;: &#x27;human&#x27;,</span><br><span class="line">   &#x27;value&#x27;: &#x27;Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and prov截取&#x27;&#125;,</span><br><span class="line">  &#123;&#x27;from&#x27;: &#x27;gpt&#x27;,</span><br><span class="line">   &#x27;value&#x27;: &#x27;Boolean operators are logical operators used in programming to manipulate boolean values. The截取&#x27;&#125;],</span><br><span class="line"> &#x27;source&#x27;: &#x27;infini-instruct-top-500k&#x27;,</span><br><span class="line"> &#x27;score&#x27;: 5.212620735168457&#125;</span><br></pre></td></tr></table></figure>
<p>其中每一条数据都是一个对话，包含一组或者多组ChatGPT的聊天信息，其中<code>from</code>代表是用户消息还是大模型回复消息，而<code>value</code>则是对应的文本。该对话数据集总共包含10万条数据</p>
<p>能够看出dataset是一种类似json的数据格式，每条数据都以字段格式进行存储，在实际微调过程中，我们需要先将数据集的目标字段进行提取和拼接，然后加载到Qwen3模型的提示词模板中，并最终带入Unsloth进行微调。</p>
<h3 id="数据集清洗">数据集清洗</h3>
<h4 id="对话数据集的清洗">对话数据集的清洗</h4>
<p>接下来尝试对上述两个格式各异的数据集进行数据清洗，主要是围绕数据集进行<strong>数据格式</strong>的调整，便于后续<strong>带入Qwen3提示词模板</strong>。对于dataset格式的数据对象来说，可以先创建满足格式调整的函数，然后使用map方法对数据集格式进行调整。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def generate_conversation(examples):</span><br><span class="line">    problems  = examples[&quot;problem&quot;]</span><br><span class="line">    solutions = examples[&quot;generated_solution&quot;]</span><br><span class="line">    conversations = []</span><br><span class="line">    for problem, solution in zip(problems, solutions):</span><br><span class="line">        conversations.append([</span><br><span class="line">            &#123;&quot;role&quot; : &quot;user&quot;,      &quot;content&quot; : problem&#125;,</span><br><span class="line">            &#123;&quot;role&quot; : &quot;assistant&quot;, &quot;content&quot; : solution&#125;,</span><br><span class="line">        ])</span><br><span class="line">    return &#123; &quot;conversations&quot;: conversations, &#125;</span><br></pre></td></tr></table></figure>
<p>这里先创建generate_conversation函数，用于对reasoning_dataset中的每一条数据进行格式调整，即通过新创建一个新的特征conversations，来以对话形式保存历史问答数据：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_data = reasoning_dataset.map(</span><br><span class="line">    generate_conversation,  # 处理函数</span><br><span class="line">    batched=True            # 批量处理，加快速度</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>map：对数据集中的每一批样本调用 generate_conversation</p>
<p>batched=True：一次传入一批（几百到几千条）样本，避免逐行慢速 Python
循环</p>
</blockquote>
<p>接下来将其带入Qwen3的提示词模板中进行转化：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_conversations = tokenizer.apply_chat_template(</span><br><span class="line">    reasoning_data[&quot;conversations&quot;],</span><br><span class="line">    tokenize = False,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>之后即可带入这些数据进行微调。能看出每条数据的格式都和Unsloth底层对话API创建的数据格式类似，之后我们或许可以借助Unsloth底层对话API来创建微调数据集。</p>
<h4 id="推理数据集的推理">推理数据集的推理</h4>
<p>然后继续处理non_reasoning_conversations数据集，由于该数据集采用了sharegpt对话格式，因此可以直接借助Unsloth的standardize_sharegpt库进行数据集的格式转化，转化效果如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from unsloth.chat_templates import standardize_sharegpt</span><br></pre></td></tr></table></figure>
<blockquote>
<p>standardize_sharegpt的作用</p>
<p><strong>把“ShareGPT 格式”的对话数据一键转成 Unsloth / Hugging Face
通用的 <code>role/content</code> 列表，后续就能直接用
<code>apply_chat_template</code> 生成训练文本。</strong></p>
<p>1️⃣ ShareGPT 原始长什么样？</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1+1=?&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span>  <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>2️⃣ 转换后长什么样？</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span>      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1+1=?&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dataset = standardize_sharegpt(non_reasoning_dataset)</span><br></pre></td></tr></table></figure>
<p>接下来即可直接带入Qwen3对话模板中进行格式调整：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">non_reasoning_conversations = tokenizer.apply_chat_template(</span><br><span class="line">    dataset[&quot;conversations&quot;],</span><br><span class="line">    tokenize = False,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="数据集采样">数据集采样</h4>
<p>自此即完成了每个数据集的格式调整工作，不过这两个数据集并不均衡，能看得出非推理类数据集的长度更长。我们假设希望模型保留一定的推理能力，但又特别希望它作为一个聊天模型来使用。</p>
<p>因此，我们需要定义一个
<strong>仅聊天数据的比例</strong>。<strong>目标是从两个数据集中构建一个混合训练集</strong>。这里我们可以设定一个
25% 推理数据、75% 聊天数据的比例：也就是说，从推理数据集中抽取
25%（或者说，抽取占比为 100% - 聊天数据占比
的部分），最后将这两个数据集合并起来即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chat_percentage = 0.75</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">#先把非推理对话列表转成 Pandas Series，方便后续抽样</span><br><span class="line">non_reasoning_subset = pd.Series(non_reasoning_conversations)</span><br><span class="line"></span><br><span class="line">non_reasoning_subset = non_reasoning_subset.sample(#sample(...)为无放回随机抽样</span><br><span class="line">    int(len(reasoning_conversations) * (1.0 - chat_percentage)),#计算 需要抽多少条非推理样本</span><br><span class="line">    random_state = 2407,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这里我们需要先将上述list格式的数据转化为pd.Series数据，然后进行采样，并最终将其转化为dataset类型对象。（此外也可以先转化为dataset对象类型，然后再进行采样）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data = pd.concat([</span><br><span class="line">    pd.Series(reasoning_conversations),</span><br><span class="line">    pd.Series(non_reasoning_subset)</span><br><span class="line">])</span><br><span class="line">data.name = &quot;text&quot;</span><br><span class="line"></span><br><span class="line">from datasets import Dataset</span><br><span class="line"></span><br><span class="line">combined_dataset = Dataset.from_pandas(pd.DataFrame(data))</span><br><span class="line">combined_dataset = combined_dataset.shuffle(seed = 3407)#用固定种子随机打乱顺序</span><br></pre></td></tr></table></figure>
<blockquote>
<p>pd.concat([…])：纵向拼接 → 一条长 Series，顺序：先推理，后非推理</p>
<p>Dataset.from_pandas(…)：把 Pandas Series 转成 Hugging Face
Dataset</p>
</blockquote>
<p><strong>把“推理对话”和“抽样后的非推理对话”合并成一个</strong>
<strong>随机打乱</strong> <strong>的 <code>Dataset</code>
对象，后面可直接拿去训练。</strong></p>
<h4 id="查看数据集-1">查看数据集</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">combined_dataset[0]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;text&#x27;: &quot;&lt;|im_start|&gt;user\nCalculate the pH during a titration when 9.54 mL of a 0.15 M HCl solution has reacted with 22.88 mL of a 0.14 M NaOH solution?&lt;|im_end|&gt;\n&lt;|im_st截取&quot;,</span><br><span class="line"> &#x27;__index_level_0__&#x27;: 49038&#125;</span><br></pre></td></tr></table></figure>
<p>其中text字段就是后续带入微调的字段。</p>
<h4 id="数据集保存">数据集保存</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">combined_dataset.save_to_disk(&quot;/workspace/cleaned_qwen3_dataset&quot;)</span><br></pre></td></tr></table></figure>
<p>后续使用时即可使用如下代码进行读取：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from datasets import load_from_disk</span><br><span class="line">combined_dataset = load_from_disk(&quot;cleaned_qwen3_dataset&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="qwen3推理能力高效微调流程">Qwen3推理能力高效微调流程</h3>
<p>准备完数据之后，即可开始进行微调。这里我们先进行少量数据微调测试，程序能够基本跑通后，我们再进行大规模数据集微调。</p>
<h4 id="进行lora参数注入">进行LoRA参数注入</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,</span><br><span class="line">    r = 32,           # 秩（LoRA 低秩矩阵的列数）。越大可学习参数越多，显存也越高。常用 8/16/32/64/128</span><br><span class="line">    target_modules = [&quot;q_proj&quot;, &quot;k_proj&quot;, &quot;v_proj&quot;, &quot;o_proj&quot;,</span><br><span class="line">                      &quot;gate_proj&quot;, &quot;up_proj&quot;, &quot;down_proj&quot;],  # 在哪些线性层插入 LoRA 适配器（Attention + MLP）</span><br><span class="line">    lora_alpha = 32,  # 缩放因子。经验值 = rank 或 2×rank，控制更新强度</span><br><span class="line">    lora_dropout = 0, # LoRA 本身的 dropout 比例；0 省显存且速度最快</span><br><span class="line">    bias = &quot;none&quot;,    # 是否训练原 Linear 的偏置。设为 &quot;none&quot; 不训练，进一步节省显存</span><br><span class="line">    use_gradient_checkpointing = &quot;unsloth&quot;,  # 梯度检查点：True 省显存，&quot;unsloth&quot; 再省 30 %，超长上下文必开</span><br><span class="line">    random_state = 3407,  # 随机种子，保证 LoRA 初始化可复现</span><br><span class="line">    use_rslora = False,   # 默认 False，True 则启用 Rank-Stabilized LoRA（训练更稳，但显存稍高）</span><br><span class="line">    loftq_config = None,  # LoftQ 量化初始化，None 表示不用；若配置可进一步压缩初始权重</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这一步<strong>“LoRA
参数注入”</strong>就是：<strong>在不改动原模型权重的前提下，给指定层插入少量</strong>
<strong>可训练低秩矩阵</strong> <strong>（LoRA 适配器），从而只更新 &lt;
1 % 的参数，完成高效微调。</strong></p>
<blockquote>
<p>不是“在原有层之外再增加一层”，而是<strong>把 LoRA
的“小矩阵”插到</strong> <strong>原有线性层内部</strong>：</p>
<ul>
<li>原层结构（冻结）： <code>x → Linear4bit(W) → y</code></li>
<li>注入后结构（冻结 + 可训练）：
<code>x → [Linear4bit(W)  +  LoRA(A·B)] → y</code></li>
</ul>
<p><code>A</code> 和 <code>B</code> 两个低秩矩阵被
<strong>注册为同一层的新参数</strong>，<strong>不新建网络层</strong>，参数在
<strong>前向时相加</strong>，<strong>反向只更新 A 和 B</strong>。</p>
</blockquote>
<h4 id="设置微调参数">设置微调参数</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from trl import SFTTrainer, SFTConfig</span><br><span class="line"></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model=model,                       # 已插入 LoRA 的 4-bit 模型</span><br><span class="line">    tokenizer=tokenizer,               # 对应 tokenizer（含 chat 模板）</span><br><span class="line">    train_dataset=combined_dataset,    # 训练集：聊天+推理对话</span><br><span class="line">    eval_dataset=None,                 # 如需验证，把验证集放进来即可</span><br><span class="line"></span><br><span class="line">    args=SFTConfig(</span><br><span class="line">        dataset_text_field=&quot;text&quot;,      # 训练集中每条样本的字段名（对话列表）</span><br><span class="line">        per_device_train_batch_size=2,  # 每张显卡上的 batch_size（显存决定）</span><br><span class="line">        gradient_accumulation_steps=4,  # 4 次累积 → 全局有效 batch = 2×4 = 8</span><br><span class="line">        warmup_steps=5,                # 前 5 步线性预热学习率</span><br><span class="line">        max_steps=30,                  # 训练 30 步（调试阶段）；正式可用 num_train_epochs</span><br><span class="line">        learning_rate=2e-4,            # LoRA 常用 2e-4；长训降到 2e-5</span><br><span class="line">        logging_steps=1,               # 每 1 步打印一次日志</span><br><span class="line">        optim=&quot;adamw_8bit&quot;,            # 8-bit AdamW，省显存</span><br><span class="line">        weight_decay=0.01,             # L2 正则</span><br><span class="line">        lr_scheduler_type=&quot;linear&quot;,    # 线性衰减到 0</span><br><span class="line">        seed=3407,                     # 固定随机种子</span><br><span class="line">        report_to=&quot;swanlab&quot;,             # 把指标推送到 swanlab</span><br><span class="line">    ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/huggingface/trl">TRL</a> (Transformers
Reinforcement Learning，用强化学习训练Transformers模型)
是一个领先的Python库，旨在通过监督微调（SFT）、近端策略优化（PPO）和直接偏好优化（DPO）等先进技术，对基础模型进行训练后优化。TRL
建立在 🤗 Transformers
生态系统之上，支持多种模型架构和模态，并且能够在各种硬件配置上进行扩展。</p>
<p>其中<code>SFTTrainer</code>：一个专门为指令微调设计的训练器，封装了
Hugging Face 的
<code>Trainer</code>，而<code>SFTConfig</code>：配置训练参数的专用类，功能类似
<code>TrainingArguments</code>。而SFTConfig核心参数解释如下：</p>
<table>
<colgroup>
<col style="width: 34%">
<col style="width: 65%">
</colgroup>
<thead>
<tr>
<th>参数名</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>dataset_text_field="text"</code></td>
<td>数据集中用于训练的字段名称，如 <code>text</code> 或
<code>prompt</code></td>
</tr>
<tr>
<td><code>per_device_train_batch_size=2</code></td>
<td>每张 GPU 上的 batch size 是 2</td>
</tr>
<tr>
<td><code>gradient_accumulation_steps=4</code></td>
<td>梯度累计 4 次后才进行一次反向传播（等效于总 batch size = 2 × 4 =
8）</td>
</tr>
<tr>
<td><code>warmup_steps=5</code></td>
<td>前 5 步进行 warmup（缓慢提升学习率）</td>
</tr>
<tr>
<td><code>max_steps=30</code></td>
<td>最多训练 30 步（适合调试或快速实验）</td>
</tr>
<tr>
<td><code>learning_rate=2e-4</code></td>
<td>初始学习率（短训练可用较高值）</td>
</tr>
<tr>
<td><code>logging_steps=1</code></td>
<td>每训练 1 步就打印一次日志</td>
</tr>
<tr>
<td><code>optim="adamw_8bit"</code></td>
<td>使用 8-bit AdamW 优化器（节省内存，Unsloth 支持）</td>
</tr>
<tr>
<td><code>weight_decay=0.01</code></td>
<td>权重衰减，用于防止过拟合</td>
</tr>
<tr>
<td><code>lr_scheduler_type="linear"</code></td>
<td>线性学习率调度器（从高到低线性下降）</td>
</tr>
<tr>
<td><code>seed=3407</code></td>
<td>固定随机种子，确保结果可复现</td>
</tr>
<tr>
<td><code>report_to="none"</code></td>
<td>不使用 WandB 或 TensorBoard 等日志平台（可改为
<code>"wandb"</code>）</td>
</tr>
</tbody>
</table>
<blockquote>
<ol type="1">
<li><p><strong>per_device_train_batch_size=2</strong>
<strong>每次前向只用了 2 条样本</strong> → 显存占用小，单卡就能跑。</p>
<p><strong>batch_size
决定「每一步真正喂给模型的样本数量」，越大训练越稳，但对显存要求越高。</strong></p></li>
<li><p><strong>gradient_accumulation_steps=4</strong> <strong>把这 2
条样本算出的梯度先攒起来，攒够 4 次再一次性做反向传播</strong> →
等效于一次性看了 <strong>2 × 4 = 8 条样本</strong>，但显存仍按 2
条算。</p></li>
</ol>
</blockquote>
<p>此时基本训练过程为： 1. 从 <code>combined_dataset</code>
中取出一批样本（2 条） 2. 重复上面过程 4
次（<code>gradient_accumulation_steps=4</code>） 3.
将累计的梯度用于更新模型一次参数（等效于一次大 batch 更新） 4.
重复上述过程，直到 <code>max_steps=30</code> 停止</p>
<h4 id="设置训练可视化swanlab">设置训练可视化swanlab</h4>
<p><a href="https://docs.swanlab.cn/guide_cloud/integration/integration-huggingface-trl.html">🤗HuggingFace
Trl | SwanLab官方文档</a></p>
<p>只需要在你的训练代码中，找到HF的<code>Config</code>部分（比如<code>SFTConfig</code>、<code>GRPOConfig</code>等），添加<code>report_to="swanlab"</code>参数，即可完成集成。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from trl import SFTConfig, SFTTrainer</span><br><span class="line"></span><br><span class="line">args = SFTConfig(</span><br><span class="line">    ...,</span><br><span class="line">    report_to=&quot;swanlab&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(..., args=args)</span><br></pre></td></tr></table></figure>
<p>默认下，项目名会使用你运行代码的<code>目录名</code>。</p>
<p>如果你想自定义项目名，可以设置<code>SWANLAB_PROJECT</code>环境变量：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&quot;SWANLAB_PROJECT&quot;]=&quot;qwen2-sft&quot;</span><br></pre></td></tr></table></figure>
<h4 id="微调执行流程">微调执行流程</h4>
<p>一切准备就绪后，接下来即可开始进行微调。由于本次微调总共只运行30个step，整个过程并不会很长，实际执行过程如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">trainer_stats = trainer.train()</span><br></pre></td></tr></table></figure>
<h4 id="保存模型">保存模型</h4>
<p><strong>1. 保存 LoRA Adapter</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 保存 LoRA adapter（仅几十 MB）</span><br><span class="line">save_path = &quot;./lora-adapter&quot;</span><br><span class="line">model.save_pretrained(save_path)          # LoRA 权重</span><br><span class="line">tokenizer.save_pretrained(save_path)      # 词表</span><br></pre></td></tr></table></figure>
<p>以后加载：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = <span class="string">&quot;base-model-name-or-path&quot;</span>,</span><br><span class="line">    max_seq_length = <span class="number">2048</span>,</span><br><span class="line">    load_in_4bit = <span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">model = FastLanguageModel.get_peft_model(model, ...)  <span class="comment"># 同训练时参数</span></span><br><span class="line">model.load_adapter(save_path)   <span class="comment"># 把 LoRA 权重挂回去</span></span><br></pre></td></tr></table></figure>
<p><strong>2.合并 LoRA → 完整模型</strong></p>
<p>如果你想把 <strong>LoRA 权重合并到基座</strong>
得到一个独立的大模型（方便推理、上传 Hub）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 合并权重</span></span><br><span class="line">merged_model = model.merge_and_unload()   <span class="comment"># 返回普通 transformers 模型</span></span><br><span class="line">merged_model.save_pretrained(<span class="string">&quot;./merged-model&quot;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;./merged-model&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>合并后就是完整的大模型（GB 级），可直接用
<code>AutoModelForCausalLM.from_pretrained("./merged-model")</code>
加载，不依赖 Unsloth。</p>
<h3 id="微调结果">微调结果</h3>
<h4 id="可视化结果">可视化结果</h4>
<figure>
<img src="/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/qwen3-8b%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98/image-20250813111238359.png" alt="image-20250813111238359">
<figcaption aria-hidden="true">image-20250813111238359</figcaption>
</figure>
<p><a href="https://swanlab.cn/@zxj123/Fine-tune-Qwen-8B/runs/e2l6g6s3v7dlb7hmfircv/chart">图表
｜ Fine-tune-Qwen-8B/rat-2</a></p>
<table>
<colgroup>
<col style="width: 18%">
<col style="width: 22%">
<col style="width: 28%">
<col style="width: 30%">
</colgroup>
<thead>
<tr>
<th>指标名称</th>
<th>含义</th>
<th>单位/范围提示</th>
<th>常见关注点</th>
</tr>
</thead>
<tbody>
<tr>
<td>train/loss</td>
<td>训练损失（Training Loss）</td>
<td>标量，越小越好</td>
<td>是否持续下降、是否震荡、是否过拟合</td>
</tr>
<tr>
<td>train/grad_norm</td>
<td>梯度范数（Gradient Norm）</td>
<td>标量，通常 0.01–1.0 为合理区间</td>
<td>是否爆炸（&gt;10）或消失（&lt;1e-4）</td>
</tr>
<tr>
<td>train/learning_rate</td>
<td>学习率（Learning Rate）</td>
<td>标量，如 1e-4、5e-4 等</td>
<td>是否过大导致震荡、过小导致收敛慢</td>
</tr>
<tr>
<td>train/epoch</td>
<td>已训练的轮次（Epoch）</td>
<td>标量，1.0 表示完整遍历一次训练集</td>
<td>当前已训练多少轮、是否还需继续训练</td>
</tr>
<tr>
<td>train/global_step</td>
<td>全局步数（Global Step）</td>
<td>整数，每个 batch +1</td>
<td>与 epoch 对应，计算已见样本量</td>
</tr>
</tbody>
</table>
<h4 id="对话测试">对话测试</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;&quot;role&quot; : &quot;user&quot;, &quot;content&quot; : &quot;解决(x + 2)^2 = 0.&quot;&#125;</span><br><span class="line">]</span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tokenize = False,</span><br><span class="line">    add_generation_prompt = True, # Must add for generation</span><br><span class="line">    enable_thinking = True, # Disable thinking</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">from transformers import TextStreamer</span><br><span class="line">_ = model.generate(</span><br><span class="line">    **tokenizer(text, return_tensors = &quot;pt&quot;).to(&quot;cuda&quot;),</span><br><span class="line">    max_new_tokens = 20488, # Increase for longer outputs!</span><br><span class="line">    temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking</span><br><span class="line">    streamer = TextStreamer(tokenizer, skip_prompt = True),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>模型</category>
        <category>微调</category>
      </categories>
      <tags>
        <tag>模型微调</tag>
        <tag>LoRA</tag>
      </tags>
  </entry>
  <entry>
    <title>消息队列Message Queue</title>
    <url>/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[<h2 id="什么是消息队列">什么是消息队列</h2>
<p>用一个最简单的生活类比：<strong>去餐厅吃饭</strong>。</p>
<ul>
<li><strong>没有 MQ
(同步通信)</strong>：你（客户端）点完菜，必须站在厨房门口盯着厨师（服务端）把菜做好，端走后才能去干别的事。如果厨师动作慢，你就被“卡”住了。</li>
<li><strong>有 MQ
(异步通信)</strong>：你把点菜单交给服务员（MQ）。服务员把单子贴在后厨的墙上（队列）。你就可以回座位玩手机了。厨师做完一道菜，就从墙上撕下一个单子继续做。</li>
</ul>
<p><strong>技术上的定义：</strong>
消息队列是一个<strong>存放消息的容器</strong>。</p>
<ol type="1">
<li><strong>生产者
(Producer)</strong>：发送消息的程序（比如：点餐系统）。</li>
<li><strong>消费者
(Consumer)</strong>：从队列中读取并处理消息的程序（比如：后厨系统）。</li>
<li><strong>Broker</strong>：消息队列的服务端本身，负责接收、存储和转发消息。</li>
</ol>
<p><strong>消息队列（Message Queue, MQ）</strong>
是一种<strong>进程间通信（IPC）*<em>或*</em>服务间通信</strong>的中间件机制。它通过提供<strong>异步通信协议</strong>，允许发送者（Producer）和接收者（Consumer）在不同的时间、不同的进程甚至不同的网络环境下进行数据交换。</p>
<h2 id="为什么要用-mq">为什么要用 MQ？</h2>
<p>MQ 主要是为了解决三个问题：</p>
<h4 id="解耦-decoupling">1. 解耦 (Decoupling)</h4>
<ul>
<li><strong>场景</strong>：系统 A 下单后，需要通知系统 B（库存）、系统
C（积分）、系统 D（短信）。</li>
<li><strong>问题</strong>：如果不用 MQ，A 必须调用 B、C、D 的接口。如果
D 挂了，A 也会报错；如果后面加个系统 E，A 又要改代码。</li>
<li><strong>MQ 方案</strong>：A 下单后，往 MQ
扔一条消息“有人下单了”，然后就不管了。B、C、D 自己去 MQ
里监听这条消息。哪怕 D 挂了，A 也不受影响。</li>
</ul>
<figure>
<img src="/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20251217163458817.png" alt="image-20251217163458817">
<figcaption aria-hidden="true">image-20251217163458817</figcaption>
</figure>
<h4 id="异步-asynchronous">2. 异步 (Asynchronous)</h4>
<ul>
<li><strong>场景</strong>：用户注册，需要写数据库(50ms) + 发邮件(50ms) +
发短信(50ms)。总共耗时 150ms。</li>
<li><strong>MQ 方案</strong>：写完数据库(50ms)后，往 MQ
发个消息(5ms)就直接告诉用户“注册成功”。邮件和短信服务自己在后台慢慢消费消息去发送。响应时间从
150ms 降到了 55ms。</li>
</ul>
<figure>
<img src="/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20251217163433856.png" alt="image-20251217163433856">
<figcaption aria-hidden="true">image-20251217163433856</figcaption>
</figure>
<h4 id="削峰-peak-shaving-load-leveling">3. 削峰 (Peak Shaving / Load
Leveling)</h4>
<ul>
<li><strong>场景</strong>：秒杀活动，平时每秒 10 个请求，秒杀时每秒 5000
个请求。数据库只能抗 2000 个，直接崩了。</li>
<li><strong>MQ 方案</strong>：把 5000 个请求全部打入 MQ（MQ
的写入性能通常极高）。后台系统按照自己的能力（比如每秒处理 2000
个）慢慢从 MQ 里拉取处理。就像水库蓄水一样，保护下游系统不被冲垮。</li>
</ul>
<figure>
<img src="/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20251217163517525.png" alt="image-20251217163517525">
<figcaption aria-hidden="true">image-20251217163517525</figcaption>
</figure>
<h2 id="市面上主流的-mq-选型">市面上主流的 MQ 选型</h2>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 27%">
<col style="width: 32%">
<col style="width: 30%">
</colgroup>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>RabbitMQ</strong></th>
<th><strong>RocketMQ</strong></th>
<th><strong>Kafka</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>主要特点</strong></td>
<td><strong>稳定、功能全</strong></td>
<td><strong>金融级可靠、高吞吐</strong></td>
<td><strong>极高吞吐、大数据</strong></td>
</tr>
<tr>
<td><strong>开发语言</strong></td>
<td>Erlang</td>
<td>Java</td>
<td>Scala/Java</td>
</tr>
<tr>
<td><strong>单机吞吐量</strong></td>
<td>万级</td>
<td>十万级</td>
<td>百万级</td>
</tr>
<tr>
<td><strong>消息延迟</strong></td>
<td>微秒级 (极快)</td>
<td>毫秒级</td>
<td>毫秒级</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>中小型公司，对实时性要求高，数据量没那么大。</td>
<td>阿里出品，适合复杂的业务系统（如电商交易），高可靠。</td>
<td><strong>日志收集、大数据实时计算</strong>、用户行为追踪。</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>Erlang 语言难维护，吞吐量相对低。</td>
<td>社区主要在国内。</td>
<td>某些配置下可能丢数据，不适合极其严苛的金融交易。</td>
</tr>
</tbody>
</table>
<h2 id="exchange交换器">Exchange（交换器）</h2>
<p>在消息队列（特别是基于 <strong>AMQP 协议</strong> 的实现，如
<strong>RabbitMQ</strong>）中，<strong>交换器 (Exchange)</strong>
是核心组件之一。</p>
<p>如果说 Queue（队列）是存储消息的“仓库”，那么
Exchange（交换器）就是负责分拣和投递的“<strong>路由器</strong>”。</p>
<p>在专业的 AMQP 架构中，<strong>生产者 (Producer)
绝不会直接把消息发送到队列中</strong>，而是发送给交换器。交换器根据既定的<strong>路由规则
(Routing Key)</strong>，将消息分发到一个或多个队列中。</p>
<h3 id="核心机制binding-与-routing-key">核心机制：Binding 与 Routing
Key</h3>
<p>理解交换器，必须先理解两个概念：</p>
<ul>
<li><strong>Binding (绑定)</strong>：这是连接 Exchange 和 Queue
的纽带。它告诉交换器：“如果你收到了消息，请把它按这条路径转给这个队列。”</li>
<li><strong>Routing Key
(路由键)</strong>：生产者发送消息时带的一个“标签”。交换器会拿着这个标签，去和
Binding 规则做匹配。</li>
</ul>
<p><strong>数据流向：</strong></p>
<blockquote>
<p>Producer –&gt; <code>Message + RoutingKey</code> –&gt;
<strong>Exchange</strong> –&gt; (匹配逻辑) –&gt; <strong>Queue</strong>
–&gt; Consumer</p>
</blockquote>
<h2 id="rabbitmq-的工作模式">RabbitMQ 的工作模式</h2>
<h3 id="第一类基础队列模式-点对点">第一类：基础队列模式 (点对点)</h3>
<p>这两种模式主要利用队列“存储转发”的特性，通常不需要显式配置复杂的
Exchange（交换机）。</p>
<h4 id="简单模式-simple-hello-world">1. 简单模式 (Simple / Hello
World)</h4>
<ul>
<li><strong>架构</strong>：<code>P</code> (生产者) -&gt;
<code>Queue</code> (队列) -&gt; <code>C</code> (消费者)</li>
<li><strong>机制</strong>：最原始的模式。一个生产者对应一个消费者。</li>
<li><strong>场景</strong>：简单的“短信发送”任务。程序 A 产生内容，程序 B
发送，两者不需要同时在线。</li>
</ul>
<h4 id="工作队列模式-work-queues">2. 工作队列模式 (Work Queues)</h4>
<ul>
<li><strong>架构</strong>：<code>P</code> -&gt; <code>Queue</code> -&gt;
<code>C1</code>, <code>C2</code>…</li>
<li><strong>机制</strong>：<strong>竞争消费</strong>。一个队列对应多个消费者，但<strong>一条消息只能被一个消费者抢到</strong>。</li>
<li><strong>核心逻辑</strong>：
<ul>
<li><strong>轮询 (Round-robin)</strong>：默认情况下，RabbitMQ
会依次把消息分给每个消费者（你一条，我一条）。</li>
<li><strong>公平分发 (Fair Dispatch)</strong>：通过设置
<code>prefetch=1</code>，让“忙碌”的消费者不接新单，把消息给“空闲”的消费者（即：谁处理得快谁多干活）。</li>
</ul></li>
<li><strong>场景</strong>：<strong>集群削峰</strong>。比如大促期间的订单处理，启动
100 个订单处理服务（Worker）去消费同一个订单队列，加快处理速度。</li>
</ul>
<hr>
<h3 id="第二类高级发布订阅模式-publishsubscribe">第二类：高级发布订阅模式
(Publish/Subscribe)</h3>
<p>这类模式引入了 <strong>Exchange (交换机)</strong>
的概念，实现了“一次发送，多处接收”。区别在于路由规则的不同。</p>
<h4 id="发布订阅模式-publishsubscribe---fanout">3. 发布/订阅模式
(Publish/Subscribe - Fanout)</h4>
<ul>
<li><strong>架构</strong>：<code>P</code> -&gt;
<code>Exchange (Fanout)</code> -&gt; <code>Queue A</code>,
<code>Queue B</code> -&gt; <code>C1</code>, <code>C2</code></li>
<li><strong>机制</strong>：<strong>广播</strong>。生产者把消息发给交换机，交换机把它<strong>复制</strong>给所有绑定到它身上的队列。</li>
<li><strong>特点</strong>：速度最快，因为它完全忽略 Routing
Key，闭着眼转发。</li>
<li><strong>场景</strong>：<strong>数据同步</strong>或<strong>日志广播</strong>。比如“修改密码”事件，既要发给“短信队列”通知用户，又要发给“审计队列”记录日志。</li>
</ul>
<h4 id="路由模式-routing---direct">4. 路由模式 (Routing - Direct)</h4>
<ul>
<li><strong>架构</strong>：<code>P</code> -&gt;
<code>Exchange (Direct)</code> -&gt; <code>Queue A (error)</code>,
<code>Queue B (info)</code></li>
<li><strong>机制</strong>：<strong>精准匹配</strong>。发送消息时携带
<code>Routing Key</code>（比如 “error”），交换机只把消息投递给绑定了
“error” Key 的队列。</li>
<li><strong>场景</strong>：<strong>日志分级存储</strong>。
<ul>
<li>消费者 A 只想接收 <code>error</code> 级别的日志写磁盘（绑定
key=“error”）。</li>
<li>消费者 B 想接收所有级别的日志打印控制台（绑定 key=“info”, “warning”,
“error”）</li>
</ul></li>
</ul>
<figure>
<img src="/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20251217182529481.png" alt="image-20251217182529481">
<figcaption aria-hidden="true">image-20251217182529481</figcaption>
</figure>
<h4 id="主题模式-topics---topic">5. 主题模式 (Topics - Topic)</h4>
<ul>
<li><strong>架构</strong>：<code>P</code> -&gt;
<code>Exchange (Topic)</code> -&gt; <code>Queue</code></li>
<li><strong>机制</strong>：<strong>通配符匹配</strong>。这是最灵活的模式。
<ul>
<li><code>#</code>：匹配 0 个或多个单词。</li>
<li><code>*</code>：匹配 1 个单词。</li>
</ul></li>
<li><strong>例子</strong>：
<ul>
<li>发送 Key：<code>usa.news</code></li>
<li>队列 A 绑定：<code>usa.#</code> (接收美国的所有消息)</li>
<li>队列 B 绑定：<code>#.news</code> (接收全世界的新闻)</li>
</ul></li>
<li><strong>场景</strong>：<strong>复杂业务路由</strong>。比如外卖系统，按区域（北京.海淀）、按品类（食品.奶茶）进行多维度的消息分发。</li>
</ul>
<figure>
<img src="/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20251217182552430.png" alt="image-20251217182552430">
<figcaption aria-hidden="true">image-20251217182552430</figcaption>
</figure>
<h2 id="quorum-队列">Quorum 队列</h2>
<h3 id="为什么要发明-quorum-队列历史背景">1. 为什么要发明 Quorum
队列？(历史背景)</h3>
<p>在 Quorum 队列出现之前，RabbitMQ
想要实现“一台机器挂了数据不丢”，用的是 <strong>镜像队列 (Mirrored
Queues)</strong>。</p>
<p><strong>老镜像队列的致命痛点：</strong></p>
<ol type="1">
<li><strong>同步风暴</strong>：当一个新节点加入集群时，它需要从老节点把所有数据复制过来。这个过程会导致整个集群卡顿（Stop-the-world），甚至导致集群崩溃。</li>
<li><strong>效率低下</strong>：它采用的是“链式复制”或者简单的广播，一条消息要在所有节点间转圈圈，性能随着节点数增加而剧烈下降。</li>
<li><strong>即将被废弃</strong>：RabbitMQ
官方已经宣布，在未来的版本（4.0）中将<strong>彻底删除</strong>镜像队列。</li>
</ol>
<p>所以，Quorum 队列就是为了<strong>“接班”</strong>而来的。</p>
<hr>
<h3 id="quorum-队列的核心原理raft-算法">2. Quorum 队列的核心原理：Raft
算法</h3>
<p>“Quorum”这个词的本意是<strong>“法定人数”</strong>（也就是<strong>多数派</strong>）。</p>
<p>它的核心逻辑不再是“所有人都必须收到消息”，而是<strong>“只要大多数人收到消息，这事儿就成了”</strong>。它基于著名的分布式一致性算法
<strong>Raft</strong>。</p>
<h4 id="工作机制图解">工作机制图解：</h4>
<p>假设你的集群有 3 个节点（Node A, Node B, Node C）。</p>
<ol type="1">
<li><strong>Leader 选举</strong>：三个节点通过投票，选出 Node A 作为
<strong>Leader</strong>，B 和 C 是 <strong>Follower</strong>。</li>
<li><strong>写消息</strong>：
<ul>
<li>生产者把消息发给 Leader (A)。</li>
<li>A 把消息写入自己的日志，并同时发给 B 和 C。</li>
<li><strong>关键点</strong>：只要 B 或者 C <strong>其中有一个</strong>
回复“我收到了”（加上 A 自己，就是 2 票，满足 3 票中的多数派），A
就认为这条消息<strong>写入成功</strong>。</li>
<li>A 返回 ACK 给生产者。</li>
</ul></li>
<li><strong>故障切换</strong>：
<ul>
<li>如果 Leader (A) 挂了。</li>
<li>B 和 C 发现老大不在了，迅速发起新一轮投票。</li>
<li>因为 B 和 C 都是活着的（2 &gt; 3/2），它们能立刻选出新的
Leader，继续工作。</li>
</ul></li>
</ol>
<figure>
<img src="/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20251217190353627.png" alt="image-20251217190353627">
<figcaption aria-hidden="true">image-20251217190353627</figcaption>
</figure>
<h2 id="常见问题">常见问题</h2>
<h3 id="如果重启rabbitmq出现消息丢失问题如何解决">如果重启rabbitmq，出现消息丢失问题如何解决</h3>
<p>核心原因是默认情况下 RabbitMQ
是将数据存储在内存中的。一旦进程关闭或服务器重启，内存数据就会被清空。</p>
<p>要解决这个问题，必须配置 <strong>“持久化”
(Persistence)</strong>。</p>
<p>但这不仅仅是改一个配置那么简单。要保证消息绝对不丢，你需要同时满足
<strong>三个层面的持久化</strong>（缺一不可）：</p>
<h4 id="交换器的持久化-exchange-durability">1. 交换器的持久化 (Exchange
Durability)</h4>
<p>如果你只持久化了队列和消息，但交换器没持久化。重启后，交换器没了，生产者发消息时找不到交换器，消息就会直接报错或丢弃。</p>
<ul>
<li><p><strong>如何设置</strong>：在声明交换器时，将
<code>durable</code> 参数设为 <code>True</code>。</p></li>
<li><p><strong>代码示例 (Python)</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import pika</span><br><span class="line"></span><br><span class="line"># durable=True 是关键</span><br><span class="line">channel.exchange_declare(exchange=&#x27;my_exchange&#x27;, </span><br><span class="line">                         exchange_type=&#x27;direct&#x27;, </span><br><span class="line">                         durable=True)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="队列的持久化-queue-durability">2. 队列的持久化 (Queue
Durability)</h4>
<p>如果队列不持久化，重启后队列元数据会消失，依附于该队列的消息（无论消息本身是否持久化）都会一起消失。</p>
<ul>
<li><p><strong>如何设置</strong>：在声明队列时，将 <code>durable</code>
参数设为 <code>True</code>。</p></li>
<li><p><strong>代码示例 (Python)</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># durable=True 告诉 RabbitMQ 重启后恢复该队列</span><br><span class="line">channel.queue_declare(queue=&#x27;my_queue&#x27;, durable=True)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="消息的持久化-message-persistence">3. 消息的持久化 (Message
Persistence)</h4>
<p>这是最容易被遗忘的一步。即便队列还在，如果消息本身是“瞬态”的，重启后队列是空的。</p>
<ul>
<li><p><strong>如何设置</strong>：在发送消息（Publish）时，设置
<code>delivery_mode = 2</code>（1 是非持久化，2 是持久化）。</p></li>
<li><p><strong>代码示例 (Python)</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">channel.basic_publish(</span><br><span class="line">    exchange=&#x27;my_exchange&#x27;,</span><br><span class="line">    routing_key=&#x27;my_queue&#x27;,</span><br><span class="line">    body=&#x27;Hello World&#x27;,</span><br><span class="line">    properties=pika.BasicProperties(</span><br><span class="line">        delivery_mode=2,  # 关键点：2 代表消息持久化</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="进阶这样就-100-安全了吗">进阶：这样就 100% 安全了吗？</h4>
<p><strong>不是的。</strong>
即便你做到了以上三点，依然存在两个极端情况会导致丢失：</p>
<ul>
<li><strong>漏洞 1：消息刚到内存，还没来得及刷盘</strong> RabbitMQ
为了性能，不会每收到一条消息就立马写硬盘（fsync），而是先存缓存区。如果这时候断电了，缓存区里的几条消息就丢了。
<ul>
<li><strong>解决方案</strong>：<strong>发布确认机制 (Publisher
Confirms)</strong>。 生产者开启 Confirm 模式。只有当 RabbitMQ
明确告诉你“我已经把这条消息存入硬盘了”（Handle
Ack），你才算发送成功。如果超时未收到 Ack，生产者需要重发。</li>
</ul></li>
<li><strong>漏洞 2：磁盘坏了 / 物理机报废</strong>
如果单台机器硬盘物理损坏，持久化也没用。
<ul>
<li><strong>解决方案</strong>：<strong>镜像队列 (Mirrored
Queues)</strong> 或 <strong>仲裁队列 (Quorum Queues)</strong>。
这是集群层面的高可用。将消息复制到 3
台不同的机器上。挂掉一台，另外两台还有数据。</li>
</ul></li>
</ul>
<h3 id="如何解决同一个消息被消费多次的问题">如何解决同一个消息被消费多次的问题</h3>
<p>这是一个非常经典且必须解决的分布式系统问题。在专业术语中，解决这个问题的方法叫做<strong>实现接口的“幂等性”
(Idempotency)</strong>。</p>
<p>简单来说，<strong>幂等性</strong>意味着：<strong>无论我对同一个消息处理多少次，最终的结果都和处理一次是一样的。</strong></p>
<p>在 RabbitMQ（以及大多数 MQ）的设计中，为了保证消息不丢，默认采用的是
<strong>“至少投递一次” (At-Least-Once)</strong> 策略。</p>
<ul>
<li><strong>场景还原</strong>：消费者把钱扣了，正准备告诉 MQ
“我办完了(ACK)”，结果<strong>网线断了</strong>或<strong>进程崩了</strong>。</li>
<li><strong>后果</strong>：MQ 没收到
ACK，以为你没办完，于是把消息重新发给另一个消费者。结果：<strong>扣了两次钱</strong>。</li>
</ul>
<p>要解决这个问题，不能依赖
MQ，必须由<strong>消费者（Consumer）</strong>在业务逻辑层面来保证。以下是三种最主流的工程实现方案：</p>
<h4 id="方案一利用数据库的唯一约束-最强硬方案">方案一：利用数据库的唯一约束
(最强硬方案)</h4>
<p>这是最简单、最可靠的方法，适用于<strong>新增数据</strong>（Insert）的场景。</p>
<ul>
<li><strong>原理</strong>：利用数据库（MySQL/Oracle）的主键（Primary
Key）或唯一索引（Unique Key）约束。</li>
<li><strong>做法</strong>：
<ol type="1">
<li>每条消息必须携带一个<strong>全局唯一的 ID</strong>（比如
<code>message_id</code> 或者业务上的 <code>order_id</code>）。</li>
<li>消费者尝试向数据库插入数据。</li>
<li>如果插入成功 -&gt; 处理结束，发送 ACK。</li>
<li>如果插入失败（报 <code>DuplicateKeyException</code>） -&gt;
说明已经处理过了，<strong>直接忽略，发送 ACK</strong>。</li>
</ol></li>
</ul>
<h4 id="方案二利用-sql-的条件更新-状态机方案">方案二：利用 SQL
的条件更新 (状态机方案)</h4>
<p>适用于<strong>更新数据</strong>（Update）的场景，比如更新订单状态。</p>
<ul>
<li><p><strong>原理</strong>：利用 SQL 的 <code>WHERE</code>
条件作为乐观锁，防止回退。</p></li>
<li><p><strong>错误做法</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UPDATE orders SET status = &#x27;PAID&#x27; WHERE id = 1001;</span><br></pre></td></tr></table></figure>
<p><em>风险：如果你执行两次，它就更新两次，虽然状态看起来一样，但如果有触发器或日志，就会重复。</em></p></li>
<li><p><strong>正确做法 (带前置条件)</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UPDATE orders SET status = &#x27;PAID&#x27; </span><br><span class="line">WHERE id = 1001 AND status = &#x27;UNPAID&#x27;; -- 关键在这里</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>第一次执行</strong>：找到 ID=1001 且状态是 UNPAID
的记录，更新成功，影响行数 = 1。</li>
<li><strong>第二次执行</strong>：虽然 ID=1001 还在，但这时的状态已经是
PAID 了，不满足 <code>status = 'UNPAID'</code>，所以<strong>影响行数 =
0</strong>。业务逻辑判断影响行数为 0，即视为重复消费，直接 ACK。</li>
</ul></li>
</ul>
<h4 id="方案三redis-去重表-最高性能方案">方案三：Redis 去重表
(最高性能方案)</h4>
<p>如果你的业务不涉及数据库，或者并发量极高，可以用 Redis
做“去重记录表”。</p>
<ul>
<li><p><strong>做法</strong>：</p>
<ol type="1">
<li>消息到达，先拿着 <code>message_id</code> 去 Redis
查一下：<code>EXISTS message_id</code>？</li>
<li><strong>如果有</strong>：说明处理过了，直接丢弃，ACK。</li>
<li><strong>如果无</strong>：开始处理业务。</li>
<li>业务处理完，把 <code>message_id</code> 写入
Redis（通常设置一个过期时间，比如 24 小时）。</li>
</ol>
<p><em>注意：这里存在原子性问题（先查后写中间可能并发），通常使用
<code>SETNX</code> (Set if Not Exists) 命令或者 Lua
脚本来保证原子性。</em></p></li>
</ul>
<h3 id="如何处理消息乱序的问题">如何处理消息乱序的问题</h3>
<p>在 RabbitMQ
中，<strong>单个队列由单个消费者消费</strong>时，是严格保证先进先出（FIFO）的。</p>
<p>但是，为了提升性能，我们通常会开启<strong>多个消费者</strong>（Competing
Consumers
Pattern）同时消费同一个队列，或者发生消息重试（Nack/Requeue）。这时候，顺序就乱了。</p>
<blockquote>
<p><strong>场景举例</strong>： 生产者依次发了三条关于“订单
A”的消息：</p>
<ol type="1">
<li><code>INSERT</code> (创建订单)</li>
<li><code>UPDATE</code> (支付订单)</li>
<li><code>DELETE</code> (删除订单)</li>
</ol>
<p>如果有两个消费者 C1 和 C2。 C1 拿到了 <code>INSERT</code>，C2 拿到了
<code>UPDATE</code>。 C2 的网速很快，先处理完
<code>UPDATE</code>。结果数据库报错“找不到订单”，操作失败。然后 C1 才把
<code>INSERT</code> 做完。
<strong>结果</strong>：数据不一致，业务崩盘。</p>
</blockquote>
<p>解决这个问题的核心思路是：<strong>我们不需要“全局有序”，只需要“局部有序”</strong>（即：保证同一个
ID 的消息是有序的即可，不同 ID 之间的顺序无所谓）。</p>
<p>对于 Python
开发者以及大多数分布式系统来说，解决消息乱序最稳健、最通用的方案就是：<strong>拆分
Queue + 一致性 Hash (Queue Sharding)</strong>。</p>
<h4 id="核心方案拆分-queue-一致性-hash">核心方案：拆分 Queue + 一致性
Hash</h4>
<p>这个方案的核心逻辑是：<strong>我们不需要“全局有序”，只需要保证“同一业务
ID 的消息有序”</strong>。</p>
<p>只要保证同一个订单（例如
<code>Order_1001</code>）的所有操作（下单、支付、发货）都严格进入<strong>同一个队列</strong>，并且被<strong>同一个消费者</strong>处理，那么顺序就绝对不会乱。</p>
<h4 id="架构设计图解">1. 架构设计图解</h4>
<p>我们要把原来的“一个大队列”拆分成 N 个“小队列”。</p>
<ul>
<li><strong>原来的模型（会乱序）</strong>： <code>Producer</code> -&gt;
<code>Queue</code> -&gt; <code>Consumer A</code>,
<code>Consumer B</code> (并发抢单，顺序错乱)</li>
<li><strong>现在的模型（保证有序）</strong>： <code>Producer</code>
-&gt; <code>Exchange</code> -&gt; <code>Queue_1</code> -&gt;
<code>Consumer A</code> (只负责 Queue_1) <code>Producer</code> -&gt;
<code>Exchange</code> -&gt; <code>Queue_2</code> -&gt;
<code>Consumer B</code> (只负责 Queue_2) <code>Producer</code> -&gt;
<code>Exchange</code> -&gt; <code>Queue_3</code> -&gt;
<code>Consumer C</code> (只负责 Queue_3)</li>
</ul>
<h4 id="具体实现步骤">2. 具体实现步骤</h4>
<p>这个方案分为三个关键环节：</p>
<p><strong>第一步：生产者负责“路由分发”</strong>
在发送消息时，生产者必须根据业务 ID（如
<code>order_id</code>）决定这条消息发往哪个队列。通常使用 <strong>Hash
取模</strong> 算法。</p>
<ul>
<li><strong>逻辑</strong>：<code>index = hash(order_id) % N</code> (N
是队列的总数量)。</li>
<li><strong>例子</strong>：假设有 3 个队列。
<ul>
<li><code>Order_1001</code> 的 Hash 模 3 结果是 0 -&gt; <strong>发往
Queue_0</strong></li>
<li><code>Order_1002</code> 的 Hash 模 3 结果是 1 -&gt; <strong>发往
Queue_1</strong></li>
<li><code>Order_1001</code> 的<strong>后续状态</strong>（如支付）Hash
结果肯定还是 0 -&gt; <strong>依然发往 Queue_0</strong></li>
</ul></li>
</ul>
<p><strong>第二步：RabbitMQ 队列配置</strong> 你需要创建 N 个队列（如
<code>order_sub_queue_0</code>, <code>order_sub_queue_1</code>…）。</p>
<ul>
<li><em>进阶技巧</em>：RabbitMQ 有一个官方插件叫
<strong><code>rabbitmq_consistent_hash_exchange</code></strong>。你只需要把消息发给这个交换机，带上
routing_key（设为 order_id），交换机会自动帮你根据 Hash
值均匀分发到绑定的队列中，连生产者的代码都不用改太复杂。</li>
</ul>
<p><strong>第三步：消费者“独占”队列 (关键)</strong>
这是最重要的一点：<strong>每个小队列，同一时刻只能有一个消费者在监听。</strong></p>
<ul>
<li><strong>Consumer A</strong> 专门监听 <code>Queue_0</code>。</li>
<li><strong>Consumer B</strong> 专门监听 <code>Queue_1</code>。</li>
</ul>
<p>因为 RabbitMQ 的单个队列是先进先出 (FIFO) 的，而 Consumer A
是单线程顺序处理 Queue_0 的，所以 <code>Order_1001</code>
的“下单”一定比“支付”先被处理。</p>
<h3 id="如何处理消息处理失败的情况">如何处理消息处理失败的情况</h3>
<p>在分布式系统中，<strong>消息处理失败是常态</strong>（比如数据库挂了、网络抖动、代码
bug）。</p>
<p>如果处理失败，绝不能简单地忽略，否则会导致数据丢失；也不能死板地无限重试，否则会死循环拖垮系统。</p>
<p>处理失败通常有<strong>三道防线</strong>，层层递进：</p>
<h4 id="第一步判断异常类型是病还是命">第一步：判断异常类型（是“病”还是“命”？）</h4>
<p>当 <code>try...except</code>
捕获到异常时，不能盲目重试，先看是什么错：</p>
<ol type="1">
<li><strong>致命错误（Fatal Error）</strong>：
<ul>
<li>例如：<code>JsonDecodeError</code>（格式不对）、<code>KeyError</code>（缺字段）、<code>NullPointerException</code>（空指针）。</li>
<li><strong>决策</strong>：这种错误重试一万次也没用。<strong>跳过重试，直接进死信队列</strong>。</li>
</ul></li>
<li><strong>临时错误（Transient Error）</strong>：
<ul>
<li>例如：<code>Timeout</code>（连接超时）、<code>Deadlock</code>（数据库死锁）、<code>503 Service Unavailable</code>。</li>
<li><strong>决策</strong>：这种病能治。<strong>进入重试流程</strong>。</li>
</ul></li>
</ol>
<h4 id="第二步带策略的重试retry-关键缓冲">第二步：带策略的重试（Retry）——
关键缓冲</h4>
<p>既然决定要救，也不能瞎救（比如立即原地无限重试，那是“毒药”）。我们需要<strong>“有节制、有延迟”</strong>的重试。</p>
<ul>
<li><strong>检查重试次数</strong>： 从消息 Header 中读取
<code>retry_count</code>。</li>
<li><strong>逻辑</strong>：
<ul>
<li><strong>如果 count &lt; 3</strong>（假设最大重试3次）：
<ol type="1">
<li><code>count + 1</code>。</li>
<li><strong>等待一会儿</strong>（Backoff）：不要立即重试，而是把消息发到一个
<strong>“延迟队列”</strong>（或者用代码 <code>sleep</code> 一会儿，但
Python 中不建议阻塞主线程，推荐用延迟插件
<code>rabbitmq_delayed_message_exchange</code>）。</li>
<li>重新发布这条消息（Publish）。</li>
<li>对当前失败的这条消息进行
<code>ACK</code>（因为它已经生成了新的替身去排队了）。</li>
</ol></li>
<li><strong>如果 count &gt;= 3</strong>：
<ul>
<li>说明救不活了，放弃治疗。</li>
<li><strong>进入第三步</strong>。</li>
</ul></li>
</ul></li>
</ul>
<h4 id="第三步死信队列dlq-最终兜底">第三步：死信队列（DLQ）——
最终兜底</h4>
<p>这是最后一道防线。当重试次数耗尽，或者遇到致命错误时，才轮到它出场。</p>
<ul>
<li><strong>操作</strong>：调用
<code>basic_nack(delivery_tag, requeue=False)</code>。</li>
<li><strong>结果</strong>：
<ul>
<li>RabbitMQ 会根据配置，自动把这条消息“踢”到死信交换机。</li>
<li>死信交换机把它路由到 <strong>死信队列</strong>。</li>
</ul></li>
<li><strong>后续</strong>：
<ul>
<li>开发/运维人员配置报警脚本，监听死信队列。</li>
<li>一旦有消息进来，<strong>发钉钉/邮件报警</strong>。</li>
<li>人工排查原因（比如发现是数据库挂了），修复后，手动把死信队列里的消息取出来再发回业务队列（或者写脚本批量重发）。</li>
</ul></li>
</ul>
<h2 id="kafka">Kafka</h2>
<p><a href="https://www.bilibili.com/video/BV1TT421y79S/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">消息队列Kafka是什么？架构是怎么样的？5分钟快速入门_哔哩哔哩_bilibili</a></p>
<h3 id="核心思维转变从队列到日志">1. 核心思维转变：从“队列”到“日志”</h3>
<p>这是理解 Kafka 最重要的一步。</p>
<ul>
<li><strong>RabbitMQ
(队列模型)</strong>：就像<strong>“收件箱”</strong>。你把信拿出来，信就没了（Delete）。它的目标是让消息越快被处理完越好，堆积消息是异常状态。</li>
<li><strong>Kafka
(日志模型)</strong>：就像<strong>“船长的航海日志”</strong>。
<ul>
<li>消息是<strong>追加写入 (Append-only)</strong> 的。</li>
<li>消费者读消息，<strong>不会删除消息</strong>，只是在自己的笔记本上记一下：“我读到了第
100 行”。</li>
<li>这意味着：<strong>消息可以被多个不同的消费者重复读取，甚至可以“倒带”回去重读历史数据。</strong></li>
</ul></li>
</ul>
<hr>
<h3 id="为什么-kafka-快得离谱架构设计">2. 为什么 Kafka
快得离谱？(架构设计)</h3>
<p>Kafka 单机可以轻松抗住 <strong>每秒几十万甚至上百万</strong>
的写入，它是怎么做到的？</p>
<h4 id="a.-顺序写磁盘-sequential-write">A. 顺序写磁盘 (Sequential
Write)</h4>
<p>RabbitMQ 尽量用内存，而 Kafka <strong>直接写磁盘</strong>。
你可能会问：“写磁盘不是慢吗？”
<strong>随机写</strong>确实慢，但<strong>顺序写</strong>极快。Kafka
强制所有数据只能追加到文件末尾。在现代操作系统中，顺序写磁盘的速度（600MB/s+）甚至可以超过随机写内存的速度。</p>
<h4 id="b.-零拷贝-zero-copy">B. 零拷贝 (Zero-Copy)</h4>
<p>还记得你之前感兴趣的底层原理吗？Kafka 是利用 OS <code>sendfile</code>
系统调用的教科书级案例。</p>
<ul>
<li><strong>传统方式</strong>：磁盘 -&gt; 内核 Buffer -&gt; 用户态
Buffer (Application) -&gt; 内核 Socket Buffer -&gt; 网卡。</li>
<li><strong>Kafka 方式</strong>：磁盘 -&gt; 内核 Buffer -&gt;
<strong>直接传给网卡</strong>。
<ul>
<li>数据完全不经过应用程序（Kafka JVM），CPU 也就不用瞎忙活。</li>
</ul></li>
</ul>
<h4 id="c.-分区-partitioning-扩展性的核心">C. 分区 (Partitioning) ——
扩展性的核心</h4>
<p>Kafka 将一个 <strong>Topic (主题)</strong> 拆分成了多个
<strong>Partition (分区)</strong>。</p>
<ul>
<li>每个 Partition 是一个独立的物理日志文件。</li>
<li>不同的 Partition 可以分布在不同的服务器上。</li>
<li><strong>结果</strong>：并发读写能力随着机器数量线性扩展。</li>
</ul>
<hr>
<h3 id="kafka-的核心组件">3. Kafka 的核心组件</h3>
<h4 id="broker">1. Broker</h4>
<p>Kafka 的服务器节点。</p>
<h4 id="topic-partition">2. Topic &amp; Partition</h4>
<ul>
<li>Topic 是逻辑分类（比如 <code>logs</code>）。</li>
<li>Partition 是物理存储。Topic A 可以分为 Partition 0, 1, 2。</li>
<li><strong>注意</strong>：Kafka <strong>只保证 Partition
内部的消息有序</strong>，不保证整个 Topic 全局有序。</li>
</ul>
<h4 id="producer-生产者">3. Producer (生产者)</h4>
<p>生产者决定把消息发给哪个 Partition（通常轮询或 Hash）。</p>
<h4 id="consumer-group-消费者组-kafka-的神来之笔">4. Consumer Group
(消费者组) —— Kafka 的神来之笔</h4>
<p>这是 Kafka 区别于 RabbitMQ 的最大特色。</p>
<ul>
<li><strong>机制</strong>：一个 Topic 可以被多个 Group 消费。</li>
<li><strong>组内 (Queue 模式)</strong>：同一个 Group
里的消费者，互相竞争。Partition 0 给消费者 A，Partition 1 给消费者
B。<strong>一个 Partition
只能被组内的一个消费者消费</strong>（防止乱序）。</li>
<li><strong>组间 (Pub/Sub 模式)</strong>：Group A 消费了一遍数据，Group
B 可以再消费一遍同样的数据，互不干扰。</li>
</ul>
<h4 id="offset-偏移量">5. Offset (偏移量)</h4>
<p>消费者读到哪了？RabbitMQ 是 Server 记，Kafka 是
<strong>消费者自己记</strong>（或者提交给 Kafka 的内部 Topic
<code>__consumer_offsets</code>）。</p>
<ul>
<li>你可以随时修改 Offset，让消费者从昨天的数据开始重新跑一遍（用于修复
Bug 后重算数据）。</li>
</ul>
<figure>
<img src="/2025/12/17/%E5%AD%A6%E4%B9%A0/%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20251217193104605.png" alt="image-20251217193104605">
<figcaption aria-hidden="true">image-20251217193104605</figcaption>
</figure>
<h2 id="rocketmq">RocketMQ</h2>
<p><a href="https://www.bilibili.com/video/BV1m7421Z7fN/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">消息队列RocketMQ是什么？和Kafka有什么区别？架构是怎么样的？7分钟快速入门_哔哩哔哩_bilibili</a></p>
<h2 id="参考资料">参考资料</h2>
<p><a href="https://www.bilibili.com/video/BV12qmyBQEwL?buvid=XX7932A7E9DD8A1DA92D4974AB535749A9B44&amp;from_spmid=tm.recommend.0.0&amp;is_story_h5=false&amp;mid=25yhOI1fPeVYa5V16BFcAw%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=32fc9f4a-5eb3-4380-b6c8-f84d3b23dfe8&amp;share_source=QQ&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1765803150&amp;unique_k=uPhnhXg&amp;up_id=12890453&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">什么是消息队列？不就是排个队么？_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1oCwEeVEe4/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">RabbitMQ是什么？架构是怎么样的？_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>后端相关</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型开发学习之路——动手学大模型应用开发</title>
    <url>/2025/04/19/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/%E5%8A%A8%E6%89%8B%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<h3 id="笔记">笔记</h3>
<p>技术栈：streamlit，fastapi，Gradio，langchain，dify，coze</p>
<h4 id="conda常用指令">conda常用指令</h4>
<p><strong>列出所有环境</strong>conda env list</p>
<p><strong>删除指定环境</strong>conda env remove –name 环境名称</p>
<p>创建 Conda 环境conda create -n llm-universe python==3.9.0</p>
<p>激活 Conda 环境conda activate llm-universe</p>
<p>安装依赖项pip install -r requirements.txt</p>
<h3 id="参考文献">参考文献</h3>
<p><a href="https://www.datawhale.cn/learn/content/19/445">动手学大模型应用开发-课程详情
| Datawhale</a></p>
<p><a href="https://datawhalechina.github.io/llm-universe/#/">动手学大模型应用开发</a></p>
<p><a href="https://www.bilibili.com/video/BV1QuZAY2EW1?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">10
分钟！零基础彻底学会 Cursor AI 编程 | Cursor AI 编程｜Cursor 进阶技巧 |
Cursor 开发小程序 | 小白 AI 编程_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV12TLAzuEni?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=12">【Langchain进阶篇】12.Prompt
templates Few shot. Example
selector(提示模板：少镜头。示例选择器)_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.langchain.com.cn/docs/concepts/">概念指南 |
LangChain中文网</a></p>
]]></content>
      <categories>
        <category>大模型开发学习之路</category>
        <category>动手学大模型应用开发</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>开发</tag>
      </tags>
  </entry>
  <entry>
    <title>模型微调——LoRA</title>
    <url>/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/</url>
    <content><![CDATA[<h3 id="为什么要微调">为什么要微调</h3>
<p>预训练大模型在海量通用语料上学到的知识，在垂直场景（医疗、法律、零售客服等）里往往“泛而浅”。</p>
<p>从零训练一个同等规模的大模型成本极高（千卡周级别），而微调只需在已有权重上做小步调整，算力/数据量都指数级下降。</p>
<h3 id="什么是全量微调">什么是全量微调</h3>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811104846104.png" alt="image-20250811104846104">
<figcaption aria-hidden="true">image-20250811104846104</figcaption>
</figure>
<p>全量微调（full
fine-tuning）通俗来说，对于参数的每一个权重，都要学习一个新的值（或者偏移量），更新所有
Transformer 层里的权重矩阵（包括
embedding、attention、FFN），这样的开销是很大的。</p>
<h3 id="什么是lora">什么是LoRA</h3>
<p>LoRA（Low-Rank
Adaptation，低秩适配）是一种<strong>参数高效微调（PEFT）</strong>技术，核心目的：
<strong>“冻结大模型 99 %
以上原始权重，只额外训练极少量低秩矩阵，就能让模型在下游任务上达到近似全量微调的效果。”</strong></p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811105145633.png" alt="image-20250811105145633">
<figcaption aria-hidden="true">image-20250811105145633</figcaption>
</figure>
<p>通俗来说，通过学习两个低秩的矩阵，来近似于完整的矩阵，如图，W=A*B，矩阵相乘</p>
<p>在实际应用中，<strong>LoRA可以直接和transformer的FFN层（线性层）对齐</strong></p>
<p>Transformer 模型的核心是注意力机制，其中涉及到 Query, Key, Value
的计算，这些都是线性变换。</p>
<p>在标准的注意力机制中，计算公式为：</p>
<p><span class="math display">$$
\text{Attention}(Q, K, V) =
\text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$</span></p>
<p>其中 <span class="math inline"><em>Q</em></span>, <span class="math inline"><em>K</em></span>, <span class="math inline"><em>V</em></span> 的计算为：</p>
<p><span class="math display"><em>Q</em> = <em>X</em><sub><em>Q</em></sub><em>W</em><sub><em>Q</em></sub>,  <em>K</em> = <em>X</em><sub><em>K</em></sub><em>W</em><sub><em>K</em></sub>,  <em>V</em> = <em>X</em><sub><em>V</em></sub><em>W</em><sub><em>V</em></sub></span></p>
<p><span class="math inline"><em>X</em><sub><em>Q</em></sub></span>,
<span class="math inline"><em>X</em><sub><em>K</em></sub></span>, <span class="math inline"><em>X</em><sub><em>V</em></sub></span>
的输入可以相同，也可以不同。例如，在 Cross-Attention
中，解码器的隐藏状态作为 <span class="math inline"><em>X</em><sub><em>Q</em></sub></span>，编码器的输出作为
<span class="math inline"><em>X</em><sub><em>K</em></sub></span> 和
<span class="math inline"><em>X</em><sub><em>V</em></sub></span>。</p>
<p><strong>LoRA 可以应用到 <span class="math inline"><em>W</em><sub><em>Q</em></sub></span>, <span class="math inline"><em>W</em><sub><em>K</em></sub></span>, <span class="math inline"><em>W</em><sub><em>V</em></sub></span>
上，采用与线性层类似的方式</strong>。</p>
<h3 id="为什么要用lora">为什么要用lora</h3>
<p>首先要理解低秩：秩可以理解成一个矩阵所代表的信息，低秩矩阵，便是带有少量信息的矩阵，当然这样的矩阵计算效率是更高的，</p>
<p>在全量微调中，由于训练一个完整的矩阵开销是非常大的；在lora中就通过训练低秩矩阵，来近似<strong>模型权重更新</strong>的效果</p>
<blockquote>
<p>若模型参数比较小，使用冻结部分参数或全量微调的方式，往往更好</p>
</blockquote>
<p>初学者不禁会思考，这样难道不会损失信息导致大模型的性能变差吗？但是，实验下来效果还是不错的，通过牺牲一点性能，来换取开销的大幅度减少</p>
<blockquote>
<p>LoRA 原文实验 在 GPT-3 175 B 上，仅用 rank 4 的 LoRA 就能在全量微调
99 % 参数量的情况下，保持 97 % 的下游指标。</p>
</blockquote>
<h3 id="什么是qlora">什么是QLoRA</h3>
<p>QLoRA（Quantized Low-Rank Adaptation，量化低秩适应）是 <strong>LoRA
的“极致省内存”版本</strong>。它把 LoRA
的“低秩增量”思路再往前推一步：<strong>先把整个底座模型权重压到
4-bit，再在上面做 LoRA 微调</strong>。</p>
<p>QLoRA 是另一个热门术语，它与 LoRA
之间的唯一区别在于首字母“Q”，代表“量化（quantized）”。“量化”一词指的是用来减少存储神经元权重的比特数。</p>
<p>例如，神经网络的权重通常以浮点数表示，每个权重需要 32
位。量化的思想是将神经网络的权重压缩为更低的精度，而不会显著损失模型性能或产生重大影响。因此，不再使用
32 位，而是可以舍弃部分比特，例如只用 16 位。</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811142432782.png" alt="image-20250811142432782">
<figcaption aria-hidden="true">image-20250811142432782</figcaption>
</figure>
<h3 id="微调工具的介绍">微调工具的介绍</h3>
<h4 id="unsloth">unsloth</h4>
<p><a href="https://github.com/unslothai/unsloth?tab=readme-ov-file">unslothai/unsloth:
Fine-tuning &amp; Reinforcement Learning for LLMs. 🦥 Train OpenAI
gpt-oss, Qwen3, Llama 4, DeepSeek-R1, Gemma 3, TTS 2x faster with 70%
less VRAM.</a></p>
<p>unsloth是一个专为大型语言模型（LLM）设计的动态量化与微调框架，旨在提高微调效率并减少显存占用，因此主要用于单机单卡的模型微调。</p>
<p>值得一提的是，Unsloth动态量化模型：https://unsloth.ai/blog/dynamic-v2</p>
<p>Unsloth的动态量化方法，特别是其最新的Dynamic
2.0版本，旨在在尽量减少性能损失的同时显著压缩大型语言模型（LLMs）的体积。对于Qwen3模型，尤其是4-bit动态量化版本，现有的评测显示其性能下降非常有限，甚至在某些任务上与原始模型相当。</p>
<blockquote>
<p>Unsloth 的「动态量化」可以一句话概括为：
<strong>“按层、按敏感度自动决定每块权重到底用 2.5 / 3.5 / 4 / 6 / 8 / 32
bit 的精细化量化策略，而不是一股脑全量化到 4 bit。”</strong></p>
</blockquote>
<p>这也使得Unsloth的动态量化模型成为<strong>个人配置</strong>下的最佳微调工具。</p>
<p>不过需要注意的是，动态量化由利也有弊，其<strong>好处在于可以极大程度压缩模型运行所需占用的显存大小，同时几乎不损失性能</strong>，但问题在于动态量化的模型，无论是推理还是微调，<strong>只能单卡运行</strong>，这就使得其吞吐量有限，无法在一台物理机上实现多GPU并行从而扩大吞吐量。</p>
<h4 id="llama-factory"><strong>LLaMA Factory</strong></h4>
<p><a href="https://github.com/hiyouga/LLaMA-Factory/tree/main">hiyouga/LLaMA-Factory:
Unified Efficient Fine-Tuning of 100+ LLMs &amp; VLMs (ACL 2024)</a></p>
<p>LLaMA Factory
是一个简单易用且高效的大型语言模型训练与微调平台。通过它，用户可以在无需编写任何代码的前提下，在本地完成上百种预训练模型的微调。</p>
<p>LLaMA Factory 提供了API Server 和一站式 WebUI
Board，方便企业进行模型的管理和部署。适合不会写代码或代码基础比较弱的同学快速上手进行微调。</p>
<h4 id="其他">其他</h4>
<p>ms-SWIFT GitHub项目主页：https://github.com/modelscope/swift</p>
<p>ColossalAI
GitHub项目主页：https://github.com/hpcaitech/ColossalAI</p>
<p>除此之外，也可以借助更加底层的库，如peft、LoRA、transformer等实现高效微调。</p>
<h3 id="模型性能评估框架">模型性能评估框架</h3>
<h4 id="evalscope">EvalScope</h4>
<p>项目地址： https://github.com/modelscope/evalscope</p>
<p>EvalScope
是由阿里巴巴魔搭社区（ModelScope）推出的一款开源模型评估框架，旨在为大语言
模型（LLM）和多模态模型提供统一、系统化的性能评估方案。该框架具备高度的自动化和可扩展性，
适用于研究机构、工业界以及模型开发者在模型验证与性能对比场景中的广泛需求。</p>
<h3 id="可视化框架">可视化框架</h3>
<h4 id="wandb">wandb</h4>
<p><strong>Weights &amp; Biases（简称 wandb）</strong>
是一个专为机器学习 / 深度学习设计的
<strong>云端实验管理、可视化与协作平台</strong>。它帮你把“训练过程中发生了什么”全部自动化地记录下来，并以网页仪表盘的形式实时展示，省去你手动保存日志、画图、整理表格的麻烦。</p>
<p>wandb官网： https://wandb.ai/site</p>
<h4 id="swanlab">swanlab</h4>
<p>SwanLab 是一款<strong>开源、轻量</strong>的 AI
模型训练跟踪与可视化工具，提供了一个<strong>跟踪、记录、比较、和协作实验</strong>的平台。</p>
<p>SwanLab 面向人工智能研究者，设计了友好的Python API
和漂亮的UI界面，并提供<strong>训练可视化、自动日志记录、超参数记录、实验对比、多人协同等功能</strong>。在SwanLab上，研究者能基于直观的可视化图表发现训练问题，对比多个实验找到研究灵感，并通过<strong>在线网页</strong>的分享与基于组织的<strong>多人协同训练</strong>，打破团队沟通的壁垒，提高组织训练效率。</p>
<p><a href="https://docs.swanlab.cn/">SwanLab官方文档 |
先进的AI团队协作与模型创新引擎</a></p>
<h3 id="构造微调数据集">构造微调数据集</h3>
<h4 id="为什么要构造微调数据集">为什么要构造微调数据集</h4>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811162229104.png" alt="image-20250811162229104">
<figcaption aria-hidden="true">image-20250811162229104</figcaption>
</figure>
<p>其中 &lt;∣im_start∣&gt;
代表文本开始,而user则代表消息身份,用于构建多轮对话,而<lim_end>则代表文本结束,即用户输入结束,而<lim_start>代表新一段文本开始,assistant代表接下来由模型创建消息,而<lim_end>同样代表模型创建消息的结束。</lim_end></lim_start></lim_end></p>
<p>而模型其实是通过这样一组<strong>特殊字符标记</strong>来规范自己的行为,<strong>判断当前消息类型,以及通过输出特殊标记来确定停止时间</strong>。对于绝大多数模型,我们可以在模型的<strong>tokenizer_config.json中看到完整的特殊标记符</strong>(以及系统提示词模板):</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811163120092.png" alt="image-20250811163120092">
<figcaption aria-hidden="true">image-20250811163120092</figcaption>
</figure>
<p>而在实际微调过程中,我们都知道需要<strong>有监督的数据集</strong>、也就是需要输入QA对来进行微调。以著名的<strong>alpaca_zh中文微调数据集</strong>来说,其基本格式如下:</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811163232521.png" alt="image-20250811163232521">
<figcaption aria-hidden="true">image-20250811163232521</figcaption>
</figure>
<p>就可以表示为下列json格式数据集:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">json&#123;  &quot;instruction&quot;: &quot;&quot;,  &quot;input&quot;: &quot;输入:你好。&quot;,  &quot;output&quot;: &quot;输出:你好,有什么可以帮到你的?&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>而在真实的微调过程中,如果是针对Qwen3进行微调,微调脚本会将这条数据集(无论什么格式)转化为如下格式:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xml&lt;im_start|&gt;user\n你好&lt;im_end|&gt;\n&lt;im_start|&gt;assistant\n你好,有什么可以帮到你的?&lt;im_end|&gt;</span><br></pre></td></tr></table></figure>
<p>而在实际训练过程中,模型就会根据assistant前的内容,学习assistant后面的输出内容。</p>
<p><strong>因此我们要在下载数据集后，进行微调前，对数据集进行预处理</strong>，接下来引出构造数据集的几种场景</p>
<h4 id="带有系统提示微调数据集格式">带有系统提示微调数据集格式</h4>
<p>在很多场景下,我们还会发现一些<strong>带有instruction字段的微调数据集</strong>,那instruction字段是如何带入到微调过程中的呢?</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811163232521.png" alt="image-20250811163232521">
<figcaption aria-hidden="true">image-20250811163232521</figcaption>
</figure>
<p>答案非常简单,还是依靠特殊字符。例如有一个对话内容如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- 系统提示词(instruction):你是一名助人为乐的助手。</span><br><span class="line">- 用户输入(input):你好,好久不见。</span><br><span class="line">- 助手回复(output):是的呀,好久不见,最近有什么有趣的事情要和我分享么?</span><br></pre></td></tr></table></figure>
<p>此时模型的输入和输出如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;lim_start|&gt;system你是一名助人为乐的助手。&lt;/im_end&gt;</span><br><span class="line">&lt;lim_start|&gt;user 你好,好久不见。&lt;/lim_end&gt;</span><br><span class="line">&lt;lim_start|&gt;assistant 是的呀,好久不见,最近有什么有趣的事情要和我分享么?&lt;/lim_end&gt;</span><br></pre></td></tr></table></figure>
<p>即会通过&lt;lim_start|&gt;system…&lt;lim_end|&gt;来标记系统提示词。实际进行微调时,模型会根据assistant为界,学习assistant之前的文本输入情况下应该如何输出。</p>
<h4 id="带function-calling微调数据集格式">带Function
calling微调数据集格式</h4>
<p>更进一步的,如果对话过程中带入了<strong>Function
calling</strong>,此时首先模型会读取提前准备好的tool
schema(也可能是自动生成的,例如MCP即可自动创建tool schema):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;tool_schema&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;get_weather&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;查询指定城市的天气信息&quot;,</span><br><span class="line">      &quot;parameters&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;object&quot;,</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">          &quot;location&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">            &quot;description&quot;: &quot;要查询天气的城市名称&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;required&quot;: [&quot;location&quot;]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而假设我们的对话内容如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- 系统提示词(instruction):你是一名助人为乐的助手。当用户查询天气的时候,请调用get_weather函数进行天气信息查询。</span><br><span class="line">- 用户输入(input):你好,请帮我查询下北京天气。</span><br><span class="line">- 助手回复(output):&#123;&quot;name&quot;: &quot;get_weather&quot;, &quot;arguments&quot;: &#123;&quot;location&quot;: &quot;北京&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>此时回复内容就是一条Function call message</p>
</blockquote>
<p>而此时模型真实的输入和输出内容如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;|im_start|&gt;system</span><br><span class="line">你是天气助手，当用户查询天气时请调用 get_weather 函数。</span><br><span class="line"># Tools</span><br><span class="line">You may call one or more functions to assist with the user query.</span><br><span class="line">You are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:</span><br><span class="line">&lt;tools&gt;</span><br><span class="line">[&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;description&quot;:&quot;查询指定城市的天气信息&quot;,&quot;parameters&quot;:&#123;&quot;type&quot;:&quot;object&quot;,&quot;properties&quot;:&#123;&quot;location&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;description&quot;:&quot;要查询天气的城市名称&quot;&#125;&#125;,&quot;required&quot;:[&quot;location&quot;]&#125;&#125;]</span><br><span class="line">&lt;/tools&gt;</span><br><span class="line">&lt;tool_call&gt;</span><br><span class="line"> &#123;&quot;name&quot;: &lt;function-name&gt;, &quot;arguments&quot;: &lt;args-json-object&gt;&#125;</span><br><span class="line">&lt;/tool_call&gt;.</span><br><span class="line">&lt;|im_end|&gt;</span><br><span class="line">&lt;|im_start|&gt;user</span><br><span class="line">北京天气如何？</span><br><span class="line">&lt;|im_end|&gt;</span><br><span class="line">&lt;|im_start|&gt;assistant</span><br><span class="line">&lt;tool_call&gt;&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;arguments&quot;:&#123;&quot;location&quot;:&quot;北京&quot;&#125;&#125;&lt;/tool_call&gt;</span><br><span class="line">&lt;|im_end|&gt;</span><br></pre></td></tr></table></figure>
<p>接下来在进行训练时,模型同样根据assistant前的内容,学习assistant后面的输出内容。不过需要注意的是,由于高效微调调整的参数量较少,因此只能优化模型的Function
calling能力,并不能从无到有让模型学会Function calling。</p>
<h4 id="带有思考过程的微调数据集结构">带有思考过程的微调数据集结构</h4>
<p>而如果是带有思考链,则一个简单的问答数据如下:</p>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811165802090.png" alt="image-20250811165802090">
<figcaption aria-hidden="true">image-20250811165802090</figcaption>
</figure>
<ul>
<li>系统提示词(instruction):你是一名助人为乐的助手。</li>
<li>用户输入(input):你好,好久不见。</li>
<li>助手回复(output):好的,用户发来“你好,好久不见!”,我需要回应。首先,用户可能希望得到亲切的回应,所以应该用友好的语气。/n是的呀,好久不见,最近有什么有趣的事情要和我分享么?</li>
</ul>
<p>此时模型真实的内部输入和输出结果如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;lim_start|&gt;system</span><br><span class="line">你是一名助人为乐的助手。&lt;lim_end|&gt;</span><br><span class="line">&lt;lim_start|&gt;user</span><br><span class="line">你好,好久不见。&lt;lim_end|&gt;</span><br><span class="line">&lt;lim_start|&gt;assistant</span><br><span class="line"></span><br><span class="line">&lt;think&gt;  好的,用户发来“你好,好久不见!”,我需要回应。首先,用户可能希望得到亲切的回应,所以应该用友好的语气。&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">是的呀,好久不见,最近有什么有趣的事情要和我分享么?&lt;/lim_end|&gt;</span><br></pre></td></tr></table></figure>
<p>模型同样根据assistant前的内容,学习assistant后面的输出内容。也就是说,所谓的思考过程,本质上其实是一种文本响应格式,通过模型训练而来。</p>
<h4 id="混合推理模型构造微调数据集基本方法">混合推理模型构造微调数据集基本方法</h4>
<p>在了解了微调数据集结构背后的基本原理后,接下来的问题是应该如何构造微调数据集呢?</p>
<p>一般来说我们可以在huggingface、ModelScope或llama-
factory中挑选合适的数据集,并根据实际情况进行组装。</p>
<p>例如围绕Qwen3模型的高效微调,为了确保其仍然<strong>保留混合推理能力,</strong>我们可以考虑在微调数据集中加入如普<strong>通对话数据集</strong><a href="https://huggingface.co/datasets/mlabonne/FineTome-100k">FineTome</a>,以及<strong>带有推理字段的数学类数据集</strong><a href="https://huggingface.co/datasets/nvidia/OpenMathReasoning">OpenMathReasoning</a>,<strong>并围绕这两个数据集进行拼接</strong>,从而在确保能提升模型的数学能力的同时,保留非推理的功能。</p>
<p>同时还需要在持续微调训练过程中<strong>不断调整COT数学数据集和普通文本问答数据集之间的配比</strong>,以确保模型能够在提升数学能力的同时,保留混合推理的性能。</p>
<blockquote>
<p>Qwen3 的「混合推理能力」=
<strong>在同一个模型里内置两套“大脑”</strong>： •
<strong>快思考（非思考模式）</strong>：轻量算力、秒级响应，适合简单问答；
•
<strong>慢思考（思考模式）</strong>：多步链式推理、深度推敲，适合复杂逻辑、数学、代码。
系统会自动或按用户指令在两种模式之间 <strong>动态切换</strong>，从而
<strong>既省算力又保证难题精度</strong>。</p>
</blockquote>
<h3 id="微调的基本流程">微调的基本流程</h3>
<figure>
<img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250812105535330.png" alt="image-20250812105535330">
<figcaption aria-hidden="true">image-20250812105535330</figcaption>
</figure>
<h3 id="环境配置">环境配置</h3>
<p><strong>安装Unsloth</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo</span><br></pre></td></tr></table></figure>
<p><strong>安装Qwen3-8B-unsloth-bnb-4bit</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">modelscope download --model unsloth/Qwen3-8B-unsloth-bnb-4bit --local_dir /workspace/qwen3-8b</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#模型下载</span><br><span class="line">from modelscope import snapshot_download</span><br><span class="line">model_dir = snapshot_download(&#x27;unsloth/Qwen3-8B-unsloth-bnb-4bit&#x27;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>unsloth/Qwen3-8B-unsloth-bnb-4bit</strong> 这个模型它是
<strong>专门为Unsloth微调框架优化过的4bit量化版本</strong></p>
<p>原始 Qwen3-8B（FP16）需要约 <strong>22GB 显存</strong>，而 4bit
量化后仅需 <strong>6GB 左右</strong></p>
<p><strong>只要显存允许，原始 FP16/BF16 模型也可以用 Unsloth 做 4-bit
LoRA（即 QLoRA）微调；官方预量化 4-bit
模型只是帮你把“量化”这一步提前做完了，二者本质相同。</strong></p>
<p><strong>Unsloth 的两种用法示例</strong></p>
<table>
<colgroup>
<col style="width: 30%">
<col style="width: 42%">
<col style="width: 27%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">场景</th>
<th style="text-align: left;">代码片段</th>
<th style="text-align: left;">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">A. 用官方已量化好的 4-bit 权重</td>
<td style="text-align: left;"><code>model_name="unsloth/Qwen3-8B-bnb-4bit"</code></td>
<td style="text-align: left;">显卡 6 GB 就能跑，省去自己量化</td>
</tr>
<tr>
<td style="text-align: left;">B. 用原始 FP16 权重并现场 4-bit 量化</td>
<td style="text-align: left;"><code>model_name="Qwen/Qwen3-8B"</code> +
<code>load_in_4bit=True</code></td>
<td style="text-align: left;">显卡仍需 6 GB，显存占用与 A 相同</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两种写法效果等价</span></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name=<span class="string">&quot;Qwen/Qwen3-8B&quot;</span>,   <span class="comment"># 原始权重</span></span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,            <span class="comment"># 现场量化到 4-bit</span></span><br><span class="line">    max_seq_length=<span class="number">2048</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>安装EvalScope</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install evalscope                </span><br><span class="line"># 安装 Native backend (默认)</span><br><span class="line"> # 额外选项</span><br><span class="line">pip install &#x27;evalscope[opencompass]&#x27;   # 安装 OpenCompass backend</span><br><span class="line"> pip install &#x27;evalscope[vlmeval]&#x27;       </span><br><span class="line"># 安装 VLMEvalKit backend</span><br><span class="line"> pip install &#x27;evalscope[rag]&#x27;           </span><br><span class="line">pip install &#x27;evalscope[perf]&#x27;          </span><br><span class="line">pip install &#x27;evalscope[app]&#x27;           </span><br><span class="line"># 或可以直接输入all，安装全部模块</span><br><span class="line"># pip install &#x27;evalscope[all]&#x27;           </span><br><span class="line"># 安装 RAGEval backend</span><br><span class="line"> # 安装 模型压测模块 依赖</span><br><span class="line"># 安装 可视化 相关依赖</span><br><span class="line"># 安装所有 backends (Native, OpenCompass, </span><br><span class="line">VLMEvalKit, RAGEval)</span><br></pre></td></tr></table></figure>
<p><strong>安装wandb</strong></p>
<p>wandb官网： https://wandb.ai/site</p>
<p>安装wandb：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install wandb</span><br></pre></td></tr></table></figure>
<blockquote>
<p><a href="https://github.com/SwanHubX/SwanLab?tab=readme-ov-file#-快速开始">SwanHubX/SwanLab:
⚡️SwanLab - an open-source, modern-design AI training tracking and
visualization tool. Supports Cloud / Self-hosted use. Integrated with
PyTorch / Transformers / LLaMA Factory / veRL/ Swift / Ultralytics /
MMEngine / Keras etc.</a></p>
<p>与其类似，一个开源、现代化设计的深度学习训练跟踪与可视化工具</p>
</blockquote>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV13BKozLEXE/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">DIY你的AI梦中情人？Qwen3微调手把手教你！_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1tthPeFEWb/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">通俗易懂理解全量微调和LoRA微调_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1DT421r7Et?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">通俗易懂理解大模型预训练和微调_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1YLE1zyEvX?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=3">3.四大微调框架及微调硬件环境介绍_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1s2AUe2EBq/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">如何把你的
DeePseek-R1 微调为某个领域的专家？（实战篇）_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/javatiange/article/details/149964743?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=149964743&amp;sharerefer=PC&amp;sharesource=2501_91530961&amp;sharefrom=from_link">一文详解：8种常见的大模型微调方法，看这篇就够了！-CSDN博客</a></p>
]]></content>
      <categories>
        <category>模型</category>
        <category>微调</category>
      </categories>
      <tags>
        <tag>模型微调</tag>
        <tag>LoRA</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——初读论文与初步学习</title>
    <url>/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/</url>
    <content><![CDATA[<h1 id="视频异常检测初步了解">视频异常检测初步了解</h1>
<h2 id="传统方法检测异常样本">传统方法检测异常样本：</h2>
<ul>
<li>高斯分布 Gaussian Distribute</li>
<li>高斯混合模型 Gaussian Mixture Model</li>
</ul>
<h2 id="深度学习方法下的异常检测">深度学习方法下的异常检测：</h2>
<ul>
<li>两种主流的异常检测任务：
<ul>
<li>重构任务
Reconstruction：图像通过深度神经网络DNN输出一张重构图像，通过损失函数，先训练调整DNN，测试结果由AUC评判（AUC（Area
Under the Curve）是用于评估分类模型性能的一个重要指标）</li>
<li>预测任务
Prediction：连续输入图像，预测新图像，用预测与非预测比较</li>
</ul></li>
<li>自动编码器 Auto-Encoder：U-Net
是一种用于图像分割的深度学习模型，主要特点是采用了编码器-解码器结构（也叫对称结构），并在编码器和解码器之间引入了跳跃连接（skip
connections）</li>
</ul>
<blockquote>
<p><strong>编码器（Contracting
Path）</strong>：这一部分类似于卷积神经网络（CNN），用于提取输入图像的特征。</p>
<p><strong>瓶颈层（Bottleneck）</strong>：编码器和解码器之间的连接层，负责处理最深层次的特征。</p>
<p><strong>解码器（Expansive
Path）</strong>：这一部分用于将编码器提取的特征还原回原始图像的大小。</p>
<p><strong>跳跃连接（Skip
Connections）</strong>：解码器部分会与编码器的对应层进行直接连接，从而帮助模型在恢复空间分辨率的过程中更好地保留细节信息。</p>
<figure>
<img src="./../../images/大创/v2-39073bacc426f0e464b53336c83e19da_1440w.jpg" alt="v2-39073bacc426f0e464b53336c83e19da_1440w">
<figcaption aria-hidden="true">v2-39073bacc426f0e464b53336c83e19da_1440w</figcaption>
</figure>
</blockquote>
<h2 id="根据学习方法分类">根据学习方法分类：</h2>
<ul>
<li>无监督学习 unsupervised learning 只有正常样本训练</li>
<li>半监督学习 weakly spervised learning 以不平衡的样本比例训练</li>
<li>监督学习 spervised learning 都训练</li>
</ul>
<h2 id="视频异常检测领域未来挑战">视频异常检测领域未来挑战：</h2>
<ul>
<li>异常检测视频大部分采用mini-batch训练方法，非常消耗时间和资源，无法实时进行视频检测</li>
<li>现实的数据集，模型难以训练</li>
<li>异常的情况定义模糊</li>
<li>模型的迁移性差，shanghaiTech的数据集是多摄像头融合的数据集，大部分数据集表现一般</li>
</ul>
<h2 id="了解yolo">了解yolo</h2>
<p>YOLO（You Only Look Once）系列算法是计算机视觉领域中重要的<a href="https://so.csdn.net/so/search?q=目标检测技术&amp;spm=1001.2101.3001.7020">目标检测技术</a>。凭借其高效的实时处理能力，YOLO被广泛应用于视频监控、自动驾驶等多个领域。</p>
<h1 id="论文一human-action-recognition-from-various-data-modalities-a-review">论文一：Human
Action Recognition from Various Data Modalities: A Review</h1>
<h2 id="概述">概述</h2>
<p><strong>人类动作识别（Human Action Recognition,
HAR）</strong>旨在理解人类的行为，并为每个行为分配一个标签。</p>
<p>多种不同的数据形态都可以用来表示人类的动作和行为。这些模态可以分为2类：<strong>视觉模态和非视觉模态</strong></p>
<p>视觉模态和非视觉模态的主要区别在于：视觉模态的数据对人类行为的表示相对直观，但是非视觉模态的数据则不是。视觉模态主要包括：如RGB，骨架，深度，红外，点云，事件流（event
stream）等数据模态，而非视觉模态则主要包括音频，加速度，雷达，wifi信号等数据模态</p>
<p>然而，由于不同的模态对 HAR
具有不同的优势和局限性，因此多种数据模态的融合和跨模态的知识传递以提高
HAR 的准确性和稳健性，近年来也受到了极大的关注
[23]，[24]。更具体地说，融合是指将两种或多种模态的信息组合起来，以识别动作</p>
<p>该综述对基于不同数据模态的深度学习HAR方法的最新进展做了一个综合调研。介绍调研的主要内容分为三部分</p>
<ul>
<li>当前主流的单模态深度学习方法</li>
<li>当前主流的多模态深度学习方法，包括基于融合（fusion）和协同学习（co-learning）的学习框架</li>
<li>当前HAR任务的主流数据集</li>
</ul>
<h2 id="单一模态-single-modality">单一模态 SINGLE MODALITY</h2>
<h3 id="rgb模态-rgb-modality">RGB模态 RGB MODALITY</h3>
<p>RGB 模态通常是指由 RGB
相机捕获的图像或视频（图像序列），旨在重现人眼所见。</p>
<p>RGB模态优点主要有：（1）RGB数据容易收集，通常是最常用的数据模态。（2）RGB模态包含所捕获的场景上下文的信息。（3）基于RGB的HAR方法也可以用来做pretrained
model。</p>
<p>缺点主要有：（1）由于RGB数据中存在背景、视点、尺度和光照条件的变化，所以在RGB模态中进行识别通常具有挑战性。（2）RGB
视频通常具有较大的数据量，导致在为 HAR
的时空环境建模时会产生高计算成本。</p>
<p>下面介绍面向基于 RGB 的 HAR 的高级深度学习，主要可分为四大类，即双流
2D 卷积神经网络 （CNN）、递归神经网络 （RNN）、3D CNN 和基于 Transformer
的方法</p>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/v2-4ec2f54d013bb5ab6996585c53f7755d_1440w.png" alt="v2-4ec2f54d013bb5ab6996585c53f7755d_1440w">
<figcaption aria-hidden="true">v2-4ec2f54d013bb5ab6996585c53f7755d_1440w</figcaption>
</figure>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/sadasd.png" alt="sadasd">
<figcaption aria-hidden="true">sadasd</figcaption>
</figure>
<h3 id="骨骼模态-skeleton-modality">骨骼模态 SKELETON MODALITY</h3>
<p>骨骼序列编码人体关节的轨迹，这些轨迹表征了信息丰富的人体运动。因此，骨架数据也是
HAR 的合适模式。</p>
<p>骨架数据提供的是身体结构与姿态信息，其具有两个明显的优点：（1）具有比例不变性。（2）对服装纹理和背景是鲁棒的。</p>
<p>但同时也有两个缺点：（1）骨架信息的表示比较稀疏，存在噪声。（2）骨架数据缺少人-物交互时可能存在的形状信息。</p>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/v2-f3f49680590c848b02f3e7911c5d7d3c_1440w.png" alt="v2-f3f49680590c848b02f3e7911c5d7d3c_1440w">
<figcaption aria-hidden="true">v2-f3f49680590c848b02f3e7911c5d7d3c_1440w</figcaption>
</figure>
<h3 id="深度模态-depth-modality">深度模态 DEPTH MODALITY</h3>
<p>深度图其中像素值表示从给定视点到场景中的点的距离信息。深度模态通常对颜色和纹理的变化具有鲁棒性，提供了可靠的人体三维结构和几何形状信息，因此可用于
HAR。随着技术的发展，现在已经有多种设备可以捕获场景中的深度图。现有的对深度数据学习的方法大多数还是利用CNN提取深度图中的feature。深度数据可以提供几何形状信息，但是对外观数据的提供是缺失的，所以深度数据通常不单独使用，而是与其他模态的数据融合使用。</p>
<h3 id="红外模态-infrared-modality">红外模态 INFRARED MODALITY</h3>
<p>通常，红外传感器不需要依赖外部环境光，因此特别适用于夜间
HARat。红外传感技术可分为有源和无源两种。一些红外传感器（如
Kinect）依赖于主动红外技术，该技术发射红外线并利用目标反射光线来感知场景中的物体。在目前基于深度学习的方法中，比较多的做法是把红外图像作为其中一个stream输入双流或多流网络中。红外数据以其不需要依赖外部环境的可见光的特点，特别适合于夜间的HAR，但是，红外图像也有着对比度低和信噪比低的固有缺点。</p>
<h3 id="点云模态-point-cloudmodality">点云模态 POINT CLOUDMODALITY</h3>
<p>点云数据由许多点集合组成，这些点表示空间参考系统下目标的空间分布和表面特征。获取
3D 点云数据有两种主要方法，即 （1） 使用 3D 传感器，例如 LiDAR 和
Kinect，或 （2） 使用基于图像的 3D 重建。点云作为一种 3D
数据模态，具有强大的能力来表示主体的空间轮廓和 3D 几何形状，因此可以用于
HAR。但是点云中通常存在噪声和高度不均匀的点分布。</p>
<h3 id="事件流模态-event-stream-modality">事件流模态 EVENT STREAM
MODALITY</h3>
<p>事件照相机（event
camera）可以捕捉照明条件的变化并为每个像素独立产生异步事件。传统的摄像机通常会捕捉整个图像阵列，而事件摄像机仅响应视觉场景的变化。事件照相机能够有效地滤除背景信息，而只保留前景运动信息，这样可以避免视觉信息中的大量冗余，但是其捕捉到的信息通常在时间和空间维度上是稀疏的，而且是异步的。因此一些现有的方法主要聚焦于设计事件聚合策略，将事件摄像机的异步输出转换为同步的视觉帧。</p>
<h3 id="音频模态-audio-modality">音频模态 AUDIO MODALITY</h3>
<p>音频信号通常与视频信号一起提供，由于音频和视频是同步的，所以音频数据可以用定位动作。因为音频信号中的信息量是不足的，所以单独使用音频数据执行HAR任务相对比较少见。更常见的情况是音频信号作为HAR的补充信息，与其他模态（如rgb图像）一起使用。</p>
<h3 id="后续">后续</h3>
<p>还有加速度模态，雷达模态，wifi模态，我先不了解，后续若有需要再完善知识</p>
<h2 id="多模态-multi-modality">多模态 MULTI-MODALITY</h2>
<p>在现实生活中，人类经常以多模态认知方式感知环境。同样，多模态机器学习是一种建模方法，旨在处理和关联来自多种模态的感觉信息[358]。通过聚合各种数据模态的优势和功能，多模态机器学习通常可以提供更强大、更准确的
HAR。</p>
<p>多模态学习方法主要有两种，融合（fusion）和协同学习（co-learning）。其中融合指的是对来自两个或更多模态的信息进行集成，并将其用于训练或推理，而协同学习指的则是对不同模态之间的知识进行迁移。图4展示了多模态学习方法的分类</p>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/v2-04335982349266acffdb93355ce2686c_1440w.png" alt="v2-04335982349266acffdb93355ce2686c_1440w">
<figcaption aria-hidden="true">v2-04335982349266acffdb93355ce2686c_1440w</figcaption>
</figure>
<h3 id="har任务中的多模态融合">HAR任务中的多模态融合</h3>
<p>模态融合的目的是利用不同数据模态的互补优势，以达到更好的识别性能。现有的多模态融合方案主要有两种：（1）评分融合（score
fusion），即对不同模态输出的score做融合，例如使用加权平均或学习一个分数融合模型。（2）特征融合，即对来自不同模态的特征进行组合。数据融合（在特征提取之前就融合不同模态的输入数据）可以看成是特征融合，因为某一模态的数据数据可以被视为该模态的原始特征。</p>
<p>依据输入模态的不同，现有的多模态融合方法大概可以分为视觉模态之间的融合，与视觉+非视觉模态之间的融合两种</p>
<h4 id="视觉模态之间的融合"><strong>视觉模态之间的融合</strong></h4>
<ol type="1">
<li>RGB+深度模态：RGB和深度模态分别能够捕捉外观信息和3D形状信息，因此它们具有比较强的互补性。</li>
<li>RGB+骨架模态：骨架模态可以提供身体位置和关节运动信息，同样和RGB模态是互补的。[28]提出了一个双流深度网络，两个stream分别是CNN和RNN，用以分别处理RGB和骨架数据，融合方式同时尝试了特征融合和分数融合，并发现应用特征融合策略可以取得更好的效果。</li>
<li>深度图+骨架模态：[31]将身体的每个部分与其他部分之间的相对几何关系作为骨架特征，将不同身体部分周围的深度图像块作为外观特征，以编码身体-对象和身体部分-身体部分之间的关系，进而实现可靠的HAR。</li>
<li>RGB+深度图+骨架模态：这类方法大多是前文提到了三类多模态融合方法的扩展。</li>
</ol>
<h4 id="视觉模态非视觉模态的融合"><strong>视觉模态+非视觉模态的融合</strong></h4>
<ol type="1">
<li>视频与音频的融合：前文中已经提到，音频可以为视频的外观和运动信息提供补充信息。所以目前已经有一些基于深度学习的方法来融合这种模态的数据</li>
<li>视频与加速度模态的融合</li>
<li>其他类型的模态融合：[43]的核心思想是将非RGB模态的数据，包括骨架、加速度和wifi数据都转换成彩色图像，然后送入CNN中。</li>
</ol>
<h3 id="har任务中的多模态协同学习">HAR任务中的多模态协同学习</h3>
<p>多模态协同学习旨在探索如何利用辅助模态学习到的知识帮助另一个模态的学习，希望通过跨模态的知识传递和迁移可以克服单一模态的缺点，提高性能。多模态协同学习与多模态融合的一个关键区别在于，在多模态协同学习中，辅助模态的数据仅仅在训练阶段需要，测试阶段并不需要。所以多模态协同学习尤其适用于模态缺失的场景。此外对于模态样本数较小的场景，多模态协同学习也可以起到一定的帮助作用。</p>
<h4 id="视觉模态的协同学习"><strong>视觉模态的协同学习</strong></h4>
<ol type="1">
<li>RGB和深度模态的协同学习</li>
<li>RGB和骨架模态的协同学习。如[48]利用CNN+LSTM执行基于RGB视频的分类，并利用在骨架数据上训练的LSTM模型充当调节器，强制两个模型的输出特征相似。</li>
</ol>
<h4 id="视觉和非视觉模态的协同学习"><strong>视觉和非视觉模态的协同学习</strong></h4>
<p>第一种类型是在不同模态之间进行知识的迁移，如[50]中的teacher
network使用非视觉模态训练，而student
network使用RGB模态作为输入，通过强制teacher和student的attention
map相似以弥补模态间的形态差距，并实现知识的提炼。</p>
<p>第二种类型是利用不同模态之间的相关性进行自监督学习，比如[51]分别利用音频/视频模态中的无监督聚类结果作为视频/音频模态的监督信号。[52]使用视频和音频的时间同步信息作为自监督信号。</p>
<h1 id="论文二rwf-2000-an-open-large-scale-video-database-for-violence-detection">论文二：RWF-2000:
An Open Large Scale Video Database for Violence Detection</h1>
<p><a href="https://github.com/mchengny/RWF2000-Video-Database-for-Violence-Detection">mchengny/RWF2000-Video-Database-for-Violence-Detection：一个用于暴力检测的大型视频数据库，其中包含
2,000 个包含暴力或非暴力行为的视频剪辑。</a></p>
<h2 id="摘要">摘要</h2>
<p>近年来，监控摄像头在公共场所广泛部署，由于这些无处不在的设备，总体犯罪率已显著降低。通常，这些摄像头会在犯罪发生后提供线索和证据，而很少用于及时预防或制止犯罪活动。手动监控来自监控摄像头的大量视频数据既费时又费力。因此，从视频信号中自动识别暴力行为变得至关重要。</p>
<p>本文总结了几个现有的用于暴力检测的视频数据集，并提出了 RWF-2000
数据库，其中包含监控摄像头在真实场景中捕获的 2,000
个视频。此外，我们还提出了一种同时利用 3D-CNN
和光流优点的新方法，即流门控网络。所提出的方法在我们提出的数据库的测试集上获得了
87.25% 的准确率。数据库和源代码目前对 Access 1 开放。</p>
<h2 id="概述-1">概述</h2>
<p>通常，基于视频的暴力检测的定义是检测视频数据中的暴力行为。它是人类动作识别的一个子集，旨在识别常见的人类动作。与静止图像相比，视频数据具有额外的时间序列。一组连续的帧表示连续的运动，而相邻的帧由于帧间相关性高而包含冗余信息。</p>
<p>一些早期的方法依赖于检测高度相关物体（例如，枪击、火焰、血腥、爆炸）的存在，而不是直接识别暴力事件</p>
<p>此前数据的劣势：尽管存在一些用于暴力检测的视频数据集，但它们仍然存在规模小、多样性少和图像分辨率低的缺点。此外，一些具有高图像质量的相关数据集来自电影，这些电影与真实场景不够接近。为解决真实暴力活动中高质量数据不足的问题</p>
<p>本文工作：</p>
<ol type="1">
<li>为了解决真实暴力活动中高质量数据不足的问题，我们收集了一个新的视频数据集
（RWF-2000）
并将其免费发布给研究界。该数据集规模较大，包含从监控视频中提取的 2,000
个剪辑</li>
<li>我们提出了一种新的具有自学习池机制的模型，该模型可以很好地兼顾外观特征和时间特征。</li>
</ol>
<h2 id="先前数据集">先前数据集</h2>
<p>根据注释方法，仍然存在两种用于暴力检测的视频数据集：修剪和未修剪。裁剪后的数据集中的视频都是几秒长的短片，每个视频都有一个视频级标注。而视频未修剪的数据集通常具有更长的持续时间。此外，暴力活动的开始时间和结束时间都有帧级注释。</p>
<p>总结这些提议的数据集，每个数据集都至少具有以下一个或多个限制：</p>
<ul>
<li>图像质量低;缺乏足够的数据量</li>
<li>视频时长但注释粗糙</li>
<li>与现实暴力不够接近的视频混合来源</li>
</ul>
<p>为了解决上述问题，我们从 YouTube 网站收集了一个新的 RWF
2000（真实世界格斗）数据集，其中包括 2,000
个由监控枪式摄像机从真实场景中拍摄的修剪视频剪辑。</p>
<h2 id="先前方法">先前方法</h2>
<p>传统方法通常会尝试找到一个 powfer
特征提取算法，并实现一个基于机器学习的分类器来完成暴力检测任务。</p>
<p>总之，基于深度学习的方法通常优于传统的基于特征提取的模型。此外，大多数最先进的结果都使用多通道输入（例如，原始
RGB 图像、光流、加速度图）。同时，复杂模型对过拟合不是很鲁棒。</p>
<p>在本文中，我们只采用 RGB
图像和光流来构建神经网络，它可以处理空间和时间信息。此外，我们提出的
Flow-Gated
架构可以通过自学习来减少输入视频的时间通道，而不是传统的池化策略。</p>
<h2 id="rwf-2000-数据库和建议的方法">RWF-2000 数据库和建议的方法</h2>
<h3 id="数据采集">数据采集</h3>
<p>为了使暴力检测在现实应用中更加实用，我们从 YouTube
平台收集了一个新的真实世界格斗 （RWF）
数据集，其中包含监控摄像头在真实场景中拍摄的 2,000 个视频剪辑。</p>
<p>拟议的数据集有 2,000 个视频剪辑，分为两部分：训练集 （80%） 和测试集
（20%）。一半的视频包含暴力行为，而其他视频属于非暴力活动。</p>
<h3 id="flow-gated-network">Flow Gated Network</h3>
<p>以前的大多数方法都探索从单个帧中提取外观特征，然后将它们融合以对时间信息进行建模。由于粗略的池化机制，运动信息可能毫无用处，我们的目标是设计一种通过网络自学习实现的时间池化机制</p>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/asdasf.png" alt="asdasf">
<figcaption aria-hidden="true">asdasf</figcaption>
</figure>
<p>由四个部分组成：RGB 通道、光流通道、合并块和全连接层。RGB
通道和光流通道由级联的 3D CNN
组成，它们具有一致的结构，因此它们的输出可以融合。Merging Block
也由基本的 3D CNN 组成，这些 CNN
在自学时间池化后处理信息。最后，全连接层生成输出。</p>
<p>该模型的亮点是利用光流通道的一个分支来帮助构建池化机制。</p>
<h1 id="后续学习">后续学习</h1>
<p><a href="https://blog.csdn.net/qq_32892383/article/details/136413119">基于YOLOv8/YOLOv7/YOLOv6/YOLOv5的暴力行为检测系统（深度学习模型+UI界面+Python代码+训练数据集）-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/qq_42681787/article/details/134423818">YOLO8实战：暴力行为检测系统_yolov8
打架检测-CSDN博客</a></p>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://www.bilibili.com/video/BV1aR4y1J7uv/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">科研分享|视频异常检测_哔哩哔哩_bilibili</a></p>
<p>[<a href="https://zhuanlan.zhihu.com/p/553262457">领域综述] TPAMI
2022 | Human Action Recognition from Various Data Modalities: A Review -
知乎</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/105360879">RWF-2000
暴力行为检测视频数据集 - 知乎</a></p>
<p>另一个暴力行为数据集<a href="https://roc-ng.github.io/XD-Violence/">XD-暴力</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——基础知识储备</title>
    <url>/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/</url>
    <content><![CDATA[<h1 id="学习计划">学习计划</h1>
<ul class="task-list">
<li><label><input type="checkbox">yolo深入学习，代码初步运行尝试</label></li>
<li><label><input type="checkbox" checked>视频异常检测与视频动作识别的概念明晰与区分</label></li>
<li><label><input type="checkbox">实际操作知识储备：视频预处理，训练，测试</label></li>
<li><label><input type="checkbox" checked>具体算法知识储备：<strong>3D CNN</strong> ，<strong>2D CNN
+ RNN</strong>，<strong>LSTM</strong></label></li>
<li><label><input type="checkbox" checked>根据PPT初步构建立项书框架</label></li>
</ul>
<h1 id="视频异常检测与视频动作识别的概念明晰与区分">视频异常检测与视频动作识别的概念明晰与区分</h1>
<p>我们后续做的主要是<strong>暴力行为的识别</strong>，我个人原本概念并没有清楚，以为是属于视频异常检测领域，但这里更关注的是人的动作，应该与视频动作识别更贴合，以下是我结合网上文章理解的二者区别，用词不严谨处还请指正</p>
<p>视频异常检测系统能够检测明显偏离正常的异常行为或实体，例如在视频监控的先验知识有限的情况下识别多个移动物体，或检测特定事件，例如打架、踩踏、交通事故和流浪。<strong>视频异常通常是上下文的，并根据真实场景定义</strong>。具体来说，检测过程集中于识别所有视频中包含异常的视频片段，而定位致力于确定哪一帧是异常的，并解释该帧的哪一部分是异常的。</p>
<p><strong>视频动作识别</strong>是通过已标记的数据集训练模型实现视频理解视频分类的功能。动作识别的目标是识别出视频中出现的动作，通常是视频中人的动作。视频可以看作是由一组图像帧按时间顺序排列而成的数据结构，比图像多了一个时间维度。动作识别不仅要分析视频中每帧图像的内容，还需要从视频帧之间的时序信息中挖掘线索。动作识别是视频理解的核心领域，虽然动作识别主要是识别视频中人的动作，但是该领域发展出来的算法大多数不特定针对人，也可以用于其他视频分类场景。</p>
<h1 id="二维卷积-2d-cnn">二维卷积 2D CNN</h1>
<p>卷积神经网络（convolutional neural
network）是含有卷积层（convolutional
layer）的神经网络。它有高和宽两个空间维度，常用来处理图像数据。</p>
<h2 id="卷积神经网络的结构">卷积神经网络的结构</h2>
<p>层级网络，数据包括输入层，卷积层，激活层，池化层，全连接层等</p>
<p><strong>输入层</strong>：就是原始图像，非提取的信息，因此卷积神经网络是一个无监督的特征学习网络，数据输入层主要对原始图像数据进行预处理，基础的操作包括去均值、灰度归一化，数据增强等；</p>
<p><strong>卷积层</strong>：就是特征提取层，一般卷积神经网络包含多个卷积层，一个卷积层可以有多个不同的卷积核。通过不同的多个卷积核对图像进行预处理，提取特征，每个卷积核会映射出新的特征平面。再通过非线性激活函数对卷积结果进行处理；</p>
<p><strong>激活层</strong>：卷积神经网络需要激活层进行特征的选择和抑制；</p>
<p><strong>池化层</strong>：用于降低特征平面分辨率及抽象特征，可以有效的压缩网络参数和数据，减少过拟合。池化层最主要的作用就是压缩图像同时保存图像的特征不变；</p>
<p><strong>全连接层</strong>：是卷积神经网络的最后，具有卷积核和偏移量两个参数。（fully
connected
layers，FC）在整个卷积神经网络中起到“分类器”的作用，全连接层则起到将学到的“分布式特征表示”映射到样本标记空间的作用。在实际使用中，全连接层可由卷积操作实现：对前层是全连接的全连接层可以转化为卷积核为1x1的卷积；而前层是卷积层的全连接层可以转化为卷积核为hxw的全局卷积，h和w分别为前层卷积结果的高和宽</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/3c266da23107494b04b09683b8427f0e.png" alt="3c266da23107494b04b09683b8427f0e">
<figcaption aria-hidden="true">3c266da23107494b04b09683b8427f0e</figcaption>
</figure>
<p>卷积核的运算</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/7b8af7c9507e7652df6ff7e3c14f8a1f.png" alt="7b8af7c9507e7652df6ff7e3c14f8a1f">
<figcaption aria-hidden="true">7b8af7c9507e7652df6ff7e3c14f8a1f</figcaption>
</figure>
<h2 id="应用">应用</h2>
<p>2D卷积神经网络（2D CNN）则主要用于处理二维图像数据，如<a href="https://cloud.baidu.com/product/face">人脸识别</a>、物体检测和自动驾驶等任务。2D
CNN通过将图像划分为多个小的矩形区域（也称为滤波器或卷积核），可以对每个区域进行<strong>独立的特征提取</strong>。这种网络结构可以有效地减少计算量，同时提高特征提取的精度。在计算机视觉领域，2D
CNN已经成为许多重要应用的基石，如人脸识别和目标检测等。</p>
<h1 id="三维卷积-3d-cnn">三维卷积 3D CNN</h1>
<p>三维卷积输入多了深度C这个维度，输入是高度H<em>宽度W</em>深度C的三维矩阵。</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/7d1a499a0a3c3a43c7677e57c85e1890.png" alt="7d1a499a0a3c3a43c7677e57c85e1890">
<figcaption aria-hidden="true">7d1a499a0a3c3a43c7677e57c85e1890</figcaption>
</figure>
<p>3D
CNN是如何对时间维度进行操作的，如下图所示，我们将时间维度看成是第三维，这里是对连续的四帧图像进行卷积操作，3D卷积是通过堆叠多个连续的帧组成一个立方体，然后在立方体中运用3D卷积核。在这个结构中，卷积层中每一个特征map都会与上一层中多个邻近的连续帧相连，因此捕捉运动信息。
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/f8c08dd50063b71d02bbfe5c73c364dd.png" alt="f8c08dd50063b71d02bbfe5c73c364dd"></p>
<h2 id="三维卷积和多通道卷积的区别">三维卷积和多通道卷积的区别</h2>
<h3 id="多通道卷积">多通道卷积</h3>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/61bbb9de76c74320cb9d22077a128612.jpg" alt="61bbb9de76c74320cb9d22077a128612">
<figcaption aria-hidden="true">61bbb9de76c74320cb9d22077a128612</figcaption>
</figure>
<p>具体的实现过程为：</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/968772caaeba0e8b02257717f4019d97.png" alt="968772caaeba0e8b02257717f4019d97">
<figcaption aria-hidden="true">968772caaeba0e8b02257717f4019d97</figcaption>
</figure>
<p>3D CNN主要运用在视频分类、动作识别等领域，它是在2D
CNN的基础上改变而来。由于2D
CNN不能很好的捕获时序上的信息，因此我们采用3D
CNN，这样就能将视频中时序信息进行很好的利用。</p>
<h1 id="循环神经网络-rnn-与-长短期记忆-lstm">循环神经网络 RNN 与
长短期记忆 LSTM</h1>
<p><a href="https://zhuanlan.zhihu.com/p/123211148">史上最详细循环神经网络讲解（RNN/LSTM/GRU）
- 知乎</a></p>
<p><a href="https://www.bilibili.com/video/BV1z5411f7Bm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【循环神经网络】5分钟搞懂RNN，3D动画深入浅出_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1Z34y1k7mc?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【LSTM长短期记忆网络】3D模型一目了然，带你领略算法背后的逻辑_哔哩哔哩_bilibili</a></p>
<h1 id="立项书框架构建">立项书框架构建</h1>
<h2 id="工作清单">工作清单</h2>
<ol type="1">
<li>每个人写一份自我介绍，包括自身具备的知识条件、自己的特长、兴趣、已有的实践创新成果</li>
<li>每个人查找8篇关于人体动作识别或者暴力事件识别的相关论文，要求：1.国内外论文都要有
2.每个人找好后打成一个压缩包发群里，并把论文名发群里，后面发的就不要跟上面重复了
3.压缩包中除了包含论文，再有一个word文档，简单说明收集每个论文的主要内容</li>
<li>简单看一下我发群里的两份去年的立项书，结合立项书框架想一想，后续会进行分工</li>
</ol>
<h2 id="立项书框架">立项书框架</h2>
<ol type="1">
<li>项目研究背景
<ol type="1">
<li>研究意义</li>
<li>国内外研究现状
<ol type="1">
<li>人类动作识别现状</li>
<li>暴力行为识别现状</li>
</ol></li>
<li>项目研究目标及主要内容</li>
<li>项目创新特色概述</li>
<li>项目研究技术路线</li>
<li>项目方案设计</li>
</ol></li>
</ol>
<h2 id="ppt思路初步构建">PPT思路初步构建</h2>
<h3 id="背景与意义">背景与意义</h3>
<ol type="1">
<li>人体行为事件的含义与应用</li>
<li>视频暴力行为识别的意义</li>
<li>暴力行为的定义，早期与后续方法的比较，数据集的比较，暴力行为识别任务和应用</li>
</ol>
<h3 id="研究现状">研究现状</h3>
<p>单模态与多模态的优点和挑战</p>
<p>行为识别和暴力行为的识别和挑战</p>
<p>数据集的对比</p>
<p>解决方法的比较：3D CNN, 2D CNN+ RNN, 骨架</p>
<h3 id="研究方法抓住识别暴力的要素">研究方法：抓住识别暴力的要素</h3>
<p>一方面：抓住重要因素进行特征提取</p>
<p>另一方面：尽可能去除冗余信息（裁剪 / 去背景）</p>
<p>算法框架</p>
<p>注意力融合模块</p>
<h3 id="总结">总结</h3>
<ol type="1">
<li><p>提出了一种基于多模态特征融合的视频暴力行为识别算法。通过融合RGB模态提供的外观信息、RGB帧差提供的运动信息以及Depth模态提供的相对位置信息，丰富、完善了暴力行为的特征，使其能够准确、鲁棒地在复杂的真实环境下进行暴力行为识别。</p></li>
<li><p>提出了一种自适应的注意力算法用于多模态融合。让模型自适应地学习不同模态特征之间的权重关系，允许模型根据具体任务动态调整每个模态的重要性，从而更灵活地应对不同的场景。</p></li>
</ol>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://blog.csdn.net/qq_63019407/article/details/125805364">【视频异常检测综述-论文阅读】Deep
Video Anomaly Detection: Opportunities and Challenges-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/Yong_Qi2015/article/details/120837919">视频理解综述：动作识别、时序动作定位、视频Embedding-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/YOULANSHENGMENG/article/details/121328554">深度学习笔记—-三维卷积及其应用（3DCNN,PointNet,3D
U-Net）-CSDN博客</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>PaddleOCR</title>
    <url>/2025/12/06/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/PaddleOCR/</url>
    <content><![CDATA[<h3 id="ocr-返回字段详解表格">🔍 OCR 返回字段详解（表格）</h3>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 13%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr>
<th>字段名</th>
<th>类型</th>
<th>含义说明</th>
<th>示例值</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>file_path</code></td>
<td><code>str</code></td>
<td>输入的 PDF 文件路径</td>
<td><code>"D:\code\python\ocr\MMGraphRAG_Connecting_Vision_and_Language.pdf"</code></td>
</tr>
<tr>
<td><code>model_settings</code></td>
<td><code>dict</code></td>
<td>模型推理时的配置参数</td>
<td><code>&#123;'use_doc_preprocessor': False, 'use_textline_orientation': False&#125;</code></td>
</tr>
<tr>
<td><code>dt_polys</code></td>
<td><code>List[List[List[int]]]</code></td>
<td><strong>文本检测框</strong>（Detection），每个框由 4 个
<code>[x, y]</code>
坐标表示（顺时针或任意顺序），通常为四边形（支持倾斜文本）</td>
<td><code>[[479, 209], [2264, 203], [2265, 316], [479, 322]]</code></td>
</tr>
<tr>
<td><code>text_det_params</code></td>
<td><code>dict</code></td>
<td>文本检测模块的超参数（如阈值、尺寸限制等）</td>
<td><code>&#123;'thresh': 0.3, 'box_thresh': 0.6, 'unclip_ratio': 1.5&#125;</code></td>
</tr>
<tr>
<td><code>text_type</code></td>
<td><code>str</code></td>
<td>文本类型（如通用文本、公式、表格等）</td>
<td><code>"general"</code></td>
</tr>
<tr>
<td><code>textline_orientation_angles</code></td>
<td><code>List[int]</code></td>
<td>每行文本的旋转角度（单位：度或索引），<code>-1</code>
表示未启用或无旋转</td>
<td><code>[-1, -1, ..., -1]</code></td>
</tr>
<tr>
<td><code>text_rec_score_thresh</code></td>
<td><code>float</code></td>
<td>文本识别的置信度阈值（低于此值的文本可能被过滤）</td>
<td><code>0.0</code>（表示全部保留）</td>
</tr>
<tr>
<td><code>return_word_box</code></td>
<td><code>bool</code></td>
<td>是否返回单词级而非行级的 bounding box</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>rec_texts</code></td>
<td><code>List[str]</code></td>
<td><strong>识别出的文本内容</strong>（Recognition），与
<code>dt_polys</code> 一一对应</td>
<td><code>["MMGraphRAG：通过可 解释的多模态", ...]</code></td>
</tr>
<tr>
<td><code>rec_scores</code></td>
<td><code>List[float]</code></td>
<td>每个识别文本的<strong>置信度得分</strong>（0~1）</td>
<td><code>[0.9902, 0.9990, ...]</code></td>
</tr>
<tr>
<td><code>rec_polys</code></td>
<td><code>List[List[List[int]]]</code></td>
<td>同
<code>dt_polys</code>，通常是检测和识别结果对齐后的多边形坐标</td>
<td>与 <code>dt_polys</code> 相同（此处未做后处理调整）</td>
</tr>
<tr>
<td><code>rec_boxes</code></td>
<td><code>List[List[int]]</code></td>
<td><strong>简化版文本框</strong>（轴对齐矩形 bounding box），格式为
<code>[x_min, y_min, x_max, y_max]</code></td>
<td><code>[479, 203, 2265, 322]</code></td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>ocr</category>
      </categories>
      <tags>
        <tag>ocr</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——论文筛选</title>
    <url>/2024/11/19/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B3%E2%80%94%E2%80%94%E8%AE%BA%E6%96%87%E7%AD%9B%E9%80%89/</url>
    <content><![CDATA[<p>本文对目前已收集到的论文进行筛选工作，并简单概述可取之处</p>
<h1 id="视频监控中人体暴力行为检测系统设计与应用">视频监控中人体暴力行为检测系统设计与应用</h1>
<p>非常非常好的一篇，跟我们要做的方向很贴合，每个人都要看一下，以下是我认为可以学习的地方：</p>
<ol type="1">
<li><p>绪论部分：课题研究的背景和意义；从智能视频监控技术和行为识别算法两个方面介绍了研究现状</p></li>
<li><p>同样选用了RWF-2000数据集，并给出了理由，同时介绍了三大常见数据集并进行了比较（HMDB-51，UCF101，Kinetics）；在模型框架技术选型方面，简要介绍了
传统方法，然后对比了深度学习下的基于人体骨架的方法以及基于视频的方法。
之后详细介绍了三类基于视频的深度学习方法（双流法，3D卷积方法
和基于时序模型的方法）</p></li>
</ol>
<p>​ 本文文采用了双流模型 作为基础框架，我后续了解双流法与我们的
多模态方向是很贴合的</p>
<ol start="3" type="1">
<li>本文完成了人体暴力行为检测系统的设计与实现，包含离线分析和在线监测两种模式，这跟我们的设想很符合</li>
</ol>
<h1 id="基于注意力机制的暴力音视频检测方法研究">基于注意力机制的暴力音视频检测方法研究</h1>
<p>与上一篇同样是哈尔滨工业大学的硕士论文，侧重点也是多模态暴力检测，本文先提出分别基于视觉通道和基于听觉通道的暴力音频检测，再提出了基于视听觉通道的音视频特征融合的暴力音视频检测</p>
<p>本文开头的课题研究的背景和意义和研究现状同样值得参考</p>
<h1 id="基于多模态的校园暴力检测">基于多模态的校园暴力检测</h1>
<p>给我感觉一般，多模态的部分写的并不是很好，他还说的一个基于多模态的校园暴力检测，感觉什么都写到了什么都写的不是很精</p>
<p>但是他在相关理论基础详细地介绍了深度学习网络（RNN，LSTM，GRU）和人体动作识别（openpose），可以参考学习</p>
<h1 id="基于对比学习的视频暴力行为检测算法及-tensorrt-平台实现">基于对比学习的视频暴力行为检测算法及
TensorRT 平台实现</h1>
<p>里面的对比学习和注意力机制不是很看得懂，但感觉写的挺好的，这篇还把识别系统做在TensorRT
平台实现轻量化，这个跟我们关系不大，只做了解</p>
<h1 id="基于yolo和convlstm混合神经网络的暴力视频检测">基于YOLO和ConvLSTM混合神经网络的暴力视频检测</h1>
<p>有yolo相关知识，后续可做参考学习</p>
<h1 id="国外论文">国外论文</h1>
<p>因为英文看的太费劲，对国外论文暂时只做初步筛选</p>
<p>Conv3D-Based Video Violence Detection Network Using Optical Flow and
RGB Data：光流和RGB数据多模态</p>
<p>Multimodal vision-based human action recognition using deep learning:
a review：关于多模态的综述论文，这一篇写的不错，有时间值得啃一下</p>
<p>A Real-Time 3-Dimensional Object Detection Based Human Action
Recognition
Model：3D卷积神经网络（3DCNN）、LSTM乘法递归网络和YOLOv6实时目标检测</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——模型环境配置</title>
    <url>/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h3 id="模型环境配置">模型环境配置</h3>
<p>利用yml导入conda虚拟环境</p>
<figure>
<img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/sad.png" alt="sad">
<figcaption aria-hidden="true">sad</figcaption>
</figure>
<p>安装cuda与cudnn</p>
<p><a href="https://blog.csdn.net/weixin_44779079/article/details/141528972">cuda和cudnn的安装教程(全网最详细保姆级教程)_cudnn安装-CSDN博客</a></p>
<p>使用国内源安装</p>
<p><code>pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p><code>pip install --upgrade tensorflow -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p>测试gpu运行</p>
<figure>
<img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/as.png" alt="as">
<figcaption aria-hidden="true">as</figcaption>
</figure>
<figure>
<img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/daf.png" alt="daf">
<figcaption aria-hidden="true">daf</figcaption>
</figure>
<p>根据提示补全依赖项</p>
<p>datasetProcess.py 将视频文件转换为 NumPy 数组（.npy
文件），并保存到指定目录中</p>
<p>models_rgb_depth.py 模型</p>
<p>evaluate_rgb_depth.py 跑数据集，返回准确度</p>
<figure>
<img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/asd.png" alt="asd">
<figcaption aria-hidden="true">asd</figcaption>
</figure>
<p>prediction_test.py 返回true or false</p>
<figure>
<img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/sadff.png" alt="sadff">
<figcaption aria-hidden="true">sadff</figcaption>
</figure>
<p>前两者需要输入命令行参数</p>
<p><code>python evaluate_rgb_depth.py --dataset rwf2000 --vidLen 32 --batchSize 4 --mode all --lstmType sepconv --fusionType C --weightsPath models/rgb_rgbdiff_depth_C_6/rwf2000_best_val_acc_Model</code></p>
<figure>
<img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/gadga.png" alt="gadga">
<figcaption aria-hidden="true">gadga</figcaption>
</figure>
<ul>
<li><code>--dataset rwf2000</code>: 指定数据集为
<code>rwf2000</code>。</li>
<li><code>--vidLen 32</code>: 每个视频序列的帧数为 32。</li>
<li><code>--batchSize 4</code>: 训练和评估的批量大小为 4。</li>
<li><code>--mode all</code>: 模型工作模式为
<code>all</code>，即使用视频帧、帧差和深度图三种输入。</li>
<li><code>--lstmType sepconv</code>: 使用 <code>sepconv</code> 类型的
LSTM 层。</li>
<li><code>--fusionType C</code>: 使用 <code>C</code>
类型的融合策略（特征拼接和注意力机制）。</li>
<li><code>--weightsPath models/rgb_rgbdiff_depth_C_6/rwf2000_best_val_acc_Model</code>:
指定预训练权重文件路径。</li>
</ul>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——立项答辩</title>
    <url>/2024/12/08/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B4%E2%80%94%E2%80%94%E7%AB%8B%E9%A1%B9%E7%AD%94%E8%BE%A9/</url>
    <content><![CDATA[<h2 id="答辩稿">答辩稿</h2>
<p>各位评委老师大家好，我是我们组的主持人张熙浚，我们组的研究方向是基于多模态特征融合的视频暴力行为识别方法的研究</p>
<p>接下来我会从四个方面介绍我们的项目</p>
<p>首先是背景与意义，暴力行为对社会危害极大，即使公共场所存在大量监控摄像头，但这些视频片段通常被用来在暴力犯罪发生后提供线索和证据，而很少被用来实时监控并阻止暴力行为。</p>
<p>由于监控人员不可能实时监控每一个摄像头产生的视频，所以部署暴力行为监测系统，能够节约人力资源，降低监控人员因疲劳而造成的风险，这十分关键</p>
<p>接下来，我将讲述当前暴力行为检测的研究现状。主流的人体动作识别把数据模态分为2类：视觉模态和非视觉模态。不同模态的数据有着各自的独特优势。</p>
<p>目前主流的单模态深度学习方法存在以下缺点。但真实的暴力事件场景往往存在以下特点。因此，我们提出了基于多模态的暴力事件检测，通过结合多种数据来源，从多个角度捕捉行为特征，尤其是在面对复杂环境、多人交互和遮挡等问题时，具有显著的优势。</p>
<p>接下来我会通过几篇论文中的方法介绍行为识别算法的研究现状</p>
<p>这一篇提出了数据集Rwf-2000，同时提出一种的双流网络架构，他们充分利用了RGB数据提供的外观信息和光流提供的运动信息，但缺点在于光流法计算量大、存储成本高，仅仅适用于光照条件良好、不拥挤的情况</p>
<p>这一篇是基于骨架的方法，通过提取人体骨骼关节，构成三维骨架阵列，通过骨架点卷积，实现分类。</p>
<p>优点是骨架可以很好的表示人体运动信息，但问题在于仅使用骨架数据，效果高度依赖于位姿估计的精度，无法有效应对存在遮挡的情况，同时因为仅使用骨架数据，其他信息存在缺失</p>
<p>这一篇是基于 2D CNN + RNN 的方法，2D CNN
提供强大的空间特征提取能力，RNN
提供强大的时间序列建模能力。将两者结合，能够更好地理解视频中的空间和时间信息。这一篇使用简单快速的预处理方法减少了冗余的背景信息，但其仅使用RGB模态，提取的特征不够全面</p>
<p>接下来我将介绍我们的研究内容与方法</p>
<p>我们的研究内容大致包含三个部分：1.提出一种基于多模态特征融合的视频暴力行为识别算法2.提出一种自适应的注意力算法用于多模态融合3.完成人体暴力行为检测系统的设计，接下来我将依次为大家介绍</p>
<p>第一部分，在特征提取阶段，为了区分暴力行为与非暴力行为，我们选择了三个要素进行提取：人体姿态、运动趋势和幅度、人物之间的位置关系，为了获取以上三个要素，研究工作包括下列内容：</p>
<p>a.RGB模态的去除冗余信息
为了避免原生RGB图像冗余信息影响模型判断，我们决定对于原生RGB图像进行冗余信息去除工作，首先计算一个视频中所有帧的均值，记为平均帧，用每一帧减去平均帧：去除不变的背景，保留运动的人体。</p>
<p>b.运动趋势与幅度特征的提取
目前主流反映物体运动趋势的方法是光流法，但我们考虑到光流图像在低像素复杂场景下效果不佳，且易受光照条件改变，并且计算量巨大，于是我们决定采取帧差法，通过对视频图像序列中相邻两帧作差分运算，来获得运动目标轮廓，以很好地适用于存在多个运动目标的情况。</p>
<p>c.深度模态的提取
在原始的RGB模态，复杂场景中难以分辨人物间的相对位置关系。因此，我们选取深度模态，其去除了颜色和纹理信息，并提供三维结构信息和人体轮廓，我们利用该论文提出的深度估计算法，对原始RGB视频进行深度估计，得到深度图，其清晰地反映了三维空间中人物间的相对位置关系。</p>
<p>算法框架方面，我们选择了CNN-LSTM的深度学习网络<strong>。</strong>LSTM擅长处理时序数据，而CNN能够从视频帧中提取空间特征。通过结合两者的优势，并以此构建了算法框架。</p>
<p>第二部分我们提出了一种自适应的注意力算法用于多模态融合，动态调整每个模态的权重，强调有用的信息特征，抑制不太有用的特征，从而应对不同场景。</p>
<p>池化，全连接层，归一化函数</p>
<p>第三部分，我们完成了人体暴力行为检测系统的设计，刻画了系统的边界及大小，人体暴力行为检测系统是一个自动检测暴力行为的智能视频监控系统。该系统采用了四层架构，即访问层，表示层、业务层以及数据层。
包含暴力检测模块，用户管理模块，视频源管理模块</p>
<p>我们已经初步构建了暴力行为的检测流程，系统包含离线分析和在线监测两种模式</p>
<p>为了提高检测速度和避免资源浪费，根据传入视频的总帧数进行判断，采取提示过短、一次预测或是多轮预测。</p>
<p>离线分析不依赖实时的监控视频，可对任意视频进行分析。它
的优点是它不依赖于视频监控系统，可以直接选择视频开始分析。</p>
<p>在线监测是暴力行为检测系统提供的另一种检测方式。它旨在利用监控视频资源，进行实时的暴力行为检测，达到即时分析并报警提示的功能。</p>
<p>最后是进度安排，我们已经完成算法大部分的编写，后续会继续完成系统的开发</p>
<p>谢谢各位老师观看，请各位老师批评指正</p>
<h2 id="疑问与解惑">疑问与解惑</h2>
<h3 id="为什么暴力行为检测隶属于人体行为识别">为什么暴力行为检测隶属于人体行为识别</h3>
<p>人体行为识别（Human Activity Recognition,
HAR）是一个广泛的领域，旨在通过传感器或视频数据来识别和分析人的各种动作或行为。暴力行为检测（Violent
Behavior Detection,
VBD）是这一领域的一个子任务，其核心目标是识别出具有暴力性质的特定行为，如打斗、推搡、殴打等。</p>
<p>暴力行为检测隶属于人体行为识别，主要原因是暴力行为本质上也是一种“人体行为”，通过分析人体的运动模式、姿态变化、动作轨迹等特征，能够有效识别出暴力事件。</p>
<h3 id="对于暴力行为的定义是什么">对于暴力行为的定义是什么？</h3>
<p>暴力行为通常指的是一种以伤害他人或具有威胁性、攻击性目的的行为。</p>
<h3 id="之前的暴力行为检测方向是什么现在侧重于人体动作本身有什么好处吗">之前的暴力行为检测方向是什么，现在侧重于人体动作本身有什么好处吗？</h3>
<p>暴力行为的检测方法<strong>传统上</strong>主要依赖于视频监控中检测到的图像信息、声音信号以及动作的特征。早期的检测方法侧重于基于背景和环境的变化,声学信号分析</p>
<p>现代的暴力行为检测越来越注重<strong>人体动作本身的识别</strong>，这有几个显著的好处：</p>
<ol type="1">
<li><strong>精确度提高</strong>：通过分析人体动作的细节，尤其是肢体的动态变化（如运动轨迹、速度、姿势变化），可以更准确地判断是否为暴力行为。</li>
<li><strong>降低误报率</strong>：单纯依靠环境变化或者声学分析容易受其他因素干扰（如背景噪音、非暴力事件的运动），而人体动作本身可以提供更加直接、可靠的行为判定依据。</li>
<li><strong>多模态融合</strong>：现代的暴力行为检测往往不仅仅依赖于单一的视觉信息，还结合了深度学习、动作识别等技术，可以从多个角度进行判断。通过分析人体动作特征和其他环境数据（如声音、位置等），可以更好地识别暴力事件。</li>
<li><strong>实时监控</strong>：实时检测人体动作变化对于暴力行为的早期预警至关重要，尤其是在公共安全或视频监控系统中，动作识别可以即时检测到潜在的暴力行为并进行响应。</li>
</ol>
<p>综上，侧重人体动作本身不仅可以提升检测的准确性，还能更好地从动态和连续的角度识别暴力行为，提高系统的实时性和鲁棒性。</p>
<h3 id="单模态的人体动作识别的缺点有哪些">单模态的人体动作识别的缺点有哪些</h3>
<p>单模态人体动作识别（即仅使用一种数据模态，如视觉、声音、加速度等）存在以下主要缺点：</p>
<ol type="1">
<li><p><strong>信息局限性</strong>：</p>
<p>单一模态只能捕获动作的部分信息，可能导致对动作的理解不够全面。例如，仅依赖视觉模态可能无法捕获细微的物理接触或动作的力度变化。</p></li>
<li><p><strong>环境敏感性</strong>：</p>
<p>单模态方法对环境条件过于依赖。例如，视觉模态在光照不足或存在遮挡的情况下表现不佳，而非视觉模态（如加速度计）在传感器未正确佩戴或被干扰时表现不佳。</p></li>
<li><p><strong>无法应对模糊或模态冲突</strong>：</p>
<p>单模态方法难以处理模糊的行为信号或区分相似动作。例如，在视觉模态中，某些动作（如挥手与投掷）可能在外观上十分相似。</p></li>
<li><p><strong>鲁棒性差</strong>：</p>
<p>单模态在面对复杂场景（如多人交互、噪音、遮挡等）时，容易出现误判或漏判。例如，在仅依赖声音模态时，背景噪音可能干扰动作识别。</p></li>
<li><p><strong>缺乏上下文信息</strong>：</p>
<p>单模态通常难以捕获行为发生的上下文。例如，仅通过视觉识别到一个人弯腰的动作，可能无法判断是捡拾物品还是摔倒</p></li>
</ol>
<h3 id="暴力行为场景有哪些特点使用多模态对这些特点的优势有哪些">暴力行为场景有哪些特点，使用多模态对这些特点的优势有哪些</h3>
<p>暴力行为场景通常具有以下几个显著特点，这些特点对检测系统提出了更高的要求：</p>
<ol type="1">
<li><p><strong>动态性强</strong>：</p>
<p>暴力行为往往是迅速发生的，例如打斗、推搡、摔倒等动作可能在短时间内完成，导致动作的变化非常快。</p></li>
<li><p><strong>多人交互</strong>：</p>
<p>暴力行为通常涉及两个或更多个体之间的互动，如互相推搡、打斗或攻击等。多个目标的运动和交互增加了识别的复杂度。</p></li>
<li><p><strong>复杂的姿态变化</strong>：</p>
<p>暴力行为中的人物姿态变化通常非常剧烈，涉及肢体的快速摆动、抓握、推拉等动作，且可能伴随一定的身体接触。</p></li>
<li><p><strong>不规则的空间布局</strong>：</p>
<p>在暴力行为场景中，人物可能会在空间内迅速移动，动作的方向和速度可能会发生剧烈变化。背景也可能因为人物的动态而发生显著变化。</p></li>
<li><p><strong>潜在的遮挡</strong>：</p>
<p>在暴力行为中，人物之间的动作可能会出现遮挡（例如，两人打斗时，其中一个人可能被另一个人挡住）。这种情况给基于视觉的检测带来了挑战。</p></li>
<li><p><strong>噪声与干扰因素</strong>：</p>
<p>背景中的其他活动、环境变化、背景噪声等都可能干扰暴力行为的识别。例如，打斗声可能被背景音乐、交通噪声等因素掩盖。</p></li>
</ol>
<p>多模态（即结合多种数据来源或感知方式，如视觉、声音、传感器数据等）方法能够弥补单模态方法的不足，通过结合视觉、声音和传感器等多模态信息，可以更好地应对这些挑战，提升暴力行为检测的准确性、鲁棒性和实时性。多模态方法能够综合各类信息，从多个角度捕捉行为特征，尤其是在面对复杂环境、多人交互和遮挡等问题时，具有显著的优势。</p>
<h3 id="d-cnn-rnn-的优点">2D CNN + RNN 的优点</h3>
<p>2D CNN（卷积神经网络）与
RNN（递归神经网络）的结合是行为识别中的一种常见方法，尤其适用于视频行为识别任务。其主要优点包括：</p>
<ol type="1">
<li><strong>空间特征与时间依赖性的有效结合</strong>：</li>
</ol>
<ul>
<li><strong>2D
CNN</strong>：能够从视频帧中提取空间特征，如人物的姿态、背景和动作细节。通过多层卷积，CNN能够识别局部和全局的空间信息。</li>
<li><strong>RNN（LSTM/GRU）</strong>：RNN特别擅长处理时序数据，可以建模视频帧之间的时间依赖关系，捕捉动作的动态变化和时间长短的依赖，适应动作序列的连续性和长期依赖。</li>
<li><strong>优点</strong>：2D CNN 提供强大的空间特征提取能力，RNN
提供强大的时间序列建模能力。将两者结合，能够更好地理解视频中的空间和时间信息，提升行为识别的准确性。</li>
</ul>
<ol start="2" type="1">
<li><strong>自动特征学习</strong>：</li>
</ol>
<ul>
<li>传统方法依赖手工特征提取（如HOG、光流等），需要依赖专家知识且难以适应多样的场景。而
<strong>2D CNN</strong>
能够自动学习空间特征，减少了人工设计特征的依赖，提高了对复杂场景的适应能力。</li>
<li><strong>RNN</strong>
则可以自动从数据中学习到行为模式的时间序列特征，不需要事先设定固定的时间模型或参数。</li>
</ul>
<ol start="3" type="1">
<li><strong>鲁棒性强，适应性好</strong>：</li>
</ol>
<ul>
<li><strong>2D CNN</strong>
通过卷积层提取多层次的空间特征，具有较好的鲁棒性，能够应对不同背景和复杂场景中的视频数据。</li>
<li><strong>RNN</strong>
具有处理不规则、可变时间长度序列的能力，能够识别动态变化的动作和突发行为，提高了模型的适应性。</li>
</ul>
<ol start="4" type="1">
<li><strong>可扩展性强</strong>：</li>
</ol>
<ul>
<li>2D CNN 和 RNN
的组合能够很好地扩展到不同的视频数据规模、场景和复杂度上。随着数据集的增大，模型仍然能够通过更深的网络层次和更多的时序数据进行训练，进一步提升识别效果。</li>
</ul>
<h2 id="答辩稿初版">答辩稿——初版</h2>
<p>各位评委老师大家好，我是我们组的主持人张熙浚，我们组的研究方式是基于多模态特征融合的视频暴力行为识别方法研究</p>
<p>接下来我会从五个方面介绍我们的项目</p>
<p>首先是背景与意义，暴力行为对社会危害极大，即使诸如学校、商场、银行、车站等公共场所存在大量监控摄像头，产生了大量的视频片段，但这些片段通常被用来在暴力犯罪发生后提供线索和证据，而很少被用来实时识别并停止暴力行为。</p>
<p>这便引出了我们项目的目的，我们希望利用计算机视觉技术，赋予机器暴力行为的判别能力，从而及时发现暴力行为并能有效降低其带来的危害，而且大大降低了人力成本，在安防领域有极大的应用价值。</p>
<p>暴力行为的检测方法早期的检测方法主要是依靠设立一些规则，或是依靠背景和环境的变化，这些方法在很多方面存在不足，包括受环境因素影响大，特征提取和分析能力有限，计算效率低等问题</p>
<p>而现代的暴力行为检测越来越注重<strong>人体动作本身的识别</strong>，其通过分析人体动作的细节，尤其是肢体的动态变化，不仅可以提升检测的准确性，还能更好地从动态和连续的角度识别暴力行为，提高系统的实时性和鲁棒性。</p>
<p>由于监控人员不可能实时监控每一个摄像头产生的视频，所以部署视频暴力行为识别系统，能够节约用于监控的人力资源，降低监控人员因疲劳或走神而造成的漏检风险，一旦识别到暴力行为立即警示相关人员，进一步采取相应措施。由此可以得出我们项目研究的现实意义和应用场景。</p>
<p>接下来，我将讲述当前暴力行为检测的研究背景和挑战，并引出我们的解决方案。多种不同的数据形态都可以用来表示人类的动作和行为。主流的人体动作识别把这些模态分为2类：视觉模态和非视觉模态。这些数据模态是对不同的信息来源进行编码，根据应用场景的不同，不同模态的数据有着不同的独特优势。</p>
<p>目前主流的单模态深度学习方法存在以下缺点：信息单一、对环境敏感、鲁棒性较差，难以应对复杂场景等。但真实的暴力事件场景往往存在以下特点：存在复杂姿态变化，多人交互，大量环境噪声等。因此，我们提出了基于多模态的暴力事件检测，通过结合多种数据来源，从多个角度捕捉行为特征，尤其是在面对复杂环境、多人交互和遮挡等问题时，具有显著的优势。</p>
<p>随着深度学习和计算机视觉技术的发展，深度学习方法已经成为了行为识别算法的主流方向，接下来我会通过几篇论文中的方法介绍研究现状</p>
<p>这一篇是早提出使用深度学习方法解决视频暴力行为识别任务，直接将视频输入三维卷积进行建模</p>
<p>这一篇提出了数据集Rwf-2000，同时提出一种的双流网络架构，他们充分利用了RGB数据提供的外观信息和光流提供的运动信息，但缺点在于光流法计算、存储成本高，适用于光照条件良好、不拥挤的情况</p>
<p>这一篇提出了一种弱监督方法，即通过少量的标签（例如，仅标记视频是否包含暴力，而不是标记具体的暴力事件位置和类型）来训练模型。他选取视频帧最关键的区域，但使用I3D作为骨干网络，参数量巨大（1300万）</p>
<p>这一篇是基于骨架的方法，通过提取人体骨骼关节点构成三维骨架阵列，根据局部区域点的特征和时空位置信息，构建特定的权重分布策略，通过骨架点卷积实现分类。优点是骨架可以很好的表示人体运动信息，但问题在于仅使用骨架数据，效果高度依赖于位姿估计的精度，无法有效遮挡情况，同时因为仅使用骨架数据，其他信息缺失</p>
<p>这一篇是基于 2D CNN + RNN 的方法，2D CNN
提供强大的空间特征提取能力，RNN
提供强大的时间序列建模能力。将两者结合，能够更好地理解视频中的空间和时间信息，提升行为识别的准确性。这一篇使用简单快速的预处理方法突出了人体，减少了冗余的背景信息，但其仅使用RGB模态，提取的特征不够全面</p>
<p>我们的研究内容大致包含三个部分：1.提出一种基于多模态特征融合的视频暴力行为识别算法2.提出一种自适应的注意力算法用于多模态融合3.完成人体暴力行为检测系统的设计，接下来我将依次为大家介绍</p>
<p>第一部分，在特征提取阶段，为了区分暴力行为与非暴力行为，我们选择了三个要素进行提取：人体姿态、运动（趋势、幅度）、人物之间的位置关系，为了获取以上三个要素，并保证模型的通用性和现实性，需要从原始的RGB图像中提取以上特征，研究工作包括下列内容：</p>
<p>a.RGB模态的去除冗余信息
为了避免原生RGB图像冗余信息影响模型判断，减少计算量，我们决定对于原生RGB图像进行冗余信息去除工作，首先计算一个视频中所有帧的均值，记为平均帧（主要包含背景信息，因为背景在所有视频帧中几乎保持不变）用每一帧减去平均帧：去除（不变的）背景，保留（运动的）人体。通过简易的预处理，去除了冗余的背景信息，聚焦于人体的外观、姿态。</p>
<p>b.运动趋势与幅度特征的提取
目前主流反映物体运动趋势的方法是光流法，但我们考虑到光流图像在低像素复杂场景下效果不佳，且易受光照条件改变的影响，于是决定采取帧差法，通过对视频图像序列中相邻两帧作差分运算来获得运动目标轮廓的方法，以很好地适用于存在多个运动目标的情况，算法相对实现简单，程序设计复杂度低，对光线等场景变化不太敏感，能够适应各种动态环境，有着比较强的鲁棒。</p>
<p>c.深度模态的提取
在原始的RGB模态中，复杂场景中，人物多且受光照影响严重，难以分辨人物间的相对位置关系。为了反映人物之间的位置关系，我们选取深度模态，其去除了颜色和纹理信息并提供三维结构信息和人体轮廓，我们利用Depth
estimation算法，对原始RGB视频进行深度估计，得到视点到场景中各点之间的距离作为像素点的图片，即深度图，其划分了近景与远景，刻画了人物的轮廓，反映了三维空间中人物间的相对位置关系。</p>
<p>我们选择了CNN-LSTM的深度学习方法<strong>。</strong>LSTM擅长处理时序数据，可以建模视频帧之间的时间依赖关系，而CNN能够从视频帧中提取空间特征。通过结合两者的优势，我们可以让模型同时考虑到数据的时序信息和空间信息，减少参数降低过拟合风险，从而提供更精确的预测、更出色的性能以及更高的训练效率，并以此构建了算法思路。</p>
<p>第二部分，针对多模态融合中权重数值处理的问题，我们提出了一种自适应的注意力算法用于多模态融合，让模型自适应地学习不同模态特征之间的权重关系，允许模型根据具体任务动态调整每个模态的重要性，强调信息特征，抑制不太有用的特征,从而更灵活地应对不同的场景。</p>
<p>第三部分，我们完成了人体暴力行为检测系统的设计，刻画了系统的边界及大小，人体暴力行为检测系统是一个自动检测暴力行为的智能视频监控系统。该系统采用了三层架构，即表示层、业务层以及数据层。
它被设计成一个Web系统，主要以网页的形式显示在PC 显示器上</p>
<p>我们已经初步构建了暴力行为的检测流程，系统包含离线分析和在线监测两种模式</p>
<p>离线分析不依赖实时的监控视频，可对任意视频进行后处理式的分析。它
的优点是它不依赖于视频监控系统，可以直接选择视频开始分析，在视频来源
和分析时机的选择上更自由。</p>
<p>在线监测是人体暴力行为检测系统提供的另一种检测方式。它旨在利用监
控视频资源，进行实时的暴力行为检测，达到即时分析并报警提示的功能。这
一功能极大地降低了人工分析实时监控视频的成本，便于管理人员进行安全监
管，提高了监管的效率。</p>
<p>为了提高检测速度和避免资源浪费，根据传入视频的总帧数进行判断，采取提示过短、一次预测或是多轮预测。</p>
<p>最后是进度安排，我们已经完成算法大部分的编写，后续会继续完成系统的开发</p>
<p>谢谢各位老师观看，请各位老师批评指正</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——Langchain与LLM集成解决方案</title>
    <url>/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/</url>
    <content><![CDATA[<h2 id="了解langchain">了解Langchain</h2>
<p>LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型
(LLM) 和聊天模型提供支持的应用程序的过程。LangChain
可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如
API 和数据库。</p>
<p>一句话概括就是：<strong>langchain
完成了对数据一个提炼、查找的完全链路。</strong>它并不能提供数据源、查找理由，只是一种方法的凝练。</p>
<p>数据源支持由用户等自行提供，因此它支持本地知识库的搭建，合理想象未来的学生课设系统将会是：金融知识系统（使用
langchain 爬取金融网站提取摘要凝练成知识）、图书简介系统（使用 langchain
对图书提取摘要进行展示）……</p>
<h2 id="安装">安装</h2>
<p>Jupyter 就是一个非常好用的 Python 语言编程工具。</p>
<p>或者说是一个 Python
编程语言、以及更多其他编程语言的，交互式集成开发环境。</p>
<p>Jupyter 的一个非常重要的优点，就是
写程序的界面，和运行程序的界面，在一起。</p>
<p>jubyter notebook的安装：<code>pip install jupyterlab</code></p>
<p>web页面的启动：<code>jupyter-lab</code></p>
<p>vscode：创建.ipynb格式的文件</p>
<hr>
<p>langchain的安装：<code>pip install langchain</code></p>
<h2 id="提供一种llm集成解决方案一份代码支持快速同时支持gpt大模型国产大模型通义千问文心一言百度千帆讯飞星火等本地开源大模型ollama">提供一种LLM集成解决方案，一份代码支持快速同时支持gpt大模型、国产大模型(通义千问、文心一言、百度千帆、讯飞星火等)、本地开源大模型(Ollama)</h2>
<p>项目地址：<a href="https://github.com/NanGePlus/LLMTest">NanGePlus/LLMTest:
为实现代码的高扩展性和兼容性，提出一套综合解决方案，支持多种大模型类型的无缝集成，包括GPT系列大模型、国内主流模型（如通义千问、智谱AI等），以及本地化部署的大模型（如qwen2.5）。</a></p>
<h3 id="前期准备">前期准备</h3>
<p>openai-api代理：<a href="https://api.wlai.vip/">云雾 API</a></p>
<p>安装One-Api</p>
<p><a href="https://github.com/songquanpeng/one-api">songquanpeng/one-api:
OpenAI 接口管理 &amp; 分发系统，支持 Azure、Anthropic Claude、Google
PaLM 2 &amp; Gemini、智谱
ChatGLM、百度文心一言、讯飞星火认知、阿里通义千问、360
智脑以及腾讯混元，可用于二次分发管理 key，仅单可执行文件，已打包好
Docker 镜像，一键部署，开箱即用. OpenAI key management &amp;
redistribution system, using a single API for all LLMs, and features an
English UI.</a></p>
<p>利用exe</p>
<p><a href="http://localhost:3000/">One API</a></p>
<p>默认账号密码：root 12345</p>
<p>创建渠道，这里以阿里通义千问为例</p>
<p>获取API-KEY：<a href="https://bailian.console.aliyun.com/?spm=5176.29619931.J__Z58Z6CX7MY__Ll8p1ZOR.1.136959fcA1q1xF&amp;accounttraceid=a01e32df30fa4776a42f6cb88a6f938dfnlu#/model-market/detail/qwen-plus">阿里云百炼</a></p>
<p><a href="https://blog.csdn.net/qq_26303031/article/details/140987551">2024年最新免费AI大模型API汇总及国内大模型使用教程（附代码）_免费大模型api-CSDN博客</a></p>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216103856131.png" alt="image-20241216103856131">
<figcaption aria-hidden="true">image-20241216103856131</figcaption>
</figure>
<hr>
<p>使用 Ollama 非常简单，只需要按照以下步骤：</p>
<ol type="1">
<li><strong>安装 Ollama</strong> ： 根据你的操作系统，从 <a href="https://ollama.com/">Ollama 官网</a>下载并安装最新版本。</li>
<li><strong>启动 Ollama</strong> ： 打开终端或命令行，输入
<code>ollama serve</code> 命令启动 Ollama 服务器。</li>
<li><strong>下载模型</strong>： 在<a href="https://ollama.com/library">模型仓库</a>找到想要的模型，然后使用
<code>ollama pull</code> 命令下载，例如
<code>ollama pull llama3:70b</code> 。</li>
<li><strong>运行模型</strong> ： 使用 <code>ollama run</code>
命令启动模型，例如 <code>ollama run llama3:70b</code> 。</li>
<li><strong>开始聊天</strong> ： 在终端中输入你的问题或指令，Ollama
会根据模型生成相应的回复。</li>
<li><strong>查看模型列表</strong> ：<code>ollama list</code></li>
</ol>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216115902772.png" alt="image-20241216115902772">
<figcaption aria-hidden="true">image-20241216115902772</figcaption>
</figure>
<h3 id="项目">项目</h3>
<p>初始化：采用pycharm+anaconda</p>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216120328229.png" alt="image-20241216120328229">
<figcaption aria-hidden="true">image-20241216120328229</figcaption>
</figure>
<p>安装依赖</p>
<p>pip install -r requirements.txt
每个软件包后面都指定了本次视频测试中固定的版本号 <strong>注意：</strong>
截止2024.10.18，langchain最新版本为0.3.3，langchain-openai最新版本为0.2.2</p>
<p>调整api，调整 utils/myLLM.py 内容</p>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216131346999.png" alt="image-20241216131346999">
<figcaption aria-hidden="true">image-20241216131346999</figcaption>
</figure>
<p>调整 llmTest.py 内容</p>
<p>LLM_TYPE = “oneapi” #
openai：调用gpt模型;oneapi：调用oneapi方案支持的模型（这里调用通义千问）</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://github.com/langchain-ai/langchain?tab=readme-ov-file">langchain-ai/langchain：🦜🔗构建上下文感知推理应用程序</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/680828606">LangChain
入门与避坑指北 - 知乎</a></p>
<p><a href="https://www.langchain.com.cn/docs/introduction/">LangChain中文网</a></p>
<p><a href="https://blog.csdn.net/franklfeng/article/details/117562667">Jupyter
是什么-CSDN博客</a></p>
<p><a href="https://vscode.github.net.cn/docs/datascience/jupyter-notebooks#_save-your-jupyter-notebook">在
Visual Studio Code 中使用 Jupyter Notebook_Vscode中文网</a></p>
<p><a href="https://cuterwrite.top/p/ollama/#:~:text=如何使用%20Ollama？%201%20安装%20Ollama：%20根据你的操作系统，从%20Ollama%20官网,ollama%20run%20llama3%3A70b%20。%205%20开始聊天：%20在终端中输入你的问题或指令，Ollama%20会根据模型生成相应的回复。">Ollama：从入门到进阶</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——初识zinc</title>
    <url>/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94zinc/</url>
    <content><![CDATA[<p>安装，注意配置环境变量 <span class="math inline">$env:ZINC_FIRST_ADMIN_USER="admin"$</span>env:ZINC_FIRST_ADMIN_PASSWORD=“admin”
..exe</p>
<p>加载示例数据，利用bash curl -L
https://github.com/zincsearch/zincsearch/releases/download/v0.1.1/olympics.ndjson.gz
-o olympics.ndjson.gz gzip -d olympics.ndjson.gz curl
http://localhost:4080/api/_bulk -i -u admin:Complexpass#123 –data-binary
“<span class="citation" data-cites="olympics.ndjson">@olympics.ndjson</span>”</p>
<p>概念 ZincSearch 是一个搜索引擎，允许您在上传到 ZincSearch
时搜索自己的数据。将其视为“Google”或“Bing”搜索，但仅用于您自己的数据。
ZincSearch 允许您索引 （json） 文档并允许进行全文搜索。</p>
<p>添加索引 使用 JSON 格式：{ “分析”： { “分析器”： { “默认”： {
“type”： “standard” } } } } { “index”: “my_index”, “settings”: {
“analysis”: { “analyzer”: { “default”: { “type”: “standard” } } } } }’
“index”: 指定你要创建的索引名称，这里是 my_index。 “settings”:
包含索引的设置。 “analysis”: 定义分析器的部分。 “analyzer”:
指定分析器的配置。 “default”: 定义默认分析器，类型为 standard。</p>
<p>索引的映射（mapping）
映射（mapping）是指在数据存储系统（如数据库或搜索引擎）中定义索引中字段的结构和属性的过程。它类似于数据库中的表结构定义
使用 JSON 格式：{ “属性”： { “内容”： { “type”： “text” } } }</p>
<p>参考文献 https://geekdaxue.co/read/ZincSearch-doc/create-update-index
https://prabhatsharma.in/blog/in-search-of-a-search-engine-beyond-elasticsearch-introducing-zinc/</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——LightRAG与GraphRAG</title>
    <url>/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/</url>
    <content><![CDATA[<h2 id="graphrag">GraphRAG</h2>
<p>最新消息是11.26凌晨，微软宣布将推出 GraphRAG
的全新迭代版本LazyGraphRAG
核心亮点是极低的使用成本，其数据索引成本仅为现有GraphRAG 的
0.1%。此外，LazyGraphRAG
引入了全新的混合数据检索方法，大幅提升了生成结果的准确性和效率。该版本将很快开源，并纳入到
GitHub GraphRAG 库中
原文链接如下:https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/</p>
<hr>
<p><strong>支持的检索方式</strong></p>
<p><strong>Naive Search</strong> Naive
模式是最简单的检索策略，它直接基于输入查询计算向量相似度，返回最接近的结果，不进行任何额外的优化或复杂处理
<strong>Local Search</strong> Local
模式只在本地上下文范围内进行检索。它聚焦于用户当前输入的特定领域或某部分数据，不会考虑全局数据
<strong>Global Search</strong> Global
模式会在整个知识库范围内进行检索，试图找到与查询最相关的信息，而不局限于当前上下文或局部区域
<strong>Hybrid Search</strong> Hybrid 模式结合了 Local 和 Global
的优势，同时考虑局部上下文和全局信息，综合结果以提高答案的相关性和覆盖范围</p>
<h2 id="anaconda">Anaconda</h2>
<p>Anaconda，中文大蟒蛇，是一个开源的Anaconda是专注于数据分析的Python发行版本，包含了conda、Python等190多个科学包及其依赖项。</p>
<p>Anaconda就是可以便捷获取包且对包能够进行管理，包括了python和很多常见的软件库和一个包管理器conda。常见的科学计算类的库都包含在里面了，使得安装比常规python安装要容易，同时对环境可以统一管理的发行版本</p>
<h3 id="为什么要安装anaconda">为什么要安装Anaconda？</h3>
<p>Anaconda对于python初学者而言及其友好，相比单独安装python主程序，选择Anaconda可以帮助省去很多麻烦，Anaconda里添加了许多常用的功能包，如果单独安装python，这些功能包则需要一条一条自行安装，在Anaconda中则不需要考虑这些，同时Anaconda还附带捆绑了两个非常好用的交互式代码编辑器（Spyder、Jupyter
notebook）。</p>
<p>简单来说，Anconda，可以理解成运输车，每当下载Anconda的时候，里面不仅包含了python，还有180多个库（武器)一同被打包下载下来。</p>
<p>下载完Anconda之后，再也不用一个个下载那些库了。</p>
<h3 id="集成开发环境搭建anacondapycharm">集成开发环境搭建Anaconda+PyCharm</h3>
<p><a href="https://www.bilibili.com/video/BV1q9HxeEEtT/?vd_source=30acb5331e4f5739ebbad50f7cc6b949">【大模型应用开发基础】集成开发环境搭建Anaconda+PyCharm_哔哩哔哩_bilibili</a></p>
<h2 id="lightrag与graphrag运行对比">LightRAG与GraphRAG运行对比</h2>
<p><a href="https://github.com/NanGePlus/LightRAGTest">NanGePlus/LightRAGTest:
LightRAG与GraphRAG在索引构建、检索测试中的耗时、模型请求次数、Token消耗金额、检索质量等方面进行对比</a></p>
<p>命令行终端中执行如下命令安装依赖包 cd LightRAG pip install -e . cd
GraphRAG pip install graphrag==0.5.0</p>
<hr>
<p><strong>测试文本</strong>
测试文本均为使用西游记白话文前九回内容，文件名为book.txt
<strong>模型配置</strong>
大模型使用OpenAI(代理方案)，Chat模型均使用gpt-4o-mini,Embedding模型均使用text-embedding-3-small
<strong>其他配置</strong> 笔记本均为MacBook
Pro2017,网速、python环境均相同</p>
<hr>
<p>LightRAG测试</p>
<p>(1)构建索引</p>
<p>打开命令行终端，执行如下指令 cd LightRAG/nangeAGICode python test.py
<strong>注意</strong>
在运行脚本之前，需要调整相关代码将如下代码块打开，检索相关的代码块注释</p>
<p>(2)逐一测试</p>
<p>执行如下指令 cd LightRAG/nangeAGICode python test.py
<strong>注意</strong>
在运行脚本之前，需要注释如下构建索引代码，取消检索相关的代码块注释</p>
<p>GraphRAG测试</p>
<p>(1)构建索引</p>
<p>打开命令行终端，执行如下指令 cd GraphRAG graphrag index –root ./</p>
<p>(2)逐一测试</p>
<p>graphrag query –root ./ –method local –query
“这个故事的核心主题是什么?” graphrag query –root ./ –method global
–query “这个故事的核心主题是什么?” graphrag query –root ./ –method drift
–query “这个故事的核心主题是什么?”</p>
<hr>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/img.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="利用neo4j可视化">利用neo4j可视化</h2>
<p><strong>测试文本</strong> 测试文本均为使用西游记白话文前九回内容
<strong>模型配置</strong>
大模型均使用OpenAI(代理方案)，Chat模型均使用gpt-4o,Embedding模型均使用text-embedding-3-small
<strong>其他配置</strong> 笔记本均为MacBook
Pro2017,网速、python环境均相同</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># gpt大模型相关配置根据自己的实际情况进行调整</span><br><span class="line">OPENAI_API_BASE = &quot;https://api.wlai.vip/v1&quot;</span><br><span class="line">OPENAI_CHAT_API_KEY = &quot;sk-Tuza9B8WYo1vkBAAmmLeQjuOl1VTP9Dd0nuKxqnLOaJJMZZd&quot;</span><br><span class="line">OPENAI_CHAT_MODEL = &quot;gpt-4o&quot;</span><br><span class="line">OPENAI_EMBEDDING_MODEL = &quot;text-embedding-3-small&quot;</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="lightrag构建索引测试">LightRAG构建索引测试</h3>
<h4 id="安装textract依赖包">(1)安装textract依赖包</h4>
<p>通过指令 pip install textract 安装时会报错，报错的原因是
其元数据文件中使用了不再被支持的版本约束符号（&lt;=0.29.*），而当前 pip
和 setuptools 不再接受这种格式
解决方案:下载依赖包源码，修改相应参数后本地进行安装
https://pypi.org/project/textract/1.6.5/#description cd textract-1.6.5
pip install .</p>
<h4 id="创建neo4j数据库实例">(2) 创建neo4j数据库实例</h4>
<p>推荐使用云服务进行测试，链接地址如下:
https://console-preview.neo4j.io/tools/query
注册登录成功，直接新建实例即可</p>
<p>也可以用本地neo4j</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据库连接相关参数配置</span></span><br><span class="line">NEO4J_URI=<span class="string">&quot;bolt://localhost:7687&quot;</span></span><br><span class="line">NEO4J_USERNAME=<span class="string">&quot;neo4j&quot;</span></span><br><span class="line">NEO4J_PASSWORD=<span class="string">&quot;zxj03051218&quot;</span></span><br><span class="line">NEO4J_DATABASE=<span class="string">&quot;neo4j&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="增量索引构建及知识图谱可视化测试">(3)增量索引构建及知识图谱可视化测试</h4>
<p>运行如下指令进行索引构建 cd LightRAG/nangeAGICode1201 python
insertTest.py python queryTest.py
每一次构建完成，先清除数据库中的数据再运行如下指令进行可视化
在运行之前需要根据自己的实际情况进行参数的调整 python
graph_visual_with_html.py</p>
<p>python graph_visual_with_neo4j.py
<strong>在数据库中进行查询测试</strong> MATCH (n:<code>PERSON</code>)
WHERE n.displayName CONTAINS ‘唐僧’ RETURN n LIMIT 25;</p>
<p>MATCH (n:<code>PERSON</code>) WHERE n.displayName CONTAINS ‘八戒’
RETURN n LIMIT 25;</p>
<p>MATCH (n:<code>PERSON</code>) WHERE n.displayName CONTAINS ‘沙和尚’
RETURN n LIMIT 25;</p>
<p><strong>清除数据</strong> MATCH (n) CALL { WITH n DETACH DELETE n }
IN TRANSACTIONS OF 25000 ROWS;</p>
<p>MATCH (n) OPTIONAL MATCH (n)-[r]-() DELETE n,r</p>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/image-20241221160947727.png" alt="image-20241221160947727">
<figcaption aria-hidden="true">image-20241221160947727</figcaption>
</figure>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/image-20241221160843951.png" alt="image-20241221160843951">
<figcaption aria-hidden="true">image-20241221160843951</figcaption>
</figure>
<h3 id="lightrag和graphrag生成的知识图谱对比">LightRAG和GraphRAG生成的知识图谱对比</h3>
<p>运行如下指令将GraphRAG生成的知识图谱进行可视化展示 cd GraphRAG/utils
python graph_visual_with_neo4j.py
在运行脚本前根据自己的实际情况进行调整,修改文件所在路径为存储增量数据的文件路径
GRAPHRAG_FOLDER=“/Users/janetjiang/Desktop/agi_code/LightRAGTest/GraphRAG/output”
<strong>在数据库中进行查询测试</strong> MATCH
(n:<code>__Entity__</code>) WHERE n.name CONTAINS ‘唐僧’ RETURN n LIMIT
25;</p>
<p>MATCH (n:<code>__Entity__</code>) WHERE n.name CONTAINS ‘八戒’ RETURN
n LIMIT 25;</p>
<p>MATCH (n:<code>__Entity__</code>) WHERE n.name CONTAINS ‘沙和尚’
RETURN n LIMIT 25;</p>
<p><strong>清除数据</strong> MATCH (n) CALL { WITH n DETACH DELETE n }
IN TRANSACTIONS OF 25000 ROWS;</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1CmzEYcEnS/?spm_id_from=333.1007.tianma.1-1-1.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">LightRAG与GraphRAG对比评测，从索引构建、本地检索、全局检索、混合检索等维度对请求大模型次数、Token消耗、金额消耗、检索质量等方面进行全面对比_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/weixin_56197703/article/details/124630222">还是搞不懂Anaconda是什么?读这一篇文章就够了-CSDN博客</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——Neo4j</title>
    <url>/2024/12/06/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94Neo4j/</url>
    <content><![CDATA[<h2 id="什么是-neo4j">什么是 Neo4j？</h2>
<p><strong>Neo4j</strong> 是一个开源的<strong>图形数据库</strong>，由
Neo4j 公司开发和维护。作为图数据库的代表，Neo4j
使用图理论中的节点和边（关系）来表示和存储数据，相较于传统的关系型数据库（如
MySQL、PostgreSQL）和其他 NoSQL 数据库（如文档型、键值型数据库），Neo4j
在处<strong>理复杂关系和连接性强的数据方面</strong>具有显著优势。</p>
<h3 id="主要特点">主要特点：</h3>
<ul>
<li><strong>图模型</strong>：使用节点、关系和属性来建模数据，直观地反映实体及其之间的关联。</li>
<li><strong>Cypher
查询语言</strong>：专为图数据库设计的声明式查询语言，语法简洁，易于表达复杂的图形查询。</li>
<li><strong>高性能</strong>：优化的存储和索引机制，能够高效地处理大规模图数据和复杂查询。</li>
<li><strong>ACID
事务支持</strong>：保证数据的一致性和可靠性，适用于需要强事务保障的应用场景。</li>
</ul>
<h2 id="为什么需要-neo4j">为什么需要 Neo4j？</h2>
<p>在许多应用场景中，<strong>数据之间存在复杂的关系和连接性</strong>。传统的关系型数据库在处理多层级的关联查询时，往往需要大量的联接操作（JOIN），这会导致查询性能下降，尤其是在数据规模庞大时。而
Neo4j
通过图模型天然适合表示和处理这种高度连接的数据，能够更高效地执行复杂的关系查询。</p>
<h3 id="主要需求原因">主要需求原因：</h3>
<ol type="1">
<li><strong>复杂关系处理</strong>：需要频繁进行多级关联查询，如社交网络、推荐系统等。</li>
<li><strong>灵活的数据模型</strong>：数据结构可能随时间变化，图数据库提供了更大的灵活性。</li>
<li><strong>性能需求</strong>：需要在大规模数据集上执行快速的关系查询和遍历操作。</li>
<li><strong>实时性</strong>：需要实时分析和处理数据关系，如欺诈检测、网络安全等。</li>
</ol>
<figure>
<img src="/2024/12/06/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94Neo4j/ed250b8ea580015278be07a9233448c2.png" alt="ed250b8ea580015278be07a9233448c2">
<figcaption aria-hidden="true">ed250b8ea580015278be07a9233448c2</figcaption>
</figure>
<h2 id="graphrag的理解">GraphRAG的理解</h2>
<p><strong>GraphRAG=Graph(知识图谱)+RAG技术</strong></p>
<p><strong>GraphRAG</strong>
是一种结合了<strong>图结构</strong>和<strong>检索增强生成（RAG）</strong>的方法，旨在增强语言模型（如大规模预训练的变换器模型）的推理能力和信息检索能力。这个方法通常用于处理复杂的推理任务，尤其是当涉及到大规模知识库或图形数据时，GraphRAG可以通过图的结构来有效地组织信息，从而提高模型在生成和推理时的效率和准确性。</p>
<p><strong>图结构（Graph）</strong>：</p>
<ul>
<li><strong>图</strong>通常用于表示节点之间的关系和依赖，在处理复杂知识结构时非常有用。在GraphRAG中，图结构帮助捕捉信息之间的关系，能够有效地组织和链接不同的知识点，尤其是在涉及多个实体和关系的任务中。</li>
</ul>
<p><strong>检索增强生成（RAG）</strong>：</p>
<ul>
<li>RAG
是一种将信息检索与生成模型结合的框架。它的核心思想是，模型在生成答案时不仅仅依赖于其预训练时获得的知识，还会从一个外部数据库或文档库中检索相关的信息来增强回答的准确性和上下文适应性。</li>
</ul>
<h2 id="neo4j的安装">Neo4j的安装</h2>
<ol type="1">
<li>官网下载社区版</li>
<li>安装JDK，java11</li>
<li>配置环境变量</li>
<li>启动Neo4j</li>
</ol>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">常用命令</span><br><span class="line"># 启动服务</span><br><span class="line">neo4j(.bat) start</span><br><span class="line"># 重启服务</span><br><span class="line">neo4j(.bat) restart</span><br><span class="line"># 停止服务</span><br><span class="line">neo4j(.bat) stop</span><br><span class="line"># 控制台模式启动</span><br><span class="line">neo4j(.bat) console</span><br></pre></td></tr></table></figure>
</blockquote>
<ol start="5" type="1">
<li>进入到 http://localhost:7474</li>
</ol>
<p>账号密码 neo4j zxj03051218</p>
<p>第一次进入前安装neo4j 的服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">neo4j install-service</span><br></pre></td></tr></table></figure>
<p>查看版本 neo4j –version</p>
<h2 id="apoc用处">apoc用处</h2>
<p>数据导入和导出：使用APOC插件可以轻松导入和导出不同格式的数据到Neo4j图数据库。您可以将数据从关系型数据库、CSV文件、JSON等转换为图形数据，并相反地，将图形数据导出到其他格式。
图形算法：APOC提供了许多有用的图形算法，如PageRank、社区发现（例如Louvain算法），路径分析等。这些算法可以帮助您发现数据之间的关联性和模式，并从中提取有价值的信息。
数据清洗和转换：APOC提供了丰富的过程和函数，用于数据清洗和转换。您可以使用它来处理字符串、时间、密码学等方面的数据，并进行必要的清洗和格式化。
可视化：APOC支持将图形数据转换为其他可视化工具所需的格式，例如Gephi、D3.js等。这使得您可以将您的图形数据以更直观的方式呈现，进一步探索和交流。
地理空间分析：APOC提供了与地理空间数据相关的功能，如计算两个地点之间的距离、查找附近的地点等。这对于在地理空间上分析和查询数据特别有用。</p>
<p>我应该是主要用到了数据导入和导出的功能，因为要将构建好的所以传到本地neo4j上</p>
<h2 id="apoc插件安装">apoc插件安装</h2>
<p><a href="https://blog.csdn.net/shdabai/article/details/132880323">知识图谱基本工具Neo4j使用笔记
五 ：APOC插件安装及简单应用_neo4j apoc-CSDN博客</a></p>
<p>版本 neo4j 4.4.39</p>
<p>APOC插件下载：apoc-4.4.0.9-all.jar（注意apoc要与neo4j版本对应）</p>
<p><a href="https://github.com/neo4j/apoc/releases?page=2">Releases ·
neo4j/apoc</a></p>
<p>将下载的 <code>apoc-4.4.0.9-all.jar</code>
直接复制到neo4j/plugins文件夹</p>
<p>修改APOC的配置文件</p>
<p>打开配置文件将，这一下内容的注释去掉</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dbms.security.procedures.unrestricted=apoc.*</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://segmentfault.com/a/1190000037690548#item-0-2">java -
我的Neo4j探索之旅 - 初识Neo4j（一） - 个人文章 - SegmentFault
思否</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>算法期末复习</title>
    <url>/2025/06/12/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/%E7%AE%97%E6%B3%95%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="贪心问题">贪心问题</h3>
<h4 id="找零钱">找零钱</h4>
<p>用最少数量的钱币凑出目标金额 m 元。</p>
<p><strong>核心思想</strong> ：
每次选择<strong>不超过剩余金额的最大面值</strong>
，直到凑够目标金额。</p>
<p><strong>步骤：</strong></p>
<ol type="1">
<li>将钱币面值按从大到小排序。</li>
<li>对于当前剩余金额，不断减去最大可用面值，直到金额为 0。</li>
</ol>
<p><strong>贪心策略的适用性</strong></p>
<p><strong>仅当钱币面值满足以下条件时有效</strong> ：</p>
<ul>
<li>面值序列中每个元素都是前一个元素的因数（如
<code>1, 2, 5, 10</code>）。</li>
<li>否则，贪心可能失败（例如面值 <code>[1, 3, 4]</code>，目标
<code>6</code>：贪心选 <code>4+1+1</code> 需 3 枚，而最优解是
<code>3+3</code> 需 2 枚）。</li>
</ul>
<p><strong>代码问题分析</strong></p>
<p>用户提供的代码是一个基于贪心策略的找零钱实现，但在<strong>硬币面值不满足贪心条件</strong>时可能无法得到最优解。以下是具体分析：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">findMinCoins</span>(<span class="params">coins, amount</span>):</span><br><span class="line">    coins.sort(reverse=<span class="literal">True</span>)  <span class="comment"># 降序排序</span></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(coins)):</span><br><span class="line">        <span class="keyword">while</span> amount &gt;= coins[i]:</span><br><span class="line">            res.append(coins[i])</span><br><span class="line">            amount -= coins[i]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">coins = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line">amount = <span class="number">1136</span></span><br><span class="line">out = findMinCoins(coins, amount)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;钱币数量为<span class="subst">&#123;<span class="built_in">len</span>(out)&#125;</span>.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>问题点：</strong></p>
<ol type="1">
<li><p><strong>贪心策略的局限性</strong><br>
仅当硬币面值满足 <strong>每种面值是前一种面值的因数</strong>（如
<code>[1, 2, 5, 10, 50, 100]</code>）时，贪心算法才能保证最优解。若面值不满足此条件（如
<code>[1, 3, 4]</code>），则可能失败。</p></li>
<li><p><strong>未处理特殊情况</strong></p>
<ul>
<li>若 <code>amount</code> 无法被硬币组合凑出（如硬币为
<code>[2, 5]</code>，目标
<code>3</code>），代码会返回非最优解或死循环。</li>
</ul></li>
</ol>
<p><strong>改进方案</strong></p>
<p>适用于任意硬币面值，确保最优解： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">min_coins_dp</span>(<span class="params">coins, amount</span>):</span><br><span class="line">    dp = [<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)] * (amount + <span class="number">1</span>)</span><br><span class="line">    dp[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, amount + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> coin <span class="keyword">in</span> coins:</span><br><span class="line">            <span class="keyword">if</span> a &gt;= coin <span class="keyword">and</span> dp[a - coin] + <span class="number">1</span> &lt; dp[a]:</span><br><span class="line">                dp[a] = dp[a - coin] + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dp[amount] <span class="keyword">if</span> dp[amount] != <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">coins = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line">amount = <span class="number">1136</span></span><br><span class="line"><span class="built_in">print</span>(min_coins_dp(coins, amount))  <span class="comment"># 输出 16</span></span><br></pre></td></tr></table></figure></p>
<h4 id="最优装载问题">最优装载问题</h4>
<p>🧮 问题描述</p>
<p>给定一个集装箱重量列表 <code>weights</code> 和轮船的最大载重
<code>W</code>，目标是
<strong>尽可能多地装载集装箱</strong>（不考虑体积限制）。</p>
<p>✅ 算法思路</p>
<ol type="1">
<li><strong>排序</strong>：将所有集装箱按重量从小到大排序。</li>
<li><strong>贪心装载</strong>：依次尝试装载每个集装箱，若当前总重量加上该集装箱的重量不超过
<code>W</code>，则装载；否则停止。</li>
<li><strong>返回结果</strong>：返回成功装载的集装箱数量。</li>
</ol>
<p>🧾 Python 实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">max_loaded_containers</span>(<span class="params">weights, W</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    返回在总载重 W 下，最多可以装载的集装箱数量。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    weights (list of int/float): 集装箱重量列表</span></span><br><span class="line"><span class="string">    W (int/float): 轮船的最大载重</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    int: 最多可以装载的集装箱数量</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 按重量从小到大排序</span></span><br><span class="line">    weights.sort()</span><br><span class="line">    </span><br><span class="line">    total_weight = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> weight <span class="keyword">in</span> weights:</span><br><span class="line">        <span class="keyword">if</span> total_weight + weight &lt;= W:</span><br><span class="line">            total_weight += weight</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    weights = [<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">    W = <span class="number">10</span></span><br><span class="line">    result = max_loaded_containers(weights, W)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;最多可以装载 <span class="subst">&#123;result&#125;</span> 个集装箱&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="活动选择问题最大相容活动子集">活动选择问题（最大相容活动子集）</h4>
<p>📌 问题描述</p>
<p>给定 $ n $ 个活动的集合 $ C = {1, 2, …, n} $，每个活动 $ i $
都有起始时间 $ s_i $ 和结束时间 $ f_i $（满足 $ s_i &lt; f_i
$）。要求选择一个<strong>最大相容活动子集</strong>，使得被选中的活动之间<strong>时间互不重叠</strong>。</p>
<p>两个活动 $ i $ 和 $ j $ 相容的条件为： <span class="math display"><em>s</em><sub><em>i</em></sub> ≥ <em>f</em><sub><em>j</em></sub>  或  <em>s</em><sub><em>j</em></sub> ≥ <em>f</em><sub><em>i</em></sub></span></p>
<p>✅ 贪心策略与正确性</p>
<p><strong>贪心策略</strong>：<br>
1. <strong>按活动结束时间 $ f_i $ 从小到大排序</strong>。 2.
<strong>依次选择结束最早的活动</strong>，并跳过与其冲突的所有活动。</p>
<p><strong>正确性证明（归纳法）</strong>：</p>
<ul>
<li><strong>基础情况</strong>：当只有一项活动时，显然选择它是最优的。</li>
<li><strong>归纳假设</strong>：对于前 $ k $
个活动，该策略能得到最大相容子集。</li>
<li><strong>归纳步骤</strong>：考虑第 $ k+1 $
个活动。若选择结束最早的活动 $ A $，则剩下的可用时间区间为 $ [f_A, +)
$，此时在该区间内继续应用该策略，仍能得到最大子集。若不选 $ A $
而选其他活动，则剩余时间更少，无法容纳更多活动。</li>
</ul>
<p>🧾 Python 实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">max_compatible_activities</span>(<span class="params">activities</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    返回最大相容活动子集的数量及具体活动列表。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    activities (list of tuples): 每个元素为 (s_i, f_i)，表示活动的起始和结束时间</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    tuple: (最大活动数量, 相容活动列表)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 按结束时间从小到大排序</span></span><br><span class="line">    sorted_activities = <span class="built_in">sorted</span>(activities, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    selected = []</span><br><span class="line">    last_end = -<span class="number">1</span>  <span class="comment"># 上一个选中的活动的结束时间</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> activity <span class="keyword">in</span> sorted_activities:</span><br><span class="line">        s, f = activity</span><br><span class="line">        <span class="keyword">if</span> s &gt;= last_end:</span><br><span class="line">            selected.append(activity)</span><br><span class="line">            last_end = f</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(selected), selected</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    activities = [</span><br><span class="line">        (<span class="number">1</span>, <span class="number">4</span>), (<span class="number">3</span>, <span class="number">5</span>), (<span class="number">0</span>, <span class="number">6</span>), (<span class="number">5</span>, <span class="number">7</span>), </span><br><span class="line">        (<span class="number">3</span>, <span class="number">8</span>), (<span class="number">5</span>, <span class="number">9</span>), (<span class="number">6</span>, <span class="number">10</span>), (<span class="number">8</span>, <span class="number">11</span>)</span><br><span class="line">    ]</span><br><span class="line">    count, selected = max_compatible_activities(activities)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;最大相容活动数: <span class="subst">&#123;count&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;所选活动:&quot;</span>, selected)</span><br></pre></td></tr></table></figure>
<h4 id="使用堆优化的-dijkstra-算法python-实现">使用堆优化的 Dijkstra
算法（Python 实现）</h4>
<p>🧠 <strong>核心思想</strong></p>
<ul>
<li>使用<strong>最小堆</strong>（优先队列）高效选择当前距离最小的节点，避免暴力遍历。</li>
<li>每次从堆中取出当前最短路径的节点，进行<strong>松弛操作</strong>（Relaxation）。</li>
<li>若发现堆中存在过时的路径记录，则跳过（因为已找到更优路径）。</li>
</ul>
<p>📦 <strong>图的表示</strong></p>
<p>使用邻接表（字典嵌套列表）： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">graph = &#123;</span><br><span class="line">    <span class="string">&#x27;A&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">4</span>)],</span><br><span class="line">    <span class="string">&#x27;B&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">5</span>)],</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">1</span>)],</span><br><span class="line">    <span class="string">&#x27;D&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">1</span>)]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>🧾 <strong>Python 代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dijkstra_with_heap</span>(<span class="params">graph, start</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用堆优化的 Dijkstra 算法求单源最短路径。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    graph (dict): 邻接表形式的图，格式为 &#123;节点: [(邻接节点, 权重), ...]&#125;</span></span><br><span class="line"><span class="string">    start (str/int): 起始节点</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    dict: 从起始节点到所有节点的最短路径长度</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 初始化距离字典，所有节点初始距离为无穷大</span></span><br><span class="line">    distances = &#123;node: <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">for</span> node <span class="keyword">in</span> graph&#125;</span><br><span class="line">    distances[start] = <span class="number">0</span>  <span class="comment"># 起始节点到自身的距离为 0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 优先队列（最小堆），存储 (距离, 节点)</span></span><br><span class="line">    heap = [(<span class="number">0</span>, start)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> heap:</span><br><span class="line">        current_distance, current_node = heapq.heappop(heap)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果当前弹出的距离大于记录的距离，说明该节点已被处理过，跳过</span></span><br><span class="line">        <span class="keyword">if</span> current_distance &gt; distances[current_node]:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历当前节点的所有邻接边</span></span><br><span class="line">        <span class="keyword">for</span> neighbor, weight <span class="keyword">in</span> graph[current_node]:</span><br><span class="line">            distance = current_distance + weight</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果找到更短路径，更新距离并推入堆</span></span><br><span class="line">            <span class="keyword">if</span> distance &lt; distances[neighbor]:</span><br><span class="line">                distances[neighbor] = distance</span><br><span class="line">                heapq.heappush(heap, (distance, neighbor))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> distances</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    graph = &#123;</span><br><span class="line">        <span class="string">&#x27;A&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">4</span>)],</span><br><span class="line">        <span class="string">&#x27;B&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">5</span>)],</span><br><span class="line">        <span class="string">&#x27;C&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">1</span>)],</span><br><span class="line">        <span class="string">&#x27;D&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">1</span>)]</span><br><span class="line">    &#125;</span><br><span class="line">    start_node = <span class="string">&#x27;A&#x27;</span></span><br><span class="line">    shortest_paths = dijkstra_with_heap(graph, start_node)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;从节点 <span class="subst">&#123;start_node&#125;</span> 出发的最短路径：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> node, dist <span class="keyword">in</span> shortest_paths.items():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;start_node&#125;</span> → <span class="subst">&#123;node&#125;</span> : <span class="subst">&#123;dist&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="哈夫曼编码"><strong>哈夫曼编码</strong></h4>
<p><strong>2. 构建哈夫曼树的步骤</strong></p>
<p><strong>步骤 1：统计字符频率</strong></p>
<p>假设输入字符串为
<code>"BCCABBDDAECCBAAAEC"</code>，统计每个字符的出现次数：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A: 6, B: 4, C: 5, D: 2, E: 1</span><br></pre></td></tr></table></figure></p>
<p><strong>步骤 2：创建最小堆（优先队列）</strong></p>
<ul>
<li>将每个字符及其频率构建成节点，并按频率升序排列。</li>
<li>初始堆：<code>[E(1), D(2), B(4), C(5), A(6)]</code></li>
</ul>
<p><strong>步骤 3：合并节点，构建哈夫曼树</strong></p>
<ol type="1">
<li>取出两个频率最小的节点 <code>E(1)</code> 和
<code>D(2)</code>，合并为新节点 <code>ED(3)</code>。</li>
<li>将新节点插入堆：<code>[B(4), C(5), ED(3), A(6)]</code> → 重新排序为
<code>[ED(3), B(4), C(5), A(6)]</code></li>
<li>重复上述步骤，直到堆中只剩一个根节点（哈夫曼树）。</li>
</ol>
<p>最终树结构示意图（频率越小越靠近叶子）： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">        (18)</span><br><span class="line">       /    \</span><br><span class="line">     (8)    A(6)</span><br><span class="line">    /   \</span><br><span class="line"> (4)   (4)</span><br><span class="line">B     C(5)</span><br></pre></td></tr></table></figure></p>
<p><strong>步骤 4：生成哈夫曼编码表</strong></p>
<p>从根节点出发，左子树标记为 <code>0</code>，右子树标记为
<code>1</code>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A: 11</span><br><span class="line">B: 00</span><br><span class="line">C: 01</span><br><span class="line">D: 100</span><br><span class="line">E: 101</span><br></pre></td></tr></table></figure></p>
<p><strong>4. Python 实现哈夫曼编码</strong></p>
<p>以下代码展示如何用 Python 构建哈夫曼树并生成编码表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HuffmanNode</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, char, freq</span>):</span><br><span class="line">        <span class="variable language_">self</span>.char = char</span><br><span class="line">        <span class="variable language_">self</span>.freq = freq</span><br><span class="line">        <span class="variable language_">self</span>.left = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.right = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__lt__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.freq &lt; other.freq</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_huffman_tree</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="comment"># 统计频率</span></span><br><span class="line">    frequency = Counter(text)</span><br><span class="line">    <span class="comment"># 创建最小堆</span></span><br><span class="line">    heap = [HuffmanNode(char, freq) <span class="keyword">for</span> char, freq <span class="keyword">in</span> frequency.items()]</span><br><span class="line">    heapq.heapify(heap)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 合并节点</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(heap) &gt; <span class="number">1</span>:</span><br><span class="line">        left = heapq.heappop(heap)</span><br><span class="line">        right = heapq.heappop(heap)</span><br><span class="line">        merged = HuffmanNode(<span class="literal">None</span>, left.freq + right.freq)</span><br><span class="line">        merged.left = left</span><br><span class="line">        merged.right = right</span><br><span class="line">        heapq.heappush(heap, merged)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> heapq.heappop(heap) <span class="keyword">if</span> heap <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_huffman_codes</span>(<span class="params">root</span>):</span><br><span class="line">    codes = &#123;&#125;</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">node, current_code</span>):</span><br><span class="line">        <span class="keyword">if</span> node:</span><br><span class="line">            <span class="keyword">if</span> node.char <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                codes[node.char] = current_code</span><br><span class="line">            dfs(node.left, current_code + <span class="string">&quot;0&quot;</span>)</span><br><span class="line">            dfs(node.right, current_code + <span class="string">&quot;1&quot;</span>)</span><br><span class="line">    dfs(root, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> codes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">text = <span class="string">&quot;BCCABBDDAECCBAAAEC&quot;</span></span><br><span class="line">root = build_huffman_tree(text)</span><br><span class="line">codes = build_huffman_codes(root)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;哈夫曼编码表:&quot;</span>, codes)</span><br></pre></td></tr></table></figure>
<p><strong>输出示例：</strong> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">哈夫曼编码表: &#123;&#x27;B&#x27;: &#x27;0&#x27;, &#x27;C&#x27;: &#x27;10&#x27;, &#x27;A&#x27;: &#x27;11&#x27;, &#x27;D&#x27;: &#x27;110&#x27;, &#x27;E&#x27;: &#x27;111&#x27;&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="prim">prim</h4>
<p>以下是 <strong>朴素 Prim 算法</strong>
的实现与详解，适用于稠密图（如邻接矩阵存储的图）：</p>
<p><strong>Prim 算法核心思想</strong></p>
<ol type="1">
<li>从任意顶点开始（如 <code>start=0</code>）。</li>
<li>维护一个集合 <code>selected</code>，记录已加入生成树的顶点。</li>
<li>每次从未选顶点中选择到当前生成树的最小权重边的顶点。</li>
<li>重复步骤 3，直到所有顶点加入生成树。</li>
</ol>
<p>时间复杂度：<strong>O(V²)</strong>，其中 V 是顶点数。</p>
<p><strong>Python 实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prim</span>(<span class="params">graph, start=<span class="number">0</span></span>):</span><br><span class="line">    V = <span class="built_in">len</span>(graph)  <span class="comment"># 顶点数量</span></span><br><span class="line">    selected = [<span class="literal">False</span>] * V  <span class="comment"># 标记顶点是否已加入生成树</span></span><br><span class="line">    key = [sys.maxsize] * V  <span class="comment"># 记录各顶点到生成树的最小权重</span></span><br><span class="line">    parent = [-<span class="number">1</span>] * V         <span class="comment"># 记录最小生成树的父节点</span></span><br><span class="line"></span><br><span class="line">    key[start] = <span class="number">0</span>  <span class="comment"># 起始顶点的权值设为0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(V):</span><br><span class="line">        <span class="comment"># 找到当前未选顶点中 key 最小的顶点 u</span></span><br><span class="line">        min_key = sys.maxsize</span><br><span class="line">        u = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(V):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> selected[v] <span class="keyword">and</span> key[v] &lt; min_key:</span><br><span class="line">                min_key = key[v]</span><br><span class="line">                u = v</span><br><span class="line">        <span class="keyword">if</span> u == -<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span>  <span class="comment"># 无连通顶点，生成树结束</span></span><br><span class="line">        </span><br><span class="line">        selected[u] = <span class="literal">True</span>  <span class="comment"># 将 u 加入生成树</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新 u 的所有邻接顶点的 key 值</span></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(V):</span><br><span class="line">            <span class="keyword">if</span> graph[u][v] &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> selected[v] <span class="keyword">and</span> graph[u][v] &lt; key[v]:</span><br><span class="line">                key[v] = graph[u][v]</span><br><span class="line">                parent[v] = u  <span class="comment"># 记录 v 的父节点为 u</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> key, parent</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：邻接矩阵表示的图</span></span><br><span class="line">graph = [</span><br><span class="line">    [<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">5</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>],</span><br><span class="line">    [<span class="number">6</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">0</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">key, parent = prim(graph)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最小生成树的总权重:&quot;</span>, <span class="built_in">sum</span>(key))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;父节点数组:&quot;</span>, parent)</span><br></pre></td></tr></table></figure>
<h4 id="kruskal">kruskal</h4>
<p><strong>2. Kruskal 算法的核心思想</strong></p>
<ol type="1">
<li><strong>按权重从小到大排序所有边</strong>。</li>
<li><strong>依次选择边</strong>：
<ul>
<li>如果这条边的两个顶点不在同一个连通分量中（即不形成环），则将这条边加入生成树。</li>
<li>否则跳过这条边。</li>
</ul></li>
<li><strong>重复步骤2，直到生成树中有 <code>V-1</code>
条边</strong>（<code>V</code> 是顶点数）。</li>
</ol>
<p><strong>6. Python 实现示例</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UnionFind</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size</span>):</span><br><span class="line">        <span class="variable language_">self</span>.parent = <span class="built_in">list</span>(<span class="built_in">range</span>(size))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.parent[x] != x:</span><br><span class="line">            <span class="variable language_">self</span>.parent[x] = <span class="variable language_">self</span>.find(<span class="variable language_">self</span>.parent[x])  <span class="comment"># 路径压缩</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.parent[x]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        rootX = <span class="variable language_">self</span>.find(x)</span><br><span class="line">        rootY = <span class="variable language_">self</span>.find(y)</span><br><span class="line">        <span class="keyword">if</span> rootX == rootY:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span>  <span class="comment"># 已在同一个集合</span></span><br><span class="line">        <span class="variable language_">self</span>.parent[rootY] = rootX  <span class="comment"># 合并</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kruskal</span>(<span class="params">n, edges</span>):</span><br><span class="line">    <span class="comment"># edges: [(权重, u, v), ...]</span></span><br><span class="line">    edges.sort()</span><br><span class="line">    uf = UnionFind(n)</span><br><span class="line">    mst = []</span><br><span class="line">    cost = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> weight, u, v <span class="keyword">in</span> edges:</span><br><span class="line">        <span class="keyword">if</span> uf.union(u, v):</span><br><span class="line">            mst.append((u, v))</span><br><span class="line">            cost += weight</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(mst) == n - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">break</span>  <span class="comment"># 已选够 n-1 条边</span></span><br><span class="line">    <span class="keyword">return</span> mst, cost</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">n = <span class="number">5</span>  <span class="comment"># 顶点数（0~4）</span></span><br><span class="line">edges = [</span><br><span class="line">    (<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>),  <span class="comment"># A(0)-B(1)</span></span><br><span class="line">    (<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>),  <span class="comment"># B(1)-C(2)</span></span><br><span class="line">    (<span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>),  <span class="comment"># C(2)-D(3)</span></span><br><span class="line">    (<span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>),  <span class="comment"># D(3)-E(4)</span></span><br><span class="line">    (<span class="number">5</span>, <span class="number">0</span>, <span class="number">4</span>),  <span class="comment"># A(0)-E(4)</span></span><br><span class="line">    (<span class="number">6</span>, <span class="number">1</span>, <span class="number">3</span>)   <span class="comment"># B(1)-D(3)</span></span><br><span class="line">]</span><br><span class="line">mst, total = kruskal(n, edges)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MST 边：&quot;</span>, mst)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;总权重：&quot;</span>, total)</span><br></pre></td></tr></table></figure>
<h3 id="动态规划">动态规划</h3>
<h4 id="完全背包">完全背包</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def unbounded_knapsack_2d(weights, values, capacity):</span><br><span class="line">    n = len(weights)</span><br><span class="line">    dp = [[0] * (capacity + 1) for _ in range(n + 1)]</span><br><span class="line"></span><br><span class="line">    for i in range(1, n + 1):</span><br><span class="line">        for j in range(1, capacity + 1):</span><br><span class="line">            if weights[i-1] &lt;= j:</span><br><span class="line">                dp[i][j] = max(</span><br><span class="line">                    dp[i-1][j],</span><br><span class="line">                    dp[i][j - weights[i-1]] + values[i-1]</span><br><span class="line">                )</span><br><span class="line">            else:</span><br><span class="line">                dp[i][j] = dp[i-1][j]</span><br><span class="line">    </span><br><span class="line">    return dp[n][capacity]</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">weights = [1, 2, 3]</span><br><span class="line">values = [15, 20, 50]</span><br><span class="line">capacity = 5</span><br><span class="line">print(unbounded_knapsack_2d(weights, values, capacity))  # 输出 80</span><br></pre></td></tr></table></figure>
<h4 id="最优二叉搜索树">最优二叉搜索树</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def optimal_bst(p, q, n):</span><br><span class="line">    # 初始化 dp 和 w 数组（大小为 (n+2) x (n+2)，避免越界）</span><br><span class="line">    dp = [[0] * (n+2) for _ in range(n+2)]</span><br><span class="line">    w = [[0] * (n+2) for _ in range(n+2)]</span><br><span class="line">    root = [[0] * (n+2) for _ in range(n+2)]</span><br><span class="line"></span><br><span class="line">    # 初始化虚拟键的权重</span><br><span class="line">    for i in range(n+1):</span><br><span class="line">        w[i][i] = q[i]</span><br><span class="line">    </span><br><span class="line">    # 填表顺序：链长从 1 到 n</span><br><span class="line">    for l in range(1, n+1):  # l 为关键字数量</span><br><span class="line">        for i in range(n - l + 1):</span><br><span class="line">            j = i + l</span><br><span class="line">            w[i][j] = w[i][j-1] + p[j] + q[j]</span><br><span class="line">            dp[i][j] = float(&#x27;inf&#x27;)</span><br><span class="line">            # 枚举根节点 r（i &lt; r ≤ j）</span><br><span class="line">            for r in range(i+1, j+1):</span><br><span class="line">                cost = dp[i][r-1] + dp[r][j]</span><br><span class="line">                if cost &lt; dp[i][j]:</span><br><span class="line">                    dp[i][j] = cost</span><br><span class="line">                    root[i][j] = r</span><br><span class="line">    </span><br><span class="line">    return dp[0][n], root</span><br><span class="line"></span><br><span class="line"># 示例输入</span><br><span class="line">p = [0, 0.15, 0.1, 0.05]  # 关键字概率（从 k₁ 开始）</span><br><span class="line">q = [0.05, 0.1, 0.05, 0.05]  # 虚拟键概率（从 d₀ 开始）</span><br><span class="line">n = 3  # 关键字数量</span><br><span class="line">min_cost, root = optimal_bst(p, q, n)</span><br><span class="line">print(&quot;最小期望搜索代价:&quot;, min_cost)</span><br></pre></td></tr></table></figure>
<h3 id="回溯法">回溯法</h3>
<h4 id="八皇后">八皇后</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">https://leetcode.cn/problems/n-queens/</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">n=4</span><br><span class="line">ans=[]</span><br><span class="line">path=[]</span><br><span class="line">onpath=[False]*n#记录哪一列有皇后</span><br><span class="line">diag1=[False]*(2*n-1)#记录主对角线是否有皇后</span><br><span class="line">diag2=[False]*(2*n-1)#记录副对角线是否有皇后</span><br><span class="line">def dfs(row,path:list):</span><br><span class="line">    if row==n:</span><br><span class="line">        #print(path)</span><br><span class="line">        chess=[]</span><br><span class="line">        # 生成棋盘</span><br><span class="line">        for i in range(n):</span><br><span class="line">            chess.append(&quot;.&quot;*path[i]+&quot;Q&quot;+&quot;.&quot;*(n-path[i]-1))</span><br><span class="line">        ans.append(chess)</span><br><span class="line">        return</span><br><span class="line">    for col in range(n):</span><br><span class="line">        if isvalid(row,col):</span><br><span class="line">            path.append(col)#放置皇后</span><br><span class="line">            onpath[col]=diag1[row+col]=diag2[row-col+n-1]=True</span><br><span class="line">            dfs(row+1,path)#递归下一行</span><br><span class="line">            path.pop()#回溯，取消放置</span><br><span class="line">            onpath[col]=diag1[row+col]=diag2[row-col+n-1]=False</span><br><span class="line">    </span><br><span class="line">def isvalid(row,col):</span><br><span class="line">    if onpath[col] or diag1[row+col] or diag2[row-col+n-1]:</span><br><span class="line">        return False</span><br><span class="line">    return True</span><br><span class="line">dfs(0,path)</span><br><span class="line">print(ans)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——初识RAG</title>
    <url>/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<p>基于 <strong>LLM （Large Language
Model）</strong>最火热的应用技术是什么，检索增强生成（<strong>RAG，Retrieval
Augmented Generation</strong>）技术必占据重要的一席。RAG 最初是为了解决
LLM
的各类问题的产生的，但后面大家发现在现阶段的很多企业痛点上，使用RAG好像是更好的解决方案。</p>
<p>LLM的问题</p>
<p>尽管LLM拥有令人印象深刻的能力，但是它们还面临着一些问题和挑战：</p>
<ul>
<li><p>幻觉问题：大模型的底层原理是基于概率，在没有答案的情况下经常会胡说八道，提供虚假信息。</p></li>
<li><p>时效性问题：规模越大（参数越多、tokens
越多），大模型训练的成本越高。类似 ChatGPT3.5，起初训练数据是截止到 2021
年的，对于之后的事情就不知道了。而且对于一些高时效性的事情，大模型更加无能为力，比如帮我看看今天晚上有什么电影值得去看？这种任务是需要去淘票票、猫眼等网站先去获取最新电影信息的，大模型本身无法完成这个任务。</p></li>
<li><p>数据安全：OpenAI
已经遭到过几次隐私数据的投诉，而对于企业来说，如果把自己的经营数据、合同文件等机密文件和数据上传到互联网上的大模型，那想想都可怕。既要保证安全，又要借助
AI
能力，那么最好的方式就是<strong>把数据全部放在本地，企业数据的业务计算全部在本地完成</strong>。而在线的大模型仅仅完成一个归纳的功能，甚至，LLM
都可以完全本地化部署。</p></li>
</ul>
<hr>
<p>解决这些挑战对于 LLMs
在各个领域的有效利用至关重要。一个有效的解决方案是集成检索增强生成（RAG）技术，该技术通过获取外部数据来响应查询来补充模型，从而确保更准确和最新的输出。主要表现方面如下：</p>
<ul>
<li><p>有效避免幻觉问题：虽然无法 100% 解决大模型的幻觉问题，但通过 RAG
技术能够有效的降低幻觉，在软件系统中结合大模型提供幂等的API接口就可以发挥大模型的重要作用。</p></li>
<li><p>经济高效的处理知识&amp;开箱即用：只需要借助信息检索和向量技术，将用户的问题和知识库进行相关性搜索结合，就能高效的提供大模型不知道的知识，同时具有权威性。</p></li>
<li><p>数据安全：企业的数据可以得到有效的保护，通过私有化部署基于 RAG
系统开发的AI产品，能够在体验AI带来的便利性的同时，又能避免企业隐私数据的泄漏。</p></li>
</ul>
<h1 id="什么是rag">什么是RAG</h1>
<p>RAG 是检索增强生成（Retrieval Augmented Generation
）的简称，它为大语言模型 (LLMs)
提供了从数据源检索信息的能力，并以此为基础生成回答。简而言之，RAG
结合了信息检索技术和大语言模型的提示功能，即模型根据搜索算法找到的信息作为上下文来查询回答问题。无论是查询还是检索的上下文，都会被整合到发给大语言模型的提示中。
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/v2-76c9a386a70bbcd610f76f1f32423165_1440w.png" alt="v2-76c9a386a70bbcd610f76f1f32423165_1440w"></p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/e9280ebbd3c04d400de7c0619fd0bb50.jpg" alt="e9280ebbd3c04d400de7c0619fd0bb50">
<figcaption aria-hidden="true">e9280ebbd3c04d400de7c0619fd0bb50</figcaption>
</figure>
<p>RAG
的架构如图中所示。它既不是一个特定的开源代码库，也不是某个特定的应用，是一个开发框架。</p>
<p>完整的 RAG 应用流程主要包含两个阶段：</p>
<p>数据准备阶段：（A）数据提取–&gt; （B）分块（Chunking）–&gt;
（C）向量化（embedding）–&gt; （D）数据入库</p>
<p>检索生成阶段：（1）问题向量化–&gt; （2）根据问题查询匹配数据–&gt;
（3）获取索引数据 –&gt; （4）将数据注入Prompt–&gt; （5）LLM生成答案</p>
<h2 id="向量数据库">向量数据库</h2>
<h3 id="gpt-的缺陷">GPT 的缺陷</h3>
<p>GPT-3.5/4
带给我们无限震撼的同时，其天然的缺陷和诸多的限制也让开发者头痛不已，例如其输入端上下文（tokens）大小的限制困扰着很多的开发者和消费者，像
gpt-3.5-turbo 模型它的限制是 4K
tokens(～3000字)，这意味着使用者最多只能输入 3000 字给 GPT
来理解和推理答案。</p>
<h3 id="向量数据库的崛起">向量数据库的崛起</h3>
<p>在 GPT
模型的限制下，开发者们不得不寻找其他的解决方案，而向量数据库就是其中之一。向量数据库的核心思想是将文本转换成向量，然后将向量存储在数据库中，当用户输入问题时，将问题转换成向量，然后在数据库中搜索最相似的向量和上下文，最后将文本返回给用户。</p>
<p>当我们有一份文档需要 GPT
处理时，例如这份文档是客服培训资料或者操作手册，我们可以先将这份文档的所有内容转化成向量（这个过程称之为
Vector
Embedding），然后当用户提出相关问题时，我们将用户的搜索内容转换成向量，然后在数据库中搜索最相似的向量，匹配最相似的几个上下文，最后将上下文返回给
GPT。这样不仅可以大大减少 GPT
的计算量，从而提高响应速度，更重要的是降低成本，并绕过 GPT 的 tokens
限制。</p>
<h1 id="rag的挑战">RAG的挑战</h1>
<p>一个基本的 RAG 通常集成了一个向量数据库和一个 LLM，其中<a href="https://zilliz.com/learn/what-is-vector-database">向量数据库</a>存储并检索与用户查询相关的上下文信息，LLM
根据检索到的上下文生成答案。虽然这种方法在大部分情况下效果都很好，但在处理复杂任务时却面临一些挑战，如多跳推理（multi-hop
reasoning）或联系不同信息片段全面回答问题。</p>
<p>以这个问题为例：“<em>What name was given to the son of the man who
defeated the usurper Allectus?</em>”</p>
<p>一个基本的 RAG 通常会遵循以下步骤来回答这个问题：</p>
<ol type="1">
<li>识别那个人：确定谁打败了 Allectus。</li>
<li>研究那个人的儿子：查找有关这个人家庭的信息，特别是他的儿子。</li>
<li>找到名字：确定儿子的名字。</li>
</ol>
<p>通常第一步就会面临挑战，因为基本的 RAG 根据<a href="https://zilliz.com/glossary/semantic-similarity">语义相似性</a>检索文本，而不是基于在数据集中没有明确提及具体细节来回答复杂的查询问题。这种局限性让我们很难找到所需的确切信息。解决方案通常是为常见查询手动创建问答对。但这种解决方案通常十分昂贵甚至不切实际。</p>
<p>为了应对这些挑战，微软研究院引入了 <a href="https://microsoft.github.io/graphrag/">GraphRAG</a>，这是一种全新方法，它通过知识图谱增强
RAG 的检索和生成。</p>
<h1 id="graphrag的诞生">GraphRAG的诞生</h1>
<p>与使用向量数据库检索语义相似文本的基本 RAG 不同，GraphRAG
通过结合知识图谱（KGs）来增强
RAG。知识图谱是一种数据结构，它根据数据间的关系来存储和联系相关或不相关的数据。</p>
<p>GraphRAG 流程通常包括两个基本过程：索引和查询。</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/1_03c0dcc161.png" alt="1_03c0dcc161">
<figcaption aria-hidden="true">1_03c0dcc161</figcaption>
</figure>
<h1 id="graphrag的优势">GraphRAG的优势</h1>
<p>基础 RAG 和 GraphRAG
都被问到了同样的问题，这需要汇总整个数据集中的信息来构成答案。</p>
<p>问：What are the top 5 themes in the dataset?</p>
<p>下图为答案。基础 RAG
提供的结果与战争主题无关，因为向量搜索检索到了无关的文本，导致了答案的不准确。相比之下，GraphRAG
提供了一个清晰且高度相关的答案，识别了主要的主题和相关细节。结果与数据集一致，并引用了源材料。</p>
<p>上述例子展示了 GraphRAG
如何通过结合知识图谱和向量数据库，更有效地处理需要跨数据集整合信息的复杂查询，从而提高答案的相关性和准确性。</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/5_8bd8df7ac9.png" alt="5_8bd8df7ac9">
<figcaption aria-hidden="true">5_8bd8df7ac9</figcaption>
</figure>
<p>GraphRAG 在多跳推理和复杂信息总结方面性能明显更佳。研究表明GraphRAG
在全面性和多样性方面都超过了基础 RAG：</p>
<ul>
<li><strong>全面性</strong>：答案覆盖问题的所有方面。</li>
<li><strong>多样性</strong>：答案提供的观点和见解具有多样性和丰富性。</li>
</ul>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://blog.csdn.net/Python_0011/article/details/139752344">大模型RAG入门及实践（非常详细）零基础入门到精通，收藏这一篇就够了-CSDN博客</a></p>
<p><a href="https://cloud.tencent.com/developer/article/2312534">向量数据库｜一文全面了解向量数据库的基本概念、原理、算法、选型-腾讯云开发者社区-腾讯云</a></p>
<p><a href="https://zilliz.com.cn/blog/graphrag-explained-enhance-rag-with-knowledge-graphs">GraphRAG
详解: 通过知识图谱提升 RAG 系统 - Zilliz 向量数据库</a></p>
<p>论文： https://arxiv.org/pdf/2404.16130</p>
<p><a href="https://www.bilibili.com/video/av1256338452?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">GraphRAG：知识图谱+RAG、更高质量的检索_哔哩哔哩_bilibili</a></p>
<p>微软开源的GraphRAG代码： https://github.com/microsoft/graphrag</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——决策树</title>
    <url>/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h2 id="正文">正文</h2>
<h2 id="作业">作业</h2>
<h3 id="什么是信息增益根据下图分别计算按照属性a和b划分时的信息增益id3决策树学习算法将会选择哪个属性">什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/hw_h_82p6lenbyhkws867e413c0614d3.png" alt="hw_h_82p6lenbyhkws867e413c0614d3">
<figcaption aria-hidden="true">hw_h_82p6lenbyhkws867e413c0614d3</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153252.jpg" alt="IMG_20250329_153252">
<figcaption aria-hidden="true">IMG_20250329_153252</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153259.jpg" alt="IMG_20250329_153259">
<figcaption aria-hidden="true">IMG_20250329_153259</figcaption>
</figure>
<h3 id="什么是交叉验证法有什么用途">什么是交叉验证法？有什么用途？</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153307.jpg" alt="IMG_20250329_153307">
<figcaption aria-hidden="true">IMG_20250329_153307</figcaption>
</figure>
<h3 id="什么是过拟合overfitting什么情况下可能发生过拟合采取什么措施有助于消除过拟合">什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153310.jpg" alt="IMG_20250329_153310">
<figcaption aria-hidden="true">IMG_20250329_153310</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>最优化方法——期末复习</title>
    <url>/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/</url>
    <content><![CDATA[<p><a href="https://www.bilibili.com/video/BV1uP411K7Hf?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">最优化理论与方法-对偶线性规划（例题分析）_哔哩哔哩_bilibili</a></p>
<h3 id="复习笔记">复习笔记</h3>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120458.jpg" alt="IMG_20250624_120458">
<figcaption aria-hidden="true">IMG_20250624_120458</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120516.jpg" alt="IMG_20250624_120516">
<figcaption aria-hidden="true">IMG_20250624_120516</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120523.jpg" alt="IMG_20250624_120523">
<figcaption aria-hidden="true">IMG_20250624_120523</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120527.jpg" alt="IMG_20250624_120527">
<figcaption aria-hidden="true">IMG_20250624_120527</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120534.jpg" alt="IMG_20250624_120534">
<figcaption aria-hidden="true">IMG_20250624_120534</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120539.jpg" alt="IMG_20250624_120539">
<figcaption aria-hidden="true">IMG_20250624_120539</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120546.jpg" alt="IMG_20250624_120546">
<figcaption aria-hidden="true">IMG_20250624_120546</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120550.jpg" alt="IMG_20250624_120550">
<figcaption aria-hidden="true">IMG_20250624_120550</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120557.jpg" alt="IMG_20250624_120557">
<figcaption aria-hidden="true">IMG_20250624_120557</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120600.jpg" alt="IMG_20250624_120600">
<figcaption aria-hidden="true">IMG_20250624_120600</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120611.jpg" alt="IMG_20250624_120611">
<figcaption aria-hidden="true">IMG_20250624_120611</figcaption>
</figure>
<figure>
<img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120607.jpg" alt="IMG_20250624_120607">
<figcaption aria-hidden="true">IMG_20250624_120607</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>最优化方法</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>最优化方法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——期末复习（上）</title>
    <url>/2025/06/14/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    <content><![CDATA[<h3 id="svm支持向量机">SVM支持向量机</h3>
<h4 id="作业">作业</h4>
<h5 id="section">1</h5>
<p>关于核化软间隔支持向量机，推导目标函数的原始问题转换为对偶问题的过程、KKT条件、预测函数。</p>
<p><strong>原始问题</strong></p>
<p>软间隔SVM的目标函数为： <span class="math display">$$
\min_{\mathbf{w}, b, \xi} \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n
\xi_i
$$</span> 约束条件： <span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong><sup><em>T</em></sup><em>ϕ</em>(<strong>x</strong><sub><em>i</em></sub>) + <em>b</em>) ≥ 1 − <em>ξ</em><sub><em>i</em></sub>,  <em>ξ</em><sub><em>i</em></sub> ≥ 0,  <em>i</em> = 1, …, <em>n</em></span>
其中 <span class="math inline"><em>C</em> &gt; 0</span>
是惩罚参数，<span class="math inline"><em>ξ</em><sub><em>i</em></sub></span>
是松弛变量，<span class="math inline"><em>ϕ</em>(⋅)</span>
是特征映射。</p>
<p><strong>转化为对偶问题</strong></p>
<ol type="1">
<li><p><strong>构造拉格朗日函数</strong>： <span class="math display">$$
\mathcal{L}(\mathbf{w}, b, \xi, \boldsymbol{\alpha}, \boldsymbol{\beta})
= \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n \xi_i - \sum_{i=1}^n
\alpha_i \left[y_i (\mathbf{w}^T \phi(\mathbf{x}_i) + b) - 1 +
\xi_i\right] - \sum_{i=1}^n \beta_i \xi_i
$$</span> 其中 <span class="math inline"><em>α</em><sub><em>i</em></sub> ≥ 0, <em>β</em><sub><em>i</em></sub> ≥ 0</span>
是拉格朗日乘子。</p></li>
<li><p><strong>对原始变量求偏导并令其为零</strong>：</p></li>
</ol>
<ul>
<li>对 <span class="math inline"><strong>w</strong></span> 求导： <span class="math display">$$
\frac{\partial \mathcal{L}}{\partial \mathbf{w}} = \mathbf{w} -
\sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i) = 0 \quad \Rightarrow
\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i)
$$</span></li>
<li>对 <span class="math inline"><em>b</em></span> 求导： <span class="math display">$$
\frac{\partial \mathcal{L}}{\partial b} = -\sum_{i=1}^n \alpha_i y_i = 0
\quad \Rightarrow \sum_{i=1}^n \alpha_i y_i = 0
$$</span></li>
<li>对 <span class="math inline"><em>ξ</em><sub><em>i</em></sub></span>
求导： <span class="math display">$$
\frac{\partial \mathcal{L}}{\partial \xi_i} = C - \alpha_i - \beta_i = 0
\quad \Rightarrow \beta_i = C - \alpha_i
$$</span></li>
</ul>
<ol start="3" type="1">
<li><p><strong>代入拉格朗日函数消去原始变量</strong>： 将 <span class="math inline"><strong>w</strong></span> 和 <span class="math inline"><em>β</em><sub><em>i</em></sub></span> 代入 <span class="math inline">ℒ</span>，得到对偶目标函数： <span class="math display">$$
\max_{\boldsymbol{\alpha}} \sum_{i=1}^n \alpha_i - \frac{1}{2}
\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j \phi(\mathbf{x}_i)^T
\phi(\mathbf{x}_j)
$$</span> 约束条件： <span class="math display">$$
0 \leq \alpha_i \leq C, \quad \sum_{i=1}^n \alpha_i y_i = 0
$$</span></p></li>
<li><p><strong>引入核函数</strong>： 用核函数 <span class="math inline"><em>K</em>(<strong>x</strong><sub><em>i</em></sub>, <strong>x</strong><sub><em>j</em></sub>) = <em>ϕ</em>(<strong>x</strong><sub><em>i</em></sub>)<sup><em>T</em></sup><em>ϕ</em>(<strong>x</strong><sub><em>j</em></sub>)</span>
替换内积，得到最终对偶问题： <span class="math display">$$
\max_{\boldsymbol{\alpha}} \sum_{i=1}^n \alpha_i - \frac{1}{2}
\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(\mathbf{x}_i,
\mathbf{x}_j)
$$</span> 约束条件不变。</p></li>
</ol>
<p><strong>KKT条件</strong></p>
<ul>
<li><strong>原始可行性</strong>：<span class="math inline"><em>y</em><sub><em>i</em></sub>(<strong>w</strong><sup><em>T</em></sup><em>ϕ</em>(<strong>x</strong><sub><em>i</em></sub>) + <em>b</em>) ≥ 1 − <em>ξ</em><sub><em>i</em></sub>,  <em>ξ</em><sub><em>i</em></sub> ≥ 0</span></li>
<li><strong>对偶可行性</strong>：<span class="math inline"><em>α</em><sub><em>i</em></sub> ≥ 0,  <em>β</em><sub><em>i</em></sub> = <em>C</em> − <em>α</em><sub><em>i</em></sub> ≥ 0</span></li>
<li><strong>互补松弛性</strong>：<span class="math inline"><em>α</em><sub><em>i</em></sub>[<em>y</em><sub><em>i</em></sub>(<strong>w</strong><sup><em>T</em></sup><em>ϕ</em>(<strong>x</strong><sub><em>i</em></sub>) + <em>b</em>) − 1 + <em>ξ</em><sub><em>i</em></sub>] = 0,  <em>β</em><sub><em>i</em></sub><em>ξ</em><sub><em>i</em></sub> = 0</span></li>
<li><strong>梯度为零条件</strong>：已通过偏导数消去原始变量。</li>
</ul>
<p><strong>预测函数</strong></p>
<p>测试样本 <span class="math inline"><strong>x</strong></span>
的预测函数为： <span class="math display">$$
f(\mathbf{x}) = \text{sign} \left( \sum_{i=1}^n \alpha_i y_i
K(\mathbf{x}_i, \mathbf{x}) + b \right)
$$</span> 其中 <span class="math inline"><em>b</em></span>
可通过任一支持向量（满足 <span class="math inline">0 &lt; <em>α</em><sub><em>i</em></sub> &lt; <em>C</em></span>）计算：
<span class="math display">$$
b = y_i - \sum_{j=1}^n \alpha_j y_j K(\mathbf{x}_j, \mathbf{x}_i)
$$</span></p>
<h5 id="section-1">2</h5>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——支持向量机</title>
    <url>/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<h2 id="正文">正文</h2>
<p>下面我将为你详细解释KKT（Karush-Kuhn-Tucker）条件。KKT条件是优化理论中用于求解带约束非线性规划问题的一组必要条件，广泛应用于支持向量机（SVM）等机器学习算法中。我会使用内联数学公式（如
<span class="math display"><em>f</em>(<strong>x</strong>)</span>）来展示相关表达式。</p>
<hr>
<h3 id="优化问题的一般形式">1. 优化问题的一般形式</h3>
<p>我们考虑一个带有约束的优化问题，数学形式如下： - 目标：<span class="math display">min<sub><strong>x</strong></sub><em>f</em>(<strong>x</strong>)</span>
- 不等式约束：<span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) ≤ 0</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>m</em></span> -
等式约束：<span class="math display"><em>h</em><sub><em>j</em></sub>(<strong>x</strong>) = 0</span>，其中
<span class="math display"><em>j</em> = 1, 2, …, <em>p</em></span></p>
<p>这里： - <span class="math display"><em>f</em>(<strong>x</strong>)</span>
是目标函数，通常是我们希望最小化的函数。 - <span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) ≤ 0</span>
表示 <span class="math display"><em>m</em></span> 个不等式约束。 - <span class="math display"><em>h</em><sub><em>j</em></sub>(<strong>x</strong>) = 0</span>
表示 <span class="math display"><em>p</em></span> 个等式约束。</p>
<p>KKT条件的目标是找到满足这些约束的局部最优解 <span class="math display"><strong>x</strong></span>。</p>
<hr>
<h3 id="拉格朗日函数">2. 拉格朗日函数</h3>
<p>为了引入KKT条件，我们首先定义拉格朗日函数： <span class="math display">$$\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda},
\boldsymbol{\mu}) = f(\mathbf{x}) + \sum_{i=1}^{m} \lambda_i
g_i(\mathbf{x}) + \sum_{j=1}^{p} \mu_j h_j(\mathbf{x})$$</span></p>
<p>其中： - <span class="math display"><strong>λ</strong> = (<em>λ</em><sub>1</sub>, <em>λ</em><sub>2</sub>, …, <em>λ</em><sub><em>m</em></sub>)</span>
是与不等式约束 <span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) ≤ 0</span>
对应的拉格朗日乘子。 - <span class="math display"><strong>μ</strong> = (<em>μ</em><sub>1</sub>, <em>μ</em><sub>2</sub>, …, <em>μ</em><sub><em>p</em></sub>)</span>
是与等式约束 <span class="math display"><em>h</em><sub><em>j</em></sub>(<strong>x</strong>) = 0</span>
对应的拉格朗日乘子。</p>
<p>拉格朗日函数将目标函数和约束条件结合在一起，通过引入乘子 <span class="math display"><em>λ</em><sub><em>i</em></sub></span> 和 <span class="math display"><em>μ</em><sub><em>j</em></sub></span>
来平衡约束对优化的影响。</p>
<hr>
<h3 id="kkt条件的组成部分">3. KKT条件的组成部分</h3>
<p>KKT条件由以下四个部分组成，只有当某些正则性条件（如Slater条件）满足时，局部最优解
<span class="math display"><strong>x</strong></span>
才会同时满足这些条件。以下是具体的KKT条件：</p>
<h4 id="梯度条件stationarity">3.1 梯度条件（Stationarity）</h4>
<p>拉格朗日函数对 <span class="math display"><strong>x</strong></span>
的梯度必须为零，即： <span class="math display">$$\nabla_{\mathbf{x}}
\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = \nabla
f(\mathbf{x}) + \sum_{i=1}^{m} \lambda_i \nabla g_i(\mathbf{x}) +
\sum_{j=1}^{p} \mu_j \nabla h_j(\mathbf{x}) = 0$$</span></p>
<p>这意味着在最优解处，目标函数的梯度可以通过约束函数梯度的线性组合来表示。</p>
<h4 id="原始可行性primal-feasibility">3.2 原始可行性（Primal
Feasibility）</h4>
<p>解 <span class="math display"><strong>x</strong></span>
必须满足原始问题的所有约束： - 不等式约束：<span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) ≤ 0</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>m</em></span> -
等式约束：<span class="math display"><em>h</em><sub><em>j</em></sub>(<strong>x</strong>) = 0</span>，其中
<span class="math display"><em>j</em> = 1, 2, …, <em>p</em></span></p>
<p>这确保了解仍在问题的可行域内。</p>
<h4 id="对偶可行性dual-feasibility">3.3 对偶可行性（Dual
Feasibility）</h4>
<p>对于不等式约束对应的拉格朗日乘子，必须满足： <span class="math display"><em>λ</em><sub><em>i</em></sub> ≥ 0</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>m</em></span></p>
<p>这表明不等式约束的乘子非负，反映了约束对优化方向的影响。</p>
<h4 id="互补松弛条件complementary-slackness">3.4
互补松弛条件（Complementary Slackness）</h4>
<p>对于每个不等式约束，乘子与约束函数的乘积必须为零： <span class="math display"><em>λ</em><sub><em>i</em></sub><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) = 0</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>m</em></span></p>
<p>这意味着： - 如果某个约束不“紧”（即 <span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) &lt; 0</span>），则对应的乘子
<span class="math display"><em>λ</em><sub><em>i</em></sub> = 0</span>。
- 如果 <span class="math display"><em>λ</em><sub><em>i</em></sub> &gt; 0</span>，则该约束必须是“紧”的（即
<span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) = 0</span>）。</p>
<hr>
<h3 id="kkt条件的意义">4. KKT条件的意义</h3>
<ul>
<li><strong>梯度条件</strong>：表明最优解处目标函数的改变方向被约束完全平衡。</li>
<li><strong>原始可行性</strong>：确保解满足所有约束条件。</li>
<li><strong>对偶可行性</strong>：限制拉格朗日乘子的符号，保证优化方向的合理性。</li>
<li><strong>互补松弛条件</strong>：揭示哪些约束在最优解处起作用（紧约束），哪些不起作用。</li>
</ul>
<hr>
<h3 id="kkt条件在svm中的应用示例">5. KKT条件在SVM中的应用示例</h3>
<p>KKT条件在支持向量机（SVM）中尤为重要。SVM的原始优化问题为： -
目标：<span class="math display">$$\min_{\mathbf{w}, b} \frac{1}{2}
\|\mathbf{w}\|^2$$</span> - 约束：<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong> ⋅ <strong>x</strong><sub><em>i</em></sub> + <em>b</em>) ≥ 1</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>n</em></span></p>
<p>将其改写为标准形式的不等式约束：<span class="math display">1 − <em>y</em><sub><em>i</em></sub>(<strong>w</strong> ⋅ <strong>x</strong><sub><em>i</em></sub> + <em>b</em>) ≤ 0</span>。</p>
<p>拉格朗日函数为： <span class="math display">$$\mathcal{L}(\mathbf{w},
b, \boldsymbol{\alpha}) = \frac{1}{2} \|\mathbf{w}\|^2 + \sum_{i=1}^{n}
\alpha_i \left[ 1 - y_i (\mathbf{w} \cdot \mathbf{x}_i + b)
\right]$$</span></p>
<p>应用KKT条件： 1. <strong>梯度条件</strong>： - 对 <span class="math display"><strong>w</strong></span>：<span class="math display">$$\nabla_{\mathbf{w}} \mathcal{L} = \mathbf{w} -
\sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i = 0$$</span> - 对 <span class="math display"><em>b</em></span>：<span class="math display">$$\frac{\partial \mathcal{L}}{\partial b} =
-\sum_{i=1}^{n} \alpha_i y_i = 0$$</span> 2.
<strong>原始可行性</strong>：<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong> ⋅ <strong>x</strong><sub><em>i</em></sub> + <em>b</em>) ≥ 1</span>
3. <strong>对偶可行性</strong>：<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span> 4.
<strong>互补松弛条件</strong>：<span class="math display"><em>α</em><sub><em>i</em></sub>[<em>y</em><sub><em>i</em></sub>(<strong>w</strong> ⋅ <strong>x</strong><sub><em>i</em></sub> + <em>b</em>) − 1] = 0</span></p>
<p>这些条件帮助我们识别支持向量（<span class="math display"><em>α</em><sub><em>i</em></sub> &gt; 0</span>
的点）并求解最优的 <span class="math display"><strong>w</strong></span>
和 <span class="math display"><em>b</em></span>。</p>
<hr>
<h3 id="总结">6. 总结</h3>
<p>KKT条件是求解带约束优化问题的核心工具，它通过梯度条件、原始可行性、对偶可行性和互补松弛条件，确保了解既是最优的，又满足所有约束。在机器学习中，KKT条件为SVM等算法提供了理论支持，是理解和实现这些模型的关键。</p>
<h3 id="作业">作业</h3>
<h4 id="关于支持向量机推导目标函数的原始问题转换为对偶问题的过程和条件使用拉格朗日乘子法">关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）</h4>
<figure>
<img src="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/IMG_20250416_164811.jpg" alt="IMG_20250416_164811">
<figcaption aria-hidden="true">IMG_20250416_164811</figcaption>
</figure>
<p>下面我们将推导支持向量机（SVM）中目标函数从原始问题转换为对偶问题的过程和条件，使用拉格朗日乘子法。我们将一步步展开，确保推导清晰且完整。</p>
<hr>
<h3 id="原始问题">1. 原始问题</h3>
<p>支持向量机（SVM）的目标是找到一个超平面，能够最大化到最近数据点的间隔。对于线性可分的情况，原始优化问题可以定义为：</p>
<ul>
<li><p><strong>目标函数</strong>：<br>
<span class="math display">$$\min_{\mathbf{w}, b} \frac{1}{2}
\|\mathbf{w}\|^2$$</span></p></li>
<li><p><strong>约束条件</strong>：<br>
<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong> ⋅ <strong>x</strong><sub><em>i</em></sub> + <em>b</em>) ≥ 1,  <em>i</em> = 1, 2, …, <em>n</em></span></p></li>
</ul>
<p>其中： - <span class="math display"><strong>w</strong></span>
是超平面的法向量； - <span class="math display"><em>b</em></span>
是超平面的截距； - <span class="math display"><strong>x</strong><sub><em>i</em></sub></span>
是训练样本，<span class="math display"><em>y</em><sub><em>i</em></sub> ∈ {−1, 1}</span>
是对应的类别标签； - <span class="math display">∥<strong>w</strong>∥<sup>2</sup></span>
表示法向量的平方范数，目标是最小化它以最大化间隔； -
约束条件确保所有样本点被正确分类，并且到超平面的归一化距离至少为 1。</p>
<hr>
<h3 id="引入拉格朗日乘子法">2. 引入拉格朗日乘子法</h3>
<p>由于这是一个带不等式约束的优化问题，我们使用拉格朗日乘子法将其转换为无约束形式。引入拉格朗日乘子
<span class="math display"><strong>α</strong> = (<em>α</em><sub>1</sub>, <em>α</em><sub>2</sub>, …, <em>α</em><sub><em>n</em></sub>)</span>，其中
<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span>，构造拉格朗日函数：</p>
<p><span class="math display">$$\mathcal{L}(\mathbf{w}, b,
\boldsymbol{\alpha}) = \frac{1}{2} \|\mathbf{w}\|^2 - \sum_{i=1}^{n}
\alpha_i \left[ y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1
\right]$$</span></p>
<ul>
<li>第一项 <span class="math display">$$\frac{1}{2}
\|\mathbf{w}\|^2$$</span> 是原始目标函数；</li>
<li>第二项 <span class="math display">$$-\sum_{i=1}^{n} \alpha_i \left[
y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 \right]$$</span>
将约束条件引入，由于是 <span class="math display">≥</span> 不等式，乘子
<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span>。</li>
</ul>
<p>我们的目标是通过拉格朗日函数，将原始问题转换为对偶问题。</p>
<hr>
<h3 id="转换为对偶问题">3. 转换为对偶问题</h3>
<p>对偶问题的核心思想是：先对 <span class="math display"><strong>w</strong></span> 和 <span class="math display"><em>b</em></span> 求拉格朗日函数的极小值，然后对
<span class="math display"><strong>α</strong></span> 求极大值。即：</p>
<p><span class="math display">max<sub><strong>α</strong> ≥ 0</sub>min<sub><strong>w</strong>, <em>b</em></sub>ℒ(<strong>w</strong>, <em>b</em>, <strong>α</strong>)</span></p>
<h4 id="对-mathbfw-和-b-求偏导">3.1 对 <span class="math display"><strong>w</strong></span> 和 <span class="math display"><em>b</em></span> 求偏导</h4>
<p>为了找到 <span class="math display">ℒ</span> 关于 <span class="math display"><strong>w</strong></span> 和 <span class="math display"><em>b</em></span>
的极小值，分别求偏导并令其为零：</p>
<ul>
<li><p>对 <span class="math display"><strong>w</strong></span>
求偏导：<br>
<span class="math display">$$\frac{\partial \mathcal{L}}{\partial
\mathbf{w}} = \mathbf{w} - \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i =
0$$</span><br>
解得：<br>
<span class="math display">$$\mathbf{w} = \sum_{i=1}^{n} \alpha_i y_i
\mathbf{x}_i$$</span></p></li>
<li><p>对 <span class="math display"><em>b</em></span> 求偏导：<br>
<span class="math display">$$\frac{\partial \mathcal{L}}{\partial b} =
-\sum_{i=1}^{n} \alpha_i y_i = 0$$</span><br>
解得：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i =
0$$</span></p></li>
</ul>
<p>这两个结果是后续推导的关键。</p>
<h4 id="代入拉格朗日函数">3.2 代入拉格朗日函数</h4>
<p>将 <span class="math display">$$\mathbf{w} = \sum_{i=1}^{n} \alpha_i
y_i \mathbf{x}_i$$</span> 代入拉格朗日函数，并利用 <span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i = 0$$</span>
简化：</p>
<p><span class="math display">$$\mathcal{L} = \frac{1}{2} \left\|
\sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \right\|^2 - \sum_{i=1}^{n}
\alpha_i \left[ y_i \left( \left( \sum_{j=1}^{n} \alpha_j y_j
\mathbf{x}_j \right) \cdot \mathbf{x}_i + b \right) - 1
\right]$$</span></p>
<ul>
<li><p>计算第一项：<br>
<span class="math display">$$\left\| \sum_{i=1}^{n} \alpha_i y_i
\mathbf{x}_i \right\|^2 = \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i
\alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)$$</span></p></li>
<li><p>计算第二项中的内积部分：<br>
<span class="math display">$$y_i \left( \sum_{j=1}^{n} \alpha_j y_j
\mathbf{x}_j \right) \cdot \mathbf{x}_i = y_i \sum_{j=1}^{n} \alpha_j
y_j (\mathbf{x}_j \cdot \mathbf{x}_i)$$</span><br>
所以：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i \left(
\sum_{j=1}^{n} \alpha_j y_j (\mathbf{x}_j \cdot \mathbf{x}_i) \right) =
\sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i
\cdot \mathbf{x}_j)$$</span></p></li>
<li><p>考虑 <span class="math display"><em>b</em></span> 项：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i b = b
\sum_{i=1}^{n} \alpha_i y_i = 0 \quad (\text{因为} \sum_{i=1}^{n}
\alpha_i y_i = 0)$$</span></p></li>
</ul>
<p>代入后，拉格朗日函数变为：<br>
<span class="math display">$$\mathcal{L} = \frac{1}{2} \sum_{i=1}^{n}
\sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot
\mathbf{x}_j) - \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j
(\mathbf{x}_i \cdot \mathbf{x}_j) + \sum_{i=1}^{n} \alpha_i$$</span></p>
<p>化简：<br>
<span class="math display">$$\mathcal{L} = -\frac{1}{2} \sum_{i=1}^{n}
\sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot
\mathbf{x}_j) + \sum_{i=1}^{n} \alpha_i$$</span></p>
<h4 id="对偶优化问题">3.3 对偶优化问题</h4>
<p>于是，对偶问题是：<br>
<span class="math display">$$\max_{\boldsymbol{\alpha}} \left[
\sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n}
\alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)
\right]$$</span></p>
<ul>
<li><strong>约束条件</strong>：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i =
0$$</span><br>
<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0,  <em>i</em> = 1, 2, …, <em>n</em></span></li>
</ul>
<p>为了与标准优化形式一致，常将其写为最小化问题：<br>
<span class="math display">$$\min_{\boldsymbol{\alpha}} \left[
\frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j
(\mathbf{x}_i \cdot \mathbf{x}_j) - \sum_{i=1}^{n} \alpha_i
\right]$$</span></p>
<ul>
<li><strong>约束条件不变</strong>：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i =
0$$</span><br>
<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span></li>
</ul>
<hr>
<h3 id="转换的条件">4. 转换的条件</h3>
<p>原始问题与对偶问题之间的关系由<strong>强对偶性</strong>保证。在SVM中：
- 目标函数 <span class="math display">$$\frac{1}{2}
\|\mathbf{w}\|^2$$</span> 是凸函数（二次函数）； - 约束条件 <span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong> ⋅ <strong>x</strong><sub><em>i</em></sub> + <em>b</em>) ≥ 1</span>
是线性不等式； -
对于线性可分数据，Slater条件满足（存在可行解使约束严格成立）。</p>
<p>因此，强对偶性成立，原始问题的最优解可以通过对偶问题求解得到。</p>
<p>此外： - 最优的 <span class="math display"><strong>α</strong></span>
通过对偶问题求解； - <span class="math display">$$\mathbf{w} =
\sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i$$</span>； -
对于支持向量（<span class="math display"><em>α</em><sub><em>i</em></sub> &gt; 0</span>
的样本），<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong> ⋅ <strong>x</strong><sub><em>i</em></sub> + <em>b</em>) = 1</span>，可据此解出
<span class="math display"><em>b</em></span>。</p>
<hr>
<h3 id="总结-1">5. 总结</h3>
<ul>
<li><p><strong>原始问题</strong>：<br>
<span class="math display">$$\min_{\mathbf{w}, b} \frac{1}{2}
\|\mathbf{w}\|^2$$</span><br>
受约束：<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong> ⋅ <strong>x</strong><sub><em>i</em></sub> + <em>b</em>) ≥ 1</span></p></li>
<li><p><strong>对偶问题</strong>：<br>
<span class="math display">$$\max_{\boldsymbol{\alpha}} \left[
\sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n}
\alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)
\right]$$</span><br>
受约束：<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i =
0$$</span>，<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span></p></li>
<li><p><strong>转换条件</strong>：<br>
通过拉格朗日乘子法，基于凸优化和强对偶性完成转换。对偶形式不仅便于求解，还为引入核函数奠定了基础。</p></li>
</ul>
<p>以上就是SVM目标函数从原始问题到对偶问题的推导过程和条件。</p>
<h4 id="已知训练数据集中正例点x123x233x332负例点x412-x521x631训练线性svm分类器求最大间隔分类超平面和分类决策函数并画出分类超平面间隔边界以及支持向量">2.已知训练数据集中正例点x1=(2,3)，x2=(3,3)，x3=(3,2)，负例点x4=(1,2)，
x5=(2,1)，x6=(3,1)，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。</h4>
<figure>
<img src="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/IMG_20250416_164804-1744793466526-4.jpg" alt="IMG_20250416_164804">
<figcaption aria-hidden="true">IMG_20250416_164804</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——神经网络</title>
    <url>/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h2 id="正文">正文</h2>
<h3 id="作业">作业</h3>
<h4 id="类别不均衡指的是什么有哪些解决方案">类别不均衡指的是什么？有哪些解决方案。</h4>
<p><strong>类别不均衡（Class Imbalance）</strong>
是指分类任务中不同类别样本的数量差异显著，例如：<br>
- <strong>多数类（Majority
Class）</strong>：样本数量多（如正常交易占99%）。<br>
- <strong>少数类（Minority
Class）</strong>：样本数量极少（如欺诈交易仅占1%）。</p>
<p>这种问题会导致模型倾向于预测多数类，严重降低少数类的预测性能（如漏检欺诈行为）。以下是详细解释和解决方案：</p>
<p><strong>1. 类别不均衡的影响</strong></p>
<ul>
<li><strong>模型偏差</strong>：模型过度关注多数类，忽略少数类（如将所有样本预测为多数类，准确率虚高）。<br>
</li>
<li><strong>评估指标失效</strong>：准确率（Accuracy）失去意义（例如：99%
的样本是多数类，模型只需预测多数类即可达到 99% 准确率）。</li>
</ul>
<p><strong>2. 解决方案</strong></p>
<p><strong>2.1 数据层面调整</strong></p>
<ul>
<li><strong>过采样（Oversampling）</strong>
<ul>
<li><strong>复制少数类样本</strong>：直接复制少数类数据（可能导致过拟合）。<br>
</li>
<li><strong>生成合成样本</strong>：使用
<strong>SMOTE</strong>（Synthetic Minority Over-sampling
Technique）生成新样本（通过插值法）。<br>
</li>
<li><strong>改进版算法</strong>：如
<strong>ADASYN</strong>（自适应合成采样），根据样本分布动态生成数据。</li>
</ul></li>
<li><strong>欠采样（Undersampling）</strong>
<ul>
<li><strong>随机删除多数类样本</strong>：减少多数类数量，但可能丢失重要信息。<br>
</li>
<li><strong>选择性欠采样</strong>：保留多数类中更具代表性的样本（如
<strong>Tomek Links</strong> 或 <strong>Cluster
Centroids</strong>）。</li>
</ul></li>
<li><strong>混合采样</strong><br>
结合过采样和欠采样（如先过采样少数类，再欠采样多数类）。</li>
</ul>
<p><strong>2.2 算法层面调整</strong></p>
<ul>
<li><strong>调整类别权重（Class Weight）</strong>
<ul>
<li>为少数类分配更高的权重（如
<code>class_weight='balanced'</code>），让模型更关注少数类。<br>
</li>
<li>公式：<br>
[ = ]</li>
</ul></li>
<li><strong>集成学习（Ensemble Methods）</strong>
<ul>
<li><strong>EasyEnsemble</strong>：从多数类中随机采样多个子集，分别与少数类结合训练多个模型，集成结果。<br>
</li>
<li><strong>BalanceCascade</strong>：逐步筛选多数类样本，避免冗余信息。<br>
</li>
<li><strong>RUSBoost</strong>：结合欠采样和提升算法（Boosting）。</li>
</ul></li>
<li><strong>改进损失函数</strong>
<ul>
<li><strong>Focal
Loss</strong>：降低易分类样本的权重，聚焦于难分类的少数类样本。<br>
</li>
<li><strong>Cost-sensitive
Learning</strong>：为不同类别分配不同的误分类代价。</li>
</ul></li>
</ul>
<p><strong>2.3 评估指标调整</strong></p>
<ul>
<li><strong>避免使用准确率（Accuracy）</strong>，改用以下指标：
<ul>
<li><strong>F1-Score</strong>：精确率（Precision）和召回率（Recall）的调和平均。<br>
</li>
<li><strong>AUC-ROC
曲线</strong>：衡量分类器在不同阈值下的整体性能。<br>
</li>
<li><strong>精确率-召回率曲线（PR
Curve）</strong>：关注少数类的识别能力。<br>
</li>
<li><strong>平衡准确率（Balanced
Accuracy）</strong>：计算每个类别的召回率的平均值。</li>
</ul></li>
</ul>
<p><strong>2.4 高级技术</strong></p>
<ul>
<li><p><strong>异常检测（Anomaly Detection）</strong><br>
将少数类视为异常，使用 One-Class SVM 或孤立森林（Isolation
Forest）检测。</p></li>
<li><p><strong>生成对抗网络（GAN）</strong><br>
使用 GAN 生成高质量的少数类样本（如医疗数据中的罕见病样本）。</p></li>
<li><p><strong>阈值调整</strong><br>
根据业务需求调整分类阈值（如将欺诈检测的阈值从 0.5 降低到
0.3）。</p></li>
</ul>
<p><strong>3. 实际应用建议</strong></p>
<ul>
<li><strong>场景举例</strong>：
<ul>
<li><strong>欺诈检测</strong>：少数类（欺诈）样本极少，需使用 SMOTE +
集成学习。<br>
</li>
<li><strong>医疗诊断</strong>：罕见病识别可尝试 GAN
生成数据或异常检测。<br>
</li>
</ul></li>
<li><strong>工具库</strong>：
<ul>
<li>Python 的 <code>imbalanced-learn</code>（提供 SMOTE、EasyEnsemble
等）。<br>
</li>
<li>TensorFlow/PyTorch 中的 <code>class_weight</code> 参数。</li>
</ul></li>
</ul>
<p><strong>总结</strong></p>
<p>类别不均衡的核心是让模型“看到”足够的少数类信息，同时选择合适的评估指标。根据数据特点和业务需求，灵活组合数据采样、算法改进和评估方法，才能有效提升模型对少数类的识别能力。</p>
<h4 id="关于误差逆传播bp算法详细推导e_k对w_hj的导数和对v_ih的导数">关于误差逆传播BP算法，详细推导E_k对w_hj的导数和对v_ih的导数。</h4>
<p>以下是误差逆传播（Backpropagation, BP）算法中误差 ( E_k ) 对权重 (
w_{hj} )（输出层权重）和 ( v_{ih}
)（隐藏层权重）的详细导数推导过程：</p>
<p><strong>符号定义</strong></p>
<ul>
<li><strong>输入层节点</strong>：( <span class="math inline"><em>x</em><sub><em>i</em></sub></span> )（( i = 1,
2, $, n $)）<br>
</li>
<li><strong>隐藏层节点</strong>：( <span class="math inline"><em>b</em><sub><em>h</em></sub></span> )（( h = 1,
2, $, q $)）<br>
</li>
<li><strong>输出层节点</strong>：( <span class="math inline"><em>y</em><sub><em>j</em></sub></span> )（( j = 1,
2,$ , l $)）<br>
</li>
<li><strong>隐藏层到输出层的权重</strong>：( <span class="math inline"><em>w</em><sub><em>h</em><em>j</em></sub></span>
)（从隐藏层节点 ( h ) 到输出层节点 ( j )）<br>
</li>
<li><strong>输入层到隐藏层的权重</strong>：( <span class="math inline"><em>v</em><sub><em>i</em><em>h</em></sub></span>
)（从输入层节点 ( i ) 到隐藏层节点 ( h )）<br>
</li>
<li><strong>激活函数</strong>：假设为 Sigmoid 函数 ($ f(x) = <span class="math inline">$\)，其导数为 \($</span> f’(x) = f(x)(1 - f(x))
$)<br>
</li>
<li><strong>损失函数</strong>：均方误差 ($ E_k = _{j=1}^l (y_j - _j)^2
$)，其中 ( $_j $) 是真实标签。</li>
</ul>
<p><strong>1. 计算 ( $ $)（输出层权重的梯度）</strong></p>
<p><strong>步骤分解</strong>：</p>
<ol type="1">
<li><p><strong>输出层输入</strong>：<br>
[ <span class="math inline">$net_j = \sum_{h=1}^q w_{hj} b_h$</span> ]
输出层节点的激活值为 ( <span class="math inline"><em>y</em><sub><em>j</em></sub> = <em>f</em>(<em>n</em><em>e</em><em>t</em><sub><em>j</em></sub>)</span>
)。</p></li>
<li><p><strong>损失函数对 ( net_j ) 的导数</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial net_j} =
\frac{\partial E_k}{\partial y_j} \cdot \frac{\partial y_j}{\partial
net_j}$</span> ]</p>
<ul>
<li>( <span class="math inline">$\frac{\partial E_k}{\partial y_j} =
(y_j - \hat{y}_j)$</span> )（均方误差导数）<br>
</li>
<li>( $ = f’(net_j) = y_j (1 - y_j) <span class="math inline">$\)（Sigmoid 导数）
因此：
\[$</span> = (y_j - _j) y_j (1 - y_j)$ ]</li>
</ul></li>
<li><p><strong>损失函数对 ( w_{hj} ) 的导数</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial w_{hj}} =
\frac{\partial E_k}{\partial net_j} \cdot \frac{\partial net_j}{\partial
w_{hj}}$</span> ]</p>
<ul>
<li>( <span class="math inline">$\frac{\partial net_j}{\partial w_{hj}}
= b_h$</span> )（因为 ( $net_j = w_{hj} b_h <span class="math inline">$\)）
因此：
\[$</span> = (y_j - _j) y_j (1 - y_j) b_h$ ]</li>
</ul></li>
</ol>
<p><strong>2. 计算 ( $ $)（隐藏层权重的梯度）</strong></p>
<p><strong>步骤分解</strong>：<br>
1. <strong>隐藏层输入</strong>：<br>
[ <span class="math inline">$net_h = \sum_{i=1}^n v_{ih} x_i$</span> ]
隐藏层节点的激活值为 ($ b_h = f(net_h) $)。</p>
<ol start="2" type="1">
<li><strong>损失函数对 ( net_h ) 的导数</strong>：<br>
需要将误差从输出层反向传播到隐藏层：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial net_h} =
\sum_{j=1}^l \left( \frac{\partial E_k}{\partial net_j} \cdot
\frac{\partial net_j}{\partial b_h} \right) \cdot \frac{\partial
b_h}{\partial net_h}$</span> ]
<ul>
<li>($ = w_{hj} $)（输出层输入依赖于隐藏层输出 ( b_h )）<br>
</li>
<li>($ = f’(net_h) = b_h (1 - b_h) <span class="math inline">$\)
因此：
\[$</span> = ( <em>{j=1}^l w</em>{hj} ) b_h (1 - b_h)$ ]</li>
</ul></li>
<li><strong>损失函数对 ( v_{ih} ) 的导数</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial v_{ih}} =
\frac{\partial E_k}{\partial net_h} \cdot \frac{\partial net_h}{\partial
v_{ih}}$</span> ]
<ul>
<li>($ = x_i <span class="math inline">$\)（因为 \($</span> net_h =
v_{ih} x_i <span class="math inline">$）
因此：
\[$</span> = ( <em>{j=1}^l w</em>{hj} ) b_h (1 - b_h) x_i$ ]</li>
</ul></li>
</ol>
<p><strong>3. 最终梯度公式</strong></p>
<ul>
<li><p><strong>输出层权重梯度</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial w_{hj}} =
\delta_j \cdot b_h, \quad \text{其中 } \delta_j = (y_j - \hat{y}_j)
\cdot y_j (1 - y_j)$</span> ]</p></li>
<li><p><strong>隐藏层权重梯度</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial v_{ih}} =
\delta_h \cdot x_i, \quad \text{其中 } \delta_h = \left( \sum_{j=1}^l
\delta_j \cdot w_{hj} \right) \cdot b_h (1 - b_h)$</span> ]</p></li>
</ul>
<p><strong>4. 参数更新规则</strong></p>
<p>使用梯度下降法更新权重：<br>
1. <strong>输出层权重更新</strong>：<br>
[ <span class="math inline">$w_{hj} \leftarrow w_{hj} - \eta \cdot
\frac{\partial E_k}{\partial w_{hj}}$</span> ]</p>
<ol start="2" type="1">
<li><strong>隐藏层权重更新</strong>：<br>
[ <span class="math inline">$v_{ih} \leftarrow v_{ih} - \eta \cdot
\frac{\partial E_k}{\partial v_{ih}}$</span> ] 其中，( $$)
是学习率。</li>
</ol>
<p><strong>关键点总结</strong></p>
<ol type="1">
<li><strong>链式法则</strong>：通过逐层反向传播误差，将全局误差分解为对每个权重的局部梯度。<br>
</li>
<li><strong>敏感度（Delta）</strong>：
<ul>
<li>输出层：($ _j = (y_j - _j) f’(net_j)$ )<br>
</li>
<li>隐藏层：($ _h = ( <em>j w</em>{hj} ) f’(net_h)$ )<br>
</li>
</ul></li>
<li><strong>高效性</strong>：通过存储中间结果（如 ( _j
)），避免重复计算，降低时间复杂度。</li>
</ol>
<p>如果需要进一步解释具体步骤或示例，请随时告诉我！ 😊</p>
<h2 id="参考资料">参考资料</h2>
<p>[<a href="https://www.bilibili.com/video/BV1oY411N7Xz/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">5分钟深度学习]
#01 梯度下降算法_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1zV4y1R7B4/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">反向传播算法可视化展示_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——期末复习（查漏补缺）</title>
    <url>/2025/06/10/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA%EF%BC%89/</url>
    <content><![CDATA[<h3 id="高斯核rbf核中-σ²-的作用及其对模型的影响">高斯核（RBF核）中 σ²
的作用及其对模型的影响</h3>
<p>高斯核（RBF核）的形式为： <span class="math display">$$
K(x, x') = \exp\left(-\frac{\|x - x'\|^2}{2\sigma^2}\right)
$$</span> 其中 $ |x - x’| $ 是两个样本点之间的欧氏距离，$ ^2 $
是高斯核的方差参数，控制核函数的“宽度”或“局部性”。</p>
<p><strong>1. σ² 的几何意义：核函数的“影响范围”</strong></p>
<ul>
<li><p><strong>σ² 较小时</strong>：<br>
分母较小，指数项中的 $ $ 会更大，导致指数函数值快速衰减。<br>
<strong>结果</strong>：只有当 $ x $ 和 $ x’ $
非常接近时，核函数值才接近1；稍远一点的距离会导致核函数值迅速趋近于0。<br>
<strong>直观理解</strong>：模型只关注局部区域内的样本点，决策边界会围绕每个样本点“弯曲”，形成复杂的非线性形状。</p></li>
<li><p><strong>σ² 较大时</strong>：<br>
分母较大，指数项中的 $ $ 会更小，指数函数值衰减缓慢。<br>
<strong>结果</strong>：即使 $ x $ 和 $ x’ $
相距较远，核函数值仍可能较大。<br>
<strong>直观理解</strong>：模型会考虑更大范围的样本点，决策边界更平滑，接近线性分隔。</p></li>
</ul>
<p><strong>2. σ² 如何影响模型的复杂度</strong></p>
<ul>
<li><strong>σ² 小 → 局部敏感，高复杂度</strong>：
<ul>
<li>每个样本点的影响范围有限，模型需要“记住”每个局部区域的细节。<br>
</li>
<li>决策边界会围绕每个样本点剧烈弯曲，甚至形成孤立的环形区域（如图1）。<br>
</li>
<li>容易过拟合：模型过度适应训练数据的噪声和细节。</li>
</ul></li>
<li><strong>σ² 大 → 全局平滑，低复杂度</strong>：
<ul>
<li>样本点的影响范围扩大，模型倾向于用简单的全局模式区分数据。<br>
</li>
<li>决策边界接近线性（如图2），可能无法捕捉数据中的非线性结构。<br>
</li>
<li>容易欠拟合：模型无法拟合数据中的局部特征。</li>
</ul></li>
</ul>
<p><strong>3. 数学与直观示例</strong></p>
<p>假设两个样本点 $ x_1 $ 和 $ x_2 $ 距离为 $ d $，核函数值 $ K(x_1,
x_2) $ 随 $ ^2 $ 的变化如下：</p>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 22%">
<col style="width: 31%">
<col style="width: 32%">
</colgroup>
<thead>
<tr>
<th>$ ^2 $</th>
<th>$ d = 1 $</th>
<th>$ d = 2 $</th>
<th>$ d = 3 $</th>
</tr>
</thead>
<tbody>
<tr>
<td>$ ^2 = 0.1 $</td>
<td>$ (-5) $</td>
<td>$ (-20) ^{-9} $</td>
<td>$ (-45) ^{-20} $</td>
</tr>
<tr>
<td>$ ^2 = 1 $</td>
<td>$ (-0.5) $</td>
<td>$ (-2) $</td>
<td>$ (-4.5) $</td>
</tr>
<tr>
<td>$ ^2 = 10 $</td>
<td>$ (-0.05) $</td>
<td>$ (-0.2) $</td>
<td>$ (-0.45) $</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>σ² 小（如
0.1）</strong>：距离稍大的样本点之间几乎无关联，模型仅依赖极邻近的点做决策。<br>
</li>
<li><strong>σ² 大（如
10）</strong>：即使距离较远的样本点仍有显著关联，模型决策边界更平滑。</li>
</ul>
<h3 id="为什么使用高斯核之前要归一化">为什么使用高斯核之前要归一化</h3>
<p>在使用高斯核（RBF核）之前对数据进行归一化，是机器学习中至关重要的预处理步骤。其核心原因是<strong>高斯核对特征的尺度（scale）极度敏感</strong>，而归一化能消除特征间尺度差异带来的负面影响。以下是详细解释：</p>
<ol type="1">
<li><strong>高斯核的本质依赖距离计算</strong></li>
</ol>
<p>高斯核的公式为： <span class="math display">$$
K(x, x') = \exp\left(-\frac{\|x - x'\|^2}{2\sigma^2}\right)
$$</span> 其中 <span class="math inline">∥<em>x</em> − <em>x</em><sup>′</sup>∥</span>
是两个样本点之间的欧氏距离。<br>
<strong>问题</strong>：欧氏距离的计算受特征尺度影响极大。例如： -
假设特征A的取值范围是 [0,1]，特征B的取值范围是 [0,1000]。 -
此时特征B的差异会主导距离计算（如 $ (0.5)^2 + (500)^2
$），特征A的贡献几乎被忽略。</p>
<p><strong>结果</strong>：模型决策边界会过度依赖尺度大的特征，导致性能下降。</p>
<ol start="2" type="1">
<li><strong>归一化消除特征尺度差异</strong></li>
</ol>
<p>归一化（如标准化或最小-最大缩放）将所有特征调整到相似的数值范围（如
[0,1] 或均值为0、方差为1）。<br>
<strong>效果</strong>： -
<strong>公平比较特征</strong>：每个特征对距离的贡献权重均衡。 -
<strong>防止“大尺度特征主导”</strong>：避免模型因某些特征数值过大而忽略其他重要特征。</p>
<p><strong>示例</strong>：<br>
假设两个样本：<br>
- 未归一化：$ x_1 = [1, 100], x_2 = [2, 200] $，距离为 $ <span class="math inline">。 − <em>归</em><em>一</em><em>化</em><em>后</em>（<em>假</em><em>设</em><em>缩</em><em>放</em><em>到</em>[0, 1]）：</span>
x_1 = [0.1, 0.1], x_2 = [0.2, 0.2] $，距离为 $ $。<br>
此时两个特征的贡献比例从 1:100 变为 1:1。</p>
<ol start="3" type="1">
<li><strong>高斯核参数 σ² 的有效性依赖归一化</strong></li>
</ol>
<p>高斯核的参数 σ²（或 γ =
1/σ²）决定了核函数的“局部性”（即模型关注局部还是全局模式）。<br>
- <strong>未归一化时</strong>：σ²
的选择必须同时适应不同尺度的特征，导致参数调优困难。 -
例如：若某特征尺度极大，需要极小的 σ²
才能捕捉其局部变化，但这可能使其他小尺度特征的核函数失效。 -
<strong>归一化后</strong>：所有特征尺度一致，σ²
的调参只需关注数据整体分布，而非单个特征的尺度。</p>
<h3 id="svm的hinge损失函数">SVM的Hinge损失函数</h3>
<p>Hinge损失函数是支持向量机（SVM）中用于分类任务的核心损失函数，其核心思想是<strong>最大化分类间隔</strong>，同时惩罚分类错误或置信度不足的样本。以下是详细解析：</p>
<p><strong>1. 数学定义</strong></p>
<p>对于二分类问题，假设真实标签 $ y {+1, -1} $，模型输出 $ f(x) = w^T x
+ b <span class="math inline">，<em>则</em> * *<em>H</em><em>i</em><em>n</em><em>g</em><em>e</em><em>损</em><em>失</em> * *<em>的</em><em>定</em><em>义</em><em>为</em>：</span>$
(y, f(x)) = (0, 1 - y f(x)) $$ - <strong>关键含义</strong>： - 当 $ y
f(x) $：样本被正确分类且置信度足够（位于间隔边界外），损失为0。 - 当 $ y
f(x) &lt; 1 $：样本位于间隔内或被错误分类，损失随 $ y f(x) $
线性增长。</p>
<p><strong>2. 几何意义：最大化间隔</strong></p>
<p>Hinge损失的设计与SVM的<strong>硬间隔（Hard
Margin）</strong>和<strong>软间隔（Soft Margin）</strong>目标直接相关：
- <strong>硬间隔</strong>：要求所有样本严格满足 $ y_i (w^T x_i + b)
$，即完全线性可分。 -
<strong>软间隔</strong>：允许部分样本违反间隔约束，通过Hinge损失将约束转化为优化目标：
<span class="math display">$$
  \min_{w,b} \left( \frac{1}{2} \|w\|^2 + C \sum_{i=1}^n \max(0, 1 - y_i
(w^T x_i + b)) \right)
  $$</span> - <strong>第一项</strong> $ |w|^2 $：最大化间隔（间隔宽度与
$ |w| $ 成反比）。 - <strong>第二项</strong>
Hinge损失：惩罚违反间隔约束的样本，$ C $ 控制惩罚强度。</p>
<h3 id="为什么树的数量增加不会导致过拟合">为什么树的数量增加不会导致过拟合？</h3>
<p><strong>核心原因</strong>：随机森林通过<strong>集成学习</strong>和<strong>多样性机制</strong>抑制了单棵决策树的过拟合风险。具体来说：</p>
<ol type="1">
<li><p><strong>Bagging（自助聚合）机制</strong>：<br>
每棵树的训练数据是通过有放回采样（Bootstrap）得到的子集，这意味着每棵树看到的数据略有不同，减少了对训练数据的“记忆”依赖。</p></li>
<li><p><strong>特征随机选择</strong>：<br>
每次分裂节点时，仅从随机选择的特征子集中挑选最优特征，进一步降低了各树之间的相关性。</p></li>
<li><p><strong>投票/平均机制</strong>：<br>
多棵树的预测结果通过投票（分类）或平均（回归）结合，高方差的个体树被平滑，整体模型的泛化能力增强。</p></li>
<li><p><strong>收敛性保证</strong>：<br>
随着树的数量增加，模型性能逐渐收敛到一个稳定值。即使继续增加树的数量，也不会显著提升训练集性能，更不会过拟合。</p></li>
</ol>
<h3 id="欧式距离的特性分析">欧式距离的特性分析</h3>
<p><strong>欧式距离</strong>（Euclidean
Distance）是衡量欧几里得空间中两点之间直线距离的常用方法，其公式为：
<span class="math display">$$
d(x, y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}
$$</span> 以下是对其特性的详细分析：</p>
<p><strong>A. 旋转不变性</strong></p>
<p><strong>正确</strong><br>
- <strong>定义</strong>：若坐标系旋转，两点间的欧式距离保持不变。<br>
- <strong>原因</strong>：旋转是刚性变换（rigid
transformation），仅改变点的坐标表示，但不改变几何距离。<br>
- <strong>示例</strong>：在二维平面中，将坐标系旋转θ角度，两点 <span class="math inline">(<em>x</em><sub>1</sub>, <em>y</em><sub>1</sub>)</span>
和 <span class="math inline">(<em>x</em><sub>2</sub>, <em>y</em><sub>2</sub>)</span>
的旋转后坐标分别为： <span class="math display">(<em>x</em><sub>1<sup>′</sup></sub>, <em>y</em><sub>1<sup>′</sup></sub>) = (<em>x</em><sub>1</sub>cos <em>θ</em> − <em>y</em><sub>1</sub>sin <em>θ</em>, <em>x</em><sub>1</sub>sin <em>θ</em> + <em>y</em><sub>1</sub>cos <em>θ</em>)</span>
<span class="math display">(<em>x</em><sub>2<sup>′</sup></sub>, <em>y</em><sub>2<sup>′</sup></sub>) = (<em>x</em><sub>2</sub>cos <em>θ</em> − <em>y</em><sub>2</sub>sin <em>θ</em>, <em>x</em><sub>2</sub>sin <em>θ</em> + <em>y</em><sub>2</sub>cos <em>θ</em>)</span>
计算旋转后的距离仍等于原始距离。</p>
<p><strong>B. 尺度缩放不变性</strong></p>
<p><strong>错误</strong><br>
-
<strong>定义</strong>：若对坐标轴进行非均匀或均匀缩放，欧式距离会发生变化。<br>
- <strong>反例</strong>：假设对某维特征缩放 <span class="math inline"><em>k</em></span> 倍（如将 <span class="math inline"><em>x</em><sub><em>i</em></sub></span> 变为 <span class="math inline"><em>k</em><em>x</em><sub><em>i</em></sub></span>），则距离变为原来的
<span class="math inline"><em>k</em></span> 倍。<br>
-
<strong>结论</strong>：欧式距离<strong>依赖于特征的绝对尺度</strong>，不具备缩放不变性。</p>
<p><strong>C. 不受量纲影响的特性</strong></p>
<p><strong>错误</strong><br>
-
<strong>定义</strong>：若不同特征的量纲不同（如身高[m]与体重[kg]），欧式距离的计算会因量纲差异而失真。<br>
- <strong>反例</strong>：<br>
- 点A：(1.8m, 70kg)，点B：(1.7m, 65kg)<br>
-
若不标准化，身高差（0.1m）与体重差（5kg）的贡献会被直接相加，但两者量纲不同，结果无实际意义。<br>
-
<strong>解决方法</strong>：需通过标准化（如Z-score归一化）消除量纲影响。</p>
<h3 id="下列哪个不属于特征提取">下列哪个不属于特征提取</h3>
<p><strong>答案：D. 主成分分析</strong></p>
<p><strong>解析：</strong></p>
<p>在文本分类的特征选择中，常用的方法包括：</p>
<ul>
<li><strong>A.
卡方检验值</strong>：通过统计检验评估特征与类别的相关性，属于过滤式特征选择方法。</li>
<li><strong>B.
互信息</strong>：基于信息论，衡量特征与类别的依赖关系，属于无监督或半监督的特征选择方法。</li>
<li><strong>C.
信息增益</strong>：基于熵的指标，评估特征对分类的贡献，常用于决策树等算法中的特征选择。</li>
</ul>
<p>而 <strong>D. 主成分分析（PCA）</strong> 是一种
<strong>降维技术</strong>，通过线性变换将高维数据映射到低维空间，其核心目标是保留数据的主要方差，而非直接选择原始特征。它属于
<strong>特征提取</strong>（Feature Extraction）而非传统意义上的
<strong>特征选择</strong>（Feature
Selection）。因此，主成分分析不属于常用的文本分类特征选择算法。</p>
<p>### ridge回归和lasso回归</p>
<p>Ridge回归（岭回归）和Lasso回归（套索回归）是两种常用的<strong>正则化线性回归方法</strong>，主要用于解决线性回归中的<strong>过拟合问题</strong>和<strong>特征选择问题</strong>。它们的核心思想是在损失函数中添加正则化项（惩罚项），从而限制模型参数的大小，提升模型的泛化能力。</p>
<p><strong>1. Ridge回归（岭回归）</strong></p>
<p><strong>目标函数</strong> <span class="math display">$$
\min_{\mathbf{w}} \left\{ \sum_{i=1}^n (y_i - \mathbf{w}^T
\mathbf{x}_i)^2 + \lambda \|\mathbf{w}\|_2^2 \right\}
$$</span> - 第一项是普通线性回归的均方误差（MSE）。 -
第二项是L2正则化项（权重平方的和），<span class="math inline"><em>λ</em> ≥ 0</span>
是正则化系数，控制惩罚强度。</p>
<p><strong>特点</strong></p>
<ul>
<li><strong>L2正则化</strong>：通过缩小权重系数（但不会完全置零）来减少模型复杂度。</li>
<li><strong>解决多重共线性</strong>：当特征之间存在高度相关性时，Ridge回归能稳定回归系数。</li>
<li><strong>唯一解</strong>：目标函数是凸函数，且严格凸，因此有唯一最优解。</li>
<li><strong>计算效率高</strong>：可以通过解析解（闭式解）求解： <span class="math display"><strong>w</strong><sub>Ridge</sub> = (<strong>X</strong><sup><em>T</em></sup><strong>X</strong> + <em>λ</em><strong>I</strong>)<sup>−1</sup><strong>X</strong><sup><em>T</em></sup><strong>y</strong></span></li>
</ul>
<p><strong>应用场景</strong></p>
<ul>
<li>特征维度较低，但存在多重共线性。</li>
<li>需要保留所有特征，但希望抑制其影响（如基因数据分析）。</li>
</ul>
<p><strong>2. Lasso回归（套索回归）</strong></p>
<p><strong>目标函数</strong> <span class="math display">$$
\min_{\mathbf{w}} \left\{ \sum_{i=1}^n (y_i - \mathbf{w}^T
\mathbf{x}_i)^2 + \lambda \|\mathbf{w}\|_1 \right\}
$$</span> - 第一项是均方误差。 -
第二项是L1正则化项（权重绝对值的和），<span class="math inline"><em>λ</em> ≥ 0</span> 是正则化系数。</p>
<p><strong>特点</strong></p>
<ul>
<li><strong>L1正则化</strong>：强制部分权重系数为零，实现特征选择。</li>
<li><strong>稀疏模型</strong>：适用于高维数据（如文本分类、基因数据），自动筛选关键特征。</li>
<li><strong>非唯一解</strong>：目标函数是凸函数，但可能有多个解（当特征高度相关时）。</li>
<li><strong>计算复杂度较高</strong>：通常需要迭代优化算法（如坐标下降法、近端梯度下降）。</li>
</ul>
<p><strong>应用场景</strong></p>
<ul>
<li>特征维度极高（如万维以上），需降维。</li>
<li>需要可解释性强的模型（如金融风控中的关键特征筛选）。</li>
</ul>
<p><strong>3. 总结</strong></p>
<ul>
<li><strong>Ridge回归</strong>：适合特征较少且需要稳定系数的场景。</li>
<li><strong>Lasso回归</strong>：适合高维数据和特征选择场景。</li>
<li><strong>实际选择</strong>：
<ul>
<li>如果特征数量远大于样本数量（<span class="math inline"><em>p</em> ≫ <em>n</em></span>），优先使用Lasso。</li>
<li>如果特征间存在强相关性，优先使用Ridge或弹性网络。</li>
</ul></li>
</ul>
<p>通过调整正则化系数 <span class="math inline"><em>λ</em></span>，可以控制模型的复杂度与泛化能力。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——知识查漏补缺</title>
    <url>/2025/03/08/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h2 id="pip与conda区别">pip与conda区别</h2>
<p><code>pip</code> 和 <code>conda</code> 都是用来安装和管理 Python
包的工具，但它们的工作方式和适用场景有所不同。以下是它们的主要区别：</p>
<h3 id="包管理的范围">1. <strong>包管理的范围</strong></h3>
<ul>
<li><code>pip</code>：是 Python 官方的包管理工具，只用于安装 Python
包。它从 Python 包索引 (PyPI) 中获取包并安装。这意味着它只能安装 Python
包，不能直接处理其他类型的依赖（如系统库、C 库等）。</li>
<li><code>conda</code>：是一个跨平台的包和环境管理工具，它不仅可以安装
Python 包，还可以安装其他语言（如 R、Java、C++ 等）以及非 Python
依赖（如系统库）。<code>conda</code> 能够管理整个环境（包括 Python
版本和库），并解决与系统库之间的依赖关系。</li>
</ul>
<h3 id="依赖管理">2. <strong>依赖管理</strong></h3>
<ul>
<li><code>pip</code>：在安装包时，<code>pip</code> 仅会安装 Python
包及其 Python 依赖，而不处理系统级依赖。如果一个包依赖于特定的 C
库或其他非 Python 包，<code>pip</code>
不会自动解决这些问题，这可能导致一些复杂的兼容性问题。</li>
<li><code>conda</code>：会同时处理 Python 包和非 Python
包的依赖。它会在安装时自动解决所有依赖，包括操作系统库、C
库等。因此，<code>conda</code> 在依赖关系处理上比 <code>pip</code>
更强大。</li>
</ul>
<h3 id="包来源">3. <strong>包来源</strong></h3>
<ul>
<li><code>pip</code>：通过 PyPI（Python Package
Index）来下载和安装包，PyPI 是一个包含大多数 Python 包的中央库。</li>
<li><code>conda</code>：使用 Anaconda 仓库或其他 conda 仓库。Anaconda
仓库提供了大量的科学计算、数据分析相关的包，而不仅限于 Python 包。conda
还支持安装一些没有在 PyPI 上的包。</li>
</ul>
<h3 id="环境管理">4. <strong>环境管理</strong></h3>
<ul>
<li><code>pip</code>：本身不提供环境管理功能，但可以与
<code>virtualenv</code> 或 <code>venv</code>
等工具结合使用来创建虚拟环境。这些虚拟环境允许你为不同项目隔离依赖。</li>
<li><code>conda</code>：内置环境管理功能，可以通过
<code>conda create</code> 命令直接创建隔离的环境，支持不同版本的 Python
以及其他软件的管理。<code>conda</code> 环境的管理比
<code>pip + virtualenv</code> 更加方便和高效。</li>
</ul>
<h3 id="安装速度">5. <strong>安装速度</strong></h3>
<ul>
<li><code>pip</code>：通常只安装 Python
包。对于某些包，特别是需要从源代码编译的包，安装可能会比较慢，尤其是在没有预编译二进制文件的情况下。</li>
<li><code>conda</code>：由于它使用的是预编译的二进制包，安装速度通常更快，尤其是对于依赖项繁多的包（如
<code>numpy</code>、<code>scipy</code>
等）。它无需从源代码编译，直接安装预编译的版本。</li>
</ul>
<h3 id="跨平台支持">6. <strong>跨平台支持</strong></h3>
<ul>
<li><code>pip</code>：支持所有操作系统，但在一些操作系统（尤其是
Windows）上，安装某些包时可能会遇到编译问题，尤其是 C 扩展包。</li>
<li><code>conda</code>：同样支持多平台，并且在 Windows
系统上安装一些复杂的包（如 <code>numpy</code>、<code>pandas</code>
等）时，比 <code>pip</code>
更加稳定和方便，因为它会自动提供适合平台的预编译二进制文件。</li>
</ul>
<h3 id="包版本冲突">7. <strong>包版本冲突</strong></h3>
<ul>
<li><code>pip</code>：虽然可以安装特定版本的包，但如果项目中的多个包有不同的依赖版本，<code>pip</code>
并不能很好地解决这些版本冲突，需要手动处理依赖版本。</li>
<li><code>conda</code>：在安装时，<code>conda</code>
会自动解析所有的依赖关系，确保包和其依赖的版本兼容，从而减少版本冲突。</li>
</ul>
<h3 id="包更新">8. <strong>包更新</strong></h3>
<ul>
<li><strong><code>pip</code></strong>：更新包的方式通常是直接运行
<code>pip install --upgrade &lt;package&gt;</code>，但是它会仅更新
Python 包本身，不会考虑系统级的依赖。</li>
<li><strong><code>conda</code></strong>：更新包时，<code>conda</code>
会同时考虑包的 Python 依赖和系统库依赖，可以更全面地管理包更新。</li>
</ul>
<h3 id="总结对比表">总结对比表：</h3>
<table>
<colgroup>
<col style="width: 22%">
<col style="width: 33%">
<col style="width: 44%">
</colgroup>
<thead>
<tr>
<th>特性</th>
<th><code>pip</code></th>
<th><code>conda</code></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>包管理范围</strong></td>
<td>只管理 Python 包</td>
<td>管理 Python 包和其他非 Python 包</td>
</tr>
<tr>
<td><strong>依赖关系管理</strong></td>
<td>只处理 Python 依赖</td>
<td>处理 Python 和非 Python 依赖</td>
</tr>
<tr>
<td><strong>包来源</strong></td>
<td>PyPI</td>
<td>Anaconda 仓库等</td>
</tr>
<tr>
<td><strong>环境管理</strong></td>
<td>需配合 <code>virtualenv</code> 使用</td>
<td>内建环境管理</td>
</tr>
<tr>
<td><strong>安装速度</strong></td>
<td>慢（尤其是需要编译的包）</td>
<td>快（使用预编译二进制包）</td>
</tr>
<tr>
<td><strong>跨平台支持</strong></td>
<td>跨平台支持良好</td>
<td>更好的 Windows 支持</td>
</tr>
<tr>
<td><strong>版本冲突处理</strong></td>
<td>手动解决版本冲突</td>
<td>自动解决版本冲突</td>
</tr>
</tbody>
</table>
<h3 id="什么时候使用-pip什么时候使用-conda">什么时候使用
<code>pip</code>，什么时候使用 <code>conda</code>？</h3>
<ul>
<li>如果你已经在使用 Anaconda 或 Miniconda，并且需要安装 Python
包及其相关依赖，<code>conda</code>
是更好的选择，因为它可以自动解决依赖并更好地管理环境。</li>
<li>如果你没有使用 Anaconda 或只需要安装纯粹的 Python
包，<code>pip</code> 更为轻量和直接。</li>
</ul>
<p>在实际使用中，有时你会发现两者可以结合使用：可以用 <code>conda</code>
安装 Python 环境和一些复杂的依赖，再用 <code>pip</code> 安装一些不在
Anaconda 仓库中的包。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——绪论</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[<h3 id="正文">正文</h3>
<figure>
<img src="/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%AA%E8%AE%BA/QQ20250320-191604.png" alt="QQ20250320-191604">
<figcaption aria-hidden="true">QQ20250320-191604</figcaption>
</figure>
<h3 id="参考文章">参考文章</h3>
<p><a href="https://blog.csdn.net/lhxez6868/article/details/108150777">准确度(accuracy)、精确率（precision)、召回率（recall）、F1值
谈谈我的看法_recall f1-CSDN博客</a></p>
<p>南瓜书在线阅读：https://datawhalechina.github.io/pumpkin-book/#/</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数字图像处理</title>
    <url>/2025/09/28/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h3 id="正变换逆变换与逆向映射法">正变换，逆变换与逆向映射法</h3>
<h4 id="正变换forward-mapping">正变换（Forward Mapping）：</h4>
<ul>
<li>思路：遍历原图每个像素 <code>(x, y)</code> → 计算它在新图中的位置
<code>(u, v)</code></li>
<li>问题：
<ul>
<li><code>(u, v)</code> 很可能是非整数坐标（如
<code>(123.7, 45.2)</code>）</li>
<li>无法直接赋值给新图的整数像素位置</li>
<li>即使四舍五入，也会导致：
<ul>
<li><strong>空洞</strong>：某些新图像素从未被赋值 → 黑色或空白</li>
<li><strong>重叠</strong>：多个原图像素映射到同一新图像素 →
颜色混合或丢失</li>
</ul></li>
</ul></li>
</ul>
<h3 id="图像插值方法interpolation-methods"><strong>图像插值方法</strong>（Interpolation
Methods）</h3>
<p>当你对图像做以下操作时，就需要插值：</p>
<ul>
<li><strong>放大（zoom in）</strong>：像素变多，新像素值从哪来？</li>
<li><strong>缩小（zoom out）</strong>：像素变少，如何保留信息？</li>
<li><strong>旋转、仿射变换、透视变换</strong>：目标像素位置可能落在原图两个像素之间，需要“估算”颜色。</li>
</ul>
<p>插值就是<strong>估算非整数坐标处像素值的方法</strong>。</p>
<h4 id="最近邻插值nearest-neighbor">最近邻插值（Nearest Neighbor）</h4>
<ul>
<li><strong>原理</strong>：新像素的值 =
<strong>离它最近的原图像素值</strong></li>
<li><strong>计算</strong>：不计算！直接“抄最近的”</li>
<li><strong>特点</strong>：
<ul>
<li>⚡ 速度最快</li>
<li>🧱 放大后有明显“马赛克”或“锯齿”（blocky / jagged）</li>
<li>❌ 不适合高质量图像处理</li>
</ul></li>
</ul>
<h4 id="双线性插值bilinear-interpolation">双线性插值（Bilinear
Interpolation）</h4>
<ul>
<li><strong>原理</strong>：在 <strong>2×2
邻域</strong>（4个像素）内，<strong>先水平插值，再垂直插值</strong></li>
<li><strong>计算</strong>：加权平均（距离越近，权重越大）</li>
<li><strong>特点</strong>：
<ul>
<li>⏱ 速度较快</li>
<li>🌫 图像变“柔和”，边缘轻微模糊</li>
<li>✅ 是<strong>默认的 resize 插值方法</strong>（OpenCV 默认值）</li>
</ul></li>
</ul>
<blockquote>
<p>🖼 举例（1D 简化）： 原值：A=100（位置0），B=200（位置1） 在 0.3
处插值 → <code>100×(1−0.3) + 200×0.3 = 130</code> 2D
就是两次这样的操作（x方向 + y方向）</p>
</blockquote>
<h4 id="双三次插值bicubic-interpolation">双三次插值（Bicubic
Interpolation）</h4>
<ul>
<li><strong>原理</strong>：在 <strong>4×4
邻域</strong>（16个像素）内，用<strong>三次多项式</strong>拟合曲面</li>
<li><strong>计算</strong>：复杂，涉及更多像素和权重函数（常用
Catmull-Rom 样条）</li>
<li><strong>特点</strong>：
<ul>
<li>🐢 速度较慢（约是 bilinear 的 4~8 倍）</li>
<li>🔍 边缘更锐利，细节保留更好</li>
<li>⚠️ 可能产生“过冲”（overshoot）：边缘出现亮/暗 halo（光晕）</li>
</ul></li>
</ul>
<h3 id="图像逻辑运算">图像逻辑运算</h3>
<h3 id="单尺度和多尺度retinex增强方法实现图像增强">单尺度和多尺度Retinex增强方法实现图像增强</h3>
<p>图像模板运算</p>
]]></content>
      <categories>
        <category>大三上</category>
        <category>数字图像处理</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>数字图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——线性模型</title>
    <url>/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="正文">正文</h2>
<h3 id="极大似然估计">极大似然估计</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200047048.png" alt="image-20250320200047048">
<figcaption aria-hidden="true">image-20250320200047048</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200109835.png" alt="image-20250320200109835">
<figcaption aria-hidden="true">image-20250320200109835</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200139754.png" alt="image-20250320200139754">
<figcaption aria-hidden="true">image-20250320200139754</figcaption>
</figure>
<h2 id="作业">作业</h2>
<h3 id="何为正则化其功能是什么如何理解l1和l2正则化">1、何为正则化？其功能是什么？如何理解L1和L2正则化？</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250320_170100.jpg" alt="IMG_20250320_170100">
<figcaption aria-hidden="true">IMG_20250320_170100</figcaption>
</figure>
<h3 id="什么是偏差与方差简要说明偏差方差与过拟合欠拟合的关系">2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。</h3>
<table>
<colgroup>
<col style="width: 6%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 44%">
<col style="width: 40%">
</colgroup>
<thead>
<tr>
<th>现象</th>
<th>偏差</th>
<th>方差</th>
<th>典型原因</th>
<th>解决方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>欠拟合</td>
<td>高</td>
<td>低</td>
<td>模型过于简单（如线性模型拟合非线性数据）</td>
<td>增加特征、使用更复杂模型、减少正则化</td>
</tr>
<tr>
<td>过拟合</td>
<td>低</td>
<td>高</td>
<td>模型过于复杂（如深度树模型拟合噪声）</td>
<td>增加数据、正则化、简化模型、早停法</td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250320_181442.jpg" alt="IMG_20250320_181442">
<figcaption aria-hidden="true">IMG_20250320_181442</figcaption>
</figure>
<h3 id="公式推导最小二乘法多元线性回归与岭回归逻辑回归极大似然法">3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163937.jpg" alt="IMG_20250321_163937">
<figcaption aria-hidden="true">IMG_20250321_163937</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163941.jpg" alt="IMG_20250321_163941">
<figcaption aria-hidden="true">IMG_20250321_163941</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163944.jpg" alt="IMG_20250321_163944">
<figcaption aria-hidden="true">IMG_20250321_163944</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163948.jpg" alt="IMG_20250321_163948">
<figcaption aria-hidden="true">IMG_20250321_163948</figcaption>
</figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1Z44y147xA/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">“L1和L2正则化”直观理解(之一)，从拉格朗日乘数法角度进行理解_哔哩哔哩_bilibili</a></p>
<p>超级棒的公式证明，对我帮助很大</p>
<p>https://www.bilibili.com/video/BV1Mh411e7VU?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=3&amp;spm_id_from=333.788.videopod.episodes</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——Python常用库</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Python%E5%B8%B8%E7%94%A8%E5%BA%93/</url>
    <content><![CDATA[<h2 id="python常用库">Python常用库</h2>
<h3 id="numpy">1. Numpy</h3>
<p>numpy（Numerical
Python的简称）是高性能科学计算和数据分析的基础包。其部分功能如下：</p>
<p>ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。
用于对整组数据进行快速运算的标准数学函数（无需编写循环）。
用于读写磁盘数据的工具以及用于操作内存映射文件的工具。
线性代数、随机数生成以及傅里叶变换功能。
用于集成由C、C++、Fortran等语言编写的代码的工具。</p>
<h3 id="pandas">2. Pandas</h3>
<p>pandas是python第三方库，提供高性能易用数据类型和分析工具
pandas基于numpy实现，常与numpy和matplotlib一同使用
pandas中有两大核心数据结构：Series（一维数据） 和
DataFrame（多特征数据,既有行索引,又有列索引）</p>
<h3 id="pil">3. PIL</h3>
<p>PIL库是一个具有强大图像处理能力的第三方库 在命令行下的安装方法：pip
install pillow 在使用过程中的引入方法：from PIL import Image Image 是
PIL 库中代表一个图像的类（对象）
图像是一个由像素组成的二维矩阵，每个元素是一个RGB值</p>
<h3 id="matplotlib">4. Matplotlib</h3>
<p>Matplotlib库由各种可视化类构成，内部结构复杂。
受Matlab启发，matplotlib.pylot是绘制各类可视化图形的命令字库，相当于快捷方式。</p>
<h3 id="scikit-learn">5. scikit-learn</h3>
<p><code>scikit-learn</code>（简称 <code>sklearn</code>）是一个开源的
Python
库，广泛应用于机器学习任务，提供了丰富的工具和算法，能够帮助数据科学家和机器学习工程师高效地进行数据预处理、模型训练、评估和优化。它基于
<code>NumPy</code>、<code>SciPy</code> 和
<code>matplotlib</code>，具有以下主要特点和功能：</p>
<h4 id="主要功能"><strong>主要功能</strong>：</h4>
<ul>
<li><strong>分类 (Classification)</strong>
：用于预测数据点所属的类别（如垃圾邮件分类、疾病预测等）。</li>
<li><strong>回归 (Regression)</strong>
：用于预测连续的数值（如房价预测、股票价格预测等）。</li>
<li><strong>聚类 (Clustering)</strong>
：将数据点分为不同的簇或组（如客户细分、图像分割等）。</li>
<li><strong>降维 (Dimensionality Reduction)</strong>
：减少数据的维度，常用于数据压缩和可视化。</li>
<li><strong>模型评估 (Model Evaluation)</strong>
：提供评估工具，如交叉验证、准确率、F1 分数等。</li>
<li><strong>数据预处理 (Data Preprocessing)</strong>
：包括标准化、归一化、缺失值处理、编码等。</li>
<li><strong>超参数调优 (Hyperparameter Tuning)</strong>
：通过网格搜索（GridSearchCV）和随机搜索（RandomizedSearchCV）来优化模型超参数。</li>
</ul>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库大作业——工厂管理系统复盘</title>
    <url>/2025/12/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%A4%A7%E4%BD%9C%E4%B8%9A/</url>
    <content><![CDATA[<h2 id="介绍">介绍</h2>
<p>FastAPI + Supabase 后端，React + Ant Design
前端的工厂管理系统。包含零件、供应商、仓库、员工、库存、采购、用户权限等模块，支持
Supabase Auth 鉴权和业务角色控制。</p>
<h2 id="后端结构">后端结构</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- backend/</span><br><span class="line">  - main.py：FastAPI 入口，注册各路由</span><br><span class="line">  - api/：业务路由（factory 模块、auth、users 等）</span><br><span class="line">  - services/：业务服务、鉴权依赖</span><br><span class="line">  - schemas/：Pydantic 模型</span><br><span class="line">  - src/db/：SQLAlchemy 模型、数据库工具、DDL/示例数据文档</span><br><span class="line">  - docs/：后端设计文档</span><br></pre></td></tr></table></figure>
<h2 id="鉴权功能实现解析">鉴权功能实现解析</h2>
]]></content>
      <categories>
        <category>大三上</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>matlab与opencv基本操作</title>
    <url>/2025/09/15/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/matlab%E4%B8%8Eopencv/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>本文讲解matlab<del>与opencv</del>对图像处理的基础操作，代码会有matlab<del>与python两版</del>，可对比学习。</p>
<h3 id="读写">读写</h3>
<h4 id="读入图像">读入图像</h4>
<p>matlab</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">I = imread(<span class="string">&#x27;cameraman.jpg&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>python</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">I = cv2.imread(&#x27;cameraman.jpg&#x27;, cv2.IMREAD_COLOR)</span><br></pre></td></tr></table></figure>
<p><strong><code>cv2.IMREAD_COLOR</code> = 强制读成 3 通道 BGR
彩色图。</strong></p>
<h4 id="存入图像">存入图像</h4>
<p>matlab</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">imwrite(J,&#x27;cameramanC.jpg&#x27;);</span><br></pre></td></tr></table></figure>
<p>python</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cv2.imwrite(&#x27;cameramanC.jpg&#x27;, J)</span><br></pre></td></tr></table></figure>
<h4 id="读图并转-double">读图并转 double</h4>
<p>matlab</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Image1 = im2double(imread(&#x27;lotus.jpg&#x27;));</span><br></pre></td></tr></table></figure>
<ul>
<li><code>imread</code> 把图像读成 0-255 的 <code>uint8</code>。</li>
<li><code>im2double</code> 把像素值线性缩放到 <strong>0–1
浮点</strong>，方便后续计算。</li>
</ul>
<blockquote>
<p>为什么要转成double</p>
<p>如果像素是 0–255，你在代码里写 <code>0.299*r</code> 就永远只用到
0.299×255≈76 灰度级，结果会整体偏暗甚至直接截断。</p>
<p>几级灰度的含义是什么</p>
<p><strong>几级灰度</strong>”这句话里的“级”就是“<strong>台阶</strong>”的意思：
把黑→白这段连续亮度等间隔切成多少份，就有多少个离散台阶，叫多少<strong>灰度级</strong>。</p>
<ul>
<li>2 级灰度 → 纯黑 + 纯白，一共 2 个台阶（1 bit）</li>
<li>8 级灰度 → 0, 36, 73, 109, 146, 182, 219, 255（3 bit）</li>
<li>256 级灰度 → 0–255，共 256 个台阶（8 bit）</li>
</ul>
<p><code>uint8</code> 是“<strong>Unsigned Integer, 8
bit</strong>”的缩写，含义一句话：</p>
<blockquote>
<p><strong>无符号、8 位、整型数字，只能放 0–255 的整数。</strong></p>
</blockquote>
</blockquote>
<h3 id="图像操作">图像操作</h3>
<h4 id="反色">反色</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">J=255-I;</span><br></pre></td></tr></table></figure>
<h4 id="提取通道">提取通道</h4>
<p>matlab</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">r = Image1(:,:,1);</span><br><span class="line">g = Image1(:,:,2);</span><br><span class="line">b = Image1(:,:,3);</span><br></pre></td></tr></table></figure>
<p>分别提取rgb三个通道</p>
<p>opencv</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">matlab:g = Image1(1,1,2)提取G通道的第一个像素点</span><br><span class="line">opencv:g = image[0,0,1]</span><br></pre></td></tr></table></figure>
<p>opencv是从下标0开始</p>
<h4 id="合并通道">合并通道</h4>
<p>NTSC 标准</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Y = 0.299*r + 0.587*g + 0.114*b;</span><br></pre></td></tr></table></figure>
<p><strong>0.299、0.587、0.114 是 NTSC 在 1953
年定下的“亮度加权系数”，源于人眼三种视锥细胞对 R、G、B
光谱的灵敏度——绿最亮、红次之、蓝最暗</strong></p>
<h4 id="二值化阈值-0.3">二值化（阈值 0.3）</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BW = zeros(size(Y));   % 先全黑</span><br><span class="line">BW(Y &gt; 0.3) = 1;       % 亮度&gt;0.3 的像素置 1（白）</span><br></pre></td></tr></table></figure>
<h4 id="从rgb颜色空间转换成hsi颜色空间">从RGB颜色空间转换成HSI颜色空间</h4>
<p>matlab</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hsi = rgb2hsv(img);</span><br></pre></td></tr></table></figure>
<p>HSI 颜色空间是把一幅彩色图像的<strong>每个像素</strong>拆成 3
个独立、且更符合人眼感知习惯的物理量：</p>
<ol type="1">
<li>H（Hue，色调） 用 0°–360° 的“角度”表示“到底是什么颜色”。
例：0°≈红，120°≈绿，240°≈蓝，绕一圈回到红。</li>
<li>S（Saturation，饱和度） 0–1（或 0–100%）表示“颜色有多鲜艳”。 0 →
灰，1 → 最纯、最艳。</li>
<li>I（Intensity，亮度/强度） 0–1（或
0–255）表示“有多亮”，与颜色本身无关，只反映明暗。</li>
</ol>
<ul>
<li>RGB 是“机器友好”的立方体坐标，但人眼很难从 (R,G,B)
直接说出“颜色、多艳、多亮”。</li>
</ul>
<h3 id="matlab基本操作">matlab基本操作</h3>
<h4 id="获取图像行列和通道数">获取图像行列和通道数</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[N,M,~]=size(r);</span><br></pre></td></tr></table></figure>
<p><strong>把二维矩阵 <code>r</code> 的“行数”赋给
<code>N</code>，“列数”赋给 <code>M</code>。</strong></p>
<h4 id="截取图像">截取图像</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">newimage=img(H/4:H*3/4,W/4:W*3/4,:);</span><br></pre></td></tr></table></figure>
<h3 id="人脸肤色检测">人脸肤色检测</h3>
<h4 id="ycrcb-阈值法">YCrCb 阈值法</h4>
<ol type="1">
<li><p>Y “Luma”——<strong>亮度</strong>（Luminance）。
对应人眼最敏感的黑↔︎白信息，决定了你看到的“明暗”。 计算公式近似：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Y = 0.299·R + 0.587·G + 0.114·B</span><br></pre></td></tr></table></figure></li>
<li><p>Cr “Chroma-red”——<strong>红色色度</strong>。 表示
<strong>红色与亮度的差值</strong>：<code>Cr = R – Y</code></p></li>
<li><p>Cb “Chroma-blue”——<strong>蓝色色度</strong>。 表示
<strong>蓝色与亮度的差值</strong>：<code>Cb = B – Y</code></p></li>
</ol>
<p>人眼对 <strong>绿色最敏感</strong>，对
<strong>红、蓝最迟钝</strong>。 把“绿色”信息扔掉，只保留
<strong>R-Y</strong> 和 <strong>B-Y</strong> 两个差值，就能
<strong>最小化数据量</strong>，同时
<strong>还能把颜色还原回来</strong>。</p>
<ul>
<li>人类肤色在 YCrCb 颜色空间呈明显的“聚类”特性：无论人种如何，Cb、Cr
两个色度分量都落在狭长带状区域。</li>
<li>选取经验区间（Cr ∈ [133,173]，Cb ∈ [77,127]）直接做 2D 门限，亮度 Y
不参与判断，因此对光照强度变化不敏感，但对色偏敏感。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def skin_YCrCb(img):</span><br><span class="line">    #把一张 BGR 彩色图像从“蓝-绿-红”颜色空间转换到“亮度-红度-蓝度”颜色空间（YCrCb）</span><br><span class="line">    ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)</span><br><span class="line">    min_YCrCb = np.array([0, 133, 77])</span><br><span class="line">    max_YCrCb = np.array([255, 173, 127])</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">把落在 [min_YCrCb, max_YCrCb] 立方体内的像素标为 255（白），其余标为 0（黑），返回一张单通道掩膜图。</span><br><span class="line">执行过程（逐像素）：</span><br><span class="line">取 ycrcb 的一个像素 (y, cr, cb)</span><br><span class="line">检查是否同时满足</span><br><span class="line">min_Y ≤ y ≤ max_Y</span><br><span class="line">min_Cr ≤ cr ≤ max_Cr</span><br><span class="line">min_Cb ≤ cb ≤ max_Cb</span><br><span class="line">满足 → 输出 255；任一通道不满足 → 输出 0</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    skin = cv2.inRange(ycrcb, min_YCrCb, max_YCrCb)</span><br><span class="line">    return skin</span><br></pre></td></tr></table></figure>
<h4 id="hsv-阈值法">HSV 阈值法</h4>
<p>肤色聚类现象 大量统计表明：</p>
<ul>
<li><strong>不同人种、不同光照</strong> 的肤色在 RGB
空间里沿对角线“灰度轴”散开 → 亮度影响大。</li>
<li>转到 HSV 后，<strong>Hue 坐标紧紧挤在 0-20°
之间</strong>（红-橙-黄），<strong>S 中等偏高</strong>，<strong>V
中等偏亮</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def skin_HSV(img):</span><br><span class="line">    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)</span><br><span class="line">    low  = np.array([0,  30,  60])</span><br><span class="line">    high = np.array([20, 150, 255])</span><br><span class="line">    skin = cv2.inRange(hsv, low, high)</span><br><span class="line">    return skin</span><br></pre></td></tr></table></figure>
<h4 id="椭圆模型法">椭圆模型法</h4>
<p>原理：将RGB图像转换到YCRCB空间，肤色像素点会聚集到一个椭圆区域。先定义一个椭圆模型，然后将每个RGB像素点转换到YCRCB空间比对是否再椭圆区域，是的话判断为皮肤。</p>
<figure>
<img src="/2025/09/15/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/matlab%E4%B8%8Eopencv/image-20250923091302411.png" alt="image-20250923091302411">
<figcaption aria-hidden="true">image-20250923091302411</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ---------------- 3. 椭圆模型法 ----------------</span><br><span class="line">def skin_ellipse(img):</span><br><span class="line">    ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)</span><br><span class="line">    # 如果本地没有模型图，现场画一张 256×256 查找表</span><br><span class="line">    ellipse_model = cv2.imread(&#x27;ellipse_skin_model.png&#x27;, 0)</span><br><span class="line">    if ellipse_model is None:</span><br><span class="line">        ellipse_model = np.zeros((256, 256), dtype=np.uint8)</span><br><span class="line">        cv2.ellipse(ellipse_model, (113, 155), (23, 15),</span><br><span class="line">                    43, 0, 360, 255, -1)</span><br><span class="line">    cr = ycrcb[:, :, 1].astype(np.uint16)  # 防止溢出</span><br><span class="line">    cb = ycrcb[:, :, 2].astype(np.uint16)</span><br><span class="line">    indices = cr * 256 + cb</span><br><span class="line">    skin = np.take(ellipse_model, indices)</span><br><span class="line">    return skin</span><br></pre></td></tr></table></figure>
<h3 id="将彩色图像-image1-的-rb-通道互换">将彩色图像 Image1 的 R、B
通道互换</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">img_swap = img(:,:,[3 1 2]);</span><br></pre></td></tr></table></figure>
<p>在 <strong>MATLAB</strong> 中，读取彩色图像（如用
<code>imread</code>）默认是 <strong>RGB 顺序</strong>：</p>
<ul>
<li>第1通道：Red（红）</li>
<li>第2通道：Green（绿）</li>
<li>第3通道：Blue（蓝）</li>
</ul>
<p>但在 <strong>OpenCV（Python/C++）</strong> 中，图像默认是 <strong>BGR
顺序</strong>：</p>
<ul>
<li>第1通道：Blue</li>
<li>第2通道：Green</li>
<li>第3通道：Red</li>
</ul>
<h3 id="使用或操作进行图像的嵌入">使用或操作，进行图像的嵌入</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clear; clc; close all;  % 清空所有变量</span><br><span class="line">% 读取两张图片</span><br><span class="line">background = imread(&#x27;图片2.png&#x27;);   </span><br><span class="line">butterfly = imread(&#x27;图片1.png&#x27;);  </span><br><span class="line"></span><br><span class="line">% 设置缩放比例</span><br><span class="line">scale = 0.5;</span><br><span class="line">small_butterfly = imresize(butterfly, scale, &#x27;bilinear&#x27;);</span><br><span class="line"></span><br><span class="line">% 获取尺寸</span><br><span class="line">[ih, iw, ~] = size(small_butterfly);</span><br><span class="line">x = 200; y = 400;</span><br><span class="line"></span><br><span class="line">% 提取背景中对应区域</span><br><span class="line">bg_patch = background(x:x+ih-1, y:y+iw-1, :);</span><br><span class="line"></span><br><span class="line">is_black = any(small_butterfly~=0,3);   % 蝴蝶主体区域</span><br><span class="line"></span><br><span class="line">%只把背景中“蝴蝶主体对应位置”设为 0</span><br><span class="line">% 获取尺寸</span><br><span class="line">[ih, iw, ~] = size(bg_patch);</span><br><span class="line"></span><br><span class="line">% 双重循环遍历每个像素</span><br><span class="line">for i = 1:ih</span><br><span class="line">    for j = 1:iw</span><br><span class="line">        if is_black(i, j)   % 如果该位置是蝴蝶主体（非黑）</span><br><span class="line">            bg_patch(i, j, 1) = 0;  % R 通道设为 0</span><br><span class="line">            bg_patch(i, j, 2) = 0;  % G 通道设为 0</span><br><span class="line">            bg_patch(i, j, 3) = 0;  % B 通道设为 0</span><br><span class="line">        end</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">%现在做 bitor：0 | butterfly = butterfly，背景黑区 | 0 = 背景</span><br><span class="line">patch_bitor = bitor(bg_patch, small_butterfly);</span><br><span class="line"></span><br><span class="line">% 写回背景</span><br><span class="line">background(x:x+ih-1, y:y+iw-1, :) = patch_bitor;</span><br><span class="line"></span><br><span class="line">% 显示结果</span><br><span class="line">figure;</span><br><span class="line">subplot(1,3,1), imshow(small_butterfly), title([&#x27;缩小后的蝴蝶 (&#x27;, num2str(scale*100), &#x27;%)&#x27;]);</span><br><span class="line">subplot(1,3,2), imshow(bg_patch), title(&#x27;处理后的背景块（蝴蝶位置清黑）&#x27;);</span><br><span class="line">subplot(1,3,3), imshow(background), title(&#x27;最终合成图（bitor）&#x27;);</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/09/15/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/matlab%E4%B8%8Eopencv/image-20251016114415946.png" alt="image-20251016114415946">
<figcaption aria-hidden="true">image-20251016114415946</figcaption>
</figure>
<h3 id="利用单尺度和多尺度-retinex-增强方法实现图像增强">利用单尺度和多尺度
Retinex 增强方法实现图像增强</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">I = imread(&#x27;gugong1.jpg&#x27;);</span><br><span class="line"></span><br><span class="line">if ndims(I) == 3</span><br><span class="line">    I_gray = rgb2gray(I);</span><br><span class="line">else</span><br><span class="line">    I_gray = I;</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">I_double = double(I_gray) + eps;</span><br><span class="line"></span><br><span class="line">% SSR</span><br><span class="line">sigma = 15;</span><br><span class="line">L_ssr = log(conv2(I_double, fspecial(&#x27;gaussian&#x27;, [31, 31], sigma), &#x27;same&#x27;));</span><br><span class="line">R_ssr = log(I_double) - L_ssr;</span><br><span class="line">ssr_img = mat2gray(R_ssr);</span><br><span class="line"></span><br><span class="line">% MSR</span><br><span class="line">sigmas = [15, 80, 250];</span><br><span class="line">weights = [0.33, 0.34, 0.33];</span><br><span class="line">R_msr = zeros(size(I_double));</span><br><span class="line">for k = 1:length(sigmas)</span><br><span class="line">    sigma = sigmas(k);</span><br><span class="line">    kernel_size = round(6 * sigma) + 1;</span><br><span class="line">    if mod(kernel_size, 2) == 0</span><br><span class="line">        kernel_size = kernel_size + 1;</span><br><span class="line">    end</span><br><span class="line">    L = log(conv2(I_double, fspecial(&#x27;gaussian&#x27;, [kernel_size, kernel_size], sigma), &#x27;same&#x27;));</span><br><span class="line">    R_msr = R_msr + weights(k) * (log(I_double) - L);</span><br><span class="line">end</span><br><span class="line">msr_img = mat2gray(R_msr);</span><br><span class="line"></span><br><span class="line">figure;</span><br><span class="line">subplot(1,3,1); imshow(I); title(&#x27;Original&#x27;);</span><br><span class="line">subplot(1,3,2); imshow(ssr_img); title(&#x27;SSR&#x27;);</span><br><span class="line">subplot(1,3,3); imshow(msr_img); title(&#x27;MSR&#x27;);</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/09/15/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/matlab%E4%B8%8Eopencv/image-20251104095521796.png" alt="image-20251104095521796">
<figcaption aria-hidden="true">image-20251104095521796</figcaption>
</figure>
<h3 id="直方图均衡化计算"><strong>直方图均衡化计算</strong></h3>
<figure>
<img src="/2025/09/15/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/matlab%E4%B8%8Eopencv/image-20251112090645146.png" alt="image-20251112090645146">
<figcaption aria-hidden="true">image-20251112090645146</figcaption>
</figure>
<figure>
<img src="/2025/09/15/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/matlab%E4%B8%8Eopencv/image-20251112090723928.png" alt="image-20251112090723928">
<figcaption aria-hidden="true">image-20251112090723928</figcaption>
</figure>
<figure>
<img src="/2025/09/15/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/matlab%E4%B8%8Eopencv/image-20251112090714359.png" alt="image-20251112090714359">
<figcaption aria-hidden="true">image-20251112090714359</figcaption>
</figure>
<p>5.4代码</p>
<p>opencv</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"># --- Step 1: 构造原始图像 ---</span><br><span class="line">gray_levels = np.array([0, 1/7, 2/7, 3/7, 4/7, 5/7, 6/7, 1])  # 原始灰度值 (0~1)</span><br><span class="line">pixel_counts = np.array([560, 920, 1046, 705, 356, 267, 170, 72])</span><br><span class="line">total_pixels = 64 * 64  # 4096</span><br><span class="line"></span><br><span class="line"># 将灰度值映射到整数 0~7 用于图像存储</span><br><span class="line">int_gray_levels = np.round(gray_levels * 7).astype(int)  # [0,1,2,3,4,5,6,7]</span><br><span class="line"></span><br><span class="line"># 创建图像数组</span><br><span class="line">img = np.zeros(total_pixels, dtype=np.uint8)</span><br><span class="line"></span><br><span class="line">start_idx = 0</span><br><span class="line">for i, count in enumerate(pixel_counts):</span><br><span class="line">    img[start_idx:start_idx + count] = int_gray_levels[i]</span><br><span class="line">    start_idx += count</span><br><span class="line"></span><br><span class="line">img = img.reshape((64, 64))  # 重塑为 64x64 图像</span><br><span class="line"></span><br><span class="line"># --- Step 2: 直方图均衡化 ---</span><br><span class="line">hist, _ = np.histogram(img, bins=8, range=(0, 8))</span><br><span class="line">cdf = np.cumsum(hist) / total_pixels</span><br><span class="line">mapping = np.round(cdf * 7).astype(int)</span><br><span class="line">equalized_img = mapping[img]</span><br><span class="line"></span><br><span class="line"># --- Step 3: 可视化对比 ---</span><br><span class="line">plt.figure(figsize=(8, 4))</span><br><span class="line"></span><br><span class="line">plt.subplot(1, 2, 1)</span><br><span class="line">plt.imshow(img, cmap=&#x27;gray&#x27;, vmin=0, vmax=7)</span><br><span class="line">plt.title(&#x27;Original&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line"></span><br><span class="line">plt.subplot(1, 2, 2)</span><br><span class="line">plt.imshow(equalized_img, cmap=&#x27;gray&#x27;, vmin=0, vmax=7)</span><br><span class="line">plt.title(&#x27;Equalized&#x27;)</span><br><span class="line">plt.axis(&#x27;off&#x27;)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大三上</category>
        <category>数字图像处理</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>数字图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>数据挖掘</title>
    <url>/2025/09/21/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</url>
    <content><![CDATA[<h3 id="认识数据">认识数据</h3>
<h4 id="数据的属性">数据的属性</h4>
<table>
<colgroup>
<col style="width: 21%">
<col style="width: 29%">
<col style="width: 49%">
</colgroup>
<thead>
<tr>
<th>属性类型</th>
<th>定义</th>
<th>举例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>标称属性 (Nominal)</strong></td>
<td>仅用于区分不同类别，无顺序关系</td>
<td>性别（男/女）、颜色（红/绿/蓝）</td>
</tr>
<tr>
<td><strong>二元属性 (Binary)</strong></td>
<td>仅有两个类别的标称属性</td>
<td>是否存活（是/否）、性别（男/女）</td>
</tr>
<tr>
<td><strong>序数属性 (Ordinal)</strong></td>
<td>类别之间存在明确的顺序关系</td>
<td>教育水平（小学/中学/大学）、舱位等级（1等/2等/3等）</td>
</tr>
<tr>
<td><strong>数值属性 (Numeric)</strong></td>
<td>可度量的数值，可进行数学运算</td>
<td>年龄、票价</td>
</tr>
</tbody>
</table>
<h4 id="数据相似度的计算方法">数据相似度的计算方法</h4>
<h3 id="关联分析算法">关联分析算法</h3>
<h3 id="频繁项集">频繁项集</h3>
<h4 id="apriori算法">apriori算法</h4>
<h4 id="fp-growth">fp-growth</h4>
<p><a href="https://www.bilibili.com/video/BV1VAN1z2Ev1/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">十分钟速通
| FP-Tree算法_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1131uYxE1a/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">频繁模式挖掘FP-growth算法分析例题讲解_哔哩哔哩_bilibili</a></p>
<h4 id="规则评估方法">规则评估方法</h4>
<h3 id="聚类">聚类</h3>
<h4 id="k-meansk均值聚类">1. K-means（K均值聚类）</h4>
<p>✅ 核心思想：</p>
<ul>
<li><strong>假设</strong>：簇是“球状”、“大小相近”、“围绕中心分布”的。</li>
<li><strong>目标</strong>：把数据分成 K 个簇，使得
<strong>每个点到其所属簇中心的距离平方和最小</strong>。</li>
</ul>
<p>🔄 算法步骤（迭代优化）：</p>
<p><strong>Step 1：初始化</strong></p>
<ul>
<li>随机选择 <strong>K 个点</strong>作为初始簇中心（centroids）。
<ul>
<li>也可以用 K-means++ 更智能地选初始点（避免坏初始化）。</li>
</ul></li>
</ul>
<p><strong>Step 2：分配阶段（Assignment）</strong></p>
<ul>
<li>对每个数据点 *x<strong>i* ，计算它到 </strong>每个簇中心**
的距离（通常用欧氏距离）；</li>
<li>将 *x<strong>i* 分配给 </strong>距离最近的簇中心** 所在的簇。</li>
</ul>
<blockquote>
<p>💡 例如：点 (1,2) 到中心 A(0,0) 距离是 2.24，到 B(3,3) 是 2.24 →
可能分给 A（打破平局规则）。</p>
</blockquote>
<p><strong>Step 3：更新阶段（Update）</strong></p>
<ul>
<li>对每个簇，重新计算其<strong>新的簇中心</strong>：取该簇中所有点的<strong>坐标均值</strong>。
<ul>
<li>例如：簇中有 (0,0)、(1,1)、(2,2) → 新中心 = ((0+1+2)/3, (0+1+2)/3) =
(1,1)</li>
</ul></li>
</ul>
<p><strong>Step 4：判断收敛</strong></p>
<ul>
<li>如果<strong>簇中心不再变化</strong>（或变化小于阈值），算法结束；</li>
<li>否则，回到 Step 2 继续迭代。</li>
</ul>
<p>✅ 优点：</p>
<ul>
<li>简单、高效、易于实现；</li>
<li>适合大规模数据（时间复杂度 ≈ O(nKIt)）。</li>
</ul>
<p>❌ 缺点：</p>
<ul>
<li>必须提前知道 K（簇数量）；</li>
<li>对异常值敏感；</li>
<li><strong>只能识别凸形（球状）簇</strong>，无法处理月牙形、环形等。</li>
</ul>
<h4 id="agnesagglomerative-nesting凝聚层次聚类">2. AGNES（Agglomerative
Nesting，凝聚层次聚类）</h4>
<p>✅ 核心思想：</p>
<ul>
<li><strong>自底向上</strong>：开始时每个点自己是一个簇，然后不断<strong>合并最相似的两个簇</strong>，直到只剩一个簇。</li>
<li>用 <strong>树状图（dendrogram）</strong>
展示合并过程，你可以“切一刀”得到任意数量的簇。</li>
</ul>
<p>🔄 算法步骤：</p>
<p><strong>Step 1：初始化</strong></p>
<ul>
<li>将每个数据点视为一个<strong>独立的簇</strong>。共 n 个簇。</li>
</ul>
<p><strong>Step 2：计算簇间距离</strong></p>
<ul>
<li>对每一对簇，计算它们之间的距离。
<ul>
<li>距离定义方式（关键！）：
<ul>
<li><strong>Single
Linkage</strong>：两个簇中<strong>最近两点</strong>的距离；</li>
<li><strong>Complete
Linkage</strong>：两个簇中<strong>最远两点</strong>的距离；</li>
<li><strong>Average
Linkage</strong>：所有点对的<strong>平均距离</strong>。</li>
</ul></li>
</ul></li>
</ul>
<p><strong>Step 3：合并最近的两个簇</strong></p>
<ul>
<li>找到距离最小的两个簇，将它们<strong>合并为一个新簇</strong>。</li>
</ul>
<p><strong>Step 4：更新距离矩阵</strong></p>
<ul>
<li>从距离矩阵中删除这两个旧簇；</li>
<li>添加新簇，并计算它与其他所有簇的距离。</li>
</ul>
<p><strong>Step 5：重复</strong></p>
<ul>
<li>重复 Step
2–4，直到<strong>只剩一个簇</strong>（或达到预设簇数）。</li>
</ul>
<p>🔗 簇间距离定义（关键！）：</p>
<table>
<colgroup>
<col style="width: 22%">
<col style="width: 29%">
<col style="width: 47%">
</colgroup>
<thead>
<tr>
<th>链接方式</th>
<th>定义</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Single Linkage</strong></td>
<td>两个簇中<strong>最近两点</strong>的距离</td>
<td>能识别链状结构（如 Moons），但易受噪声影响</td>
</tr>
<tr>
<td><strong>Complete Linkage</strong></td>
<td>两个簇中<strong>最远两点</strong>的距离</td>
<td>倾向生成大小相近的紧凑簇</td>
</tr>
<tr>
<td><strong>Average Linkage</strong></td>
<td>所有点对的<strong>平均距离</strong></td>
<td>折中方案，较稳健</td>
</tr>
</tbody>
</table>
<p>✅ 优点：</p>
<ul>
<li>不需要预设 K（后期从树状图决定）；</li>
<li>能发现嵌套结构；</li>
<li>可处理非球形簇（尤其 Single Linkage）。</li>
</ul>
<p>❌ 缺点：</p>
<ul>
<li>时间复杂度高（O(n²) 或 O(n³)），不适合大数据；</li>
<li>一旦合并不能撤销（贪心算法）。</li>
</ul>
<h4 id="dbscan基于密度的聚类">3. DBSCAN（基于密度的聚类）</h4>
<p>✅ 核心思想：</p>
<ul>
<li><strong>高密度区域 = 簇，低密度区域 = 噪声</strong>；</li>
<li>不需要指定簇数量；</li>
<li>能发现<strong>任意形状</strong>的簇，并自动识别<strong>离群点</strong>。</li>
</ul>
<p>🔑 两个关键参数：</p>
<ul>
<li><code>eps</code>：邻域半径（多近算邻居？）</li>
<li><code>min_samples</code>：成为核心点所需的最小邻居数（多密才算高密度？）</li>
</ul>
<p>🔄 点的类型：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>定义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>核心点</strong></td>
<td><code>eps</code>范围内 ≥<code>min_samples</code>个点</td>
</tr>
<tr>
<td><strong>边界点</strong></td>
<td>不是核心点，但在某个核心点的邻域内</td>
</tr>
<tr>
<td><strong>噪声点</strong></td>
<td>既不是核心点，也不被任何核心点覆盖（标记为 -1）</td>
</tr>
</tbody>
</table>
<p>🔄 算法步骤：</p>
<p><strong>Step 1：初始化</strong></p>
<ul>
<li>所有点标记为 <strong>未访问（unvisited）</strong>；</li>
<li>簇编号 <code>cluster_id = 0</code>。</li>
</ul>
<p><strong>Step 2：遍历每个点</strong></p>
<ul>
<li>对每个未访问的点 <code>P</code>：
<ol type="1">
<li>标记 P 为 <strong>已访问</strong>；</li>
<li>找出 P 的 eps 邻域内的所有点（称为 <code>neighbors</code>）；</li>
<li><strong>如果 <code>|neighbors| &lt; MinPts</code></strong>：
<ul>
<li>将 P 标记为 <strong>噪声（noise）</strong>；</li>
<li>继续下一个点；</li>
</ul></li>
<li><strong>否则（P 是核心点）</strong>：
<ul>
<li><code>cluster_id += 1</code>，创建新簇；</li>
<li>将 P 加入新簇；</li>
<li>将 <code>neighbors</code>
中所有点加入一个<strong>种子集合（seeds）</strong>；</li>
<li><strong>扩展簇</strong>：
<ul>
<li>从 seeds 中取出一个点 Q；</li>
<li>如果 Q 未被访问，标记为已访问，并检查其邻域；
<ul>
<li>如果 Q 是核心点，将其邻居加入 seeds；</li>
</ul></li>
<li>将 Q 加入当前簇；</li>
<li>重复直到 seeds 为空。</li>
</ul></li>
</ul></li>
</ol></li>
</ul>
<p><strong>Step 3：输出</strong></p>
<ul>
<li>返回每个点的簇标签（噪声点为 -1）。</li>
</ul>
<p>✅ 优点：</p>
<ul>
<li>不需要 K；</li>
<li>能处理任意形状（月牙、环形等）；</li>
<li>对噪声鲁棒；</li>
<li>一次扫描完成（高效）。</li>
</ul>
<p>❌ 缺点：</p>
<ul>
<li>对 <code>eps</code> 和 <code>min_samples</code> 敏感；</li>
<li>在<strong>密度差异大</strong>的数据上表现差（比如一个密簇 +
一个稀疏簇）；</li>
<li>高维数据中“距离失效”（维度灾难）。</li>
</ul>
<h4 id="轮廓系数">轮廓系数</h4>
<p>轮廓系数（<strong>Silhouette
Coefficient</strong>）是一种<strong>无监督聚类评估指标</strong>，用于衡量聚类结果的“好坏”——它告诉我们：<strong>簇内是否紧密，簇间是否分离</strong>。</p>
<p>它的取值范围是 <strong>[-1, 1]</strong>： - <strong>接近
1</strong>：簇内紧密，簇间远离 → 聚类效果好； - <strong>接近
0</strong>：簇间边界模糊 → 聚类效果一般； - <strong>接近
-1</strong>：样本可能被分错簇 → 聚类效果差。</p>
<p>下面我将<strong>一步步带你理解轮廓系数的计算过程</strong>，并配上<strong>具体数值例子
+ 公式 + Python 验证</strong>。</p>
<p><strong>轮廓系数的定义（对单个样本）</strong></p>
<p>对数据集中的<strong>每一个样本 i</strong>，计算其轮廓系数 $ s(i)
$：</p>
<p><span class="math display">$$
s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}}
$$</span></p>
<p>其中： - $ a(i) $：样本 i
到<strong>同簇其他点</strong>的<strong>平均距离</strong>（<strong>簇内不相似度</strong>）；
- $ b(i) $：样本 i
到<strong>最近的其他簇</strong>中所有点的<strong>平均距离</strong>的最小值（<strong>最近簇间距离</strong>）。</p>
<blockquote>
<p>💡 直观理解： - $ a(i) $ 越小越好（和自己人很近）； - $ b(i) $
越大越好（离别人很远）； - 所以 $ b(i) - a(i) $ 越大，$ s(i) $ 越接近
1。</p>
</blockquote>
]]></content>
      <categories>
        <category>大三上</category>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——上机作业1</title>
    <url>/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A1/</url>
    <content><![CDATA[<h2 id="环境搭建">环境搭建</h2>
<p>安装vmware虚拟机</p>
<p>安装ubuntu</p>
<h2 id="在ubuntu终端里编写c语言程序">在Ubuntu终端里编写C语言程序</h2>
<p>打开终端：ctrl+alt+t</p>
<p>新建文件：<strong>vim hello.c</strong></p>
<p>输入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#define DISPLAY &quot;hello c!&quot;</span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">  printf(&quot;%s\n&quot;, DISPLAY);</span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br><span class="line">ZZ（*说明：ZZ当前文件进行快速保存操作*）</span><br></pre></td></tr></table></figure>
<p>退出编译模式：shift+：</p>
<p>输入：w保存q退出</p>
<p><strong>预编译(Preprocessing)</strong></p>
<p><em>对各种预处理指令（#include #define #ifdef
等#开始的代码行）进行处理，删除注释和多余的空白字符，生成一份新的代码</em></p>
<p>输入：<strong>gcc -E hello.c -o hello.i</strong></p>
<ol type="1">
<li><strong>命令分解</strong></li>
</ol>
<ul>
<li><strong><code>gcc</code></strong> ：GNU Compiler
Collection（GCC）的编译器命令。</li>
<li><strong><code>-E</code></strong> ：选项表示
<strong>仅执行预处理阶段</strong> ，不进行编译、汇编和链接。</li>
<li><strong><code>hello.c</code></strong> ：输入的C语言源文件。</li>
<li><strong><code>-o hello.i</code></strong>
：指定预处理后的输出文件名为 <code>hello.i</code>（<code>.i</code>
是预处理文件的默认后缀）。</li>
</ul>
<p><strong>2. 预处理阶段的作用</strong></p>
<p>预处理是编译过程的第一个阶段，主要处理以下内容：</p>
<ol type="1">
<li>头文件展开
<ul>
<li>将 <code>#include &lt;stdio.h&gt;</code>
等指令替换为对应头文件的实际内容。</li>
</ul></li>
<li>宏展开
<ul>
<li>替换 <code>#define PI 3.14</code> 等宏定义。</li>
</ul></li>
<li>条件编译
<ul>
<li>处理 <code>#ifdef</code>, <code>#ifndef</code>, <code>#endif</code>
等条件编译指令。</li>
</ul></li>
<li>删除注释
<ul>
<li>移除代码中的注释（<code>//</code> 或 <code>/* */</code>）。</li>
</ul></li>
</ol>
<p><strong>编译(Compilation)</strong></p>
<p><em>对代码进行语法、语义分析和错误判断，生成汇编代码文件</em></p>
<p><strong>gcc -S hello.i -o hello.s</strong></p>
<p><strong>编译阶段的作用</strong></p>
<p>在编译流程中，<code>-S</code> 选项对应 <strong>编译阶段</strong>
，主要完成以下任务：</p>
<ol type="1">
<li><strong>语法分析</strong> ：检查代码是否符合C语言语法规则。</li>
<li><strong>中间代码生成</strong>
：将预处理后的代码转换为中间表示（如抽象语法树）。</li>
<li><strong>优化</strong> ：根据优化选项（如
<code>-O2</code>）对代码进行优化。</li>
<li><strong>生成汇编代码</strong>
：将优化后的中间代码转换为目标平台的汇编指令（如x86-64汇编）。</li>
</ol>
<p><strong>汇编(Assembly)</strong></p>
<p><strong>gcc -c hello.s -o hello.o</strong></p>
<p><strong>汇编阶段的作用</strong></p>
<p>该命令执行 <strong>汇编阶段</strong> ，将人类可读的汇编代码（如
<code>mov</code>, <code>call</code> 等指令）转换为
<strong>二进制机器码</strong> ，生成目标文件（<code>.o</code>）。
目标文件包含：</p>
<ul>
<li>机器指令（二进制代码）。</li>
<li>符号表（函数名、变量名等）。</li>
<li>未解析的引用（如外部函数 <code>printf</code> 的地址）。</li>
</ul>
<p><strong>链接(Linking/Build)</strong></p>
<p><strong>gcc hello.o -o hello</strong></p>
<p><strong>链接阶段的作用</strong></p>
<p>链接器（<code>ld</code>）完成以下任务：</p>
<ol type="1">
<li>合并代码和数据
<ul>
<li>将 <code>hello.o</code> 中的机器码与标准库（如 <code>stdio.h</code>
中的 <code>printf</code>）的二进制代码合并。</li>
</ul></li>
<li>解析符号引用
<ul>
<li>解决外部符号（如
<code>printf</code>）的地址，确保所有函数和全局变量正确关联。</li>
</ul></li>
<li>生成可执行文件格式
<ul>
<li>创建符合操作系统要求的可执行文件（如Linux的ELF格式）。</li>
</ul></li>
</ol>
<p><strong>程序运行</strong></p>
<p><strong>./hello</strong></p>
<h2 id="手动安装vmware-tools">手动安装VMware tools</h2>
<p><a href="https://www.bilibili.com/video/BV1F6DzY2Ep9/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">手动安装VMware
Tools（提示VMware Tools 不再随旧版客户机操作系统的 VMware Workstation
一起提供的解决办法）_哔哩哔哩_bilibili</a></p>
<p><strong>在线安装</strong></p>
<p>如果方法一不行，可以试试方法二，我是通过方法二进行安装的。</p>
<p>首先更新系统已安装的软件源，以确保是最新的，在终端输入命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br></pre></td></tr></table></figure>
<p>然后再输入命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install open-vm-tools-desktop</span><br></pre></td></tr></table></figure>
<p>完成后运行upgrade命令，来升级系统中已安装的软件包(命令后面的
-y可以跳过确认询问)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt upgrade -y</span><br></pre></td></tr></table></figure>
<p>完成后进行重启，重启过后，点击菜单栏查看，变成重新安装就是成功了。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>数据挖掘作业</title>
    <url>/2025/09/21/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%BD%9C%E4%B8%9A/</url>
    <content><![CDATA[<h3 id="数据的规范化">数据的规范化</h3>
<ol type="1">
<li><strong>Min-Max 归一化（Normalization）</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 公式: X_scaled = (X - X_min) / (X_max - X_min)</span></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">X_norm = scaler.fit_transform(X)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>结果范围</strong>：[0, 1]（或可指定其他范围）</li>
<li><strong>保留原始分布形状</strong></li>
<li><strong>对异常值敏感</strong>（因为依赖最大/最小值）</li>
</ul>
<ol start="2" type="1">
<li><strong>Z-score 标准化（Standardization）</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 公式: X_scaled = (X - μ) / σ</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_std = scaler.fit_transform(X)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>结果</strong>：均值 ≈ 0，标准差 ≈ 1</li>
<li><strong>不保证固定范围</strong>（可能有 -3 到 +3 甚至更大）</li>
<li><strong>对异常值相对稳健</strong></li>
</ul>
<h4 id="robustscaler-鲁棒标准化与z-score-标准化standardization对比"><strong>RobustScaler
(鲁棒标准化)</strong>与Z-score 标准化（Standardization）对比</h4>
<p>StandardScaler (Z-score标准化) <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">公式: (x - 均值) / 标准差</span><br><span class="line"></span><br><span class="line">问题: 均值和标准差都会被异常值严重影响！</span><br><span class="line"></span><br><span class="line">例如:</span><br><span class="line">正常值: [100, 150, 200, 180, 220]  → 均值 = 170</span><br><span class="line">加入异常值: [100, 150, 200, 180, 220, 6445]  → 均值 = 1216 ❌</span><br><span class="line"></span><br><span class="line">结果: 所有正常值都变成负数，异常值主导了整个标准化过程</span><br></pre></td></tr></table></figure> RobustScaler
(鲁棒标准化)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">公式: (x - 中位数) / IQR</span><br><span class="line">其中 IQR = Q3 - Q1 (四分位距)</span><br><span class="line"></span><br><span class="line">优势: 中位数和IQR不受异常值影响！</span><br><span class="line"></span><br><span class="line">例如:</span><br><span class="line">正常值: [100, 150, 200, 180, 220]  → 中位数 = 180, IQR = 70</span><br><span class="line">加入异常值: [100, 150, 200, 180, 220, 6445]  → 中位数 = 190, IQR = 70 ✅</span><br><span class="line"></span><br><span class="line">结果: 异常值不会扭曲正常数据的标准化结果</span><br></pre></td></tr></table></figure>
<h3 id="apriori算法">Apriori算法</h3>
<p><strong>Apriori 算法</strong> 是一种用于
<strong>频繁项集挖掘（Frequent Itemset Mining）</strong> 和
<strong>关联规则学习（Association Rule Learning）</strong>
的经典算法。</p>
<p>Apriori 基于一个非常重要的性质，叫 <strong>先验性质（Apriori
Property）</strong>：</p>
<blockquote>
<p><strong>如果一个项集是频繁的，那么它的所有子集也一定是频繁的。</strong>
反过来：<strong>如果一个项集是非频繁的，那么它的所有超集也一定是非频繁的。</strong></p>
</blockquote>
<p>这个性质可以用来
<strong>剪枝（prune）</strong>，避免穷举所有可能的组合。</p>
<p>Apriori 的 <strong>候选生成规则</strong>：</p>
<blockquote>
<p>当且仅当它们的前 <strong>(k-1)</strong> 个项相同，两个频繁
k项集才可以连接生成 (k+1)项集。</p>
</blockquote>
<p>剪枝规则只有一句话：</p>
<blockquote>
<p>对候选 k-项集 c，<strong>只要存在</strong>任何一个 (k−1)-子集
<strong>不在</strong> Lₖₖ₋₁ 里， 就把 c
<strong>整集扔掉</strong>，不再给它计数。</p>
</blockquote>
<p>为什么这样做合法？</p>
<p>基于 Apriori
<strong>向下封闭性</strong>（频繁项集的所有子集必频繁）。 若 c
哪怕只有一个 (k−1)-子集是非频繁的，c
自己<strong>绝对不可能频繁</strong>，
所以<strong>没必要浪费一次数据库扫描</strong>去数它的支持度。</p>
<h4 id="例子">例子</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">transactions = [</span><br><span class="line">    [<span class="string">&#x27;牛奶&#x27;</span>, <span class="string">&#x27;面包&#x27;</span>, <span class="string">&#x27;黄油&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;牛奶&#x27;</span>, <span class="string">&#x27;面包&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;牛奶&#x27;</span>, <span class="string">&#x27;可乐&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;面包&#x27;</span>, <span class="string">&#x27;黄油&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;牛奶&#x27;</span>, <span class="string">&#x27;面包&#x27;</span>, <span class="string">&#x27;可乐&#x27;</span>],</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>我们的目标是找出
<strong>频繁项集</strong>（比如哪些商品经常一起出现）。</p>
<p><strong>步骤 1：设定最小支持度（min_support）</strong></p>
<p>假设我们设 <code>min_support = 2</code>，意思是：<strong>至少出现在 2
个购物篮中才算“频繁”</strong>。</p>
<blockquote>
<p>支持度（Support） = 包含该项集的交易数 / 总交易数<br>
这里我们直接用“出现次数 ≥ 2”来简化。</p>
</blockquote>
<p><strong>步骤 2：生成 1-项集（单个商品）</strong></p>
<p>统计每个商品出现次数：</p>
<table>
<thead>
<tr>
<th>项集</th>
<th>出现次数</th>
</tr>
</thead>
<tbody>
<tr>
<td>{‘牛奶’}</td>
<td>4</td>
</tr>
<tr>
<td>{‘面包’}</td>
<td>4</td>
</tr>
<tr>
<td>{‘黄油’}</td>
<td>2</td>
</tr>
<tr>
<td>{‘可乐’}</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>全部 ≥2 → 都是频繁 1-项集。</p>
<p><strong>步骤 3：生成 2-项集（两两组合）</strong></p>
<p>从频繁 1-项集中两两组合（注意：只组合那些“所有子集都频繁”的）：</p>
<p>可能的组合： - {‘牛奶’, ‘面包’} - {‘牛奶’, ‘黄油’} - {‘牛奶’, ‘可乐’}
- {‘面包’, ‘黄油’} - {‘面包’, ‘可乐’} - {‘黄油’, ‘可乐’}</p>
<p>现在统计它们在交易中出现的次数：</p>
<table>
<thead>
<tr>
<th>项集</th>
<th>出现次数</th>
</tr>
</thead>
<tbody>
<tr>
<td>{‘牛奶’, ‘面包’}</td>
<td>3 ✅</td>
</tr>
<tr>
<td>{‘牛奶’, ‘黄油’}</td>
<td>1 ❌</td>
</tr>
<tr>
<td>{‘牛奶’, ‘可乐’}</td>
<td>2 ✅</td>
</tr>
<tr>
<td>{‘面包’, ‘黄油’}</td>
<td>2 ✅</td>
</tr>
<tr>
<td>{‘面包’, ‘可乐’}</td>
<td>1 ❌</td>
</tr>
<tr>
<td>{‘黄油’, ‘可乐’}</td>
<td>0 ❌</td>
</tr>
</tbody>
</table>
<p>保留 ≥2 的 → 频繁 2-项集： - {‘牛奶’, ‘面包’} - {‘牛奶’, ‘可乐’} -
{‘面包’, ‘黄油’}</p>
<p><strong>步骤 4：生成 3-项集</strong></p>
<p>从频繁 2-项集中尝试组合。<br>
比如：{‘牛奶’,‘面包’} 和 {‘牛奶’,‘可乐’} → 可以组合成
{‘牛奶’,‘面包’,‘可乐’}<br>
但必须检查它的所有 2-项子集是否都在频繁 2-项集中：</p>
<ul>
<li>子集：{‘牛奶’,‘面包’} ✅<br>
</li>
<li>子集：{‘牛奶’,‘可乐’} ✅<br>
</li>
<li>子集：{‘面包’,‘可乐’} ❌（之前被剪掉了！）</li>
</ul>
<p>→ 所以 <strong>{‘牛奶’,‘面包’,‘可乐’} 不合法</strong>，不能生成。</p>
<p>再试：{‘牛奶’,‘面包’} + {‘面包’,‘黄油’} →
{‘牛奶’,‘面包’,‘黄油’}<br>
检查子集： - {‘牛奶’,‘面包’} ✅ - {‘牛奶’,‘黄油’} ❌（之前只有1次） -
{‘面包’,‘黄油’} ✅</p>
<p>→ 有一个子集不频繁 → 整个 3-项集被剪枝！</p>
<p><strong>结论：没有频繁 3-项集。</strong></p>
<p>算法结束。</p>
<h3 id="fp-growth"><strong>FP-growth</strong></h3>
<p><strong>FP-growth（Frequent Pattern
Growth）算法</strong>，它是一种用于<strong>频繁项集挖掘</strong>的高效算法</p>
<ul>
<li><strong>Apriori
算法</strong>：通过逐层生成候选项集（先1项，再2项…），每次都要扫描整个数据库，效率低。</li>
<li><strong>FP-growth</strong>：<strong>不生成候选项集</strong>，而是构建一种压缩数据结构——<strong>FP树（Frequent
Pattern Tree）</strong>，只需扫描数据库 <strong>2
次</strong>，效率更高！</li>
</ul>
<h4 id="fp-growth-的核心思想分两步"><strong>FP-growth
的核心思想（分两步）</strong></h4>
<p>第一步：构建 FP 树（FP-Tree）</p>
<ol type="1">
<li><strong>第一次扫描</strong>：统计每个单项的支持度，过滤掉低于
min_support 的项。</li>
<li><strong>对每条事务</strong>：
<ul>
<li>只保留频繁项</li>
<li>按支持度<strong>从高到低排序</strong></li>
</ul></li>
<li><strong>第二次扫描</strong>：将排序后的事务插入 FP 树。</li>
</ol>
<p>第二步：从 FP 树中挖掘频繁项集</p>
<ul>
<li>从<strong>支持度最低的频繁项</strong>开始（称为“后缀模式”）</li>
<li>对每个项，找出它的<strong>条件模式基（Conditional Pattern
Base）</strong></li>
<li>构建<strong>条件 FP 树（Conditional FP-Tree）</strong></li>
<li>递归挖掘，直到树为空</li>
</ul>
<p><a href="https://www.bilibili.com/video/BV1MtqsYHEZr?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=18">补充.4
关联_FP算法_哔哩哔哩_bilibili</a></p>
<h3 id="模型评价指标">模型评价指标</h3>
<h3 id="课后第一二次作业">课后第一，二次作业</h3>
<p>考虑表1中的候选3-项集，假设hash函数为h(x)=x mod
4，叶节点最大尺寸为2，构造hash树。</p>
<p><strong>表1. 候选3-项集</strong></p>
<table>
<thead>
<tr>
<th>编号</th>
<th>项集</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>{1, 4, 5}</td>
</tr>
<tr>
<td>2</td>
<td>{1, 5, 9}</td>
</tr>
<tr>
<td>3</td>
<td>{3, 5, 6}</td>
</tr>
<tr>
<td>4</td>
<td>{1, 2, 4}</td>
</tr>
<tr>
<td>5</td>
<td>{1, 3, 6}</td>
</tr>
<tr>
<td>6</td>
<td>{3, 5, 7}</td>
</tr>
<tr>
<td>7</td>
<td>{4, 5, 7}</td>
</tr>
<tr>
<td>8</td>
<td>{2, 3, 4}</td>
</tr>
<tr>
<td>9</td>
<td>{6, 8, 9}</td>
</tr>
<tr>
<td>10</td>
<td>{1, 2, 5}</td>
</tr>
<tr>
<td>11</td>
<td>{5, 6, 7}</td>
</tr>
<tr>
<td>12</td>
<td>{3, 6, 7}</td>
</tr>
<tr>
<td>13</td>
<td>{4, 5, 8}</td>
</tr>
<tr>
<td>14</td>
<td>{3, 4, 5}</td>
</tr>
<tr>
<td>15</td>
<td>{3, 6, 8}</td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/09/21/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%BD%9C%E4%B8%9A/IMG_20251027_094247.jpg" alt="IMG_20251027_094247">
<figcaption aria-hidden="true">IMG_20251027_094247</figcaption>
</figure>
<p>事务集如表2所示，<strong>最小支持度阈值是30%</strong>。</p>
<p>根据表2的事务集，在格结构上对每个结点添加所有符合条件的字母标记：</p>
<p><strong>N</strong>：如果该项集被Apriori算法认为不是候选项集。（一个项集不是候选项集有两种可能的原因，一个是它们没有在候选项集产生步骤产生，另一个是它虽然在候选项集产生步骤产生，但是在剪枝步骤被丢掉）</p>
<p><strong>I</strong>：如果计算支持度计数后，该候选项集被认为是非频繁的。</p>
<p><strong>表2. 事务集</strong>：</p>
<table>
<thead>
<tr>
<th>TID</th>
<th>项集</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>{a, b, d, e}</td>
</tr>
<tr>
<td>2</td>
<td>{b, c, d}</td>
</tr>
<tr>
<td>3</td>
<td>{a, b, d, e}</td>
</tr>
<tr>
<td>4</td>
<td>{a, c, d, e}</td>
</tr>
<tr>
<td>5</td>
<td>{b, c, d, e}</td>
</tr>
<tr>
<td>6</td>
<td>{b, d, e}</td>
</tr>
<tr>
<td>7</td>
<td>{c, d}</td>
</tr>
<tr>
<td>8</td>
<td>{a, b, c}</td>
</tr>
<tr>
<td>9</td>
<td>{a, d, e}</td>
</tr>
<tr>
<td>10</td>
<td>{b, d}</td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/09/21/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%BD%9C%E4%B8%9A/wps1.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="/2025/09/21/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%BD%9C%E4%B8%9A/IMG_20251029_160558.jpg" alt="IMG_20251029_160558">
<figcaption aria-hidden="true">IMG_20251029_160558</figcaption>
</figure>
<h4 id="判断极大频繁项集m">判断极大频繁项集（M）</h4>
<p>极大频繁项集：是频繁的，且<strong>没有频繁的真超集</strong>。</p>
<blockquote>
<p><strong>定义</strong>：极大频繁项集（Maximal Frequent
Itemset）是一个频繁项集，其<strong>所有超集都不是频繁的</strong>。</p>
</blockquote>
<p>检查每个频繁项集：</p>
<ul>
<li><strong>ade</strong>：超集有 abde, acde, adde（无效）, bcde
等，但所有 4-项集都不频繁 → 所以 <strong>ade 是极大</strong></li>
<li><strong>bde</strong>：同理，超集如 abde, bcde 都不频繁 → <strong>bde
是极大</strong></li>
<li>其他频繁项集（如 ad）：有超集 ade（频繁）→ 所以 ad
<strong>不是极大</strong></li>
<li>ab：超集 abd（非频繁），abe（非频繁）→ 但 ab
本身频繁，但有没有频繁超集？没有 →
等等！<strong>极大要求：没有频繁的超集</strong>。abd
支持度=2（非频繁），abe=2（非频繁）→ 所以 ab
<strong>没有频繁超集</strong> → 那 ab 是极大？</li>
</ul>
<h4 id="判断闭频繁项集c">判断闭频繁项集（C）</h4>
<p><strong>闭项集</strong>：一个项集 X 是闭的，如果<strong>不存在超集 Y
⊃ X 使得 support(Y) = support(X)</strong>。</p>
<p>即：它的支持度<strong>严格大于</strong>所有超集的支持度（或者没有超集具有相同支持度）。</p>
<p>以单项集为例：</p>
<p>单项集：</p>
<ul>
<li>a (5)：超集 ad(4), ae(4), ab(3), ade(4) → 所有支持度 &lt;5 →
没有超集支持度=5 → <strong>a 是闭</strong></li>
<li>b (7)：超集 bd(6), be(4), ab(3), bde(4) → 都 &lt;7 → <strong>b
是闭</strong></li>
<li>c (5)：超集 bc(3), cd(4) → 都 &lt;5 → <strong>c 是闭</strong></li>
<li>d (9)：超集 ad(4), bd(6), cd(4), de(6), ade(4), bde(4) → 都 &lt;9 →
<strong>d 是闭</strong></li>
<li>e (6)：超集 ae(4), be(4), de(6) → 注意：<strong>de 支持度=6，等于 e
的支持度！</strong>
<ul>
<li>e ⊂ de，且 support(e)=support(de)=6 → 所以 <strong>e
不是闭</strong></li>
</ul></li>
</ul>
<h3 id="课后第三次作业">课后第三次作业</h3>
<p>假设最小支持度阈值为40%，基于以下事务集写出使用FP-growth挖掘频繁项集的过程。</p>
<p>表1. 事务集</p>
<table>
<thead>
<tr>
<th>TID</th>
<th>项集</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>{a,b,d,e}</td>
</tr>
<tr>
<td>2</td>
<td>{b,c,d}</td>
</tr>
<tr>
<td>3</td>
<td>{a,b,d,e}</td>
</tr>
<tr>
<td>4</td>
<td>{a,c,d,e}</td>
</tr>
<tr>
<td>5</td>
<td>{b,c,d,e}</td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/09/21/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%BD%9C%E4%B8%9A/image-20251117112729200.png" alt="image-20251117112729200">
<figcaption aria-hidden="true">image-20251117112729200</figcaption>
</figure>
<figure>
<img src="/2025/09/21/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%BD%9C%E4%B8%9A/image-20251117112739932.png" alt="image-20251117112739932">
<figcaption aria-hidden="true">image-20251117112739932</figcaption>
</figure>
<p>条件 FP 树（Conditional FP-tree）是 FP-growth
算法在“递归”阶段用来压缩“条件模式基”的一棵小 FP 树。 它的构建过程与初始
FP
树几乎一样，只是输入数据换成了“条件模式基”，并且再扫一遍、删低计数、排序、插入即可。下面用
<strong>“以 e 为后缀”</strong>
的例子把每一步都写出来，你就能完全复现。</p>
<p><strong>一、准备：条件模式基（Conditional Pattern Base）</strong></p>
<p>从主 FP 树里提取所有<strong>以 e
结尾</strong>的路径，并记录该路径的出现次数：</p>
<table>
<thead>
<tr>
<th style="text-align: left;">路径（删去 e 本身）</th>
<th style="text-align: left;">该路径计数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">d b a</td>
<td style="text-align: left;">2</td>
</tr>
<tr>
<td style="text-align: left;">d a c</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">d b c</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
<p>这就是“e 的条件模式基”。</p>
<p><strong>二、第一次扫描：算单项计数</strong></p>
<p>把上面 3 条记录拆成单项累加：</p>
<ul>
<li>d: 2+1+1 = 4</li>
<li>b: 2+0+1 = 3</li>
<li>a: 2+1+0 = 3</li>
<li>c: 0+1+1 = 2</li>
</ul>
<p>最小支持度计数仍是 2，因此<strong>全部保留</strong>（若某项 &lt;2
则直接丢弃）。</p>
<p><strong>三、第二次扫描：排序 + 插入</strong></p>
<ol type="1">
<li>排序规则：按<strong>全局频繁 1-项集</strong>的降序排（即
d≻b≻a≻c≻e）。 因此每条记录内部重新排序：</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align: left;">原路径</th>
<th style="text-align: left;">排序后路径</th>
<th style="text-align: left;">计数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">d b a</td>
<td style="text-align: left;">d b a</td>
<td style="text-align: left;">2</td>
</tr>
<tr>
<td style="text-align: left;">d a c</td>
<td style="text-align: left;">d a c</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">d b c</td>
<td style="text-align: left;">d b c</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
<ol type="1">
<li>逐条插入，构建“e 的条件 FP 树”：</li>
</ol>
<ul>
<li>插入 <code>d b a</code>（计数 2） 根 → d(2) → b(2) → a(2)</li>
<li>插入 <code>d a c</code>（计数 1） 根 → d(3) → a(1) → c(1)</li>
<li>插入 <code>d b c</code>（计数 1） 根 → d(4) → b(3) → c(1)</li>
</ul>
<p>最终得到的<strong>条件 FP 树</strong>文字表示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">null</span><br><span class="line">└── d(4)</span><br><span class="line">    ├── b(3)</span><br><span class="line">    │   ├── a(2)</span><br><span class="line">    │   └── c(1)</span><br><span class="line">    └── a(1)</span><br><span class="line">        └── c(1)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大三上</category>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——知识点</title>
    <url>/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h2 id="位运算">位运算</h2>
<p>在这张图片中，表格列出了 <code>x</code> 和 <code>y</code>
的十六进制值，并且要求用 C
语言中的位运算符对它们进行操作。接下来，我将对每个表达式进行详细的计算和解释。</p>
<p>在表格中，要求使用 C 语言中的不同位运算符来计算 <code>x</code> 和
<code>y</code> 之间的结果。位运算符包括：</p>
<ol type="1">
<li><code>&amp;</code>（位与）</li>
<li><code>|</code>（位或）</li>
<li><code>^</code>（位异或）</li>
<li><code>~</code>（位取反）</li>
<li><code>&lt;&lt;</code>（左移）</li>
<li><code>&gt;&gt;</code>（右移）</li>
<li><code>!</code>（逻辑非）</li>
</ol>
<h3 id="计算步骤">计算步骤：</h3>
<ol type="1">
<li><strong>位与运算 <code>x &amp; y</code></strong>： 位与运算会比较
<code>x</code> 和 <code>y</code> 的每一位，只有当对应位都为 1
时，结果才为 1，否则为 0。</li>
<li><strong>位或运算 <code>x | y</code></strong>： 位或运算会比较
<code>x</code> 和 <code>y</code> 的每一位，只要对应位有一个为
1，结果就为 1。</li>
<li><strong>位异或运算 <code>x ^ y</code></strong>： 位异或运算会比较
<code>x</code> 和 <code>y</code> 的每一位，当两者相同时，结果为
0；当两者不同时，结果为 1。</li>
<li><strong>位取反运算 <code>~x</code> 和 <code>~y</code></strong>：
位取反运算会将 <code>x</code> 或 <code>y</code> 的每一位都反转，0 变
1，1 变 0。</li>
<li><strong>左移运算 <code>x &lt;&lt; y</code></strong>： 左移运算会将
<code>x</code> 的二进制位向左移动 <code>y</code> 位，并在右边补 0。</li>
<li><strong>右移运算 <code>x &gt;&gt; y</code></strong>： 右移运算会将
<code>x</code> 的二进制位向右移动 <code>y</code>
位，符号位（对于负数来说是 1）保持不变。</li>
<li><strong>逻辑非运算 <code>!x</code></strong>： 逻辑非运算对
<code>x</code> 进行布尔值判断，如果 <code>x</code> 为 0，则结果为
1，否则为 0。</li>
</ol>
<h2 id="十六进制hexadecimal-h和二进制binary-b之间的直接关系">十六进制（Hexadecimal,
H）和二进制（Binary, b）之间的直接关系</h2>
<p><strong>核心原理:</strong> 每一个十六进制数字正好对应 4
个二进制位。这是因为 16=24。</p>
<p>我们可以将十六进制数 <code>8080 108B</code> H
中的每一位数字，分别转换为它对应的4位二进制数：</p>
<ol type="1">
<li><strong><code>8</code></strong> H =
<strong><code>1000</code></strong> b</li>
<li><strong><code>0</code></strong> H =
<strong><code>0000</code></strong> b</li>
<li><strong><code>8</code></strong> H =
<strong><code>1000</code></strong> b</li>
<li><strong><code>0</code></strong> H =
<strong><code>0000</code></strong> b</li>
<li><strong><code>1</code></strong> H =
<strong><code>0001</code></strong> b</li>
<li><strong><code>0</code></strong> H =
<strong><code>0000</code></strong> b</li>
<li><strong><code>8</code></strong> H =
<strong><code>1000</code></strong> b</li>
<li><strong><code>B</code></strong> H (B 代表十进制的 11) =
<strong><code>1011</code></strong> b</li>
</ol>
<p><strong>组合:</strong>
现在，按照原始十六进制数的顺序，把这些4位的二进制数组合起来：</p>
<p><code>1000</code> (来自<code>8</code>) + <code>0000</code>
(来自<code>0</code>) + <code>1000</code> (来自<code>8</code>) +
<code>0000</code> (来自<code>0</code>) + <code>0001</code>
(来自<code>1</code>) + <code>0000</code> (来自<code>0</code>) +
<code>1000</code> (来自<code>8</code>) + <code>1011</code>
(来自<code>B</code>)</p>
<p>结果: 将它们连接在一起就得到：</p>
<p>1000 0000 1000 0000 0001 0000 1000 1011 b</p>
<p><strong>所以，<code>8080 108B</code> H 等于
<code>1000 0000 1000 0000 0001 0000 1000 1011</code> b
是因为每个十六进制位都可以独立地、直接地转换为一个4位的二进制表示，然后按顺序拼接起来。</strong></p>
<h2 id="指令决定了如何解释寄存器中的二进制位串">指令决定了如何解释寄存器中的二进制位串</h2>
<p>好的，我们来详细解释一下为什么在不同的指令下，寄存器 R1 和 R2 的内容
<code>0000 108B</code> H 和 <code>8080 108B</code> H
会对应不同的真值。核心原因在于，<strong>指令决定了如何解释寄存器中的二进制位串</strong>。</p>
<p><strong>（1）无符号数加法指令 (Unsigned Addition)</strong></p>
<ul>
<li><strong>解释规则:</strong>
当执行无符号数指令时，计算机会将寄存器中的 <strong>所有32位</strong>
都视为表示数值大小（magnitude）的部分，没有单独的符号位。数值就是这个32位二进制数直接转换成的十进制（或十六进制）值。</li>
</ul>
<p><strong>（2）带符号整数乘法指令 (Signed Integer
Multiplication)</strong></p>
<ul>
<li><p>解释规则:</p>
<p>当执行带符号整数指令时，计算机会使用</p>
<p>补码 (Two’s Complement)</p>
<p>来表示整数。</p>
<ul>
<li><strong>最高位 (MSB, Most Significant Bit)</strong>
是符号位：<code>0</code> 代表正数或零，<code>1</code> 代表负数。</li>
<li><strong>正数:</strong>
其补码、原码、反码相同，数值就是除去符号位后的二进制值。</li>
<li><strong>负数:</strong>
其真值需要通过补码转换回原码来确定其绝对值。转换方法是：<strong>对补码再次求补（符号位不变，数值位按位取反，末位加1；或者全部位按位取反，末位加1）得到原码的绝对值</strong>。</li>
</ul></li>
</ul>
<p><strong>（3）单精度浮点数减法指令 (Single-Precision Floating-Point
Subtraction)</strong></p>
<ul>
<li><p>解释规则:</p>
<p>当执行浮点数指令时，计算机会按照</p>
<p>IEEE 754 单精度 (32位)</p>
<p>标准来解释寄存器中的位。格式如下：</p>
<ul>
<li><strong>符号位 (Sign, S):</strong> 1位 (第31位)。<code>0</code>
为正，<code>1</code> 为负。</li>
<li><strong>阶码 (Exponent, E):</strong> 8位 (第30-23位)。存储的是
<code>e + bias</code>，其中 <code>e</code> 是实际指数，<code>bias</code>
(偏移量) 对于单精度是 <strong>127</strong>。</li>
<li><strong>尾数 (Mantissa/Fraction, F):</strong> 23位
(第22-0位)。表示小数部分。对于规格化数，实际尾数是
<code>1.F</code>（有一个隐藏的1）。</li>
<li><strong>数值公式 (规格化):</strong> Value=(−1)S×(1.F)2×2(E−127)</li>
<li><strong>特殊情况:</strong> 需要注意 E=0 (表示0或非规格化数) 和 E=255
(表示无穷大或NaN)。</li>
</ul></li>
</ul>
<h2 id="补码的基本规则">补码的基本规则</h2>
<p>在开始计算之前，我们先了解补码的基本规则：</p>
<ol type="1">
<li><strong>符号位</strong>：
<ul>
<li>补码的最高位（最左边的位）是符号位。</li>
<li>符号位为 <strong>0</strong> 表示正数或零，符号位为
<strong>1</strong> 表示负数。</li>
</ul></li>
<li><strong>正数的补码</strong>：
<ul>
<li>如果符号位是 0，补码与原码相同，直接按照二进制数值解释即可。</li>
</ul></li>
<li><strong>负数的补码</strong>：
<ul>
<li>如果符号位是
1，表示负数。要得到原码（即实际的数值），需要对数值部分取反（0 变 1，1
变 0），然后加 1。</li>
<li>最后在结果前加上负号。</li>
</ul></li>
<li><strong>小数部分的处理</strong>：
<ul>
<li>如果补码表示包含小数点，符号位在小数点左边，数值部分在小数点右边，按照二进制小数计算。</li>
</ul></li>
</ol>
<h2 id="是的在-c-语言中0u-后面的-u-确实表示无符号的意思具体来说">是的，在 C
语言中，<code>0U</code> 后面的 <code>U</code>
确实表示无符号的意思。具体来说：</h2>
<ul>
<li><strong><code>0</code>
本身</strong>：这是一个整数常量，默认情况下是有符号整数类型（<code>signed int</code>）。</li>
<li><strong><code>0U</code> 的含义</strong>：当在 <code>0</code>
后面加上 <code>U</code>
后缀时，它就变成了一个无符号整数常量（<code>unsigned int</code>）。<code>U</code>
后缀明确指定了这个数字是无符号类型。</li>
</ul>
<h3 id="c-语言中整数常量的后缀规则">C 语言中整数常量的后缀规则</h3>
<p>在 C 语言中，可以通过后缀来指定整数常量的类型： -
<strong>无后缀</strong>：表示默认的有符号整数（<code>int</code>）。 -
<strong><code>U</code> 或
<code>u</code></strong>：表示无符号整数（<code>unsigned int</code>）。 -
<strong><code>L</code> 或
<code>l</code></strong>：表示长整型（<code>long int</code>）。 -
<strong><code>UL</code> 或
<code>ul</code></strong>：表示无符号长整型（<code>unsigned long int</code>）。</p>
<h3 id="举例说明">举例说明</h3>
<ul>
<li><code>0</code>：有符号整数，值是 0。</li>
<li><code>0U</code>：无符号整数，值仍然是 0，但它的类型是
<code>unsigned int</code>。</li>
</ul>
<h3 id="为什么这很重要">为什么这很重要？</h3>
<p>无符号类型和有符号类型的区别在某些情况下会影响程序的行为，比如比较运算：
- 如果比较两个无符号整数，或者两个有符号整数，直接按数值比较即可。 -
如果一个是有符号整数，另一个是无符号整数，C
语言会将有符号整数转换为无符号整数后再比较。这可能导致意外结果，例如负数在转换为无符号整数时变成一个很大的正数。</p>
<p>总之，<code>U</code>
后缀的作用就是告诉编译器，这个整数常量是无符号的。所以你的理解是对的，后面带
<code>U</code> 就是无符号的意思！</p>
<h2 id="让我们来分析这个问题为什么在表达式-unsigned--1--2-中-1-被转换为无符号整数而--2-也被按无符号数处理">让我们来分析这个问题：为什么在表达式
<code>(unsigned) -1 &gt; -2</code> 中，<code>-1</code>
被转换为无符号整数，而 <code>-2</code> 也被按无符号数处理。</h2>
<h3 id="表达式-unsigned--1-的含义">1. 表达式 <code>(unsigned) -1</code>
的含义</h3>
<ul>
<li><strong>(unsigned)</strong> 是一个强制类型转换，表示将后面的值
<code>-1</code>
从有符号整数（<code>int</code>）转换为无符号整数（<code>unsigned int</code>）。</li>
<li>在计算机中，整数通常以补码形式存储。以 32 位为例：
<ul>
<li>有符号整数 <code>-1</code> 的补码是 <code>1111...1111</code>（32
位全 1）。</li>
<li>当将其强制转换为无符号整数时，这串二进制位被重新解释为一个正数。</li>
<li><code>1111...1111</code> 作为无符号整数的值是 (2^{32} - 1 =
4294967295)。</li>
</ul></li>
<li>所以，<code>(unsigned) -1</code> 的结果是
<code>4294967295</code>。</li>
</ul>
<h3 id="比较中的--2-为什么按无符号数处理">2. 比较中的 <code>-2</code>
为什么按无符号数处理</h3>
<ul>
<li>在表达式 <code>(unsigned) -1 &gt; -2</code> 中，<code>-2</code>
默认是一个有符号整数（<code>int</code>），其补码表示为
<code>1111...1110</code>（32 位中最后一位是 0）。</li>
<li>当一个无符号整数（<code>(unsigned) -1</code>）与一个有符号整数（<code>-2</code>）进行比较时，C
语言会执行<strong>隐式类型转换</strong>，以确保两个操作数的类型一致。</li>
<li>根据 C 语言的规则：
<ul>
<li>如果一个操作数是无符号整数，另一个是有符号整数，有符号整数会被转换为无符号整数。</li>
</ul></li>
<li>因此，<code>-2</code> 会被隐式转换为无符号整数：
<ul>
<li><code>1111...1110</code> 作为无符号整数的值是 (2^{32} - 2 =
4294967294)。</li>
</ul></li>
</ul>
<h3 id="比较的过程">3. 比较的过程</h3>
<ul>
<li>现在，表达式 <code>(unsigned) -1 &gt; -2</code> 变成了：
<ul>
<li><code>(unsigned) -1 = 4294967295</code>（无符号整数）。</li>
<li><code>-2</code> 被转换为
<code>4294967294</code>（无符号整数）。</li>
</ul></li>
<li>比较
<code>4294967295 &gt; 4294967294</code>，显然成立，结果为真（<code>1</code>）。</li>
</ul>
<h3 id="为什么--2-被按无符号数处理">4. 为什么 <code>-2</code>
被按无符号数处理</h3>
<ul>
<li><code>-2</code> 被按无符号数处理的原因在于 C
语言的<strong>类型转换规则</strong>：
<ul>
<li>当有符号整数与无符号整数进行运算或比较时，有符号整数会被自动转换为无符号整数。</li>
<li>这种转换基于补码的二进制表示，直接将补码重新解释为无符号值，而不改变位模式。</li>
</ul></li>
<li>在这个例子中：
<ul>
<li><code>(unsigned) -1</code> 强制指定了无符号类型。</li>
<li><code>-2</code> 由于与无符号数比较，被隐式转换成了无符号数。</li>
</ul></li>
</ul>
<h3 id="总结">5. 总结</h3>
<ul>
<li><strong>(unsigned) -1</strong> 将 <code>-1</code>
显式转换为无符号整数，结果是 <code>4294967295</code>。</li>
<li><strong>-2</strong> 在比较中被隐式转换为无符号整数，结果是
<code>4294967294</code>。</li>
<li>这种行为是 C
语言类型转换规则的结果：为了保证比较时类型一致，<code>-2</code>
被按无符号数处理。</li>
</ul>
<p>这种机制虽然确保了类型一致性，但在处理负数时可能导致意外结果，因此在使用无符号类型时需要特别注意。希望这个解释清晰地回答了你的问题！</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——课后答案</title>
    <url>/2025/03/12/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88/</url>
    <content><![CDATA[<h1 id="目录">目录</h1>
<h2 id="说明"><a href="#说明">说明</a></h2>
<h1 id="说明-1">说明</h1>
<h2 id="版本信息">版本信息</h2>
<p>书名：《计算机系统基础（第二版）》 袁春风</p>
<p>整理日期：2019-10-27</p>
<p>整理人：李加其（幽弥狂）</p>
<p>内容：课后习题参考答案</p>
<p>联系方式：13812991101</p>
<p>邮箱：1768478912@qq.com</p>
<p>QQ:1768478912</p>
<p>版本：v1.0</p>
<h2 id="声明">声明</h2>
<p>1、如果有侵权或者其他问题欢迎联系我。</p>
<p>2、参考书目为https://github.com/JackeyLea/NJUCS中README.md文件中列出的参考书目。</p>
<p>3、红色字体为重要内容，比如曾作为课后习题、考试考过等等。</p>
<p>4、括号里的P**表示在书本的第几页。</p>
<h1 id="第一部分-系统概述和可执行目标文件的生成">第一部分
系统概述和可执行目标文件的生成</h1>
<h2 id="第一章计算机系统概述">第一章计算机系统概述</h2>
<p>1、见《计算机系统基础习题解答与教学指导》</p>
<p>2、简单回答下列问题。</p>
<p>（1）冯·诺依曼计算机由哪几部分组成？各部分的功能是什么？</p>
<pre><code>控制器：用于控制主动执行指令；

运算器：用于执行指令；

存储器：存放数据和指令；

输入输出设备：通过输入输出设备使用计算机；</code></pre>
<p>（2）什么是“存储程序”工作方式？</p>
<pre><code>必须将事先编好的程序和原始数据送人主存后才开能执行程序，一旦程序被启动执行，计算机能在必须操作人员干预的情况下自动完成逐条指令取出和执行任务。（P3）</code></pre>
<p>（3）一条指令的执行过程包含哪几个阶段？</p>
<pre><code>程序的执行就是指令的执行过程。

阶段：
取指令、取数、传数、ALU运算阶段。（P6）</code></pre>
<p>（4）计算机系统的层次结构如何划分？</p>
<pre><code>电路设计、数字设计、ISA、汇编程序、编译程序、应用程序、操作系统（P18 图1.11）</code></pre>
<p>（5）计算机系统的用户可分哪几类？每类用户工作在哪个层次？</p>
<pre><code>用户有四种：

最终用户：应用程序级

系统管理员：操作系统

应用程序员：编译程序

系统程序员：汇编程序和ISA之间</code></pre>
<p>（6）程序的 CPI 与哪些因素有关？</p>
<pre><code>总时钟周期数、指令条数（P20）</code></pre>
<p>（7）为什么说性能指标 MIPS 不能很好地反映计算机的性能？</p>
<pre><code>MIPS反映了机器执行定点指令的速度。首先，不同机器的指令集是不同的，而且指令的功能也是不同的，也许在机器1上一条指令完成的功能机器2需要多条指令。其次，不同机器的CPI和时钟周期也是不同的，因此同一条指令在不同的机器上所用的时间也不同。（P20 最后一段）</code></pre>
<p>3、略</p>
<p>4、略</p>
<p>5、题目略</p>
<p>仿照图1.3</p>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr>
<th>主存地址</th>
<th>主存单元地址</th>
<th>内容说明（Ii表示第i条指令）</th>
<th>指令的符号表示</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1110 0111</td>
<td>I1：R[0]←M[7]；op=1110；取数操作</td>
<td>load r0,7#</td>
</tr>
<tr>
<td>1</td>
<td>0000 0100</td>
<td>I2：R[1]←R[0]；op=0000；传送操作</td>
<td>mov r1,r0</td>
</tr>
<tr>
<td>2</td>
<td>1110 0101</td>
<td>I3：R[0]←M[6]；op=1110；取数操作</td>
<td>load r0,6#</td>
</tr>
<tr>
<td>3</td>
<td>0010 0001</td>
<td>I4：R[0]←R[0]-R[1]；op=0010；减操作</td>
<td>sub r0,r1</td>
</tr>
<tr>
<td>4</td>
<td>0011 0001</td>
<td>I5：R[0]←R[0]*R[1]；op=0011；乘操作</td>
<td>mul r0,r1</td>
</tr>
<tr>
<td>5</td>
<td>1111 1000</td>
<td>I6：M[8]←R[0]；op=1111；存数操作</td>
<td>store 8#,r0</td>
</tr>
<tr>
<td>6</td>
<td>0001 0000</td>
<td>操作数x，值为16</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>0010 0001</td>
<td>操作数y，值为33</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>0000 0000</td>
<td>结果z，初始值为0</td>
<td></td>
</tr>
</tbody>
</table>
<p>仿照图1.5</p>
<table style="width:100%;">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr>
<th>操作</th>
<th>I1:1110 0111</th>
<th>I2：0000 0100</th>
<th>I3：1110 0101</th>
<th>I4：0010 0001</th>
<th>I5：0011 0001</th>
<th>I6：1111 1000</th>
</tr>
</thead>
<tbody>
<tr>
<td>取指令</td>
<td>IR←M[0000]</td>
<td>IR←M[0001]</td>
<td>IR←M[0010]</td>
<td>IR←M[0011]</td>
<td>IR←M[0100]</td>
<td>IR←M[0101]</td>
</tr>
<tr>
<td>指令译码</td>
<td>op=1110，取数</td>
<td>op=0000，传送</td>
<td>op=1110，取数</td>
<td>op=0010，减</td>
<td>op=0011，乘</td>
<td>op=1111，存数</td>
</tr>
<tr>
<td>PC增量</td>
<td>PC←0000+1</td>
<td>PC←0001+1</td>
<td>PC←0010+1</td>
<td>PC←0011+1</td>
<td>PC←0100+1</td>
<td>PC←0101+1</td>
</tr>
<tr>
<td>取数并执行</td>
<td>MDR←M[0110]</td>
<td>A←R[0]、mov</td>
<td>MDR←M[0101]</td>
<td>A←R[0]、B←R[1]、sub</td>
<td>A←R[0]、B←R[1]、mul</td>
<td>MDR←R[0]</td>
</tr>
<tr>
<td>送结果</td>
<td>R[0]←MDR</td>
<td>R[1]←F</td>
<td>R[0]←MDR</td>
<td>R[0]←F</td>
<td>R[0]←F</td>
<td>M[1000]←MDR</td>
</tr>
<tr>
<td>执行结果</td>
<td>R[0]=33</td>
<td>R[1]=33</td>
<td>R[0]=16</td>
<td>R[0]=16-33=-17</td>
<td>R[0]=-17×33</td>
<td>M[8]=-561</td>
</tr>
</tbody>
</table>
<p>6、若有两个基准测试程序P1和P2在机器M1和M2上运行，假定M1和M2的价格分别是5000元和8000元，下表给出了P1和P2在M1和M2上所花的时间和指令条数。</p>
<table>
<tr>
<th rowspan="2">
程序
</th>
<th colspan="2">
M1
</th>
<th colspan="2">
M2
</th>
</tr>
<tr>
<td>
指令条数
</td>
<td>
执行时间(ms)
</td>
<td>
指令条数
</td>
<td>
执行时间(ms)
</td>
</tr>
<tr>
<td>
P1
</td>
<td>
200×10^6
</td>
<td>
10000
</td>
<td>
150×10^6
</td>
<td>
5000
</td>
</tr>
<tr>
<td>
P2
</td>
<td>
300×10^3
</td>
<td>
3
</td>
<td>
420×10^3
</td>
<td>
6
</td>
</tr>
</table>
<p>请回答下列问题：</p>
<p>（1）对于P1，哪台机器的速度快？快多少？对于P2呢？</p>
<pre><code>对于P1，M2比M1快一倍；对于P2，M1比M2快一倍。</code></pre>
<p>（2）在M1上执行P1和P2的速度分别是多少MIPS？在M2上的执行速度又各是多少？从执行速度来看，对于P2，哪台机器的速度快？快多少？</p>
<pre><code>对于M1，P1的速度为：200M/10=20MIPS；P2为300k/0.003=100MIPS。

对于M2，P1的速度为：150M/5=30MIPS；P2为420k/0.006=70MIPS。

从执行速度来看，对于P2，因为100/70=1.43倍，所以M1比M2快0.43倍。</code></pre>
<p>（3）假定M1和M2的时钟频率各是800MHz和1.2GHz，则在M1和M2上执行P1时的平均时钟周期数CPI各是多少？</p>
<pre><code>在M1上执行P1时的平均时钟周期数CPI为：10×800M/(200×106)=40。

在M2上执行P1时的平均时钟周期数CPI为：5×1.2G/(150×106)=40。</code></pre>
<p>（4）如果某个用户需要大量使用程序P1，并且该用户主要关心系统的响应时间而不是吞吐率，那么，该用户需要大批购进机器时，应该选择M1还是M2？为什么？（提示：从性价比上考虑）</p>
<pre><code>考虑运行P1时M1和M2的性价比，因为该用户主要关心系统的响应时间，所以性价比中的性能应考虑执行时间，其性能为执行时间的倒数。故性价比R为：

R=1/(执行时间×价格)

R越大说明性价比越高，也即，“执行时间×价格”的值越小，则性价比越高。

因为10×5000 &gt; 5×8000，所以，M2的性价比高。应选择M2。</code></pre>
<p>（5）如果另一个用户也需要购进大批机器，但该用户使用P1和P2一样多，主要关心的也是响应时间，那么，应该选择M1还是M2？为什么？</p>
<pre><code>P1和P2需要同等考虑，性能有多种方式：执行时间总和、算术平均、几何平均。

若用算术平均方式，则：因为 (10+0.003)/2×5000 &gt; (5+0.006)/2×8000，所以M2的性价比高，应选择M2。

若用几何平均方式，则：因为sqrt(10×0.003) ×5000 &lt; sqrt(5×0.006) ×8000，所以M1的性价比高，应选择M1。</code></pre>
<p>7．若机器M1和M2具有相同的指令集，其时钟频率分别为1GHz和1.5GHz。在指令集中有五种不同类型的指令A~E。下表给出了在M1和M2上每类指令的平均时钟周期数CPI。</p>
<table>
<thead>
<tr>
<th>机器</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr>
<td>M1</td>
<td>1</td>
<td>2</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>M2</td>
<td>2</td>
<td>2</td>
<td>4</td>
<td>5</td>
<td>6</td>
</tr>
</tbody>
</table>
<p>请回答下列问题： （1）M1和M2的峰值MIPS各是多少？</p>
<pre><code>M1上可以选择一段都是A类指令组成的程序，其峰值MIPS为1000MIPS。
M2上可以选择一段A和B类指令组成的程序，其峰值MIPS为1500/2=750MIPS。</code></pre>
<p>（2）假定某程序P的指令序列中，五类指令具有完全相同的指令条数，则程序P在M1和M2上运行时，哪台机器更快？快多少？在M1和M2上执行程序P时的平均时钟周期数CPI各是多少？</p>
<pre><code>5类指令具有完全相同的指令条数，所以各占20%。
在M1和M2上执行程序P时的平均时钟周期数CPI分别为：
    M1：20%×(1+2+2+3+4)= 0.2×12 = 2.4
    M2：20%×(2+2+4+5+6)= 0.2×19 = 3.8
假设程序P的指令条数为N，则在M1和M2上的执行时间分别为：
    M1：2.4× N×1/1G = 2.4N (ns)
    M2：3.8×N×1/1.5G = 2.53 N (ns)
M1执行P的速度更快，每条指令平均快0.13ns，也即M1比M2快0.13/2.53×100%≈5%。</code></pre>
<p>8．假设同一套指令集用不同的方法设计了两种机器M1和M2。机器M1的时钟周期为0.8ns，机器M2的时钟周期为1.2ns。某个程序P在机器M1上运行时的CPI为4，在M2上的CPI为2。对于程序P来说，哪台机器的执行速度更快？快多少？</p>
<pre><code>假设程序P的指令条数为N，则在M1和M2上的执行时间分别为：
    M1：4 N×0.8 = 3.2N (ns)
    M2：2 N×1.2 = 2.4 N (ns)  
所以，M2执行P的速度更快，每条指令平均快0.8ns，比M1快0.8/3.2×100%=25%。</code></pre>
<p>9．假设某机器M的时钟频率为4GHz，用户程序P在M上的指令条数为8×109，其CPI为1.25，则P在M上的执行时间是多少？若在机器M上从程序P开始启动到执行结束所需的时间是4秒，则P占用的CPU时间的百分比是多少？</p>
<pre><code>程序P在M上的执行时间为：1.25×8××1/4G = 2.5 s，
从启动P执行开始到执行结束的总时间为4秒，
其中2.5秒是P在CPU上真正的执行时间，
其他时间可能执行操作系统程序或其他用户程序。
程序P占用的CPU时间的百分比为：2.5/4 = 62.5%。</code></pre>
<p>10．假定某编译器对某段高级语言程序编译生成两种不同的指令序列S1和S2，在时钟频率为500MHz的机器M上运行，目标指令序列中用到的指令类型有A、B、C和D四类。四类指令在M上的CPI和两个指令序列所用的各类指令条数如下表所示。
| | A | B | C | D | |–| —|—|—|—| 各指令的CPI 1 2 3 4 S1的指令条数 5 2 2
1 S2的指令条数 1 1 1 5</p>
<p>请问：S1和S2各有多少条指令？CPI各为多少？所含的时钟周期数各为多少？执行时间各为多少？</p>
<pre><code>S1有10条指令，CPI为 (5×1+2×2+2×3+1×4)/10=1.9, 所含的时钟周期数为10×1.9=19，执行时间为19/500M = 38ns。
S2有8条指令，CPI为 (1×1+1×2+1×3+5×4)/8 =3.25, 所含的时钟周期数为8×3.25=26，执行时间为26/500M = 52ns。 </code></pre>
<p>10．假定机器M的时钟频率为1.2GHz，某程序P在机器M上的执行时间为12秒钟。对P优化时，将其所有的乘4指令都换成了一条左移2位的指令，得到优化后的程序P’。已知在M上乘法指令的CPI为5，左移指令的CPI为2，P的执行时间是P’执行时间的1.2倍，则P中有多少条乘法指令被替换成了左移指令被执行？
参考答案：
显然，P’的执行时间为10秒，因此，P比P’多花了2秒钟，因此，执行时被换成左移指令的乘法指令的条数为1.2G×2/(5–2)
= 800M。</p>
<h2 id="第二章计算机系统基本功能和基本组成">第二章计算机系统基本功能和基本组成</h2>
<p>1、见习题解答。</p>
<p>2、简单回答下列问题。</p>
<p>（1）为什么计算机内部采用二进制表示信息？既然计算机内部所有信息都用二进制表示，为什么还要用到十六进制或八进制数？</p>
<p>制造两个稳定状态的元器件比多个稳定状态的元器件要容易，两个稳定状态对应高低电平，正好可以用0/1表示；二进制编码规则简单，可用开关电路实现；方便通过逻辑电路实现算术运算。
二进制硬件容易理解，但是不方便书写和阅读。</p>
<p>（2）常用的定点数编码方式有哪几种？ 通常它们各自用来表示什么？</p>
<p>原码：用定点原码表示浮点数的尾数部分；</p>
<p>补码：带符号整数；</p>
<p>反码：</p>
<p>移码：</p>
<p>（3）为什么计算机中大多用补码表示带符号整数？</p>
<p>（4）在浮点数的基和位数一定的情况下，浮点数的表数范围和表数精度分别由什么决定？两者如何相互制约？</p>
<p>（5）为什么要对浮点数进行规格化？有哪两种规格化操作？</p>
<p>（6）为什么有些计算机中除了用二进制外还用 BCD 码来表示数值数据？</p>
<p>（7）为什么计算机处理汉字时会涉及到不同的编码（如，输入码、内码、字模码）？说明这些编码中哪些是用二进制编码，哪些不是用二进制编码，为什么？</p>
<p>3．实现下列各数的转换。 （1）(25.8125)10= (?)2= (?) 8= (?) 16</p>
<p>（2）(101101.011)2 = (?)10= (?) 8= (?) 16= (?) 8421</p>
<p>（3）(0101 1001 0110.0011)8421 = (?)10= (?) 2= (?) 16</p>
<p>（4）(4E.C)16 = (?)10= (?) 2</p>
<p>参考答案：</p>
<p>（1） (25.8125)10 = (1 1001.1101)2 = (31.64) 8 = (19.D) 16</p>
<p>（2）(101101.011)2 = (45.375)10 = (55.3) 8 = (2D.6) 16 = (0100
0101.0011 0111 0101) 8421</p>
<p>（3）(0101 1001 0110.0011)8421 = (596.3)10 =
(1001010100.01001100110011…) 2 = (254.4CCC…) 16</p>
<p>（4）(4E.C)16 = (78.75)10 = (0100 1110.11) 2</p>
<p>4．
假定机器数为8位（1位符号，7位数值），写出下列各二进制数的原码和补码表示。
+0.1001，–0.1001，+1.0，–1.0，+0.010100，–0.010100，+0，–0</p>
<p>参考答案： | 原码 | 补码 | |—– |—–| |+0.1001： 0.1001000 0.1001000
–0.1001： 1.1001000 1.0111000 +1.0： 溢出 溢出 –1.0： 溢出 1.0000000
+0.010100： 0.0101000 0.0101000 –0.010100： 1.0101000 1.1011000 +0：
0.0000000 0.0000000 –0： 1.0000000 0.0000000</p>
<p>5．
假定机器数为8位（1位符号，7位数值），写出下列各二进制数的补码和移码表示。
+1001，–1001，+1，–1，+10100，–10100，+0，–0 参考答案：<br>
移码 补码 +1001： 10001001 00001001 –1001： 01110111 11110111 +1：
10000001 00000001 –1： 011111111 11111111 +10100： 10010100 00010100
–10100： 01101100 11101100 +0： 10000000 00000000 –0： 10000000
00000000</p>
<p>6． 已知 [x]补，求x （1）[x]补=1.1100111 （2）[x]补=10000000
（3）[x]补=0.1010010 （4）[x]补=11010011 参考答案： （1）[x]补=1.1100111
x = –0.0011001B （2）[x]补=10000000 x = –10000000B = –128
（3）[x]补=0.1010010 x = +0.101001B （4）[x]补=11010011 x = – 101101B =
– 45</p>
<p>7．假定一台32位字长的机器中带符号整数用补码表示，浮点数用IEEE
754标准表示，寄存器R1和R2的内容分别为R1：0000108BH，R2：8080108BH。不同指令对寄存器进行不同的操作，因而，不同指令执行时寄存器内容对应的真值不同。假定执行下列运算指令时，操作数为寄存器R1和R2的内容，则R1和R2中操作数的真值分别为多少？
（1）无符号数加法指令 （2）带符号整数乘法指令 （3）单精度浮点数减法指令
参考答案： R1 = 0000108BH = 0000 0000 0000 0000 0001 0000 1000 1011b R2
= 8080108BH = 1000 0000 1000 0000 0001 0000 1000 1011b
（1）对于无符号数加法指令，R1和R2中是操作数的无符号数表示，因此，其真值分别为R1：108BH,
R2：8080108BH。
（2）对于带符号整数乘法指令，R1和R2中是操作数的带符号整数补码表示，由最高位可知，
R1为正数， R2为负数。R1的真值为+108BH, R2的真值为–(0111 1111 0111 1111
1110 1111 0111 0100b + 1b) = –7F7FEF75H。
（3）对于单精度浮点数减法指令，R1和R2中是操作数的IEEE754单精度浮点数表示。在IEEE
754
标准中，单精度浮点数的位数为32位，其中包含1位符号位，8位阶码，23位尾数。
由R1中的内容可知，其符号位为0，表示其为正数，阶码为0000
0000，尾数部分为000 0000 0001 0000 1000
1011，故其为非规格化浮点数，指数为–126，尾数中没有隐藏的1，用十六进制表示尾数为+0.002116H，故R1表示的真值为+0.002116H
× 10-126。 由R2中的内容可知，其符号位为1，表示其为负数，阶码为0000
0001， 尾数部分为000 0000 0001 0000 1000
1011，故其为规格化浮点数，指数为1–127 =
–126，尾数中有隐藏的1，用十六进制表示尾数为–1.002116H，故R2表示的真值为–1.002116H
× 10-126</p>
<p>8．假定机器M的字长为32位，用补码表示带符号整数。下表第一列给出了在机器M上执行的C语言程序中的关系表达式，请参照已有的表栏内容完成表中后三栏内容的填写。
关系表达式 运算类型 结果 说明 0 == 0U –1 &lt; 0 –1 &lt; 0U 2147483647
&gt; –2147483647 – 1 2147483647U &gt; –2147483647 – 1 2147483647 &gt;
(int) 2147483648U –1 &gt; –2 (unsigned) –1 &gt; –2 无符号整数 有符号整数
无符号整数 有符号整数 无符号整数 有符号整数 有符号整数 无符号整数 1 1 0
1 0 1 1 1 00…0B = 00…0B 11…1B (–1) &lt; 00…0B (0) 11…1B (232–1) &gt;
00…0B(0) 011…1B (231–1) &gt; 100…0B (–231) 011…1B (231–1) &lt;
100…0B(231) 011…1B (231–1) &gt; 100…0B (–231) 11…1B (–1) &gt; 11…10B
(–2) 11…1B (232–1) &gt; 11…10B (232–2)</p>
<p>9．以下是一个C语言程序，用来计算一个数组a中每个元素的和。当参数len为0时，返回值应该是0，但是在机器上执行时，却发生了存储器访问异常。请问这是什么原因造成的，并说明程序应该如何修改。
1 float sum_elements(float a[], unsigned len) 2 { 3 int i; 4 float
result = 0; 5 6 for (i = 0; i &lt;= len–1; i++) 7 result += a[i]; 8
return result; 9 }</p>
<p>参考答案：
参数len的类型是unsigned，所以，当len=0时，执行len-1的结果为11…1，是最大可表示的无符号数，因而，任何无符号数都比它小，使得循环体被不断执行，引起数组元素的访问越界，发生存储器访问异常。
只要将len声明为int型，或循环的测试条件改为i&lt;len。</p>
<ol type="1">
<li>设某浮点数格式为：</li>
</ol>
<p>其中，移码的偏置常数为16，补码采用一位符号位，基数为4。
（1）用这种格式表示下列十进制数：+1.7，–0.12，+19，–1/8。
（2）写出该格式浮点数的表示范围，并与12位定点补码整数表示范围比较。
参考答案：（假定采用0舍1入法进行舍入） （1） +1.7 = +1.1011001B =
0.011011B× 41, 故阶码为1 +16 = 17 = 10001B, 尾数为+0.011011的补码，
即0.011011，所以+1.7表示为0 10001 011011。</p>
<pre><code>–0.12 = – 0.000111101B = – 0.011111B × 4–1, 故阶码为 –1 + 16 =15 = 01111B, 尾数为– 0.011111的补码，即1.100001, 所以–0.12表示为1 01111 100001。

+19 = +10011B = 0.010011B× 43，故阶码为3 + 16 = 19 = 10011B, 尾数为0.010011，所以+19表示为0 10011 010011。

–1/8 = – 0.125 = – 0.001B = – 0.100000 × 4–1，阶码为 –1 + 16 = 15 = 01111B，尾数为– 0.100000的补码，即1.100000，所以–1/8表示为1 01111 100000。</code></pre>
<p>（2）该格式浮点数表示的范围如下。 正数最大值：0.111111B ×
411111，即：0.333× 415 （≈230 ≈109） 正数最小值：0.000001B ×
400000，即：0.001× 4–16 （≈2–34≈10–10） 负数最大值：–0.000001B ×
400000，即：–0.001× 4–16 负数最小值：–1.000000B × 411111，即：–1.000×
415 因此，该格式浮点数的数量级在10–10～109之间。
12位定点补码整数的表示范围为：–211～+(211–1)，即：–2048～2047
由此可见，定点数和浮点数的表示范围相差非常大。</p>
<ol start="11" type="1">
<li><p>下列几种情况所能表示的数的范围是什么？ （1）16位无符号整数
（2）16位原码定点小数 （3）16位补码定点小数 （4）16位补码定点整数
（5）下述格式的浮点数（基数为2，移码的偏置常数为128）</p>
<p>参考答案： （1）无符号整数：0～216–1。 （2）原码定点小数：–(1–2–15)
～ + (1–2–15)。 （3）补码定点小数：–1 ～ + (1–2–15)。
（4）补码定点整数：–32768 ～ +32767。 （5）浮点数：负数：– (1–2–7)×2+127
～ –2–7×2–128。 正数：+2–135 ～ (1–2–7) ×2+127。</p></li>
<li><p>以IEEE 754单精度浮点数格式表示下列十进制数。
+1.75，+19，–1/8，258 参考答案： +1.75 = +1.11B = 1.11B × 20,
故阶码为0+127=01111111B,
数符为0，尾数为1.110…0，小数点前为隐藏位，所以+1.7表示为0 01111111 110
0000 0000 0000 0000 0000，用十六进制表示为3FE00000H。</p>
<p>+19 = +10011B = +1.0011B × 24，故阶码为4+127 = 10000011B,
数符为0，尾数为1.00110…0，所以+19表示为0 10000011 001 1000 0000 0000
0000 0000，用十六进制表示为41980000H。</p>
<p>–1/8 = – 0.125 = – 0.001B = – 1.0 × 2–3，阶码为–3+127 =
01111100B，数符为1，尾数为1.0…0，所以–1/8表示为1 01111100 000 0000 0000
0000 0000 0000，用十六进制表示为BE000000H。</p></li>
</ol>
<p>258=100000010B=1.0000001B × 28, 故阶码为8+127=10000111B,
数符为0，尾数为1.0000001，所以258表示为0 10000111 000 0001 0000 0000
0000 0000，用十六进制表示为43810000H。</p>
<p>13．设一个变量的值为4098，要求分别用32位补码整数和IEEE
754单精度浮点格式表示该变量（结果用十六进制表示），并说明哪段二进制序列在两种表示中完全相同，为什么会相同？
参考答案： 4098 = +1 0000 0000 0010B = +1. 0000 0000 001 × 212
32位2-补码形式为：0000 0000 0000 0000 0001 0000 0000 0010 （00001002H）
IEEE754单精度格式为：0 10001011 0000 0000 0010 0000 0000 000
（45801000H）
粗体部分为除隐藏位外的有效数字，因此，在两种表示中是相同的序列。</p>
<p>14．设一个变量的值为–2147483647，要求分别用32位补码整数和IEEE754单精度浮点格式表示该变量（结果用十六进制表示），并说明哪种表示其值完全精确，哪种表示的是近似值。
参考答案： –2147483647 = –111 1111 1111 1111 1111 1111 1111 1111B =
–1.11 1111 1111 1111 1111 1111 1111 1111 × 230 32位2-补码形式为：1000
0000 0000 0000 0000 0000 0000 0001 （80000001H） IEEE 754单精度格式为：1
10011101 1111 1111 1111 1111 1111 111 （CEFFFFFFH）
32位2-补码形式能表示精确的值，而浮点数表示的是近似值，低位被截断</p>
<p>15．下表给出了有关IEEE
754浮点格式表示中一些重要数据的取值，表中已经有最大规格化数的相应内容，要求填入其他浮点数的相应内容。（注：表中a代表一个在1到10之间的正纯小数）
项目 阶码 尾数 单精度 双精度 以2的幂次表示的值 以10的幂次表示的值
以2的幂次表示的值 以10的幂次表示的值 0 1 最大规格化数 最小规格化数
最大非规格化数 最小非规格化数 +∞ NaN 00000000 01111111 11111110 00000001
00000000 00000000 11111111 11111111 0….00 0….00 1…11 0….00 1…11 0…01
0….00 非全0 0 1 (2–2–23)×2127 1.0×2–126 (1–2–23)×2–126 2–23×2–126=2–149
– – 0 1 a×1038 a×10–38 a×10–38 a×10–44 – – 0 1 (2–2–52)×21023 1.0×2–1022
(1–2–52)×2–1022 2–52×2–1022 – – 0 1 a×10308 a×10–308 a×10–308 a×10–? –
–</p>
<p>16．已知下列字符编码：A=100 0001，a=110 0001，0=011
0000，求E、e、f、7、G、Z、5的7位ACSII码和第一位前加入奇校验位后的8位编码。
参考答案： E的ASCII码为 ‘A’ + (‘E’ – ‘A’) = 100 0001 + 100 = 100 0101,
奇校验位P = 0，第一位前加入奇校验位后的8位编码是0 100 0101。
e的ASCII码为‘a’+ (‘e’ – ‘a’) = 110 0001 + 100 = 110 0101， 奇校验位P =
1, 第一位前加入奇校验位后的8位编码是1 110 0101。 f的ASCII码为‘a’+ (‘f’ –
‘a’) = 110 0001 + 101 = 110 0110, 奇校验位P = 1, 第一位前
加入奇校验位后的8位编码是 1 110 0110。 7的ASCII码为‘0’+ (7 - 0) = 011
0000 + 111 = 011 0111,奇校验位P = 0, 第一位前加入奇校验位后的8位编码是0
011 0111。 G的ASCII码为‘A’+ (‘G’ – ‘A’) = 100 0001 + 0110 = 100 0111,
奇校验位P = 1, 第一位前加入奇校验位后的8位编码是1 100 0111。
Z的ASCII码为‘A’+(‘Z’ – ‘A’) = 100 0001 + 11001 = 101 1010, 奇校验位P =
1, 第一位前加入奇校验位后的8位编码是 1 101 1010。 5的ASCII码为‘0’+(5 –
0) = 011 0000 + 101 = 011 0101， 奇校验位P = 1,
第一位前加入奇校验位后的8位编码是 1 011 0101。</p>
<p>17．假定在一个程序中定义了变量x、y和i，其中，x和y是float型变量（用IEEE754单精度浮点数表示），i是16位short型变量（用补码表示）。程序执行到某一时刻，x
=
–0.125、y=7.5、i=100，它们都被写到了主存（按字节编址），其地址分别是100，108和112。请分别画出在大端机器和小端机器上变量x、y和i在内存的存放位置。
参考答案： –0.125 = –0.001B = –1.0 × 2-3 x在机器内部的机器数为：1
01111100 00…0 (BE00 0000H) 7.5= +111.1B= +1.111 × 22
y在机器内部的机器数为：0 10000001 11100…0 (40F0 0000H)
100=64+32+4=1100100B i在机器内部表示的机器数为：0000 0000 0110
0100（0064H） 大端机 小端机 地址 内容 内容<br>
100 BEH 00H 101 00H 00H 102 00H 00H 103 00H BEH 108 40H 00H 109 F0H 00H
110 00H F0H 111 00H 40H 112 00H 64H 113 64H 00H</p>
<p>18．假定某计算机的总线采用奇校验，每8位数据有一位校验位，若在32位数据线上传输的信息是8F
3C AB
96H，则对应的4个校验位应为什么？若接受方收到的数据信息和校验位分别为87
3C AB 96H和0101B，则说明发生了什么情况，并给出验证过程。 参考答案：
传输信息8F 3C AB 96H展开为1000 1111 0011 1100 1010 1011 1001
0110，每8位有一个奇校验位，因此，总线上发送方送出的4个校验位应该分别为0、1、0、1。
接受方的数据信息为87 3C AB 96H，展开后为1000 0111 0011 1100 1010 1011
1001 0110；接收到的校验位分别为0、1、0、1。在接受方进行校验判断如下：
根据接收到的数据信息计算出4个奇校验位分别为1、1、0、1，将该4位校验位分别和接收到的4位校验位进行异或，得到1、0、0、0，说明数据信息的第一个字节发生传输错误。对照传输前、后的数据信息，第一字节8FH变成了87H，说明确实发生了传输错误，验证正确。</p>
<p>19．写出16位数据的SEC码。假定数据为0101 0001 0100
0110，说明SEC码如何正确检测数据位5的错误。 参考答案： 对于16位数据，
可以如下插入校验位： M16 M15 M14 M13 M12 P5 M11 M10 M9 M8 M7 M6 M5 P4 M4
M3 M2 P3 M1 P2 P1 其中Mi是原信息数据， Pi是加入的校验位，
对于各个校验位的值可以如下计算 P1 = M1⊕M2⊕M3⊕M4⊕M5⊕M7⊕M9⊕M11⊕M12⊕M14⊕M16
= 1 P2 = M1⊕M3⊕M4⊕M6⊕M7⊕M10⊕M11⊕M13⊕M14 = 1 P3 =
M2⊕M3⊕M4⊕M8⊕M9⊕M10⊕M11⊕M15⊕M16 = 0 P4 = M5⊕M6⊕M7⊕M8⊕M9⊕M10⊕M11 = 0 P5 =
M12⊕M13⊕M14⊕M15⊕M16 = 0 所以此时P5 P4 P3 P2 P1 =
00011，第五位数据出错时，数据字变为：0101 0001 0101
0110，P5’P4’P3’P2’P1’= 01010，故障字 = 00011⊕01010 =
01001，说明码字第9位出错，即M5出错。</p>
<p>20．假设要传送的数据信息为：100011，若约定的生成多项式为：G(x)=
x3+1，则校验码为多少？假定在接收端接收到的数据信息为100010，说明如何正确检测其错误，写出检测过程。</p>
<p>参考答案： 原数据信息为100011，对应的报文多项式为M(x) = x5 + x + 1,
生成多项式的位数为4位， 所以在原数据信息后面添加3个0，变为M’(x) = x3M(x)
= x8 + x4 + x3, 用M(x)去模2除G(x)，得到的余数为111，
所以得到CRC码为100011 111。</p>
<pre><code>检测时， 用接收到的CRC码去模2除生成多项式1001，若得到的余数为0，则表明正确，否则说明传输时发生了错误。此题中接收到的CRC码为100010 111（即数据100010加检验位111），显然，用100010 111 模2除 1001，得到余数为001，不为0，说明传输时发生错误。</code></pre>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础期末笔记汇总</title>
    <url>/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<h3 id="笔记">笔记</h3>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165933.jpg" alt="IMG_20250706_165933">
<figcaption aria-hidden="true">IMG_20250706_165933</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165925.jpg" alt="IMG_20250706_165925">
<figcaption aria-hidden="true">IMG_20250706_165925</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165919.jpg" alt="IMG_20250706_165919">
<figcaption aria-hidden="true">IMG_20250706_165919</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165914.jpg" alt="IMG_20250706_165914">
<figcaption aria-hidden="true">IMG_20250706_165914</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165903.jpg" alt="IMG_20250706_165903">
<figcaption aria-hidden="true">IMG_20250706_165903</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165909.jpg" alt="IMG_20250706_165909">
<figcaption aria-hidden="true">IMG_20250706_165909</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——期末复习（下）</title>
    <url>/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
    <content><![CDATA[<h2 id="期末复习">期末复习</h2>
<h3 id="方差与偏差">方差与偏差</h3>
<p>方差（Variance）和偏差（Bias）是机器学习中衡量模型性能的两个核心概念，它们共同构成了<strong>偏差-方差权衡</strong>（Bias-Variance
Tradeoff）的基础框架。以下是两者的定义与区别：</p>
<p><strong>1. 偏差（Bias）</strong></p>
<ul>
<li><strong>定义</strong>：偏差是指模型预测的期望值与真实值之间的差异。它反映了模型本身的拟合能力，即是否能够准确捕捉数据中的规律。</li>
</ul>
<p><strong>2. 方差（Variance）</strong></p>
<ul>
<li><strong>定义</strong>：方差是指模型在不同训练数据集下预测结果的波动程度。它衡量了模型对训练数据中噪声或微小变化的敏感性。</li>
</ul>
<p><strong>3. 如何降低偏差与方差</strong></p>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 56%">
<col style="width: 32%">
</colgroup>
<thead>
<tr>
<th><strong>目标</strong></th>
<th><strong>方法</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>降低偏差</strong></td>
<td>增加模型复杂度（如更多特征、更深的神经网络）、减少正则化强度</td>
<td>使用多项式回归替代线性回归</td>
</tr>
<tr>
<td><strong>降低方差</strong></td>
<td>增加训练数据、引入正则化（L1/L2）、使用集成方法（如
Bagging、Boosting）</td>
<td>随机森林（Bagging）降低决策树的方差</td>
</tr>
</tbody>
</table>
<p><strong>4. 总结</strong></p>
<ul>
<li><strong>偏差</strong>关注模型是否能准确拟合数据（<strong>学习能力</strong>），而<strong>方差</strong>关注模型对数据波动的稳定性（<strong>泛化能力</strong>）。</li>
<li>实际应用中需通过交叉验证、正则化或集成学习等技术平衡两者的关系。</li>
</ul>
<h3 id="监督学习与无监督学习">监督学习与无监督学习</h3>
<p>以下是关于监督学习与无监督学习的核心区别总结：</p>
<p><strong>1. 监督学习（Supervised Learning）</strong></p>
<p><strong>任务类型</strong>：<br>
-
<strong>分类（Classification）</strong>：预测离散类别标签（如垃圾邮件/非垃圾邮件）。<br>
-
<strong>回归（Regression）</strong>：预测连续数值标签（如房价预测）。</p>
<p><strong>特点</strong>：<br>
- 需要<strong>带标签的样本</strong>（Labeled
Data），即每个训练样本都有明确的输入 $ x $ 和输出 $ y $。<br>
- 模型通过学习输入与标签之间的映射关系进行预测。</p>
<p><strong>2. 无监督学习（Unsupervised Learning）</strong></p>
<p><strong>任务类型</strong>：</p>
<ul>
<li><strong>聚类（Clustering）</strong>：将样本划分为具有相似特征的群体（如客户分群）。<br>
</li>
<li><strong>降维（Dimensionality
Reduction）</strong>：压缩数据维度同时保留关键信息（如PCA）。</li>
</ul>
<p><strong>特点</strong>：<br>
- 仅需<strong>无标签的样本</strong>（Unlabeled
Data），无需预先定义输出目标。<br>
- 模型自主挖掘数据内在结构或分布规律。</p>
<h3 id="贝叶斯分类">贝叶斯分类</h3>
<h4 id="贝叶斯分类器">贝叶斯分类器</h4>
<h5 id="贝叶斯决策论">贝叶斯决策论</h5>
<p>本质思想：寻找合适的参数使得「当前的样本情况发生的概率」最大。</p>
<p>又由于假设每一个样本相互独立（概率条件理想的情况下），因此可以用连乘的形式表示上述概率，当然由于概率较小导致连乘容易出现浮点数精度损失，因此尝尝采用取对数的方式来避免「下溢」问题。也就是所谓的「对数似然估计」方法。</p>
<p>在已知样本特征 $ $ 的条件下，选择分类结果 $ c_i
$，使得分类的期望损失（Risk）最小<strong>。</strong></p>
<p>**(1) 损失函数 $ _{ij} $**</p>
<ul>
<li><strong>定义</strong>：$ _{ij} $ 是将真实类别为 $ c_j $
的样本误分类为 $ c_i $ 所产生的损失。
<ul>
<li>例如：
<ul>
<li>在医学诊断中，若 $ c_1 $ 表示“患病”，$ c_2 $ 表示“未患病”：
<ul>
<li>$ _{21} <span class="math inline">：<em>将</em><em>实</em><em>际</em><em>患</em><em>病</em>（</span>
c_1 <span class="math inline">）<em>误</em><em>判</em><em>为</em><em>未</em><em>患</em><em>病</em>（</span>
c_2 $）的损失（可能更高）。</li>
<li>$ _{12} <span class="math inline">：<em>将</em><em>实</em><em>际</em><em>未</em><em>患</em><em>病</em>（</span>
c_2 <span class="math inline">）<em>误</em><em>判</em><em>为</em><em>患</em><em>病</em>（</span>
c_1 $）的损失（可能较低）。</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p><strong>(2) 条件风险（单个样本的期望损失）</strong></p>
<p>对于给定样本 $ $，若将其分类为 $ c_i <span class="math inline">，<em>则</em><em>其</em> * *<em>条</em><em>件</em><em>风</em><em>险</em> * *<em>为</em>：</span>$
R(c_i | ) = <em>{j=1}^N </em>{ij} P(c_j | ) $$ -
<strong>含义</strong>：在已知 $ $ 的情况下，分类为 $ c_i $ 的平均损失。
- <strong>推导</strong>： - $ P(c_j | ) $：样本 $ $ 真实属于 $ c_j $
的后验概率。 - $ <em>{ij} $：若真实类别是 $ c_j $，但被分到 $ c_i
$，则产生损失 $ </em>{ij} $。 -
因此，总期望损失是所有可能真实类别的加权和（权重为后验概率）。</p>
<p><strong>(3) 总体风险</strong></p>
<p>对于整个数据集，分类器 $ h() $ 的<strong>总体风险</strong>为： <span class="math display"><em>R</em>(<em>h</em>) = 𝔼<sub><strong>x</strong></sub>[<em>R</em>(<em>h</em>(<strong>x</strong>)|<strong>x</strong>)] = ∫<em>R</em>(<em>h</em>(<strong>x</strong>)|<strong>x</strong>)<em>p</em>(<strong>x</strong>)<em>d</em><strong>x</strong></span>
- <strong>含义</strong>：所有样本的平均条件风险。h为分类器（模型） -
<strong>目标</strong>：找到使 $ R(h) $ 最小的分类器 $ h() $。</p>
<h5 id="贝叶斯决策规则"><strong>贝叶斯决策规则</strong></h5>
<p>根据上述定义，贝叶斯决策论的分类规则是： &gt; <strong>对于样本 $
$，选择使其条件风险 $ R(c_i | ) $ 最小的类别 $ c_i $
作为预测结果。</strong></p>
<p>即： <span class="math display">$$
h^*(\mathbf{x}) = \arg\min_{c_i} R(c_i | \mathbf{x}) = \arg\min_{c_i}
\sum_{j=1}^N \lambda_{ij} P(c_j | \mathbf{x})
$$</span></p>
<h5 id="特殊情况0-1-损失函数"><strong>特殊情况：0-1
损失函数</strong></h5>
当所有误分类的损失相同（即 $ <em>{ij} = 1 $ 对于 $ i j <span class="math inline">，</span> </em>{ii} = 0 <span class="math inline">） * *0 − 1<em>损</em><em>失</em><em>函</em><em>数</em> * *：</span>$
_{ij} =
<p><span class="math display"><em>此</em><em>时</em><em>条</em><em>件</em><em>风</em><em>险</em><em>简</em><em>化</em><em>为</em>：</span>
R(c_i | ) = <em>{j i} P(c_j | ) = 1 - P(c_i | ) $$ 原因：概率之和为 1：$
</em>{j=1}^N P(c_j | ) = 1 $，因此 $ _{j i} P(c_j | ) = 1 - P(c_i | )
$。</p>
<p>此时，最小化风险等价于<strong>最大化后验概率</strong>，即： <span class="math display"><em>h</em><sup>*</sup>(<strong>x</strong>) = arg max<sub><em>c</em><sub><em>i</em></sub></sub><em>P</em>(<em>c</em><sub><em>i</em></sub>|<strong>x</strong>)</span>
这正是传统贝叶斯分类器的决策规则。</p>
<blockquote>
<p>即在x样本的情况下，分类正确的概率最大</p>
</blockquote>
<h4 id="后验概率与先验概率">后验概率与先验概率</h4>
<h5 id="后验概率">后验概率</h5>
<p>后验概率（Posterior
Probability）是贝叶斯理论中的核心概念，指的是<strong>在观察到新证据（数据）后，对事件发生概率的修正</strong>
。 其本质是：</p>
<blockquote>
<p><strong>“已知结果（数据），反推原因（类别或参数）的概率”</strong>
。</p>
</blockquote>
<p>已知结果（数据）B，反推最可能的原因A（后验概率
<em>P</em>(<em>A</em>∣<em>B</em>) ）</p>
<h5 id="先验概率prior-probability"><strong>先验概率（Prior
Probability）</strong></h5>
<p>先验概率是贝叶斯统计中的核心概念，指的是在<strong>观察到新数据之前</strong>，对某一事件或假设的概率估计。它是基于<strong>已有知识、经验或假设</strong>得出的初始概率，后续会通过新数据更新为更准确的<strong>后验概率</strong>。</p>
<p><strong>1. 核心定义</strong></p>
<ul>
<li><strong>数学表达</strong>：<br>
<span class="math display"><em>P</em>(<em>A</em>)</span>
<ul>
<li>$ P(A) $：事件 $ A $ 的先验概率。</li>
<li>例如：$ A $ 表示“某人患有某种疾病”，则 $ P(A) $
是该疾病的已知发病率（在未进行检测前的概率）。</li>
</ul></li>
<li><strong>与后验概率的区别</strong>：
<ul>
<li><strong>先验概率</strong>：$ P(A) $，在无新数据时的概率。<br>
</li>
<li><strong>后验概率</strong>：$ P(A|B) $，在观察到数据 $ B $
后更新的概率（通过贝叶斯定理计算）。</li>
</ul></li>
</ul>
<p><strong>2. 直观理解</strong></p>
<p><strong>(1) 类比：医学诊断</strong></p>
<ul>
<li><strong>先验概率</strong>：某种疾病的已知发病率（如 1%）。<br>
</li>
<li><strong>新数据</strong>：患者接受检测，结果为阳性。<br>
</li>
<li><strong>后验概率</strong>：结合发病率和检测结果，计算实际患病的概率（如
8.7%，参考贝叶斯定理的经典医学测试案例）。</li>
</ul>
<h4 id="生成式模型和判别式模型">生成式模型和判别式模型</h4>
<h5 id="核心区别"><strong>核心区别</strong></h5>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 44%">
<col style="width: 44%">
</colgroup>
<thead>
<tr>
<th><strong>模型类型</strong></th>
<th><strong>建模目标</strong></th>
<th><strong>数学表达</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>判别式模型</strong></td>
<td>直接建模 $ P(c</td>
<td>) $</td>
</tr>
<tr>
<td><strong>生成式模型</strong></td>
<td>先建模联合概率 $ P(, c) $，再推导 $ P(c</td>
<td>) $</td>
</tr>
</tbody>
</table>
<h5 id="详细解释"><strong>详细解释</strong></h5>
<p><strong>1. 判别式模型（Discriminative Model）</strong></p>
<ul>
<li><strong>目标</strong>：直接学习从输入 $ $ 到标签 $ c $
的映射关系。</li>
<li><strong>数学本质</strong>：建模条件概率 $ P(c|) $，即“已知特征 $
$，预测类别 $ c $”。</li>
<li><strong>特点</strong>：
<ul>
<li>不关心数据本身的分布，只关注分类边界。</li>
<li>例如：逻辑回归、支持向量机（SVM）、神经网络等。</li>
</ul></li>
</ul>
<p><strong>2. 生成式模型（Generative Model）</strong></p>
<ul>
<li><p><strong>目标</strong>：先学习数据的生成过程，即联合概率 $ P(, c)
$，再通过贝叶斯定理推导条件概率 $ P(c|) $。</p></li>
<li><p><strong>数学步骤</strong>：</p>
<ol type="1">
<li>建模 $ P(|c) $（特征在类别 $ c $ 下的分布）和 $ P(c)
$（类别先验）。</li>
<li>根据贝叶斯定理计算后验概率： <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(\mathbf{x}|c)P(c)}{P(\mathbf{x})}
$$</span></li>
<li>选择使 $ P(c|) $ 最大的类别作为预测结果。</li>
</ol></li>
</ul>
<h5 id="示例二分类问题"><strong>示例：二分类问题</strong></h5>
<p>假设我们要判断一封邮件是否为垃圾邮件（$ c=spam $ 或 $ ham $）。</p>
<p><strong>判别式模型（逻辑回归）</strong></p>
<p>直接建模： <span class="math display">$$
P(spam|\mathbf{x}) = \frac{1}{1 + e^{-(w^T \mathbf{x} + b)}}
$$</span> 若 $ P(spam|) &gt; 0.5 $，则判定为垃圾邮件。</p>
<p><strong>生成式模型（朴素贝叶斯）</strong></p>
<ol type="1">
<li>建模联合概率： <span class="math display"><em>P</em>(<strong>x</strong>, <em>s</em><em>p</em><em>a</em><em>m</em>) = <em>P</em>(<em>s</em><em>p</em><em>a</em><em>m</em>)∏<sub><em>i</em></sub><em>P</em>(<em>w</em><em>o</em><em>r</em><em>d</em><sub><em>i</em></sub>|<em>s</em><em>p</em><em>a</em><em>m</em>)</span>
<span class="math display"><em>P</em>(<strong>x</strong>, <em>h</em><em>a</em><em>m</em>) = <em>P</em>(<em>h</em><em>a</em><em>m</em>)∏<sub><em>i</em></sub><em>P</em>(<em>w</em><em>o</em><em>r</em><em>d</em><sub><em>i</em></sub>|<em>h</em><em>a</em><em>m</em>)</span></li>
<li>计算后验概率： <span class="math display">$$
P(spam|\mathbf{x}) = \frac{P(\mathbf{x}|spam)P(spam)}{P(\mathbf{x})}
$$</span> <span class="math display">$$
P(ham|\mathbf{x}) = \frac{P(\mathbf{x}|ham)P(ham)}{P(\mathbf{x})}
$$</span></li>
<li>选择概率更大的类别。</li>
</ol>
<h4 id="生成式模型的建模思路">生成式模型的建模思路</h4>
<p>根据概率论的基本定义： <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(\mathbf{x}, c)}{P(\mathbf{x})}
$$</span> - <strong>含义</strong>： - $ P(, c) $：联合概率，表示特征 $ $
和类别 $ c $ 同时发生的概率。 - $ P() $：边缘概率（证据），表示特征 $ $
出现的概率，用于归一化。</p>
<p>根据贝叶斯定理，联合概率 $ P(, c) $ 可以分解为： <span class="math display"><em>P</em>(<strong>x</strong>, <em>c</em>) = <em>P</em>(<em>c</em>) ⋅ <em>P</em>(<strong>x</strong>|<em>c</em>)</span>
其中： - $ P(c) $：类先验概率（Prior Probability），表示类别 $ c $
在数据中的整体占比。 - $ P(|c) $：似然度（Likelihood），表示在类别 $ c $
下，特征 $ $ 出现的概率。</p>
<p>将上述分解代入条件概率公式，得到： <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(c) \cdot P(\mathbf{x}|c)}{P(\mathbf{x})}
$$</span> 产生问题：</p>
<p>在贝叶斯分类中，需要计算联合概率
<em>P</em>(<strong>x</strong>∣<em>c</em>) ，即在类别 <em>c</em>
下，特征向量 <strong>x</strong>=(<em>x</em>1,<em>x</em>2,…,*x**d<em>)
的条件概率。 若直接建模联合概率，需估计 </em>d*
个特征的所有可能组合的概率。例如：</p>
<ul>
<li>若每个特征有 <em>k</em> 个取值，类别数为 <em>K</em> ，则需要估计
<em>K</em>⋅*k**d* 个参数。</li>
<li>当特征维度 <em>d</em>
很大时（如文本分类中成千上万的词汇），参数数量呈指数级增长，导致计算不可行（<strong>维度灾难</strong>
）。</li>
</ul>
<p>举例：</p>
<ul>
<li><strong>低维空间</strong> ：假设只有 2
个特征（如“免费”和“中奖”），每个特征取值为 0 或 1，则特征空间共有 22=4
个可能的组合（即四个格子）。
<ul>
<li>如果有 100 封邮件，每个格子平均有 25 封邮件（数据较密集）。</li>
</ul></li>
<li><strong>高维空间</strong> ： 当特征维度增加到 <em>d</em>=10,000
时，特征空间的组合数是 210,000 ，远大于宇宙中原子的数量（约 1080 ）。
<ul>
<li>即使有 100 万封邮件，每个组合几乎都是空的（数据极度稀疏）。</li>
</ul></li>
</ul>
<p><strong>结果</strong> ：
在高维空间中，训练数据无法覆盖所有可能的特征组合，导致模型无法可靠估计联合概率
<em>P</em>(x∣c) 。</p>
<p>因此产生<strong>属性条件独立性假设</strong></p>
<h4 id="朴素贝叶斯分类器">朴素贝叶斯分类器</h4>
<p>朴素贝叶斯分类器的核心思想是通过<strong>贝叶斯定理</strong>和<strong>属性条件独立性假设</strong>来简化计算，从而高效地进行分类。</p>
<h5 id="属性条件独立性假设">属性条件独立性假设</h5>
<p>朴素贝叶斯的核心假设是：<strong>在已知类别 $ c $
的条件下，所有属性（特征）之间相互独立</strong>。<br>
因此，联合概率 $ P(|c) $ 可以分解为各属性独立概率的乘积： <span class="math display">$$
P(\mathbf{x}|c) = \prod_{i=1}^d P(x_i|c)
$$</span> 其中 $ d $ 是特征的数量，$ x_i $ 是第 $ i $ 个特征的取值。</p>
<p>将此代入贝叶斯公式： <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(c) \cdot \prod_{i=1}^d
P(x_i|c)}{P(\mathbf{x})}
$$</span></p>
<h5 id="为何可以忽略-p"><strong>为何可以忽略 $ P() $?</strong></h5>
<p>在分类任务中，我们的目标是比较不同类别 $ c $ 的后验概率 $ P(c|)
$，并选择最大值。由于 $ P() $
对所有类别来说是相同的常量（与类别无关），因此在最大化过程中可以忽略：
<span class="math display">$$
\arg\max_{c} P(c|\mathbf{x}) = \arg\max_{c} \left[ \frac{P(c) \cdot
\prod_{i=1}^d P(x_i|c)}{P(\mathbf{x})} \right] = \arg\max_{c} \left[
P(c) \cdot \prod_{i=1}^d P(x_i|c) \right]
$$</span> 这就是公式中 $ P() $ 被省略的原因。</p>
<blockquote>
<p>在比较的过程中，分母相同，可以忽略</p>
</blockquote>
<h5 id="朴素贝叶斯的最终决策规则"><strong>朴素贝叶斯的最终决策规则</strong></h5>
<p>简化后的决策规则为： <span class="math display">$$
h_{nb}(\mathbf{x}) = \arg\max_{c} \left[ P(c) \cdot \prod_{i=1}^d
P(x_i|c) \right]
$$</span> 即： - 计算每个类别的先验概率 $ P(c) $。 -
计算每个特征在该类别下的条件概率 $ P(x_i|c) $。 -
将这些概率相乘，选择乘积最大的类别作为预测结果。</p>
<h5 id="类先验概率-pc-的估计方法"><strong>类先验概率 $ P(c) $
的估计方法</strong></h5>
<p>基于<strong>大数定律</strong> <span class="math display">$$
P(c) = \frac{|D_c|}{|D|}
$$</span> - <strong>符号含义</strong>： - $ D $：训练集，包含所有样本。
- $ D_c $：训练集中类别为 $ c $ 的样本子集。 - $ |D_c| $：类别 $ c $
的样本数量。 - $ |D| $：训练集总样本数量。</p>
<ul>
<li><strong>直观解释</strong>：
类先验概率等于该类别样本数占总样本数的比例。</li>
</ul>
<h5 id="条件概率-px_i-c-的估计方法"><strong>条件概率 $ P(x_i | c) $
的估计方法</strong></h5>
<p>在生成式模型（如朴素贝叶斯分类器）中，<strong>条件概率 $ P(x_i | c)
$</strong> 表示在类别 $ c $ 下，第 $ i $ 个属性取值为 $ x_i $
的概率。根据属性类型（离散或连续），其估计方法不同：</p>
<p><strong>1. 离散属性的条件概率估计</strong></p>
<p><strong>公式</strong>： <span class="math display">$$
P(x_i | c) = \frac{|D_{c,x_i}|}{|D_c|}
$$</span> - <strong>符号含义</strong>： - $ D_c $：训练集中类别为 $ c $
的样本集合。 - $ D_{c,x_i} <span class="math inline">：</span> D_c $
中第 $ i $ 个属性取值为 $ x_i $ 的样本子集。 - $ |D_{c,x_i}| <span class="math inline">：</span> D_{c,x_i} $ 的样本数量。 - $ |D_c| $：类别
$ c $ 的总样本数量。</p>
<p><strong>直观解释</strong>：</p>
<ul>
<li>在类别 $ c $ 的样本中，统计第 $ i $ 个属性取值为 $ x_i $
的频率，作为 $ P(x_i | c) $ 的估计。</li>
<li><strong>示例</strong>：<br>
若类别 $ c=spam <span class="math inline">（<em>垃</em><em>圾</em><em>邮</em><em>件</em>）<em>有</em>200<em>封</em>，<em>其</em><em>中</em>150<em>封</em><em>包</em><em>含</em>“ <em>免</em><em>费</em>” <em>一</em><em>词</em>，<em>则</em>：</span>$
P( | spam) = = 0.75 $$</li>
</ul>
<p><strong>注意事项</strong>：</p>
<ul>
<li><strong>零概率问题</strong>：若某属性值在类别 $ c $ 中未出现，则 $
P(x_i | c) = 0 <span class="math inline">，<em>可</em><em>能</em><em>导</em><em>致</em><em>后</em><em>续</em><em>计</em><em>算</em><em>失</em><em>效</em>。 * *<em>解</em><em>决</em><em>方</em><em>案</em> * *：<em>使</em><em>用</em> * *<em>拉</em><em>普</em><em>拉</em><em>斯</em><em>平</em><em>滑</em>（<em>L</em><em>a</em><em>p</em><em>l</em><em>a</em><em>c</em><em>e</em><em>S</em><em>m</em><em>o</em><em>o</em><em>t</em><em>h</em><em>i</em><em>n</em><em>g</em>） * *，<em>将</em><em>公</em><em>式</em><em>改</em><em>为</em>：</span>$
P(x_i | c) = $$ 其中 $ K $ 是该属性的取值总数。</li>
</ul>
<p><strong>2. 连续属性的条件概率估计</strong></p>
<p><strong>假设</strong>：属性服从正态分布（高斯分布） <span class="math display">$$
p(x_i | c) = \frac{1}{\sqrt{2\pi}\sigma_{c,i}} \exp\left( -\frac{(x_i -
\mu_{c,i})^2}{2\sigma_{c,i}^2} \right)
$$</span> - <strong>符号含义</strong>： - $ <em>{c,i} $：类别 $ c $ 在第
$ i $ 个属性上的均值。 - $ </em>{c,i}^2 $：类别 $ c $ 在第 $ i $
个属性上的方差。</p>
<p><strong>直观解释</strong>：</p>
<ul>
<li>假设在类别 $ c $ 下，属性 $ x_i $ 服从均值为 $ <em>{c,i} $、方差为 $
</em>{c,i}^2 $ 的正态分布。</li>
<li><strong>示例</strong>：<br>
若类别 $ c=spam $ 的“字数”属性均值 $ <em>{spam, } = 500 $，方差 $
</em>{spam, }^2 = 100 <span class="math inline">，<em>则</em>：</span>$
p(600 | spam) = ( - ) $$</li>
</ul>
<p><strong>注意事项</strong>：</p>
<ul>
<li><strong>分布假设</strong>：若实际数据不符合正态分布，需调整假设（如使用核密度估计、对数变换等）。</li>
<li><strong>参数估计</strong>：均值和方差通过训练数据计算： <span class="math display">$$
\mu_{c,i} = \frac{1}{|D_c|} \sum_{x \in D_c} x_i, \quad \sigma_{c,i}^2 =
\frac{1}{|D_c|} \sum_{x \in D_c} (x_i - \mu_{c,i})^2
$$</span></li>
</ul>
<h4 id="半朴素贝叶斯分类器">半朴素贝叶斯分类器</h4>
<p>半朴素贝叶斯分类器是对传统<strong>朴素贝叶斯</strong>的改进，它在保留计算效率的同时，<strong>适当引入部分属性间的依赖关系</strong>，从而在分类性能和计算复杂度之间取得平衡。</p>
<h5 id="独依赖估计ode方法"><strong>独依赖估计（ODE）方法</strong></h5>
<p><strong>(1) 定义</strong></p>
<p>独依赖估计（One-Dependent Estimator,
ODE）是半朴素贝叶斯的一种实现方式，其核心假设是： &gt; <strong>每个属性
$ x_i $ 在类别 $ c $ 之外最多依赖于一个其他属性（称为父属性 $ pa_i
$）</strong>。</p>
<p>数学表达式为： <span class="math display">$$
P(c|\mathbf{x}) \propto P(c) \prod_{i=1}^d P(x_i | c, pa_i)
$$</span> 其中： - $ pa_i $：属性 $ x_i $ 的父属性（依赖的单一属性）。 -
$ P(x_i | c, pa_i) $：在类别 $ c $ 和父属性 $ pa_i $ 下，属性 $ x_i $
的条件概率。</p>
<p><strong>(2) 直观理解</strong></p>
<ul>
<li>每个属性 $ x_i $ 的分布不仅受类别 $ c $ 影响，还受其父属性 $ pa_i $
的影响。</li>
<li>例如，在文本分类中，若属性 $ x_1 $ 是“免费”，$ x_2 $
是“中奖”，可设定 $ pa_2 = x_1
$，表示“中奖”在类别和“免费”的共同作用下出现。</li>
</ul>
<h5 id="超父独依赖估计spode"><strong>超父独依赖估计（SPODE）</strong></h5>
<p>超父独依赖估计（Super Parent One-Dependent Estimator,
SPODE）是<strong>半朴素贝叶斯分类器</strong>的一种扩展，其核心思想是：
&gt; <strong>所有属性都依赖于同一个“超父”属性 $ x_i
$</strong>，从而在保留部分依赖关系的同时避免完全联合概率的计算。</p>
<p><strong>(1) 贝叶斯定理展开</strong> <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(\mathbf{x}, c)}{P(\mathbf{x})}
$$</span> 其中： - $ P(, c) $：联合概率，表示特征 $ $ 和类别 $ c $
同时发生的概率。 - $ P() $：证据（归一化因子）。</p>
<p><strong>(2) 引入“超父”属性 $ x_i $</strong></p>
<p>假设所有属性 $ x_j (j i) $ 在类别 $ c $ 下仅依赖于 $ x_i <span class="math inline">，<em>则</em>：</span>$ P(, c) = P(c, x_i) P(x_1, ,
x_{i-1}, x_{i+1}, , x_d | c, x_i) <span class="math display"><em>进</em><em>一</em><em>步</em><em>分</em><em>解</em><em>为</em>：</span>
P(, c) = P(c, x_i) _{j i} P(x_j | c, x_i) $$</p>
<p><strong>(3) 最终形式</strong></p>
<p>由于 $ P() $ 对所有类别相同，可忽略，最终决策规则为： <span class="math display">$$
P(c|\mathbf{x}) \propto P(c, x_i) \cdot \prod_{j=1}^d P(x_j | c, x_i)
$$</span> 其中： - $ P(c, x_i) $：类别 $ c $ 和属性 $ x_i $ 的联合概率。
- $ P(x_j | c, x_i) $：在类别 $ c $ 和 $ x_i $ 的条件下，属性 $ x_j $
的概率。</p>
<h5 id="树增强朴素贝叶斯tan-tree-augmented-naive-bayes"><strong>树增强朴素贝叶斯（TAN:
Tree-Augmented Naive Bayes）</strong></h5>
<p><strong>TAN</strong>（Tree-Augmented Naive
Bayes）是<strong>半朴素贝叶斯分类器</strong>的一种扩展，旨在通过引入属性间的<strong>树状依赖关系</strong>，在保留计算效率的同时，显著提升分类性能。它结合了<strong>贝叶斯网络</strong>的建模能力和<strong>生成式模型</strong>的概率推理优势。</p>
<p><strong>1. 核心思想</strong></p>
<p>TAN 的核心假设是： &gt; <strong>所有属性（特征）在类别 $ c $
的基础上，形成一个以属性为节点的树状依赖结构</strong>，即每个属性最多依赖一个其他属性（父属性），且整个依赖图是一棵无环的树。</p>
<p><strong>数学表达</strong>： <span class="math display">$$
P(c|\mathbf{x}) \propto P(c) \cdot \prod_{i=1}^d P(x_i | c, pa_i)
$$</span> 其中： - $ pa_i $：属性 $ x_i $ 的父属性（依赖的单一属性）。 -
$ P(x_i | c, pa_i) $：在类别 $ c $ 和父属性 $ pa_i $ 的条件下，属性 $
x_i $ 的条件概率。</p>
<p><strong>2. TAN 的构建步骤</strong></p>
<p>TAN 通过以下步骤构建属性间的依赖结构：</p>
<p><strong>(1) 计算互信息（Mutual Information）</strong></p>
<p>互信息衡量两个属性之间的相关性： <span class="math display">$$
I(x_i, x_j) = \sum_{x_i, x_j} P(x_i, x_j) \log \frac{P(x_i,
x_j)}{P(x_i)P(x_j)}
$$</span> -
<strong>含义</strong>：互信息越大，两个属性之间的依赖关系越强。</p>
<p><strong>(2) 构建带权图</strong></p>
<ul>
<li>将所有属性视为图中的节点。</li>
<li>每对属性间的边权重设为互信息 $ I(x_i, x_j) $。</li>
</ul>
<p><strong>(3) 最大带权生成树（Maximum Weight Spanning Tree,
MWST）</strong></p>
<p>使用克鲁斯卡尔（Kruskal）算法或普里姆（Prim）算法，选择一棵连接所有属性节点的树，使得：
- 树的边权重（互信息）总和最大。 - 树中无环。</p>
<p><strong>(4) 确定依赖方向</strong></p>
<ul>
<li>随机选择一个根节点（或根据领域知识指定）。</li>
<li>从根节点出发，确定每条边的方向（父属性 → 子属性）。</li>
</ul>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250605223036362.png" alt="image-20250605223036362">
<figcaption aria-hidden="true">image-20250605223036362</figcaption>
</figure>
<h4 id="贝叶斯网">贝叶斯网</h4>
<p>待学习</p>
<h4 id="em算法">EM算法</h4>
<p>EM算法（Expectation-Maximization
Algorithm）是一种<strong>迭代优化算法</strong>，用于处理<strong>含有隐变量</strong>（Hidden
Variables）或<strong>缺失数据</strong>的概率模型参数估计问题。它的核心思想是通过交替执行<strong>期望（E）步</strong>和<strong>最大化（M）步</strong>，逐步逼近模型参数的最大似然估计。</p>
<h5 id="核心思想解决隐变量问题"><strong>1.
核心思想：解决隐变量问题</strong></h5>
<p><strong>(1) 什么是隐变量？</strong></p>
<p>隐变量（Latent
Variables）是模型中<strong>不可观测但影响观测数据</strong>的变量。例如：
-
<strong>混合高斯模型（GMM）</strong>：每个样本属于哪个高斯分布是隐变量。
- <strong>聚类任务</strong>：样本所属的聚类标签是隐变量。</p>
<p><strong>(2) 问题挑战</strong></p>
<p>当存在隐变量时，直接最大化似然函数变得困难。例如： <span class="math display">log <em>P</em>(<strong>x</strong>|<em>θ</em>) = log ∑<sub><em>z</em></sub><em>P</em>(<strong>x</strong>, <em>z</em>|<em>θ</em>)</span>
其中 $ z $ 是隐变量，$ $
是模型参数。由于对数中包含求和，直接求导无法分离参数。</p>
<p><strong>(3) EM算法的解决方案</strong></p>
<p>EM算法通过以下步骤迭代求解： 1.
<strong>E步（期望）</strong>：用当前参数估计隐变量的后验分布（即“责任”分配）。
2.
<strong>M步（最大化）</strong>：基于隐变量的后验分布，最大化期望似然函数以更新参数。</p>
<h5 id="算法流程"><strong>2. 算法流程</strong></h5>
<p><strong>(1) 初始化参数</strong></p>
<p>选择初始参数 $ ^{(0)} $，例如随机初始化或通过启发式方法设定。</p>
<p><strong>(2) E步：计算隐变量后验分布</strong></p>
<p>给定当前参数 $ ^{(t)} $，计算隐变量 $ z $ 的后验概率： <span class="math display"><em>Q</em><sup>(<em>t</em>)</sup>(<em>z</em>) = <em>P</em>(<em>z</em>|<strong>x</strong>, <em>θ</em><sup>(<em>t</em>)</sup>)</span>
这一步为每个样本分配隐变量的概率分布（如样本属于某个聚类的概率）。</p>
<p><strong>(3) M步：最大化期望似然</strong></p>
<p>基于 $ Q^{(t)}(z) <span class="math inline">，<em>构</em><em>造</em><em>期</em><em>望</em><em>似</em><em>然</em><em>函</em><em>数</em><em>并</em><em>最</em><em>大</em><em>化</em>：</span>$
^{(t+1)} = _{} _z Q^{(t)}(z) P(, z|) $$ 这一步更新参数 $
$，使得期望似然最大。</p>
<p><strong>(4) 收敛判断</strong></p>
<p>重复E步和M步直到参数收敛（如 $ |^{(t+1)} - ^{(t)}| &lt;
$）或达到最大迭代次数。</p>
<h5 id="示例混合高斯模型gmm"><strong>3.
示例：混合高斯模型（GMM）</strong></h5>
<p>假设数据由多个高斯分布生成，但不知道每个样本属于哪个分布。</p>
<p><strong>(1) 模型定义</strong></p>
<ul>
<li>观测变量 $ x_i ^d $：第 $ i $ 个样本。</li>
<li>隐变量 $ z_i {1, …, K} $：样本 $ x_i $ 所属的高斯分布。</li>
<li>参数 $ = {_k, _k, <em>k}</em>{k=1}^K $：
<ul>
<li>$ _k $：第 $ k $ 个高斯分布的均值。</li>
<li>$ _k $：第 $ k $ 个高斯分布的协方差矩阵。</li>
<li>$ _k $：第 $ k $ 个高斯分布的权重（先验概率）。</li>
</ul></li>
</ul>
<p><strong>(2) E步：计算责任分配</strong></p>
<p>对于每个样本 $ x_i $ 和类别 $ k <span class="math inline">，<em>计</em><em>算</em><em>责</em><em>任</em>（<em>r</em><em>e</em><em>s</em><em>p</em><em>o</em><em>n</em><em>s</em><em>i</em><em>b</em><em>i</em><em>l</em><em>i</em><em>t</em><em>y</em>）：</span>$
_{ik}^{(t)} = P(z_i=k|x_i, ^{(t)}) = $$ 含义：在当前参数下，样本 $ x_i $
属于类别 $ k $ 的概率。</p>
<p><strong>(3) M步：更新参数</strong></p>
<p>根据责任 $ _{ik} $ 更新参数： - <strong>均值更新</strong>： <span class="math display">$$
  \mu_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)} x_i}{\sum_{i=1}^N
\gamma_{ik}^{(t)}}
  $$</span> - <strong>协方差更新</strong>： <span class="math display">$$
  \Sigma_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)} (x_i -
\mu_k^{(t+1)})(x_i - \mu_k^{(t+1)})^T}{\sum_{i=1}^N \gamma_{ik}^{(t)}}
  $$</span> - <strong>权重更新</strong>： <span class="math display">$$
  \pi_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)}}{N}
  $$</span></p>
<p><strong>(4) 迭代终止</strong></p>
<p>当参数变化小于阈值或达到最大迭代次数时停止。</p>
<h4 id="作业">作业</h4>
<h5 id="section">1</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143758565.png" alt="image-20250606143758565">
<figcaption aria-hidden="true">image-20250606143758565</figcaption>
</figure>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143819352.png" alt="image-20250606143819352">
<figcaption aria-hidden="true">image-20250606143819352</figcaption>
</figure>
<h5 id="section-1">2</h5>
<p>已知观测数据-67，-48，6，8，14，16，23，24，28，29，41，49，56，60，75，试估计两个分量的高斯混合模型的5个参数。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150830535.png" alt="image-20250606150830535">
<figcaption aria-hidden="true">image-20250606150830535</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化观测数据</span></span><br><span class="line">data = np.array([-<span class="number">67</span>, -<span class="number">48</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">41</span>, <span class="number">49</span>, <span class="number">56</span>, <span class="number">60</span>,</span><br><span class="line">                 <span class="number">75</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类</span></span><br><span class="line">gmmModel = GaussianMixture(n_components=<span class="number">2</span>)</span><br><span class="line">gmmModel.fit(data)</span><br><span class="line">labels = gmmModel.predict(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels =&quot;</span>, labels)</span><br><span class="line">labels = [<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(labels)):</span><br><span class="line">    <span class="keyword">if</span> labels[i] == <span class="number">0</span>:</span><br><span class="line">        plt.scatter(i, data.take(i), s=<span class="number">15</span>, c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> labels[i] == <span class="number">1</span>:</span><br><span class="line">        plt.scatter(i, data.take(i), s=<span class="number">15</span>, c=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Gaussian Mixture Model&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;means =&quot;</span>, gmmModel.means_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;covariances =&quot;</span>, gmmModel.covariances_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights = &quot;</span>, gmmModel.weights_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150906475.png" alt="image-20250606150906475">
<figcaption aria-hidden="true">image-20250606150906475</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># means = [[ 32.98489643 -57.51107027]]</span></span><br><span class="line"><span class="comment"># covariances = [[429.45764867  90.24987882]]</span></span><br><span class="line"><span class="comment"># weights =  [[0.86682762 0.13317238]]</span></span><br></pre></td></tr></table></figure>
<h5 id="section-2">3</h5>
<p>简要阐述下EM算法的原理，并给出EM算法对高斯混合模型GMM进行求解的具体过程。</p>
<h6 id="em算法的原理">EM算法的原理</h6>
<p>EM算法（期望最大化算法）是一种用于含有隐变量的概率模型参数估计的迭代优化方法。其核心思想是通过交替执行两个步骤来最大化观测数据的似然函数：</p>
<ol type="1">
<li><strong>E步（期望步）</strong>：计算隐变量的后验期望（即责任），给定当前参数估计。</li>
<li><strong>M步（最大化步）</strong>：基于责任，最大化完全数据的期望似然函数以更新参数。</li>
</ol>
<p>EM算法通过不断优化似然函数的下界，最终收敛到局部最优解。以下具体阐述EM算法对高斯混合模型（GMM）的求解过程。</p>
<h6 id="em算法对gmm的具体求解过程"><strong>EM算法对GMM的具体求解过程</strong></h6>
<p><strong>1. GMM模型定义</strong></p>
<p>GMM假设数据由 $ K $ 个高斯分布线性组合生成，其概率密度函数为： <span class="math display">$$
p(\mathbf{x}|\theta) = \sum_{k=1}^K \alpha_k \cdot
\mathcal{N}(\mathbf{x}|\mu_k, \Sigma_k)
$$</span> 其中： - $ <em>k $：第 $ k $ 个高斯分布的权重（$ </em>{k=1}^K
_k = 1 $）。 - $ _k $：第 $ k $ 个高斯分布的均值向量。 - $ _k $：第 $ k
$ 个高斯分布的协方差矩阵。 - $ = {_k, _k, <em>k}</em>{k=1}^K
$：模型参数。</p>
<p>隐变量 $ z_i {1,,K} $ 表示样本 $ _i $ 的类别标签（未知）。</p>
<p><strong>2. EM算法步骤</strong></p>
<p><strong>(1) 初始化参数</strong></p>
<p>随机或通过K-means初始化： - 每个高斯分布的均值 $ _k^{(0)} $、协方差 $
_k^{(0)} $、权重 $ _k^{(0)} $。</p>
<p><strong>(2) 迭代优化（E步与M步）</strong></p>
<p><strong>E步：计算责任（后验概率）</strong> 对每个样本 <span class="math inline"><strong>x</strong><sub><em>i</em></sub></span>
和每个簇 $ k $，计算其属于第 $ k $ 个高斯分布的后验概率 <span class="math display">$$
\gamma(z_{ik}) = \frac{\alpha_k \cdot \mathcal{N}(\mathbf{x}_i | \mu_k,
\Sigma_k)}{\sum_{j=1}^K \alpha_j \cdot \mathcal{N}(\mathbf{x}_i | \mu_j,
\Sigma_j)}
$$</span> 此概率表示在当前参数下，样本 $ _i $ 属于第 $ k $
个高斯分布的“责任”。</p>
<p><strong>M步：更新参数</strong><br>
基于责任 $ (z_{ik}) $，最大化完全数据似然函数的期望，更新参数：</p>
<ul>
<li><strong>权重更新</strong>： <span class="math display">$$
\alpha_k^{(new)} = \frac{1}{N} \sum_{i=1}^N \gamma(z_{ik})
$$</span></li>
<li><strong>均值更新</strong>： <span class="math display">$$
\mu_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik})
\mathbf{x}_i}{\sum_{i=1}^N \gamma(z_{ik})}
$$</span></li>
<li><strong>协方差更新</strong>： <span class="math display">$$
\Sigma_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) (\mathbf{x}_i -
\mu_k^{(new)})(\mathbf{x}_i - \mu_k^{(new)})^\top}{\sum_{i=1}^N
\gamma(z_{ik})}
$$</span> 若为单变量高斯分布，则更新方差： <span class="math display">$$
\sigma_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) (x_i -
\mu_k^{(new)})^2}{\sum_{i=1}^N \gamma(z_{ik})}
$$</span></li>
</ul>
<p><strong>(3) 收敛判断</strong></p>
<p>计算对数似然函数： <span class="math display">$$
\log p(\mathbf{X}|\theta) = \sum_{i=1}^N \log \left( \sum_{k=1}^K
\alpha_k \cdot \mathcal{N}(\mathbf{x}_i|\mu_k, \Sigma_k) \right)
$$</span>
若对数似然的变化量小于阈值或达到最大迭代次数，则停止；否则重复E步和M步。。</p>
<h4 id="参考资料">参考资料</h4>
<p>[<a href="https://www.bilibili.com/video/BV1RT411G7jJ/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">5分钟学算法]
#06 EM算法 你到底是哪个班级的_哔哩哔哩_bilibili</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/396007256">《统计学习方法_第二版》学习笔记第九章
- 知乎</a></p>
<h3 id="集成学习">集成学习</h3>
<h4 id="个体与集成">个体与集成</h4>
<h5 id="集成学习的基本概念"><strong>集成学习的基本概念</strong></h5>
<p>集成学习（Ensemble
Learning）通过构建并结合<strong>多个学习器（基模型）</strong>来完成学习任务，其核心思想是“<strong>优而不同</strong>”，即<strong>通过多个弱学习器的协作提升整体性能</strong>，通常能获得比单一学习器更优的泛化能力
。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606154731476.png" alt="image-20250606154731476">
<figcaption aria-hidden="true">image-20250606154731476</figcaption>
</figure>
<p>在上图的集成模型中，若个体学习器都属于同一类别，例如都是决策树或都是神经网络，则称该集成为同质的（homogeneous）;若个体学习器包含多种类型的学习算法，例如既有决策树又有神经网络，则称该集成为异质的（heterogenous）。</p>
<blockquote>
<p><strong>同质集成</strong>：个体学习器称为“基学习器”（base
learner），对应的学习算法为“基学习算法”（base learning algorithm）。</p>
<p><strong>异质集成</strong>：个体学习器称为“组件学习器”（component
learner）或直称为“个体学习器”。</p>
</blockquote>
<p>集成学习的两个重要概念：<strong>准确性</strong>和<strong>多样性</strong>（diversity）。准确性指的是个体学习器不能太差，要有一定的准确度；多样性则是个体学习器之间的输出要具有差异性。</p>
<p>通过下面的这三个例子可以很容易看出这一点，准确度较高，差异度也较高，可以较好地提升集成性能。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606155939884.png" alt="image-20250606155939884">
<figcaption aria-hidden="true">image-20250606155939884</figcaption>
</figure>
<p><strong>集成策略</strong>：如何结合多个基模型的预测结果，例如：</p>
<ul>
<li><strong>投票法</strong>（Voting）：多数投票（硬投票）或概率加权（软投票）。<br>
</li>
<li><strong>加权平均法</strong>：对基模型的输出赋予不同权重 。<br>
</li>
<li><strong>Stacking</strong>：用元模型（Meta-Model）学习基模型的输出作为新特征
。</li>
</ul>
<h5 id="基于投票法的集成个体学习器的收敛性保证"><strong>基于投票法的集成个体学习器的收敛性保证</strong>：</h5>
<p><strong>公式解析</strong> <span class="math display">$$
P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) = \sum_{k=0}^{\lfloor T/2
\rfloor} \binom{T}{k} (1-\epsilon)^k \epsilon^{T-k} \leq
\exp\left(-\frac{1}{2} T (1 - 2\epsilon)^2\right)
$$</span></p>
<p><strong>1. 公式含义</strong></p>
<ul>
<li><strong><span class="math inline"><em>H</em>(<strong>x</strong>)</span></strong>：集成学习器的最终预测结果（如多数投票结果）。</li>
<li><strong><span class="math inline"><em>f</em>(<strong>x</strong>)</span></strong>：真实标记。</li>
<li><strong><span class="math inline"><em>ϵ</em></span></strong>：单个弱学习器的错误率（即
<span class="math inline"><em>P</em>(<em>h</em><sub><em>t</em></sub>(<strong>x</strong>) ≠ <em>f</em>(<strong>x</strong>))</span>），默认小于0.5。</li>
<li><strong><span class="math inline"><em>T</em></span></strong>：基学习器的数量。</li>
<li><strong>左边</strong>：集成学习器预测错误的概率（即至少有超过 <span class="math inline"><em>T</em>/2</span>
个基学习器预测错误的概率）。</li>
<li><strong>右边</strong>：对左边概率的指数级上限估计。</li>
</ul>
<p><strong>2. 推导思路</strong></p>
<ul>
<li>假设每个基学习器独立且错误率为 <span class="math inline"><em>ϵ</em></span>，则错误次数服从<strong>二项分布</strong>
<span class="math inline"><em>B</em>(<em>T</em>, <em>ϵ</em>)</span>。</li>
<li>集成错误的条件是“超过半数基学习器错误”，即错误次数 <span class="math inline"><em>k</em> ≤ ⌊<em>T</em>/2⌋</span>。</li>
</ul>
<p><strong>两个基本结论</strong></p>
<p><strong>1. 收敛速率随个体学习器数量 <span class="math inline"><em>T</em></span> 指数下降</strong></p>
<ul>
<li><strong>数学体现</strong>：错误概率的上界是 <span class="math inline">exp (−<em>c</em><em>T</em>)</span> 形式，其中 <span class="math inline">$c = \frac{1}{2}(1 - 2\epsilon)^2$</span>。</li>
</ul>
<p><strong>2. <span class="math inline"><em>ϵ</em> = 0.5</span>
的个体学习器对收敛没有作用</strong></p>
<ul>
<li><strong>数学原因</strong>：当 <span class="math inline"><em>ϵ</em> = 0.5</span> 时，<span class="math inline">(1 − 2<em>ϵ</em>)<sup>2</sup> = 0</span>，指数项变为
0，错误概率上界为 <span class="math inline">exp (0) = 1</span>，即错误概率无法降低。</li>
</ul>
<p>根据个体学习器的<strong>生成方式</strong>，目前集成学习可分为两类，代表作如下：</p>
<ol type="1">
<li>个体学习器直接存在强依赖关系，必须串行生成的序列化方法：<strong>Boosting</strong>；</li>
<li>个体学习器间不存在强依赖关系，可以同时生成的并行化方法：<strong>Bagging</strong>
和 <strong>随机森林 (Random Forest)</strong>。</li>
</ol>
<h4 id="boosting"><strong>Boosting</strong></h4>
<p>Boosting是一种<strong>串行</strong>的工作机制，即<strong>个体学习器的训练存在依赖关系</strong>，必须一步一步序列化进行。</p>
<p>其<strong>基本思想</strong>是：<strong>增加前一个基学习器在训练过程中预测错误样本的权重，使得后续基学习器更加关注这些打标错误的训练样本，尽可能纠正这些错误，然后基于调整后的样本分布训练下一个基学习器</strong>，如此重复，一直向下串行直至产生需要的T个基学习器，Boosting最终对这T个学习器进行加权结合，产生学习器委员会。</p>
<p>Boosting族算法最著名、使用最为广泛的就是<strong>AdaBoost</strong>，因此下面主要是对AdaBoost算法进行介绍。</p>
<p>AdaBoost使用的是<strong>指数损失函数</strong>，因此AdaBoost的权值与样本分布的更新都是围绕着最小化指数损失函数进行的。</p>
<blockquote>
<p>看到这里回想一下之前的机器学习算法，<strong>不难发现机器学习的大部分带参模型只是改变了最优化目标中的损失函数</strong>：如果是Square
loss，那就是最小二乘了；如果是Hinge
Loss，那就是著名的SVM了；如果是log-Loss，那就是Logistic
Regression了。</p>
</blockquote>
<h5 id="adaboost">AdaBoost</h5>
<h5 id="公式解析"><strong>公式解析</strong></h5>
<p><span class="math display">$$
H(\boldsymbol{x}) = \sum_{t=1}^T \alpha_t h_t(\boldsymbol{x})
$$</span> <span class="math display"><em>ℓ</em><sub>exp</sub>(<em>H</em>|𝒟) = 𝔼<sub><strong>x</strong> ∼ 𝒟</sub>[<em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup>]</span></p>
<p><strong>1. 符号含义</strong></p>
<ul>
<li><strong><span class="math inline"><em>H</em>(<strong>x</strong>)</span></strong>：最终集成模型的预测结果，是
<span class="math inline"><em>T</em></span> 个基学习器 <span class="math inline"><em>h</em><sub><em>t</em></sub>(<strong>x</strong>)</span>
的加权和。</li>
<li><strong><span class="math inline"><em>α</em><sub><em>t</em></sub></span></strong>：第
<span class="math inline"><em>t</em></span>
个基学习器的权重，表示其在集成中的重要性。</li>
<li><strong><span class="math inline"><em>h</em><sub><em>t</em></sub>(<strong>x</strong>)</span></strong>：第
<span class="math inline"><em>t</em></span>
个基学习器（如决策树、感知机等）。</li>
<li><strong><span class="math inline"><em>f</em>(<strong>x</strong>)</span></strong>：真实标签，通常取值为
<span class="math inline">{−1, +1}</span>（二分类问题）。</li>
<li><strong><span class="math inline">𝒟</span></strong>：训练数据分布。</li>
<li><strong><span class="math inline"><em>ℓ</em><sub>exp</sub></span></strong>：指数损失函数（Exponential
Loss）。</li>
</ul>
<p><strong>2. 指数损失函数的意义</strong></p>
<p>指数损失函数的形式为： <span class="math display"><em>ℓ</em><sub>exp</sub>(<em>H</em>|𝒟) = 𝔼<sub><strong>x</strong> ∼ 𝒟</sub>[<em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup>]</span>
- <strong>直观解释</strong>： - 当 <span class="math inline"><em>H</em>(<strong>x</strong>)</span> 与 <span class="math inline"><em>f</em>(<strong>x</strong>)</span>
同号时（预测正确），指数项 <span class="math inline"><em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup></span>
接近 0，损失小。 - 当 <span class="math inline"><em>H</em>(<strong>x</strong>)</span> 与 <span class="math inline"><em>f</em>(<strong>x</strong>)</span>
异号时（预测错误），指数项趋近于正无穷，损失极大。 -
因此，该损失函数对错误样本的惩罚非常严格，迫使模型优先修正错误。</p>
<h5 id="adaboost的优化目标"><strong>AdaBoost的优化目标</strong></h5>
<p>AdaBoost的目标是选择基学习器 <span class="math inline"><em>h</em><sub><em>t</em></sub></span> 和权重 <span class="math inline"><em>α</em><sub><em>t</em></sub></span>，使得集成模型
<span class="math inline"><em>H</em>(<strong>x</strong>)</span>
能够<strong>最小化指数损失函数</strong>： <span class="math display">$$
\min_{\alpha_1, h_1, \dots, \alpha_T, h_T} \mathbb{E}_{\boldsymbol{x}
\sim \mathcal{D}} \left[ e^{-f(\boldsymbol{x}) \sum_{t=1}^T \alpha_t
h_t(\boldsymbol{x})} \right]
$$</span></p>
<p><strong>优化策略</strong></p>
<p>AdaBoost采用<strong>前向分步算法（Forward Stagewise
Algorithm）</strong>，逐轮迭代优化： 1.
<strong>初始化样本权重</strong>：初始时所有样本权重相等。 2.
<strong>训练基学习器 <span class="math inline"><em>h</em><sub><em>t</em></sub></span></strong>：在当前样本权重分布下，训练一个弱学习器
<span class="math inline"><em>h</em><sub><em>t</em></sub></span>。 3.
<strong>计算权重 <span class="math inline"><em>α</em><sub><em>t</em></sub></span></strong>：根据
<span class="math inline"><em>h</em><sub><em>t</em></sub></span>
的错误率 <span class="math inline"><em>ϵ</em><sub><em>t</em></sub></span> 计算其权重：
<span class="math display">$$
   \alpha_t = \frac{1}{2} \ln \left( \frac{1 - \epsilon_t}{\epsilon_t}
\right)
   $$</span> 4. <strong>更新样本权重</strong>：提高被 <span class="math inline"><em>h</em><sub><em>t</em></sub></span>
错分类样本的权重，降低正确分类样本的权重。 5. <strong>重复步骤
2-4</strong>，直到训练完成 <span class="math inline"><em>T</em></span>
轮。</p>
<h5 id="示例二分类问题-1"><strong>示例：二分类问题</strong></h5>
<p>假设一个二分类任务，真实标签 <span class="math inline"><em>f</em>(<strong>x</strong>) ∈ {−1, +1}</span>，集成模型预测值
<span class="math inline">$H(\boldsymbol{x}) = \sum_{t=1}^T \alpha_t
h_t(\boldsymbol{x})$</span>： - 若 <span class="math inline"><em>H</em>(<strong>x</strong>) &gt; 0</span>，预测为
<span class="math inline">+1</span>； - 若 <span class="math inline"><em>H</em>(<strong>x</strong>) &lt; 0</span>，预测为
<span class="math inline">−1</span>。</p>
<p>此时，指数损失函数的值反映了模型对错误样本的惩罚程度： -
正确预测时，<span class="math inline"><em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup> ≈ 0</span>；
- 错误预测时，<span class="math inline"><em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup> ≫ 1</span>。</p>
<h5 id="adaboost的算法流程">AdaBoost的算法流程</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606172851748.png" alt="image-20250606172851748">
<figcaption aria-hidden="true">image-20250606172851748</figcaption>
</figure>
<h5 id="重赋权法与重采样法">重赋权法与重采样法</h5>
<p>在集成学习中，<strong>Boosting
算法的核心在于动态调整样本权重</strong> ，以逐步聚焦难分类样本。Boosting
主要通过两种方法实现样本权重的更新：<strong>重赋权法（re-weighting）</strong>
和 <strong>重采样法（re-sampling）</strong> 。</p>
<blockquote>
<p><strong>重赋权法</strong> :
对每个样本附加一个权重，这时涉及到样本属性与标签的计算，都需要乘上一个权值。
<strong>重采样法</strong> :
对于一些无法接受带权样本的及学习算法，适合用“重采样法”进行处理。方法大致过程是，根据各个样本的权重，对训练数据进行重采样，初始时样本权重一样，每个样本被采样到的概率一致，每次从N个原始的训练样本中按照权重有放回采样N个样本作为训练集，然后计算训练集错误率，然后调整权重，重复采样，集成多个基学习器。</p>
</blockquote>
<p>从偏差-方差分解来看：Boosting算法主要关注于降低偏差，每轮的迭代都关注于训练过程中预测错误的样本，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成学习器。</p>
<h5 id="拓展gradient-boosting">拓展：Gradient Boosting</h5>
<p>任务分为分类，回归，聚类，降维等，而分类中还分为二分类和多分类</p>
<p>从AdaBoost的算法流程来看，标准的AdaBoost只适用于二分类问题。</p>
<p>通过改造AdaBoost对样本分类的限制和损失函数，可以实现多分类或回归问题，这样改造出来的算法框架成为<strong>Gradient
Boosting</strong></p>
<h6 id="gbdtgradient-boosting-decision-tree与xgboost"><strong>GBDT（Gradient
Boosting Decision Tree）与XGBoost</strong></h6>
<p><strong>1. GBDT 的核心思想</strong></p>
<p>GBDT 是基于<strong>梯度提升（Gradient
Boosting）</strong>框架的集成学习方法，其特点包括： -
<strong>基学习器</strong>：使用<strong>CART（分类与回归树）</strong>作为个体学习器。
- <strong>损失函数</strong>： -
<strong>回归问题</strong>：平方损失（Squared Loss）： <span class="math display">err(<em>H</em><sub><em>t</em></sub>(<strong>x</strong>), <em>f</em>(<strong>x</strong>)) = (<em>H</em><sub><em>t</em></sub>(<strong>x</strong>) − <em>f</em>(<strong>x</strong>))<sup>2</sup></span>
- <strong>二分类问题</strong>：对数似然损失（Log-Likelihood
Loss，类似逻辑回归）： <span class="math display">err(<em>H</em><sub><em>t</em></sub>(<strong>x</strong>), <em>f</em>(<strong>x</strong>)) = log (1 + exp (−<em>f</em>(<strong>x</strong>)<em>H</em><sub><em>t</em></sub>(<strong>x</strong>)))</span>
- <strong>多分类问题</strong>：扩展为多分类对数损失。</p>
<p><strong>2. XGBoost 的定位</strong></p>
<p>XGBoost（eXtreme Gradient Boosting）是 GBDT
的一种<strong>高效实现和改进</strong>，类似于 LIBSVM 对 SVM
的优化关系。其核心目标是： -
<strong>提升训练速度</strong>：通过<strong>并行计算</strong>、<strong>内存优化</strong>等工程技巧。
-
<strong>增强模型性能</strong>：引入<strong>正则化项</strong>、<strong>缺失值处理</strong>、<strong>自适应学习率</strong>等改进。</p>
<blockquote>
<p>XGBoost即eXtremeGradient
Boosting的缩写，XGBoost与GBDT的关系可以类比为
LIBSVM和SVM的关系，即XGBoOst是GBDT的一种高效实现和改进。</p>
<p>它并非一个全新的算法框架，而是对标准 GBDT
进行了<strong>大量的工程优化和算法增强</strong>。</p>
</blockquote>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606175536310.png" alt="image-20250606175536310">
<figcaption aria-hidden="true">image-20250606175536310</figcaption>
</figure>
<h4 id="bagging">Bagging</h4>
<p>Bagging是一种<strong>并行式</strong>的集成学习方法，即<strong>基学习器的训练之间没有前后顺序可以同时进行</strong></p>
<p>Bagging使用<strong>“有放回”采样的方式选取训练集</strong>，对于包含m个样本的训练集，进行m次有放回的随机采样操作，从而得到m个样本的采样集，这样训练集中有<strong>接近36.8%</strong>的样本没有被采到，可用作验证集来对泛化性能进行“包外估计”(out-of-bag
estimate)。</p>
<p>按照相同的方式重复进行，我们就可以采集到T个包含m个样本的数据集，从而训练出<strong>T个基学习器</strong>，最终对<strong>这T个基学习器的输出进行结合</strong>。</p>
<h5 id="bagging与boosting的差异">Bagging与Boosting的差异</h5>
<p>Boosting算法一大特点是串行，这样诚然可以降低模型的偏差，增强拟合能力，但是当数据过大时，一大缺点就是会降低学习效率</p>
<p>Bagging作为并行式的集成学习方法，通过综合多个基学习器的结果，可以增加学习效率</p>
<p>二者差异性：</p>
<p>1.对目标的拟合程度：Boosting对目标有更好的拟合能力（偏差小）；Bagging则偏差相对大一些</p>
<p>2.运行效率：由于并行的特点，Bagging的运行效率是大于Boosting的</p>
<p>3.泛化能力：由于Bagging每个学习器不会受其他学习器的影响，泛化能力（方差大）相对于Boosting</p>
<p>更好</p>
<h5 id="bagging的算法流程">Bagging的算法流程</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606182733022.png" alt="image-20250606182733022">
<figcaption aria-hidden="true">image-20250606182733022</figcaption>
</figure>
<p>可以看出Bagging主要通过<strong>样本的扰动</strong>来增加基学习器之间的多样性，因此Bagging的基学习器应为那些对训练集十分敏感的不稳定学习算法，例如：神经网络与决策树等。</p>
<p>从偏差-方差分解来看，Bagging算法主要关注于降低方差，即通过多次重复训练提高稳定性。</p>
<p>不同于AdaBoost的是，Bagging可以十分简单地移植到多分类、回归等问题。总的说起来则是：<strong>AdaBoost关注于降低偏差，而Bagging关注于降低方差。</strong></p>
<h5 id="自助采样法bootstrap-sampling">自助采样法（Bootstrap
Sampling）</h5>
<p>在机器学习中，<strong>自助采样法（Bootstrap Sampling）</strong> 是
Bagging
算法的核心技术之一。其核心思想是从原始数据集中有放回地随机抽取样本，形成新的训练子集。这一过程的一个重要数学性质是：当样本量
<span class="math inline"><em>n</em></span> 趋近于无穷大时，每个样本在
Bootstrap 样本集中<strong>未被抽中</strong>的概率趋近于 <span class="math inline">$\frac{1}{e} \approx
36.6\%$</span>。以下是详细解析：</p>
<p><strong>1. 公式推导</strong></p>
<p>假设我们从 <span class="math inline"><em>n</em></span>
个样本中<strong>有放回地</strong>抽取 <span class="math inline"><em>n</em></span> 次，形成一个 Bootstrap
样本集。对于任意一个特定样本（如第 <span class="math inline"><em>i</em></span>
个样本），它在某次抽样中<strong>未被选中</strong>的概率为： <span class="math display">$$
1 - \frac{1}{n}
$$</span> 因此，它在整个 <span class="math inline"><em>n</em></span>
次抽样中<strong>从未被选中</strong>的概率为： <span class="math display">$$
\left(1 - \frac{1}{n}\right)^n
$$</span> 当 <span class="math inline"><em>n</em> → ∞</span>
时，该概率的极限为： <span class="math display">$$
\lim_{n \to \infty} \left(1 - \frac{1}{n}\right)^n = \frac{1}{e} \approx
0.3679 \quad (\text{即 } 36.6\%)
$$</span> 在每次 Bootstrap 采样中，约有 <strong>36.6%
的样本未被选中</strong> ，这些样本称为
<strong>Out-of-Bag（OOB，包外估计）样本</strong> 。</p>
<p><strong>2. OOB 样本的应用</strong></p>
<p>在 Bagging 算法中，OOB 样本具有以下重要作用： 1.
<strong>无偏验证</strong>：<br>
每个基学习器的训练数据不包含其对应的 OOB
样本，因此可以用这些样本直接评估模型性能（即 OOB
误差），无需额外的交叉验证。 2. <strong>特征重要性评估</strong>：<br>
在随机森林中，通过比较 OOB
样本在打乱某个特征后的预测误差变化，可以衡量该特征的重要性。</p>
<p><strong>3. 与其他采样方法的对比</strong></p>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 17%">
<col style="width: 32%">
<col style="width: 24%">
</colgroup>
<thead>
<tr>
<th><strong>采样方法</strong></th>
<th><strong>是否放回</strong></th>
<th><strong>样本覆盖范围</strong></th>
<th><strong>典型应用场景</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Bootstrap 采样</strong></td>
<td>是</td>
<td>约 63.4% 样本被重复使用</td>
<td>Bagging、随机森林</td>
</tr>
<tr>
<td><strong>简单随机采样</strong></td>
<td>否</td>
<td>所有样本唯一出现</td>
<td>传统交叉验证</td>
</tr>
</tbody>
</table>
<h5 id="随机森林">随机森林</h5>
<p>随机森林（Random
Forest）是Bagging的一个拓展体，它的基学习器固定为<strong>决策树</strong>，多棵树也就组成了森林，而<strong>“随机”则在于选择划分属性的随机</strong>，随机森林在训练基学习器时，也采用有放回采样的方式添加样本扰动，同时它还引入了一种<strong>属性扰动</strong>，即在基决策树的训练过程中，在选择划分属性时，RF先从候选属性集中随机挑选出一个包含K个属性的子集，再从这个子集中选择最优划分属性
。</p>
<p>这样随机森林中基学习器的<strong>多样性不仅来自样本扰动，还来自属性扰动</strong>，从而进一步提升了基学习器之间的差异度。相比决策树的Bagging集成，随机森林的起始性能较差（由于属性扰动，基决策树的准确度有所下降），但随着基学习器数目的增多，随机森林往往会收敛到更低的泛化误差。同时不同于Bagging中决策树从所有属性集中选择最优划分属性，<strong>随机森林只在属性集的一个子集中选择划分属性，因此训练效率更高</strong>。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606184958951.png" alt="image-20250606184958951">
<figcaption aria-hidden="true">image-20250606184958951</figcaption>
</figure>
<h4 id="结合策略">结合策略</h4>
<p>在集成学习中，结合策略是将多个基学习器的输出整合为最终预测结果的关键步骤。以下是针对回归和分类问题的不同结合策略及其核心要点：</p>
<p><strong>定义</strong>：在训练好多个基学习器后，如何将其输出组合成集成模型的最终输出。</p>
<h5 id="平均法回归问题"><strong>1.平均法（回归问题）</strong></h5>
<ol type="1">
<li><p><strong>简单平均法（Simple Averaging）</strong></p>
<ul>
<li><strong>公式</strong>：<br>
<span class="math display">$$
H(x) = \frac{1}{T} \sum_{i=1}^{T} h_i(x)
$$</span></li>
<li><strong>特点</strong>：
<ul>
<li>直接对所有基学习器的预测结果取算术平均。<br>
</li>
<li>计算简单，适合基学习器性能相近的场景。<br>
</li>
<li>若部分基学习器表现较差，可能拖累整体性能。</li>
</ul></li>
</ul></li>
<li><p><strong>加权平均法（Weighted Averaging）</strong></p>
<ul>
<li><strong>公式</strong>：<br>
<span class="math display">$$
H(x) = \sum_{i=1}^{T} w_i h_i(x)
$$</span> 其中，$ w_i $ 且 $ _{i=1}^{T} w_i = 1 $。<br>
</li>
<li><strong>特点</strong>：
<ul>
<li>通过权重 $ w_i $ 调节各基学习器的贡献，灵活性更高。<br>
</li>
<li>适用于基学习器性能差异较大的情况，可提升鲁棒性。<br>
</li>
<li>权重可通过验证集性能（如RMSE、MAE）或优化算法（如梯度下降）确定。</li>
</ul></li>
</ul></li>
</ol>
<h5 id="投票法分类问题"><strong>2.投票法（分类问题）</strong></h5>
<ol type="1">
<li><strong>简单投票法（Majority Voting）</strong>
<ul>
<li><strong>原理</strong>：<br>
每个基学习器对样本进行分类投票，最终结果由得票最多的类别决定。<br>
</li>
<li><strong>公式</strong>（二分类示例）：<br>
<span class="math display">$$
H(x) =
\begin{cases}
1 &amp; \text{若} \sum_{i=1}^{T} I(h_i(x) = 1) &gt; T/2 \\
0 &amp; \text{否则}
\end{cases}
$$</span> 其中，$ I() $ 为指示函数。<br>
</li>
<li><strong>特点</strong>：
<ul>
<li>简单高效，适合基学习器性能相近的场景。<br>
</li>
<li>对异常分类器的鲁棒性较弱。</li>
</ul></li>
</ul></li>
<li><strong>加权投票法（Weighted Voting）</strong>
<ul>
<li><strong>原理</strong>：<br>
给不同基学习器分配权重，最终结果由加权票数最高的类别决定。<br>
</li>
<li><strong>公式</strong>（二分类示例）：<br>
<span class="math display">$$
H(x) =
\begin{cases}
1 &amp; \text{若} \sum_{i=1}^{T} w_i I(h_i(x) = 1) &gt; 0.5
\sum_{i=1}^{T} w_i \\
0 &amp; \text{否则}
\end{cases}
$$</span></li>
<li><strong>特点</strong>：
<ul>
<li>权重可根据基学习器的验证集准确率或领域知识设定。<br>
</li>
<li>更适合处理性能差异较大的基学习器。</li>
</ul></li>
</ul></li>
</ol>
<p>绝对多数投票法（majority
voting）提供了拒绝选项，这在可靠性要求很高的学习任务中是一个很好的机制。同时，对于分类任务，各个基学习器的输出值有两种类型，分别为类标记和类概率。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606195241433.png" alt="image-20250606195241433">
<figcaption aria-hidden="true">image-20250606195241433</figcaption>
</figure>
<p>一些在产生类别标记的同时也生成置信度的学习器，置信度可转化为类概率使用，<strong>一般基于类概率进行结合往往比基于类标记进行结合的效果更好</strong>，需要注意的是对于异质集成，其类概率不能直接进行比较，此时需要将类概率转化为类标记输出，然后再投票。</p>
<h5 id="学习法stacking"><strong>3.学习法（Stacking）</strong></h5>
<p><strong>学习法</strong>是一种更高级的结合策略，其核心思想是通过训练一个<strong>次级学习器（Meta-Learner）</strong>
来动态融合多个基学习器的输出。其中，<strong>Stacking（堆叠泛化）</strong>
是学习法的典型代表，它通过将基学习器的预测结果作为新特征，进一步训练一个次级模型，最终实现更优的泛化性能。</p>
<p><strong>Stacking 的基本原理</strong></p>
<p><strong>步骤概述</strong>：</p>
<ul>
<li><strong>训练基学习器</strong>：使用原始数据训练 $ T $
个基学习器（如决策树、SVM、神经网络等）。<br>
</li>
<li><strong>生成新特征</strong>：对于每个样本，将 $ T $
个基学习器的输出（预测结果）作为该样本的新特征，形成一个 $ m T $
的数据集（$ m $ 为样本数量）。<br>
</li>
<li><strong>训练次级学习器</strong>：使用新数据集（基学习器输出 +
真实标签）训练一个次级学习器（如逻辑回归、梯度提升树等），该学习器负责融合基学习器的预测结果。</li>
</ul>
<p><strong>Stacking 的优势</strong></p>
<ol type="1">
<li><strong>动态权重分配</strong>：<br>
次级学习器可以自动学习基学习器的权重，无需人工设定。例如，若某个基学习器表现优异，次级学习器会赋予其更高的权重。<br>
</li>
<li><strong>异质模型融合</strong>：<br>
可以混合不同类型的基学习器（如线性模型与树模型），充分利用各自的特性。<br>
</li>
<li><strong>提升泛化能力</strong>：<br>
次级学习器通过学习基学习器的输出模式，能够捕捉更复杂的决策边界。</li>
</ol>
<p><strong>Stacking 的实现细节</strong></p>
<ol type="1">
<li><strong>数据划分</strong>：
<ul>
<li>通常需将原始数据分为两部分：
<ul>
<li><strong>训练集</strong>：用于训练基学习器。<br>
</li>
<li><strong>验证集</strong>：用于生成基学习器的输出（避免过拟合）。<br>
</li>
</ul></li>
<li>或采用交叉验证（如 $ k
$-折）生成基学习器的预测结果，确保次级学习器的训练数据不被污染。</li>
</ul></li>
<li><strong>基学习器输出类型</strong>：
<ul>
<li><strong>分类任务</strong>：基学习器输出类概率（Soft
Voting），而非类别标签（Hard Voting）。例如，逻辑回归输出 $ P(c_j | x)
$，随机森林输出节点样本的类别分布。<br>
</li>
<li><strong>回归任务</strong>：基学习器直接输出预测值（如线性回归的
<span class="math inline"><em>ŷ</em></span>）。</li>
</ul></li>
<li><strong>次级学习器选择</strong>：
<ul>
<li><strong>多响应线性回归（MLR）</strong>：适用于基学习器输出可加权平均的情况，计算简单且鲁棒。<br>
<span class="math display">$$
H(x) = \sum_{i=1}^{T} w_i h_i(x)
$$</span></li>
<li><strong>复杂模型</strong>：如梯度提升树、神经网络，可捕捉基学习器输出之间的非线性关系。</li>
</ul></li>
</ol>
<h4 id="多样性">多样性</h4>
<p>在集成学习中，<strong>多样性增强（Diversity Enhancement）</strong>
是提升模型性能的关键策略。通过引入多样性，可以降低基学习器之间的相关性，从而减少误差传递和过拟合风险。以下是四种常见的多样性增强方法及其核心要点：</p>
<p><strong>1. 数据样本扰动（Data Perturbation）</strong></p>
<p><strong>原理</strong>：通过修改训练数据的分布或采样方式，使每个基学习器看到不同的数据子集。</p>
<p><strong>实现方式</strong>：<br>
- <strong>Bagging（如随机森林）</strong>：<br>
- 随机有放回地采样（Bootstrap），生成多个不同的训练集。<br>
- 对输入扰动敏感的基学习器（如决策树、神经网络）效果显著。<br>
- <strong>示例</strong>：<br>
- 决策树对数据扰动敏感，Bagging 可有效提升其泛化能力。<br>
- 线性模型（如线性回归、SVM）对数据扰动不敏感，Bagging 效果有限。</p>
<p><strong>2. 输入属性扰动（Input Attribute Perturbation）</strong></p>
<p><strong>原理</strong>：通过改变输入特征的表示或选择，增加基学习器间的差异。</p>
<p><strong>实现方式</strong>：<br>
-
<strong>特征子集采样</strong>：每次随机选择部分特征进行训练（如随机森林中的列扰动）。<br>
- <strong>特征变换</strong>：对特征进行缩放、旋转或加噪声等操作。<br>
- <strong>适用场景</strong>：<br>
- 数据包含大量冗余属性时，可大幅加速训练并提升多样性。<br>
- 对高维数据（如图像、文本）尤其有效。</p>
<p><strong>3. 输出属性扰动（Output Attribute Perturbation）</strong></p>
<p><strong>原理</strong>：通过修改训练样本的标签，间接影响基学习器的学习过程。</p>
<p><strong>实现方式</strong>：<br>
-
<strong>随机翻转标签</strong>：对部分样本的标记进行随机更改（需谨慎使用，避免干扰模型）。<br>
- <strong>Dropout（神经网络）</strong>：<br>
- 在训练过程中随机“关闭”部分神经元，强制网络学习更鲁棒的特征。<br>
- 类似于对输出属性的随机扰动，可提升模型泛化能力。</p>
<p><strong>4. 算法参数扰动（Algorithm Parameter
Perturbation）</strong></p>
<p><strong>原理</strong>：通过调整基学习器的超参数，生成不同的模型行为。</p>
<p><strong>实现方式</strong>：</p>
<ul>
<li><strong>正则化方法</strong>：L1/L2 正则化（如
Ridge、Lasso）限制模型复杂度，降低过拟合风险。</li>
<li><strong>随机初始化</strong>：
神经网络的随机权重初始化可能导致收敛到不同局部最优解。</li>
</ul>
<h4 id="作业-1">作业</h4>
<h5 id="section-3">1</h5>
<p>集成学习中常见的两种方法是什么？请分别介绍它们的原理和特点。集成学习相比于单个模型有什么优势和应用场景？</p>
<p><strong>集成学习常见方法、原理、特点及优势</strong></p>
<p><strong>常见方法</strong>：Bagging 和 Boosting<br>
<strong>原理与特点</strong>：</p>
<table>
<colgroup>
<col style="width: 9%">
<col style="width: 45%">
<col style="width: 45%">
</colgroup>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>原理</strong></th>
<th><strong>特点</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Bagging</strong></td>
<td>1. <strong>自助采样</strong>：从训练集有放回抽取多个子集<br>2.
<strong>并行训练</strong>基模型<br>3.
<strong>聚合预测</strong>（投票/平均）</td>
<td>- 降低方差<br>- 适合高方差模型（如未剪枝决策树）<br>-
并行化，训练快<br>- 代表：随机森林</td>
</tr>
<tr>
<td><strong>Boosting</strong></td>
<td>1. <strong>顺序训练</strong>：后一个模型修正前一个模型的错误<br>2.
<strong>加权困难样本</strong><br>3. <strong>加权组合</strong>模型</td>
<td>- 降低偏差<br>- 需弱学习器（如树桩）<br>- 易过拟合（需正则化）<br>-
代表：AdaBoost, GBDT, XGBoost</td>
</tr>
</tbody>
</table>
<p><strong>集成学习的优势</strong>：<br>
-
<strong>提升泛化能力</strong>：降低过拟合（Bagging）或欠拟合（Boosting）风险<br>
- <strong>增强鲁棒性</strong>：减少异常值/噪声影响（如投票机制）<br>
- <strong>突破性能上限</strong>：组合多个弱模型达到强模型效果</p>
<p><strong>应用场景</strong>：<br>
- <strong>分类任务</strong>：医疗诊断（整合多模型减少误诊）<br>
- <strong>回归任务</strong>：房价预测（融合不同树模型提升精度）<br>
- <strong>不平衡数据</strong>：Boosting 加权少数类样本<br>
- <strong>高维数据</strong>：随机森林自动特征选择</p>
<h5 id="section-4">2</h5>
<p>如果在完全相同的训练集上训练了五个不同的模型，并且它们都达到了95%的准确率，是否还有机会通过结合这些模型来获得更好的结果？如果可以，该怎么做？如果不行，为什么？</p>
<p><strong>模型结合提升性能的可能性与方法</strong></p>
<p><strong>是否可能提升</strong>：<strong>是</strong>，但需满足条件：<strong>模型错误不相关</strong>（即犯错样本不同）。</p>
<p><strong>如何实现</strong>：</p>
<ol type="1">
<li><strong>投票法（分类）</strong>：
<ul>
<li>多数投票：5个模型对样本 (x) 的预测为 ([A, A, B, A, C]) → 最终输出
(A)<br>
</li>
<li><strong>关键要求</strong>：模型存在<strong>多样性</strong>（如使用SVM、决策树等不同算法）<br>
</li>
</ul></li>
<li><strong>加权平均（回归）</strong>：
<ul>
<li>若模型精度不同，分配权重：$ y_{} = w_1 y_1 + w_2 y_2 + + w_5
y_5$</li>
<li>权重可通过验证集性能确定</li>
</ul></li>
</ol>
<p><strong>若无法提升的情况</strong>：<br>
-
<strong>原因</strong>：模型高度相关（如相同算法、相同特征、相同超参）<br>
- <strong>数学解释</strong>：误差相关性 <span class="math inline"><em>r</em><em>h</em><em>o</em> ≈ 1</span>
时，集成误差 <span class="math inline">≈</span>单一模型误差</p>
<h5 id="section-5">3</h5>
<p>是否可以通过在多个服务器上并行来加速随机森林的训练？AdaBoost集成呢？为什么？</p>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 18%">
<col style="width: 68%">
</colgroup>
<thead>
<tr>
<th><strong>算法</strong></th>
<th><strong>是否支持并行</strong></th>
<th><strong>原因</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>随机森林</strong></td>
<td>✅ <strong>是</strong></td>
<td>1. 树之间独立训练<br>2. 可分布式分配Bootstrap样本到不同服务器<br>3.
特征分裂也可并行（如选特征子集）</td>
</tr>
<tr>
<td><strong>AdaBoost</strong></td>
<td>❌ <strong>否</strong></td>
<td>1.
模型必须<strong>顺序训练</strong>：后一个模型依赖前一个模型的样本权重更新<br>2.
无法解耦迭代过程</td>
</tr>
</tbody>
</table>
<h3 id="聚类">聚类</h3>
<h4 id="聚类任务"><strong>聚类任务</strong></h4>
<blockquote>
<p>我们之前学习的分类/回归任务都属于 有监督学习
需要我们提供样本与标签</p>
<p>而马上要学习的聚类任务和后续学习的降维则属于 无监督学习
仅需提供样本</p>
</blockquote>
<p>聚类是一种经典的<strong>无监督学习</strong>(unsupervised
learning)方法，<strong>无监督学习的目标是通过对无标记训练样本的学习，发掘和揭示数据集本身潜在的结构与规律</strong>，即不依赖于训练数据集的类标记信息。</p>
<p>聚类试图将数据集中的样本划分为若干个通常是不相交的子集,<strong>每个子集称为一个“簇”(
cluster)</strong>。通过这样的划分,每簇可能对应于一些潜在的概念(类别),如“浅色瓜”“深色瓜”,“有籽瓜”“无籽瓜”,甚至“本地瓜”“外地瓜”等;需说明的是,这些概念对聚类算法而言事先是未知的,聚类过程仅能自动形成簇结构,
<strong>簇所对应的概念语义需由使用者来把握和命名</strong>。</p>
<p>直观上来说，聚类是将相似的样本聚在一起，从而形成一个<strong>类簇（cluster）</strong>。涉及两个问题</p>
<ul>
<li>如何<strong>度量相似性</strong>（similarity
measure），这便是<strong>距离度量</strong>(distance
measure)，在生活中我们说差别小则相似，对应到多维样本，每个样本可以对应于高维空间中的一个数据点，若它们的距离相近，我们便可以称它们相似。</li>
<li>如何<strong>评价聚类结果</strong>，这便是<strong>性能度量</strong>(validity
index)</li>
</ul>
<h4 id="距离度量">距离度量</h4>
<h5 id="连续离散有序">连续/离散有序</h5>
<p><strong>明可夫斯基距离（Minkowski Distance）</strong></p>
<p>明可夫斯基距离是一组常用的<strong>连续型距离度量</strong>，通过调整参数
$ p $ 可以统一表示多种距离形式，是欧氏距离和曼哈顿距离的推广。</p>
<p><strong>1. 公式定义</strong></p>
<p>对于两个 $ n $ 维向量 $ <em>i = (x</em>{i1}, x_{i2}, , x_{in}) $ 和 $
<em>j = (x</em>{j1}, x_{j2}, , x_{jn}) <span class="math inline">，<em>明</em><em>可</em><em>夫</em><em>斯</em><em>基</em><em>距</em><em>离</em><em>的</em><em>计</em><em>算</em><em>公</em><em>式</em><em>为</em>：</span>$
<em>{}(<em>i, <em>j) = ( </em>{u=1}^{n} |x</em>{iu} - x</em>{ju}|^p )^{}
$$ 其中，$ p $ 是一个可调节的参数。</p>
<p><strong>2. 特殊情况</strong></p>
<ul>
<li>**当 $ p = 2 <span class="math inline">* * ：<em>退</em><em>化</em><em>为</em> * *<em>欧</em><em>氏</em><em>距</em><em>离</em>（<em>E</em><em>u</em><em>c</em><em>l</em><em>i</em><em>d</em><em>e</em><em>a</em><em>n</em><em>D</em><em>i</em><em>s</em><em>t</em><em>a</em><em>n</em><em>c</em><em>e</em>） * *</span>$
_{}(_i, _j) = $$
<ul>
<li><strong>几何意义</strong>：两点之间的直线距离。<br>
</li>
<li><strong>适用场景</strong>：大多数机器学习算法（如KNN、PCA）默认使用欧氏距离。</li>
</ul></li>
<li>**当 $ p = 1 <span class="math inline">* * ：<em>退</em><em>化</em><em>为</em> * *<em>曼</em><em>哈</em><em>顿</em><em>距</em><em>离</em>（<em>M</em><em>a</em><em>n</em><em>h</em><em>a</em><em>t</em><em>t</em><em>a</em><em>n</em><em>D</em><em>i</em><em>s</em><em>t</em><em>a</em><em>n</em><em>c</em><em>e</em>） * *</span>$
<em>{}(<em>i, <em>j) = </em>{u=1}^{n} |x</em>{iu} - x</em>{ju}| $$
<ul>
<li><strong>几何意义</strong>：沿坐标轴移动的总距离（如棋盘格路径）。<br>
</li>
<li><strong>适用场景</strong>：高维稀疏数据（如文本特征）、计算资源受限的场景。</li>
</ul></li>
<li>**当 $ p <span class="math inline">* * ：<em>退</em><em>化</em><em>为</em> * *<em>切</em><em>比</em><em>雪</em><em>夫</em><em>距</em><em>离</em>（<em>C</em><em>h</em><em>e</em><em>b</em><em>y</em><em>s</em><em>h</em><em>e</em><em>v</em><em>D</em><em>i</em><em>s</em><em>t</em><em>a</em><em>n</em><em>c</em><em>e</em>） * *</span>$
<em>{}(<em>i, <em>j) = </em>{u} |x</em>{iu} - x</em>{ju}| $$
<ul>
<li><strong>几何意义</strong>：各维度差值的最大值。<br>
</li>
<li><strong>适用场景</strong>：关注最坏情况下的误差（如游戏AI路径规划）。</li>
</ul></li>
</ul>
<p><strong>3. 参数 $ p $ 的影响</strong></p>
<ul>
<li><strong>$ p $
越小</strong>：距离计算越关注较小的维度差异（如曼哈顿距离对单个维度的扰动更敏感）。<br>
</li>
<li><strong>$ p $
越大</strong>：距离计算越关注较大的维度差异（如切比雪夫距离仅关注最大差值）。<br>
</li>
<li><strong>选择依据</strong>：
<ul>
<li>数据分布是否均匀：若某些维度差异显著，可增大 $ p $。<br>
</li>
<li>算法需求：如KNN中，高维数据可能更适合曼哈顿距离（缓解“维度灾难”）。</li>
</ul></li>
</ul>
<h5 id="离散无序">离散无序</h5>
<p>我们知道属性分为两种：<strong>连续属性</strong>(continuous
attribute)和<strong>离散属性</strong>（catergorical
attribute有限个取值）。对于连续值的属性，一般都可以被学习器所用，有时会根据具体的情形作相应的预处理，例如：归一化等；而对于离散值的属性，需要作下面进一步的处理：</p>
<blockquote>
<p>若属性值之间<strong>存在序关系</strong>(ordinal
attribute)，则可以将其转化为连续值，例如：身高属性“高”“中等”“矮”，可转化为{1,
0.5, 0}。</p>
<p>若属性值之间<strong>不存在序关系</strong>(non-ordinal
attribute)，则通常将其转化为向量的形式，例如：性别属性“男”“女”，可转化为{（1,0）,（0,1）}。</p>
</blockquote>
<p><strong>连续属性和存在序关系的离散属性都可以直接参与计算</strong>，而不存在序关系的<strong>无序属性，我们一般采用VDM（Value
Difference Metric）进行距离的计算</strong></p>
<p>VDM
是一种专门用于<strong>离散无序属性</strong>的距离度量方法，通过统计信息量化不同类别间的差异。其核心思想是：<strong>若两个类别的样本在目标变量上的分布差异越大，则它们的距离越大</strong>。</p>
<p><strong>1. 公式解析</strong> <span class="math display">$$
\text{VDM}_p(a, b) = \sum_{i=1}^{k} \left| \frac{m_{u,a,i}}{m_{u,a}} -
\frac{m_{u,b,i}}{m_{u,b}} \right|^p
$$</span> - <strong>符号含义</strong>：<br>
- $ a, b $：两个不同的类别值（如性别“男”和“女”）。<br>
- $ m_{u,a,i} $：在属性 $ u $ 的第 $ i $ 个取值下，类别 $ a $
的样本数量。<br>
- $ m_{u,a} $：类别 $ a $ 的总样本数量。<br>
- $ k $：属性 $ u $ 的不同取值数目（如颜色属性有红、蓝、绿三种取值，则 $
k=3 $）。<br>
- $ p $：距离幂指数（通常取 $ p=1 $ 或 $ p=2 $）。</p>
<p><strong>2. 核心思想</strong></p>
<ul>
<li><strong>统计分布差异</strong>：<br>
对于每个属性取值 $ i $，计算类别 $ a $ 和 $ b $ 的样本比例差异：<br>
<span class="math display">$$
\left| \frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}} \right|
$$</span> 该值越大，说明两个类别在该取值上的分布差异越大。<br>
</li>
<li><strong>加权求和</strong>：<br>
将所有属性取值的差异按 $ p $ 次方加权求和，得到最终的距离。</li>
</ul>
<p><strong>3. 示例说明</strong></p>
<p>假设我们有一个“颜色”属性（红、蓝、绿），目标变量是“是否购买商品”（0/1）。统计结果如下：</p>
<table>
<thead>
<tr>
<th>颜色</th>
<th>购买（1）</th>
<th>不购买（0）</th>
<th>总计</th>
</tr>
</thead>
<tbody>
<tr>
<td>红</td>
<td>10</td>
<td>5</td>
<td>15</td>
</tr>
<tr>
<td>蓝</td>
<td>8</td>
<td>12</td>
<td>20</td>
</tr>
<tr>
<td>绿</td>
<td>3</td>
<td>7</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>计算“红”与“蓝”之间的 VDM 距离（$ p=1 <span class="math inline">）：1.<em>计</em><em>算</em><em>每</em><em>个</em><em>颜</em><em>色</em><em>在</em><em>购</em><em>买</em>/<em>不</em><em>购</em><em>买</em><em>的</em><em>比</em><em>例</em>： − <em>红</em>：</span>
P(1) = 10/15 <span class="math inline">，</span> P(0) = 5/15 $<br>
- 蓝：$ P(1) = 8/20 = 0.4 <span class="math inline">，</span> P(0) =
12/20 = 0.6 $<br>
2. 计算差异并求和：<br>
<span class="math display">VDM<sub>1</sub>(红, 蓝) = |0.67 − 0.4|+|0.33 − 0.6| = 0.27 + 0.27 = 0.54</span></p>
<h4 id="性能度量">性能度量</h4>
<p>于聚类算法不依赖于样本的真实类标，就不能像监督学习的分类那般，通过计算分对分错（即精确度或错误率）来评价学习器的好坏或作为学习过程中的优化目标。</p>
<p>直观上看,我们希望<strong>“物以类聚”</strong>,即同一簇的样本尽可能彼此相似,不同簇的样本尽可能不同换言之,聚类结果的<strong>“簇内相似度”(
intra-cluster similarity)高且“簇间相似度” inter-cluster
similarity)低</strong></p>
<p><strong>聚类性能度量有两类</strong></p>
<ul>
<li>“外部指标”(external
index)：所谓外部指标就是已经有一个“参考模型”存在了，将当前模型与参考模型的比对结果作为指标。</li>
<li>“内部指标”( internal
index)：所谓内部指标就是仅仅考虑当前模型的聚类结果。</li>
</ul>
<h5 id="外部指标">外部指标</h5>
<p><strong>1.基本概念</strong></p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607110103570.png" alt="image-20250607110103570">
<figcaption aria-hidden="true">image-20250607110103570</figcaption>
</figure>
<p>显然，$ a + b + c + d = $ 。</p>
<p><strong>2. 常用外部指标</strong></p>
<p><strong>（1）Jaccard系数（JC）</strong> <span class="math display">$$
\text{JC} = \frac{a}{a + b + c}
$$</span> -
<strong>含义</strong>：衡量两个划分的重叠程度，仅考虑正确匹配（$ a <span class="math inline">）<em>与</em><em>矛</em><em>盾</em><em>情</em><em>况</em>（</span>
b + c <span class="math inline">）。 − * * <em>范</em><em>围</em> * *：</span> [0,
1] $，值越大越好。<br>
- <strong>特点</strong>：对称性差，对噪声敏感 。</p>
<p><strong>（2）Fowlkes-Mallows指数（FMI）</strong> <span class="math display">$$
\text{FMI} = \sqrt{\frac{a}{a + b} \cdot \frac{a}{a + c}}
$$</span> - <strong>含义</strong>：结合查准率（$ <span class="math inline">）<em>和</em><em>查</em><em>全</em><em>率</em>（</span>
<span class="math inline">），<em>反</em><em>映</em><em>正</em><em>确</em><em>匹</em><em>配</em><em>的</em><em>综</em><em>合</em><em>能</em><em>力</em>。 − * * <em>范</em><em>围</em> * *：</span>
[0, 1] $，值越大越好。<br>
- <strong>特点</strong>：平衡性较好，适合小样本 。</p>
<p><strong>（3）Rand指数（RI）</strong> <span class="math display">$$
\text{RI} = \frac{2(a + d)}{m(m - 1)}
$$</span> - <strong>含义</strong>：同时考虑正确匹配（$ a + d <span class="math inline">）<em>与</em><em>总</em><em>样</em><em>本</em><em>对</em><em>数</em>，<em>适</em><em>用</em><em>于</em><em>大</em><em>规</em><em>模</em><em>数</em><em>据</em>。 − * * <em>范</em><em>围</em> * *：</span>
[0, 1] $，值越大越好。<br>
- <strong>特点</strong>：计算简单，但对噪声较鲁棒 。</p>
<p><strong>常用指标</strong></p>
<ul>
<li><strong>调整兰德指数（Adjusted Rand Index, ARI）</strong>
<ul>
<li><strong>定义</strong>：衡量聚类结果与真实标签的匹配程度，调整随机聚类的影响，取值范围
[-1, 1]，值越大越好。<br>
</li>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{ARI} = \frac{\text{RI} - \mathbb{E}[\text{RI}]}{\max(\text{RI}) -
\mathbb{E}[\text{RI}]}
$$</span> 其中 RI 是兰德指数（匹配样本对的比例）。</li>
</ul></li>
<li><strong>归一化互信息（Normalized Mutual Information, NMI）</strong>
<ul>
<li><strong>定义</strong>：衡量聚类结果与真实标签的信息共享程度，值越大越好。<br>
</li>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{NMI} = \frac{I(C; K)}{\sqrt{H(C) H(K)}}
$$</span> 其中 $ I(C; K) $ 是互信息，$ H(C) $ 和 $ H(K) $ 是熵。</li>
</ul></li>
<li><strong>Fowlkes-Mallows 指数（FMI）</strong>
<ul>
<li><strong>定义</strong>：基于聚类结果与真实标签的 TP、FP、TN、FN
计算，值越大越好。<br>
</li>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{FMI} = \sqrt{\frac{\text{TP}}{\text{TP} + \text{FP}} \cdot
\frac{\text{TP}}{\text{TP} + \text{FN}}}
$$</span></li>
</ul></li>
</ul>
<p><strong>优点</strong></p>
<ul>
<li>在有真实标签时，能更客观地评估聚类效果。</li>
<li>适用于验证聚类结果的业务意义（如客户分群是否符合预期）。</li>
</ul>
<p><strong>局限性</strong></p>
<ul>
<li>需要真实标签，不适用于纯无监督任务。</li>
<li>对标签噪声敏感（如标签错误会误导 $ K $ 的选择）。</li>
</ul>
<p><strong>3. 应用示例</strong></p>
<p>假设一个包含4个样本的数据集，参考标签为 <span class="math inline">{<em>A</em>, <em>A</em>, <em>B</em>, <em>B</em>}</span>，聚类结果为
<span class="math inline">{<em>C</em>, <em>C</em>, <em>D</em>, <em>D</em>}</span>：
- <strong>计算样本对</strong>：<br>
- $ a = 2 $（样本1-2同簇，参考与聚类均同类）。<br>
- $ b = 0 $（参考同类但聚类不同类）。<br>
- $ c = 0 $（参考不同类但聚类同类）。<br>
- $ d = 2 $（参考不同类且聚类不同类）。<br>
- <strong>指标结果</strong>：<br>
- JC = $ = 1 $（完美匹配）。<br>
- FMI = $ = 1 $。<br>
- RI = $ = $。</p>
<h5 id="内部指标">内部指标</h5>
<p>内部指标不依赖任何外部参考模型，直接通过<strong>簇内紧凑性</strong>和<strong>簇间分离性</strong>评估聚类结果。其核心思想是：
- <strong>簇内高内聚</strong>：同一簇的样本尽可能相似（距离小）。<br>
- <strong>簇间低耦合</strong>：不同簇的样本尽可能不同（距离大）。</p>
<p><strong>1. 基本定义</strong></p>
<p>设聚类结果为 $ C = {C_1, C_2, , C_k} $，定义以下四个关键距离：</p>
<p><strong>（1）簇内平均距离（avg(C)）</strong> <span class="math display">$$
\text{avg}(C) = \frac{2}{|C|(|C| - 1)} \sum_{1 \leq i &lt; j \leq |C|}
\text{dist}(\boldsymbol{x}_i, \boldsymbol{x}_j)
$$</span> - <strong>含义</strong>：簇内所有样本对的平均距离。<br>
- <strong>目标</strong>：越小越好，表示簇内样本更紧密。</p>
<p><strong>（2）簇内最大距离（diam(C)）</strong> <span class="math display">diam(<em>C</em>) = max<sub>1 ≤ <em>i</em> &lt; <em>j</em> ≤ |<em>C</em>|</sub>dist(<strong>x</strong><sub><em>i</em></sub>, <strong>x</strong><sub><em>j</em></sub>)</span>
- <strong>含义</strong>：簇内最远的两个样本之间的距离。<br>
- <strong>目标</strong>：越小越好，避免簇内存在离群点。</p>
<p>**（3）簇间最小距离（$ d_{}(C_i, C_j) <span class="math inline">） * *</span>$ d_{}(C_i, C_j) = _{_i C_i, _j C_j}
(_i, _j) $$ - <strong>含义</strong>：簇 $ C_i $ 和 $ C_j $
之间最近的两个样本的距离。<br>
- <strong>目标</strong>：越大越好，表示簇间分离度高。</p>
<p>**（4）簇中心距离（$ d_{}(C_i, C_j) <span class="math inline">） * *</span>$ d_{}(C_i, C_j) = (_i, _j) $$ -
<strong>含义</strong>：簇 $ C_i $ 和 $ C_j $
的中心点（均值向量）之间的距离。<br>
- <strong>目标</strong>：越大越好，表示簇中心相隔较远。</p>
<p><strong>2. 常用内部指标</strong></p>
<p><strong>1. DB指数（Davies-Bouldin Index, DBI）</strong></p>
<ul>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{DBI} = \frac{1}{k} \sum_{i=1}^{k} \max_{j \neq i} \left(
\frac{\text{avg}(C_i) + \text{avg}(C_j)}{d_{\text{cen}}(\mu_i, \mu_j)}
\right)
$$</span>
<ul>
<li><strong>符号含义</strong>：
<ul>
<li>$ k $：簇的数量。<br>
</li>
<li>$ (C_i) $：簇 $ C_i $ 内部样本的平均距离。<br>
</li>
<li>$ d_{}(_i, _j) $：簇 $ C_i $ 和 $ C_j $
的中心点（均值向量）之间的距离。<br>
</li>
</ul></li>
<li><strong>目标</strong>：越小越好。<br>
</li>
<li><strong>核心思想</strong>：对于每个簇 $ C_i $，找到与其“最竞争”的簇
$ C_j $（即 $ $ 最大的簇），并取所有簇的平均值。</li>
</ul></li>
<li><strong>示例</strong>：<br>
若簇 $ C_1 $ 和 $ C_2 $ 的平均距离分别为 2 和 3，中心距离为
5，则它们的比值为 $ = 1 $。若这是 $ C_1 $ 的最大比值，则 $ C_1 $ 对 DBI
的贡献为 1。最终 DBI 是所有簇贡献的平均值。</li>
</ul>
<p><strong>2. Dunn指数（Dunn Index, DI）</strong></p>
<ul>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{DI} = \min_{1 \leq i \leq k} \left\{ \frac{\min_{j \neq i}
d_{\min}(C_i, C_j)}{\max_{1 \leq l \leq k} \text{diam}(C_l)} \right\}
$$</span>
<ul>
<li><strong>符号含义</strong>：
<ul>
<li>$ d_{}(C_i, C_j) $：簇 $ C_i $ 和 $ C_j $
之间的最小距离（最近样本对的距离）。<br>
</li>
<li>$ (C_l) $：簇 $ C_l $ 内的最大距离（最远样本对的距离）。<br>
</li>
</ul></li>
<li><strong>目标</strong>：越大越好。<br>
</li>
<li><strong>核心思想</strong>：
<ul>
<li>分子：所有簇对之间的最小距离中的最小值（即最“脆弱”的簇间分离度）。<br>
</li>
<li>分母：所有簇中的最大直径（最“松散”的簇内紧凑度）。<br>
</li>
<li>指数越大，表示簇间分离度高且簇内紧凑。</li>
</ul></li>
</ul></li>
<li><strong>示例</strong>：<br>
假设簇对 $ (C_1, C_2) $ 的最小距离为 5，簇 $ C_3 $ 的最大直径为 10，则
DI 为 $ = 0.5 $。</li>
</ul>
<p><strong>3. 轮廓系数（Silhouette Coefficient）</strong></p>
<ul>
<li><p><strong>单一样本的轮廓系数</strong>：<br>
<span class="math display">$$
s = \frac{b - a}{\max(a, b)}
$$</span></p>
<ul>
<li><strong>符号含义</strong>：
<ul>
<li>$ a $：样本到同簇其他样本的平均距离（簇内凝聚度）。<br>
</li>
<li>$ b $：样本到最近簇中样本的平均距离（簇间分离度）。<br>
</li>
</ul></li>
<li><strong>取值范围</strong>：$ [-1, 1] $，越接近 1
表示聚类效果越好。<br>
</li>
<li><strong>核心思想</strong>：
<ul>
<li>若 $ a &lt; b $（同簇紧密，异簇疏远），则 $ s &gt; 0
$，样本分类合理。<br>
</li>
<li>若 $ a &gt; b $（同簇松散，异簇更近），则 $ s &lt; 0
$，样本可能被错误分类。</li>
</ul></li>
</ul></li>
<li><p><strong>整体轮廓系数</strong>：所有样本轮廓系数的平均值。</p></li>
<li><p><strong>示例</strong>：<br>
若某样本 $ a = 2 <span class="math inline">，</span> b = 5 $，则 $ s = =
0.6 $，表明该样本分类合理。</p></li>
</ul>
<p><strong>4.肘部法则（Elbow Method）</strong></p>
<p>肘部法则是一种<strong>经验性方法</strong>，常用于确定K-means等聚类算法的最优簇数（$
K $）。其核心思想是通过观察误差平方和（SSE, Sum of Squared Errors）随 $
K $ 值变化的趋势，寻找“肘部点”（即 SSE
下降速度明显减缓的拐点），从而选择最优的 $ K $ 值</p>
<ul>
<li><p><strong>SSE（误差平方和）</strong>：衡量每个样本到其所属簇中心的距离平方和，公式为：
<span class="math display">$$
\text{SSE} = \sum_{i=1}^n \|x_i - \mu_{c_i}\|^2
$$</span> 其中 $ x_i $ 是样本点，$ _{c_i} $ 是其所属簇中心。</p></li>
<li><p><strong>趋势分析</strong>：</p>
<ul>
<li>当 $ K $ 增大时，SSE
会不断减小（因为簇越多，每个簇的样本越密集）。</li>
<li>但当 $ K $ 增加到某个值后，SSE
的下降速度会显著放缓，形成“肘部”形状。</li>
</ul></li>
<li><p><strong>肘部点的意义</strong>：<br>
肘部点对应的 $ K $
值是<strong>模型复杂度</strong>（簇数）与<strong>聚类效果</strong>（SSE）之间的平衡点。</p></li>
</ul>
<p><strong>指标对比与选择</strong></p>
<table style="width:100%;">
<colgroup>
<col style="width: 8%">
<col style="width: 32%">
<col style="width: 13%">
<col style="width: 22%">
<col style="width: 22%">
</colgroup>
<thead>
<tr>
<th><strong>指标</strong></th>
<th><strong>计算方式</strong></th>
<th><strong>目标</strong></th>
<th><strong>适用场景</strong></th>
<th><strong>局限性</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>DBI</td>
<td>簇内平均距离与簇中心距离的比值</td>
<td>越小越好</td>
<td>球形簇，需指定 $ k $</td>
<td>对离群点敏感</td>
</tr>
<tr>
<td>Dunn指数</td>
<td>簇间最小距离与簇内最大直径的比值</td>
<td>越大越好</td>
<td>强调簇间分离与簇内紧凑</td>
<td>计算复杂，受离群点影响</td>
</tr>
<tr>
<td>轮廓系数</td>
<td>样本到同簇/异簇的平均距离差</td>
<td>越接近 1 越好</td>
<td>快速评估，适合 K-Means</td>
<td>对非球形簇不敏感</td>
</tr>
</tbody>
</table>
<h4 id="原型聚类与kmeans">原型聚类与kmeans</h4>
<h5 id="原型聚类">原型聚类</h5>
<p>原型聚类即“<strong>基于原型的聚类</strong>”（prototype-based
clustering），原型表示模板的意思，就是通过参考一个模板向量或模板分布的方式来完成聚类的过程，通常情形下算法先对原型进行初始化,然后对原型进行迭代更新求解。采用不同的原型表、不同的求解方式,将产生不同的算法。</p>
<p>常见的K-Means便是基于簇中心（原型向量）来实现聚类，混合高斯聚类则是基于簇分布（概率模型）来实现聚类。</p>
<h5 id="k-means-聚类算法详解"><strong>K-Means 聚类算法详解</strong></h5>
<p><strong>目标函数</strong>：最小化所有样本到其所属簇中心的平方距离之和：<br>
<span class="math display">$$
E = \sum_{i=1}^{k} \sum_{\boldsymbol{x} \in C_i} \|\boldsymbol{x} -
\boldsymbol{\mu}_i\|_2^2
$$</span> 其中，$ <em>i = </em>{ C_i} $ 是簇 $ C_i $ 的均值向量。</p>
<p><strong>算法步骤</strong></p>
<ol type="1">
<li><strong>初始化簇中心</strong>：随机选择 $ k $ 个样本作为初始簇中心。
<ul>
<li><strong>改进方法</strong>：K-Means++
算法可提升初始中心的质量。<br>
</li>
</ul></li>
<li><strong>分配样本到最近簇</strong>：对每个样本 $
$，计算其到所有簇中心的距离，将其分配到距离最近的簇 $ C_i $。<br>
</li>
<li><strong>更新簇中心</strong>：重新计算每个簇的均值向量 $ _i $。<br>
</li>
<li><strong>迭代终止条件</strong>：
<ul>
<li>达到预设的最大迭代次数；<br>
</li>
<li>簇中心不再显著变化（如变化幅度小于阈值 $ $）；<br>
</li>
<li>样本分配不再改变。</li>
</ul></li>
</ol>
<p><strong>如何选择 $ k $ 值？</strong></p>
<ul>
<li><strong>肘部法则（Elbow Method）</strong>：绘制 $ k $ 与误差 $ E $
的关系曲线，选择误差下降显著变缓的 $ k $ 值。<br>
</li>
<li><strong>轮廓系数（Silhouette
Coefficient）</strong>：计算每个样本的轮廓系数，选择平均轮廓系数最大的 $
k $。</li>
</ul>
<h5 id="k-means的算法流程">K-Means的算法流程</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607114743211.png" alt="image-20250607114743211">
<figcaption aria-hidden="true">image-20250607114743211</figcaption>
</figure>
<h5 id="k-means">K-means++</h5>
<p>此法相对于 K-means 做出了一个小的改进。在一开始选择 k
个聚类中心时，并不是随机初始化 k 个，而是首先随机出 1 个，然后循环
k−1<em>k</em>−1 次选择剩下的 k-1
个聚类中心。选择的规则是：每次选择最不可能成为新的聚类中心的样本，或者是到所有聚类中心的最小距离最大的样本。</p>
<h5 id="优势"><strong>优势</strong></h5>
<p><strong>避免不良初始化</strong>
：传统K-means随机初始化可能导致中心过于集中，而K-means++通过“最大化最小距离”策略，使初始中心分布更均匀。</p>
<h5 id="bisecting-k-means">Bisecting K-means</h5>
<p>此法叫做二分 K-means
算法。具体的，在一开始将所有的样本划分为一个簇，然后每次选择一个误差最大的簇进行二分裂，不断分裂直到收敛。这种方法不能使得
Loss 最小，但是可以作为 K-means
算法的一个预热，比如可以通过这种方法得到一个相对合理的簇中心，然后再利用
K-means 算法进行聚类。</p>
<h5 id="优势-1"><strong>优势</strong></h5>
<p><strong>降低计算复杂度</strong>
：每次仅对一个簇进行二分，时间复杂度为
<em>O</em>(<em>k</em>⋅<em>m</em>⋅<em>n</em>) ，适合大规模数据。</p>
<p><strong>提供合理初始中心</strong>
：可作为传统K-means的预处理，减少随机初始化的影响。</p>
<h5 id="lvq学习向量量化"><strong>LVQ（学习向量量化）</strong></h5>
<p><strong>核心思想</strong>：<br>
LVQ
是一种<strong>有监督的原型聚类算法</strong>，结合了神经网络与向量量化技术。它通过维护一组<strong>原型向量</strong>（Prototype
Vectors）来代表不同类别，并利用这些原型对数据进行分类或聚类。与 K-Means
类似，LVQ
会为每个簇分配一个原型向量，但其更新规则受类别标签的指导，因此更适用于分类任务
。</p>
<p><strong>算法特点</strong>：</p>
<ul>
<li><strong>有监督学习</strong>：需要已知类别标签来调整原型向量，使同类样本更接近对应原型，异类样本远离原型。<br>
</li>
<li><strong>拓扑结构建模</strong>：通过原型向量捕捉数据的局部特征，类似于自组织映射（SOM），但更具针对性。<br>
</li>
<li><strong>硬聚类</strong>：每个样本最终被分配到最近的原型对应的类别，不提供概率输出
。</li>
</ul>
<h5 id="高斯混合聚类gaussian-mixture-model-gmm"><strong>高斯混合聚类（Gaussian
Mixture Model, GMM）</strong></h5>
<p>一句话概述算法：高斯混合聚类算法是一种概率模型，假设数据由多个高斯分布混合而成，通过迭代优化参数以拟合数据分布，常用于无监督学习中的聚类任务。</p>
<p>算法过程：</p>
<p>初始化参数： 随机初始化每个分量的均值、协方差矩阵和混合系数。</p>
<p>E 步（Expectation）：
对每个数据点，计算它属于每个分量的后验概率，即计算每个分量的权重。</p>
<p>M 步（Maximization）：
使用E步计算得到的后验概率，更新每个分量的均值、协方差矩阵和混合系数。</p>
<p>迭代： 重复执行E步和M步，直到模型参数收敛或达到预定的迭代次数。</p>
<p>GMM的优点包括对各种形状和方向的聚类簇建模能力，以及对数据分布的灵活性。它在许多领域，如模式识别、图像处理和自然语言处理等，都有广泛的应用。
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250611180451162.png" alt="image-20250611180451162"></p>
<p>以下是高斯混合聚类（GMM）算法的详细步骤及EM算法中E步与M步的解释：</p>
<p><strong>算法流程解析</strong></p>
<p><strong>输入</strong>：样本集 $ D = {x_1, x_2, , x_m} $，混合成分个数
$ k $。<br>
<strong>输出</strong>：簇划分 $ C = {C_1, C_2, , C_k} $。</p>
<p><strong>步骤详解</strong></p>
<ol type="1">
<li><p><strong>初始化模型参数</strong><br>
随机初始化或通过K-means初步估计以下参数：</p>
<ul>
<li><strong>混合系数</strong> $ <em>i $（满足 $ </em>{i=1}^k _i = 1
$）。</li>
<li><strong>均值向量</strong> $ _i $。</li>
<li><strong>协方差矩阵</strong> $ _i $。</li>
</ul></li>
<li><p><strong>迭代优化参数（EM循环）</strong><br>
重复以下步骤直到收敛（如对数似然变化小于阈值）：</p>
<ul>
<li><p><strong>E步（期望步）</strong>：<br>
对每个样本 $ x_j $，计算其由第 $ i $
个高斯分布生成的<strong>后验概率</strong>（责任度 $ <em>{ji} <span class="math inline">）：</span>$ </em>{ji} = p(z_j = i | x_j) = $$ 其中
$ (x | , ) $ 是高斯分布的概率密度函数。</p></li>
<li><p><strong>M步（最大化步）</strong>：<br>
根据当前的责任度 $ _{ji} $，更新模型参数：</p>
<ol type="1">
<li><strong>新均值向量</strong>： <span class="math display">$$
\mu_i' = \frac{\sum_{j=1}^m \gamma_{ji} x_j}{\sum_{j=1}^m \gamma_{ji}}
$$</span></li>
<li><strong>新协方差矩阵</strong>： <span class="math display">$$
\Sigma_i' = \frac{\sum_{j=1}^m \gamma_{ji} (x_j - \mu_i')(x_j -
\mu_i')^\top}{\sum_{j=1}^m \gamma_{ji}}
$$</span></li>
<li><strong>新混合系数</strong>： <span class="math display">$$
\alpha_i' = \frac{\sum_{j=1}^m \gamma_{ji}}{m}
$$</span></li>
</ol></li>
</ul></li>
<li><p><strong>簇划分</strong></p>
<ul>
<li>初始化空簇 $ C_i = $。</li>
<li>对每个样本 $ x_j $，计算其属于各簇的后验概率 $ _j = <em>i </em>{ji}
$。</li>
<li>将 $ x_j $ 分配到簇 $ C_{_j} $ 中。</li>
</ul></li>
</ol>
<p><strong>E步与M步的核心作用</strong></p>
<p><strong>E步（期望步）</strong></p>
<ul>
<li><strong>目标</strong>：基于当前参数 $ (_i, _i, <em>i)
$，计算每个样本 $ x_j $ 属于各高斯分布的<strong>责任度</strong> $
</em>{ji} $。</li>
<li><strong>意义</strong>：
<ul>
<li>责任度反映了在当前模型下，样本 $ x_j $ 由第 $ i $
个高斯分布生成的概率。</li>
<li><strong>软分配</strong>：允许样本部分属于多个簇，而非硬划分。</li>
</ul></li>
</ul>
<p><strong>M步（最大化步）</strong></p>
<ul>
<li><strong>目标</strong>：根据责任度 $ _{ji} $，重新估计模型参数 $
(_i’, _i’, _i’) $，以最大化数据的对数似然。</li>
<li><strong>关键公式</strong>：
<ul>
<li><strong>均值更新</strong>：加权平均样本点，权重为责任度。</li>
<li><strong>协方差更新</strong>：加权样本点的方差，反映簇内数据分布。</li>
<li><strong>混合系数更新</strong>：各簇样本的“有效数量”占总样本的比例。</li>
</ul></li>
</ul>
<h4 id="参考资料-1">参考资料</h4>
<p><a href="https://blog.csdn.net/smileyan9/article/details/135398479">西瓜书读书笔记整理（九）
—— 第九章 聚类_西瓜书笔记第9章-CSDN博客</a></p>
<h4 id="密度聚类与dbscan">密度聚类与DBSCAN</h4>
<blockquote>
<p>若样本分布为同心的两个环，kmeans则无法做到良好的聚类效果，因此引出密度聚类</p>
</blockquote>
<p>密度聚类是一种基于<strong>样本分布密集程度</strong>的无监督学习方法，其核心思想是：<strong>将高密度区域划分为同一簇，低密度区域视为噪声或边界</strong>。</p>
<p>DBSCAN（Density-Based Spatial Clustering of Applications with
Noise）是密度聚类的典型代表，通过两个关键参数 $ $ 和 $ MinPts $
描述样本分布的紧密性。</p>
<h5 id="核心概念"><strong>1. 核心概念</strong></h5>
<ol type="1">
<li><strong>$ $-邻域</strong>
<ul>
<li>定义：与样本 $ x $ 距离不超过 $ $ 的所有样本集合。<br>
</li>
<li>作用：衡量样本周围的局部密度。<br>
</li>
</ul></li>
<li><strong>核心对象（Core Object）</strong>
<ul>
<li>定义：若样本 $ x $ 的 $ $-邻域内包含至少 $ MinPts $ 个样本，则 $ x $
是核心对象。<br>
</li>
<li>作用：作为簇的生长起点，确保簇的最小密度要求。<br>
</li>
</ul></li>
<li><strong>密度直达（Directly Density-Reachable）</strong>
<ul>
<li>定义：若样本 $ x_j $ 位于核心对象 $ x_i $ 的 $ $-邻域内，则称 $ x_i
$ 可密度直达 $ x_j $。<br>
</li>
<li>作用：建立核心对象与邻近样本的直接连接。<br>
</li>
</ul></li>
<li><strong>密度可达（Density-Reachable）</strong>
<ul>
<li>定义：若存在样本序列 $ x_i, p_1, p_2, , p_n, x_j $，其中 $ p_i $
密度直达 $ p_{i+1} $，则称 $ x_i $ 可密度可达 $ x_j $。<br>
</li>
<li>作用：通过链式传递扩展簇的范围。<br>
</li>
</ul></li>
<li><strong>密度相连（Density-Connected）</strong>
<ul>
<li>定义：若样本 $ x_i $ 和 $ x_j $ 均可密度可达某个公共样本 $ x_k
$，则称 $ x_i $ 和 $ x_j $ 密度相连。<br>
</li>
<li>作用：确保簇的连通性，避免碎片化。</li>
</ul></li>
</ol>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124326529.png" alt="image-20250607124326529">
<figcaption aria-hidden="true">image-20250607124326529</figcaption>
</figure>
<p><strong>DBSCN定义的簇</strong></p>
<ul>
<li>定义：最大密度相连的样本集合为一个簇</li>
<li>有两个性质：1.连接性：同一个簇内任意两样本，必然密度相连2.最大性：密度可达的两个样本必
定属于同一个簇</li>
</ul>
<h5 id="dbscan-算法流程"><strong>2. DBSCAN 算法流程</strong></h5>
<p>简单来理解DBSCAN：<strong>找出一个核心对象所有密度可达的样本集合形成簇</strong>。首先从数据集中任选一个核心对象A，找出所有A密度可达的样本集合，将这些样本形成一个密度相连的类簇，直到所有的核心对象都遍历完。DBSCAN算法的流程如下图所示：</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124446432.png" alt="image-20250607124446432">
<figcaption aria-hidden="true">image-20250607124446432</figcaption>
</figure>
<h5 id="参数选择与影响"><strong>3. 参数选择与影响</strong></h5>
<ul>
<li><strong>$ $（邻域半径）</strong>：
<ul>
<li>过小：可能导致多数样本被标记为噪声，簇数量增加。<br>
</li>
<li>过大：可能导致不同簇合并，簇数量减少。<br>
</li>
<li><strong>选择方法</strong>：通过<strong>K-Distance图</strong>（排序后的第
$ k $ 近邻距离）观察“拐点”。</li>
</ul></li>
<li><strong>$ MinPts $（最小样本数）</strong>：
<ul>
<li>控制簇的最小密度阈值。<br>
</li>
<li>通常取 $ d+1 <span class="math inline">（</span> d $
为特征维度），避免在高维空间中误判噪声。</li>
</ul></li>
</ul>
<h4 id="层次聚类与agnes">层次聚类与AGNES</h4>
<p>层次聚类是一种通过构建<strong>树状结构（Dendrogram）</strong>将数据划分为不同层次的聚类方法。其核心思想是：<br>
-
<strong>凝聚型（Agglomerative）</strong>：从每个样本作为一个独立簇开始，逐步合并最相似的簇，直到达到预设的簇数或形成一个唯一簇。<br>
-
<strong>分裂型（Divisive）</strong>：与凝聚型相反，从整个数据集作为一个簇开始，逐步分裂为更小的簇。</p>
<p>本节重点介绍<strong>AGNES（Agglomerative
Nesting）</strong>，一种经典的自底向上的层次聚类算法。</p>
<h5 id="agnes-算法流程"><strong>1. AGNES 算法流程</strong></h5>
<ol type="1">
<li><strong>初始化</strong>：每个样本作为一个独立簇。<br>
</li>
<li><strong>迭代合并</strong>：
<ul>
<li>计算所有簇对之间的距离。<br>
</li>
<li>合并距离最近的两个簇。<br>
</li>
</ul></li>
<li><strong>终止条件</strong>：
<ul>
<li>达到预设的簇数 $ k $；<br>
</li>
<li>所有簇之间的距离大于阈值。</li>
</ul></li>
</ol>
<h5 id="簇间距离的定义"><strong>2. 簇间距离的定义</strong></h5>
<p>AGNES
的关键在于如何定义<strong>簇间距离</strong>，常见的三种方法如下：</p>
<p><strong>（1）最小距离（Single Linkage）</strong> <span class="math display"><em>d</em><sub>min</sub>(<em>C</em><sub><em>i</em></sub>, <em>C</em><sub><em>j</em></sub>) = min<sub><strong>x</strong> ∈ <em>C</em><sub><em>i</em></sub>, <strong>z</strong> ∈ <em>C</em><sub><em>j</em></sub></sub>dist(<strong>x</strong>, <strong>z</strong>)</span>
- <strong>含义</strong>：两个簇之间最近的两个样本的距离。</p>
<p><strong>（2）最大距离（Complete Linkage）</strong> <span class="math display"><em>d</em><sub>max</sub>(<em>C</em><sub><em>i</em></sub>, <em>C</em><sub><em>j</em></sub>) = max<sub><strong>x</strong> ∈ <em>C</em><sub><em>i</em></sub>, <strong>z</strong> ∈ <em>C</em><sub><em>j</em></sub></sub>dist(<strong>x</strong>, <strong>z</strong>)</span>
- <strong>含义</strong>：两个簇之间最远的两个样本的距离。</p>
<p><strong>（3）平均距离（Average Linkage）</strong> <span class="math display">$$
d_{\text{avg}}(C_i, C_j) = \frac{1}{|C_i| |C_j|} \sum_{\boldsymbol{x}
\in C_i} \sum_{\boldsymbol{z} \in C_j} \text{dist}(\boldsymbol{x},
\boldsymbol{z})
$$</span> - <strong>含义</strong>：两个簇所有样本对距离的平均值。</p>
<h5 id="层次聚类法的算法流程如下所示">层次聚类法的算法流程如下所示：</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125338029.png" alt="image-20250607125338029">
<figcaption aria-hidden="true">image-20250607125338029</figcaption>
</figure>
<h4 id="作业-2">作业</h4>
<h5 id="section-6">1</h5>
<p>假设任务是将下面8个点聚类成3个簇：A1(2,10), A2(2,5), A3(8,4),
B1(5,8), B2(7,5), B3(6,4), C1(1,2),
C3(4,9)，距离函数是欧式距离。假设初始选择A1，B1，C1分别作为每个聚类的中心，用Kmeans算法给出计算过程。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125506436.png" alt="image-20250607125506436">
<figcaption aria-hidden="true">image-20250607125506436</figcaption>
</figure>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125606040.png" alt="image-20250607125606040">
<figcaption aria-hidden="true">image-20250607125606040</figcaption>
</figure>
<h5 id="section-7">2</h5>
<p>Kmeans初始类簇中心如何选取？K值如何确定？请简要阐述。</p>
<p><strong>一、初始类簇中心的选取 (如何选好的起始点？)</strong></p>
<p>传统K-means随机选择初始中心点，容易导致结果不稳定（多次运行结果不同）或陷入局部最优（效果差）。改进方法主要有：</p>
<ol type="1">
<li><strong>K-means++ (最常用且推荐)：</strong>
<ul>
<li><strong>核心思想：</strong> 让初始中心点彼此尽量远离。</li>
<li><strong>步骤：</strong>
<ol type="1">
<li>随机选择<strong>第一个</strong>中心点。</li>
<li>计算每个数据点到<strong>当前已选中心点</strong>的最短距离（即离最近中心的距离）。</li>
<li>以<strong>与这个最短距离平方成正比</strong>的概率，随机选择下一个中心点（距离越大的点，被选中的概率越大）。</li>
<li>重复步骤2和3，直到选出K个中心点。</li>
</ol></li>
<li><strong>优点：</strong>
显著提高聚类质量和稳定性，计算开销增加不大。</li>
</ul></li>
<li><strong>多次运行+选取最优：</strong>
<ul>
<li>独立运行K-means算法多次（每次随机初始化）。</li>
<li>每次运行完成后，计算所有数据点与其所属簇中心的距离平方和（SSE, Sum
of Squared Errors）。</li>
<li>选择SSE最小的那次运行结果作为最终结果。</li>
<li><strong>优点：</strong> 简单，增加找到更好解的机会。</li>
<li><strong>缺点：</strong> 计算开销随运行次数增加。</li>
</ul></li>
<li><strong>基于样本密度/距离：</strong>
<ul>
<li>选择数据空间中样本密度高的区域点作为中心。</li>
<li>或选择相互之间距离较远的点作为中心（类似K-means++的思想，但实现方式可能不同）。</li>
</ul></li>
</ol>
<p><strong>二、K值（簇数量）的确定 (如何知道分几类？)</strong></p>
<p>K值通常需要预先指定，但没有绝对正确的答案。常用方法基于评估不同K值下聚类结果的“质量”，寻找拐点或最优值：</p>
<ol type="1">
<li><strong>肘部法则：</strong>
<ul>
<li><strong>核心思想：</strong>
随着K增大，簇内样本聚合更紧密，簇内平方和误差（SSE）会下降，但下降幅度会逐渐变缓。找到SSE下降速率发生显著变化的“肘点”。</li>
<li><strong>做法：</strong> 计算不同K值（如K=1, 2, 3, …,
max）对应的SSE。绘制<code>K值 - SSE</code>曲线图。观察曲线，寻找SSE下降幅度突然变得平缓的那个K值（形如手臂的“肘关节”）。</li>
<li><strong>优点：</strong> 直观。</li>
<li><strong>缺点：</strong>
“肘点”有时不明显或不存在，需要主观判断。</li>
</ul></li>
<li><strong>轮廓系数：</strong>
<ul>
<li><strong>核心思想：</strong>
综合衡量一个样本与其自身簇的紧密度(<code>a</code>)和与其他簇的分离度(<code>b</code>)。</li>
<li><strong>计算：</strong> 对于每个样本i：
<ul>
<li><code>a(i)</code> = i
到同簇内所有其他点的平均距离（簇内不相似度）。</li>
<li><code>b(i)</code> = i
到所有<strong>其他簇</strong>中点的平均距离的最小值（最近邻簇的不相似度）。</li>
<li>样本i的轮廓系数：<code>s(i) = (b(i) - a(i)) / max(a(i), b(i))</code>。值在[-1,
1]之间。</li>
</ul></li>
<li><strong>整体评估：</strong>
计算所有样本轮廓系数的平均值，作为该K值下聚类的整体轮廓系数。</li>
<li><strong>选择K：</strong>
尝试不同K值，选择<strong>平均轮廓系数最大</strong>对应的K值。轮廓系数越接近1，表示聚类效果越好（簇内紧凑，簇间分离）。</li>
<li><strong>优点：</strong> 量化评估，结果在[-1, 1]之间有界。</li>
<li><strong>缺点：</strong> 计算量较大，尤其对于大数据集。</li>
</ul></li>
</ol>
<h4 id="参考资料-2">参考资料</h4>
<p><a href="https://cloud.tencent.com.cn/developer/article/1802143">《机器学习》–
第九章 聚类-腾讯云开发者社区-腾讯云</a></p>
<h3 id="降维与度量学习">降维与度量学习</h3>
<h4 id="knn">KNN</h4>
<p>k近邻算法简称<strong>kNN（k-Nearest
Neighbor）</strong>，是一种经典的监督学习方法，是数据挖掘十大算法之一。其工作机制十分简单：给定某个测试样本，kNN基于某种<strong>距离度量</strong>在训练集中找出与其距离最近的k个带有真实标记的训练样本，然后基于这k个邻居的真实标记来进行预测，类似于集成学习中的基学习器结合策略：分类任务采用投票法，回归任务则采用平均法。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607150256290.png" alt="image-20250607150256290">
<figcaption aria-hidden="true">image-20250607150256290</figcaption>
</figure>
<p><strong>核心思想</strong></p>
<p>1NN 分类器通过将测试样本 $ $ 分配到其最近邻样本 $ $
的类别来完成预测。其错误概率取决于两个关键因素： - <strong>$ $
的真实类别</strong>：$ P(c | ) $，即给定 $ $ 属于类别 $ c $
的概率。<br>
- <strong>$ $ 的类别</strong>：$ P(c | ) $，即 $ $ 属于类别 $ c $
的概率。</p>
<p><strong>错误概率公式</strong></p>
<p>若测试样本 $ $ 的最近邻为 $ <span class="math inline">，<em>则</em>1<em>N</em><em>N</em><em>分</em><em>类</em><em>器</em><em>出</em><em>错</em><em>的</em><em>概</em><em>率</em><em>为</em>：</span>$
P() = 1 - P() = 1 - _{c } P(c | ) P(c | ) $$ 其中： - $ $
是所有可能的类别集合。<br>
- $ P(c | ) <span class="math inline">：</span> $ 属于类别 $ c $
的条件概率。<br>
- $ P(c | ) <span class="math inline">：</span> $ 属于类别 $ c $
的条件概率。</p>
<p>通过证明可以发现一个令人震惊的结论：<strong>最近邻分类器的错误率不超过贝叶斯最优分类器错误率的两倍</strong>。</p>
<p>对于距离度量，<strong>不同的度量方法得到的k个近邻不尽相同，从而对最终的投票结果产生了影响</strong>，因此选择一个合适的距离度量方法也十分重要。</p>
<p>在上一篇聚类算法中，在度量样本相似性时介绍了常用的几种距离计算方法，包括<strong>闵可夫斯基距离，曼哈顿距离，VDM</strong>等。在实际应用中，<strong>kNN的距离度量函数一般根据样本的特性来选择合适的距离度量，同时应对数据进行去量纲/归一化处理来消除大量纲属性的强权政治影响</strong>。</p>
<h4 id="低维嵌入">低维嵌入</h4>
<p><strong>使用knn的前提是样本空间的密度要一定大，但是这个条件在现实中很难满足，因此引出降维操作</strong></p>
<blockquote>
<p>kNN的重要假设: 任意测试样本 附近任意小的
距离范围内总能找到一个训练样本，即训练样本的采样密度足够大，或称为
<strong>“密采样”( dense sample)</strong>
。然而，这个假设在现实任务中通常很难满足</p>
</blockquote>
<p>样本的<strong>特征数</strong>也称为<strong>维数</strong>（dimensionality），当维数非常大时，也就是通常所说的“<strong>维数灾难</strong>”(curse
of
dimensionality)，具体表现在：在高维情形下，<strong>数据样本变得十分稀疏</strong>，因为此时要满足训练样本为“<strong>密采样</strong>”的总体样本数目是一个触不可及的天文数字。<strong>训练样本的稀疏使得其代表总体分布的能力大大减弱，从而消减了学习器的泛化能力</strong>；同时当维数很高时，<strong>计算距离也变得十分复杂</strong>，甚至连计算内积都不再容易</p>
<p>缓解维数灾难的一个重要途径就是<strong>降维（dimension
reduction），即通过某种数学变换将原始高维空间转变到一个低维的子空间</strong>。在这个子空间中，样本的密度将大幅提高，同时距离计算也变得容易。这</p>
<p>时也许会有疑问，降维之后不是会丢失原始数据的一部分信息吗？</p>
<p>实际上，在很多实际问题中，虽然训练数据是高维的，但是与学习任务相关也许仅仅是其中的一个低维子空间，也称为一个<strong>低维嵌入</strong>，例如：数据属性中存在噪声属性、相似属性或冗余属性等，<strong>对高维数据进行降维能在一定程度上达到提炼低维优质属性或降噪的效果</strong>。</p>
<h4 id="mds算法"><strong>MDS算法</strong></h4>
<p>MDS（Multidimensional
Scaling，多维尺度分析）是一种经典的<strong>降维技术</strong>，其核心目标是将高维数据映射到低维空间（如二维或三维），同时<strong>尽可能保留原始数据中样本点之间的距离关系</strong>。以下是其核心原理与应用要点：</p>
<p><strong>1. 核心思想</strong></p>
<ul>
<li><strong>输入</strong>：一个样本点之间的距离矩阵 $ D
$（如欧氏距离、余弦距离等）。<br>
</li>
<li><strong>输出</strong>：低维空间中样本点的坐标矩阵 $ Z
$，使得低维空间中的距离与原始距离尽可能一致 。<br>
</li>
<li><strong>关键假设</strong>：高维数据的内在结构可通过样本间的距离关系描述，降维后需最小化这种关系的失真。</li>
</ul>
<p><strong>2. 算法步骤</strong></p>
<p>MDS 的核心是通过<strong>矩阵分解</strong>从距离矩阵推导低维坐标： 1.
<strong>构建距离矩阵 $ D $</strong>：<br>
对于 $ r $ 个样本，计算两两之间的距离，形成 $ r r $ 的矩阵 $ D $，其中 $
D_{ij} $ 表示样本 $ i $ 和 $ j $ 的距离 。</p>
<ol start="2" type="1">
<li><p><strong>双中心化（Double Centering）</strong>：<br>
构造矩阵 $ B = - H D^{(2)} H $，其中 $ D^{(2)} $ 是距离的平方矩阵，$ H =
I - ^$ 是中心化矩阵 。</p></li>
<li><p><strong>特征值分解</strong>：<br>
对 $ B $ 进行特征值分解，得到 $ B = V V^$，其中 $ $
是按降序排列的特征值对角矩阵，$ V $ 是对应的特征向量矩阵 。</p></li>
<li><p><strong>构造低维坐标</strong>：<br>
选择前 $ d’ $ 个最大特征值（$ d’ $
为目标维度）和对应的特征向量，计算低维坐标矩阵：<br>
<span class="math display"><em>Z</em> = <em>Λ</em><sup>1/2</sup><em>V</em><sup>⊤</sup></span>
其中 $ ^{1/2} $ 是特征值矩阵的平方根 。</p></li>
</ol>
<p><strong>3. 关键特性</strong></p>
<ul>
<li><strong>保留距离关系</strong>：MDS
直接优化低维空间中的距离与原始距离的一致性，适用于需精确保留样本相似性的场景（如生物信息学中的基因关系分析）。<br>
</li>
<li><strong>非线性适应性</strong>：与 PCA 不同，MDS
不要求数据线性分布，更适合处理非线性结构（如环形、流形数据）。<br>
</li>
<li><strong>灵活性</strong>：支持任意距离度量（如自定义的相似性指标），而
PCA 仅适用于欧氏距离 。</li>
</ul>
<h4 id="线性降维方法"><strong>线性降维方法</strong></h4>
<p>线性降维通过<strong>线性变换</strong>将高维数据 $ ^{d m} $
投影到低维空间 $ ^{d’ m} <span class="math inline">（</span> d’ d <span class="math inline">），<em>保</em><em>留</em><em>数</em><em>据</em><em>的</em><em>主</em><em>要</em><em>信</em><em>息</em>。<em>其</em><em>数</em><em>学</em><em>表</em><em>达</em><em>为</em>：</span>$
= ^ $$</p>
<ul>
<li><p><strong>变换矩阵 $ ^{d d’} $</strong>：<br>
每一列是正交的基向量，构成低维子空间的坐标系。<br>
</p></li>
<li><p><strong>目标</strong>：选择 $ $ 使得低维表示 $ $
最大化保留原始数据的信息（如方差、距离等）。</p></li>
<li><p><strong>MDS</strong>：<br>
直接以<strong>保留高维空间中样本点之间的距离关系</strong>为目标。降维后的低维空间需尽可能保持原始样本两两之间的距离（如欧氏距离、自定义相似性距离）。</p>
<ul>
<li><strong>示例</strong>：在基因数据分析中，MDS可确保基因表达相似的样本在低维空间中仍紧密分布。</li>
</ul></li>
<li><p><strong>其他线性方法（如PCA、LDA）</strong>：</p>
<ul>
<li><strong>PCA</strong>：最大化数据在低维空间的方差，强调保留全局结构而非具体距离。<br>
</li>
<li><strong>LDA</strong>：在监督学习中最大化类间分离度，忽略类内距离。</li>
</ul></li>
</ul>
<h4 id="主成分分析">主成分分析</h4>
<p>不同于MDS采用距离保持的方法，主成分分析（Principal Component Analysis
,PCA）是一种经典的<strong>无监督降维算法</strong>
，其核心目标是通过线性变换将高维数据映射到低维空间，同时保留数据的<strong>最大方差信息</strong>
（即信息损失最小）</p>
<p>直接通过一个<strong>线性变换</strong>，将原始空间中的样本<strong>投影</strong>到新的低维空间中。</p>
<p>简单来理解这一过程便是：<strong>PCA采用一组新的基（向量）来表示样本点，其中每一个基向量都是原始空间基向量的线性组合，通过使用尽可能少的新基向量来表出样本，从而达到降维的目的。</strong></p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607155733314.png" alt="image-20250607155733314">
<figcaption aria-hidden="true">image-20250607155733314</figcaption>
</figure>
<p>假设使用d’个新基向量来表示原来样本，实质上是将样本投影到一个由d’个基向量确定的一个<strong>超平面</strong>上（<strong>即舍弃了一些维度</strong>），要用一个超平面对空间中所有高维样本进行恰当的表达，最理想的情形是：<strong>若这些样本点都能在超平面上表出且这些表出在超平面上都能够很好地分散开来</strong>。但是一般使用较原空间低一些维度的超平面来做到这两点十分不容易，因此我们退一步海阔天空，要求这个超平面应具有如下两个性质：</p>
<blockquote>
<p><strong>最近重构性</strong>：样本点到超平面的距离足够近，即尽可能在超平面附近；</p>
<p><strong>最大可分性</strong>：样本点在超平面上的投影尽可能地分散开来，即投影后的坐标具有区分性。</p>
</blockquote>
<p>这里十分神奇的是：<strong>最近重构性与最大可分性虽然从不同的出发点来定义优化问题中的目标函数，但最终这两种特性得到了完全相同的优化问题</strong>：</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607165159235.png" alt="image-20250607165159235">
<figcaption aria-hidden="true">image-20250607165159235</figcaption>
</figure>
<h5 id="协方差矩阵与优化求解"><strong>协方差矩阵与优化求解</strong></h5>
<p>若数据已<strong>中心化</strong>（均值为零），则 $ ^$
是<strong>样本协方差矩阵</strong>的 $ m $
倍。此时，PCA的优化问题转化为： <span class="math display">$$
\begin{aligned}
&amp; \underset{\mathbf{W}}{\text{maximize}}
&amp; &amp; \text{tr}\left( \mathbf{W}^\top \mathbf{X} \mathbf{X}^\top
\mathbf{W} \right) \\
&amp; \text{subject to}
&amp; &amp; \mathbf{W}^\top \mathbf{W} = \mathbf{I}
\end{aligned}
$$</span> 通过拉格朗日乘数法，该问题的解为 $ ^$ 的前 $ d’ $
个最大特征值对应的特征向量</p>
<h5 id="pca的数学推导"><strong>PCA的数学推导</strong></h5>
<ul>
<li><p><strong>优化目标</strong>：<br>
<span class="math display">max<sub><strong>W</strong></sub>  tr(<strong>W</strong><sup>⊤</sup><strong>X</strong><strong>X</strong><sup>⊤</sup><strong>W</strong>)  s.t.  <strong>W</strong><sup>⊤</sup><strong>W</strong> = <strong>I</strong></span>
其中，$ ^{d m} $ 是中心化后的数据矩阵（均值为零）。</p></li>
<li><p><strong>拉格朗日乘数法</strong>：<br>
引入拉格朗日乘子 $ <span class="math inline">，<em>构</em><em>造</em><em>拉</em><em>格</em><em>朗</em><em>日</em><em>函</em><em>数</em>：</span>$
(, ) = ( ^ ^ ) - ( (^ - ) ) <span class="math display">$$
对 $ \mathbf{W} $ 求导并令导数为零，得到：
$$</span> ^ = <span class="math display">$$
即 $ \mathbf{X} \mathbf{X}^\top $ 的特征向量 $ \mathbf{w}_i $ 满足：
$$</span> ^_i = _i _i $$</p></li>
</ul>
<h5 id="pca特征向量选择">PCA特征向量选择</h5>
<p><strong>1. 核心问题</strong></p>
<p>在PCA中，我们希望找到一个 $ d’ d $ 的变换矩阵 $
$，其列向量是协方差矩阵 $ ^$ 的特征向量，且满足正交约束 $ ^ =
$。关键问题是：<strong>如何从 $ d $ 个特征向量中选择 $ d’ $
个最优的？</strong></p>
<p><strong>2. 数学推导</strong></p>
<ol type="1">
<li><p><strong>特征值分解</strong>：<br>
协方差矩阵 $ <sup></sup>{d d} $ 可分解为： <span class="math display"><strong>X</strong><strong>X</strong><sup>⊤</sup><strong>W</strong> = <strong>W</strong><strong>Λ</strong></span>
其中，$ = (_1, _2, , _d) $ 是特征值对角矩阵，$ $
是特征向量矩阵。</p></li>
<li><p><strong>优化目标转化</strong>：<br>
PCA的目标是最大化 $ (^ ^) <span class="math inline">。<em>利</em><em>用</em><em>特</em><em>征</em><em>值</em><em>分</em><em>解</em>，<em>可</em><em>得</em>：</span>$
^ ^ = ^( ) = <span class="math display"><em>因</em><em>此</em>，<em>优</em><em>化</em><em>目</em><em>标</em><em>变</em><em>为</em>：</span>
<em>{} () = </em>{i=1}^{d’} _i $$ 即选择 $ d’ $ 个最大的特征值 $ _i $
对应的特征向量组成 $ $。</p></li>
</ol>
<p><strong>3. 特征向量选择策略</strong></p>
<ul>
<li><strong>按特征值排序</strong>：<br>
特征值 $ _i $ 表示数据沿特征向量 $ _i $ 方向的方差。选择前 $ d’ $
个最大特征值对应的特征向量，可保留最多信息。<br>
</li>
<li><strong>正交性保证</strong>：<br>
特征向量矩阵 $ $ 的列自动满足 $ ^ = $，无需额外正交化。</li>
</ul>
<h5 id="pca算法的整个流程如下图所示">PCA算法的整个流程如下图所示：</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607170020467.png" alt="image-20250607170020467">
<figcaption aria-hidden="true">image-20250607170020467</figcaption>
</figure>
<h4 id="核化线性降维"><strong>核化线性降维</strong></h4>
<p>待学习</p>
<h4 id="流形学习">流形学习</h4>
<p><strong>流形学习（manifold
learning）</strong>是一种借助拓扑流形概念的降维方法，流形是指在<strong>局部与欧式空间同胚的空间</strong>，即在局部与欧式空间具有相同的性质，能用欧氏距离计算样本之间的距离。这样即使高维空间的分布十分复杂，但是在局部上依然满足欧式空间的性质，基于流形学习的降维正是这种
<strong>“邻域保持”</strong> 的思想。其中
<strong>等度量映射（Isomap）试图在降维前后保持邻域内样本之间的距离，而局部线性嵌入（LLE）则是保持邻域内样本之间的线性关系</strong>
。</p>
<h5 id="等度量映射isomap">等度量映射Isomap</h5>
<p>等度量映射的基本出发点是：高维空间中的直线距离具有误导性，因为有时高维空间中的直线距离在低维空间中是不可达的。<strong>因此利用流形在局部上与欧式空间同胚的性质，可以使用近邻距离来逼近测地线距离</strong>，即对于一个样本点，它与近邻内的样本点之间是可达的，且距离使用欧式距离计算，这样整个样本空间就形成了一张近邻图，高维空间中两个样本之间的距离就转为最短路径问题。可采用著名的<strong>Dijkstra算法</strong>或<strong>Floyd算法</strong>计算最短距离，得到高维空间中任意两点之间的距离后便可以使用
MDS 算法来其计算低维空间中的坐标。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171119645.png" alt="image-20250607171119645">
<figcaption aria-hidden="true">image-20250607171119645</figcaption>
</figure>
<p>Isomap算法流程如下图：</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171258284.png" alt="image-20250607171258284">
<figcaption aria-hidden="true">image-20250607171258284</figcaption>
</figure>
<p>对于近邻图的构建，常用的有两种方法：<strong>一种是指定近邻点个数</strong>，像kNN一样选取k个最近的邻居；<strong>另一种是指定邻域半径</strong>，距离小于该阈值的被认为是它的近邻点。但两种方法均会出现下面的问题：</p>
<blockquote>
<p>若<strong>邻域范围指定过大，则会造成“短路问题”</strong>，即本身距离很远却成了近邻，将距离近的那些样本扼杀在摇篮。</p>
<p>若<strong>邻域范围指定过小，则会造成“断路问题”</strong>，即有些样本点无法可达了，整个世界村被划分为互不可达的小部落。</p>
</blockquote>
<h5 id="局部线性嵌入">局部线性嵌入</h5>
<p>待学习</p>
<h4 id="度量学习">度量学习</h4>
<p><strong>1. 核心思想</strong></p>
<p>度量学习（Metric
Learning）的核心目标是<strong>学习一个合理的距离度量</strong>，使得相似样本距离更近，不相似样本距离更远。传统欧式距离（Euclidean
Distance）虽然简单，但其固定权重无法反映不同特征的实际重要性。因此，我们引入<strong>加权欧式距离</strong>，通过可调节的参数（权重）优化距离计算。</p>
<p><strong>2. 欧式距离与加权欧式距离</strong></p>
<ul>
<li><p><strong>标准欧式距离</strong>：<br>
<span class="math display">$$
\text{dist}_{\text{ed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) =
\|\boldsymbol{x}_i - \boldsymbol{x}_j\|_2^2 = \sum_{k=1}^d
(\boldsymbol{x}_{i,k} - \boldsymbol{x}_{j,k})^2
$$</span>
每个特征维度对距离的贡献相同，未考虑特征的重要性差异。</p></li>
<li><p><strong>加权欧式距离</strong>：<br>
<span class="math display">dist<sub>wed</sub><sup>2</sup>(<strong>x</strong><sub><em>i</em></sub>, <strong>x</strong><sub><em>j</em></sub>) = (<strong>x</strong><sub><em>i</em></sub> − <strong>x</strong><sub><em>j</em></sub>)<sup>⊤</sup><strong>W</strong>(<strong>x</strong><sub><em>i</em></sub> − <strong>x</strong><sub><em>j</em></sub>)</span>
其中，$ = () $ 是对角权重矩阵，$ w_k $ 表示第 $ k $ 个特征的权重。<br>
展开后为： <span class="math display">$$
\text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) =
\sum_{k=1}^d w_k (\boldsymbol{x}_{i,k} - \boldsymbol{x}_{j,k})^2
$$</span></p></li>
</ul>
<p><strong>3. 权重的作用</strong></p>
<ul>
<li><strong>特征重要性调节</strong>：
<ul>
<li>高权重 $ w_k $：强调第 $ k $
维特征对距离的影响（如图像的颜色通道比位置更重要）。<br>
</li>
<li>低权重 $ w_k $：弱化噪声或冗余特征的影响。<br>
</li>
</ul></li>
<li><strong>几何意义</strong>：<br>
加权欧式距离相当于在各特征维度上进行缩放，将数据映射到一个新的空间，使得关键特征的差异更显著。</li>
</ul>
<p><strong>4. 度量学习的目标</strong></p>
<p>通过学习最优权重 $ <span class="math inline">，<em>使</em><em>以</em><em>下</em><em>目</em><em>标</em><em>成</em><em>立</em>： − * * <em>相</em><em>似</em><em>样</em><em>本</em> * *：<em>加</em><em>权</em><em>距</em><em>离</em><em>小</em>（</span>
_{}^2(_i, <em>j) <span class="math inline">）。 − * * <em>不</em><em>相</em><em>似</em><em>样</em><em>本</em> * *：<em>加</em><em>权</em><em>距</em><em>离</em><em>大</em>（</span>
</em>{}^2(_i, _j) $）。</p>
<p>典型优化问题形式： <span class="math display">min<sub><strong>w</strong></sub>  ∑<sub>(<strong>x</strong><sub><em>i</em></sub>, <strong>x</strong><sub><em>j</em></sub>) ∈ <em>S</em></sub>dist<sub>wed</sub><sup>2</sup>(<strong>x</strong><sub><em>i</em></sub>, <strong>x</strong><sub><em>j</em></sub>) + <em>λ</em>∥<strong>w</strong>∥<sub>2</sub><sup>2</sup></span>
其中，$ S $ 是相似样本对集合，$ $ 是正则化项防止过拟合。</p>
<blockquote>
<p>总结来说，</p>
<ul>
<li><strong>降维是将原高维空间嵌入到一个合适的低维子空间中，接着在低维空间中进行学习任务</strong></li>
<li><strong>度量学习则是试图去学习出一个 *距离度量*
来等效降维的效果</strong></li>
</ul>
</blockquote>
<h5 id="lmnnlarge-margin-nearest-neighbors详解"><strong>LMNN（Large
Margin Nearest Neighbors）详解</strong></h5>
<p><strong>1. 核心思想</strong></p>
<p>LMNN
是一种<strong>监督度量学习方法</strong>，其目标是通过学习一个线性变换矩阵
$
$，使<strong>同类样本在变换后的空间中更紧密</strong>，<strong>不同类样本被推开</strong>，从而提升KNN等基于距离的算法性能。其核心是引入<strong>最大边距（Large
Margin）</strong>的概念，类似于SVM的分类边界。</p>
<p><strong>2. 损失函数</strong></p>
<p>LMNN 的优化目标由两部分组成： - <strong>Pull
Loss（拉力损失）</strong>：<br>
使同类样本对的距离尽可能小，公式为： <span class="math display">$$
  \varepsilon_{\text{pull}}(\mathbf{L}) = \sum_{j \sim i}
\|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2
  $$</span> 其中，$ j i $ 表示与样本 $ i $ 同类的最近邻样本。</p>
<ul>
<li><p><strong>Push Loss（推力损失）</strong>：<br>
使不同类样本对的距离至少保持一个固定边距 $ <em>{ijl} <span class="math inline">，<em>公</em><em>式</em><em>为</em>：</span>$
</em>{}() = <em>{i,j,l} (1 - y</em>{il}) <em>+ $$ 其中，$ y</em>{il} = 1
$ 表示样本 $ i $ 和 $ l $ 属于同一类，否则为0；$ []_+ $
表示取正值部分。</p></li>
<li><p><strong>总损失函数</strong>：<br>
<span class="math display"><em>ε</em>(<strong>L</strong>) = (1 − <em>μ</em>)<em>ε</em><sub>pull</sub>(<strong>L</strong>) + <em>μ</em><em>ε</em><sub>push</sub>(<strong>L</strong>)</span>
参数 $ $ 控制两类损失的权重。</p></li>
</ul>
<p><strong>3. 优化问题</strong></p>
<p>LMNN 的目标是最小化总损失函数，同时满足以下约束： <span class="math display">$$
\begin{aligned}
&amp; \min_{\mathbf{M}, \boldsymbol{\xi}} \quad (1 - \mu) \sum_{i,j \sim
i} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)^\top \mathbf{M}
(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j) + \mu \sum_{i,j \sim
i,l} (1 - y_{il}) \xi_{ijl} \\
&amp; \text{s.t.} \quad (\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_l)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_l) - (\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_j)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_j) \geq 1 - \xi_{ijl}, \\
&amp; \quad \quad \quad \xi_{ijl} \geq 0, \quad \mathbf{M} \succeq 0.
\end{aligned}
$$</span> -
<strong>约束（1）</strong>：确保不同类样本对的距离比同类样本对大至少 $ 1
- <em>{ijl} $。<br>
- <strong>约束（2）</strong>：松弛变量 $ </em>{ijl} $
允许部分样本对违反约束。<br>
- <strong>约束（3）</strong>：$ $
必须是半正定矩阵，保证距离的非负性和三角不等式。</p>
<h4 id="作业-3">作业</h4>
<h5 id="section-8">1</h5>
<p>数据降维有哪些常用的方法？阐述主成分分析（PCA）算法的计算流程，并讨论PCA
降维之后的维度如何确定？</p>
<p><strong>（1）常用数据降维方法</strong></p>
<ol type="1">
<li><strong>主成分分析（PCA）</strong>：通过线性变换保留最大方差方向，适用于去噪和压缩数据
。<br>
</li>
<li><strong>线性判别分析（LDA）</strong>：在监督学习中最大化类间分离度，适用于分类任务
。</li>
</ol>
<p><strong>（2）主成分分析（PCA）的计算流程</strong></p>
<ol type="1">
<li><strong>数据标准化</strong>：对原始数据去均值、方差归一化，消除量纲影响
。<br>
</li>
<li><strong>计算协方差矩阵</strong>：<br>
<span class="math display">$$
\mathbf{\Sigma} = \frac{1}{m} \mathbf{X} \mathbf{X}^\top
$$</span> 其中 $ $ 是中心化后的数据矩阵 。<br>
</li>
<li><strong>特征值分解</strong>：对协方差矩阵进行特征值分解，得到特征值
$ _i $ 和单位正交特征向量 $ _i $ 。<br>
</li>
<li><strong>选择主成分</strong>：按特征值大小排序，选择前 $ d’ $
个最大特征值对应的特征向量构成变换矩阵 $ = [_1, <em>2, , </em>{d’}]
$。<br>
</li>
<li><strong>降维投影</strong>：计算低维表示 $ = ^ $，其中 $ ^{d’ m} $
。</li>
</ol>
<p><strong>（3）PCA降维后维度的确定</strong></p>
<ul>
<li><strong>累积方差贡献率</strong>：选择前 $ d’ $
个主成分，使累计方差占比达到阈值（如95%）。<br>
</li>
<li><strong>肘部法则（Elbow
Method）</strong>：绘制特征值随维度变化的曲线，选择“拐点”作为 $ d’
$。</li>
</ul>
<h5 id="section-9">2</h5>
<p>度量学习的目标是什么？LMNN算法中三元组损失是什么？如何计算？</p>
<p><strong>（1）度量学习的目标</strong></p>
<p>度量学习旨在学习一个合理的距离度量，使得： -
<strong>相似样本</strong>：距离尽可能小（如同类样本）。<br>
- <strong>不相似样本</strong>：距离尽可能大（如异类样本）。<br>
典型应用包括推荐系统（优化用户-商品相似性）、图像检索（提升匹配精度）和生物识别（增强类间可分性）。</p>
<p><strong>（2）LMNN中的三元组损失</strong></p>
<p>LMNN（Large Margin Nearest
Neighbor）是一种监督度量学习方法，其核心思想是通过优化距离度量来提升KNN的分类性能。虽然LMNN本身主要使用对比损失（Contrastive
Loss），但三元组损失（Triplet
Loss）是深度度量学习中常见的损失函数，其计算方式如下：<strong>三元组损失的定义</strong></p>
<p>三元组损失基于锚点（Anchor）、正例（Positive）和负例（Negative）三个样本，目标是使锚点与正例的距离小于锚点与负例的距离，公式为：
<span class="math display">ℒ = ∑<sub><em>i</em>, <em>j</em>, <em>l</em></sub>max (0, ∥<strong>z</strong><sub><em>i</em></sub> − <strong>z</strong><sub><em>j</em></sub>∥<sup>2</sup>−∥<strong>z</strong><sub><em>i</em></sub> − <strong>z</strong><sub><em>l</em></sub>∥<sup>2</sup> + <em>m</em>)</span>
- $ _i $：锚点样本的嵌入表示。<br>
- $ _j $：与锚点同类的正例样本。<br>
- $ _l $：与锚点不同类的负例样本。<br>
- $ m $：预设的边界值（Margin），控制正负样本距离的最小差距 。</p>
<p><strong>LMNN的损失函数</strong></p>
<p>LMNN 的损失函数包含两部分： 1. <strong>拉力损失（Pull
Loss）</strong>：最小化同类样本对的距离：<br>
<span class="math display">$$
   \varepsilon_{\text{pull}} = \sum_{i,j \sim i}
\|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2
   $$</span> 2. <strong>推力损失（Push
Loss）</strong>：最大化异类样本对的距离：<br>
<span class="math display">$$
   \varepsilon_{\text{push}} = \sum_{i,j \sim i,l} (1 - y_{il}) \left[1
+ \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2 -
\|\mathbf{L}(\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_l)\|^2\right]_+
   $$</span> 其中 $ $ 是线性变换矩阵，$ y_{il} $ 表示样本对是否同类，$
[]_+ $ 表示取正值部分 。</p>
<p><strong>优化目标</strong></p>
<p>LMNN 的总损失为拉力和推力损失的加权和： <span class="math display"><em>ε</em>(<strong>L</strong>) = (1 − <em>μ</em>)<em>ε</em><sub>pull</sub> + <em>μ</em><em>ε</em><sub>push</sub></span>
参数 $ $ 平衡两类损失的权重，最终通过优化 $ $ 得到最优距离度量 。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607175825520.png" alt="image-20250607175825520">
<figcaption aria-hidden="true">image-20250607175825520</figcaption>
</figure>
<h3 id="半监督学习">半监督学习</h3>
<p>监督学习解决现实问题有哪些难点?
1.标记数据获取成本高：在许多领域如医疗，获取标记数据是昂贵且耗时的。
2.未标记数据大量存在且易得：相对而言，未标记数据大量存在且容易获取。
3.提升模型的泛化能力：通过利用未标记数据，可以增强模型的泛化能力。
举例：在医疗领域，获取医生标记的诊断数据非常昂贵，但有大量未标记的病人记录。
半监督学习可以帮助利用这些未标记数据，提高疾病预测模型的准确性。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607181345721.png" alt="image-20250607181345721">半监督学习结合了有监督学习和无监督学习，半监督学习使用<strong>少量的标记数据</strong>和<strong>大量的未标记数据</strong>来训练模型，主要目标是提升模型在未标记数据上的表现。</p>
<h5 id="基于生成模型的方法">基于生成模型的方法</h5>
<p>假设所有数据（无论是否有标记）都是由一个<strong>潜在的模型</strong>“生成”的。那么无标记的数据可以帮助更准确的估计潜在模型的参数。
比如右图中可以看到数据可以由两个高斯分布近似，则无监督的数据可以被用来更好得做高斯分布的参数估计</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183201926.png" alt="image-20250607183201926">
<figcaption aria-hidden="true">image-20250607183201926</figcaption>
</figure>
<h5 id="半监督svm"><strong>半监督SVM</strong></h5>
<p>监督学习中的SVM试图找到一个划分超平面，使得两侧支持向量之间的间隔最大，即
<strong>最大划分间隔</strong> 思想。对于半监督SVM (Semi-Supervised
Support Vector Machine, S3VM)
则考虑超平面在能将两类标记样本分隔的同时，<strong>穿过数据低密度的区域</strong>。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183349866.png" alt="image-20250607183349866">
<figcaption aria-hidden="true">image-20250607183349866</figcaption>
</figure>
<h6 id="tsvmtransductive-support-vector-machine">TSVM(Transductive
Support Vector Machine)</h6>
<p><strong>1. 核心思想</strong></p>
<p>TSVM 是一种<strong>半监督学习方法</strong>，通过结合有标记数据 $ D_l
$ 和未标记数据 $ D_u
$，利用伪标签（Pseudo-labels）和迭代优化策略，最大化分类超平面的间隔。其损失函数需同时考虑：
- <strong>有标记样本</strong>：最小化分类错误（Hinge Loss）。<br>
- <strong>未标记样本</strong>：通过伪标签引入约束，逐步调整超平面。</p>
<p><strong>2. 损失函数推导</strong></p>
<p>TSVM 的目标是找到一个超平面 $ ^ + b = 0 $，使得： 1.
<strong>有标记样本</strong>的分类误差最小。<br>
2. <strong>未标记样本</strong>的伪标签与超平面预测结果一致。</p>
<p><strong>标准SVM的损失函数</strong>为： <span class="math display">$$
\min_{\boldsymbol{w}, b, \xi} \quad \frac{1}{2} \|\boldsymbol{w}\|^2 + C
\sum_{i=1}^l \xi_i
$$</span> 其中，$ _i $ 是松弛变量，表示样本 $ (_i, y_i) $
的分类误差。</p>
<p><strong>TSVM的扩展</strong>：<br>
引入未标记样本 $ D_u $ 的伪标签 $ <em>j <span class="math inline">（</span> j = l+1, , l+u $），并赋予其较小的惩罚系数
$ C_u $（初始阶段 $ C_u C_l <span class="math inline">）：</span>$
</em>{, b, } ||^2 + C_l _{i=1}^l <em>i + C_u </em>{j=l+1}^{l+u} _j $$
其中： - $ C_l $：有标记样本的惩罚系数。<br>
- $ C_u
$：未标记样本的惩罚系数，初始值很小，逐步增大以增强伪标签的影响。</p>
<p><strong>3. 迭代优化流程</strong></p>
<ol type="1">
<li><strong>初始化</strong>：
<ul>
<li>用有标记数据 $ D_l $ 训练初始 SVM，得到 $ _0, b_0 $。<br>
</li>
<li>对未标记数据 $ D_u $ 预测伪标签 $ _j = (_0^_j + b_0) $。</li>
</ul></li>
<li><strong>伪标签调整</strong>：
<ul>
<li>若存在冲突（如 $ _i _j &lt; 0 $ 且 $ _i + _j &gt; 2
$），翻转其中一个伪标签（如 $ _i -_i $）。<br>
</li>
<li>重新求解优化问题，更新 $ , b $。</li>
</ul></li>
<li><strong>参数调整</strong>：
<ul>
<li>逐步增大 $ C_u $（如 $ C_u {2C_u, C_l}
$），增强未标记样本的影响。</li>
</ul></li>
</ol>
<p><strong>4. 关键数学细节</strong></p>
<ul>
<li><p><strong>Hinge Loss</strong>：<br>
对每个样本 $ (_i, y_i) <span class="math inline">，<em>损</em><em>失</em><em>为</em>：</span>$ _i =
(0, 1 - y_i (^_i + b)) $$ 未标记样本的伪标签 $ _j $
同样代入此公式，但惩罚系数为 $ C_u $。</p></li>
<li><p><strong>正则化项</strong>：<br>
$ ||^2 $ 确保超平面的泛化能力，防止过拟合。</p></li>
<li><p><strong>伪标签翻转条件</strong>：<br>
当两个未标记样本 $ i, j $ 满足： <span class="math display"><em>ŷ</em><sub><em>i</em></sub><em>ŷ</em><sub><em>j</em></sub> &lt; 0  且  <em>ξ</em><sub><em>i</em></sub> &gt; 0, <em>ξ</em><sub><em>j</em></sub> &gt; 0,  <em>ξ</em><sub><em>i</em></sub> + <em>ξ</em><sub><em>j</em></sub> &gt; 2</span>
表示它们被错误分类且距离超平面较近，需翻转其中一个标签以减少冲突。</p></li>
</ul>
<h5 id="图半监督学习"><strong>图半监督学习</strong></h5>
<p>给定一个数据集，我们可将其映射为一个图，数据集中每个样本对应于图结点，若两个样本之间的相似度很高(或相关性很强)，则对应的结点之间存在一条边，边的“强度”(strength)
正比于样本之间的相似度(或相关性)。</p>
<p>可将有标记样本所对应的结点想象为染过色，标记样本所对应的结点尚未染色。半监督学习就对应于“颜色”在图上扩散或传播的过程。由于个图对应了一个矩阵，我们就能基于矩阵运算来进行半监督学习算法的推导与分析。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607184534217.png" alt="image-20250607184534217">
<figcaption aria-hidden="true">image-20250607184534217</figcaption>
</figure>
<p><strong>图半监督学习中的能量函数推导详解</strong></p>
<p><strong>1. 图结构与亲和矩阵</strong></p>
<p>给定有标记数据集 $ D_l = {(<em>1, y_1), (<em>2, y_2), , (<em>l, y_l)}
$ 和未标记数据集 $ D_u = {</em>{l+1}, </em>{l+2}, , </em>{l+u}}
$，构建图 $ G = (V, E) <span class="math inline">： − * * <em>结</em><em>点</em><em>集</em> * *：</span>
V = {<em>1, , <em>l, </em>{l+1}, , </em>{l+u}} $，包含所有样本。<br>
- <strong>边集</strong>：通过亲和矩阵 $ $ 表示，元素定义为： <span class="math display">$$
  (\mathbf{W})_{ij} =
  \begin{cases}
  \exp\left(-\frac{\|\boldsymbol{x}_i -
\boldsymbol{x}_j\|^2}{2\sigma^2}\right), &amp; i \neq j \\
  0, &amp; \text{otherwise}
  \end{cases}
  $$</span> 其中，$ $ 是高斯核的带宽参数，控制邻接关系的敏感性。</p>
<p><strong>2. 能量函数的定义与推导</strong></p>
<p>假设分类模型的输出标记为 $ f(_i) $（取值为类别标签，如 $
$），定义能量函数 $ E(f) $ 为： <span class="math display">$$
E(f) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij}
(f(\boldsymbol{x}_i) - f(\boldsymbol{x}_j))^2
$$</span> 其中 $ m = l + u $ 是总样本数。</p>
<p><strong>3. 能量函数的展开与简化</strong></p>
<ol type="1">
<li><strong>展开平方项</strong> <span class="math display">$$
E(f) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} \left[
f^2(\boldsymbol{x}_i) - 2 f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) +
f^2(\boldsymbol{x}_j) \right]
$$</span></li>
<li><strong>利用对称性简化</strong> 由于 $ $ 是对称矩阵（<span class="math inline">(<strong>W</strong>)<sub><em>i</em><em>j</em></sub> = (<strong>W</strong>)<sub><em>j</em><em>i</em></sub></span>），可交换求和顺序：
<span class="math display">$$
\sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_j) =
\sum_{j=1}^m \sum_{i=1}^m (\mathbf{W})_{ji} f^2(\boldsymbol{x}_j) =
\sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_i)
$$</span> 因此，能量函数变为 <span class="math display">$$
E(f) = \frac{1}{2} \left( 2 \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij}
f^2(\boldsymbol{x}_i) - 2 \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij}
f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) \right)
$$</span></li>
<li><strong>引入度矩阵</strong> 定义度矩阵 $ $
为对角矩阵，其对角线元素为： <span class="math display">$$
d_i = \sum_{j=1}^m (\mathbf{W})_{ij}
$$</span> 最终能量函数可表示为： <span class="math display">$$
E(f) = \sum_{i=1}^m d_i f^2(\boldsymbol{x}_i) - \sum_{i=1}^m
\sum_{j=1}^m (\mathbf{W})_{ij} f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) =
\boldsymbol{f}^\top (\mathbf{D} - \mathbf{W}) \boldsymbol{f}
$$</span> 其中，$ = [f(_1), f(_2), , f(_m)]^$。</li>
</ol>
<p><strong>图半监督学习方法推导详解</strong></p>
<p><strong>1. 分块矩阵表示</strong></p>
<p>将亲和矩阵 $ $ 和度矩阵 $ $ 按有标记数据（前 $ l $
行列）和未标记数据（后 $ u $ 行列）分块： <span class="math display">$$
\mathbf{W} =
\begin{bmatrix}
\mathbf{W}_{ll} &amp; \mathbf{W}_{lu} \\
\mathbf{W}_{ul} &amp; \mathbf{W}_{uu}
\end{bmatrix}, \quad
\mathbf{D} =
\begin{bmatrix}
\mathbf{D}_{ll} &amp; \mathbf{0}_{lu} \\
\mathbf{0}_{ul} &amp; \mathbf{D}_{uu}
\end{bmatrix}
$$</span> 其中： - $ <em>{ll} $：有标记数据间的亲和度。<br>
- $ </em>{lu} $：有标记与未标记数据间的亲和度。<br>
- $ <em>{uu} $：未标记数据间的亲和度。<br>
- $ </em>{ll}, _{uu} $：对应子图的度矩阵。</p>
<p><strong>2. 能量函数的分块展开</strong></p>
<p>能量函数 $ E(f) = ^( - ) $ 可展开为</p>
<p>展开后得到： <span class="math display"><em>E</em>(<em>f</em>) = <strong>f</strong><sub><em>l</em></sub><sup>⊤</sup>(<strong>D</strong><sub><em>l</em><em>l</em></sub> − <strong>W</strong><sub><em>l</em><em>l</em></sub>)<strong>f</strong><sub><em>l</em></sub> − 2<strong>f</strong><sub><em>u</em></sub><sup>⊤</sup><strong>W</strong><sub><em>u</em><em>l</em></sub><strong>f</strong><sub><em>l</em></sub> + <strong>f</strong><sub><em>u</em></sub><sup>⊤</sup>(<strong>D</strong><sub><em>u</em><em>u</em></sub> − <strong>W</strong><sub><em>u</em><em>u</em></sub>)<strong>f</strong><sub><em>u</em></sub></span></p>
<p>**3. 对未标记数据 $ _u $ 求偏微分**</p>
<p>目标是最小化 $ E(f) $，对 $ _u $ 求偏导并令其为零： <span class="math display">$$
\frac{\partial E(f)}{\partial \boldsymbol{f}_u} = -2 \mathbf{W}_{ul}
\boldsymbol{f}_l + 2 (\mathbf{D}_{uu} - \mathbf{W}_{uu})
\boldsymbol{f}_u = 0
$$</span> 解得： <span class="math display"><strong>f</strong><sub><em>u</em></sub> = (<strong>D</strong><sub><em>u</em><em>u</em></sub> − <strong>W</strong><sub><em>u</em><em>u</em></sub>)<sup>−1</sup><strong>W</strong><sub><em>u</em><em>l</em></sub><strong>f</strong><sub><em>l</em></sub></span></p>
<h4 id="协同训练">协同训练</h4>
<p>协同训练（Co-training）是一种经典的<strong>半监督学习方法</strong>，由Blum和Mitchell于1998年首次提出，主要用于处理<strong>多视图数据</strong>（Multi-view
Data）。其核心思想是通过多个分类器的协作，利用少量标记数据和大量未标记数据提升模型性能。以下是详细解析：</p>
<p><strong>1. 核心思想与假设</strong></p>
<p><strong>（1）多视图数据</strong></p>
<ul>
<li><strong>定义</strong>：每个样本可被划分为多个<strong>充分冗余且条件独立</strong>的视图（View）。
<ul>
<li><strong>充分冗余</strong>：每个视图本身包含足够信息，可独立完成学习任务。<br>
</li>
<li><strong>条件独立性</strong>：在给定类别标签的条件下，不同视图的特征相互独立。<br>
例如，网页数据可划分为“文本内容”和“超链接结构”两个视图，它们共同描述网页内容。</li>
</ul></li>
</ul>
<p><strong>（2）协作机制</strong></p>
<ul>
<li><strong>双分类器设计</strong>：使用两个分类器 $ h_1 $ 和 $ h_2
$，分别基于视图 $ V_1 $ 和 $ V_2 $ 进行训练。<br>
</li>
<li><strong>伪标签生成</strong>：分类器 $ h_1 $
对未标记数据的高置信度预测结果会被 $ h_2 $
使用，反之亦然，形成迭代优化。<br>
</li>
<li><strong>目标</strong>：通过分类器间的互补性，逐步扩展标记数据集，提升模型泛化能力。</li>
</ul>
<p><strong>2. 算法流程</strong></p>
<ol type="1">
<li><strong>初始化阶段</strong>：
<ul>
<li>使用少量标记数据 $ D_l $，分别训练分类器 $ h_1 $（基于视图 $ V_1
$）和 $ h_2 $（基于视图 $ V_2 $）。<br>
</li>
</ul></li>
<li><strong>伪标签生成</strong>：
<ul>
<li>对未标记数据 $ D_u <span class="math inline">，</span> h_1 $
预测视图 $ V_1 $ 的伪标签，$ h_2 $ 预测视图 $ V_2 $ 的伪标签。<br>
</li>
<li>选择置信度高于阈值的样本加入训练集（如 $ h_1 $ 的预测结果用于更新 $
h_2 $ 的训练数据，反之亦然）。<br>
</li>
</ul></li>
<li><strong>迭代优化</strong>：
<ul>
<li>重复伪标签生成和模型训练，直到未标记数据耗尽或模型收敛。</li>
</ul></li>
</ol>
<p><strong>3. 核心优势</strong></p>
<ul>
<li><strong>减少对标注数据的依赖</strong>：仅需少量标记数据即可训练高性能模型，尤其适合标注成本高的场景（如医疗影像分析）。<br>
</li>
<li><strong>提升模型鲁棒性</strong>：分类器间的协作可纠正彼此的错误，降低单一模型过拟合风险。<br>
</li>
<li><strong>多视图互补性</strong>：不同视图的信息融合能捕捉更全面的特征（如图像的RGB通道与纹理特征）。</li>
</ul>
<h4 id="作业-4">作业</h4>
<h5 id="section-10">1</h5>
<p>什么是半监督学习？请简要描述其基本思想。半监督学习相比于监督学习和无监督学习有什么优势和应用场景？</p>
<p><strong>（1）定义与基本思想</strong></p>
<p>半监督学习（Semi-Supervised
Learning）是结合<strong>监督学习</strong>（利用标记数据）和<strong>无监督学习</strong>（利用未标记数据）的机器学习方法，其核心思想是通过少量标记数据与大量未标记数据的联合训练，提升模型的泛化能力和鲁棒性。<br>
-
<strong>监督学习</strong>：依赖大量人工标注数据（如分类、回归）。<br>
-
<strong>无监督学习</strong>：仅利用数据分布规律（如聚类、降维）。<br>
-
<strong>半监督学习</strong>：在标记数据稀缺时，通过未标记数据挖掘潜在结构，降低标注成本
。</p>
<p><strong>（2）优势</strong></p>
<ul>
<li><strong>减少标注依赖</strong>：仅需少量标记数据即可训练高性能模型，适用于标注成本高的场景（如医疗影像分析）。<br>
</li>
<li><strong>提升模型性能</strong>：利用未标记数据增强数据多样性，缓解过拟合风险。<br>
</li>
<li><strong>平衡效率与精度</strong>：在资源有限时，兼顾监督学习的准确性与无监督学习的高效性
。</li>
</ul>
<p><strong>（3）应用场景</strong></p>
<ul>
<li><strong>医学诊断</strong>：利用少量标注的病理图像和大量未标注数据训练疾病预测模型。<br>
</li>
<li><strong>推荐系统</strong>：结合用户行为（有标记）与商品属性（未标记）优化排序模型。<br>
</li>
<li><strong>自然语言处理</strong>：通过预训练模型（如GPT）的“预训练+微调”框架，减少人工标注需求
。</li>
</ul>
<h5 id="section-11">2</h5>
<p>协同训练算法的作用是什么？请简述算法主要流程和所需条件。</p>
<p><strong>（1）作用与核心思想</strong></p>
<p>协同训练是一种典型的半监督学习方法，适用于<strong>多视图数据</strong>（Multi-view
Data）。其核心思想是通过多个分类器的协作，利用未标记数据扩展训练集，最终提升模型性能。</p>
<ul>
<li><strong>多视图条件</strong>：
<ul>
<li><strong>充分冗余</strong>：每个视图本身包含足够信息，可独立完成任务。<br>
</li>
<li><strong>条件独立性</strong>：在给定类别标签的条件下，不同视图的特征相互独立
。</li>
</ul></li>
</ul>
<p><strong>（2）算法流程</strong></p>
<ol type="1">
<li><strong>初始化阶段</strong>：
<ul>
<li>使用少量标记数据 $ D_l $，分别训练两个分类器 $ h_1 $（基于视图 $ V_1
$）和 $ h_2 $（基于视图 $ V_2 $）。<br>
</li>
</ul></li>
<li><strong>伪标签生成</strong>：
<ul>
<li>对未标记数据 $ D_u <span class="math inline">，</span> h_1 $ 预测 $
V_2 $ 的伪标签，$ h_2 $ 预测 $ V_1 $ 的伪标签。<br>
</li>
<li>选择置信度高于阈值的样本加入训练集（如 $ h_1 $ 的预测结果用于更新 $
h_2 $ 的训练数据，反之亦然）。<br>
</li>
</ul></li>
<li><strong>迭代优化</strong>：
<ul>
<li>重复伪标签生成和模型训练，直到未标记数据耗尽或模型收敛 。</li>
</ul></li>
</ol>
<p><strong>（3）所需条件</strong></p>
<ul>
<li><strong>多视图划分</strong>：数据需满足“充分冗余”和“条件独立性”（如图像的RGB通道与纹理特征）。<br>
</li>
<li><strong>分类器多样性</strong>：选择差异较大的分类器（如SVM +
决策树），增强互补性。<br>
</li>
<li><strong>伪标签可靠性</strong>：初始模型需有一定性能，避免错误伪标签污染训练集
。</li>
</ul>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——上机作业3</title>
    <url>/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A3/</url>
    <content><![CDATA[<p>以下是针对表1和表2中所有函数的实现和验证分析，严格按照约束条件和操作符数量限制设计：</p>
<hr>
<h3 id="表1-位操作函数实现"><strong>表1 位操作函数实现</strong></h3>
<h4 id="lsbzero-将x的最低有效位清零"><strong>1. lsbZero
(将x的最低有效位清零)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">lsbZero</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> x &amp; (~<span class="number">1</span>);  <span class="comment">// 操作符: &amp; ~ 1 (共3个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x = 0x05 (0b101)</code> → <code>0x04 (0b100)</code></p>
<hr>
<h4 id="bytenot-将x的第n个字节取反"><strong>2. byteNot
(将x的第n个字节取反)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">byteNot</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = <span class="number">0xFF</span> &lt;&lt; (n &lt;&lt; <span class="number">3</span>);  <span class="comment">// 构造字节掩码</span></span><br><span class="line">    <span class="keyword">return</span> x ^ mask;               <span class="comment">// 操作符: &lt;&lt; &lt;&lt; 3 &lt;&lt; 8 (共6个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x = 0x12345678, n=1</code> → <code>0x1234A978</code>（第1字节
<code>0x56</code> 取反为 <code>0xA9</code>）</p>
<hr>
<h4 id="bytexor-比较x和y的第n个字节"><strong>3. byteXor
(比较x和y的第n个字节)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">byteXor</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> shift = n &lt;&lt; <span class="number">3</span>;</span><br><span class="line">    <span class="type">int</span> x_byte = (x &gt;&gt; shift) &amp; <span class="number">0xFF</span>;</span><br><span class="line">    <span class="type">int</span> y_byte = (y &gt;&gt; shift) &amp; <span class="number">0xFF</span>;</span><br><span class="line">    <span class="keyword">return</span> !!(x_byte ^ y_byte);  <span class="comment">// 操作符: &lt;&lt; &gt;&gt; &amp; ^ !! (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0x12345678, y=0x12745678, n=2</code> → <code>1</code>（第2字节
<code>0x34</code> vs <code>0x74</code>）</p>
<hr>
<h4 id="logicaland-模拟x-y"><strong>4. logicalAnd (模拟x &amp;&amp;
y)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">logicalAnd</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (!!x) &amp; (!!y);  <span class="comment">// 操作符: !! &amp; (共2个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0, y=5</code> → <code>0</code>；<code>x=1, y=2</code> →
<code>1</code></p>
<hr>
<h4 id="logicalor-模拟x-y"><strong>5. logicalOr (模拟x ||
y)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">logicalOr</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (!!x) | (!!y);  <span class="comment">// 操作符: !! | (共2个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0, y=0</code> → <code>0</code>；<code>x=0, y=1</code> →
<code>1</code></p>
<hr>
<h4 id="rotateleft-循环左移n位"><strong>6. rotateLeft
(循环左移n位)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">rotateLeft</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = (<span class="number">0xFF</span> &lt;&lt; <span class="number">24</span>) &gt;&gt; (<span class="number">32</span> - n);  <span class="comment">// 构造高位掩码</span></span><br><span class="line">    <span class="keyword">return</span> (x &lt;&lt; n) | ((x &gt;&gt; (<span class="number">32</span> - n)) &amp; mask);  <span class="comment">// 操作符: &lt;&lt; &gt;&gt; | &amp; (共25个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0x12345678, n=4</code> →
<code>0x23456781</code>（左移4位，高位循环到低位）</p>
<hr>
<h4 id="paritycheck-奇偶校验"><strong>7. parityCheck
(奇偶校验)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">parityCheck</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">16</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">8</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">4</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">2</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> x &amp; <span class="number">1</span>;  <span class="comment">// 操作符: ^ &gt;&gt; &amp; (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0b1010</code> →
<code>0</code>（2个1，偶数）；<code>x=0b101</code> →
<code>1</code>（奇数）</p>
<hr>
<h3 id="表2-补码运算函数实现"><strong>表2 补码运算函数实现</strong></h3>
<h4 id="mul2ok-判断2x是否溢出">**8. mul2OK (判断2*x是否溢出)**</h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mul2OK</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> sign = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> result = x &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> !(((result &gt;&gt; <span class="number">31</span>) ^ sign) &amp; (!!(x ^ (x &lt;&lt; <span class="number">1</span>))));  <span class="comment">// 操作符: &gt;&gt; &lt;&lt; ^ &amp; !! (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0x40000000</code> →
<code>0</code>（溢出）；<code>x=0x3FFFFFFF</code> → <code>1</code></p>
<hr>
<h4 id="mult3div2-计算x32">**9. mult3div2 (计算(x*3)/2)**</h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mult3div2</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> temp = x + x + x;</span><br><span class="line">    <span class="type">int</span> sign = temp &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> (temp + (temp &gt;&gt; <span class="number">31</span> &amp; <span class="number">1</span>)) &gt;&gt; <span class="number">1</span>;  <span class="comment">// 操作符: + &gt;&gt; &amp; (共12个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=-3</code> → <code>(-9)/2 = -4</code>（向零取整）</p>
<hr>
<h4 id="subok-判断x---y是否溢出"><strong>10. subOK (判断x -
y是否溢出)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">subOK</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="type">int</span> sub = x + (~y + <span class="number">1</span>);</span><br><span class="line">    <span class="type">int</span> x_sign = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> y_sign = (~y + <span class="number">1</span>) &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> sub_sign = sub &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> !((~(x_sign ^ y_sign)) &amp; (x_sign ^ sub_sign));  <span class="comment">// 操作符: ~ ^ + &gt;&gt; &amp; (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0x80000000, y=1</code> → <code>0</code>（溢出）</p>
<hr>
<h4 id="absval-求绝对值"><strong>11. absVal (求绝对值)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">absVal</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> (x + mask) ^ mask;  <span class="comment">// 操作符: &gt;&gt; + ^ (共10个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=-5</code> → <code>5</code>；<code>x=3</code> →
<code>3</code></p>
<hr>
<h3 id="验证方法"><strong>验证方法</strong></h3>
<ol type="1">
<li><strong>编写测试代码</strong>：为每个函数设计边界值（如0、最大值、最小值）。</li>
<li><strong>反汇编分析</strong>：使用 <code>objdump -d</code>
检查生成的机器码是否符合操作符限制。</li>
<li><strong>覆盖率测试</strong>：确保所有分支条件被触发（如正负数、溢出情况）。</li>
</ol>
<hr>
<h3 id="关键技巧"><strong>关键技巧</strong></h3>
<ul>
<li><strong>位掩码</strong>：使用
<code>0xFF</code>、<code>0x80000000</code> 等构造特定模式。</li>
<li><strong>符号位操作</strong>：通过 <code>x &gt;&gt; 31</code>
提取符号位。</li>
<li><strong>逻辑运算替代</strong>：用 <code>!!x</code>
将非零值转换为1，用 <code>x ^ (x &gt;&gt; 31)</code> 处理绝对值。</li>
</ul>
<p>如果需要具体函数的详细推导或测试用例，可进一步说明！</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——上机作业2</title>
    <url>/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A2/</url>
    <content><![CDATA[<h3 id="实验1变量输出与机器数分析"><strong>实验1：变量输出与机器数分析</strong></h3>
<h4 id="运行代码并分析输出"><strong>1.1 运行代码并分析输出</strong></h4>
<p><strong>源代码</strong>： <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> x = <span class="number">-1</span>;</span><br><span class="line">    <span class="type">unsigned</span> u = <span class="number">2147483648</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x = %u = %d.\n&quot;</span>, x, x);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;u = %u = %d.\n&quot;</span>, u, u);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>编译与运行</strong>： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -o test1 test1.c</span><br><span class="line">./test1</span><br></pre></td></tr></table></figure></p>
<p><strong>输出结果</strong>（假设32位系统）： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x = 4294967295 = -1.</span><br><span class="line">u = 2147483648 = -2147483648.</span><br></pre></td></tr></table></figure></p>
<p><strong>结果分析</strong>： -
<strong><code>x = %u</code></strong>：<br>
<code>x</code> 是 <code>int</code> 类型的 <code>-1</code>，二进制补码为
<code>0xFFFFFFFF</code>。用
<code>%u</code>（无符号）解释时，<code>0xFFFFFFFF</code> 对应
<code>4294967295</code>。 - <strong><code>x = %d</code></strong>：<br>
正常输出 <code>-1</code>。 -
<strong><code>u = %u</code></strong>：<br>
<code>u</code> 是 <code>unsigned</code> 类型的
<code>2147483648</code>（即 <code>0x80000000</code>），直接输出为
<code>2147483648</code>。 - <strong><code>u = %d</code></strong>：<br>
用 <code>%d</code>（有符号）解释
<code>0x80000000</code>，最高位为1，表示负数，结果为
<code>-2147483648</code>。</p>
<hr>
<h4 id="反汇编分析机器数"><strong>1.2 反汇编分析机器数</strong></h4>
<p><strong>步骤</strong>： 1. 生成目标文件： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -c test1.c -o test1.o</span><br></pre></td></tr></table></figure> 2.
反汇编查看变量赋值： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">objdump -d -M intel test1.o</span><br></pre></td></tr></table></figure></p>
<p><strong>关键汇编代码</strong>（简化）： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov DWORD PTR [rbp-4], 0xffffffff   ; x = -1 (机器数 0xFFFFFFFF)</span><br><span class="line">mov DWORD PTR [rbp-8], 0x80000000   ; u = 2147483648 (机器数 0x80000000)</span><br></pre></td></tr></table></figure></p>
<p><strong>变量机器数总结</strong>： | 变量 | 机器数（十六进制） | | —-
| —————— | | x | 0xFFFFFFFF | | u | 0x80000000 |</p>
<hr>
<h3 id="实验2表达式结果与反汇编分析"><strong>实验2：表达式结果与反汇编分析</strong></h3>
<h4 id="验证表达式结果"><strong>2.1 验证表达式结果</strong></h4>
<p><strong>源代码</strong>： <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;-1 &lt; 0\t\t -&gt; %d\n&quot;</span>, (<span class="number">-1</span> &lt; <span class="number">0</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;-1 &lt; 0U\t -&gt; %d\n&quot;</span>, (<span class="number">-1</span> &lt; <span class="number">0U</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;2147483647 &gt; -2147483647 - 1\t -&gt; %d\n&quot;</span>, (<span class="number">2147483647</span> &gt; <span class="number">-2147483647</span> - <span class="number">1</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;2147483647U &gt; -2147483647 - 1\t -&gt; %d\n&quot;</span>, (<span class="number">2147483647U</span> &gt; <span class="number">-2147483647</span> - <span class="number">1</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>编译与运行</strong>： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -o test2 test2.c</span><br><span class="line">./test2</span><br></pre></td></tr></table></figure></p>
<p><strong>输出结果</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-1 &lt; 0           -&gt; 1</span><br><span class="line">-1 &lt; 0U          -&gt; 0</span><br><span class="line">2147483647 &gt; -2147483647 - 1  -&gt; 1</span><br><span class="line">2147483647U &gt; -2147483647 - 1 -&gt; 0</span><br></pre></td></tr></table></figure></p>
<p><strong>结果分析</strong>： 1.
<strong><code>-1 &lt; 0</code></strong>：<br>
有符号比较，<code>-1</code> 小于
<code>0</code>，结果为真（<code>1</code>）。 2.
<strong><code>-1 &lt; 0U</code></strong>：<br>
<code>0U</code> 是无符号，<code>-1</code> 被转换为无符号数
<code>0xFFFFFFFF</code>（4294967295），远大于
<code>0U</code>，结果为假（<code>0</code>）。 3.
<strong><code>2147483647 &gt; -2147483647 - 1</code></strong>：<br>
右侧表达式 <code>-2147483647 - 1</code> 等于
<code>-2147483648</code>（<code>INT_MIN</code>），有符号比较，<code>2147483647</code>（<code>INT_MAX</code>）大于
<code>INT_MIN</code>，结果为真（<code>1</code>）。 4.
<strong><code>2147483647U &gt; -2147483647 - 1</code></strong>：<br>
左侧是无符号，右侧 <code>INT_MIN</code> 被转换为无符号数
<code>0x80000000</code>（2147483648），比较 <code>2147483647</code> 和
<code>2147483648</code>，结果为假（<code>0</code>）。</p>
<hr>
<h4 id="反汇编分析表达式"><strong>2.2 反汇编分析表达式</strong></h4>
<p><strong>步骤</strong>： 1. 生成目标文件： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -c test2.c -o test2.o</span><br></pre></td></tr></table></figure> 2.
反汇编查看比较指令： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">objdump -d -M intel test2.o</span><br></pre></td></tr></table></figure></p>
<p><strong>关键汇编代码</strong>（以 <code>-1 &lt; 0U</code> 为例）：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov DWORD PTR [rbp-4], 0xffffffff   ; -1 的机器数</span><br><span class="line">cmp DWORD PTR [rbp-4], 0            ; 比较时，-1 被视为无符号数 4294967295</span><br><span class="line">setb al                             ; 设置结果（0 表示假）</span><br></pre></td></tr></table></figure></p>
<p><strong>总结</strong>： - 类型转换规则决定了比较结果。 -
反汇编显示编译器如何处理有符号与无符号的隐式转换。</p>
<hr>
<h3 id="实验报告建议"><strong>实验报告建议</strong></h3>
<ol type="1">
<li><strong>源代码与输出结果</strong>：附上代码及运行结果。</li>
<li><strong>反汇编截图</strong>：展示变量赋值和表达式比较的汇编代码。</li>
<li><strong>分析</strong>：
<ul>
<li>解释类型转换对输出的影响。</li>
<li>说明反汇编中机器数与表达式比较的底层实现。</li>
</ul></li>
</ol>
<p>如果需要更详细的反汇编代码或具体步骤解释，请随时告知！</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——中缀表达式</title>
    <url>/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E4%B8%AD%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="数据结构中缀表达式">数据结构——中缀表达式</h1>
<h2 id="利用中缀表达式直接求值">利用中缀表达式直接求值</h2>
<p>要实现中缀表达式直接求值，必须设置两个栈，一个栈用于存放操作数，记作
<code>OPND</code>； 另一个栈用于存放操作符，记作 <code>OPTR</code>。</p>
<p>中缀表达式求值算法步骤如下：</p>
<ol type="1">
<li>初始化：操作符栈中放置一个元素 <code>@</code>。</li>
<li>依次读取中缀表达式中的每一个字符，对于不同类型的字符按以下情况处理：
<ol type="1">
<li>若读到的是操作数，则压入操作数栈，并读取下一个字符。</li>
<li>若读到的是操作符 <code>c</code>，则将操作符栈的栈顶元素
<code>pre_op</code>与之进行比较，会出现以下 3 种情况：
<ul>
<li>若 <code>pre_op &lt; c</code>，则将 <code>c</code>
入栈，并读取下一个字符。</li>
<li>若 <code>pre_op = c</code>，则将 <code>pre_op</code>
出栈，并读取下一个字符。</li>
<li>若 <code>pre_op &gt; c</code>，则将 <code>pre_op</code>
出栈，并在操作数栈中退栈 2 次，依次得到操作数 <code>b</code> 和
<code>a</code>，然后进行 <code>a pre_op b</code>
运算，将运算结果压入操作数栈。</li>
</ul></li>
</ol></li>
<li>扫描完毕时，操作数栈中只有一个元素，即计算结果。</li>
</ol>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E4%B8%AD%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/IMG_20241026_164151.jpg" alt="IMG_20241026_164151">
<figcaption aria-hidden="true">IMG_20241026_164151</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//中缀表达式，实数</span></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">Expression_Eval2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	SeqStack&lt;<span class="type">char</span>, <span class="number">100</span>&gt; OPTR;</span><br><span class="line">	SeqStack&lt;<span class="type">double</span>, <span class="number">100</span>&gt; OPND;</span><br><span class="line">	OPTR.<span class="built_in">Push</span>(<span class="string">&#x27;@&#x27;</span>);</span><br><span class="line">	<span class="type">char</span> ch = <span class="built_in">getchar</span>();</span><br><span class="line">	<span class="keyword">while</span> (ch != <span class="string">&#x27;@&#x27;</span> || OPTR.<span class="built_in">Top</span>() != <span class="string">&#x27;@&#x27;</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (<span class="built_in">isdigit</span>(ch) || ch == <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">// 处理多位数和小数</span></span><br><span class="line">			string number;</span><br><span class="line">			<span class="keyword">while</span> (<span class="built_in">isdigit</span>(ch) || ch == <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">			&#123;</span><br><span class="line">				number += ch;</span><br><span class="line">				ch = <span class="built_in">getchar</span>();</span><br><span class="line">			&#125;</span><br><span class="line">			OPND.<span class="built_in">Push</span>(<span class="built_in">stod</span>(number));</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="type">char</span> pre_op = OPTR.<span class="built_in">Top</span>();</span><br><span class="line">			<span class="keyword">switch</span> (<span class="built_in">Precede</span>(pre_op, ch))</span><br><span class="line">			&#123;</span><br><span class="line">			<span class="keyword">case</span> <span class="string">&#x27;&lt;&#x27;</span>:</span><br><span class="line">				OPTR.<span class="built_in">Push</span>(ch);</span><br><span class="line">				ch = <span class="built_in">getchar</span>();</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			<span class="keyword">case</span> <span class="string">&#x27;=&#x27;</span>:</span><br><span class="line">				OPTR.<span class="built_in">Pop</span>();</span><br><span class="line">				ch = <span class="built_in">getchar</span>();</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			<span class="keyword">case</span> <span class="string">&#x27;&gt;&#x27;</span>:</span><br><span class="line">				<span class="type">char</span> pre_op = OPTR.<span class="built_in">Pop</span>();</span><br><span class="line">				<span class="type">double</span> b = OPND.<span class="built_in">Pop</span>();</span><br><span class="line">				<span class="type">double</span> a = OPND.<span class="built_in">Pop</span>();</span><br><span class="line">				OPND.<span class="built_in">Push</span>(<span class="built_in">Operate</span>(a, pre_op, b));</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> OPND.<span class="built_in">Top</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>Precede(pre_op, ch)</code>为进行算符优先级比较的函数</p>
<p><code>Operate(a, pre_op, b)</code>为计算函数</p>
<h2 id="利用后缀表达式求值">利用后缀表达式求值</h2>
<h2 id="优点">优点</h2>
<p>后缀是指把操作符放在两个操作数的后面。采用后缀表示的算术表达式被称为<strong>后缀表达式</strong>或<strong>后缀算</strong>。
在后缀表达式中，<strong>完全按照操作符出现的先后顺序进行计算过程，不存在括号，也不存在优先级的差别</strong>。</p>
<p>将中缀表达式转换成等价的后缀表达式求值时，不需要再考虑操作符的优先级，只需从左到右扫描一边后缀表达式即可。只需设置一个OPND栈用于存放操作数</p>
<h3 id="先将中缀表达式转成后缀表达式">先将中缀表达式转成后缀表达式</h3>
<p>把中缀表达式转换为后缀表达式算法的基本思路如下：</p>
<ol type="1">
<li><p>初始化：操作符栈中放置一个元素 <code>@</code>。</p></li>
<li><p>依次读入中缀表达式中的每个字符</p>
<p>，对于不同类型的字符按不同情况进行处理：</p>
<ol type="1">
<li>若读到的是操作数，则输出该操作数，并读取下一个字符。</li>
<li>若读到的是左括号 <code>(</code>，则把它压入 <code>OPTR</code>
栈中，并读取下一个字符。</li>
<li>若读到的是右括号
<code>)</code>，则表明括号内的中缀表达式已经扫描完毕，将
<code>OPTR</code>
栈从栈顶直到左括号之前的操作符依次出栈并输出，然后将左括号出栈，并读取下一个字符。</li>
<li>若读到的是操作符 <code>c</code>，则将操作符栈的栈顶元素
<code>pre_op</code>与之进行比较：
<ul>
<li>若 <code>pre_op &lt; c</code>，则将 <code>c</code>
入栈，并读取下一个字符。</li>
<li>若 <code>pre_op &gt;= c</code>，则将 <code>pre_op</code>
出栈并输出。</li>
</ul></li>
<li>若读到的是结束符
<code>@</code>，则把栈中剩余的操作符依次出栈并输出，即可得到转换成的后缀表达式。</li>
</ol></li>
</ol>
<h2 id="后缀表达式求值">后缀表达式求值</h2>
<p>后缀表达式求值算法的基本思路如下</p>
<ol type="1">
<li><p>依次读入后缀表达式中的每个字符</p>
<p>，直至表达式结束。</p>
<ul>
<li>若读到的是操作数，则入 <code>OPND</code> 栈。</li>
<li>若读到的是操作符，则在 <code>OPND</code>
栈中退栈两个元素（先退出的是操作符右侧，后退出的是操作符左侧），然后用该操作符进行运算，并将运算结果压入
<code>OPND</code> 栈中。</li>
</ul></li>
<li><p><strong>后缀表达式扫描完毕时</strong>，若 <code>OPND</code>
栈中仅有一个元素，即为运算结果。</p></li>
</ol>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——图</title>
    <url>/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/</url>
    <content><![CDATA[<h2 id="图的基本概念和术语">图的基本概念和术语</h2>
<p>定义：一个图可以利用两个集合进行定义。第一个集合是点的集合,这些点在图术语中一般被称(Vertex);第二个集合是连接两个顶点的边(Edge)的集合。图的具体定义如下。
图是由顶点集合及顶点间的关系集合组成的一种数据结构:Graph = (V, E)</p>
<p>基本术语</p>
<ol type="1">
<li><p>有向图</p></li>
<li><p>无向图</p></li>
<li><p>邻接点</p></li>
<li><p>顶点的度，入度与出度</p></li>
<li><p>权和网：</p>
<ul>
<li><strong>权 ：</strong>
某些图的每条边都可能赋予一个数值，这个数值称为权。</li>
<li><strong>网 ：</strong> 带有权的图称为网。</li>
</ul></li>
<li><p><strong>无向完全图：</strong>
任意两个顶点之间都有一条边的无向图。</p>
<p><strong>有向完全图：</strong>
任意两个顶点之间都有方向相反的两条边的有向图。</p></li>
</ol>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202190122603.png" alt="image-20241202190122603">
<figcaption aria-hidden="true">image-20241202190122603</figcaption>
</figure>
<ol start="7" type="1">
<li><p>路径与路径长度</p></li>
<li><p><strong>简单路径</strong>：若路径上经过的各顶点均不重复，则称这样的路径为简单路径。</p>
<p><strong>回路或环</strong>：若路径上的第一个顶点与最后一个顶点相同，则称这样的路径为回路或环。</p></li>
</ol>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202190704319.png" alt="image-20241202190704319">
<figcaption aria-hidden="true">image-20241202190704319</figcaption>
</figure>
<ol start="9" type="1">
<li><p><strong>连通图：</strong>
在无向图中，若任意两个顶点之间都存在路径，则称该图为连通图。</p>
<p><strong>连通分量：</strong>
非连通图的极大连通子图称为连通分量。也就是说，一个连通分量是一个连通的子图，且不能再扩大。</p></li>
<li><p><strong>强连通图：</strong> 在有向图中，若对于任意一对顶点 u 和
v，都存在一条从 u 到 v 和从 v 到 u 的路径，则称该图为强连通图。</p>
<p><strong>强连通分量：</strong>
非强连通图的极大强连通子图称为强连通分量。</p></li>
<li><p><strong>生成树：</strong>
一个连通图的生成树是包含图中所有顶点的极小连通子图。也就是说，生成树是一棵树，且包含图中的所有顶点。</p>
<p><strong>生成森林：</strong>
非连通图的每个连通分量分别可以得到一棵生成树，这些生成树的集合称为生成森林。</p></li>
</ol>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202191533963.png" alt="image-20241202191533963">
<figcaption aria-hidden="true">image-20241202191533963</figcaption>
</figure>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202191543162.png" alt="image-20241202191543162">
<figcaption aria-hidden="true">image-20241202191543162</figcaption>
</figure>
<h2 id="图的储存结构">图的储存结构</h2>
<h3 id="邻接矩阵">邻接矩阵</h3>
<p>邻接矩阵表示法的基本思想是引入两个数组：</p>
<ul>
<li>一个用于记录图中各个顶点信息的—维数组，称为顶点表；</li>
<li>另一个用于表示图中各个顶点之间关系的二维数组，称为邻接矩阵。</li>
</ul>
<p>设图G=(V,
E)是具有n(n&gt;0)个顶点的图，则图G所对应的邻接矩阵A是一个n阶方阵</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202192441396.png" alt="image-20241202192441396">
<figcaption aria-hidden="true">image-20241202192441396</figcaption>
</figure>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202192456777.png" alt="image-20241202192456777">
<figcaption aria-hidden="true">image-20241202192456777</figcaption>
</figure>
<p>无向图的邻接矩阵可采用只存储上三角阵或下三角阵的压缩存储方法</p>
<hr>
<p>对于带权图，需要对邻接矩阵的元素值定义进行修改，让元素值表示相应顶点的权值</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202192636345.png" alt="image-20241202192636345">
<figcaption aria-hidden="true">image-20241202192636345</figcaption>
</figure>
<p>其中，∞可用计算机中的一个足够大的数代替，以与权重区分</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202193146935.png" alt="image-20241202193146935">
<figcaption aria-hidden="true">image-20241202193146935</figcaption>
</figure>
<h4 id="算法">算法</h4>
<p>图类MGraph的定义</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 图的类型定义: 无向图、无向网、有向图、有向网</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">GraphType</span> &#123; undigraph, digraph, undinetwork, dinetwork &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeType</span> &#123; <span class="comment">// 本类型定义也适用于后面的邻接表结构</span></span><br><span class="line">    T head, tail;</span><br><span class="line">    <span class="type">int</span> cost;</span><br><span class="line">    <span class="built_in">EdgeType</span>(T h, T t, <span class="type">int</span> c) &#123;</span><br><span class="line">        head = h;</span><br><span class="line">        tail = t;</span><br><span class="line">        cost = c;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MGraph</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> vexnum, edgenum;</span><br><span class="line">    GraphType kind;</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; edges; <span class="comment">// 邻接矩阵</span></span><br><span class="line">    vector&lt;T&gt; vexs;            <span class="comment">// 顶点表</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>无向有权图的邻接矩阵构建</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">createAdjMatrix</span><span class="params">(vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; adjMatrix, <span class="type">const</span> vector&lt;tuple&lt;<span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>&gt;&gt;&amp; edges, <span class="type">int</span> numVertices)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化邻接矩阵为无穷大</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numVertices; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; numVertices; ++j) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i != j) adjMatrix[i][j] = INT_MAX; <span class="comment">// 没有边的地方设置为无穷大，当i=j的值为0</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 填充边的信息</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; edge : edges) &#123;</span><br><span class="line">        <span class="type">int</span> u = <span class="built_in">get</span>&lt;<span class="number">0</span>&gt;(edge);  <span class="comment">// 获取第一个元素</span></span><br><span class="line">        <span class="type">int</span> v = <span class="built_in">get</span>&lt;<span class="number">1</span>&gt;(edge);  <span class="comment">// 获取第二个元素</span></span><br><span class="line">        <span class="type">int</span> weight = <span class="built_in">get</span>&lt;<span class="number">2</span>&gt;(edge);  <span class="comment">// 获取第三个元素</span></span><br><span class="line">        adjMatrix[u][v] = weight;</span><br><span class="line">        adjMatrix[v][u] = weight;  <span class="comment">// 无向图</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="邻接表">邻接表</h3>
<p>当一个图为稀疏图时（边数相对顶点较少），使用邻接矩阵法显然要浪费大量的存储空间，如下图所示：</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/dc28a71607451fd5adeb57fadf14659b.png" alt="dc28a71607451fd5adeb57fadf14659b">
<figcaption aria-hidden="true">dc28a71607451fd5adeb57fadf14659b</figcaption>
</figure>
<p>邻接表中存在两种结点:顶点表结点和边表结点，如下图所示。</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/5257342f8b24df2a6af18a35e74af60b.png" alt="5257342f8b24df2a6af18a35e74af60b">
<figcaption aria-hidden="true">5257342f8b24df2a6af18a35e74af60b</figcaption>
</figure>
<p>顶点表结点由顶点域(data)和指向第一条邻接边的指针(firstarc)
构成，边表(邻接表)结点由邻接点域(adjvex)和指向下一条邻接边的指针域(nextarc)
构成。</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241205203225293.png" alt="image-20241205203225293">
<figcaption aria-hidden="true">image-20241205203225293</figcaption>
</figure>
<h4 id="算法-1">算法</h4>
<p>基于邻接表存储表示的图类ALGraph定义</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 边节点</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeNode</span> &#123;</span><br><span class="line">    <span class="type">int</span> adjvex;  <span class="comment">// 邻接点下标</span></span><br><span class="line">    EdgeNode* next; <span class="comment">// 指向下一个邻接点</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 顶点节点</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">VexNode</span> &#123;</span><br><span class="line">    T data;</span><br><span class="line">    EdgeNode* firstEdge;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 图的邻接表表示</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ALGraph</span> &#123;</span><br><span class="line">    vector&lt;VexNode&lt;T&gt;&gt; vex;  <span class="comment">// 顶点数组</span></span><br><span class="line">    <span class="type">int</span> vexnum, edgenum;  <span class="comment">// 顶点数和边数</span></span><br><span class="line">	GraphType kind;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>无向图的构建</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">ALGraph&lt;T&gt;::<span class="built_in">ALGraph</span>(GraphType t, T vexs[], <span class="type">int</span> n, <span class="type">int</span> e) &#123;</span><br><span class="line">    <span class="comment">// 参数表示图的类型, 参数vexs为存储各顶点值的数组, 参数n和e分别为顶点数和边数</span></span><br><span class="line">    vexnum = n;</span><br><span class="line">    edgenum = e;</span><br><span class="line">    kind = t;</span><br><span class="line">    adjlist.<span class="built_in">resize</span>(vexnum);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化顶点表</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; ++i) &#123;</span><br><span class="line">        adjlist[i].data = vexs[i];</span><br><span class="line">        adjlist[i].firstEdge = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 依次输入所有的边的信息</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; edgenum; j++) &#123;</span><br><span class="line">        <span class="type">int</span> va, vb;</span><br><span class="line">        cin &gt;&gt; va &gt;&gt; vb;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 产生第一个表结点</span></span><br><span class="line">        EdgeNode* p = <span class="keyword">new</span> EdgeNode;</span><br><span class="line">        p-&gt;adjvex = vb;</span><br><span class="line">        p-&gt;nextedge = adjlist[va].firstEdge;</span><br><span class="line">        adjlist[va].firstEdge = p;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 产生第二个表结点</span></span><br><span class="line">        p = <span class="keyword">new</span> EdgeNode;</span><br><span class="line">        p-&gt;adjvex = va;</span><br><span class="line">        p-&gt;nextedge = adjlist[vb].firstEdge;</span><br><span class="line">        adjlist[vb].firstEdge = p;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="图的遍历">图的遍历</h2>
<p>为了防止已经访问过的结点重复访问的问题，提出了辅助数组
<code>visited[]</code></p>
<h3 id="深度优先遍历">深度优先遍历</h3>
<p><strong>深度优先搜索类似于树的先序遍历。</strong></p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241205210048064.png" alt="image-20241205210048064">
<figcaption aria-hidden="true">image-20241205210048064</figcaption>
</figure>
<p>算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> visited[MAX_VERTEX_NUM];	<span class="comment">//访问标记数组</span></span><br><span class="line"><span class="comment">/*从顶点出发，深度优先遍历图G*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFS</span><span class="params">(Graph G, <span class="type">int</span> v)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> w;</span><br><span class="line">	<span class="built_in">visit</span>(v);	<span class="comment">//访问顶点</span></span><br><span class="line">	visited[v] = TRUE;	<span class="comment">//设已访问标记</span></span><br><span class="line">	<span class="comment">//FirstNeighbor(G,v):求图G中顶点v的第一个邻接点，若有则返回顶点号，否则返回-1。</span></span><br><span class="line">	<span class="comment">//NextNeighbor(G,v,w):假设图G中顶点w是顶点v的一个邻接点，返回除w外顶点v</span></span><br><span class="line">	<span class="keyword">for</span>(w = <span class="built_in">FirstNeighbor</span>(G, v); w&gt;=<span class="number">0</span>; w=<span class="built_in">NextNeighor</span>(G, v, w))&#123;</span><br><span class="line">		<span class="keyword">if</span>(!visited[w])&#123;	<span class="comment">//w为u的尚未访问的邻接顶点</span></span><br><span class="line">			<span class="built_in">DFS</span>(G, w);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*对图进行深度优先遍历*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFSTraverse</span><span class="params">(MGraph G)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> v; </span><br><span class="line">	<span class="keyword">for</span>(v=<span class="number">0</span>; v&lt;G.vexnum; ++v)&#123;</span><br><span class="line">		visited[v] = FALSE;	<span class="comment">//初始化已访问标记数据</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span>(v=<span class="number">0</span>; v&lt;G.vexnum; ++v)&#123;	<span class="comment">//从v=0开始遍历</span></span><br><span class="line">		<span class="keyword">if</span>(!visited[v])&#123;</span><br><span class="line">			<span class="built_in">DFS</span>(G, v);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>DFS算法是一个递归算法，需要借助一个递归工作栈，故其空间复杂度为O(V)。</p>
<p>对于n个顶点e条边的图来说，邻接矩阵由于是二维数组，要查找每个顶点的邻接点需要访问矩阵中的所有元素，因此都需要O(V^2)的时间。而邻接表做存储结构时，找邻接点所需的时间取决于顶点和边的数量，所以是O(V＋E)。</p>
<h3 id="广度优先遍历">广度优先遍历</h3>
<p><strong>图的广度优先遍历就类似于树的层序遍历</strong></p>
<p>算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*邻接矩阵的广度遍历算法*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFSTraverse</span><span class="params">(MGraph G)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> i, j;</span><br><span class="line">	Queue Q;</span><br><span class="line">	<span class="keyword">for</span>(i = <span class="number">0</span>; i&lt;G,numVertexes; i++)&#123;</span><br><span class="line">		visited[i] = FALSE;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">InitQueue</span>(&amp;Q);	<span class="comment">//初始化一辅助用的队列</span></span><br><span class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;G.numVertexes; i++)&#123;</span><br><span class="line">		<span class="comment">//若是未访问过就处理</span></span><br><span class="line">		<span class="keyword">if</span>(!visited[i])&#123;</span><br><span class="line">			vivited[i] = TRUE;	<span class="comment">//设置当前访问过</span></span><br><span class="line">			<span class="built_in">visit</span>(i);	<span class="comment">//访问顶点</span></span><br><span class="line">			<span class="built_in">EnQueue</span>(&amp;Q, i);	<span class="comment">//将此顶点入队列</span></span><br><span class="line">			<span class="comment">//若当前队列不为空</span></span><br><span class="line">			<span class="keyword">while</span>(!<span class="built_in">QueueEmpty</span>(Q))&#123;</span><br><span class="line">				<span class="built_in">DeQueue</span>(&amp;Q, &amp;i);	<span class="comment">//顶点i出队列</span></span><br><span class="line">				<span class="comment">//FirstNeighbor(G,v):求图G中顶点v的第一个邻接点，若有则返回顶点号，否则返回-1。</span></span><br><span class="line">				<span class="comment">//NextNeighbor(G,v,w):假设图G中顶点w是顶点v的一个邻接点，返回除w外顶点v</span></span><br><span class="line">				<span class="keyword">for</span>(j=<span class="built_in">FirstNeighbor</span>(G, i); j&gt;=<span class="number">0</span>; j=<span class="built_in">NextNeighbor</span>(G, i, j))&#123;</span><br><span class="line">					<span class="comment">//检验i的所有邻接点</span></span><br><span class="line">					<span class="keyword">if</span>(!visited[j])&#123;</span><br><span class="line">						<span class="built_in">visit</span>(j);	<span class="comment">//访问顶点j</span></span><br><span class="line">						visited[j] = TRUE;	<span class="comment">//访问标记</span></span><br><span class="line">						<span class="built_in">EnQueue</span>(Q, j);	<span class="comment">//顶点j入队列</span></span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>无论是邻接表还是邻接矩阵的存储方式，BFS算法都需要借助一个辅助队列Q,
n个顶点均需入队一次，在最坏的情况下，空间复杂度为O(V)。
采用邻接表存储方式时，每个顶点均需搜索一次(或入队一次)，在搜索任一顶点的邻接点时，每条边至少访问一次，算法总的时间复杂度为O(V＋E)。采用邻接矩阵存储方式时，查找每个顶点的邻接点所需的时间为O(V)，故算法总的时间复杂度为O(V^2)。</p>
<blockquote>
<p>注意:图的邻接矩阵表示是唯一的，但对于邻接表来说，若边的输入次序不同，生成的邻接表也不同。因此，对于同样一个图，基于邻接矩阵的遍历所得到的DFS序列和BFS序列是唯一的，基于邻接表的遍历所得到的DFS序列和BFS序列是不唯一的。</p>
</blockquote>
<h3 id="应用">应用</h3>
<p>简单路径的搜索算法 dfs</p>
<p>二部图的判定算法</p>
<h2 id="最小生成树">最小生成树</h2>
<p>生成树变成非连通图;若给它增加一条边，则会形成图中的一条回路。对于一个带权连通无向图G=(V,E)，生成树不同，其中边的权值之和最小的那棵生成树（构造连通网的最小代价生成树)，称为G的<strong>最小生成树(Minimum-Spanning-Tree,MST)</strong>。</p>
<h3 id="普里姆prim算法">普里姆（Prim）算法</h3>
<p><strong>从一个顶点出发，在保证不形成回路的前提下，每找到并添加一条最短的边，就把当前形成的连通分量当做一个整体或者一个点看待，然后重复“找最短的边并添加”的操作。</strong></p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/d0daac1cd8df11a443697ee6bc3fcf03.png" alt="d0daac1cd8df11a443697ee6bc3fcf03">
<figcaption aria-hidden="true">d0daac1cd8df11a443697ee6bc3fcf03</figcaption>
</figure>
<p>引入辅助数组<code>miniedges[]</code>，用于存放每个节点到节点v的边的权值，并每次挑选出权值最小的那个边所对应的节点加入生成树，辅助数组<code>miniedges[]</code>的数据类型如下</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Edge</span> &#123;</span><br><span class="line">    <span class="type">int</span> adjvex;  <span class="comment">// 与当前生成树连接的节点的编号</span></span><br><span class="line">    <span class="type">int</span> lowcost; <span class="comment">// 到当前生成树的最小边权值</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>若将某个数组元素<code>miniedges[i]</code>的
lowcost成员值设为0，则表示相应的顶点v,已加入到最小生成树中。</p>
<p>为便于算法在执行过程中读取任意两个顶点之间边的权值，对图宜采用<strong>邻接矩阵存储结构</strong>。</p>
<p>算法思路：</p>
<ol type="1">
<li><p>初始化辅助数组，从节点v开始，将v的lowcost设为0，说明已经加入生成树</p></li>
<li><p>循环vexnum-1次，利用函数<code>MiniNum</code>找到权值最小的节点并输出</p>
<p>函数<code>MiniNum</code>循环vexnum次，找到当前所有节点中，<strong>未加入生成树的</strong>，lowcost最小的节点</p></li>
<li><p>更新辅助数组<code>miniedges[]</code>的每个节点的lowcost：循环vexnum次，如果通过当前节点k能找到比原先更小的边，更新该节点的lowcost；如果大，则保留原lowcost的值，更新后代表生成树节点的集合到未加入节点的集合的权值最小的vexnum条边</p></li>
</ol>
<p>时间复杂度：O(n^2)</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Prim</span><span class="params">(<span class="type">const</span> vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; graph, <span class="type">int</span> v, <span class="type">int</span> vexnum)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化 miniedges 数组</span></span><br><span class="line">    Edge* miniedges = <span class="keyword">new</span> Edge[vexnum];</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化 miniedges，每个节点到起始点v的边的权值</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        miniedges[i].adjvex = <span class="built_in">GetVexValue</span>(v);        <span class="comment">// 初始时节点的连接为起始节点v</span></span><br><span class="line">        miniedges[i].lowcost = <span class="built_in">GetEdgeValue</span>(graph, v, i);   <span class="comment">// 初始化每个节点到v的边权值</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    miniedges[v].lowcost = <span class="number">0</span>; <span class="comment">// 将起始节点v的lowcost设为0，表示已经加入生成树</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 循环执行，每次选取一个未加入生成树的权值最小的节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        <span class="comment">// 找到最小的lowcost</span></span><br><span class="line">        <span class="type">int</span> k = <span class="built_in">MiniNum</span>(miniedges, vexnum);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输出当前加入生成树的边</span></span><br><span class="line">        cout &lt;&lt; miniedges[k].adjvex &lt;&lt; <span class="string">&quot; --&gt; &quot;</span> &lt;&lt; <span class="built_in">GetVexValue</span>(k) &lt;&lt; endl;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将选中的节点k加入生成树</span></span><br><span class="line">        miniedges[k].lowcost = <span class="number">0</span>; <span class="comment">// 表示节点k已加入生成树</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 更新与当前生成树连接的节点的lowcost（最小边权值）</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; vexnum; j++) &#123;</span><br><span class="line">            <span class="comment">// 如果通过当前节点k能找到比原先更小的边，更新该节点的lowcost</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">GetEdgeValue</span>(graph, k, j) &lt; miniedges[j].lowcost) &#123;</span><br><span class="line">                miniedges[j].adjvex = <span class="built_in">GetVexValue</span>(k);   <span class="comment">// 记录当前节点k</span></span><br><span class="line">                miniedges[j].lowcost = <span class="built_in">GetEdgeValue</span>(graph, k, j); <span class="comment">// 更新到生成树的最小边权值</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放动态分配的内存</span></span><br><span class="line">    <span class="keyword">delete</span>[] miniedges;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>函数<code>MiniNum</code>用于在数组miniedges中查找集合V-U中的具有最小权值的顶点,可以将它定义为私有成员函数</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 找到当前所有节点中，未加入生成树的，lowcost最小的节点</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">MiniNum</span><span class="params">(Edge miniedges[], <span class="type">int</span> vexnum)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> min = INT_MAX;</span><br><span class="line">    <span class="type">int</span> k = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (miniedges[i].lowcost != <span class="number">0</span> &amp;&amp; miniedges[i].lowcost &lt; min) &#123; <span class="comment">// 如果该节点未加入生成树</span></span><br><span class="line">            min = miniedges[i].lowcost;</span><br><span class="line">            k = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> k; <span class="comment">// 返回最小权值的节点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="克鲁斯卡尔kruskal算法">克鲁斯卡尔（Kruskal）算法</h3>
<p><strong>与Prim算法从顶点开始扩展最小生成树不同，Kruskal
算法是一种按权值的递增次序选择合适的边来构造最小生成树的方法。</strong></p>
<p>每次挑选为加入生成树的最小边，若不构成回路，则加入生成树，若构成则挑选下一个</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/6b95ef2bc34f407c122e931cf06b11e6.png" alt="6b95ef2bc34f407c122e931cf06b11e6">
<figcaption aria-hidden="true">6b95ef2bc34f407c122e931cf06b11e6</figcaption>
</figure>
<p>为提高算法执行过程中<strong>查找最小权值边的速度</strong>，可以采用一种排序算法(如堆排序算法)对边集数组中的边按权值进行排序。</p>
<p>接下来，Kruskal算法的关键问题就是<strong>如何判断所选取的边加入T中是否会产生回路</strong>，这里通过引入称为<strong>并查集</strong>的数据结构来解决</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/fb9515df040633c09b3c136601c8dbd7-1743416415437-1.png" alt="fb9515df040633c09b3c136601c8dbd7">
<figcaption aria-hidden="true">fb9515df040633c09b3c136601c8dbd7</figcaption>
</figure>
<p>在下面描述的Kruskal 算法实现中，首先利用私有成员
<code>GetGraph()函数</code><strong>将图的边按权值排好序后存入边集数组graph中</strong>，而<code>边集数组tree</code>则用于<strong>保存和返回算法所构造的最小生成树T</strong>。</p>
<p>算法思路：</p>
<ol type="1">
<li>初始话数组<code>graph</code>，用于存放所有的边，并对其排序</li>
<li>并查集的使用利用<code>数组components</code>，先进行初始化，每个节点的祖先都是自己，也可以理解成每个节点都构成一个集合，后续并查集的过程即为集合合并的过程</li>
<li>循环直到找到最小生成树的所有边（vexnum -
1条），对于每条边，查找他的起点和终点节点的祖先，若是一个祖先则说明在同一集合，不能加入到生成树；若不是一个，则可以加入到<code>生成树数组tree</code>，并要修改节点的祖先，使他们集合合并</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">Kruskal</span>(vector&lt;EdgeType&gt; &amp;tree) &#123;</span><br><span class="line">    <span class="comment">// 创建一个图的边集合，用于存放所有的边</span></span><br><span class="line">    vector&lt;EdgeType&gt; graph;</span><br><span class="line">    <span class="comment">// GetGraph函数将图的所有边按权值从小到大存放到graph数组中</span></span><br><span class="line">    <span class="built_in">GetGraph</span>(graph);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化最小生成树数组，并且初始化并查集组件</span></span><br><span class="line">    tree.<span class="built_in">resize</span>(vexnum - <span class="number">1</span>);  <span class="comment">// 最小生成树包含的边数量是vexnum - 1</span></span><br><span class="line">    <span class="type">int</span> *components = <span class="keyword">new</span> <span class="type">int</span>[vexnum];  <span class="comment">// 记录每个节点所属的集合</span></span><br><span class="line">    <span class="comment">// 初始时，每个节点都属于自己的集合</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        components[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> k = <span class="number">0</span>, j = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 循环直到找到最小生成树的所有边（vexnum - 1条）</span></span><br><span class="line">    <span class="keyword">while</span> (k &lt; vexnum - <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// 从排序好的边中选择一条边</span></span><br><span class="line">        <span class="type">int</span> h1 = graph[j].head;  <span class="comment">// 边的起点</span></span><br><span class="line">        <span class="type">int</span> t1 = graph[j].tail;  <span class="comment">// 边的终点</span></span><br><span class="line">        <span class="type">int</span> h2 = components[h1];  <span class="comment">// 获取起点所在的集合</span></span><br><span class="line">        <span class="type">int</span> t2 = components[t1];  <span class="comment">// 获取终点所在的集合</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果起点和终点属于不同的集合，则这条边可以加入最小生成树</span></span><br><span class="line">        <span class="keyword">if</span> (h2 != t2) &#123;</span><br><span class="line">            <span class="comment">// 将这条边加入最小生成树中</span></span><br><span class="line">            tree[k].head = h1;</span><br><span class="line">            tree[k].tail = t1;</span><br><span class="line">            tree[k].cost = graph[j].cost;  <span class="comment">// 边的权值</span></span><br><span class="line">            k++;  <span class="comment">// 记录已选择的边的数量</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 合并两个集合，统一编号</span></span><br><span class="line">            <span class="comment">// 将所有属于终点集合t2的顶点，集合编号更新为起点集合h2的编号</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (components[i] == t2) &#123;</span><br><span class="line">                    components[i] = h2;  <span class="comment">// 更新组件编号</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        j++;  <span class="comment">// 继续检查下一条边</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放动态分配的内存</span></span><br><span class="line">    <span class="keyword">delete</span>[] components;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>显然，Kruskal算法的效率与所选择的<strong>排序算法的效率</strong>以及<strong>并查集数据结构的实现效率</strong>有关。若采用第10章介绍的比较高效的<strong>堆排序算法</strong>排序，<strong>并查集采用树结构</strong>实现，则Kruskal算法的时间复杂度可达到O(<span class="math inline"> <em>e</em><em>l</em><em>o</em><em>g</em><sub>2</sub><em>e</em></span>)。相比
Prim
算法而言，Kruskal算法更适用于求解稀疏网(指边数较少的网)的最小生成树。</p>
<h2 id="最短路径">最短路径</h2>
<p>在网图和非网图中，最短路径的含义是不同的。由于非网图它没有边上的权值，所谓的最短路径，其实就是指两顶点之间经过的边数最少的路径；而<strong>对于网图来说，最短路径，是指两顶点之间经过的边上权值之和最少的路径，并且我们称路径上的第一个顶点是源点，最后一个顶点是终点。</strong></p>
<p>求图的最短路径问题通常可分为两类。一类是求图中某顶点到其余各顶点的最短路径问题，也称为<strong>单源最短路径问题</strong>;另一类是求图中每对顶点之间的最短路径问题。</p>
<h3 id="迪杰斯特拉-dijkstra-算法">迪杰斯特拉( Dijkstra )算法</h3>
<p>Dijkstra算法用于构建单源点的最短路径—，即图中某个点到任何其他点的距离都是最短的。例如，构建地图应用时查找自己的坐标离某个地标的最短距离。可以用于有向图，但是不能存在负权值。</p>
<p><strong>通俗点说，迪杰斯特拉(Dijkstra)算法，它并不是一下子求出了<span class="math inline"> <em>v</em><sub><em>i</em></sub></span>到<span class="math inline"> <em>v</em><sub><em>j</em></sub></span>的最短路径，而是一步步求出它们之间顶点的最短路径，过程中都是基于已经求出的最短路径的基础上，求得更远顶点的最短路径，最终得到你要的结果。</strong></p>
<p>下面介绍
Dijkstra算法的具体实现。为便于在算法执行过程中快速地求得任意两个顶点之间边的权值，图的存储结构宜采用邻接矩阵方式。</p>
<p>为标识图中各顶点在算法执行过程中<strong>是否已求出最短路径</strong>，设置一个<code>一维数组s[]</code></p>
<p>为记录
Dijkstra算法所求出的从源点到各顶点的最短路径，引入<code>数组 path[]</code>,
path[i]中保存了从源点到终点v,的最短路径上该顶点的<strong>前驱顶点的序号</strong>。算法结束时，可根据数组path[
]找到源点到v,的最短路径上每个顶点的前驱顶点，并一直回溯至源点，从而推出从源点到v的最短路径。</p>
<p>为便于每次从V-S中选择当前离源点距离最短的顶点，需要引人一个<code>辅助数组dist[]</code>。它的每一个分量dist[i]表示当前所确定的从源点<span class="math inline"> <em>v</em><sub>0</sub></span>,到终点<span class="math inline"> <em>v</em><sub><em>i</em></sub></span>的最短路径.</p>
<p>算法思路：</p>
<ol type="1">
<li>初始化，s[]所有值为0，s[0]设置为1，代表从<span class="math inline"> <em>v</em><sub>0</sub></span>节点开始，path[]所有值设为0，path[0]设为-1，dist[]通过查找邻接矩阵，得到<span class="math inline"> <em>v</em><sub>0</sub></span>到各个顶点的值</li>
<li>查找dist中最小的值，从该节点继续完成最小路径，将该节点对应s[]设为1</li>
<li>遍历尚未找到最短路径的节点，即s[]为0，dist[i] = Min{dist[i]，dist[j]
+cost(j,i)}，选择是借用上一个最短路径的节点到达还是直接到达，更新dist的值</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Dijkstra算法：计算从起点start到其他所有节点的最短路径</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dijkstra</span><span class="params">(<span class="type">int</span> start, <span class="type">int</span> dist[], <span class="type">int</span> path[])</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = numVertices;  <span class="comment">// 获取图中节点的数量</span></span><br><span class="line">    <span class="type">bool</span> visited[n];  <span class="comment">// 访问标记数组，用于标记节点是否已经被访问</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化dist数组和path数组</span></span><br><span class="line">    <span class="comment">// dist[i] 表示从起点到节点i的最短距离</span></span><br><span class="line">    <span class="comment">// path[i] 表示从起点到节点i的最短路径的前驱节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">        visited[i] = <span class="literal">false</span>;  <span class="comment">// 初始时，所有节点均未被访问</span></span><br><span class="line">        dist[i] = adjMatrix[start][i];  <span class="comment">// dist数组初始化为起点到各节点的初始距离</span></span><br><span class="line">        <span class="keyword">if</span> (dist[i] != INT_MAX || i == start) &#123;  <span class="comment">// 如果有边（距离不为无穷大），或者是起点本身</span></span><br><span class="line">            path[i] = start;  <span class="comment">// 将路径的前驱节点设置为起点</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            path[i] = <span class="number">-1</span>;  <span class="comment">// 如果节点无法从起点到达，前驱节点为-1</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    dist[start] = <span class="number">0</span>;  <span class="comment">// 起点到起点的距离为0</span></span><br><span class="line">    visited[start] = <span class="literal">true</span>;  <span class="comment">// 标记起点为已访问</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进行n-1轮循环，逐步更新最短路径</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> count = <span class="number">0</span>; count &lt; n - <span class="number">1</span>; ++count) &#123;</span><br><span class="line">        <span class="type">int</span> min = INT_MAX, min_index;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到未访问的节点中距离最小的节点</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v = <span class="number">0</span>; v &lt; n; ++v) &#123;</span><br><span class="line">            <span class="comment">// 选择距离最小且未被访问的节点</span></span><br><span class="line">            <span class="keyword">if</span> (visited[v] == <span class="literal">false</span> &amp;&amp; dist[v] &lt;= min) &#123;</span><br><span class="line">                min = dist[v];  <span class="comment">// 更新最小距离</span></span><br><span class="line">                min_index = v;  <span class="comment">// 记录最小距离节点的索引</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        visited[min_index] = <span class="literal">true</span>;  <span class="comment">// 标记该节点为已访问</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 更新与该最小距离节点相邻的节点的距离</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v = <span class="number">0</span>; v &lt; n; ++v) &#123;</span><br><span class="line">            <span class="comment">// 如果v节点未被访问，并且从min_index到v有边，且经过min_index节点的路径更短</span></span><br><span class="line">            <span class="keyword">if</span> (!visited[v] &amp;&amp;  </span><br><span class="line">                dist[v] &gt; dist[min_index] + adjMatrix[min_index][v]) &#123;</span><br><span class="line">                dist[v] = dist[min_index] + adjMatrix[min_index][v];  <span class="comment">// 更新v的最短距离</span></span><br><span class="line">                path[v] = min_index;  <span class="comment">// 更新v的前驱节点</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241209092422699.png" alt="image-20241209092422699">
<figcaption aria-hidden="true">image-20241209092422699</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 打印从源节点到目标节点v的路径</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintPath</span><span class="params">(<span class="type">const</span> vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; g, vector&lt;<span class="type">int</span>&gt; path, vector&lt;<span class="type">int</span>&gt; dist, <span class="type">int</span> v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (dist[v] == INF) &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;节点 &quot;</span> &lt;&lt; v &lt;&lt; <span class="string">&quot; 无法到达&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 递归打印路径</span></span><br><span class="line">    <span class="keyword">if</span> (path[v] != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="built_in">PrintPath</span>(g, path, dist, path[v]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; v &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>时间复杂度O(n^2)</p>
<h3 id="弗洛伊德-floyd-算法">弗洛伊德( Floyd )算法</h3>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/e00a2f6ecb05b16c2cae4adfb9da8698.png" alt="e00a2f6ecb05b16c2cae4adfb9da8698">
<figcaption aria-hidden="true">e00a2f6ecb05b16c2cae4adfb9da8698</figcaption>
</figure>
<p>算法原理：递归</p>
<p>n阶数组D：用于保留每一步所求得的所有顶点对之间的当前最短路径长度</p>
<p>初始化：<span class="math inline"> <em>D</em>[<em>i</em>][<em>j</em>] = <em>c</em><em>o</em><em>s</em><em>t</em>(<em>i</em>, <em>j</em>)</span>用邻接矩阵进行初始化</p>
<p>状态转移方程：<span class="math inline"> <em>D</em><sup><em>k</em></sup>[<em>i</em>][<em>j</em>] = <em>m</em><em>i</em><em>n</em>{<em>D</em><sup><em>k</em> − 1</sup>[<em>i</em>][<em>j</em>], <em>D</em><sup><em>k</em> − 1</sup>[<em>i</em>][<em>k</em>] + <em>D</em><sup><em>k</em> − 1</sup>[<em>k</em>][<em>j</em>]}</span>更新<span class="math inline"><em>v</em><sub><em>i</em></sub></span>到<span class="math inline"><em>v</em><sub><em>j</em></sub></span>的最短路径</p>
<p>path数组：用于存储最短路径，初始化若没有直接路径则<span class="math inline"> <em>p</em><em>a</em><em>t</em><em>h</em>[<em>i</em>][<em>j</em>] = −1</span>，若有则<span class="math inline"> <em>p</em><em>a</em><em>t</em><em>h</em>[<em>i</em>][<em>j</em>] = <em>j</em></span></p>
<p>算法思路：</p>
<p>初始化数组，遍历n*n次，即<span class="math inline"><em>v</em><sub><em>i</em></sub></span>到<span class="math inline"><em>v</em><sub><em>j</em></sub></span>和<span class="math inline"><em>v</em><sub><em>j</em></sub></span>到<span class="math inline"><em>v</em><sub><em>i</em></sub></span>都遍历一遍，通过状态转移方程更新D数组的值，若找到短的路径，则同时也更新path数组</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Floyd算法</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">Floyd</span>(<span class="type">int</span> path[][MAXV], <span class="type">int</span> D[][MAXV]) &#123;</span><br><span class="line">    <span class="comment">// 初始化距离矩阵D和路径矩阵path</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; vexnum; ++j) &#123;</span><br><span class="line">            D[i][j] = edges[i][j];</span><br><span class="line">            <span class="comment">//初始化path</span></span><br><span class="line">            <span class="keyword">if</span> (D[i][j] &lt; INF &amp;&amp; i != j)</span><br><span class="line">                path[i][j] = j;  <span class="comment">// 若i到j有直接路径，记录路径</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                path[i][j] = <span class="number">-1</span>; <span class="comment">// 否则路径不存在</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 核心Floyd-Warshall算法</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; vexnum; ++k) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; vexnum; ++j) &#123;</span><br><span class="line">                <span class="keyword">if</span> (D[i][k] != INF &amp;&amp; D[k][j] != INF &amp;&amp; D[i][k] + D[k][j] &lt; D[i][j]) &#123;</span><br><span class="line">                    D[i][j] = D[i][k] + D[k][j];  <span class="comment">// 更新最短路径长度</span></span><br><span class="line">                    path[i][j] = path[i][k];      <span class="comment">// 更新路径</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>函数OutputPath用于输出保存于二维数组path中的所有路径以及保存于二维数组D中的路径长度</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">OutputPath</span><span class="params">(MGraph&lt;T&gt; &amp;G, <span class="type">int</span> path[][MAXV], <span class="type">int</span> D[][MAXV])</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 遍历所有顶点对，输出源点到目标点的最短路径及路径长度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; G.vexnum; ++i) &#123;      <span class="comment">// 遍历所有源点 i</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; G.vexnum; ++j) &#123;  <span class="comment">// 遍历所有目标点 j</span></span><br><span class="line">            <span class="keyword">if</span> (i != j) &#123; <span class="comment">// 排除自身到自身的情况</span></span><br><span class="line">                <span class="keyword">if</span> (D[i][j] == INF) &#123;  <span class="comment">// 若距离为无穷大，表示无路径</span></span><br><span class="line">                    std::cout &lt;&lt; <span class="string">&quot;Path from &quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; to &quot;</span> &lt;&lt; j &lt;&lt; <span class="string">&quot;: No path exists.\n&quot;</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;  <span class="comment">// 若存在路径</span></span><br><span class="line">                    std::cout &lt;&lt; <span class="string">&quot;Path from &quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; to &quot;</span> &lt;&lt; j &lt;&lt; <span class="string">&quot; (Length: &quot;</span> &lt;&lt; D[i][j] &lt;&lt; <span class="string">&quot;): &quot;</span>;</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">// 输出路径，使用 path 数组逐步跟踪中间节点</span></span><br><span class="line">                    <span class="type">int</span> temp = i;      <span class="comment">// 起始点</span></span><br><span class="line">                    std::cout &lt;&lt; temp; <span class="comment">// 输出源点</span></span><br><span class="line">                    <span class="keyword">while</span> (temp != j) &#123; <span class="comment">// 当未到达目标点时</span></span><br><span class="line">                        temp = path[temp][j];  <span class="comment">// 获取路径中的下一个节点</span></span><br><span class="line">                        std::cout &lt;&lt; <span class="string">&quot; -&gt; &quot;</span> &lt;&lt; temp; <span class="comment">// 输出中间节点或目标点</span></span><br><span class="line">                    &#125;</span><br><span class="line">                    std::cout &lt;&lt; std::endl; <span class="comment">// 换行</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="aov网与拓扑排序">AOV网与拓扑排序</h2>
<p><strong>有向无环图：不含环的有向图</strong></p>
<p><strong>AOV网</strong>：<strong>在一个表示工程的有向图中，用顶点表示活动，用弧表示活动之间的优先关系，这样的有向图为顶点表示活动的网</strong></p>
<p><strong>拓扑序列</strong>：<strong>设G=(V,E)是一个具有n个顶点的有向图，V中的顶点序列V,
V2 ,..V
n，满足若从顶点V到V;有一条路径，则在顶点序列中顶点V必在顶点V;之前。则我们称这样的顶点序列为一个拓扑序列。</strong></p>
<p><strong>拓扑排序</strong>：<strong>其实就是对一个有向图构造拓扑序列的过程</strong>。每个AOV网都有一个或多个拓扑排序序列。</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241215131046998.png" alt="image-20241215131046998">
<figcaption aria-hidden="true">image-20241215131046998</figcaption>
</figure>
<p>对一个AOV网进行拓扑排序的算法有很多，下面介绍比较常用的一种方法的步骤:</p>
<p>①从AOV网中选择一个没有前驱的顶点并输出。
②从网中删除该顶点和所有以它为起点的有向边。
③重复①和②直到当前的AOV网为空或当前网中不存在无前驱的顶点为止。如果输出顶点数少了，哪怕是少了一个，也说明这个网存在环(回路)，不是AOV网。
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241215131727207.png" alt="image-20241215131727207"></p>
<p>算法原理：dfs</p>
<p>对于AOV 网宜采用<strong>邻接表</strong>作为存储结构</p>
<p>数组indegree：用于存放各个顶点的入度</p>
<p>算法思路：</p>
<p>每次遍历数组indegree，查找入度为零的顶点，将其加入队列，再遍历邻接表，将遍历到的顶点的indegree值减一，并判断是否为零，若为零则加入队列</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 拓扑排序实现</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Graph::topologicalSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">indegree</span><span class="params">(V, <span class="number">0</span>)</span></span>; <span class="comment">// 入度数组</span></span><br><span class="line">    queue&lt;<span class="type">int</span>&gt; q;              <span class="comment">// 队列</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算所有顶点的入度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; V; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v : adj[i]) &#123;</span><br><span class="line">            indegree[v]++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将入度为0的顶点加入队列</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; V; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (indegree[i] == <span class="number">0</span>) &#123;</span><br><span class="line">            q.<span class="built_in">push</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> count = <span class="number">0</span>; <span class="comment">// 用于检测图是否存在环</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出拓扑排序</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;拓扑排序顺序为: &quot;</span>;</span><br><span class="line">    <span class="keyword">while</span> (!q.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="type">int</span> u = q.<span class="built_in">front</span>();</span><br><span class="line">        q.<span class="built_in">pop</span>();</span><br><span class="line">        cout &lt;&lt; u &lt;&lt; <span class="string">&quot; &quot;</span>; <span class="comment">// 输出顶点</span></span><br><span class="line">        count++;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 遍历该顶点的所有邻接点，并更新它们的入度</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v : adj[u]) &#123;</span><br><span class="line">            indegree[v]--;</span><br><span class="line">            <span class="keyword">if</span> (indegree[v] == <span class="number">0</span>) &#123;</span><br><span class="line">                q.<span class="built_in">push</span>(v);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果没有输出所有顶点，说明存在环</span></span><br><span class="line">    <span class="keyword">if</span> (count != V) &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;图中存在环，无法进行拓扑排序！&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/Real_Fool_/article/details/114141377">数据结构：图(Graph)【详解】_图数据结构-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1gT4y1v768/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">数据结构-图-prim（普里姆）算法最小生成树（过程分析+手写代码）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV19S4y1Y7MT?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">数据结构-图-最小生成树-克鲁斯卡尔（Kruskal)算法-手画+过程分析+代码_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——期末复习</title>
    <url>/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="第一章">第一章</h3>
<p><strong>时钟频率（f）</strong>
：单位时间内完成的时钟周期数，单位为赫兹（Hz）。 例如：800MHz
表示每秒完成 800×106 个周期。</p>
<p><strong>时钟周期（T）</strong>
：完成一个时钟周期所需的时间，单位为秒（s）。 例如：800MHz 的时钟周期为
<em>T</em>=800×1061​s=1.25ns （纳秒）。</p>
<p><strong>CPI</strong>（<strong>Cycles Per
Instruction</strong>，每条指令所需的时钟周期数）是衡量计算机体系结构性能的关键指标之一，用于描述<strong>CPU执行一条指令平均需要多少个时钟周期</strong>。它直接影响程序的执行速度和系统性能。</p>
<ul>
<li><strong>CPI</strong>
表示每条指令执行所需的平均时钟周期数，计算公式为： <span class="math display">$$
\text{CPI} = \frac{\text{总时钟周期数}}{\text{总指令数}}
$$</span></li>
<li><strong>执行时间</strong> 与 CPI 的关系： <span class="math display">执行时间 = 指令数 × CPI × 时钟周期时间</span>
其中，时钟周期时间 = 1 / 时钟频率。</li>
</ul>
<p><strong>MIPS（Million Instructions Per Second）</strong>
是衡量计算机处理器性能的一个经典指标，表示
<strong>每秒执行的百万条指令数</strong>，用于量化 CPU
的指令处理能力。其核心思想是：<strong>数值越大，性能越强</strong>，但需注意其局限性。</p>
<ul>
<li><strong>MIPS</strong> = 指令数 / (执行时间 × 10⁶)<br>
</li>
<li>或通过 <strong>时钟频率</strong> 和 <strong>CPI（Cycles Per
Instruction）</strong> 计算：<br>
<span class="math display">$$
\text{MIPS} = \frac{\text{时钟频率（Hz）}}{\text{CPI} \times 10^6}
$$</span></li>
</ul>
<p><strong>举例</strong>：<br>
- 若 CPU 主频为 <strong>2 GHz</strong>（2×10⁹ Hz），平均
CPI=4，则：<br>
<span class="math display">$$
  \text{MIPS} = \frac{2 \times 10^9}{4 \times 10^6} = 500 \text{ MIPS}
  $$</span></p>
<p>数量级：</p>
<p>G，吉，十的九次方</p>
<p>n，纳，十的负九次方</p>
<p><strong>m（milli，毫）的数量级是 10−3 （千分之一）</strong> 。</p>
<h3 id="第二章">第二章</h3>
<h4 id="补码">补码</h4>
<p><strong>1. 补码的定义</strong></p>
<p>补码（Two’s
Complement）是计算机中表示有符号整数的标准方法，其核心作用是将减法运算转化为加法运算，从而简化硬件设计。</p>
<p><strong>2. 如何求一个数的补码？</strong></p>
<p>以 <strong>8位二进制</strong> 为例： - <strong>正数</strong>：补码 =
原码（符号位为0，其余位直接表示数值）。<br>
例如：<code>+5</code> 的补码是 <code>00000101</code>。</p>
<ul>
<li><strong>负数</strong>：补码 =
原码的符号位不变，其余位取反（反码），然后末位加1。<br>
例如：求 <code>-5</code> 的补码：
<ol type="1">
<li>原码：<code>10000101</code>（符号位为1，其余位为5的二进制）。</li>
<li>取反（符号位保留）：<code>11111010</code>（反码）。</li>
<li>加1：<code>11111010 + 1 = 11111011</code>（补码）。</li>
</ol></li>
</ul>
<p><strong>3. 数学原理：模运算</strong></p>
<p>补码的本质是基于 <strong>模（Modulo）运算</strong>。<br>
- 对于 <strong>n位二进制数</strong>，其模为 <span class="math inline">2<sup><em>n</em></sup></span>。<br>
- 负数的补码表示为：<br>
<span class="math display">−<em>x</em> ≡ 2<sup><em>n</em></sup> − <em>x</em> (mod 2<sup><em>n</em></sup>)</span>
例如，8位二进制数的模是 <span class="math inline">2<sup>8</sup> = 256</span>，因此：<br>
<span class="math inline">−5</span> 的补码 = <span class="math inline">256 − 5 = 251</span>，二进制表示为
<code>11111011</code>。</p>
<p><strong>4. 为什么“取反 + 1”有效？</strong></p>
<ul>
<li><strong>取反</strong>：相当于将数值部分取反（即 <span class="math inline"><em>x</em> → (2<sup><em>n</em> − 1</sup> − 1 − <em>x</em>)</span>）。</li>
<li><strong>加1</strong>：最终得到 <span class="math inline">2<sup><em>n</em></sup> − <em>x</em></span>，即补码的数学定义。</li>
</ul>
<p>以 <code>-5</code> 为例（8位）： 1.
原码：<code>10000101</code>（符号位为1，数值部分为5）。 2.
取反：<code>11111010</code>（数值部分取反，符号位保留）。 3.
加1：<code>11111010 + 1 = 11111011</code>，即 <span class="math inline">251 = 256 − 5</span>。</p>
<p><strong>5. 补码的优势</strong></p>
<ul>
<li><strong>唯一零表示</strong>：补码中只有
<strong>一个零</strong>（<code>00000000</code>），而原码和反码存在
<code>+0</code> 和 <code>-0</code> 的问题。</li>
<li><strong>加减统一</strong>：所有加减运算均通过加法器完成，无需单独的减法器。<br>
例如：<code>5 - 3 = 5 + (-3)</code>，直接通过补码相加即可。</li>
<li><strong>溢出自动处理</strong>：超过范围的高位会自然丢弃（模运算特性）。</li>
</ul>
<p><strong>6. 特殊情况：最小负数</strong></p>
<p>对于 <strong>n位补码</strong>，能表示的范围是：<br>
<span class="math display">[−2<sup><em>n</em> − 1</sup>, 2<sup><em>n</em> − 1</sup> − 1]</span>
- 例如，8位补码范围是：<code>-128</code>（<code>10000000</code>）到
<code>+127</code>（<code>01111111</code>）。 -
<strong>最小负数（-128）</strong> 没有对应的正数（因为 <span class="math inline">+128</span> 超出范围），其补码直接定义为
<code>10000000</code>，无法通过“取反 + 1”从原码推导（因为原码中不存在
<code>+128</code>）。</p>
<h4 id="移码offset-binary详解"><strong>移码（Offset
Binary）详解</strong></h4>
<p><strong>1. 移码的定义</strong></p>
<p>移码是一种<strong>带偏移量的编码方式</strong>，主要用于表示<strong>浮点数的阶码</strong>（Exponent）。其核心思想是将真值（实际数值）加上一个固定的偏移量（Bias），使得所有数值映射到<strong>非负数范围</strong>，从而简化比较和运算。</p>
<p><strong>公式</strong>：<br>
<span class="math display">移码 = 真值 + 偏移量</span></p>
<p><strong>2. 移码的核心作用</strong></p>
<ul>
<li><strong>简化比较</strong>：<br>
移码将负数范围映射到正数范围，使得可以直接通过<strong>无符号整数比较</strong>来判断阶码的大小。
<ul>
<li>例如：<br>
在浮点数中，阶码 <span class="math inline">−3</span> 和 <span class="math inline">+2</span> 的移码分别为 <span class="math inline">125</span> 和 <span class="math inline">130</span>（偏移量为127），直接比较 <span class="math inline">125 &lt; 130</span> 即可得出 <span class="math inline">−3 &lt; +2</span>。</li>
</ul></li>
<li><strong>消除负数表示</strong>：<br>
移码将负数转换为正数表示，避免了补码中负数符号位的影响。</li>
</ul>
<p><strong>3. 偏移量的选择</strong></p>
<p>偏移量通常为 <span class="math inline">2<sup><em>n</em> − 1</sup></span> 或 <span class="math inline">2<sup><em>n</em> − 1</sup> − 1</span>（<span class="math inline"><em>n</em></span> 为位数）： -
<strong>单精度浮点数（32位）</strong>：偏移量为 <span class="math inline">127</span>（即 <span class="math inline">2<sup>7</sup> − 1</span>）。<br>
- <strong>双精度浮点数（64位）</strong>：偏移量为 <span class="math inline">1023</span>（即 <span class="math inline">2<sup>10</sup> − 1</span>）。</p>
<p><strong>4. 移码与补码的关系</strong></p>
<ul>
<li><strong>符号位取反</strong>：<br>
移码可以看作是<strong>补码的符号位取反</strong>。例如：
<ul>
<li>补码 <code>10000000</code>（<span class="math inline">−128</span>）的移码为 <code>00000000</code>（<span class="math inline">−128 + 128 = 0</span>）。<br>
</li>
<li>补码 <code>00000000</code>（<span class="math inline">0</span>）的移码为 <code>10000000</code>（<span class="math inline">0 + 128 = 128</span>）。</li>
</ul></li>
<li><strong>本质区别</strong>：
<ul>
<li><strong>补码</strong>：用于定点数的加减运算，支持负数和正数的统一处理。<br>
</li>
<li><strong>移码</strong>：用于浮点数阶码的表示，便于直接比较大小。</li>
</ul></li>
</ul>
<p><strong>5. 移码的应用场景</strong></p>
<ul>
<li><strong>IEEE 754浮点数标准</strong>：<br>
移码用于表示浮点数的阶码（Exponent），使得阶码可以直接按无符号整数比较。
<ul>
<li><strong>单精度（32位）</strong>：<br>
阶码占8位，偏移量为127。<br>
真值 <span class="math inline"><em>E</em></span> 的移码为 <span class="math inline"><em>E</em> + 127</span>。<br>
</li>
<li><strong>双精度（64位）</strong>：<br>
阶码占11位，偏移量为1023。<br>
真值 <span class="math inline"><em>E</em></span> 的移码为 <span class="math inline"><em>E</em> + 1023</span>。</li>
</ul></li>
</ul>
<h4 id="浮点数表示">浮点数表示</h4>
<p><a href="https://www.bilibili.com/video/BV1VK4y1f7o6?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】2-4.浮点数(上)_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1Le4y137gU/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【计算机知识】定点数与浮点数（2）浮点数法表示方法！_哔哩哔哩_bilibili</a></p>
<h4 id="进制转换">进制转换</h4>
<p><a href="https://www.bilibili.com/video/BV1ke411T7Qr?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【计算机基础】进制转换(3)
小数部分如何进行转换？_哔哩哔哩_bilibili</a></p>
<h4 id="整数加减">整数加减</h4>
<h4 id="浮点数加减">浮点数加减</h4>
<p><a href="https://www.bilibili.com/video/BV1894y1C7br/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">浮点数加减法运算
白中英计算机组成原理期末速成_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1ue4y1s71Z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">(自用)计算机组成原理
题型三 浮点数加减法运算题_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1ej411J71a/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">浮点运算（浮点数加减运算）计算机组成原理（看了包会）_哔哩哔哩_bilibili</a></p>
<p>ieee</p>
<p><a href="https://www.bilibili.com/video/BV1nwTXz7EVi/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">计算机组成原理期末复习（5分钟）：IEEE754浮点数加减计算！_哔哩哔哩_bilibili</a></p>
<h4 id="位数">位数</h4>
<p>short 16位</p>
<h3 id="第三章-程序的转换与机器级表示"><strong>第三章
程序的转换与机器级表示</strong></h3>
<h4 id="结构体与联合体">结构体与联合体</h4>
<p><a href="https://www.bilibili.com/video/BV1754y1Y7Ut?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-9.结构体与联合体_哔哩哔哩_bilibili</a></p>
<h4 id="数组的分配和访问">数组的分配和访问</h4>
<p><a href="https://www.bilibili.com/video/BV1ho4y1d7J6?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-8.数组的分配和访问_哔哩哔哩_bilibili</a></p>
<h4 id="过程调用">过程调用</h4>
<p><a href="https://www.bilibili.com/video/BV1By4y1x7Yh/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">C程序在内存中的栈_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV19X4y1P7Pn?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-7.
过程（函数调用）_哔哩哔哩_bilibili</a></p>
<h4 id="att格式">AT&amp;T格式</h4>
<p>AT&amp;T格式是汇编语言中的一种语法风格，主要用于x86/x64架构的汇编代码编写。它与Intel格式并列为最常见的两种汇编语法，两者在语法细节上有显著差异。以下是AT&amp;T格式的核心特点、示例及常见用途：</p>
<p><strong>主要特点</strong></p>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 47%">
<col style="width: 36%">
</colgroup>
<thead>
<tr>
<th>特性</th>
<th>AT&amp;T格式语法</th>
<th>对比Intel格式语法</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>寄存器</strong></td>
<td>前缀 <code>%</code>（如 <code>%eax</code>）</td>
<td>无前缀（如 <code>eax</code>）</td>
</tr>
<tr>
<td><strong>立即数</strong></td>
<td>前缀 <code>$</code>（如 <code>$0x10</code>）</td>
<td>直接使用数值（如 <code>10</code>）</td>
</tr>
<tr>
<td><strong>操作数顺序</strong></td>
<td>源操作数在前，目标在后</td>
<td>目标在前，源在后</td>
</tr>
<tr>
<td><strong>内存寻址</strong></td>
<td><code>offset(base, index, scale)</code></td>
<td><code>[base + index*scale + offset]</code></td>
</tr>
<tr>
<td><strong>指令后缀</strong></td>
<td>通过后缀标明操作数大小（如 <code>l</code> 表示32位）</td>
<td>无后缀，由操作数推断</td>
</tr>
</tbody>
</table>
<h4 id="寄存器种类">寄存器种类</h4>
<ul>
<li>8 个通用寄存器，其中
<ul>
<li><code>EAX, EBX, ECX, EDX</code> 均为 32 位寄存器</li>
<li><code>AX, BX, CX, DX</code> 均为 16 位寄存器</li>
<li><code>AH, BH, CH, DH</code> 均为高 8 位寄存器</li>
<li><code>AL, BL, CL, DL</code> 均为低 8 位寄存器</li>
</ul></li>
<li>2 个专用寄存器</li>
<li>6 个段寄存器</li>
</ul>
<h4 id="操作数寻址方式">操作数寻址方式</h4>
<p><strong>1. 基础内存寻址模式</strong></p>
<p><strong>(1) 直接寻址（Direct Addressing）</strong>
cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc</p>
<ul>
<li><strong>语法</strong>：<code>offset</code>（AT&amp;T格式）或
<code>[offset]</code>（Intel格式）。</li>
<li><strong>用途</strong>：直接访问全局变量或静态数据。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl var(%rip), %eax  # AT&amp;T格式（RIP相对寻址，64位模式推荐）</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov eax, [var]        # Intel格式（32位模式）</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>(2) 寄存器间接寻址（Register Indirect
Addressing）</strong></p>
<ul>
<li><strong>语法</strong>：<code>(base_register)</code> 或
<code>[base_register]</code></li>
<li><strong>用途</strong>：指针解引用。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl (%eax), %ebx     # 将EAX指向的内存值传入EBX</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov ebx, [eax]</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>(3) 基址寻址（Base Addressing）</strong></p>
<ul>
<li><strong>语法</strong>：<code>offset(base_register)</code> 或
<code>[base_register + offset]</code></li>
<li><strong>用途</strong>：访问栈帧中的局部变量或结构体成员。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl 8(%ebp), %ecx    # 从栈帧偏移8处读取数据到ECX</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov ecx, [ebp + 8]</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>(4) 变址寻址（Indexed Addressing）比例寻址</strong></p>
<ul>
<li><p><strong>语法</strong>：<code>array(, index_register, scale)</code>
或 <code>[array + index_register*scale]</code></p></li>
<li><p><strong>用途</strong>：数组元素访问。</p></li>
<li><p><strong>示例</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl array(,%eax,4), %edx  # 数组array + EAX*4位置的值传入EDX（数组索引）</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edx, [array + eax*4]</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>2. 组合寻址模式</strong></p>
<p><strong>(1) 基址 + 变址（Base + Index）</strong></p>
<ul>
<li><p><strong>语法</strong>：<code>(base_register, index_register)</code>
或 <code>[base_register + index_register]</code></p></li>
<li><p><strong>用途</strong>：访问二维数组或动态分配的数组。</p></li>
<li><p><strong>示例</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl (%ebx, %esi), %edi  # 将EBX + ESI指向的内存值传入EDI</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edi, [ebx + esi]</span><br></pre></td></tr></table></figure></li>
</ul>
<p>**(2) 基址 + 比例变址（Base + Index*Scale）**</p>
<ul>
<li><strong>语法</strong>：<code>(base_register, index_register, scale)</code>
或 <code>[base_register + index_register*scale]</code></li>
<li><strong>用途</strong>：按元素大小（scale）访问数组。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl (%ebx, %esi, 4), %edi  # 将EBX + ESI*4指向的内存值传入EDI（4字节元素）</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edi, [ebx + esi*4]</span><br></pre></td></tr></table></figure></li>
</ul>
<p>**(3) 基址 + 比例变址 + 偏移（Base + Index*Scale + Offset）**</p>
<ul>
<li><strong>语法</strong>：<code>offset(base_register, index_register, scale)</code>
或 <code>[base_register + index_register*scale + offset]</code></li>
<li><strong>用途</strong>：访问结构体数组或复杂数据结构。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl 12(%ebx, %esi, 8), %edi  # 结构体数组中第ESI个元素的偏移12处数据传入EDI</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edi, [ebx + esi*8 + 12]</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>3.总结</strong></p>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 28%">
<col style="width: 43%">
</colgroup>
<thead>
<tr>
<th>寻址模式</th>
<th>AT&amp;T格式语法</th>
<th>Intel格式语法</th>
</tr>
</thead>
<tbody>
<tr>
<td>直接寻址</td>
<td><code>var(%rip)</code></td>
<td><code>[rip + var]</code>（64位）或 <code>var</code></td>
</tr>
<tr>
<td>寄存器间接寻址</td>
<td><code>(%eax)</code></td>
<td><code>[eax]</code></td>
</tr>
<tr>
<td>基址寻址</td>
<td><code>8(%ebp)</code></td>
<td><code>[ebp + 8]</code></td>
</tr>
<tr>
<td>变址寻址</td>
<td><code>array(,%eax,4)</code></td>
<td><code>[array + eax*4]</code></td>
</tr>
<tr>
<td>基址+比例变址</td>
<td><code>(%ebx, %esi, 4)</code></td>
<td><code>[ebx + esi*4]</code></td>
</tr>
<tr>
<td>基址+比例变址+偏移</td>
<td><code>12(%ebx, %esi, 8)</code></td>
<td><code>[ebx + esi*8 + 12]</code></td>
</tr>
</tbody>
</table>
<h4 id="指令后缀">指令后缀</h4>
<p>在 AT&amp;T 汇编格式中，<strong>指令后缀</strong>（如
<code>b</code>、<code>w</code>、<code>l</code>、<code>q</code>）用于明确操作数的大小，确保汇编器正确生成机器码。判断后缀的核心规则是：<strong>根据操作数的大小选择对应的后缀</strong>，尤其是寄存器的位数或内存操作数的显式指定。以下是详细说明：</p>
<p><strong>后缀与操作数大小的对应关系</strong></p>
<table>
<thead>
<tr>
<th>后缀</th>
<th>操作数大小</th>
<th>示例寄存器/操作数</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>b</code></td>
<td>byte（8位）</td>
<td><code>%al</code>, <code>$0x10</code>,
<code>12(%ebp)</code>（需显式指定）</td>
</tr>
<tr>
<td><code>w</code></td>
<td>word（16位）</td>
<td><code>%ax</code>, <code>%bx</code>,
<code>12(%ebp)</code>（需显式指定）</td>
</tr>
<tr>
<td><code>l</code></td>
<td>long（32位）</td>
<td><code>%eax</code>, <code>%ebx</code>,
<code>12(%ebp)</code>（需显式指定）</td>
</tr>
<tr>
<td><code>q</code></td>
<td>quad（64位）</td>
<td><code>%rax</code>, <code>%rbx</code>,
<code>12(%ebp)</code>（需显式指定）</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>立即数默认为32位</strong></p>
</blockquote>
<h4 id="判断指针与临时变量">判断“指针”与“临时变量</h4>
<p><strong>（1）<code>%edx</code>：临时变量</strong></p>
<ul>
<li><strong>特征</strong>：直接从寄存器 <code>%edx</code>
读取数据，不涉及内存地址的间接访问。</li>
<li><strong>对应C语言</strong>：<br>
如果 <code>%edx</code> 存储的是某个局部变量或计算结果（如
<code>temp = a + b</code>），则对应<strong>临时变量</strong>。</li>
</ul>
<p><strong>（2）<code>(%ecx)</code>：指针</strong></p>
<ul>
<li><strong>特征</strong>：<code>%ecx</code>
中存储的是内存地址，<code>(%ecx)</code> 表示解引用该地址（类似C语言的
<code>*ptr</code>）。<br>
</li>
<li><strong>对应C语言</strong>：<br>
如果 <code>%ecx</code> 存储的是一个指针变量（如
<code>int *ptr</code>），则 <code>(%ecx)</code>
对应<strong>指针解引用</strong>。</li>
</ul>
<p><strong>关键结论</strong></p>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 78%">
</colgroup>
<thead>
<tr>
<th>操作数</th>
<th>类型</th>
<th>判断依据</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>%edx</code></td>
<td>临时变量</td>
<td>直接从寄存器读取数据，无间接内存访问（无括号）。</td>
</tr>
<tr>
<td><code>(%ecx)</code></td>
<td>指针</td>
<td>使用括号 <code>(%ecx)</code> 表示解引用内存地址（类似C语言的
<code>*ptr</code>）。</td>
</tr>
</tbody>
</table>
<p><strong>常见模式对比</strong></p>
<table>
<colgroup>
<col style="width: 24%">
<col style="width: 17%">
<col style="width: 58%">
</colgroup>
<thead>
<tr>
<th>汇编指令</th>
<th>C语言对应操作</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>movl %eax, (%ebx)</code></td>
<td><code>*ptr = temp;</code></td>
<td><code>%ebx</code> 是指针（存储地址），<code>%eax</code>
是临时变量。</td>
</tr>
<tr>
<td><code>movl (%ebx), %eax</code></td>
<td><code>temp = *ptr;</code></td>
<td>从指针 <code>ptr</code> 读取值到临时变量 <code>temp</code>。</td>
</tr>
<tr>
<td><code>movl $0x1, %eax</code></td>
<td><code>temp = 1;</code></td>
<td><code>%eax</code> 是临时变量，直接赋值。</td>
</tr>
</tbody>
</table>
<h4 id="汇编语言中m的作用">汇编语言中M的作用</h4>
<p>在汇编语言中，<strong>M</strong> 通常表示
<strong>内存（Memory）</strong>，用于指示操作数来自内存地址。在你的问题中，<code>M[R[eax]]</code>
的含义是：</p>
<p><strong><code>M</code> 的作用</strong></p>
<ul>
<li><strong><code>M[地址]</code></strong> 表示从 <strong>内存地址为
<code>地址</code> 的位置读取数据</strong>。</li>
<li><strong><code>R[eax]</code></strong> 表示寄存器 <code>EAX</code>
的值（即 <code>EAX</code> 中存储的内容）。</li>
<li>因此，<code>M[R[eax]]</code> 的含义是： &gt; <strong>以
<code>EAX</code>
寄存器的值作为内存地址，从该地址读取数据</strong>。</li>
</ul>
<p>** AT&amp;T 汇编中的等价写法**</p>
<p>在 AT&amp;T 汇编语法中，<code>M[R[eax]]</code> 对应的写法是：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">addl (%eax), %edx</span><br></pre></td></tr></table></figure> - <strong>含义</strong>： - <code>(%eax)</code>：以
<code>EAX</code> 的值为内存地址，读取该地址的内容（默认是 4 字节，即 32
位）。 - <code>addl</code>：执行 32 位加法。 -
<code>%edx</code>：目标寄存器，存储结果。</p>
<p><strong>关键点总结</strong></p>
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>R</code></td>
<td>寄存器（Register）</td>
<td><code>R[eax]</code> → <code>EAX</code> 的值</td>
</tr>
<tr>
<td><code>M</code></td>
<td>内存（Memory）</td>
<td><code>M[地址]</code> → 从地址读取数据</td>
</tr>
<tr>
<td><code>()</code></td>
<td>AT&amp;T 汇编中表示内存寻址</td>
<td><code>(%eax)</code> → 等价于 <code>M[R[eax]]</code></td>
</tr>
</tbody>
</table>
<h4 id="常见att格式汇编指令">常见AT&amp;T格式汇编指令</h4>
<table>
<colgroup>
<col style="width: 12%">
<col style="width: 15%">
<col style="width: 28%">
<col style="width: 43%">
</colgroup>
<thead>
<tr>
<th>指令类型</th>
<th>操作目的</th>
<th>影响标志位</th>
<th>典型用途</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>addl</code></td>
<td>加法</td>
<td>OF, SF, ZF, CF</td>
<td>数值运算、地址偏移</td>
</tr>
<tr>
<td><code>subl</code></td>
<td>减法</td>
<td>OF, SF, ZF, CF</td>
<td>数值运算、条件判断</td>
</tr>
<tr>
<td><code>orl</code></td>
<td>按位或</td>
<td>OF=0, SF, ZF, CF=0</td>
<td>位掩码操作</td>
</tr>
<tr>
<td><code>testl</code></td>
<td>按位与测试</td>
<td>OF=0, SF, ZF, CF=0</td>
<td>条件判断（如检查位是否设置）</td>
</tr>
<tr>
<td><code>imull</code></td>
<td>有符号乘法</td>
<td>OF, CF</td>
<td>数值运算</td>
</tr>
<tr>
<td><code>leal</code></td>
<td>地址计算</td>
<td>无影响</td>
<td>高效数组索引计算</td>
</tr>
<tr>
<td><code>decl</code></td>
<td>递减</td>
<td>OF, SF, ZF, CF</td>
<td>循环计数、边界检查</td>
</tr>
</tbody>
</table>
<p><strong><code>sall</code>（Shift Arithmetic Left）——
左移指令</strong></p>
<p><strong>功能</strong></p>
<ul>
<li><strong>作用</strong> ：将操作数的二进制位 <strong>向左移动</strong>
指定的位数，低位补0。</li>
<li><strong>效果</strong> ：相当于将操作数乘以 2<em>n</em> （n
为移动的位数）。</li>
</ul>
<p><strong><code>and</code>（Logical AND）—— 逻辑与指令</strong></p>
<p><strong>功能</strong></p>
<ul>
<li><strong>作用</strong> ：对两个操作数进行 <strong>按位与运算</strong>
，结果写入目标操作数。</li>
<li><strong>效果</strong> ：只有对应位都为1时，结果位才为1。</li>
</ul>
<p><code>shrl</code> 是 <strong>逻辑右移指令</strong> （Shift Right
Logical），用于对操作数进行 <strong>无符号右移</strong> ，即高位补
0，低位移出。</p>
<p><code>leal</code> 是 <strong>加载有效地址（Load Effective
Address）</strong> 的指令，其功能是
<strong>计算内存地址并存储到目标寄存器</strong> ，但
<strong>不会访问内存</strong> 。它常用于 <strong>地址计算</strong> 和
<strong>高效算术运算</strong></p>
<h4 id="标志位">标志位</h4>
<p>以下是 <strong>x86/x64
架构中常见的四个状态标志位</strong>（OF、SF、ZF、CF）的详细说明及其判断方法：</p>
<p><strong>1. 标志位概述</strong></p>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 16%">
<col style="width: 75%">
</colgroup>
<thead>
<tr>
<th>标志</th>
<th>全称</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CF</strong></td>
<td>Carry Flag</td>
<td><strong>无符号溢出标志</strong>：表示无符号数运算是否产生进位或借位。</td>
</tr>
<tr>
<td><strong>ZF</strong></td>
<td>Zero Flag</td>
<td><strong>零标志</strong>：表示运算结果是否为零。</td>
</tr>
<tr>
<td><strong>SF</strong></td>
<td>Sign Flag</td>
<td><strong>符号标志</strong>：表示运算结果的最高位（符号位）是否为1（负数）。</td>
</tr>
<tr>
<td><strong>OF</strong></td>
<td>Overflow Flag</td>
<td><strong>溢出标志</strong>：表示有符号数运算是否溢出（结果超出数据类型表示范围）。</td>
</tr>
</tbody>
</table>
<p><strong>2. 判断方法详解</strong></p>
<p><strong>(1) 进位标志（CF）</strong></p>
<ul>
<li><strong>用途</strong>：判断 <strong>无符号数运算</strong>
是否溢出。</li>
<li><strong>判断规则</strong>：
<ul>
<li><strong>加法</strong>：若结果最高位（最高有效位）发生进位（超过数据类型的最大值），CF=1。</li>
<li><strong>减法</strong>：若结果需要借位（被减数 &lt;
减数），CF=1。</li>
</ul></li>
</ul>
<p><strong>(2) 零标志（ZF）</strong></p>
<ul>
<li><strong>用途</strong>：判断运算结果是否为零。</li>
<li><strong>判断规则</strong>：
<ul>
<li><strong>结果为0</strong> → ZF=1</li>
<li><strong>结果非0</strong> → ZF=0</li>
</ul></li>
</ul>
<p><strong>(3) 符号标志（SF）</strong></p>
<ul>
<li><strong>用途</strong>：表示运算结果的符号（正/负）。</li>
<li><strong>判断规则</strong>：
<ul>
<li><strong>结果最高位为1</strong>（负数）→ SF=1</li>
<li><strong>结果最高位为0</strong>（正数）→ SF=0</li>
</ul></li>
</ul>
<p><strong>(4) 溢出标志（OF）</strong></p>
<ul>
<li><strong>用途</strong>：判断 <strong>有符号数运算</strong>
是否溢出。</li>
<li><strong>判断规则</strong>：
<ul>
<li><strong>溢出条件</strong>：两个正数相加结果为负，或两个负数相加结果为正
→ OF=1。</li>
<li><strong>无溢出</strong>：其他情况 → OF=0。</li>
</ul></li>
</ul>
<h4 id="栈帧布局和参数偏移计算规则">栈帧布局和参数偏移计算规则</h4>
<p><a href="https://www.bilibili.com/video/BV1sV411b7c1/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-3.栈与数据传送指令_哔哩哔哩_bilibili</a></p>
<p><strong>1. 参数压栈顺序</strong></p>
<p>C语言默认使用 <strong><code>cdecl</code>
调用约定</strong>，参数<strong>从右到左</strong>压入栈中。例如，函数调用
<code>operate(x, y, z, k)</code> 的压栈顺序为： <figure class="highlight c"><table><tr><td class="code"><pre><span class="line">push k;     <span class="comment">// 第四个参数（最右边）</span></span><br><span class="line">push z;     <span class="comment">// 第三个参数</span></span><br><span class="line">push y;     <span class="comment">// 第二个参数</span></span><br><span class="line">push x;     <span class="comment">// 第一个参数（最左边）</span></span><br><span class="line">call operate;</span><br></pre></td></tr></table></figure>
栈中参数布局（高地址 → 低地址）： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">高地址</span><br><span class="line">| k  (参数4) | ← 栈顶（ESP）</span><br><span class="line">| z  (参数3) |</span><br><span class="line">| y  (参数2) |</span><br><span class="line">| x  (参数1) |</span><br><span class="line">| 返回地址   |</span><br><span class="line">低地址</span><br></pre></td></tr></table></figure></p>
<p><strong>2. 栈帧建立过程</strong></p>
<p>进入函数 <code>operate</code> 后，通过以下指令建立栈帧：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pushl %ebp        ; 保存旧的EBP（栈帧基址）</span><br><span class="line">movl %esp, %ebp   ; 将当前栈顶（ESP）赋值给EBP，作为新栈帧的基址</span><br></pre></td></tr></table></figure> 此时栈帧布局如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">高地址</span><br><span class="line">| k  (参数4) | ← EBP + 20</span><br><span class="line">| z  (参数3) | ← EBP + 16</span><br><span class="line">| y  (参数2) | ← EBP + 12</span><br><span class="line">| x  (参数1) | ← EBP + 8</span><br><span class="line">| 返回地址   | ← EBP + 4</span><br><span class="line">| 旧 EBP     | ← EBP</span><br><span class="line">低地址</span><br></pre></td></tr></table></figure></p>
<p><strong>3. 参数地址的计算逻辑</strong></p>
<ul>
<li><strong><code>EBP + 4</code></strong>：返回地址（由
<code>call</code> 指令自动压栈）。<br>
</li>
<li><strong><code>EBP + 8</code></strong>：第一个参数（<code>x</code>）。<br>
</li>
<li><strong><code>EBP + 12</code></strong>：第二个参数（<code>y</code>）。<br>
</li>
<li><strong><code>EBP + 16</code></strong>：第三个参数（<code>z</code>）。<br>
</li>
<li><strong><code>EBP + 20</code></strong>：第四个参数（<code>k</code>）。</li>
</ul>
<p><strong>原因</strong>：<br>
1.
<strong>参数顺序</strong>：参数从右到左压栈，导致第一个参数（<code>x</code>）位于栈的最低地址（<code>EBP + 8</code>），而第四个参数（<code>k</code>）位于最高地址（<code>EBP + 20</code>）。<br>
2. <strong>偏移计算</strong>：每个参数占用4字节（32位系统中
<code>int</code> 和指针大小），因此偏移量依次递增4。<br>
3. <strong>栈帧基址</strong>：<code>EBP</code> 指向旧的 <code>EBP</code>
值，其上方是返回地址（<code>EBP + 4</code>），再上方是参数。</p>
<h4 id="汇编语言表示程序函数的过程调用">汇编语言表示程序函数的过程调用</h4>
<p><a href="https://www.bilibili.com/video/BV1Nt4y1G728/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">超硬核！408考研重点！汇编语言表示程序函数的过程调用！23王道计算机组成原理指令系统_哔哩哔哩_bilibili</a></p>
<h4 id="反汇编">反汇编</h4>
<p>反汇编代码是将二进制机器码（如可执行文件、内存转储）转换为
<strong>人类可读的汇编指令</strong>
的结果。它是逆向工程、漏洞分析、调试等领域的核心工具。以下是详细说明：</p>
<p><strong>1. 反汇编代码的定义</strong></p>
<ul>
<li><strong>本质</strong>：将机器码（二进制/十六进制）转换为对应的汇编指令。</li>
<li><strong>作用</strong>：帮助开发者理解程序逻辑、分析恶意软件、调试崩溃原因或研究编译器优化。</li>
</ul>
<p><strong>2. 反汇编代码的典型格式</strong></p>
<p>反汇编代码通常包含以下部分： | <strong>字段</strong> |
<strong>说明</strong> | <strong>示例</strong> | | ————————- |
————————————————– | —————————- | | <strong>地址（Address）</strong> |
指令在内存中的地址（十六进制）。 | <code>0x804838c</code> | |
<strong>机器码（Opcode）</strong> |
对应的原始十六进制机器码（机器指令的二进制表示）。 | <code>74 08</code>
| | <strong>汇编指令（Mnemonic）</strong> | 汇编助记符（如
<code>mov</code>, <code>jmp</code>, <code>call</code>）及操作数。 |
<code>je 0x8048396</code> | | <strong>注释（Comment, 可选）</strong> |
开发者添加的注释（某些工具会自动生成符号信息）。 |
<code>; if (eax == 0) goto label</code> |</p>
<p><strong>示例反汇编代码（AT&amp;T格式）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0804838c &lt;main&gt;:</span><br><span class="line">804838c:    74 08                   je     8048396 &lt;main+0xa&gt;</span><br><span class="line">804838e:    b8 00 00 00 00          mov    $0x0, %eax</span><br><span class="line">8048393:    e9 0e 00 00 00          jmp    80483a6 &lt;main+0x1a&gt;</span><br></pre></td></tr></table></figure>
<h4 id="大端小端">大端小端</h4>
<p><strong>小端方式（Little-Endian）</strong> 是一种
<strong>数据在内存中的存储顺序</strong>，其核心特点是： &gt;
<strong>数据的低位字节（LSB, Least Significant
Byte）存储在内存的低地址处，高位字节（MSB, Most Significant
Byte）存储在高地址处</strong>。</p>
<p><strong>1. 小端 vs 大端</strong></p>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 42%">
<col style="width: 42%">
</colgroup>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>小端（Little-Endian）</strong></th>
<th><strong>大端（Big-Endian）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>存储顺序</strong></td>
<td>低位字节在前（低地址），高位在后</td>
<td>高位字节在前（低地址），低位在后</td>
</tr>
<tr>
<td><strong>示例</strong></td>
<td><code>0x12345678</code> → 存储为 <code>78 56 34 12</code></td>
<td><code>0x12345678</code> → 存储为 <code>12 34 56 78</code></td>
</tr>
<tr>
<td><strong>常见平台</strong></td>
<td>x86/x64 架构（Intel/AMD 处理器）</td>
<td>ARM（部分模式）、网络协议（TCP/IP）</td>
</tr>
</tbody>
</table>
<p><strong>2. 小端方式的直观理解</strong></p>
<p><strong>示例：32位整数 <code>0x12345678</code></strong></p>
<ul>
<li><strong>内存地址分配</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">地址 →    0x1000    0x1001    0x1002    0x1003</span><br><span class="line">         +---------+---------+---------+---------+</span><br><span class="line">         |  0x78   |  0x56   |  0x34   |  0x12   |</span><br><span class="line">         +---------+---------+---------+---------+</span><br></pre></td></tr></table></figure></li>
<li><strong>解释</strong>：
<ul>
<li>数据的最低位字节 <code>0x78</code> 存储在最低地址
<code>0x1000</code>。</li>
<li>高位字节 <code>0x12</code> 存储在最高地址 <code>0x1003</code>。</li>
</ul></li>
</ul>
<h4 id="转移目标地址的计算">转移目标地址的计算</h4>
<p>在 IA-32（x86）架构中，<strong>转移目标地址的计算</strong>依赖于
<strong>指令的长度</strong> 和
<strong>相对偏移量（Displacement）</strong>。以下是详细分析：</p>
<p><strong>1. 转移指令的基本原理</strong></p>
<ul>
<li><strong>相对跳转（Relative Jump）</strong>：转移目标地址 =
<strong>下一条指令地址</strong> + <strong>偏移量</strong>。</li>
<li><strong>偏移量</strong>：有符号的 8 位、16 位或 32 位整数，表示从
<strong>下一条指令地址</strong> 开始的偏移（正向或负向）。</li>
<li><strong>小端方式（Little-Endian）</strong>：多字节偏移量需按小端方式存储（低位字节在前）。</li>
</ul>
<p><strong>2. 示例：<code>call</code> 指令的地址计算</strong></p>
<p><strong>(1) 已知条件</strong></p>
<ul>
<li><strong>指令地址</strong>：<code>0x804838e</code>（<code>call</code>
指令的起始地址）。</li>
<li><strong>机器码</strong>：<code>E8 1E 00 00 00</code>。
<ul>
<li><code>E8</code> 是 <code>call</code> 的操作码。</li>
<li><code>1E 00 00 00</code> 是偏移量（小端方式存储）。</li>
</ul></li>
</ul>
<p><strong>(2) 计算步骤</strong></p>
<ol type="1">
<li><strong>确定指令长度</strong>：
<ul>
<li><code>call</code> 指令占 <strong>5 字节</strong>（1 字节操作码 + 4
字节偏移量）。</li>
</ul></li>
<li><strong>计算下一条指令地址</strong>：
<ul>
<li>下一条指令地址 = 当前指令地址 + 指令长度<br>
= <code>0x804838e + 5 = 0x8048393</code>。</li>
</ul></li>
<li><strong>解析偏移量</strong>：
<ul>
<li>偏移量字段为 <code>1E 00 00 00</code>（小端方式）→ 转换为大端顺序为
<code>0x0000001E</code>（十进制 30）。</li>
</ul></li>
<li><strong>计算转移目标地址</strong>：
<ul>
<li>转移目标地址 = 下一条指令地址 + 偏移量<br>
= <code>0x8048393 + 0x1E = 0x80483B1</code>。</li>
</ul></li>
</ol>
<p><strong>3. 核心公式</strong> <span class="math display">目标地址 = (当前指令地址 + 指令长度) + 偏移量</span>
- <strong>当前指令地址</strong>：指令的起始地址（如
<code>0x804838e</code>）。 -
<strong>指令长度</strong>：由操作码和操作数决定（如 <code>call</code> 占
5 字节）。 -
<strong>偏移量</strong>：从指令的操作数中提取并转换为有符号整数。</p>
<p><strong>9. 其他指令示例</strong></p>
<p><strong>(1) <code>je</code> 指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">804838c:    74 08                   je     0x8048396</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>当前地址</strong>：<code>0x804838c</code>。</li>
<li><strong>指令长度</strong>：2 字节。</li>
<li><strong>偏移量</strong>：<code>0x08</code>（单字节，无需反转）。</li>
<li><strong>目标地址</strong>：<code>0x804838c + 2 + 0x08 = 0x8048396</code>。</li>
</ul>
<p><strong>(2) <code>jmp</code> 指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">80483a4:    E9 F6 FF FF FF          jmp    0x804839f</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>当前地址</strong>：<code>0x80483a4</code>。</li>
<li><strong>指令长度</strong>：5 字节。</li>
<li><strong>偏移量</strong>：<code>F6 FF FF FF</code>（小端）→ 补码为
<code>-10</code>（十进制）。</li>
<li><strong>目标地址</strong>：<code>0x80483a4 + 5 + (-10) = 0x804839f</code>。</li>
</ul>
<h4 id="计算下一条指令地址"><strong>计算下一条指令地址</strong></h4>
<p>下一条指令地址=当前指令地址+当前指令长度</p>
<h3 id="第四章-程序的链接">第四章 程序的链接</h3>
<h4 id="重定位">重定位</h4>
<p><a href="https://www.bilibili.com/video/BV1JL411L7ku?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】7-6.
重定位_哔哩哔哩_bilibili</a></p>
<h4 id="其他">其他</h4>
<p><a href="https://www.bilibili.com/video/BV1oe411n72U/?spm_id_from=333.337.search-card.all.click">3分钟彻底理解链接器_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/gzxb1995/article/details/105088502">计算机系统基础摘记——程序的链接_引入链接的好处是什么-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1oS4y1T7Uf?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】7-5.
静态库的解析过程_哔哩哔哩_bilibili</a></p>
<h3 id="其他-1">其他</h3>
<p>gdb调试</p>
<p><a href="https://www.bilibili.com/video/BV1Sg41167B1/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">一分钟学会GDB程序调试_哔哩哔哩_bilibili</a></p>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV17K4y1N7Q2?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">深入理解计算机系统合集（周更中）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——广义表</title>
    <url>/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="数据结构广义表">数据结构——广义表</h1>
<h2 id="广义表的定义和相关概念">广义表的定义和相关概念</h2>
<p>广义表是线性表的推广，其中的元素可以是原子（即不可再分的基本数据项），也可以是子表。广义表的一些常用术语包括：
- <strong>长度</strong>：广义表的长度是其顶层元素的个数。 -
<strong>深度</strong>：广义表中元素嵌套的最大深度。 -
<strong>表头</strong>：广义表中的第一个元素。 -
<strong>表尾</strong>：去掉表头后剩下的部分。</p>
<h3 id="例子">例子</h3>
<ul>
<li><strong>A = ()</strong></li>
<li><strong>B = (a, b, c)</strong>c)`</li>
<li><strong>C = (a, (b, c, d), e)</strong></li>
<li><strong>D = (a, b, (e, f, g))</strong></li>
<li><strong>E = ((a, b), c, (d, e, (f, g)))</strong></li>
<li><strong>F = ((), ((), ()))</strong></li>
</ul>
<p>下表展示了图片中的几个广义表的长度、深度、表头和表尾的具体值：</p>
<table>
<thead>
<tr>
<th>广义表</th>
<th>长度</th>
<th>深度</th>
<th>表头</th>
<th>表尾</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>0</td>
<td>1</td>
<td>空</td>
<td>()</td>
</tr>
<tr>
<td>B</td>
<td>3</td>
<td>1</td>
<td>a</td>
<td>(b, c)</td>
</tr>
<tr>
<td>C</td>
<td>3</td>
<td>2</td>
<td>a</td>
<td>((b, c, d), e)</td>
</tr>
<tr>
<td>D</td>
<td>3</td>
<td>3</td>
<td>a</td>
<td>(b, (e, f, g))</td>
</tr>
<tr>
<td>E</td>
<td>4</td>
<td>3</td>
<td>(a, b)</td>
<td>(c, (d, e, (f, g)))</td>
</tr>
<tr>
<td>F</td>
<td>3</td>
<td>3</td>
<td>()</td>
<td>((), ((), ()))</td>
</tr>
</tbody>
</table>
<h2 id="广义表的存储结构">广义表的存储结构</h2>
<figure>
<img src="/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/IMG_20241021_153619-1729496219467-9.jpg" alt="IMG_20241021_153619">
<figcaption aria-hidden="true">IMG_20241021_153619</figcaption>
</figure>
<p>由于广义表中的每个元素可能是原子或子表，因此在广义表的存储结构中存在两类结点：</p>
<ol type="1">
<li><strong>原子节点</strong>：用于存储单个元素。</li>
<li><strong>子表节点</strong>：用于存储子表的指针。</li>
</ol>
<p>为了区分元素是原子还是子表，结构中还设置了一个标识域
<code>type</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">GListNodeType</span> &#123; ATOM, LIST &#125;; <span class="comment">// 结点类型：原子或子表</span></span><br></pre></td></tr></table></figure>
<p>当type值为1，说明存入原子的值；为2，说明存入子广义表的头指针</p>
<p>广义表定义如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">char</span> ElemType; <span class="comment">// 原子的类型定义为字符类型</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">GListNode</span> &#123;</span><br><span class="line">    GListNodeType type; <span class="comment">// 类型域，表示该节点是原子还是子表</span></span><br><span class="line">    <span class="keyword">union</span> &#123;</span><br><span class="line">        ElemType data; <span class="comment">// 如果是原子节点，则存储数据</span></span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">GListNode</span> *sublist; <span class="comment">// 如果是子表节点，则存储指向子表的指针</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">GListNode</span> *next; <span class="comment">// 指向下一个表节点的指针</span></span><br><span class="line">&#125; GListNode, *GList; <span class="comment">// GList 表示广义表的指针类型</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/IMG_20241021_154058-1729496523052-14.jpg" alt="IMG_20241021_154058">
<figcaption aria-hidden="true">IMG_20241021_154058</figcaption>
</figure>
<h2 id="代码">代码</h2>
<h3 id="求广义表长度">求广义表长度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 求广义表的长度</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">LengthGList</span><span class="params">(GList list)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> length = <span class="number">0</span>;</span><br><span class="line">    GList current = list;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        length++;</span><br><span class="line">        current = current-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> length;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="求广义表深度">求广义表深度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 求广义表的深度</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">DepthGList</span><span class="params">(GList list)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (list == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;  <span class="comment">// 空表深度为 1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> maxDepth = <span class="number">1</span>;</span><br><span class="line">    GList current = list;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;type == LIST) &#123;</span><br><span class="line">            <span class="type">int</span> sublistDepth = <span class="built_in">DepthGList</span>(current-&gt;value.sublist) + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (sublistDepth &gt; maxDepth) &#123;</span><br><span class="line">                maxDepth = sublistDepth;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        current = current-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> maxDepth;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="打印">打印</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 打印广义表</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintGList</span><span class="params">(GList list)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (list == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;()&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;(&quot;</span>);</span><br><span class="line">    GList current = list;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;type == ATOM) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, current-&gt;value.data);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (current-&gt;type == LIST) &#123;</span><br><span class="line">            <span class="built_in">PrintGList</span>(current-&gt;value.sublist);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;next != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;, &quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        current = current-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;)&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="线性表章节小结">线性表章节小结</h1>
<figure>
<img src="/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/IMG_20241021_155320.jpg" alt="IMG_20241021_155320">
<figcaption aria-hidden="true">IMG_20241021_155320</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——查找</title>
    <url>/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/</url>
    <content><![CDATA[<h2 id="查找的概念">查找的概念</h2>
<p><strong>查找(Searching)</strong>
：就是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素(
或记录)。</p>
<p><strong>查找表(Search Table)</strong>
：是由同一类型的数据元素(或记录)构成的集合。</p>
<p><strong>关键字(Key)</strong>
：数据元素中唯一标识该元素的某个数据项的值，使用基于关键字的查找，查找结果应该是唯一的。例如，在由一个学生元素构成的数据集合中，学生元素中“学号”这一数据项的值唯一地标识一名学生。</p>
<p><strong>静态查找表(Static Search Table)</strong>
：只作查找操作的查找表。 <strong>动态查找表(Dynamic Search
Table)</strong> ：
在查找过程中同时插入查找表中不存在的数据元素，或者从查找表中删除已经存在的某个数据元素。</p>
<p><strong>平均查找长度</strong>
：在查找过程中，一次查找的长度是指需要比较的关键字次数，而平均查找长度，则是所有查找过程中进行关键字的比较次数的平均值，其数学定义为<span class="math inline">$\ ASL=\sum_{i=1}^{n}P_iC_i$</span></p>
<p>式中，n是查找表的长度;P是查找第i个数据元素的概率，一般认为每个数据元素的查找概率相等，即P,=
1/n;C;是找到第i个数据元素所需进行的比较次数。平均查找长度是衡量查找算法效率的最主要的指标。</p>
<h2 id="顺序表查找">顺序表查找</h2>
<h3 id="顺序查找">顺序查找</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*有哨兵顺序查找*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Sequential_Search</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> n, <span class="type">int</span> key)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> i;</span><br><span class="line">	a[<span class="number">0</span>] = key;	<span class="comment">//设置a[0]为关键字，称之为“哨兵”</span></span><br><span class="line">	i = n;	<span class="comment">//循环从数组尾部开始</span></span><br><span class="line">	<span class="keyword">while</span>(a[i] != key)&#123;</span><br><span class="line">		i--;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> i;	<span class="comment">//返回0则说明查找失败</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这种在查找方向的尽头放置“哨兵”免去了在查找过程中每一次比较后都要判断查找位置是否越界的小技巧，看似与原先差别不大，但在总数据较多时，效率提高很大，是非常好的编码技巧。
上述顺序表查找时间复杂度是O (n) 。</p>
<h3 id="折半查找">折半查找</h3>
<p>当查找表是有序表时，可采用折半查找的方法。</p>
<p>算法思路：</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215134842077.png" alt="image-20241215134842077">
<figcaption aria-hidden="true">image-20241215134842077</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">Binary_Search</span><span class="params">(SeqList L, ElemType key)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> low = <span class="number">0</span>, high = L.length - <span class="number">1</span>, mid;</span><br><span class="line">	<span class="keyword">while</span>(low &lt;= high)&#123;</span><br><span class="line">		mid = (low + hight)/<span class="number">2</span>;	<span class="comment">//取中间位置</span></span><br><span class="line">		<span class="keyword">if</span>(L.elem[mid] == key)&#123;</span><br><span class="line">			<span class="keyword">return</span> mid;	<span class="comment">//查找成功返回所在位置</span></span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(L.elem[mid] &gt; key)&#123;</span><br><span class="line">			high = mid - <span class="number">1</span>;	<span class="comment">//从前半部分继续查找</span></span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			low = mid + <span class="number">1</span>;	<span class="comment">//从后半部分继续查找</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">-1</span>;	<span class="comment">//查找失败，返回-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215134858075.png" alt="image-20241215134858075">
<figcaption aria-hidden="true">image-20241215134858075</figcaption>
</figure>
<p>折半查找的过程可用二叉树来描述，称为判定树。</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215135512761.png" alt="image-20241215135512761">
<figcaption aria-hidden="true">image-20241215135512761</figcaption>
</figure>
<p>节点的树高代表该节点的查询次数</p>
<p>因此，长度为13的有序表进行折半查找的平均查找长度ASL=(1×1+2×2+3×4+4×6)/13
=41/13。</p>
<p>折半查找的时间复杂度为<span class="math inline"> <em>O</em>(log<sub>2</sub><em>n</em>)</span>，平均情况下比顺序查找的效率高。</p>
<h3 id="分块查找">分块查找</h3>
<p>为了减少索引项的个数，我们可以对数据集进行分块，使其分块有序，然后再对每一块建立一个索引项，从而减少索引项的个数。</p>
<p>分块有序，是把数据集的记录分成了若千块，并且这些块需要满足两个条件：</p>
<ul>
<li><p>块内无序：即每一块内的记录不要求有序。</p></li>
<li><p>块间有序：例如，要求第二块所有记录的关键字均要大于第一块中所有记录的关键字，第三块的所有记录的关键字均要大于第二块的所有记录关键字…因为只有块间有序，才有可能在查找时带来效率。</p></li>
</ul>
<p>对于分块有序的数据集，将每块对应一个索引项，
这种索引方法叫做分块索引。如下图所示，我们定义的分块索引的索引项结构分三个数据项：</p>
<ul>
<li><p>最大关键码：它存储每一块中的最大关键字，这样的好处就是可以使得在它之后的下一块中的最小关键字也能比这一块最大的关键字要大；</p></li>
<li><p>块长：存储了块中的记录个数，以便于循环时使用；</p></li>
<li><p>块首指针：用于指向块首数据元素的指针，便于开始对这一块中记录进行遍历。</p></li>
</ul>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/825a789b2d39804be6b9aede1bbc0ba1.png" alt="825a789b2d39804be6b9aede1bbc0ba1">
<figcaption aria-hidden="true">825a789b2d39804be6b9aede1bbc0ba1</figcaption>
</figure>
<p>在分块索引表中查找，就是分两步进行:
1.在分块索引表中查找要查关键字所在的块。由于分块索引表是块间有序的，因此很容易利用折半、插值等算法得到结果。例如在上图的数据集中查找62，我们可以很快可以从左上角的索引表中由57&lt;62&lt;96得到62在第三个块中。
2.根据块首指针找到相应的块，并在块中顺序查找关键码。</p>
<h2 id="树表的查找">树表的查找</h2>
<h3 id="二叉排序树">二叉排序树</h3>
<p>二叉排序树(也称二叉查找树)或者是一棵空树，或者是具有下列特性的二叉树:</p>
<ol type="1">
<li>若左子树非空，则<strong>左子树上所有结点的值均小于根结点的值</strong>。</li>
<li>若右子树非空，则<strong>右子树上所有结点的值均大于根结点的值</strong>。</li>
<li>左、右子树也分别是一棵二叉排序树。</li>
</ol>
<p>根据二叉排序树的定义，左子树结点值&lt;根结点值&lt;右子树结点值，所以对二叉排序树进行中序遍历，可以得到一个递增的有序序列。例如，下图所示二叉排序树的中序遍历序列为123468。</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/bec1d08d423a4860887667fb980dfbea.png" alt="bec1d08d423a4860887667fb980dfbea">
<figcaption aria-hidden="true">bec1d08d423a4860887667fb980dfbea</figcaption>
</figure>
<h4 id="二叉排序树的插入和建立">二叉排序树的插入和建立</h4>
<p>在一棵二叉排序树中插入值为系的结点的步骤如下：</p>
<p>①若二叉排序树为空，则生成值为k的新结点s，同时将新结点s作为根结点插入。</p>
<p>②若k小于根结点的值,则在根的左子树中插入值为k的结点。</p>
<p>③若k大于根结点的值,则在根的右子树中插入值为k的结点。</p>
<p>④若k等于根结点的值，表明二叉排序树中已有此关键字，则无需插入。</p>
<p>二叉排序树插入算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"> <span class="comment">//构造函数</span></span><br><span class="line"> <span class="built_in">BiNode</span>(<span class="type">int</span> k) : <span class="built_in">key</span>(k), <span class="built_in">lchild</span>(<span class="literal">nullptr</span>), <span class="built_in">rchild</span>(<span class="literal">nullptr</span>) &#123;&#125;;</span><br><span class="line"><span class="comment">// 递归插入函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Insert</span><span class="params">(BiNode*&amp; ptr, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (ptr == <span class="literal">nullptr</span>) &#123; <span class="comment">// 如果当前指针为空，插入新节点</span></span><br><span class="line">            ptr = <span class="keyword">new</span> <span class="built_in">BiNode</span>(k);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (k &lt; ptr-&gt;key) &#123; </span><br><span class="line">            <span class="built_in">Insert</span>(ptr-&gt;lchild, k); <span class="comment">// 递归插入到左子树</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (k &gt; ptr-&gt;key) &#123;</span><br><span class="line">            <span class="built_in">Insert</span>(ptr-&gt;rchild, k); <span class="comment">// 递归插入到右子树</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果k等于当前节点值，则不插入（BST通常不允许重复值）</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 插入值到BST</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Insert</span><span class="params">(<span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">Insert</span>(root, k);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>二叉排序树的建立</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 构造函数：利用数组 a[] 和大小 n 建立二叉排序树</span></span><br><span class="line">    <span class="built_in">BiSortTree</span>(<span class="type">int</span> a[], <span class="type">int</span> n) &#123;</span><br><span class="line">        root = <span class="literal">nullptr</span>; <span class="comment">// 初始化根节点为空</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">            <span class="built_in">Insert</span>(root, a[i]); <span class="comment">// 插入数组中的每个元素</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215144119644.png" alt="image-20241215144119644">
<figcaption aria-hidden="true">image-20241215144119644</figcaption>
</figure>
<h4 id="二叉排序树的查找过程">二叉排序树的查找过程</h4>
<p>根据二叉排序树的定义，在二叉排序树中查找给定值k的过程如下:</p>
<p>①若二叉排序树为空，则表明查找失败，返回空指针;否则，若给定值k等于根结点的值,则表明查找成功,返回根结点。</p>
<p>②若给定值k小于根结点的值,则继续在根的左子树中查找。</p>
<p>③若给定值k大于根结点的值,则继续在根的右子树中查找。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 非递归查找函数</span></span><br><span class="line">   <span class="function">BiNode* <span class="title">Search2</span><span class="params">(BiNode* ptr, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">while</span> (ptr) &#123;</span><br><span class="line">           <span class="keyword">if</span> (k == ptr-&gt;key) <span class="comment">// 找到目标节点</span></span><br><span class="line">               <span class="keyword">return</span> ptr;</span><br><span class="line">           <span class="keyword">else</span> <span class="keyword">if</span> (k &lt; ptr-&gt;key) <span class="comment">// 查找左子树</span></span><br><span class="line">               ptr = ptr-&gt;lchild;</span><br><span class="line">           <span class="keyword">else</span>                  <span class="comment">// 查找右子树</span></span><br><span class="line">               ptr = ptr-&gt;rchild;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="literal">nullptr</span>; <span class="comment">// 未找到</span></span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>若二叉排序树是<strong>平衡的(即形态均匀)</strong>，则进行查找的时间复杂度为<span class="math inline"> <em>O</em>(<em>l</em><em>o</em><em>g</em><sub>2</sub><em>n</em>)</span>;若退化为一棵单支树（最极端和最差的情况)，则其时间复杂度为<span class="math inline"> <em>O</em>(<em>n</em>)</span>。对于一般情况，其时间复杂度可以认为是<span class="math inline"> <em>O</em>(<em>l</em><em>o</em><em>g</em><sub>2</sub><em>n</em>)</span>。</p>
<h4 id="二叉排序树的删除">二叉排序树的删除</h4>
<p>二叉排序树的查找和插入都很简单，但是删除操作就要复杂一些，此时要删除的结点有三种情况：</p>
<ol type="1">
<li>叶子结点；</li>
<li>仅有左或右子树的结点；</li>
<li>左右子树都有的结点；</li>
</ol>
<p>前两种情况都很简单，第一种只需删除该结点不需要做其他操作；第二种删除后需让被删除结点的直接后继接替它的位置；<strong>复杂就复杂在第三种，此时我们需要遍历得到被删除结点的直接前驱或者直接后继来接替它的位置，然后再删除</strong>。</p>
<p>第三种情况如下图所示：</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/1fa9d70c1f0ef1ab673061a9c2e39a08.png" alt="1fa9d70c1f0ef1ab673061a9c2e39a08">
<figcaption aria-hidden="true">1fa9d70c1f0ef1ab673061a9c2e39a08</figcaption>
</figure>
<p>代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">若二叉排序树T中存在关键字等于key的数据元素时，则删除该数据元素结点，</span></span><br><span class="line"><span class="comment">并返回TRUE;否则返回FALSE</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">DeleteBST</span><span class="params">(BiTree *T, <span class="type">int</span> key)</span></span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(!T)&#123;</span><br><span class="line">		<span class="keyword">return</span> FALSE; </span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		<span class="keyword">if</span>(key == T-&gt;data)&#123;</span><br><span class="line">			<span class="comment">//找到关键字等于key的数据元素</span></span><br><span class="line">			<span class="keyword">return</span> <span class="built_in">Delete</span>(T);</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(key &lt; T -&gt; data)&#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="built_in">DeleteBST</span>(T -&gt; lchild, key);</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="built_in">DeleteBST</span>(T -&gt; rchild, key);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面是Delete()方法：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*从二叉排序树中删除结点p，并重接它的左或右子树。*/</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Delete</span><span class="params">(BiTree *p)</span></span>&#123;</span><br><span class="line">	BiTree q, s;</span><br><span class="line">	<span class="keyword">if</span>(p-&gt;rchild == <span class="literal">NULL</span>)&#123;</span><br><span class="line">		<span class="comment">//右子树为空则只需重接它的左子树</span></span><br><span class="line">		q = p;</span><br><span class="line">		p = p-&gt;lchild;</span><br><span class="line">		<span class="built_in">free</span>(q);</span><br><span class="line">	&#125;<span class="keyword">else</span> <span class="keyword">if</span>(p-&gt;lchild == <span class="literal">NULL</span>)&#123;</span><br><span class="line">		<span class="comment">//左子树为空则只需重接它的右子树</span></span><br><span class="line">		q = p;</span><br><span class="line">		p = p-&gt;rchild;</span><br><span class="line">		<span class="built_in">free</span>(q);</span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		<span class="comment">//左右子树均不空</span></span><br><span class="line">		q = p;</span><br><span class="line">		s = p-&gt;lchild;	<span class="comment">//先转左</span></span><br><span class="line">		<span class="keyword">while</span>(s-&gt;rchild)&#123;<span class="comment">//然后向右到尽头，找待删结点的前驱</span></span><br><span class="line">			q = s;</span><br><span class="line">			s = s-&gt;rchild;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//此时s指向被删结点的直接前驱，p指向s的父母节点</span></span><br><span class="line">		p-&gt;data = s-&gt;data;	<span class="comment">//被删除结点的值替换成它的直接前驱的值</span></span><br><span class="line">		<span class="keyword">if</span>(q != p)&#123;</span><br><span class="line">			q-&gt;rchild = s-&gt;lchild;	<span class="comment">//重接q的右子树</span></span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			q-&gt;lchild = s-&gt;lchild;	<span class="comment">//重接q的左子树</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="built_in">pree</span>(s);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> TRUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>二叉排序树的查找性能取决于二叉排序树的形状</strong>。</p>
<p>例如{ 62 , 88 , 58 , 47 , 35 , 73 , 51 , 99 , 37 , 93 }
{62,88,58,47,35,73,51,99,37,93}{62,88,58,47,35,73,51,99,37,93}这样的数组，我们可以构建如下左图的二叉排序树。但如果数组元素的次序是从小到大有序，如{35,37,47,51,58,62,73,88,93,99},则二叉排序树就成了极端的右斜树，如下面右图的二叉排序树：
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/f33a1ebf98e14082fb0df30072964e09.png" alt="f33a1ebf98e14082fb0df30072964e09"></p>
<p>也就是说，我们希望二叉排序树是比较平衡的，即其深度与完全二叉树相同，那么查找的时间复杂也就为<span class="math inline"> <em>O</em>(log<sub>2</sub><em>n</em>)</span>，近似于折半查找。
不平衡的最坏情况就是像上面右图的斜树，查找时间复杂度为O(n)，这等同于顺序查找。
因此，如果我们希望对一个集合按二叉排序树查找，最好是把它构建成一棵<strong>平衡的二叉排序树</strong>。</p>
<h3 id="平衡二叉树">平衡二叉树</h3>
<p><strong>平衡二叉树</strong>：<strong>是一种二叉排序树，其中每一个节点的左子树和右子树的高度差至多等于1。</strong></p>
<p>我们<strong>将二叉树上结点的左子树深度减去右子树深度的值称为平衡因子BF</strong></p>
<p>那么平衡二叉树上所有结点的平衡因子只可能是-1、0和1。只要二叉树上有一个结点的平衡因子的绝对值大于1，则该二叉树就是不平衡的。</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/a1f704e077a99af5d0e5491cfbd18b50.png" alt="a1f704e077a99af5d0e5491cfbd18b50">
<figcaption aria-hidden="true">a1f704e077a99af5d0e5491cfbd18b50</figcaption>
</figure>
<h4 id="平衡二叉树的插入">平衡二叉树的插入</h4>
<p>新结点插入后，若造成查找路径上的某个结点不再平衡，则需要做出相应的调整。可将调整的规律归纳为下列4种情况：</p>
<ol type="1">
<li><strong>LL平衡旋转(右单旋转)</strong>:由于在结点A的左孩子(L)的左子树(L)上插入了新结点</li>
</ol>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/c1f0364ace56db6d49fe314233364370.png" alt="c1f0364ace56db6d49fe314233364370">
<figcaption aria-hidden="true">c1f0364ace56db6d49fe314233364370</figcaption>
</figure>
<ol start="2" type="1">
<li><strong>RR平衡旋转(左单旋转)</strong>:由于在结点A的右孩子(R)的右子树(R)上插入了
新结点</li>
</ol>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/741cd35f51fbb8eab58cd2dbb8988875.png" alt="741cd35f51fbb8eab58cd2dbb8988875">
<figcaption aria-hidden="true">741cd35f51fbb8eab58cd2dbb8988875</figcaption>
</figure>
<ol start="3" type="1">
<li><strong>LR平衡旋转(先左后右双旋转)</strong>:由于在A的左孩子(L)的右子树(R)上插入新结点</li>
</ol>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/53cabfa17150d6a0c98b467098d6379d.png" alt="53cabfa17150d6a0c98b467098d6379d">
<figcaption aria-hidden="true">53cabfa17150d6a0c98b467098d6379d</figcaption>
</figure>
<ol start="4" type="1">
<li><strong>RL平衡旋转(先右后左双旋转)</strong>:由于在A的右孩子(R)的左子树(L)上插入新结点</li>
</ol>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/fcb6dda8bd30d25a55cab887fb332c04.png" alt="fcb6dda8bd30d25a55cab887fb332c04">
<figcaption aria-hidden="true">fcb6dda8bd30d25a55cab887fb332c04</figcaption>
</figure>
<p>举例</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215152052099.png" alt="image-20241215152052099">
<figcaption aria-hidden="true">image-20241215152052099</figcaption>
</figure>
<h3 id="b树">B树</h3>
<p>B树，又称多路平衡查找树，B树中所有结点的孩子个数的最大值称为B树的阶，通常用m表示。
<strong>B树是所有结点的平衡因子均等于0的多路平衡查找树。</strong></p>
<p>下图所示的B树中所有结点的最大孩子数m = 5，因此它是一棵5阶B树，在m
mm阶B树中结点最多可以有m个孩子。可以借助该实例来分析上述性质： <img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/91938989f25f6c683f053d6b71647591.png" alt="91938989f25f6c683f053d6b71647591"></p>
<p><a href="https://www.bilibili.com/video/BV1JU411d7iY?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">B树(B-树)
- 删除_哔哩哔哩_bilibili</a></p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/Real_Fool_/article/details/114359564">数据结构：查找(Search)【详解】_index.search返回什么结构-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——循环队列</title>
    <url>/2024/10/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[<h1 id="数据结构循环队列">数据结构——循环队列</h1>
<h2 id="思考">思考</h2>
<figure>
<img src="/2024/10/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97/IMG_20241015_235239-1729007863179-13.jpg" alt="IMG_20241015_235239">
<figcaption aria-hidden="true">IMG_20241015_235239</figcaption>
</figure>
<p>头指针<code>front</code>指向的位置为队列头元素的前一个位置</p>
<p>尾指针<code>rear</code>指向的位置为队列尾元素</p>
<p>以上目的：为了区分队列是否为空或已满的判断条件</p>
<ul>
<li><strong>队列为空</strong>：当 <code>front</code> 和
<code>rear</code> 相等时，说明队列中没有元素，此时为空队列。</li>
<li><strong>队列已满</strong>：当
<code>(rear + 1) % MAXSIZE == front</code>
时，说明队列已满，因为<code>rear</code> 紧跟在 <code>front</code>
的前面，队列的最后一个位置不可用，否则会与空队列的情况冲突。</li>
</ul>
<p>注意事项：</p>
<p>由于判断队列满的条件需要 <code>front</code> 位置与
<code>rear + 1</code> 相等，意味着最多只能使用 <code>MAXSIZE - 1</code>
个元素的位置，这种策略用于避免空队列与满队列状态混淆。</p>
<p>若不做此区分，队空和队满的判断条件都是<code>(rear + 1) % MAXSIZE == front</code>，会发生混淆</p>
<h2 id="代码">代码</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//循环队列</span><br><span class="line">const int MAXSIZE = 100;</span><br><span class="line">typedef struct &#123;</span><br><span class="line">	int data[MAXSIZE];</span><br><span class="line">	int front;</span><br><span class="line">	int rear;</span><br><span class="line">&#125;Queue;</span><br><span class="line"></span><br><span class="line">//初始化队列</span><br><span class="line">void InitQueue(Queue&amp; Q) &#123;</span><br><span class="line">	Q.front = 0;</span><br><span class="line">	Q.rear = 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//判断队列是否为空</span><br><span class="line">bool IsEmpty(Queue Q) &#123;</span><br><span class="line">	return Q.front == Q.rear;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//判断队列是否已满</span><br><span class="line">bool IsFull(Queue Q) &#123;</span><br><span class="line">	return (Q.rear + 1) % MAXSIZE == Q.front;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//入队</span><br><span class="line">void push(Queue&amp; Q, int x) &#123;</span><br><span class="line">	if (IsFull(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列已满&quot; &lt;&lt; endl;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	//指针先向后移动，再赋值</span><br><span class="line">	Q.rear = (Q.rear + 1) % MAXSIZE;</span><br><span class="line">	Q.data[Q.rear] = x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//出队</span><br><span class="line">int pop(Queue&amp; Q) &#123;</span><br><span class="line">	if (IsEmpty(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	//指针先向后移动，再返回值</span><br><span class="line">	Q.front = (Q.front + 1) % MAXSIZE;</span><br><span class="line">	return Q.data[Q.front];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//获取队头元素</span><br><span class="line">int getFront(Queue Q) &#123;</span><br><span class="line">	if (IsEmpty(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	//指针向后移动，再返回值，front指针指向的是队头元素的前一个位置</span><br><span class="line">	return Q.data[(Q.front + 1) % MAXSIZE];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//获取队尾元素</span><br><span class="line">int getRear(Queue Q) &#123;</span><br><span class="line">	if (IsEmpty(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	//rear指针指向的是队尾元素</span><br><span class="line">	return Q.data[Q.rear];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//测试函数</span><br><span class="line">int main() &#123;</span><br><span class="line">	Queue Q;</span><br><span class="line">	InitQueue(Q);</span><br><span class="line">	push(Q, 1);</span><br><span class="line">	push(Q, 2);</span><br><span class="line">	push(Q, 3);</span><br><span class="line">	cout &lt;&lt; getFront(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; getRear(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; pop(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; getFront(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; getRear(Q) &lt;&lt; endl;</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意事项：</p>
<p>入队逻辑：rear指针先向后移动一位，再赋值</p>
<p>出队逻辑：front指针先向后移动一位，再返回值，因为front指针指向的是队头元素的前一个位置</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1CC4y1m7Bu/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【队列&amp;循环队列】手动实现循环队列，掌握循环队列的每一处细节_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——类模板</title>
    <url>/2024/10/24/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%B1%BB%E6%A8%A1%E6%9D%BF/</url>
    <content><![CDATA[<h1 id="数据结构类模板">数据结构——类模板</h1>
<h2 id="类模板">类模板</h2>
<p>类模板是一种用于创建通用类的机制，它可以让程序员编写一次类，然后让它适用于<strong>多种数据类型</strong>，在实际编程中非常实用。</p>
<p>优点：使用类模板时，可以为同一个类使用不同的数据类型，这使得代码更加灵活。例如，一个通用的栈类模板可以用于<code>int</code>、<code>double</code>、<code>char</code>等不同类型，而不需要为每种类型分别定义栈类。</p>
<h3 id="定义方式">定义方式</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyStack</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 构造函数、析构函数、入栈、出栈等函数</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    T* data;</span><br><span class="line">    <span class="type">int</span> top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>template</code> 关键字用于声明类模板</p>
<h3 id="函数声明与定义">函数声明与定义</h3>
<h4 id="类内定义">类内定义</h4>
<p>如果是在类内进行函数定义，则不需添加<code>template&lt;&gt;</code>，如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 类模板</span><br><span class="line">template &lt;class T1,class T2&gt;</span><br><span class="line">class Data &#123;</span><br><span class="line">private:</span><br><span class="line">	T1 a;</span><br><span class="line">	T2 b;</span><br><span class="line">public:</span><br><span class="line">	Data(T1 a, T2 b)&#123;</span><br><span class="line">		this-&gt;a = a;</span><br><span class="line">		this-&gt;b = b;</span><br><span class="line">		cout &lt;&lt; &quot;Data的有参构造&quot; &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line">	void showData()</span><br><span class="line">	&#123;</span><br><span class="line">		cout &lt;&lt; a &lt;&lt; &quot; &quot; &lt;&lt; b &lt;&lt;endl;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="类外定义">类外定义</h4>
<p>如果成员函数在类外定义</p>
<ul>
<li>在每个成员函数前必须添加<code>template&lt;&gt;</code>。</li>
<li>作用域需要添加<code>&lt;&gt;</code>修饰。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T1</span>,<span class="keyword">class</span> <span class="title class_">T2</span>&gt;</span><br><span class="line"><span class="type">void</span> Data&lt;T1,T2&gt;::<span class="built_in">showData</span>()</span><br><span class="line">&#123;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="友元函数">友元函数</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//类内声明</span></span><br><span class="line"><span class="function"><span class="keyword">friend</span> <span class="type">void</span> <span class="title">MyPrint</span><span class="params">(Data&lt;T3, T4&gt; &amp;ob)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//类外定义</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T3,<span class="keyword">typename</span> T4&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MyPrint</span><span class="params">(Data&lt;T3, T4&gt; &amp;ob)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	cout &lt;&lt; <span class="string">&quot;函数模板友元：&quot;</span> &lt;&lt; ob.a &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; ob.b &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="模板类分文件书写问题">模板类分文件书写问题</h3>
<h4 id="方案一">方案一</h4>
<p>将类的声明和成员函数的定义全部写在一个.h文件中，如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _DATA_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _DATA_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 类模板</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T1</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Data</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	T1 a;</span><br><span class="line">	T2 b;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">showData</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T1</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt;</span><br><span class="line"><span class="type">void</span> Data&lt;T1, T2&gt;::<span class="built_in">showData</span>()</span><br><span class="line">&#123;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// !_DATA_H_</span></span></span><br></pre></td></tr></table></figure>
<h4 id="方案二">方案二</h4>
<p>若将函数的定义写在.cpp文件中，main.cpp中调用时，一定要同时include”.h”和“.cpp”文件，否则编译错误</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//main.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;Data.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;Data.cpp&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">// 类模板实例化对象</span></span><br><span class="line">	</span><br><span class="line">	<span class="function">Data&lt;<span class="type">int</span>, <span class="type">char</span>&gt; <span class="title">ob2</span><span class="params">(<span class="number">100</span>,<span class="string">&#x27;A&#x27;</span>)</span></span>;</span><br><span class="line">	ob<span class="number">2.</span><span class="built_in">showData</span>();</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/Long_xu/article/details/131500484">【035】深入理解C++类模板（最全讲解）：从基础到实战-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论期末笔记汇总</title>
    <url>/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h3 id="笔记">笔记</h3>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175733.jpg" alt="IMG_20250627_175733">
<figcaption aria-hidden="true">IMG_20250627_175733</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175736.jpg" alt="IMG_20250627_175736">
<figcaption aria-hidden="true">IMG_20250627_175736</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175740.jpg" alt="IMG_20250627_175740">
<figcaption aria-hidden="true">IMG_20250627_175740</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175743.jpg" alt="IMG_20250627_175743">
<figcaption aria-hidden="true">IMG_20250627_175743</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175748.jpg" alt="IMG_20250627_175748">
<figcaption aria-hidden="true">IMG_20250627_175748</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175752.jpg" alt="IMG_20250627_175752">
<figcaption aria-hidden="true">IMG_20250627_175752</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175755.jpg" alt="IMG_20250627_175755">
<figcaption aria-hidden="true">IMG_20250627_175755</figcaption>
</figure>
<figure>
<img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175759.jpg" alt="IMG_20250627_175759">
<figcaption aria-hidden="true">IMG_20250627_175759</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>概率论</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——线性表</title>
    <url>/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%BA%BF%E6%80%A7%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="数据结构线性表">数据结构——线性表</h1>
<h2 id="线性表的定义">线性表的定义</h2>
<p><strong>线性表（List）：零个或多个数据元素的有限序列。</strong></p>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%BA%BF%E6%80%A7%E8%A1%A8/c8b3abeb72098a922a9ac4f6ff62f563.png" alt="c8b3abeb72098a922a9ac4f6ff62f563">
<figcaption aria-hidden="true">c8b3abeb72098a922a9ac4f6ff62f563</figcaption>
</figure>
<h3 id="顺序存储结构">顺序存储结构</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> SEQLIST_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SEQLIST_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 模板类定义，表示顺序表</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="type">int</span> MaxSize&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SeqList</span> &#123;</span><br><span class="line">    T data[MaxSize];  <span class="comment">// 存储顺序表数据的数组</span></span><br><span class="line">    <span class="type">int</span> length;       <span class="comment">// 顺序表的长度</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<h3 id="链式存储结构">链式存储结构</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> LINKLIST_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LINKLIST_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">    T data;</span><br><span class="line">    Node&lt;T&gt;* next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinkList</span> &#123;</span><br><span class="line">    Node&lt;T&gt;* head;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// LINKLIST_H</span></span></span><br></pre></td></tr></table></figure>
<h2 id="归并排序">归并排序</h2>
<p>[归并排序 |
菜鸟教程](https://www.runoob.com/data-structures/merge-sort.html#:~:text=归并排序（Merge
sort）是建立在归并操作上的一种有效、稳定的排序算法，该算法是采用分治法
(Divide,and Conquer）的一个非常典型的应用。
将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。
若将两个有序表合并成一个有序表，称为二路归并。)</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 友元函数：合并两个有序顺序表</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="type">int</span> MaxSize1, <span class="type">int</span> MaxSize2&gt;</span><br><span class="line"><span class="function">SeqList&lt;T, MaxSize1 + MaxSize2&gt; <span class="title">Merge</span><span class="params">(<span class="type">const</span> SeqList&lt;T, MaxSize1&gt;&amp; list1, <span class="type">const</span> SeqList&lt;T, MaxSize2&gt;&amp; list2)</span> </span>&#123;</span><br><span class="line">    SeqList&lt;T, MaxSize1 + MaxSize2&gt; MergedList;  <span class="comment">// 创建一个新的顺序表</span></span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, n = <span class="number">0</span>;                    <span class="comment">// 定义三个指针，分别表示 list1、list2 和合并表的当前索引</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取两个顺序表的长度</span></span><br><span class="line">    <span class="type">int</span> length1 = list<span class="number">1.l</span>ength;</span><br><span class="line">    <span class="type">int</span> length2 = list<span class="number">2.l</span>ength;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 合并两个有序顺序表</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; length1 &amp;&amp; j &lt; length2) &#123;</span><br><span class="line">        <span class="keyword">if</span> (list<span class="number">1.</span>data[i] &lt;= list<span class="number">2.</span>data[j]) &#123;</span><br><span class="line">            MergedList.data[n++] = list<span class="number">1.</span>data[i++];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            MergedList.data[n++] = list<span class="number">2.</span>data[j++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将 list1 中剩余的元素插入到 MergedList 中</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; length1) &#123;</span><br><span class="line">        MergedList.data[n++] = list<span class="number">1.</span>data[i++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将 list2 中剩余的元素插入到 MergedList 中</span></span><br><span class="line">    <span class="keyword">while</span> (j &lt; length2) &#123;</span><br><span class="line">        MergedList.data[n++] = list<span class="number">2.</span>data[j++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    MergedList.length = n;  <span class="comment">// 设置合并后的顺序表长度</span></span><br><span class="line">    <span class="keyword">return</span> MergedList;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——课设</title>
    <url>/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/</url>
    <content><![CDATA[<h1 id="题目">题目</h1>
<ol type="1">
<li>编程实现希尔、快速、堆排序、归并排序算法。要求随机产生10000个数据存入磁盘文件，然后读入数据文件，分别采用不同的排序方法进行排序，并将结果存入文件中。</li>
<li>N（N&gt;10）个居民区之间需要铺设煤气管道。假设任意两个居民区之间都可以铺设煤气管道，但代价不同。要求事先将任意两个居民区之间铺设煤气管道的代价存入磁盘文件中。设计一个最佳方案使得这N个居民区之间铺设煤气管道所需代价最小，并将结果以图形方式在屏幕上输出。</li>
</ol>
<h1 id="题目一">题目一</h1>
<h2 id="算法思想">算法思想</h2>
<p><strong>希尔排序</strong>：希尔排序是一种基于插入排序的排序算法，通过按一定步长将待排序的元素分组，对每组内的元素进行插入排序，不断缩小步长，最终实现整体排序。希尔排序的时间复杂度依赖于步长的选择，最坏情况下时间复杂度为O(n^2)，最好的情况下接近O(nlogn)。</p>
<p><strong>快速排序</strong>：快速排序是一种分治法思想的排序算法，选择一个基准元素，将待排序的数组分为左右两部分，左侧部分的元素都小于基准元素，右侧部分的元素都大于基准元素，然后分别对左右两部分进行递归排序。时间复杂度为O(nlogn)，最坏情况下为O(n^2)。</p>
<p><strong>堆排序</strong>：堆排序是一种选择排序的改进算法，利用堆数据结构（通常是大顶堆或小顶堆）来找到最大值或最小值，并将其移到数组的末尾，然后调整堆。时间复杂度为O(nlogn)，适合大数据量排序。</p>
<p><strong>归并排序</strong>：归并排序是一种分治法的排序算法，它将待排序的数组分为两部分，分别排序后再合并。时间复杂度为O(nlogn)，且具有稳定性。</p>
<h2 id="程序结构">程序结构</h2>
<ol type="1">
<li><p><strong>数据生成</strong>：程序首先生成10000个随机数并将其存储到文件
<code>data.txt</code> 中。</p></li>
<li><p><strong>排序算法实现</strong>：实现了四种排序算法：希尔排序、快速排序、堆排序和归并排序。</p></li>
<li><p><strong>文件操作</strong>：程序从文件中读取数据，然后使用不同的排序算法对数据进行排序，并将排序结果保存到文件中。</p></li>
</ol>
<h2 id="测试结果">测试结果</h2>
<p>程序组成</p>
<figure>
<img src="/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/sadf.png" alt="sadf">
<figcaption aria-hidden="true">sadf</figcaption>
</figure>
<p>生成数据</p>
<figure>
<img src="/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/sadffac.png" alt="sadffac">
<figcaption aria-hidden="true">sadffac</figcaption>
</figure>
<p>排序结果<img src="/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/dasfxc.png" alt="dasfxc"></p>
<h2 id="收获与体会">收获与体会</h2>
<ul>
<li>实践了不同排序算法的实现，加深了对算法效率和适用场景的理解。</li>
<li>学会了如何操作文件进行数据存储和读取，增强了文件输入输出的处理能力。</li>
</ul>
<h1 id="题目二">题目二</h1>
<h2 id="算法思想描述">算法思想描述</h2>
<p>本题使用了<strong>Kruskal算法</strong>来求解最小生成树。Kruskal算法是一种典型的贪心算法，步骤如下：</p>
<ol type="1">
<li>先将所有的边按照权重排序。</li>
<li>从最小的边开始，逐步加入到生成树中，若加入该边不会形成环，就加入生成树，否则跳过该边。</li>
<li>使用并查集（Union-Find）数据结构来判定是否会形成环。</li>
</ol>
<p>该算法通过选择最小权重的边逐步构建最小生成树，保证了铺设煤气管道的总代价最小。</p>
<h2 id="程序结构-1">程序结构</h2>
<ol type="1">
<li><strong>文件读取</strong>：程序读取包含代价矩阵和节点坐标的文件
<code>costs.txt</code>，并根据这些信息构建图。</li>
<li><strong>并查集实现</strong>：实现了一个并查集数据结构来判断是否形成环。</li>
<li><strong>图形显示</strong>：利用图形库绘制了居民区的分布、各居民区之间的煤气管道代价以及最终的最小生成树。</li>
</ol>
<h2 id="测试结果-1">测试结果</h2>
<p>通过程序实现，成功展示了根据最小生成树算法铺设的煤气管道图形，并显示了连接每个居民区的最小代价路径。图形显示了所有居民区和最小生成树路径的直观效果，确保了程序的正确性和可视化。</p>
<figure>
<img src="/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/asdf.png" alt="asdf">
<figcaption aria-hidden="true">asdf</figcaption>
</figure>
<h2 id="收获与体会-1">收获与体会</h2>
<ul>
<li>通过实现Kruskal算法，深入理解了最小生成树问题以及并查集的使用。</li>
<li>掌握了如何通过图形库展示算法结果，增加了对图论问题的兴趣。</li>
<li>通过实践提高了编程技巧，特别是在图形和图论方面的应用。</li>
</ul>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——模式匹配KMP</title>
    <url>/2024/10/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D-KMP/</url>
    <content><![CDATA[<h1 id="数据结构模式匹配kmp">数据结构——模式匹配KMP</h1>
<h2 id="前言">前言</h2>
<p>以前因为惰性，没有记录学习笔记的习惯，但我决定抛弃过去，从现在出发，既要有摒弃过去的决心，又要有继续前进的勇气，悟以往之不谏，知来者之可追。</p>
<h2 id="题目">题目</h2>
<p>对于字符串s，查找是否有子串t，并用字符串m替换</p>
<h2 id="暴力解法bf">暴力解法——BF</h2>
<p>具体操作步骤如下：</p>
<ol type="1">
<li>从文本的第一个字符开始，与模式的第一个字符进行逐一比较。</li>
<li>如果模式的每个字符都与文本中的相应字符匹配，则匹配成功，返回当前匹配的位置。</li>
<li>如果某个字符不匹配，则从文本的下一个字符开始重新进行比较。</li>
<li>重复步骤1-3，直到找到匹配或文本搜索完毕。</li>
</ol>
<p>由于每次比较都要逐一对齐模式串和文本，最坏情况下的时间复杂度是
<strong>O(m * n)</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//编写替换函数</span></span><br><span class="line"><span class="function">string <span class="title">replace</span><span class="params">(string&amp; s, string&amp; t,string&amp; m, <span class="type">int</span> start)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> len1 = s.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len2 = m.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len3 = t.<span class="built_in">length</span>();</span><br><span class="line">	string temp;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; start; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		temp += s[i];</span><br><span class="line">	&#125;</span><br><span class="line">	temp += m;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = start + len3; i &lt; len1; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		temp += s[i];</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFmatching</span><span class="params">(string &amp;s, string &amp;t, string &amp;m)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> i = <span class="number">0</span>;</span><br><span class="line">	<span class="type">int</span> j = <span class="number">0</span>;</span><br><span class="line">	<span class="type">int</span> len1 = s.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span>  len2 = t.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len3 = m.<span class="built_in">length</span>();</span><br><span class="line">	<span class="keyword">while</span> (i &lt; len1)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (s[i] == t[j])</span><br><span class="line">		&#123;</span><br><span class="line">			i++;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			i = i - j + <span class="number">1</span>;</span><br><span class="line">			j = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> (j &gt;= len2)</span><br><span class="line">		&#123;</span><br><span class="line">			s = <span class="built_in">replace</span>(s, t, m, i - j);</span><br><span class="line">			len1 = s.<span class="built_in">length</span>(); <span class="comment">// 更新字符串的长度</span></span><br><span class="line">			i = i - j + len3;</span><br><span class="line">			j = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="kmp算法">KMP算法</h2>
<h3 id="前缀和后缀">前缀和后缀</h3>
<p>前缀：从字符串的 <strong>第一个字符</strong>
开始的连续子串。前缀的长度可以从0到字符串的总长度减1。注意，前缀不包括整个字符串本身。</p>
<p>后缀：从字符串的 <strong>最后一个字符</strong>
开始的连续子串。与前缀类似，后缀的长度也可以从0到字符串的总长度减1。后缀不包括整个字符串本身。</p>
<p>二者意义：简单来说，就是当前匹配的后缀与前缀相同时，便可以跳过前缀的比较，直接开始后面的比较，而next数组则记录的是最长的既是前缀又是后缀的公共子串的长度，同样也是回溯的位置</p>
<h3 id="next数组的生成">next数组的生成</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">getnext</span><span class="params">(string&amp; t)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> len = t.<span class="built_in">length</span>();</span><br><span class="line">	<span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">next</span><span class="params">(len, <span class="number">0</span>)</span></span>;</span><br><span class="line">	<span class="type">int</span> i= <span class="number">0</span>;<span class="comment">//后缀</span></span><br><span class="line">	<span class="type">int</span> j = <span class="number">0</span>;<span class="comment">//前缀末尾的位置，也是前缀的长度</span></span><br><span class="line">	next[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; len; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">while</span> (j &gt; <span class="number">0</span> &amp;&amp; t[i] != t[j])</span><br><span class="line">		&#123;</span><br><span class="line">			j = next[j - <span class="number">1</span>];</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (t[i] == t[j])</span><br><span class="line">		&#123;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		next[i] = j;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用后缀指针i和前缀指针j，在后缀指针不断向后遍历的过程中：</p>
<ul>
<li>如果可以匹配，则前缀指针i向后移动一位</li>
<li>如果不可以匹配，则前缀指针向前回溯</li>
</ul>
<h3 id="kmp算法的匹配">KMP算法的匹配</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">KMPmatching</span><span class="params">(string&amp; s, string&amp; t, string&amp; m)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	vector&lt;<span class="type">int</span>&gt; next = <span class="built_in">getnext</span>(t);</span><br><span class="line">	<span class="type">int</span> len1 = s.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len2 = t.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len3 = m.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> i = <span class="number">0</span>,j = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">while</span> (i &lt; len1) &#123;</span><br><span class="line">		<span class="keyword">if</span> (s[i] == t[j]) &#123;</span><br><span class="line">			i++;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> (j != <span class="number">0</span>) &#123;</span><br><span class="line">				j = next[j - <span class="number">1</span>];<span class="comment">//向前回溯</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> &#123;</span><br><span class="line">				i++;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 完成匹配后进行替换</span></span><br><span class="line">		<span class="keyword">if</span> (j == len2) &#123;</span><br><span class="line">			s = <span class="built_in">replace</span>(s, t, m, i - j);</span><br><span class="line">			len1 = s.<span class="built_in">length</span>(); <span class="comment">// 更新字符串的长度</span></span><br><span class="line">			i = i - j + m.<span class="built_in">length</span>(); <span class="comment">// 从替换后的新位置继续查找</span></span><br><span class="line">			j = <span class="number">0</span>; <span class="comment">// 重置 j 以重新开始匹配</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="反思">反思</h3>
<p>注意更新<code>s</code>字符串的长度，每次替换后，<code>s</code>字符串都会变化，需要进行更新，否则运行是会造成溢出</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1PD4y1o7nd?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">帮你把KMP算法学个通透！（理论篇）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1M5411j7Xx?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">帮你把KMP算法学个通透！（求next数组代码篇）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——矩阵压缩</title>
    <url>/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/</url>
    <content><![CDATA[<h1 id="数据结构矩阵压缩">数据结构——矩阵压缩</h1>
<h2 id="特殊矩阵的压缩">特殊矩阵的压缩</h2>
<h3 id="对称矩阵">对称矩阵</h3>
<p>关键点：</p>
<ul>
<li>是选择上三角行主序存储还是下三角列主序存储</li>
<li>组的下标是从1开始还是0开始存储</li>
</ul>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019163345497.png" alt="image-20241019163345497">
<figcaption aria-hidden="true">image-20241019163345497</figcaption>
</figure>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019163357393.png" alt="image-20241019163357393">
<figcaption aria-hidden="true">image-20241019163357393</figcaption>
</figure>
<h3 id="三件矩阵">三件矩阵</h3>
<p>注意点：</p>
<ul>
<li><p>理解下三角列序和下三角行序的差异，后者是计算<code>a[i][j]</code>后面的元素数量和，再用总数减去后面，得到前面元素数量；前者是直接计算<code>a[i][j]</code>前面元素数量</p></li>
<li><p>一位数组空间为<code>n(n+1)/2+1</code>，数组最后一位为0</p></li>
</ul>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019162703259.png" alt="image-20241019162703259">
<figcaption aria-hidden="true">image-20241019162703259</figcaption>
</figure>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019162719970.png" alt="image-20241019162719970">
<figcaption aria-hidden="true">image-20241019162719970</figcaption>
</figure>
<h3 id="对角矩阵">对角矩阵</h3>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019163805806.png" alt="image-20241019163805806">
<figcaption aria-hidden="true">image-20241019163805806</figcaption>
</figure>
<h2 id="稀疏矩阵的压缩存储">稀疏矩阵的压缩存储</h2>
<h3 id="三元组表">三元组表</h3>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_164539.jpg" alt="IMG_20241019_164539">
<figcaption aria-hidden="true">IMG_20241019_164539</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 用于表示稀疏矩阵中非零元素的结构体</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Triplet</span> &#123;</span><br><span class="line">    <span class="type">int</span> row;</span><br><span class="line">    <span class="type">int</span> col;</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于表示稀疏矩阵的类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SparseMatrix</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> rows;</span><br><span class="line">    <span class="type">int</span> cols;</span><br><span class="line">    vector&lt;Triplet&gt; triplets; </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 构造函数，用于初始化矩阵的维度</span></span><br><span class="line">    <span class="built_in">SparseMatrix</span>(<span class="type">int</span> rows, <span class="type">int</span> cols) : <span class="built_in">rows</span>(rows), <span class="built_in">cols</span>(cols) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加非零元素到矩阵的方法</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">add_element</span><span class="params">(<span class="type">int</span> row, <span class="type">int</span> col, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (value != <span class="number">0</span>) &#123;</span><br><span class="line">            triplets.<span class="built_in">push_back</span>(&#123; row, col, value &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 以三元组形式显示稀疏矩阵的方法</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">display</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; triplet : triplets) &#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;行: &quot;</span> &lt;&lt; triplet.row &lt;&lt; <span class="string">&quot;, 列: &quot;</span> &lt;&lt; triplet.col &lt;&lt; <span class="string">&quot;, 值: &quot;</span> &lt;&lt; triplet.value &lt;&lt; endl;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将稀疏矩阵转换为密集矩阵表示的方法</span></span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">to_dense</span>() <span class="type">const</span> &#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dense_matrix</span>(rows, <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(cols, <span class="number">0</span>));</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; triplet : triplets) &#123;</span><br><span class="line">            dense_matrix[triplet.row][triplet.col] = triplet.value;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dense_matrix;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="朴素转置">朴素转置</h4>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_181951.jpg" alt="IMG_20241019_181951">
<figcaption aria-hidden="true">IMG_20241019_181951</figcaption>
</figure>
<p>因为矩阵A的列是矩阵B的行，所以以此遍历A的列，将其存入新的三元组顺序表</p>
<p>不能直接交换i和j的值的原因：因为三元组表是行优先顺序，如果直接交换就是列优先</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;Triplet&gt; <span class="title">transposeTripletMatrix</span><span class="params">(<span class="type">const</span> vector&lt;Triplet&gt;&amp; tripletMatrix)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取原始三元组矩阵的行数、列数和非零元素个数信息</span></span><br><span class="line">    <span class="type">int</span> rows = tripletMatrix[<span class="number">0</span>].row;</span><br><span class="line">    <span class="type">int</span> cols = tripletMatrix[<span class="number">0</span>].col;</span><br><span class="line">    <span class="type">int</span> numNonZero = tripletMatrix[<span class="number">0</span>].value;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建转置矩阵的三元组顺序表</span></span><br><span class="line">    vector&lt;Triplet&gt; transposedMatrix;</span><br><span class="line">    transposedMatrix.<span class="built_in">push_back</span>(&#123;cols, rows, numNonZero&#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过列的顺序插入非零元素到转置矩阵中</span></span><br><span class="line">    <span class="keyword">if</span> (numNonZero &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> col = <span class="number">0</span>; col &lt; cols; ++col) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= numNonZero; ++i) &#123;</span><br><span class="line">                <span class="keyword">if</span> (tripletMatrix[i].col == col) &#123;</span><br><span class="line">                    transposedMatrix.<span class="built_in">push_back</span>(&#123;tripletMatrix[i].col, tripletMatrix[i].row, tripletMatrix[i].value&#125;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transposedMatrix;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="快速转置">快速转置</h4>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_235512.jpg" alt="IMG_20241019_235512">
<figcaption aria-hidden="true">IMG_20241019_235512</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;Triplet&gt; <span class="title">fastTransposeTripletMatrix</span><span class="params">(<span class="type">const</span> vector&lt;Triplet&gt;&amp; tripletMatrix)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取原始三元组矩阵的行数、列数和非零元素个数信息</span></span><br><span class="line">    <span class="type">int</span> rows = tripletMatrix[<span class="number">0</span>].row;</span><br><span class="line">    <span class="type">int</span> cols = tripletMatrix[<span class="number">0</span>].col;</span><br><span class="line">    <span class="type">int</span> numNonZero = tripletMatrix[<span class="number">0</span>].value;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建转置矩阵的三元组顺序表</span></span><br><span class="line">    <span class="function">vector&lt;Triplet&gt; <span class="title">transposedMatrix</span><span class="params">(numNonZero + <span class="number">1</span>)</span></span>;</span><br><span class="line">    transposedMatrix[<span class="number">0</span>] = &#123;cols, rows, numNonZero&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (numNonZero &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 初始化每一列中非零元素的个数和位置</span></span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">count</span><span class="params">(cols, <span class="number">0</span>)</span></span>;</span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">index</span><span class="params">(cols + <span class="number">1</span>, <span class="number">2</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 统计每一列中非零元素的个数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= numNonZero; ++i) &#123;</span><br><span class="line">            count[tripletMatrix[i].col]++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算每一列在转置矩阵中的起始位置</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; cols; ++i) &#123;</span><br><span class="line">            index[i + <span class="number">1</span>] = index[i] + count[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 填充转置矩阵的三元组顺序表</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= numNonZero; ++i) &#123;</span><br><span class="line">            <span class="type">int</span> col = tripletMatrix[i].col;</span><br><span class="line">            <span class="type">int</span> pos = index[col];</span><br><span class="line">            transposedMatrix[pos] = &#123;tripletMatrix[i].col, tripletMatrix[i].row, tripletMatrix[i].value&#125;;</span><br><span class="line">            index[col]++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transposedMatrix;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="十字链表">十字链表</h3>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_170755.jpg" alt="IMG_20241019_170755">
<figcaption aria-hidden="true">IMG_20241019_170755</figcaption>
</figure>
<h4 id="定义">定义</h4>
<p>类中定义了两个链表数组，用于存储每一行和每一列的头节点指针</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 节点定义</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">OLNode</span> &#123;</span><br><span class="line">    <span class="type">int</span> row;         <span class="comment">// 行号</span></span><br><span class="line">    <span class="type">int</span> col;         <span class="comment">// 列号</span></span><br><span class="line">    <span class="type">int</span> value;       <span class="comment">// 元素值</span></span><br><span class="line">    OLNode* right;   <span class="comment">// 指向右边的节点</span></span><br><span class="line">    OLNode* down;    <span class="comment">// 指向下面的节点</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">OLNode</span>(<span class="type">int</span> r, <span class="type">int</span> c, <span class="type">int</span> val) : <span class="built_in">row</span>(r), <span class="built_in">col</span>(c), <span class="built_in">value</span>(val), <span class="built_in">right</span>(<span class="literal">nullptr</span>), <span class="built_in">down</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 十字链表类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OrthogonalList</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> rows, cols;</span><br><span class="line">    vector&lt;OLNode*&gt; row_heads; <span class="comment">// 行头链表数组</span></span><br><span class="line">    vector&lt;OLNode*&gt; col_heads; <span class="comment">// 列头链表数组</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="构造函数">构造函数</h4>
<p><code>row_heads.resize(rows, nullptr);</code> 是用于调整
<code>row_heads</code> 向量的大小，使其包含 <code>rows</code>
个元素，并将每个元素初始化为 <code>nullptr</code>。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">OrthogonalList</span>(<span class="type">int</span> rows, <span class="type">int</span> cols) : <span class="built_in">rows</span>(rows), <span class="built_in">cols</span>(cols) &#123;</span><br><span class="line">        row_heads.<span class="built_in">resize</span>(rows, <span class="literal">nullptr</span>);</span><br><span class="line">        col_heads.<span class="built_in">resize</span>(cols, <span class="literal">nullptr</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="插入函数">插入函数</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 插入元素</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(<span class="type">int</span> r, <span class="type">int</span> c, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (value == <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查是否已存在节点，若存在则更新值</span></span><br><span class="line">    OLNode* current = row_heads[r];</span><br><span class="line">    <span class="keyword">while</span> (current &amp;&amp; current-&gt;col &lt; c) &#123;</span><br><span class="line">        current = current-&gt;right;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (current &amp;&amp; current-&gt;col == c) &#123;</span><br><span class="line">        current-&gt;value = value; <span class="comment">// 更新已有节点的值</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OLNode* newNode = <span class="keyword">new</span> <span class="built_in">OLNode</span>(r, c, value);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 插入到行链表中</span></span><br><span class="line">    <span class="keyword">if</span> (!row_heads[r]) &#123;</span><br><span class="line">        <span class="comment">//如果该行没有头节点，则成为该行头节点</span></span><br><span class="line">        row_heads[r] = newNode;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        current = row_heads[r];</span><br><span class="line">        OLNode* prev = <span class="literal">nullptr</span>;</span><br><span class="line">        <span class="comment">//current向下遍历，直到遍历到该行链表的最后一个，或者到达插入的列的位置</span></span><br><span class="line">        <span class="comment">//注意，该插入方式如果遇到该位置已有节点存在的情况，会用新节点覆盖旧节点</span></span><br><span class="line">        <span class="keyword">while</span> (current &amp;&amp; current-&gt;col &lt; c) &#123;</span><br><span class="line">            prev = current;</span><br><span class="line">            current = current-&gt;right;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//若prev存在，则说明头节点不为零，若为空则说明插在链表最前面</span></span><br><span class="line">        <span class="keyword">if</span> (prev) &#123;</span><br><span class="line">            prev-&gt;right = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            row_heads[r] = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        newNode-&gt;right = current;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 插入到列链表中</span></span><br><span class="line">    <span class="keyword">if</span> (!col_heads[c]) &#123;</span><br><span class="line">        col_heads[c] = newNode;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        current = col_heads[c];</span><br><span class="line">        OLNode* prev = <span class="literal">nullptr</span>;</span><br><span class="line">        <span class="keyword">while</span> (current &amp;&amp; current-&gt;row &lt; r) &#123;</span><br><span class="line">            prev = current;</span><br><span class="line">            current = current-&gt;down;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (prev) &#123;</span><br><span class="line">            prev-&gt;down = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            col_heads[c] = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        newNode-&gt;down = current;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="打印函数">打印函数</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">   <span class="comment">// 打印矩阵</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; rows; ++i) &#123;</span><br><span class="line">            OLNode* current = row_heads[i];</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; cols; ++j) &#123;</span><br><span class="line">                <span class="keyword">if</span> (current &amp;&amp; current-&gt;col == j) &#123;</span><br><span class="line">                    cout &lt;&lt; current-&gt;value &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">                    current = current-&gt;right;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    cout &lt;&lt; <span class="string">&quot;0 &quot;</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            cout &lt;&lt; endl;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1WM411A7YQ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【数据结构】特殊矩阵的压缩存储/对称矩阵/三角矩阵/对角矩阵（含经典题讲解）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1a8yKYXELM/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【每个人都听得懂的】稀疏矩阵的快速转置算法_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>linux作业</title>
    <url>/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%88%9D%E8%AF%86Linux/</url>
    <content><![CDATA[<h3 id="用户和权限管理">用户和权限管理</h3>
<h4 id="创建四个系统用户">创建四个系统用户</h4>
<p>为系统添加以下四个用户：</p>
<ul>
<li><code>alice</code></li>
<li><code>bob</code></li>
<li><code>john</code></li>
<li><code>mike</code></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">useradd -d /home/bob -m bob</span><br><span class="line">useradd -d /home/john -m john</span><br><span class="line">useradd -d /home/mike -m mike</span><br></pre></td></tr></table></figure>
<h4 id="为四个用户设置密码">为四个用户设置密码</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">passwd alice</span><br><span class="line">passwd bob</span><br><span class="line">passwd john</span><br><span class="line">passwd mike</span><br></pre></td></tr></table></figure>
<h4 id="创建共享目录">创建共享目录</h4>
<p>在 <code>/home</code> 目录下创建一个名为 <code>work</code>
的共享目录：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir /home/work</span><br></pre></td></tr></table></figure>
<h4 id="创建用户组并添加成员">创建用户组并添加成员</h4>
<p>创建一个名为 <code>workgroup</code> 的用户组：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">groupadd workgroup</span><br></pre></td></tr></table></figure>
<p>将用户 <code>alice</code>, <code>bob</code>, <code>john</code>
加入该组：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">usermod -a -G workgroup alice   # 添加为附加组</span><br><span class="line">usermod -g workgroup alice       # 设置为 alice 的主组（primary group）</span><br><span class="line">usermod -a -G workgroup bob</span><br><span class="line">usermod -a -G workgroup john</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>主组（Primary
Group）</strong>：每个用户<strong>有且只有一个</strong>，是用户创建文件时<strong>默认继承的组</strong>。</li>
<li><strong>附加组（Supplementary
Group）</strong>：用户可以有<strong>多个</strong>，用于<strong>额外获得某些组的权限</strong>，但<strong>不会影响新建文件的默认组</strong>。</li>
</ul>
<p>查看某个<strong>组（group）的信息</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">getent group workgroup</span><br></pre></td></tr></table></figure>
<h4 id="修改共享目录的所有权">修改共享目录的所有权</h4>
<p>将 <code>/home/work</code> 目录的属主改为
<code>alice</code>，属组改为 <code>workgroup</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chown alice:workgroup /home/work</span><br></pre></td></tr></table></figure>
<h4 id="修改-work-目录的权限">修改 work 目录的权限</h4>
<ul>
<li>属组内的用户（workgroup 组成员）→ 完全访问权限（rwx）</li>
<li>属组外的用户 → 没有访问权限（—）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod ug+rwx,o-rwx /home/work</span><br></pre></td></tr></table></figure>
<ul>
<li><code>ug+rwx</code>：用户（user）和组（group）都加上读、写、执行权限</li>
<li><code>o-rwx</code>：其他人（others）去掉所有权限（读、写、执行）</li>
</ul>
<h4 id="尝试以-bob-用户身份在-work-目录下创建文件">尝试以 bob 用户身份在
work 目录下创建文件</h4>
<p>切换到 bob 用户：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">su - bob</span><br></pre></td></tr></table></figure>
<p>创建文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">touch /home/work/bob.txt</span><br></pre></td></tr></table></figure>
<p>查看是否成功：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ls -l /home/work/bob.txt</span><br></pre></td></tr></table></figure>
<h4 id="尝试以-john-的身份查看或修改-bob.txt">尝试以 john
的身份查看或修改 bob.txt</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">su - john</span><br><span class="line">cat /home/work/bob.txt  #查看文件内容</span><br><span class="line">echo &quot;hello&quot; &gt;&gt; /home/work/bob.txt</span><br><span class="line">ls -l /home/work/bob.txt   #查看权限</span><br></pre></td></tr></table></figure>
<h4 id="尝试以-mike-的身份查看或修改-bob.txt">尝试以 mike
的身份查看或修改 bob.txt</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">su - mike</span><br><span class="line">cat /home/work/bob.txt</span><br><span class="line">echo &quot;mike tried&quot; &gt;&gt; /home/work/bob.txt</span><br><span class="line">cd /home/work</span><br></pre></td></tr></table></figure>
<h3 id="进程管理与调试">进程管理与调试</h3>
<h4 id="编写-badproc.sh-脚本">编写 <code>badproc.sh</code> 脚本</h4>
<p><strong>Shell 程序（Shell Script）</strong> 就是一系列 <strong>Shell
命令的集合</strong>，写在一个文件里，可以像程序一样<strong>自动、批量、重复执行</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">while echo &quot;I&#x27;m making files!&quot;</span><br><span class="line">do</span><br><span class="line">    mkdir adir</span><br><span class="line">    cd adir</span><br><span class="line">    touch afile</span><br><span class="line">    sleep 10s</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p><code>#!/bin/bash</code> → 指定用 bash 解释器执行</p>
<p><code>while echo "..."</code> →
<strong>无限循环</strong>，每次循环前先打印一句话（等价于
<code>while true; do ... done</code>）</p>
<p>循环体内：</p>
<ul>
<li>创建目录 <code>adir</code></li>
<li>进入该目录</li>
<li>创建文件 <code>afile</code></li>
<li>睡眠 10 秒 → 避免太快占满磁盘</li>
</ul>
<h4 id="添加可执行权限">添加可执行权限</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod +x badproc.sh</span><br><span class="line">#验证</span><br><span class="line">ls -l badproc.sh</span><br></pre></td></tr></table></figure>
<h4 id="在后台运行脚本">在后台运行脚本</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./badproc.sh &amp;</span><br></pre></td></tr></table></figure>
<h4 id="查看进程号">查看进程号</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ps aux | grep badproc</span><br></pre></td></tr></table></figure>
<h4 id="杀死进程">杀死进程</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kill 12345</span><br></pre></td></tr></table></figure>
<h4 id="删除脚本运行时创建的目录和文件">删除脚本运行时创建的目录和文件</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rm -rf adir</span><br></pre></td></tr></table></figure>
<h4 id="创建源文件-fork.c">创建源文件 <code>fork.c</code></h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">#include &lt;sys/types.h&gt;</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">    pid_t pid;</span><br><span class="line"></span><br><span class="line">    /* fork another process */</span><br><span class="line">    pid = fork();</span><br><span class="line">    if (pid &lt; 0) &#123; /* error occurred */</span><br><span class="line">        fprintf(stderr, &quot;Fork Failed\n&quot;);</span><br><span class="line">        exit(-1);</span><br><span class="line">    &#125;</span><br><span class="line">    else if (pid == 0) &#123; /* child process */</span><br><span class="line">        printf(&quot;This is child process, pid=%d\n&quot;, getpid());</span><br><span class="line">        execl(&quot;/bin/ls&quot;, &quot;ls&quot;, NULL);  // 执行 ls 命令</span><br><span class="line">        printf(&quot;Child process finished\n&quot;); // 这句不会打印，除非 execl 失败</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123; /* parent process */</span><br><span class="line">        printf(&quot;This is parent process, pid=%d\n&quot;, getpid());</span><br><span class="line">        wait(NULL);  // 等待子进程结束</span><br><span class="line">        printf(&quot;Child Complete\n&quot;);</span><br><span class="line">        exit(0);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="编译程序带调试信息">编译程序（带调试信息）</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gcc -g -o fork fork.c</span><br></pre></td></tr></table></figure>
<h4 id="先运行一次看看效果">先运行一次，看看效果</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./fork</span><br></pre></td></tr></table></figure>
<h4 id="用-gdb-调试-fork-程序">用 <code>gdb</code> 调试 fork 程序</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gdb ./fork</span><br><span class="line">#在 fork() 调用前设置</span><br><span class="line">(gdb) set follow-fork-mode child</span><br><span class="line">#设置断点和 catch exec</span><br><span class="line">break main</span><br><span class="line">catch exec</span><br></pre></td></tr></table></figure>
<h3 id="linux编程环境熟悉">Linux编程环境熟悉</h3>
<h4 id="c编译">C++编译</h4>
<p>创建一个名为 <code>helloworld.cpp</code>
的文件，<code>nano helloworld.cpp</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">    cout &lt;&lt; &quot;Hello world&quot; &lt;&lt; endl;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>按 <code>Ctrl+O</code> 保存，再按 <code>Ctrl+X</code> 退出 nano</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#编译程序</span><br><span class="line">g++ -o hello helloworld.cpp</span><br><span class="line">#运行程序</span><br><span class="line">./hello</span><br></pre></td></tr></table></figure>
<h4 id="创建小型函数库"><strong>创建小型函数库</strong></h4>
<p>创建源文件 <code>fred.c</code> 和 <code>bill.c</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* fred.c */</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">void fred(int arg)</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;fred: we passed %d\n&quot;, arg);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* bill.c */</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">void bill(char *arg)</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;bill: we passed %s\n&quot;, arg);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译成目标文件（.o）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gcc -c bill.c fred.c</span><br></pre></td></tr></table></figure>
<p>创建头文件 <code>lib.h</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* lib.h */</span><br><span class="line">void bill(char *);</span><br><span class="line">void fred(int);</span><br></pre></td></tr></table></figure>
<p>创建主程序 <code>program.c</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/* program.c */</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &quot;lib.h&quot;   // 引入我们自己写的头文件</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    bill(&quot;Hello World&quot;);</span><br><span class="line">    exit(0);       // 正常退出</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译主程序（只编译，不链接）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gcc -c program.c</span><br></pre></td></tr></table></figure>
<p>创建静态库 <code>libfoo.a</code></p>
<p>使用 <code>ar</code> 命令把 <code>bill.o</code> 和
<code>fred.o</code> 打包成一个静态库：</p>
<ul>
<li><code>ar</code>：archive 工具，用于创建静态库</li>
<li><code>c</code>：创建新库</li>
<li><code>r</code>：将文件插入到库中（如果不存在则添加）</li>
<li><code>v</code>：显示详细信息</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ar crv libfoo.a bill.o fred.o</span><br></pre></td></tr></table></figure>
<p>链接主程序和静态库</p>
<p>现在我们要把 <code>program.o</code> 和 <code>libfoo.a</code>
链接起来，生成最终可执行文件 <code>program</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gcc -o program program.o libfoo.a</span><br></pre></td></tr></table></figure>
<p>运行程序</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./program</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大三上</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>数字逻辑电路——CMOS逻辑门电路</title>
    <url>/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/</url>
    <content><![CDATA[<h1 id="数字逻辑电路cmos逻辑门电路">数字逻辑电路——CMOS逻辑门电路</h1>
<h2 id="mos管">MOS管</h2>
<p>MOSFET全称金属-氧化物-半导体场效应三极管</p>
<p>从载流子极性来看，分为<strong>NMOS（电子型）管</strong>和<strong>PMOS（空穴型）管</strong>两种</p>
<p>按照导电机制的不同，MOS管又可以分为<strong>增强型</strong>和<strong>耗尽型</strong></p>
<p>因此MOSFET共有四种：E型NMOS管、D型NMOS管、E型PMOS管、D型PMOS管</p>
<h3 id="nmos和pmos区别">NMOS和PMOS区别</h3>
<p>MOS管的管脚有三个：<strong>源极S（source）、栅极G（Gate）和漏极（Drain）</strong></p>
<p>MOS管有两种：<strong>一个是PMOS管，一个是NMOS管</strong>；PMOS管就是positive管，是积极的管，而NMOS管是negative管，是消极的管。积极的管就是顺应潮流，顺势而为；消极的管就是违背趋势，逆流而上。
很显然，电流从源极（输入端）到漏极（输出端），那就是顺势而为，因为源极就是源头嘛，因此这种管就是PMOS管；而电流要是从漏极（输入端）到源极（输出端），那就是逆流而上，是NMOS管。</p>
<p>判定是N沟道MOS还是P沟道MOS： <strong>箭头指向G极的是N沟道
箭头背向G极的是P沟道</strong></p>
<p>从导通特性上区分：</p>
<p>NMOS：当电压高于阈值电压<strong>可以导通</strong>；当电压低于阈值电压<strong>不能导通</strong></p>
<p>PMOS：当电压高于阈值电压<strong>不能导通</strong>；当电压低于阈值电压<strong>可以导通</strong></p>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/22e26add55da2a09c803a6ed67ee4777.png" alt="22e26add55da2a09c803a6ed67ee4777">
<figcaption aria-hidden="true">22e26add55da2a09c803a6ed67ee4777</figcaption>
</figure>
<h3 id="增强型和耗尽型的区别">增强型和耗尽型的区别</h3>
<p>以<strong>NMOS管</strong>为例：</p>
<p>当<span class="math inline"> <em>V</em><sub><em>G</em><em>S</em></sub> = 0</span>时没有导电沟道，需要依靠<span class="math inline"> <em>V</em><sub><em>G</em><em>S</em></sub></span>的作用才能产生导电沟道，称为<strong>增强型FET</strong>。</p>
<p>当<span class="math inline"> <em>V</em><sub><em>G</em><em>S</em></sub> = 0</span>时有导电沟道，需要依靠<span class="math inline"> <em>V</em><sub><em>G</em><em>S</em></sub></span>的作用是削弱导电沟道，称为<strong>耗尽型FET</strong>。</p>
<h2 id="cmos逻辑门电路">CMOS逻辑门电路</h2>
<p>由<code>N</code>沟道和<code>P</code>沟道增强型<code>MOS</code>管组成的电路称为互补<code>MOS</code>或<code>CMOS</code>电路。</p>
<h3 id="非门">非门</h3>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/57F%5BQXP6AT6LH8KOVH4CIQ.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="或门和或非门">或门和或非门</h3>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/4.png" alt="4">
<figcaption aria-hidden="true">4</figcaption>
</figure>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/G%WO3%5DUHOQB5%7BDKEJ571A7.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="与门和与非门">与门和与非门</h3>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/7.png" alt="7">
<figcaption aria-hidden="true">7</figcaption>
</figure>
<h3 id="异或门和同或门">异或门和同或门</h3>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1nL411x7jH?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">【硬核科普】带你认识CPU第00期——什么是MOSFET_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV18M4y137Cr?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">【硬核科普】带你认识CPU第01期——什么是逻辑门_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/weixin_43491077/article/details/109721185">NMOS管与PMOS管的区别与总结_pmos和nmos的区别-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数字逻辑电路</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>数字逻辑电路</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统作业</title>
    <url>/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/</url>
    <content><![CDATA[<h3 id="作业一">作业一</h3>
<h4 id="section">1</h4>
<p><strong>题目：</strong></p>
<p>在某个计算机系统中有一台输入机和一台打印机，现有两道程序投入运行，且程序A先运行，程序B后开始运行。</p>
<ul>
<li><p><strong>程序A</strong>的运行轨迹为：<br>
计算50ms，打印100ms，再计算50ms，打印100ms。</p></li>
<li><p><strong>程序B</strong>的运行轨迹为：<br>
计算50ms，输入80ms，再计算100ms，结束。</p></li>
</ul>
<p><strong>问题：</strong></p>
<ol type="1">
<li><p>两道程序运行时，CPU是否空闲等待？____（有空闲等待 /
无空闲等待）<br>
若有，在哪段时间内等待？_<strong>ms -
</strong>_ms（两个空，第一个填起始时间，第二个填结束时间，仅数字）</p></li>
<li><p>程序A，B是否有等待CPU的情况？<br>
A：<strong><em>（有等待 / 无等待）<br>
B：</em></strong>（有等待 / 无等待）<br>
若有，指出发生等待的时刻（若无等待，空格填0）<br>
（若有两段以上等待时间，用“/”标表示不同等待时间，如0/30和20/40表示0ms-20ms是第一段空闲；30ms-40ms是第二段空闲）<br>
A：_<strong>ms - </strong>_ms<br>
B：___ms - ___ms</p></li>
</ol>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/IMG_20250917_090110.jpg" alt="IMG_20250917_090110">
<figcaption aria-hidden="true">IMG_20250917_090110</figcaption>
</figure>
<h4 id="section-1">2</h4>
<p><strong>题目：</strong></p>
<p>在单CPU和两台I/O设备（I1和I2）的多道程序设计环境下，同时投入三个作业运行，其执行轨迹如下：</p>
<ul>
<li><strong>Job1</strong>：I2（30ms），CPU（10ms），I1（30ms），CPU（10ms）</li>
<li><strong>Job2</strong>：I1（20ms），CPU（20ms），I2（40ms）</li>
<li><strong>Job3</strong>：CPU（30ms），I1（20ms）</li>
</ul>
<p><strong>已知条件：</strong></p>
<ul>
<li>CPU、I1、I2可以并行工作；</li>
<li>优先级从高到低依次为：Job1、Job2、Job3；</li>
<li>优先级高的作业可以抢占优先级低的作业（抢占式调度）；</li>
<li>所有作业同时投入运行。</li>
</ul>
<p><strong>问题：</strong></p>
<ol type="1">
<li>每个作业从投入到完成分别所需的时间。
<ul>
<li>Job1：____ ms</li>
<li>Job2：____ ms</li>
<li>Job3：____ ms</li>
</ul></li>
<li>从作业投入到完成，CPU的利用率是：
<ul>
<li>____ / ____ = ____%（保留小数点后两位）</li>
</ul></li>
<li>I/O设备利用率：
<ul>
<li>I1 利用率：____ / ____ = ____%（保留小数点后两位）</li>
<li>I2 利用率：____ / ____ = ____%（保留小数点后两位）</li>
</ul></li>
</ol>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/IMG_20250917_090158.jpg" alt="IMG_20250917_090158">
<figcaption aria-hidden="true">IMG_20250917_090158</figcaption>
</figure>
<h4 id="section-2">3</h4>
<p><strong>题目：</strong></p>
<p>在单机系统中，有同时到达的两个程序A、B，若每个程序单独运行，则使用CPU，DEV1（设备1）、DEV2（设备2）的顺序和时间如下表所示。</p>
<table>
<thead>
<tr>
<th>运行情况</th>
<th>程序A</th>
<th>程序B</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>25</td>
<td>20</td>
</tr>
<tr>
<td>DEV1</td>
<td>39</td>
<td>50</td>
</tr>
<tr>
<td>CPU</td>
<td>20</td>
<td>20</td>
</tr>
<tr>
<td>DEV2</td>
<td>20</td>
<td>20</td>
</tr>
<tr>
<td>CPU</td>
<td>20</td>
<td>10</td>
</tr>
<tr>
<td>DEV1</td>
<td>30</td>
<td>20</td>
</tr>
<tr>
<td>CPU</td>
<td>20</td>
<td>45</td>
</tr>
</tbody>
</table>
<p><strong>给定条件：</strong></p>
<ol type="1">
<li>DEV1和DEV2是不同的I/O设备，它们能够同时工作。</li>
<li>程序B优先级高于程序A，<strong>非抢占式</strong>。当程序A占用CPU时，即使程序B需要使用CPU，也不能打断程序A的执行，而应等待。</li>
<li>当使用CPU之后控制转向I/O设备，或者使用I/O设备之后控制转向CPU，由控制程序执行中断处理，但这段处理时间可以忽略不计。</li>
</ol>
<p><strong>问题：</strong></p>
<ol type="1">
<li>哪个程序先结束？（A / B）</li>
<li>程序全部执行结束需要多少时间？（____ ms）</li>
<li>程序全部执行完毕时，CPU利用率是多少？（____%）</li>
<li>A程序等待CPU的累积时间是多少？（____ ms）</li>
<li>B程序等待CPU的累积时间是多少？（____ ms）</li>
</ol>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/IMG_20250917_090145.jpg" alt="IMG_20250917_090145">
<figcaption aria-hidden="true">IMG_20250917_090145</figcaption>
</figure>
<h3 id="作业二">作业二</h3>
<h4 id="section-3">1</h4>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/image-20251010094314155.png" alt="image-20251010094314155">
<figcaption aria-hidden="true">image-20251010094314155</figcaption>
</figure>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/IMG_20251010_101637.jpg" alt="IMG_20251010_101637">
<figcaption aria-hidden="true">IMG_20251010_101637</figcaption>
</figure>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/IMG_20251010_101643.jpg" alt="IMG_20251010_101643">
<figcaption aria-hidden="true">IMG_20251010_101643</figcaption>
</figure>
<h4 id="section-4">2</h4>
<p><img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/image-20251010102104414.png" alt="image-20251010102104414">3.</p>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/IMG_20251010_103349.jpg" alt="IMG_20251010_103349">
<figcaption aria-hidden="true">IMG_20251010_103349</figcaption>
</figure>
<h4 id="section-5">3</h4>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/image-20251010110615738.png" alt="image-20251010110615738">
<figcaption aria-hidden="true">image-20251010110615738</figcaption>
</figure>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/IMG_20251010_110541.jpg" alt="IMG_20251010_110541">
<figcaption aria-hidden="true">IMG_20251010_110541</figcaption>
</figure>
<h3 id="作业三">作业三</h3>
<h4 id="section-6">1</h4>
<p>有一个盒子里混装了数量相等的黑白围棋子，现在利用自动分拣系统把黑子、白子分开，设分拣系统有两个进程P1和P2，其中进程P1拣白子，进程P2拣黑子。规定每个进程每次拣一子；当一个进程在拣时，不允许另一个进程去拣；当一个进程拣了一子时，必须让另一个进程去拣。试写出进程P1和P2能够正确并发执行的程序。</p>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/image-20251111211928061.png" alt="image-20251111211928061">
<figcaption aria-hidden="true">image-20251111211928061</figcaption>
</figure>
<h4 id="section-7">2</h4>
<p>请用信号量和PV操作解决以下问题：桌上有一只盘子，最多可以容纳两个水果，每次仅能放入或取出一个水果。爸爸专向盘子中放苹果(apple)，妈妈专向盘子中放橘子(orange)，两个儿子专等吃盘子中的桔子，两个女儿专等吃盘子里的苹果。写出爸爸（father）、妈妈（mother）、儿子（son）和女儿（daughter）进程及所需定义的变量和信号量。用PV操作实现爸爸、妈妈、儿子、女儿间的同步与互斥关系。</p>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/image-20251111211937533.png" alt="image-20251111211937533">
<figcaption aria-hidden="true">image-20251111211937533</figcaption>
</figure>
<h4 id="section-8">3</h4>
<p>设当前的系统状态如下，此时Available=(1,1,2)</p>
<table>
<colgroup>
<col style="width: 5%">
<col style="width: 26%">
<col style="width: 34%">
<col style="width: 32%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">进程</th>
<th style="text-align: left;">Claim (R1, R2, R3)</th>
<th style="text-align: left;">Allocation (R1, R2, R3)</th>
<th style="text-align: left;">Available (R1, R2, R3)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">P1</td>
<td style="text-align: left;">3, 2, 2</td>
<td style="text-align: left;">1, 0, 0</td>
<td style="text-align: left;">1, 1, 2</td>
</tr>
<tr>
<td style="text-align: left;">P2</td>
<td style="text-align: left;">6, 1, 3</td>
<td style="text-align: left;">5, 1, 1</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">P3</td>
<td style="text-align: left;">3, 1, 4</td>
<td style="text-align: left;">2, 1, 1</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">P4</td>
<td style="text-align: left;">4, 2, 2</td>
<td style="text-align: left;">0, 0, 2</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/image-20251111211949933.png" alt="image-20251111211949933">
<figcaption aria-hidden="true">image-20251111211949933</figcaption>
</figure>
<h3 id="作业四">作业四</h3>
<h4 id="section-9">1</h4>
<p>数组int
A[100][100]；元素按行存储，在虚拟系统中，采用LRU淘汰算法，一个进程有3页内存空间，每页可以存放200个整数，其中第1页存放程序，假定程序已在内容中，问：</p>
<p>A程序缺页次数为：____次；</p>
<p>B程序缺页次数为：____次。</p>
<p>程序A：</p>
<pre><code>for(int i=0; i&lt;100; i++)
   for(int j=0; j&lt;100; j++)
        A[i,j]=0;</code></pre>
<p>程序B：</p>
<pre><code>for(int j=0;j&lt;100;j++)
   for(int i=0;i&lt;100;i++)   
        A[i,j]=0;</code></pre>
<p>程序 A 分析</p>
<p><strong>代码逻辑</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int i=0; i&lt;100; i++)    // 外层循环：行</span><br><span class="line">   for(int j=0; j&lt;100; j++) // 内层循环：列</span><br><span class="line">      A[i][j]=0;</span><br></pre></td></tr></table></figure>
<p>访问顺序：A[0][0], A<a href="#section">0</a>, …, A[0][99], A[1][0],
…</p>
<p>这是按行访问，与数组的按行存储顺序一致。</p>
<p><strong>缺页计算过程</strong>：</p>
<ol type="1">
<li><strong>访问第0、1行</strong>：都在<strong>虚拟页0</strong>中。
<ul>
<li>第一次访问 <code>A[0][0]</code> 时，内存为空，发生
<strong>1次缺页</strong>，调入页0。</li>
<li>后续访问第0行和第1行的剩余199个元素时，都在页0中，直接命中（不缺页）。</li>
</ul></li>
<li><strong>访问第2、3行</strong>：都在<strong>虚拟页1</strong>中。
<ul>
<li>访问 <code>A[2][0]</code> 时，页1不在内存，发生
<strong>1次缺页</strong>，调入页1。</li>
<li>后续元素全部命中。</li>
</ul></li>
<li><strong>以此类推</strong>：
<ul>
<li>程序按照顺序访问：页0 <span class="math inline">→</span> 页1 <span class="math inline">→</span> 页2 … <span class="math inline">→</span>
页49。</li>
<li>由于我们有2个物理块，LRU算法会淘汰最久未使用的旧页面，但因为访问是单向顺序向前的，<strong>每一页只需要调入一次</strong>。</li>
</ul></li>
</ol>
<p>结果：共有50个页面，每页调入一次。</p>
<p>Total = 50 次缺页。</p>
<p>程序 B 分析</p>
<p><strong>代码逻辑</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int j=0; j&lt;100; j++)    // 外层循环：列</span><br><span class="line">   for(int i=0; i&lt;100; i++) // 内层循环：行</span><br><span class="line">      A[i][j]=0;</span><br></pre></td></tr></table></figure>
<p>访问顺序：A[0][0], A[1][0], A[2][0], …</p>
<p>这是按列访问，即“跳跃式”访问。</p>
<p><strong>缺页计算过程</strong>：</p>
<ol type="1">
<li><strong>分析内层循环（i 从 0 到 99，处理第 j 列）</strong>：
<ul>
<li><code>i=0, 1</code>: 访问第0、1行 <span class="math inline">→</span>
需要 <strong>虚拟页0</strong>。</li>
<li><code>i=2, 3</code>: 访问第2、3行 <span class="math inline">→</span>
需要 <strong>虚拟页1</strong>。</li>
<li>…</li>
<li><code>i=98, 99</code>: 访问第98、99行 <span class="math inline">→</span> 需要 <strong>虚拟页49</strong>。</li>
<li><strong>一轮内循环（i=0~99）</strong>会依次访问：页0, 页1, 页2, …,
页49。</li>
</ul></li>
<li><strong>内存状态与置换</strong>：
<ul>
<li>我们只有 <strong>2个</strong> 物理块用于数据。</li>
<li>当访问页0、页1时，填满内存。</li>
<li>当需要页2时，根据LRU，淘汰页0。</li>
<li>当需要页3时，根据LRU，淘汰页1。</li>
<li>…</li>
<li>因为循环访问的页面数量（50页）远大于物理内存（2页），导致内存中的页面不断被替换（<strong>颠簸/Thrashing现象</strong>）。</li>
<li><strong>结论</strong>：在处理每一列（内层循环）时，需要访问所有50个页面。因为内存存不下，这
<strong>50个页面每一次都需要重新从磁盘调入</strong>。</li>
<li>单列（一次外层循环）产生的缺页次数 = <strong>50次</strong>。</li>
</ul></li>
<li><strong>结合外层循环</strong>：
<ul>
<li>外层循环 <code>j</code> 从 0 到 99，共执行
<strong>100次</strong>。</li>
<li>每次外层循环都要重新把这50个页面遍历一遍。由于上一轮留下的页面（最后访问的页48、49）对下一轮开头需要的页（页0）没有帮助。</li>
<li>总缺页次数 = 每列缺页数 <span class="math inline">×</span> 列数</li>
<li>Total = <span class="math inline">50 × 100 = 5000</span>。</li>
</ul></li>
</ol>
<p><strong>结果</strong>：<strong>5000 次缺页。</strong></p>
<h4 id="section-10">2</h4>
<p>在一个请求分页虚存管理系统中，一个程序运行的页面走向是：1 2 3 4 2 1 5
6 2 1 2 3 7 6 3 2 1 2 3 6</p>
<p>分别用FIFO、OPT、和LRU算法，对于分配给程序3个页框的情况，求出缺页异常次数和缺页中断率：</p>
<p>（1）FIFO：缺页异常次数：_____次, 缺页中断率：______%.</p>
<p>（2）OPT：缺页异常次数：_____次, 缺页中断率：______%.</p>
<p>（3）LRU：缺页异常次数：_____次, 缺页中断率：______%.</p>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/image-20251205102751318.png" alt="image-20251205102751318">
<figcaption aria-hidden="true">image-20251205102751318</figcaption>
</figure>
<h4 id="section-11">3</h4>
<p>一个页式虚拟存储管理系统中的用户空间为1024KB，页面大小为4KB，内存空间为512KB。已知用户的10、11、12、13号虚页分得的内存页框号为62、78、25、36，试将逻辑地址0BEBCH转换为对应的物理地址:
_______H。</p>
<table>
<colgroup>
<col style="width: 17%">
<col style="width: 11%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 27%">
</colgroup>
<thead>
<tr>
<th><strong>名词</strong></th>
<th><strong>英文</strong></th>
<th><strong>所在空间</strong></th>
<th><strong>本质</strong></th>
<th><strong>通俗解释（类比）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>页面</strong> (Page)</td>
<td>Page</td>
<td><strong>逻辑/虚拟空间</strong> (程序里)</td>
<td>程序被切分成的“块”</td>
<td><strong>客人</strong> (要住店的人)</td>
</tr>
<tr>
<td><strong>页号</strong> (Page No.)</td>
<td>VPN</td>
<td><strong>逻辑/虚拟空间</strong></td>
<td>页面的编号/索引</td>
<td><strong>客人的身份证号</strong></td>
</tr>
<tr>
<td><strong>页框</strong> (Page Frame)</td>
<td>Page Frame</td>
<td><strong>物理内存</strong> (硬件里)</td>
<td>内存条被切分成的“格”</td>
<td><strong>酒店的房间</strong> (物理存在的空间)</td>
</tr>
<tr>
<td><strong>页块</strong> (Block)</td>
<td>Physical Block</td>
<td><strong>物理内存</strong></td>
<td><strong>完全等同于“页框”</strong> (别名)</td>
<td><strong>完全等同于“房间”</strong></td>
</tr>
<tr>
<td><strong>页框号</strong> (PFN)</td>
<td>PFN</td>
<td><strong>物理内存</strong></td>
<td>页框的物理编号</td>
<td><strong>房间号码</strong> (如 302 号房)</td>
</tr>
<tr>
<td><strong>页表</strong> (Page Table)</td>
<td>Page Table</td>
<td><strong>内存中</strong> (系统管理)</td>
<td>映射表 (记录对应关系)</td>
<td><strong>前台登记簿</strong> (记录谁住哪个房间)</td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/09/18/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%9C%E4%B8%9A/image-20251205104211485.png" alt="image-20251205104211485">
<figcaption aria-hidden="true">image-20251205104211485</figcaption>
</figure>
]]></content>
      <categories>
        <category>大三上</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>数字逻辑电路——数电实验1</title>
    <url>/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/</url>
    <content><![CDATA[<h1 id="实验1-门电路逻辑功能测试">实验1 门电路逻辑功能测试</h1>
<h2 id="内容一与非门和异或门逻辑功能的测试">内容一：与非门和异或门逻辑功能的测试</h2>
<h3 id="ls20双4输入与非门逻辑功能测试">74LS20双4输入与非门逻辑功能测试</h3>
<p>74LS20功能：<strong>四输入双与非门</strong>，其内部结构及真值表如图</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/1ac35b0a8f06411f05cc80a49ec9c700.png" alt="1ac35b0a8f06411f05cc80a49ec9c700">
<figcaption aria-hidden="true">1ac35b0a8f06411f05cc80a49ec9c700</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<table>
<thead>
<tr>
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">C</th>
<th style="text-align: center;">D</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>全1出0，有0出1</p>
<h3 id="ls86四2输入异或门逻辑功能测试">74LS86四2输入异或门逻辑功能测试</h3>
<p>74LS86功能：<strong>二输入端四异或门</strong>，其内部结构及真值表如图</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/a74b68814db1d802db338a7b636a523e.png" alt="a74b68814db1d802db338a7b636a523e">
<figcaption aria-hidden="true">a74b68814db1d802db338a7b636a523e</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/6-1730557274344-12.png" alt="6">
<figcaption aria-hidden="true">6</figcaption>
</figure>
<table>
<thead>
<tr>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<h2 id="内容二根据电路图写出逻辑关系表达式">内容二：根据电路图写出逻辑关系表达式</h2>
<h3 id="用74ls00按图接线将输入输出逻辑关系分别填入表中">用74LS00按图接线，将输入输出逻辑关系分别填入表中。</h3>
<p>74LS00功能：<strong>二输入端四与非门</strong>，其内部结构及真值表如图</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/4.png" alt="4">
<figcaption aria-hidden="true">4</figcaption>
</figure>
<p>题目如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/564.png" alt="564">
<figcaption aria-hidden="true">564</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/44.png" alt="44">
<figcaption aria-hidden="true">44</figcaption>
</figure>
<table>
<thead>
<tr>
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/546.png" alt="546">
<figcaption aria-hidden="true">546</figcaption>
</figure>
<table>
<thead>
<tr>
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">Y</th>
<th style="text-align: center;">Z</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<h3 id="写出两个电路逻辑表达式">写出两个电路逻辑表达式</h3>
<p>电路逻辑表达式为<span class="math inline"> <em>Ā</em><em>B</em> + <em>B̄</em><em>A</em></span></p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/DSFDSG.png" alt="DSFDSG">
<figcaption aria-hidden="true">DSFDSG</figcaption>
</figure>
<p>电路逻辑表达式为<span class="math inline"> <em>Y</em> = <em>Ā</em><em>B</em> + <em>B̄</em><em>A</em></span>
<span class="math inline"> <em>Z</em> = <em>A</em><em>B</em></span></p>
<h2 id="内容三利用与非门控制输出">内容三：利用与非门控制输出</h2>
<h3 id="用一片74ls00按图接线s接任一电平开关用示波器观察s对输出脉冲的控制作用">用一片74LS00按图接线，S接任一电平开关，用示波器观察S对输出脉冲的控制作用</h3>
<h3 id="第一题">第一题</h3>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/4552.png" alt="4552">
<figcaption aria-hidden="true">4552</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/456.png" alt="456">
<figcaption aria-hidden="true">456</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/284.png" alt="284">
<figcaption aria-hidden="true">284</figcaption>
</figure>
<h3 id="第二题">第二题</h3>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/SAD.png" alt="SAD">
<figcaption aria-hidden="true">SAD</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/VX.png" alt="VX">
<figcaption aria-hidden="true">VX</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/GS.png" alt="GS">
<figcaption aria-hidden="true">GS</figcaption>
</figure>
<h2 id="内容四用与非门组成其它门电路并测试验证">内容四：用与非门组成其它门电路并测试验证</h2>
<h3 id="第一题组成或非门">第一题：组成或非门</h3>
<p>用一片2输入端四与非门组成或非门</p>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/dsaf.png" alt="dsaf">
<figcaption aria-hidden="true">dsaf</figcaption>
</figure>
<table>
<thead>
<tr>
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<h3 id="第二题组成异或门">第二题：组成异或门</h3>
<p>同内容二</p>
<h2 id="内容五逻辑门传输延迟时间的测量">内容五：逻辑门传输延迟时间的测量</h2>
<p>用六反相器（非门）按图接线，输入200KHz连续脉冲，用双踪示波器测量输入、输出相位差，计算每个门的平均传输延迟时间的值。</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/asdfa.png" alt="asdfa">
<figcaption aria-hidden="true">asdfa</figcaption>
</figure>
<p>74LS04功能：<strong>六反相器</strong>，其内部结构及真值表如图</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/sad-1730613828885-37.png" alt="sad">
<figcaption aria-hidden="true">sad</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/sads.png" alt="sads">
<figcaption aria-hidden="true">sads</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/afdga.png" alt="afdga">
<figcaption aria-hidden="true">afdga</figcaption>
</figure>
<h2 id="内容六用基本门电路组装一个译码电路将bcd8421码转换成格雷码">内容六：用基本门电路组装一个译码电路：将BCD8421码转换成格雷码</h2>
<p>BCD8421码：二进制编码的十进制数，简称BCD码</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/t0131751fc49c1edcb4.png" alt="t0131751fc49c1edcb4">
<figcaption aria-hidden="true">t0131751fc49c1edcb4</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/63d335349be6acd1189581d69870bd56.png" alt="63d335349be6acd1189581d69870bd56">
<figcaption aria-hidden="true">63d335349be6acd1189581d69870bd56</figcaption>
</figure>
<p>一位不产生进位的加法电路用<a href="https://so.csdn.net/so/search?q=异或门&amp;spm=1001.2101.3001.7020">异或门</a>就可以实现，下图左边为一个二进制-格雷码转换器器，右边为一个格雷码-二进制码转换器。</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/353484a62261823731307a1969c8278e.png" alt="353484a62261823731307a1969c8278e">
<figcaption aria-hidden="true">353484a62261823731307a1969c8278e</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/sadsfdf.png" alt="sadsfdf">
<figcaption aria-hidden="true">sadsfdf</figcaption>
</figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/qq_41628475/article/details/136149964">数字电路逻辑与设计实验一
门电路逻辑功能及测试_数电实验-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数字逻辑电路</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>数字逻辑电路</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机组成原理</title>
    <url>/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h3 id="section"></h3>
<p>奇偶校验法</p>
<p>海明校验码（略有涉及）</p>
<p>原码补码乘除法</p>
<h3 id="布斯算法">布斯算法</h3>
<p>布斯算法是一种<strong>用于补码乘法</strong>的算法。 它的优点是：</p>
<ul>
<li><strong>直接处理补码</strong>（无需转成原码）</li>
<li><strong>减少加减次数</strong>（尤其当乘数中有连续1时）</li>
<li><strong>统一处理正负数</strong></li>
</ul>
<blockquote>
<p>💡 传统乘法：遇到1就加被乘数；遇到0就跳过。
布斯算法：看<strong>相邻两位的变化</strong>，决定是否加/减。</p>
</blockquote>
<p>布斯算法观察<strong>乘数的相邻两位</strong>（包括一个额外的最低位 Q₋₁
= 0），根据以下规则操作：</p>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 17%">
<col style="width: 53%">
</colgroup>
<thead>
<tr>
<th>当前位 Q₀</th>
<th>前一位 Q₋₁</th>
<th>操作</th>
<th>原因（数学本质）</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td><strong>无操作</strong></td>
<td>连续0，无需累加</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td><strong>无操作</strong></td>
<td>连续1，已在前面处理过</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td><strong>+ 被乘数</strong></td>
<td>从1→0，表示一个“正的块”结束 → 加一次</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td><strong>− 被乘数</strong></td>
<td>从0→1，表示一个“负的块”开始 → 减一次</td>
</tr>
</tbody>
</table>
<p><strong>布斯算法在右移时，必须使用「算术右移（Arithmetic Right
Shift）」，即：</strong></p>
<ul>
<li><strong>符号位（最高位）保持不变</strong></li>
<li><strong>左边补的是符号位的值（正数补0，负数补1）</strong></li>
</ul>
<h3 id="加减交替法">加减交替法</h3>
<p><a href="https://www.bilibili.com/video/BV1DY4y177dV/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">原码除法
恢复余数法和不恢复余数法(加减交替法) 计组_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1yToCYjEUK?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=2">整数除法处理过程_哔哩哔哩_bilibili</a></p>
<p><strong>整数不恢复余数除法</strong>中，<strong>被除数通常要进行位扩展</strong></p>
<p>在<strong>不恢复余数除法（加减交替法）*<em>中，**整数除法**和*</em>小数除法</strong>的核心算法是一样的，都是根据余数的正负决定商位和下一步操作。但它们在<strong>初始设置、精度控制、终止条件、结果处理</strong>等方面有明显区别。</p>
<p><a href="https://zhuanlan.zhihu.com/p/417008434">定点整数的除法 -
知乎</a></p>
<p><a href="https://www.bilibili.com/video/BV11b1UBoEGF/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">「小白debug」如何用开关造出一台计算机_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大三上</category>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习</title>
    <url>/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="交叉熵">交叉熵</h3>
<p>交叉熵（Cross-Entropy）主要用于衡量两个概率分布之间的差异。在分类任务中，它被广泛用作<strong>损失函数</strong>，来评估模型预测结果与真实标签之间的“不匹配程度”。</p>
<ol type="1">
<li><strong>信息量（Information Content）</strong></li>
</ol>
<p>一个事件 ( x ) 发生的概率为 ( p(x)
)，其<strong>信息量</strong>定义为： [ I(x) = -p(x) ] -
概率越小的事件，发生时带来的信息量越大（比如“太阳从西边升起”）。 -
单位通常是 <strong>比特（bit）</strong>（以 2 为底）或
<strong>纳特（nat）</strong>（以自然对数 ( e ) 为底）。</p>
<ol start="2" type="1">
<li><strong>熵（Entropy）</strong></li>
</ol>
<p>熵是<strong>一个概率分布的平均信息量</strong>，表示该分布的不确定性：
[ H(p) = -_{x} p(x) p(x) ] -
熵越大，不确定性越高（比如公平硬币的熵比偏硬币大）。</p>
<ol start="3" type="1">
<li><strong>交叉熵（Cross-Entropy）</strong></li>
</ol>
<p>现在有两个分布： - <strong>真实分布</strong> ( p(x) )（比如真实标签）
- <strong>模型预测分布</strong> ( q(x) )（比如神经网络输出的概率）</p>
<p>交叉熵衡量的是：<strong>当我们用分布 ( q ) 来编码来自分布 ( p )
的事件时，平均需要多少比特</strong>。</p>
<p>数学定义为： [ H(p, q) = -_{x} p(x) q(x) ]</p>
<blockquote>
<p>🔍 注意：交叉熵 ≠ 熵。<br>
- 熵：( H(p) = -p p )<br>
- 交叉熵：( H(p, q) = -p q )</p>
</blockquote>
<h4 id="sigmoid的交叉熵损失函数">Sigmoid的交叉熵损失函数</h4>
<p>Sigmoid 的交叉熵损失函数（通常称为
<strong>二元交叉熵损失</strong>，Binary Cross-Entropy
Loss）是用于二分类问题中，结合 Sigmoid 激活函数使用的损失函数。</p>
<ul>
<li><p>在二分类任务中，模型输出一个实数值 ( z )（logit）。</p></li>
<li><p>通过 Sigmoid 函数将其映射到概率区间 ([0, 1])： [ = (z) = ] 其中
() 表示预测为正类（标签为 1）的概率。</p></li>
<li><p>真实标签 ( y {0, 1} )。</p></li>
</ul>
<h5 id="二元交叉熵损失binary-cross-entropy-bce">二元交叉熵损失（Binary
Cross-Entropy, BCE）</h5>
<p>对于单个样本，损失函数定义为：</p>
<p>[ (y, ) = -]</p>
<p>其中： - 若 ( y = 1 )，损失为 ( -() ) - 若 ( y = 0 )，损失为 ( -(1 -
) )</p>
<h4 id="softmax-的交叉熵损失函数"><strong>Softmax
的交叉熵损失函数</strong></h4>
<p><strong>Softmax 函数</strong></p>
<p>给定 logits 向量 ( = [z_1, z_2, …, z_C] )（C 为类别数），Softmax
输出预测概率：</p>
<p>[ _i = (z_i) = ]</p>
<p><strong>交叉熵损失（单个样本）</strong></p>
<p>真实标签为 one-hot 向量 ( = [y_1, y_2, …, y_C]
)，其中只有真实类别位置为 1，其余为 0。</p>
<p>损失函数为：</p>
<p>[ = -_{i=1}^{C} y_i (_i) ]</p>
<p>由于 ( y_i ) 只有一个为 1（设真实类别为 ( c )），上式简化为：</p>
<p>[ = -(_c) = -( ) ]</p>
<p>进一步化简：</p>
<p>[ = -z_c + ( _{j=1}^{C} e^{z_j} ) ]</p>
<h4 id="sigmoid和softmax区别">Sigmoid和Softmax区别</h4>
<p><strong>1.Sigmoid（逐元素</strong>）</p>
<p>对输入 ( x )（标量或向量中的每个元素）： [ (x) = (0, 1) ]</p>
<blockquote>
<p>📌 如果输入是向量 ( = [x_1, x_2, …, x_n] )，则输出： [ [(x_1), (x_2),
…, (x_n)] ] <strong>每个元素独立计算，彼此无关</strong>。</p>
</blockquote>
<p><strong>2. Softmax（整体归一化）</strong></p>
<p>对输入向量 ( = [z_1, z_2, …, z_C] )： [ (z_i) = (0, 1) ]</p>
<blockquote>
<p>✅ 满足：( _{i=1}^{C} (z_i) = 1 )</p>
</blockquote>
<p><strong>应用场景对比</strong></p>
<p><strong>Sigmoid 适用场景：</strong></p>
<p><strong>多标签分类（Multi-label）</strong></p>
<ul>
<li>每个样本可属于多个类别（如一张图同时有“猫”和“狗”）</li>
<li>输出 C 个独立概率，每个用 Sigmoid 判断是否属于该类</li>
<li>例如：输出 <code>[0.9, 0.2, 0.8]</code> 表示属于类别 0 和 2</li>
</ul>
<p><strong>Softmax 适用场景：</strong></p>
<p><strong>多分类问题（Multi-class, 互斥）</strong></p>
<ul>
<li>每个样本<strong>只属于一个类别</strong>（如 MNIST 手写数字
0~9）</li>
<li>输出 C 个概率，<strong>和为 1</strong>，最大值对应预测类别</li>
<li>例如：输出 <code>[0.1, 0.7, 0.2]</code> 表示最可能是类别 1</li>
</ul>
<blockquote>
<p>简单来说</p>
<ul>
<li><strong>“多选一” → Softmax</strong></li>
<li><strong>“可多选” 或 “是/否” → Sigmoid</strong></li>
</ul>
</blockquote>
<h4 id="为什么多分类要用-softmax而不是对每个类别用-sigmoid-再取最大值"><strong>为什么多分类要用
Softmax，而不是对每个类别用 Sigmoid 再取最大值？</strong></h4>
<p>问题在于 <strong>损失函数</strong>：</p>
<p>如果你用 <strong>Binary Cross-Entropy (BCE)</strong>（Sigmoid
的配套损失）：</p>
<ul>
<li>损失 = <code>- [y₁·log(p₁) + y₂·log(p₂) + y₃·log(p₃)]</code></li>
<li>对于标签 <code>[0, 1, 0]</code>，损失只惩罚“狗”的预测（希望
p₂→1），但<strong>不惩罚“猫”和“鸟”是否太高</strong>！</li>
<li>结果：模型可能输出
<code>[0.9, 0.95, 0.8]</code>，虽然选对了“狗”，但对其他类也过于自信，泛化差。</li>
</ul>
<p>而 <strong>Softmax + Cross-Entropy</strong>：</p>
<ul>
<li>损失 = <code>-log(p₂)</code></li>
<li>但因为 <code>p₂ = e^&#123;z₂&#125;/(e^&#123;z₁&#125;+e^&#123;z₂&#125;+e^&#123;z₃&#125;)</code>，<strong>要让
p₂ 变大，必须让 z₂ 相对于 z₁、z₃ 更大</strong>。</li>
<li>所以模型会<strong>主动压制错误类别的
logit</strong>，学习更清晰的决策边界。</li>
</ul>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://zh.d2l.ai/index.html">《动手学深度学习》 —
动手学深度学习 2.0.0 documentation</a></p>
<p><a href="https://courses.d2l.ai/zh-v2/">课程安排 -
动手学深度学习课程</a></p>
]]></content>
      <categories>
        <category>大三上</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——树和二叉树</title>
    <url>/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/</url>
    <content><![CDATA[<h1 id="树">树</h1>
<h2 id="树的基本术语">树的基本术语</h2>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/d72517fa6b39dc28ff37c0942cda4df1.png" alt="d72517fa6b39dc28ff37c0942cda4df1">
<figcaption aria-hidden="true">d72517fa6b39dc28ff37c0942cda4df1</figcaption>
</figure>
<ol type="1">
<li><p>结点的度和树的度</p>
<p>树中结点的最大度数称为<strong>树的度</strong>。如结点B的度为2,结点D的度为3,树的度为3。</p></li>
<li><p>孩子，双亲，兄弟结点</p></li>
<li><p>路径和路径长度</p>
<p>树中两个结点之间的<strong>路径</strong>是由这两个结点之间所经过的结点序列构成的,而<strong>路径长度</strong>是路径上所经过的边的个数。
注意:由于树中的分支是有向的,即从双亲指向孩子,所以树中的路径是从上向下的,同一双亲的两个孩子之间不存在路径。</p></li>
<li><p>子孙结点和祖先结点</p>
<p>根A到结点K的唯一路径上的任意结点,称为结点K的<strong>祖先</strong>。如结点B是结点K的祖先,而结点K是结点B的<strong>子孙</strong>。</p></li>
<li><p>结点的层次和树的高度</p>
<p><strong>结点的层次</strong>从树根开始定义,根结点为第1层,它的子结点为第2层,以此类推。</p></li>
<li><p>有序树和无序树</p>
<p>树中结点的各子树从左到右是有次序的,不能互换,称该树为<strong>有序树</strong>,否则称为<strong>无序树</strong>。</p></li>
<li><p>森林</p>
<p><strong>森林</strong>是m (m≥0)棵互不相交的树的集合。</p></li>
</ol>
<h2 id="树的存储结构">树的存储结构</h2>
<h3 id="多叉链表表示法">多叉链表表示法</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/fasdfa.png" alt="fasdfa">
<figcaption aria-hidden="true">fasdfa</figcaption>
</figure>
<p>采用多叉链表表示法存储树，许多算法设计可以直接参照二叉树的二叉链表结构的算法。其优点是简单易学，缺点是存在许多指针域的浪费。设树中结点数是n，树的度是k，则共使用了n×k个指针域，而这其中只有n
-1个非空指针城。</p>
<h3 id="孩子链表表示法">孩子链表表示法</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/safsafsxcx.png" alt="safsafsxcx">
<figcaption aria-hidden="true">safsafsxcx</figcaption>
</figure>
<p>当树的度较大时，CTree类可以减少多叉链表表示法的空间浪费。但是，当插入、删除结点时，却会涉及多个孩子链表的调整,还有可能造成存储空间的再分配，因此时间复杂度较大。在CTree类中，利用孩子链表可以方便、快捷地查找指定结点的孩子结点。但是，查找双亲结点则需遍历所有的孩子链表,因此效率就低得多了。</p>
<h3 id="双亲表示法">双亲表示法</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/sadfas.png" alt="sadfas">
<figcaption aria-hidden="true">sadfas</figcaption>
</figure>
<p>在PTree类中，不仅利用结点的双亲指针域很容易找到其双亲结点，而且查找其所有祖先结点也非常便利、高效。若需要查找指定结点的孩子或子孙结点，则需遍历整个树的存储空间，效率就低得多了。</p>
<h3 id="孩子兄弟表示法">孩子兄弟表示法</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/dasfgae.png" alt="dasfgae">
<figcaption aria-hidden="true">dasfgae</figcaption>
</figure>
<p>因为孩子兄弟表示法建立起了树和二叉树之间的对应关系，所以常常将其称为树的二叉树表示法。相比树的其他存储结构，孩子兄弟表示法既简化了结构，又可以将许多二叉树的优秀算法移植到树结构的应用中来，因此具有很好的学习、应用价值。</p>
<h2 id="树的操作算法">树的操作算法</h2>
<h3 id="构造算法">构造算法</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 构造函数</span></span><br><span class="line">    <span class="built_in">CSTree</span>(vector&lt;pair&lt;T, T&gt;&gt;&amp; ps) &#123;</span><br><span class="line">        <span class="keyword">if</span> (ps.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            root = <span class="literal">nullptr</span>;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 创建根节点</span></span><br><span class="line">        root = <span class="keyword">new</span> <span class="built_in">CSNode</span>&lt;T&gt;(ps[<span class="number">0</span>].first);</span><br><span class="line">        root-&gt;firstchild = <span class="literal">nullptr</span>;</span><br><span class="line">        root-&gt;nextsibling = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 插入其他节点</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; ps.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="built_in">InsertNode</span>(ps[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 插入节点</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">InsertNode</span><span class="params">(pair&lt;T, T&gt;&amp; p)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 创建新节点</span></span><br><span class="line">        CSNode&lt;T&gt;* child = <span class="keyword">new</span> <span class="built_in">CSNode</span>&lt;T&gt;(p.second);</span><br><span class="line">        child-&gt;firstchild = <span class="literal">nullptr</span>;</span><br><span class="line">        child-&gt;nextsibling = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到父节点</span></span><br><span class="line">        CSNode&lt;T&gt;* parent = <span class="built_in">Search</span>(root, p.first);</span><br><span class="line">        <span class="keyword">if</span> (!parent) &#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;Parent node &quot;</span> &lt;&lt; p.first &lt;&lt; <span class="string">&quot; not found!&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 若父节点无子节点，将新节点作为第一个子节点</span></span><br><span class="line">        <span class="keyword">if</span> (parent-&gt;firstchild == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            parent-&gt;firstchild = child;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 若父节点已有子节点，将新节点作为最后一个子节点</span></span><br><span class="line">            CSNode&lt;T&gt;* temp = parent-&gt;firstchild;</span><br><span class="line">            <span class="keyword">while</span> (temp-&gt;nextsibling != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                temp = temp-&gt;nextsibling;</span><br><span class="line">            &#125;</span><br><span class="line">            temp-&gt;nextsibling = child;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h3 id="计算树的高度">计算树的高度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计算指定节点子树的高度</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> CSTree&lt;T&gt;::<span class="built_in">Height</span>(CSNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">nullptr</span>)  <span class="comment">// 如果节点为空，返回高度 0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> maxheight = <span class="number">0</span>;  <span class="comment">// 初始化子树的最大高度为 0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历所有子节点</span></span><br><span class="line">    <span class="keyword">for</span> (CSNode&lt;T&gt;* child = p-&gt;firstchild; child != <span class="literal">nullptr</span>; child = child-&gt;nextsibling) &#123;</span><br><span class="line">        <span class="type">int</span> height = <span class="built_in">Height</span>(child);  <span class="comment">// 递归计算子节点的高度</span></span><br><span class="line">        <span class="keyword">if</span> (height &gt; maxheight)      <span class="comment">// 更新最大高度</span></span><br><span class="line">            maxheight = height;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> maxheight + <span class="number">1</span>;  <span class="comment">// 当前节点的高度为子树最大高度 + 1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 外部接口：计算整棵树的高度</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> CSTree&lt;T&gt;::<span class="built_in">Height</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Height</span>(root);  <span class="comment">// 从根节点开始计算高度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="计算所有结点的度">计算所有结点的度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计算指定节点的度并递归处理其子树</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> CSTree&lt;T&gt;::<span class="built_in">Degree</span>(CSNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">nullptr</span>)  <span class="comment">// 如果节点为空，直接返回</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    p-&gt;degree = <span class="number">0</span>;  <span class="comment">// 初始化节点的度为 0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历所有子节点，统计度</span></span><br><span class="line">    <span class="keyword">for</span> (CSNode&lt;T&gt;* child = p-&gt;firstchild; child != <span class="literal">nullptr</span>; child = child-&gt;nextsibling) &#123;</span><br><span class="line">        p-&gt;degree++;  <span class="comment">// 子节点存在则度加 1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Degree</span>(p-&gt;firstchild);    <span class="comment">// 递归处理子节点的度</span></span><br><span class="line">    <span class="built_in">Degree</span>(p-&gt;nextsibling);   <span class="comment">// 递归处理兄弟节点的度</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 外部接口：计算整棵树的所有节点的度</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> CSTree&lt;T&gt;::<span class="built_in">Degree</span>() &#123;</span><br><span class="line">    <span class="built_in">Degree</span>(root);  <span class="comment">// 从根节点开始计算度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="二叉树">二叉树</h1>
<h2 id="特殊的二叉树">特殊的二叉树</h2>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/3ca44306b6c5f97c3544f5d091be9ac4.png" alt="3ca44306b6c5f97c3544f5d091be9ac4">
<figcaption aria-hidden="true">3ca44306b6c5f97c3544f5d091be9ac4</figcaption>
</figure>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/a99ebdd407f8c2508597d85c610c44a7.png" alt="a99ebdd407f8c2508597d85c610c44a7">
<figcaption aria-hidden="true">a99ebdd407f8c2508597d85c610c44a7</figcaption>
</figure>
<h2 id="二叉树的性质">二叉树的性质</h2>
<p>非空二叉树上的叶子结点数等于度为2的结点数加1，即<span class="math inline"> <em>n</em><sub>0</sub> = <em>n</em><sub>1</sub> + 1</span></p>
<p>因为二叉树中所有节点的度只能是 0、1、2，所以节点总数 <span class="math inline"> <em>n</em> = <em>n</em><sub>0</sub> + <em>n</em><sub>1</sub> + <em>n</em><sub>2</sub></span></p>
<p>其次考虑二叉树的分支总数。将二叉树的分支总数记作 m。
因为所有的分支是由度为 1 和度为 2 的节点发出的，所以<span class="math inline"><em>m</em> = <em>n</em><sub>1</sub> + 2 × <em>n</em><sub>2</sub></span></p>
<p>最后，由树的性质 1，可得 <span class="math inline"><em>n</em> = <em>m</em> + 1</span>，即<span class="math inline"><em>n</em><sub>0</sub> + <em>n</em><sub>1</sub> + <em>n</em><sub>2</sub> = <em>n</em><sub>1</sub> + 2 × <em>n</em><sub>2</sub> + 1</span></p>
<h2 id="二叉树的存储结构">二叉树的存储结构</h2>
<h3 id="顺序结构">顺序结构</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/afdfa.png" alt="afdfa">
<figcaption aria-hidden="true">afdfa</figcaption>
</figure>
<p>当二叉树单分支节点较多，高度变化较大时，空间浪费现象惊人</p>
<h3 id="链式结构">链式结构</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/adsfgad.png" alt="adsfgad">
<figcaption aria-hidden="true">adsfgad</figcaption>
</figure>
<h2 id="二叉树的遍历">二叉树的遍历</h2>
<p>前序遍历：根左右</p>
<p>中序遍历：左根右</p>
<p>后序遍历：左右根</p>
<p>先序遍历算法如下</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> BiTree&lt;T&gt;::<span class="built_in">PreOrder</span>(BiNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span>;             <span class="comment">// ① 若二叉树为空，则遍历结束</span></span><br><span class="line">    cout &lt;&lt; p-&gt;data;        <span class="comment">// ② 访问当前结点</span></span><br><span class="line">    <span class="built_in">PreOrder</span>(p-&gt;lchild);    <span class="comment">// ③ 先序遍历当前结点的左子树</span></span><br><span class="line">    <span class="built_in">PreOrder</span>(p-&gt;rchild);    <span class="comment">// ④ 先序遍历当前结点的右子树</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> BiTree&lt;T&gt;::<span class="built_in">PreOrder</span>() &#123;</span><br><span class="line">    <span class="built_in">PreOrder</span>(root);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>层序遍历：利用队列</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> BiTree&lt;T&gt;::<span class="built_in">LevelOrder</span>() &#123;</span><br><span class="line">    <span class="keyword">if</span> (root == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span>;             <span class="comment">// ① 若二叉树为空，则遍历结束</span></span><br><span class="line"></span><br><span class="line">    LinkQueue&lt;BiNode&lt;T&gt;*&gt; Q;    <span class="comment">// 定义一个队列存储节点指针</span></span><br><span class="line">    Q.<span class="built_in">EnQueue</span>(root);            <span class="comment">// ② 将根指针加入指针队列</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!Q.<span class="built_in">Empty</span>()) &#123;        <span class="comment">// ③ 若指针队列不空，则循环</span></span><br><span class="line">        BiNode&lt;T&gt;* p = Q.<span class="built_in">DeQueue</span>();   <span class="comment">// ④ 出队列，得到当前指针 p</span></span><br><span class="line">        cout &lt;&lt; p-&gt;data;              <span class="comment">// ④ 访问当前结点</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// ⑤ 若当前结点有左孩子，则左孩子地址进指针队列</span></span><br><span class="line">        <span class="keyword">if</span> (p-&gt;lchild != <span class="literal">NULL</span>)</span><br><span class="line">            Q.<span class="built_in">EnQueue</span>(p-&gt;lchild);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ⑤ 若当前结点有右孩子，则右孩子地址进指针队列</span></span><br><span class="line">        <span class="keyword">if</span> (p-&gt;rchild != <span class="literal">NULL</span>)</span><br><span class="line">            Q.<span class="built_in">EnQueue</span>(p-&gt;rchild);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二叉树的构造算法">二叉树的构造算法</h2>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/sADF.png" alt="sADF">
<figcaption aria-hidden="true">sADF</figcaption>
</figure>
<p>先序序列是<code>abdecf</code>，带空指针标记的先序序列是<code>abd**e**cf ***</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinNode&lt;T&gt;* BinTree&lt;T&gt;::<span class="built_in">CreateByPre</span>(vector&lt;T&gt;&amp; pre, <span class="type">int</span>&amp; i) &#123;</span><br><span class="line">    T e = pre[i]; <span class="comment">// 提取当前数据</span></span><br><span class="line">    i++;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="string">&#x27;*&#x27;</span>) <span class="comment">// 若是特殊数据，返回空指针</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建新结点</span></span><br><span class="line">    BinNode&lt;T&gt;* p = <span class="keyword">new</span> BinNode&lt;T&gt;;</span><br><span class="line">    p-&gt;data = e;</span><br><span class="line">    <span class="comment">// 创建左子树</span></span><br><span class="line">    p-&gt;lchild = <span class="built_in">CreateByPre</span>(pre, i);</span><br><span class="line">    <span class="comment">// 创建右子树</span></span><br><span class="line">    p-&gt;rchild = <span class="built_in">CreateByPre</span>(pre, i);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinTree&lt;T&gt;::<span class="built_in">BinTree</span>(vector&lt;T&gt;&amp; pre) &#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>; <span class="comment">// 向量 pre 的下标变量</span></span><br><span class="line">    root = <span class="built_in">CreateByPre</span>(pre, i); <span class="comment">// 从先序序列构造二叉树</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二叉树的其他操作算法">二叉树的其他操作算法</h2>
<h3 id="计算结点数">计算结点数</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Count</span>(BiNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// 当前节点为空，返回 0</span></span><br><span class="line">    <span class="type">int</span> left = <span class="built_in">Count</span>(p-&gt;lchild);  <span class="comment">// 统计左子树节点数</span></span><br><span class="line">    <span class="type">int</span> right = <span class="built_in">Count</span>(p-&gt;rchild); <span class="comment">// 统计右子树节点数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> + left + right;      <span class="comment">// 当前节点总数 = 左子树 + 右子树 + 当前节点</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Count</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Count</span>(root); <span class="comment">// 从根节点开始统计</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="计算高度">计算高度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Height</span>(BiNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// 空节点高度为 0</span></span><br><span class="line">    <span class="type">int</span> left = <span class="built_in">Height</span>(p-&gt;lchild);  <span class="comment">// 左子树高度</span></span><br><span class="line">    <span class="type">int</span> right = <span class="built_in">Height</span>(p-&gt;rchild); <span class="comment">// 右子树高度</span></span><br><span class="line">    <span class="keyword">return</span> (left &gt; right ? left : right) + <span class="number">1</span>; <span class="comment">// 树高度为左右子树最大高度 + 1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Height</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Height</span>(root); <span class="comment">// 从根节点开始计算树高度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="查找结点">查找结点</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinNode&lt;T&gt;* BiTree&lt;T&gt;::<span class="built_in">Search</span>(BinNode&lt;T&gt;* p, T e) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;  <span class="comment">// 查找失败</span></span><br><span class="line">    <span class="keyword">if</span> (p-&gt;data == e)</span><br><span class="line">        <span class="keyword">return</span> p;     <span class="comment">// 查找成功，返回节点指针</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在左子树中递归查找</span></span><br><span class="line">    BinNode&lt;T&gt;* q = <span class="built_in">Search</span>(p-&gt;lchild, e);</span><br><span class="line">    <span class="keyword">if</span> (q != <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> q; <span class="comment">// 若在左子树中找到，返回结果</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在右子树中递归查找</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Search</span>(p-&gt;rchild, e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinNode&lt;T&gt;* BiTree&lt;T&gt;::<span class="built_in">Search</span>(T e) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Search</span>(root, e); <span class="comment">// 从根节点开始查找</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="线索二叉树">线索二叉树</h2>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/asfafs.png" alt="asfafs">
<figcaption aria-hidden="true">asfafs</figcaption>
</figure>
<h1 id="哈夫曼树">哈夫曼树</h1>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/wqqwr.png" alt="wqqwr">
<figcaption aria-hidden="true">wqqwr</figcaption>
</figure>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/qetqt.png" alt="qetqt">
<figcaption aria-hidden="true">qetqt</figcaption>
</figure>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://blog.csdn.net/Real_Fool_/article/details/113930623">数据结构：树(Tree)【详解】_数据结构
树-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机组成原理</title>
    <url>/2025/12/12/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%BB%84%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h2 id="三种指令类型-r-i-j">三种指令类型 (R, I, J)</h2>
<p>MIPS 指令集的设计非常整齐，所有的指令都是
<strong>32位（bits）</strong> 长。但是，这 32
个格子怎么分配，取决于指令的类型。</p>
<h4 id="r-type-register-type-寄存器型">(1) R-type (Register type,
寄存器型)</h4>
<ul>
<li><strong>用途</strong>：纯粹的数学运算。</li>
<li><strong>特点</strong>：所有的操作数都在寄存器里。</li>
<li><strong>例子</strong>：<code>add $t0, $t1, $t2</code> (把 t1 和 t2
里的数拿出来相加，结果存到 t0)。</li>
<li><strong>格局</strong>：因为它需要 3
个寄存器（2个源，1个目标），所以它的空间被切得很细，最后剩下了 6 位给
<code>func</code>。</li>
</ul>
<h4 id="i-type-immediate-type-立即数型">(2) I-type (Immediate type,
立即数型)</h4>
<ul>
<li><strong>用途</strong>：涉及常数运算，或者读写内存。</li>
<li><strong>特点</strong>：操作数里包含一个具体的数字（立即数）。</li>
<li><strong>例子</strong>：
<ul>
<li><code>ori $t0, $t1, 100</code> (把 t1 和数字 100 做或运算)。</li>
<li><code>lw $t0, 4($t1)</code> (去内存取数，地址是 t1 + 4)。</li>
</ul></li>
<li><strong>格局</strong>：为了放那个数字（比如 100），它牺牲了
<code>rd</code> 和 <code>func</code> 的位置，腾出了
<strong>16位</strong> 的空间来存这个数。</li>
</ul>
<h4 id="j-type-jump-type-跳转型">(3) J-type (Jump type, 跳转型)</h4>
<ul>
<li><strong>用途</strong>：程序跳转（就像代码里的
<code>goto</code>）。</li>
<li><strong>特点</strong>：跳得很远。</li>
<li><strong>例子</strong>：<code>j 1000</code> (直接跳到地址 1000
去执行)。</li>
<li><strong>格局</strong>：除了开头的 op，剩下的 <strong>26位</strong>
全用来存目标地址，保证能跳得足够远。</li>
</ul>
<table>
<colgroup>
<col style="width: 5%">
<col style="width: 11%">
<col style="width: 27%">
<col style="width: 27%">
<col style="width: 27%">
</colgroup>
<thead>
<tr>
<th><strong>指令类型</strong></th>
<th><strong>全称 (中文名)</strong></th>
<th><strong>包含的常见指令 (加粗为你课件中的)</strong></th>
<th><strong>核心特征</strong></th>
<th><strong>指令格式结构 (32位)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>R-Type</strong></td>
<td>Register Type (寄存器型)</td>
<td><strong>add</strong> (加法) <strong>sub</strong> (减法) and, or,
slt, nor</td>
<td><strong>纯运算</strong>。
操作数全在寄存器里，不做数据传输，不涉及立即数。</td>
<td><code>op(6)</code> <code>rs(5)</code> <code>rt(5)</code>
<code>rd(5)</code> <code>shamt(5)</code> <code>func(6)</code>
<em>(特点：op全为0，靠 func 区分)</em></td>
</tr>
<tr>
<td><strong>I-Type</strong></td>
<td>Immediate Type (立即数型)</td>
<td><strong>ori</strong> (或立即数) <strong>lw</strong> (加载字)
<strong>sw</strong> (存储字) <strong>beq</strong> (相等分支) addi, andi,
bne</td>
<td><strong>带常数/地址偏移</strong>。
计算或访存时，需要用到一个具体的数字（16位）。</td>
<td><code>op(6)</code> <code>rs(5)</code> <code>rt(5)</code>
<code>immediate(16)</code> <em>(特点：最后16位是常数/地址)</em></td>
</tr>
<tr>
<td><strong>J-Type</strong></td>
<td>Jump Type (跳转型)</td>
<td><strong>jump</strong> (无条件跳转) jal (跳转并链接)</td>
<td><strong>长距离跑路</strong>。
不需要计算，直接跳到程序代码的另一个位置。</td>
<td><code>op(6)</code> <code>address(26)</code>
<em>(特点：后面26位全是目标地址)</em></td>
</tr>
</tbody>
</table>
<h2 id="op-和-func-是什么"><code>op</code> 和 <code>func</code>
是什么？</h2>
<p>这两个是指令的<strong>身份证</strong>。</p>
<ul>
<li><strong><code>op</code> (Opcode, 操作码)</strong>：指令的<strong>高
6 位</strong> (31-26 bit)。
<ul>
<li><strong>作用</strong>：它决定了这到底是一条什么指令（大类）。</li>
<li><strong>比喻</strong>：就像身份证上的“省份”。控制器一看
<code>op</code>，就知道你是 <code>lw</code> 还是 <code>sw</code> 还是
<code>beq</code>。</li>
<li><strong>特殊情况</strong>：对于所有的 <strong>R-type</strong>
指令，它们的 <code>op</code> 都是
<code>000000</code>。这就尴尬了，控制器光看 <code>op</code>
分不清你是加法还是减法。</li>
</ul></li>
<li><strong><code>func</code> (Function code,
功能码)</strong>：指令的<strong>低 6 位</strong> (5-0 bit)。
<ul>
<li><strong>作用</strong>：专门用来区分 R-type 指令的具体操作。</li>
<li><strong>比喻</strong>：就像身份证上的“名字”。</li>
<li><strong>逻辑</strong>：当 <code>op</code> 是 <code>000000</code>
时，控制器就会去查 <code>func</code>。
<ul>
<li><code>func = 100000</code> -&gt; 做加法 (add)</li>
<li><code>func = 100010</code> -&gt; 做减法 (sub)</li>
</ul></li>
<li><strong>注意</strong>：只有 R-type 有 <code>func</code>。I-type 和
J-type 的这最后 6
位已经被那个常数或者地址占用了，所以它们<strong>没有</strong> func
字段。</li>
</ul></li>
</ul>
<figure>
<img src="/2025/12/12/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%BB%84%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/image-20251212164727970.png" alt="image-20251212164727970">
<figcaption aria-hidden="true">image-20251212164727970</figcaption>
</figure>
<h3 id="为什么对于所有的-r-type-指令它们的-op-都是-000000">为什么对于所有的
R-type 指令，它们的 op 都是 000000</h3>
<p>设计者回头看了一眼 <strong>R-type</strong>
指令的格式。他们发现了一个惊喜：</p>
<p>R-type 指令只需要存 3 个寄存器编号（<code>rs</code>, <code>rt</code>,
<code>rd</code>）和 1 个移位量（<code>shamt</code>）。</p>
<ul>
<li><code>op</code>: 6位</li>
<li><code>rs</code>: 5位</li>
<li><code>rt</code>: 5位</li>
<li><code>rd</code>: 5位</li>
<li><code>shamt</code>: 5位</li>
<li><strong>总共使用</strong>：<span class="math inline">6 + 5 + 5 + 5 + 5 = 26</span> 位。</li>
</ul>
<p>32 - 26 = 6 位！</p>
<p>R-type 指令的末尾，正好空出了 6位 没地方用。</p>
<p>天才的设计思路来了：</p>
<p>既然 R-type 指令末尾空着 6 位，那为什么不把 Opcode 统一设为
000000（意思是：这是一条运算指令），然后利用末尾这空闲的 6 位（也就是
func 字段）来具体区分是加法还是减法呢？</p>
<ul>
<li>这样一来，<code>add</code>, <code>sub</code>, <code>and</code>,
<code>or</code>, <code>slt</code> 等几十条运算指令，在 Opcode
表里<strong>只占用 1 个位置</strong>（就是 000000）。</li>
<li>这就把剩下的 63 个 Opcode 宝贵名额，留给了那些没有空闲位置的 I-type
和 J-type 指令（因为它们后面被立即数填满了，没有 <code>func</code>
字段可用）。</li>
</ul>
<h2 id="控制信号的含义都有哪些">控制信号的含义都有哪些</h2>
<p>这些信号就是控制器发出的“命令”，控制数据通路里的<strong>多路选择器
(Mux)</strong> 和 <strong>使能开关 (Enable)</strong>。</p>
<p>我们把它们分为三类来记：</p>
<h4 id="第一类选路信号mux-selectors">第一类：选路信号（Mux
Selectors）</h4>
<p>这些信号决定数据走哪条路。你可以理解为火车轨道的<strong>道岔</strong>。如果是
<code>0</code> 走左边，<code>1</code> 走右边。</p>
<ol type="1">
<li><strong><code>RegDst</code> (Register Destination)</strong>
<ul>
<li><strong>含义</strong>：<strong>运算结果存到哪个寄存器编号里？</strong></li>
<li><strong>背景</strong>：
<ul>
<li>R-type 的目标寄存器编号在指令的第 15-11 位 (<code>rd</code>
字段)。</li>
<li>I-type (如 lw) 的目标寄存器编号在指令的第 20-16 位 (<code>rt</code>
字段)。</li>
</ul></li>
<li><strong>值</strong>：
<ul>
<li><code>1</code>: 选 <code>rd</code> (R-type)。</li>
<li><code>0</code>: 选 <code>rt</code> (I-type)。</li>
</ul></li>
</ul></li>
<li><strong><code>ALUSrc</code> (ALU Source)</strong>
<ul>
<li><strong>含义</strong>：<strong>ALU
的第二个操作数来自哪里？</strong></li>
<li><strong>值</strong>：
<ul>
<li><code>0</code>: 来自寄存器堆的读出数据（两个寄存器做运算，如
R-type）。</li>
<li><code>1</code>: 来自指令里的立即数（寄存器和数字做运算，如
<code>ori</code>, <code>lw</code>, <code>sw</code>）。</li>
</ul></li>
</ul></li>
<li><strong><code>MemtoReg</code> (Memory to Register)</strong>
<ul>
<li><strong>含义</strong>：<strong>写回寄存器的数据来源是谁？</strong></li>
<li><strong>值</strong>：
<ul>
<li><code>1</code>: 来自内存的数据（只有 <code>lw</code>
指令是这样，把数据从仓库搬回寄存器）。</li>
<li><code>0</code>: 来自 ALU 的计算结果（绝大多数指令，如
<code>add</code>, <code>ori</code>）。</li>
</ul></li>
</ul></li>
</ol>
<h4 id="第二类开关信号enables">第二类：开关信号（Enables）</h4>
<p>这些信号是<strong>安全锁</strong>。只有设为
<code>1</code>，才允许动作。</p>
<ol type="1">
<li><strong><code>RegWr</code> (Register Write)</strong>
<ul>
<li><strong>含义</strong>：<strong>允不允许修改寄存器的值？</strong></li>
<li><strong>值</strong>：
<ul>
<li><code>1</code>: 允许写。像 <code>add</code>, <code>lw</code>,
<code>ori</code> 这种需要保存结果的指令。</li>
<li><code>0</code>: 禁止写。像 <code>sw</code>
(只是往内存存数)，<code>beq</code> (只是比较)，<code>j</code>
(只是跳转)，绝对不能改写寄存器里的数据。</li>
</ul></li>
</ul></li>
<li><strong><code>MemWr</code> (Memory Write)</strong>
<ul>
<li><strong>含义</strong>：<strong>允不允许修改内存的值？</strong></li>
<li><strong>值</strong>：
<ul>
<li><code>1</code>: 允许写。<strong>只有 <code>sw</code> (Store Word)
指令是 1</strong>。</li>
<li><code>0</code>: 禁止写。其他所有指令。</li>
</ul></li>
</ul></li>
</ol>
<h4 id="第三类功能控制信号">第三类：功能控制信号</h4>
<ol type="1">
<li><strong><code>ExtOp</code> (Extension Operation)</strong>
<ul>
<li><strong>含义</strong>：<strong>16位的立即数怎么变成32位？</strong></li>
<li><strong>背景</strong>：指令里的数字只有16位，但计算器是32位的。</li>
<li><strong>值</strong>：
<ul>
<li><code>1</code> (Signed):
<strong>符号扩展</strong>。保持正负号不变（比如 -2 扩展后还是 -2）。用于
<code>lw</code>, <code>sw</code>,
<code>beq</code>（算地址偏移量）。</li>
<li><code>0</code> (Unsigned):
<strong>零扩展</strong>。高位直接补0。用于逻辑运算如
<code>ori</code>。</li>
</ul></li>
</ul></li>
<li><strong><code>Branch</code></strong>
<ul>
<li><strong>含义</strong>：<strong>这是一个条件分支指令吗？</strong></li>
<li><strong>值</strong>：如果是 <code>beq</code> 指令，这个信号是
<code>1</code>。它会结合 ALU 的“零标志位”来决定要不要跳。</li>
</ul></li>
<li><strong><code>Jump</code></strong>
<ul>
<li><strong>含义</strong>：<strong>这是一个无条件跳转指令吗？</strong></li>
<li><strong>值</strong>：如果是 <code>j</code> 指令，这个信号是
<code>1</code>。直接强行修改 PC 指针。</li>
</ul></li>
<li><strong><code>ALUctr</code> (ALU Control)</strong>
<ul>
<li><strong>含义</strong>：<strong>ALU 到底做什么数学题？</strong></li>
<li><strong>值</strong>：这是个多位信号（通常3位或4位）。
<ul>
<li><code>Add</code>: 加法 (用于 <code>add</code>, <code>lw</code>,
<code>sw</code>)</li>
<li><code>Sub</code>: 减法 (用于 <code>sub</code>, <code>beq</code>
比较是否相等)</li>
<li><code>Or</code>: 逻辑或 (用于 <code>ori</code>)</li>
</ul></li>
</ul></li>
</ol>
<h2 id="什么是控制器-controller">什么是控制器 (Controller)？</h2>
<p>在 CPU 这个“大工厂”里，主要分两部分：</p>
<ol type="1">
<li><strong>数据通路
(Datapath)</strong>：这是<strong>干活的工人</strong>和<strong>机器</strong>。包括寄存器（用来记账的小本子）、ALU（算盘/计算器）、内存（大仓库）。它们负责搬运数据、做加减法。</li>
<li><strong>控制器
(Controller)</strong>：这是<strong>工厂的指挥官</strong>。</li>
</ol>
<p><strong>控制器的作用：</strong>
它不直接干活（不存数、不算数），它的任务是<strong>看懂指令</strong>，然后对着数据通路里的各种开关“发号施令”。</p>
<ul>
<li><strong>输入</strong>：它看的是指令（Instruction）。比如指令说“把 A
和 B 加起来”，这串 0101 的机器码传给控制器。</li>
<li><strong>输出</strong>：控制器根据指令，把相应的控制信号线拉高（置1）或拉低（置0）。</li>
</ul>
<blockquote>
<p><strong>一句话总结</strong>：控制器就是 CPU
的大脑，它通过查表（真值表）来告诉身体的各个部位（ALU、寄存器、内存）在当前这一刻该干什么。</p>
</blockquote>
<h2 id="什么是数据通路-datapath">什么是数据通路 (Datapath)？</h2>
<p><strong>它的任务</strong>：根据指挥官（控制器）的命令，把数据从仓库（寄存器/内存）里搬出来，送到加工车间（ALU）算一下，再搬回去。</p>
<p><strong>核心组成</strong>：</p>
<ol type="1">
<li><strong>仓库</strong>：寄存器堆 (Registers)、数据存储器 (Data
Memory)。</li>
<li><strong>车间</strong>：算术逻辑单元 (ALU)、加法器 (Adder)。</li>
<li><strong>交通枢纽</strong>：多路选择器 (Mux)、扩展器 (Ext)。</li>
</ol>
<h2 id="什么是单周期处理器-single-cycle-processor">什么是单周期处理器
(Single-Cycle Processor)？</h2>
<p><strong>核心定义</strong>：CPI (Cycles Per Instruction) = 1。</p>
<p><strong>通俗解释</strong>：</p>
<ul>
<li>时钟信号<strong>“哒”</strong>（上升沿）一下，CPU 开始取指令。</li>
<li>在时钟<strong>“哒”</strong>下一响之前，CPU
必须把这条指令的所有工作（取指、翻译、运算、读写内存、写回结果）全部做完。</li>
</ul>
<h2 id="单周期处理器包含哪些功能">单周期处理器包含哪些功能？</h2>
<p>为了让程序能跑起来，处理器通常需要支持三大类功能（指令）：</p>
<h4 id="a.-算术逻辑运算-r-type">A. 算术逻辑运算 (R-Type)</h4>
<ul>
<li><strong>功能</strong>：做数学题。</li>
<li><strong>指令例子</strong>：<code>add</code> (加), <code>sub</code>
(减), <code>and</code> (与), <code>or</code> (或), <code>slt</code>
(比较大小)。</li>
<li><strong>流程</strong>：读寄存器 -&gt; ALU 算 -&gt; 写回寄存器。</li>
</ul>
<h4 id="b.-数据传输访存-i-type">B. 数据传输/访存 (I-Type)</h4>
<ul>
<li><strong>功能</strong>：搬运数据。CPU
的寄存器太小，数据多了要放内存里。</li>
<li><strong>指令例子</strong>：
<ul>
<li><code>lw</code> (Load Word)：从内存搬到寄存器。</li>
<li><code>sw</code> (Store Word)：从寄存器搬到内存。</li>
</ul></li>
<li><strong>流程</strong>：算地址 -&gt; 读/写内存 -&gt;
(如果是读)写回寄存器。</li>
</ul>
<h4 id="c.-条件分支与跳转-branch-jump">C. 条件分支与跳转 (Branch &amp;
Jump)</h4>
<ul>
<li><strong>功能</strong>：改变程序执行顺序（也就是改变 PC 的值）。</li>
<li><strong>指令例子</strong>：
<ul>
<li><code>beq</code> (Branch if
Equal)：如果两个数相等，就跳到某处去。</li>
<li><code>j</code> (Jump)：无条件直接飞到某处。</li>
</ul></li>
<li><strong>流程</strong>：比较 -&gt; 计算新地址 -&gt; 修改 PC。</li>
</ul>
<h2 id="单周期处理器包含哪些组成部分">单周期处理器包含哪些组成部分？</h2>
<p>我们可以把它分为<strong>“肉体”</strong>（数据通路）和<strong>“灵魂”</strong>（控制单元）两大部分。</p>
<h4 id="第一部分数据通路-datapath-干活的">第一部分：数据通路 (Datapath)
—— “干活的”</h4>
<p>这部分你之前的实验已经做了一大半了，现在需要补全：</p>
<ol type="1">
<li><strong>取指单元 (Instruction Fetch)</strong> ——
<strong>这是新面孔</strong>
<ul>
<li><strong>PC (Program Counter)</strong>：一个 32
位的寄存器，存着“现在执行到哪一行代码了”。</li>
<li><strong>指令存储器 (Instruction
Memory)</strong>：存放你写的机器码的大仓库。</li>
<li><strong>加法器 (+4)</strong>：让 PC 自动加 4，指向下一条指令。</li>
</ul></li>
<li><strong>寄存器堆 (Register File)</strong>
<ul>
<li>CPU 的“口袋”，这里有 32 个格子 ($0 - $31)，用来存放临时数据。</li>
</ul></li>
<li><strong>算术逻辑单元 (ALU)</strong>
<ul>
<li>CPU 的“计算器”，负责算加减法、逻辑运算。</li>
</ul></li>
<li><strong>数据存储器 (Data Memory)</strong>
<ul>
<li>CPU 的“大仓库”，用来做 <code>lw</code> 和 <code>sw</code>。</li>
</ul></li>
<li><strong>扩展单元 (Extender)</strong>
<ul>
<li>把 16 位的立即数变成 32 位。</li>
</ul></li>
<li><strong>多路选择器 (Mux)</strong> —— <strong>交通警察</strong>
<ul>
<li>关键组件！比如 <code>ALUSrc</code> 这个 Mux，决定了 ALU
的输入是来自寄存器还是立即数。</li>
</ul></li>
</ol>
<h4 id="第二部分控制单元-control-unit-发号施令的">第二部分：控制单元
(Control Unit) —— “发号施令的”</h4>
<p>在你上一个实验里，<strong>“你”</strong>就是控制器（手动在波形里设 0
或 1）。现在要写一个模块来替代你。</p>
<ol type="1">
<li><strong>主控制器 (Main Control)</strong>
<ul>
<li><strong>输入</strong>：指令的高 6 位 (Opcode)。</li>
<li><strong>输出</strong>：所有的控制信号 (<code>RegDst</code>,
<code>ALUSrc</code>, <code>MemWr</code> 等)。</li>
<li><strong>作用</strong>：看到 <code>lw</code> 指令，它就自动把
<code>MemtoReg</code> 拉高，把 <code>RegWr</code> 拉高。</li>
</ul></li>
<li><strong>ALU 控制器 (ALU Control)</strong>
<ul>
<li><strong>输入</strong>：主控制器的信号 + 指令的低 6 位 (Funct)。</li>
<li><strong>输出</strong>：给 ALU 的 <code>ALUctr</code>
(3位或4位)。</li>
<li><strong>作用</strong>：专门告诉 ALU 该做加法还是减法。</li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>大三上</category>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机组成原理作业</title>
    <url>/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/</url>
    <content><![CDATA[<h3 id="第一章作业">第一章作业</h3>
<h4 id="section">1</h4>
<p>假设同一套指令集用不同的方法设计了两种机器 M1 和 M2。机器 M1
的时钟周期为 0.8ns，机器 M2 的时钟周期为 1.2ns。某个程序 P 在机器 M1
上运行时的 CPI 为 4，在 M2 上的 CPI 为 2。对于程序 P
来说，哪台机器的执行速度更快？快多少？</p>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251011140015756.png" alt="image-20251011140015756">
<figcaption aria-hidden="true">image-20251011140015756</figcaption>
</figure>
<h4 id="section-1">2</h4>
<p>假定编译器对某段高级语言程序编译生成两种不同的指令序列 S1 和
S2，在时钟频率为 500MHz 的机器 M 上运行，目标指令序列中用到的指令类型有
A、B、C 和 D 四类。每类指令在 M 上的 CPI
和两个指令序列所用的各类指令条数如下表所示。</p>
<table>
<thead>
<tr>
<th>指令类型</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>各指令的 CPI</strong></td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td><strong>S1 的指令条数</strong></td>
<td>5</td>
<td>2</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td><strong>S2 的指令条数</strong></td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>5</td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251011140100523.png" alt="image-20251011140100523">
<figcaption aria-hidden="true">image-20251011140100523</figcaption>
</figure>
<h4 id="section-2">3</h4>
<p>假定机器 M 在运行程序 P 的过程中，共执行了 500×10⁶
条浮点数指令、4000×10⁶ 条整数指令、3000×10⁶ 条访存指令、1000×10⁶
条分支指令，这 4 种指令的 CPI 分别是 2、1、4、1。若要使程序 P
的执行时间减少一半，浮点指令的 CPI 应如何改进？若要使程序 P
的执行时间减少一半，访存指令和分支指令的 CPI
应如何改进？若浮点指令和整数指令的 CPI 减少 20%，访存指令和分支指令的
CPI 减少 40%，则程序 P 的执行时间会减少多少？</p>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251011140106600.png" alt="image-20251011140106600">
<figcaption aria-hidden="true">image-20251011140106600</figcaption>
</figure>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251011140123204.png" alt="image-20251011140123204">
<figcaption aria-hidden="true">image-20251011140123204</figcaption>
</figure>
<h3 id="第二章作业">第二章作业</h3>
<h4 id="section-3">1</h4>
<p>假定某计算机的总线采用奇校验，每8位数据有一位校验位，若在32位数据线上传输的信息是
<code>8F 3C AB 96H</code>，则对应的4个校验位应为什么？
若接收方收到的数据信息和校验位分别为<code>87 3C AB 96H</code> 和
<code>0101B</code>，则说明发生了什么情况，并给出验证过程。</p>
<p><strong>第一部分：计算原始数据 <code>8F 3C AB 96H</code> 对应的 4
个校验位</strong></p>
<p><strong>前提条件：</strong> -
使用<strong>奇校验</strong>：每个字节（8位）中，1的个数必须是<strong>奇数</strong>。
- 每8位数据配1位校验位，所以32位数据分成4个字节，对应4个校验位。 -
数据是十六进制：<code>8F 3C AB 96H</code></p>
<p>我们需要对每一个字节单独计算其奇校验位。</p>
<p><strong>第一步：把每个十六进制字节转换成二进制</strong></p>
<ul>
<li><code>8F H</code> = <code>1000 1111</code></li>
<li><code>3C H</code> = <code>0011 1100</code></li>
<li><code>AB H</code> = <code>1010 1011</code></li>
<li><code>96 H</code> = <code>1001 0110</code></li>
</ul>
<p><strong>第二步：数每个字节中“1”的个数，然后确定校验位</strong></p>
<blockquote>
<p><strong>奇校验规则：</strong>
如果当前字节中“1”的个数是<strong>偶数</strong>，则校验位设为
<code>1</code>，使总数变为奇数；如果是<strong>奇数</strong>，则校验位设为
<code>0</code>，保持奇数。</p>
</blockquote>
<p>我们逐个来看：</p>
<ol type="1">
<li><strong>字节 <code>8F</code> = <code>1000 1111</code></strong>
<ul>
<li>数“1”：位置0, 4,5,6,7 → 共 <strong>5个1</strong> →
是<strong>奇数</strong></li>
<li>所以校验位 = <code>0</code></li>
</ul></li>
<li><strong>字节 <code>3C</code> = <code>0011 1100</code></strong>
<ul>
<li>数“1”：位置2,3,4,5 → 共 <strong>4个1</strong> →
是<strong>偶数</strong></li>
<li>所以校验位 = <code>1</code></li>
</ul></li>
<li><strong>字节 <code>AB</code> = <code>1010 1011</code></strong>
<ul>
<li>数“1”：位置0,2,4,6,7 → 共 <strong>5个1</strong> →
是<strong>奇数</strong></li>
<li>所以校验位 = <code>0</code></li>
</ul></li>
<li><strong>字节 <code>96</code> = <code>1001 0110</code></strong>
<ul>
<li>数“1”：位置0,3,5,6 → 共 <strong>4个1</strong> →
是<strong>偶数</strong></li>
<li>所以校验位 = <code>1</code></li>
</ul></li>
</ol>
<hr>
<p>✅ <strong>所以，对应的4个校验位是：<code>0 1 0 1</code>，即
<code>0101B</code></strong></p>
<p><strong>第二部分：接收方收到的数据是 <code>87 3C AB 96H</code>
和校验位 <code>0101B</code>，发生了什么？验证过程</strong></p>
<p>现在接收方收到： - 数据：<code>87 3C AB 96H</code> -
校验位：<code>0101B</code></p>
<p>我们怀疑有错误，因为原始发送的是 <code>8F</code>，但收到的是
<code>87</code> —— 很可能第一个字节出错了！</p>
<p>我们来<strong>逐字节验证奇校验是否成立</strong>。</p>
<p><strong>第一步：将接收到的数据转为二进制</strong></p>
<ul>
<li><code>87 H</code> = <code>1000 0111</code></li>
<li><code>3C H</code> = <code>0011 1100</code> （没变）</li>
<li><code>AB H</code> = <code>1010 1011</code> （没变）</li>
<li><code>96 H</code> = <code>1001 0110</code> （没变）</li>
</ul>
<p>校验位：<code>0101B</code> → 对应四个字节的校验位分别是：第1字节
<code>0</code>，第2字节 <code>1</code>，第3字节 <code>0</code>，第4字节
<code>1</code></p>
<p><strong>第二步：验证每个字节 + 校验位 是否满足奇校验</strong></p>
<blockquote>
<p>注意：我们验证的是“数据位 + 校验位”一共9位中，1的个数是否为奇数。</p>
</blockquote>
<ol type="1">
<li><strong>第一字节 <code>87</code> + 校验位 <code>0</code></strong>
<ul>
<li>数据位：<code>1000 0111</code> → “1”的个数：位置0, 5,6,7 →
<strong>4个1</strong></li>
<li>加上校验位 <code>0</code> → 总共还是 <strong>4个1</strong> →
是<strong>偶数</strong> ❌</li>
<li>不满足奇校验！→ <strong>出错！</strong></li>
</ul></li>
<li><strong>第二字节 <code>3C</code> + 校验位 <code>1</code></strong>
<ul>
<li>数据位：<code>0011 1100</code> → “1”的个数：4个（偶数）</li>
<li>加上校验位 <code>1</code> → 总共 4+1=5 → <strong>奇数</strong>
✅</li>
<li>正确</li>
</ul></li>
<li><strong>第三字节 <code>AB</code> + 校验位 <code>0</code></strong>
<ul>
<li>数据位：<code>1010 1011</code> → “1”的个数：5个（奇数）</li>
<li>加上校验位 <code>0</code> → 总共 5 → <strong>奇数</strong> ✅</li>
<li>正确</li>
</ul></li>
<li><strong>第四字节 <code>96</code> + 校验位 <code>1</code></strong>
<ul>
<li>数据位：<code>1001 0110</code> → “1”的个数：4个（偶数）</li>
<li>加上校验位 <code>1</code> → 总共 5 → <strong>奇数</strong> ✅</li>
<li>正确</li>
</ul></li>
</ol>
<hr>
<p>✅
<strong>结论：只有第一个字节校验失败！说明在传输过程中，第一个字节发生了错误。</strong></p>
<p><strong>进一步分析：哪里出错了？</strong></p>
<p>原始发送的是 <code>8F H = 1000 1111</code></p>
<p>接收的是 <code>87 H = 1000 0111</code></p>
<p>对比：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">原始: 1 0 0 0  1 1 1 1</span><br><span class="line">接收: 1 0 0 0  0 1 1 1</span><br><span class="line">             ↑</span><br><span class="line">            第5位（从左数第5位，或从右数第4位）由1变成了0</span><br></pre></td></tr></table></figure>
<p>所以，<strong>第5位发生了翻转错误（bit flip）</strong>。</p>
<p>🧠 总结</p>
<ol type="1">
<li><strong>原始数据 <code>8F 3C AB 96H</code> 的校验位是
<code>0101B</code>。</strong></li>
<li><strong>接收方收到 <code>87 3C AB 96H</code> 和 <code>0101B</code>
后，发现第一个字节校验失败，说明该字节在传输中发生了错误（具体是第5位由1变0）。</strong></li>
<li>奇校验能<strong>检测单个比特错误</strong>，但不能纠正它，也不能检测偶数个比特错误。</li>
</ol>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/IMG_20251029_093747.jpg" alt="IMG_20251029_093747">
<figcaption aria-hidden="true">IMG_20251029_093747</figcaption>
</figure>
<h3 id="第三章作业">第三章作业</h3>
<p>已知 <code>x = 10</code>, <code>y = -6</code>，采用
<strong>6位机器数表示</strong>。请按如下要求计算并把结果还原成真值。</p>
<p>（1）求 <code>[x + y]补</code>，<code>[x - y]补</code>
（2）用原码一位乘法计算 <code>[x × y]原</code> （3）用布斯算法计算
<code>[x × y]补</code> （4）用加减交替法计算 <code>[x / y]原</code>
的商和余数</p>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251029194504411.png" alt="image-20251029194504411">
<figcaption aria-hidden="true">image-20251029194504411</figcaption>
</figure>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251029185146990.png" alt="image-20251029185146990">
<figcaption aria-hidden="true">image-20251029185146990</figcaption>
</figure>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/IMG_20251031_171709.jpg" alt="IMG_20251031_171709">
<figcaption aria-hidden="true">IMG_20251031_171709</figcaption>
</figure>
<h3 id="第七章作业">第七章作业</h3>
<h4 id="section-4">1</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251126152551121.png" alt="image-20251126152551121">
<figcaption aria-hidden="true">image-20251126152551121</figcaption>
</figure>
<p><strong>DRAM</strong> 的全称是 <strong>Dynamic Random Access
Memory</strong>，中文叫 <strong>动态随机存取存储器</strong>。</p>
<p>它是计算机中最常用的<strong>主存储器（Main Memory /
RAM）</strong>，也就是我们平时常说的“内存条”上的核心芯片。</p>
<p><strong>为什么 DRAM 单元要刷新？（物理原理）</strong></p>
<p><strong>核心原因：漏电。</strong></p>
<p>你可以把 DRAM
的存储单元想象成一个<strong>底部有个小针眼的“水桶”</strong>（电容），而数据就是<strong>“水”</strong>（电荷）。</p>
<ul>
<li><strong>存入数据 “1”：</strong> 你给桶里倒满水。</li>
<li><strong>存入数据 “0”：</strong> 你把桶倒空。</li>
<li><strong>问题来了：</strong>
因为那个小针眼（晶体管的漏电流），满桶的水会慢慢往下漏。
<ul>
<li>如果你不管它，过一会儿（比如 2ms 后），桶里的水漏干了，原本的
<strong>“1” 就变成了 “0”</strong>，数据就丢了。</li>
</ul></li>
</ul>
<p>这里最容易混淆的是<strong>两个时间概念</strong>，必须分清楚：</p>
<ol type="1">
<li><strong>最大刷新时间（题目中的 2ms）：</strong>
<ul>
<li>这是<strong>死线 (Deadline)</strong>。</li>
<li>意思是：对于<strong>每一个</strong>水桶，管理员最迟必须每隔 2ms
回来检查一次。如果超过 2ms 没管它，水就漏光了。</li>
</ul></li>
<li><strong>产生刷新信号的间隔（题目要求的答案）：</strong>
<ul>
<li>这是管理员<strong>处理下一行水桶的频率</strong>。</li>
<li><strong>关键点：</strong>
管理员不能一次性同时刷新几百万个水桶（那样电路会过载，电流太大）。他必须<strong>一批一批地</strong>（一行一行地）轮流刷新。</li>
</ul></li>
</ol>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/adf3c730cec214bcbd0b690a8632d0e1.jpg" alt="adf3c730cec214bcbd0b690a8632d0e1">
<figcaption aria-hidden="true">adf3c730cec214bcbd0b690a8632d0e1</figcaption>
</figure>
<h4 id="section-5">2</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251127234744026.png" alt="image-20251127234744026">
<figcaption aria-hidden="true">image-20251127234744026</figcaption>
</figure>
<p><strong>ROM</strong> 的全称是 <strong>Read-Only
Memory</strong>，中文叫 <strong>只读存储器</strong>。</p>
<p>核心特点：</p>
<ul>
<li><strong>字面意思：</strong> “Read-Only”
意味着只能读，不能写（或者说在正常工作状态下不能随意写入）。</li>
<li><strong>实际特性（最重要）：非易失性 (Non-Volatile)</strong>。
<ul>
<li><strong>RAM (DRAM/SRAM)：</strong> 一断电，数据立马消失。</li>
<li><strong>ROM：</strong>
断电后，数据<strong>依然保存</strong>。哪怕你把电脑关机放一年，ROM
里的数据也不会丢。</li>
</ul></li>
</ul>
<p><strong>为什么 ROM 总是放在内存地址的最前面（从 0
开始）？</strong></p>
<ol type="1">
<li><strong>开机第一件事：</strong>
当你按下电脑电源键时，RAM（内存条）里是空的（全是乱码或 0），CPU 无法从
RAM 里读取指令。</li>
<li><strong>启动引导：</strong> CPU 设计为通电后自动去地址
<code>0000H</code>（或其他固定地址）找第一条指令。</li>
<li><strong>固化程序：</strong>
我们必须在这个位置放一个<strong>断电也不丢数据</strong>的存储器（ROM），里面存着电脑的<strong>启动程序（BIOS/UEFI）</strong>。
<ul>
<li>它负责检测硬件、初始化系统，然后把操作系统（Windows/Linux）从硬盘搬到
RAM 里。</li>
</ul></li>
</ol>
<p>当 <span class="math inline">$\overline{\text{MREQ}} =
0$</span>（即处于低电平/有效状态）时，它的主要作用是<strong>通知系统，CPU
当前正打算对内存（RAM 或 ROM）进行访问。</strong></p>
<p><span class="math inline">$R/\overline{W}$</span> (Read / Write
Control)</p>
<ul>
<li><strong>角色</strong>：这是 <strong>CPU
发出的控制信号</strong>（总线信号）。</li>
<li><strong>含义</strong>：它告诉整个系统，CPU
当前想要控制数据流向的方向。</li>
<li><strong>状态逻辑</strong>：
<ul>
<li><strong>高电平 (1)</strong> = <strong>Read (读)</strong>：CPU
准备从总线上<strong>接收</strong>数据（数据流向：内存 <span class="math inline">→</span> CPU）。</li>
<li><strong>低电平 (0)</strong> = <strong>Write (写)</strong>：CPU
准备向总线上<strong>发送</strong>数据（数据流向：CPU <span class="math inline">→</span> 内存）。</li>
</ul></li>
</ul>
<blockquote>
<p><strong>通俗理解</strong>：这是 CPU
在喊话：“大家都听好了，我现在是要‘收东西’（Read）还是要‘发东西’（Write）。”</p>
</blockquote>
<p><span class="math inline">$\overline{WE}$</span> (Write Enable)</p>
<ul>
<li><strong>角色</strong>：这是 <strong>RAM
芯片上的输入引脚</strong>（控制端）。</li>
<li><strong>含义</strong>：允许写入信号。它决定了内存芯片是否允许将数据总线上的电平记录到存储单元中。</li>
<li><strong>符号含义</strong>：顶部的横线表示<strong>低电平有效 (Active
Low)</strong>。</li>
<li><strong>状态逻辑</strong>：
<ul>
<li><strong>低电平 (0)</strong> =
<strong>允许写入</strong>：内存芯片打开“大门”，将数据总线上的数据存入当前地址指向的单元。</li>
<li><strong>高电平 (1)</strong> =
<strong>禁止写入</strong>：内存芯片处于读取模式（配合其他信号）或待机模式，不会修改内部存储的数据。</li>
</ul></li>
</ul>
<blockquote>
<p><strong>通俗理解</strong>：这是内存芯片身上的一个开关。只有把这个开关拉下来（变低），内存才会乖乖地把数据“记下来”。</p>
</blockquote>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/d11ce94cd3db7edfb1cd4a3fa6dadf39.jpg" alt="d11ce94cd3db7edfb1cd4a3fa6dadf39">
<figcaption aria-hidden="true">d11ce94cd3db7edfb1cd4a3fa6dadf39</figcaption>
</figure>
<h4 id="section-6">3</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251127234735106.png" alt="image-20251127234735106">
<figcaption aria-hidden="true">image-20251127234735106</figcaption>
</figure>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/91e3e3a11a15b2854641380b834e3326.jpg" alt="91e3e3a11a15b2854641380b834e3326">
<figcaption aria-hidden="true">91e3e3a11a15b2854641380b834e3326</figcaption>
</figure>
<h4 id="section-7">4</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251127234807626.png" alt="image-20251127234807626">
<figcaption aria-hidden="true">image-20251127234807626</figcaption>
</figure>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/DECFBD2ECFC7C36C6D9BB49DFD0C15C2.jpg" alt="DECFBD2ECFC7C36C6D9BB49DFD0C15C2">
<figcaption aria-hidden="true">DECFBD2ECFC7C36C6D9BB49DFD0C15C2</figcaption>
</figure>
<h4 id="section-8">5</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251127234908094.png" alt="image-20251127234908094">
<figcaption aria-hidden="true">image-20251127234908094</figcaption>
</figure>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/bc48f7ff158bdc49537455d0a2d5efbd.jpg" alt="bc48f7ff158bdc49537455d0a2d5efbd">
<figcaption aria-hidden="true">bc48f7ff158bdc49537455d0a2d5efbd</figcaption>
</figure>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/d4cd56bf63b45d5da02ce2f13eb06edf.jpg" alt="d4cd56bf63b45d5da02ce2f13eb06edf">
<figcaption aria-hidden="true">d4cd56bf63b45d5da02ce2f13eb06edf</figcaption>
</figure>
<h4 id="section-9">6</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/image-20251127234930226.png" alt="image-20251127234930226">
<figcaption aria-hidden="true">image-20251127234930226</figcaption>
</figure>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/90b6c6f2d8d12022fa0bfa2d8bbcf775.jpg" alt="90b6c6f2d8d12022fa0bfa2d8bbcf775">
<figcaption aria-hidden="true">90b6c6f2d8d12022fa0bfa2d8bbcf775</figcaption>
</figure>
<h3 id="第四章作业">第四章作业</h3>
<h3 id="section-10">1</h3>
<p>哪些寻址方式下的操作数在寄存器中？哪些在存储器中？</p>
<ul>
<li><strong>操作数（Operand）</strong>：指令执行时要处理的数据。</li>
<li><strong>寻址方式（Addressing
Mode）</strong>：指明操作数在哪里（寄存器？内存？立即数？）以及如何找到它。</li>
<li><strong>寄存器（Register）</strong>：CPU内部的高速存储单元。</li>
<li><strong>存储器（Memory）</strong>：主存（RAM），速度比寄存器慢，但容量大。</li>
</ul>
<table>
<colgroup>
<col style="width: 22%">
<col style="width: 44%">
<col style="width: 32%">
</colgroup>
<thead>
<tr>
<th>寻址方式</th>
<th>操作数位置</th>
<th>举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>寄存器寻址</td>
<td>✅ 寄存器</td>
<td><code>MOV AX, BX</code></td>
</tr>
<tr>
<td>立即寻址</td>
<td>❌ 不在寄存器/存储器（在指令中）</td>
<td><code>MOV AX, 5</code></td>
</tr>
<tr>
<td>直接寻址</td>
<td>✅ 存储器</td>
<td><code>MOV AX, [2000H]</code></td>
</tr>
<tr>
<td>寄存器间接寻址</td>
<td>✅ 存储器</td>
<td><code>MOV AX, [BX]</code></td>
</tr>
<tr>
<td>寄存器相对寻址</td>
<td>✅ 存储器</td>
<td><code>MOV AX, [BX + 10]</code></td>
</tr>
<tr>
<td>基址变址寻址</td>
<td>✅ 存储器</td>
<td><code>MOV AX, [BX + SI]</code></td>
</tr>
<tr>
<td>相对基址变址寻址</td>
<td>✅ 存储器</td>
<td><code>MOV AX, [BX + SI + 5]</code></td>
</tr>
</tbody>
</table>
<blockquote>
<p>⚠️ 注意：<strong>立即数（Immediate）</strong>
不是寄存器也不是存储器，它直接嵌入在指令中。</p>
</blockquote>
<h3 id="section-11">2</h3>
<p>什么是 RISC？</p>
<p><strong>RISC = Reduced Instruction Set
Computer（精简指令集计算机）</strong></p>
<p>与之相对的是 <strong>CISC（Complex Instruction Set
Computer，复杂指令集计算机）</strong>，比如 Intel x86。</p>
<p>1️⃣ 指令集精简（Reduced Instruction Set）</p>
<ul>
<li>指令数量少（通常几十到几百条），每条指令功能单一。</li>
<li>指令长度固定（如 32 位），便于流水线处理。</li>
</ul>
<blockquote>
<p>💡
类比：就像厨房里只有几把多功能刀具，每把刀只做一件事，但做得又快又好。</p>
</blockquote>
<p><strong>例子：</strong></p>
<ul>
<li>RISC：<code>ADD R1, R2, R3</code> → 把 R2 和 R3 相加，结果存入
R1</li>
<li>CISC：<code>MOV [BX+SI+10], AX</code> →
一条指令完成地址计算+内存写入</li>
</ul>
<p>2️⃣ 指令执行周期短（Single-Cycle Execution）</p>
<ul>
<li>大多数指令在一个时钟周期内完成。</li>
<li>通过简化指令和硬件设计实现。</li>
</ul>
<p>3️⃣ 大量通用寄存器（Large Register File）</p>
<ul>
<li>寄存器数量多（如 ARM 有 16 个通用寄存器，RISC-V 有 32 个）。</li>
<li>减少对内存的访问，提高速度。</li>
</ul>
<p>4️⃣ 采用流水线技术（Pipelining）</p>
<ul>
<li>指令执行分为多个阶段（取指、译码、执行、访存、写回），并行处理。</li>
<li>RISC 指令简单统一，非常适合流水线。</li>
</ul>
<p>5️⃣ 加载/存储架构（Load/Store Architecture）</p>
<ul>
<li>只有 <code>LOAD</code> 和 <code>STORE</code> 指令可以访问内存。</li>
<li>其他运算指令只能在寄存器之间进行。</li>
</ul>
<h3 id="section-12">3</h3>
<p>假定某计算机中有一条转移指令，采用相对寻址方式，共占两字节，第一字节是操作码，第二字节是
相对位移量(用补码表示),CPU每次从内存只能取一字节。假设执行到某转移指令时
PC的内容为200,
执行该转移指令后要求转移到100开始的一段程序执行，则该转移指令第二字节的内容应该是多少?</p>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/QQ20251206-170833.png" alt="QQ20251206-170833">
<figcaption aria-hidden="true">QQ20251206-170833</figcaption>
</figure>
<h3 id="section-13">4</h3>
<p>4.假设地址为1200H的内存单元中的内容为12FCH,地址为12FCH的内存单元的内容为38B8H,而
38B8H单元的内容为88F9H。说明以下各情况下操作数的有效地址是多少?
(1)操作数采用变址寻址，变址寄存器的内容为252,指令中给出的形式地址为1200H。
(2)操作数采用一次间接寻址，指令中给出的地址码为1200H。
(3)操作数采用寄存器间接寻址，指令中给出的寄存器编号为8,8号寄存器的内容为1200H。</p>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/QQ20251206-170838.png" alt="QQ20251206-170838">
<figcaption aria-hidden="true">QQ20251206-170838</figcaption>
</figure>
<h3 id="section-14">5</h3>
<p>6.某计算机指令系统采用定长指令字格式，指令字长16位，每个操作数的地址码长6位。指令分二
地址、单地址和零地址3类。若二地址指令有k2条，零地址指令有k0条，则单地址指令最多有多少条?</p>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%BD%9C%E4%B8%9A/QQ20251206-170843.png" alt="QQ20251206-170843">
<figcaption aria-hidden="true">QQ20251206-170843</figcaption>
</figure>
]]></content>
      <categories>
        <category>大三上</category>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title>实习日志</title>
    <url>/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/</url>
    <content><![CDATA[<h3 id="日志">日志</h3>
<p>7.16 10：46</p>
<p>已经将mineru部署至服务器，完成pdf和扫描件的提取测试，但是mineru是没办法直接提取doc与docx的，能不能直接对doc与docx进行文本分块，或者先转换成pdf再提取（官方给出的解决方案：通过独立部署的LibreOffice服务先行转换为PDF格式，再进行后续解析操作。）</p>
<p>7.17 11：04</p>
<p>完成mineru脚本的编写，仅输出提取的md与image；实现调用多块gpu；实现数据并行，通过多卡同时处理多个输入来增加吞吐量；使用sglang框架</p>
<p>7.18 14：37</p>
<p>发现mineru提取的markdown文档是不带多级标题的，只有一级标题，所以不考虑文档结构分块；语义分块要调用embedding模型，而且文档里有很多表格，我感觉效果不一定会好；后续我想法是使用递归分块，表格在md文档中以html表格格式存储的，大量冗余信息，我想先对其进行预处理，转换成md表格的形式吧（用“
|”存储），然后再分块，或许效果会好一些，正在进行</p>
<p>还有一个就是libreoffice是部署在哪里，我没有找到诶</p>
<p>7.19 10：26</p>
<p>完成表格预处理的脚本编写，完成对md文档的预处理；完成递归分块，后续完成存入es数据库</p>
<p>7.21</p>
<p>完成简单地将分块结果存入elasticsearch（mapping只有content字段，使用http请求存的，没有用langchain-elasticsearch）后面要试试langchain-elasticsearch，去看看字段的处理</p>
<p>7.22</p>
<p>完成langchain-elasticsearch的bm25的检索测试，接下来尝试使用服务器的embedding模型进行测试，阅读项目文件，理清思路，具体内容见<a href="https://icnrn6ghqrgx.feishu.cn/wiki/MWZ9wVYRxixABqkMhjQcQPqTnfe">多模态
-
PDF表格图片&amp;扫描件</a>，存入es与文件处理字段处理部分已经理清了，成功存入服务器的es</p>
<p>7.23</p>
<p>今天在把之前做的所有工作进行整合，编写一个完整的代码，实现生产的流程，遇到的主要问题有两个：1.我还是没有很看懂之前对字段的存储，和字段的结构2.我没有太理解pdf分块的部分在哪里，是没有吗，我看doc的rewrite_word是有文本分块的</p>
<p>感觉需要你给我讲一下，不然我后面不大知道该怎么处理，那我明天去把语义分块和其他的检索方案试一下吧，整合代码先稍微延后</p>
<p>7.24</p>
<p>使用docker的自定义网络，实现容器之间的通信，从而可以在repo容器中调用mineru，其他容器都在network_test下，我把mineru也启动到里面</p>
<p>成功在repo容器访问到mineru容器，完成pdf分块数据的批量写入elasticsearch并可以成功检索，后续完成调用mineru的fastapi接口（还没编完），继续完成代码整合（已经完成大部分，主要差mineru的部分，和一些衔接的代码）</p>
<p>7.25</p>
<p>完成通过接口使用mineru批量处理pdf文件</p>
<p>7.28</p>
<p>完成了代码整合，可以完成pdf整个流程的处理</p>
<p>7.29</p>
<p>补充了libreoffice的代码，实现了将doc，docx转换成pdf，统一处理流程；完成了数据标记webhttps://traedemortu8-zxj2902065320-7643-junxi-zhangs-projects.vercel.app/data；后续计划：根据问题检索url，处理后存入zxj_test
es数据库，再进行进一步检索产生数据集</p>
<p>7.30</p>
<p>完成扫描件的测试，文字公式图片皆可正常识别；根据问题完成文档的收集工作，共648份文档；目前正在进行将文档录入es数据库，目前存在问题，部分docx文件在转换成pdf的过程中会导致libreoffice卡死，原因暂未查明；解决方案：跳过这些文件，缺几个影响应该也不大</p>
<p>7.31</p>
<p>已完成621/648文件的存储</p>
<p>8.1</p>
<p>已完成数据集的建立，检索了140个问题，每个问题选取top16构建数据集；</p>
<p>8.4</p>
<p>完成了ElasticsearchRetriever支持的几种检索方式的测试，为后续评估做准备（混合搜索需付费，bm25的多字段搜索有三种模式且字段的权重可以调整，后续评估时调整进行测试）；测试了agentic
chunk（其主要思想是，先进行初步分段，按照长度或递归，然后让大模型生成这一段的概要，将段与段合并生成块），但是测试下来，我们这个一个文档的内容同质化很严重，基本上都分到一块里了，我猜测语义分块也是这种效果；了解学习如何并发测试和吞吐量测试，明天完成测试和文档的撰写工作</p>
<p>8.5</p>
<p>完成七月rag部分的复盘<a href="https://icnrn6ghqrgx.feishu.cn/wiki/Q59OwEEPMiGTiykMGodcNHyCnld?from=from_copylink">七月复盘.md</a>；完成mineru的压测</p>
<p>8.7</p>
<p>继续学习transformer和模型微调</p>
<p>8.8</p>
<p>完成了transformer和Tokenizer相关知识的学习，周末完成对模型微调相关知识的学习，下周开始模型微调的实战与部署</p>
<p>学习内容概况：1.
transformer相关：了解transformer架构；学习其中的注意力机制，大致了解了几种注意力机制的差异；了解了残差连接，层归一化，前馈神经网络，位置编码的相关知识；大致了解了BERT，T5，GPT模型的差异
2.tokenizer相关：两种分词方式BPE与WordPiece；了解了transformer中的分词流程</p>
<p>8.11</p>
<p>完成了微调的理论学习，正在进行实战，学习了大致包括以下内容：什么是全量微调，lora（qlora）的原理；了解微调工具与模型评估框架；如何构建微调数据集</p>
<p>8.12</p>
<p>完成使用unsloth对Qwen3-8B-unsloth-bnb-4bit模型的lora微调实战，包括如何构建微调数据集，数据集清洗等工作的了解，还有一小部分工作没做，就是训练的可视化，使用wandb或swanlab，还没有研究完</p>
<p>peft，目的：意图识别；提取字段</p>
<p>我想问一下，我们这个项目有去试拿公司文件去微调模型吗，我找了个项目，可以根据文档生成微调数据集，但还没试，后续需要的话，我可以试试生成一下，然后去微调实操一下</p>
<p>8.13</p>
<p>完成了微调过程的可视化记录，记录了训练过程中损失下降的情况；跑了一下数据集生成的开源项目，体验了一下：支持doc，docx，pdf文件的上传，上传后会进行分块处理（策略与大小皆可自行调整；pdf可以通过设置mineruapi，也可以自己配置视觉模型解析；doc文件处理思路为，先转化为md格式再进行分块）然后根据每块生成问题，在结合问题和问题所在块，传给大模型生成问题（就像检索出来的上下文一样），最后形成数据集</p>
<p>8.21</p>
<p>完成模型部署镜像搭建，支持vllm，sglang；生成9000份qa数据集</p>
<p>rag评估；论文；部署视觉模型，qwen3-8b</p>
<h3 id="其他">其他</h3>
<h4 id="vscode连接远程服务器">vscode连接远程服务器</h4>
<ol type="1">
<li>输入 ssh root@10.117.128.50</li>
<li>输入密码 think123@</li>
</ol>
<h5 id="使用旧版remotessh">使用旧版remotessh</h5>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/image-20250708104452761.png" alt="image-20250708104452761">
<figcaption aria-hidden="true">image-20250708104452761</figcaption>
</figure>
<blockquote>
<p>原因：可能因为内网，服务器那边没有进行更新，所以新版的remotessh无法连接</p>
<p>其他问题：可能由于上述原因，trae也无法连接，并且由于trae的远程连接插件无法更改版本，因此无法使用</p>
</blockquote>
<h5 id="虚拟环境创建">虚拟环境创建</h5>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/image-20250708104254347.png" alt="image-20250708104254347">
<figcaption aria-hidden="true">image-20250708104254347</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python3 -m venv .venv</span><br><span class="line"></span><br><span class="line">which python</span><br><span class="line"></span><br><span class="line">#激活虚拟环境</span><br><span class="line"> .venv\Scripts\activate</span><br><span class="line"> source .venv/bin/activate</span><br><span class="line"> </span><br><span class="line"> #停掉虚拟环境</span><br><span class="line"> deactivate</span><br></pre></td></tr></table></figure>
<h4 id="git连接远程仓库">git连接远程仓库</h4>
<p>初始化仓库：<code>git init</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 添加所有文件到暂存区</span><br><span class="line">git add .</span><br><span class="line"></span><br><span class="line"># 提交更改</span><br><span class="line">git commit -m &quot;Initial commit&quot;</span><br><span class="line"></span><br><span class="line">#上传远程库</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>目标</th>
<th>命令</th>
</tr>
</thead>
<tbody>
<tr>
<td>查看远程仓库</td>
<td><code>git remote -v</code></td>
</tr>
<tr>
<td>修改远程仓库地址</td>
<td><code>git remote set-url origin &lt;新地址&gt;</code></td>
</tr>
<tr>
<td>添加新远程仓库（不同名）</td>
<td><code>git remote add upstream &lt;新地址&gt;</code></td>
</tr>
<tr>
<td>删除远程仓库</td>
<td><code>git remote remove origin</code></td>
</tr>
<tr>
<td>添加第一个远程仓库</td>
<td><code>git remote add origin</code></td>
</tr>
</tbody>
</table>
<blockquote>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/image-20250708151320868.png" alt="image-20250708151320868">
<figcaption aria-hidden="true">image-20250708151320868</figcaption>
</figure>
<p>当前存在连接超时问题，可能是服务器连接的原因</p>
</blockquote>
<h4 id="mineru部署情况">mineru部署情况</h4>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/1a9954d6-31d7-404a-9419-cd9a87c9ee09.png" alt="1a9954d6-31d7-404a-9419-cd9a87c9ee09">
<figcaption aria-hidden="true">1a9954d6-31d7-404a-9419-cd9a87c9ee09</figcaption>
</figure>
<p>通过调整docker镜像源，可以拉取基础镜像了，但是遇到<code>RUN apt-get update &amp;&amp; apt-get install -y libgl1 &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*</code>第二部命令再次出现网络问题</p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统</title>
    <url>/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h2 id="操作系统概论">操作系统概论</h2>
<h3 id="操作系统的主要特征">操作系统的主要特征</h3>
<h4 id="并发性-concurrency"><strong>并发性 (Concurrency)</strong></h4>
<p>🔍 核心定义</p>
<blockquote>
<p><strong>并发性</strong>是指两个或两个以上的事件或活动在<strong>同一时间间隔内</strong>发生。</p>
</blockquote>
<ul>
<li><strong>关键点</strong>：“同一时间间隔” ≠
“同一时刻”。它强调的是“看起来同时”，而不是“真正同时”。</li>
</ul>
<p>📌 操作系统中的体现</p>
<ol type="1">
<li><strong>多个 I/O 设备同时工作</strong>：
<ul>
<li>你的键盘在输入，打印机在打印，网卡在收发数据。这些设备都在“同时”工作。</li>
</ul></li>
<li><strong>I/O 和 CPU 计算同时进行</strong>：
<ul>
<li>当 CPU 在计算时，I/O 设备可能在后台传输数据。CPU 不需要等待 I/O
完成，可以去处理其他任务。</li>
</ul></li>
<li><strong>内存中多个程序交替执行</strong>：
<ul>
<li>这是最核心的体现。操作系统通过<strong>时间片轮转</strong>（Time-Slicing）等调度算法，让多个程序“轮流”使用
CPU，从而实现“宏观上的并发”。</li>
</ul></li>
</ol>
<p>🖼️ 并发 vs 并行</p>
<p>这是你 PPT 中提出的关键问题！</p>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 44%">
<col style="width: 44%">
</colgroup>
<thead>
<tr>
<th style="text-align: left;">特性</th>
<th style="text-align: left;">并发 (Concurrency)</th>
<th style="text-align: left;">并行 (Parallelism)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>定义</strong></td>
<td style="text-align: left;">多个任务在<strong>同一时间间隔内</strong>交替执行。</td>
<td style="text-align: left;">多个任务在<strong>同一时刻</strong>真正同时执行。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>物理基础</strong></td>
<td style="text-align: left;">单 CPU 系统即可实现。</td>
<td style="text-align: left;">需要多核 CPU 或多处理器系统。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>效果</strong></td>
<td style="text-align: left;">“看起来”同时进行。</td>
<td style="text-align: left;">“真正”同时进行。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>类比</strong></td>
<td style="text-align: left;">一个人在厨房里，一会儿切菜，一会儿炒菜，一会儿洗碗。</td>
<td style="text-align: left;">三个人在厨房里，一个人切菜，一个人炒菜，一个人洗碗。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>✅
<strong>一句话总结</strong>：<strong>并行是并发的一种特例</strong>。并发是“逻辑上的同时”，并行是“物理上的同时”。</p>
</blockquote>
<h4 id="共享性-sharing"><strong>共享性 (Sharing)</strong></h4>
<p>🔍 核心定义</p>
<blockquote>
<p><strong>共享性</strong>指操作系统中的资源（包括硬件资源和软件资源）可被<strong>多个并发执行的进程共同使用</strong>，而不是被一个进程所独占。</p>
</blockquote>
<ul>
<li><strong>关键点</strong>：共享不等于“无限制访问”，它必须在<strong>操作系统管理下</strong>进行，以保证安全和有序。</li>
</ul>
<p>📌 资源共享的方式</p>
<p>1️⃣ 透明资源共享 / 同时共享方式</p>
<ul>
<li><strong>含义</strong>：允许多个进程在<strong>同一时间段内</strong>对资源进行访问，好像每个进程都独占资源一样。</li>
<li><strong>特点</strong>：
<ul>
<li>访问的次序对结果无影响。</li>
<li>通常用于<strong>可重入</strong>或<strong>只读</strong>的资源。</li>
</ul></li>
<li><strong>例子</strong>：
<ul>
<li><strong>CPU</strong>：通过时间片轮转，让多个进程“同时”使用
CPU。</li>
<li><strong>主存
(RAM)</strong>：多个进程的代码和数据可以同时存在于内存中。</li>
<li><strong>磁盘</strong>：多个进程可以同时读取磁盘上的不同文件。</li>
<li><strong>打印机</strong>：虽然物理上一次只能打印一个任务，但操作系统可以通过“打印队列”实现逻辑上的“同时共享”。</li>
</ul></li>
</ul>
<p>2️⃣ 独占资源共享 / 互斥共享方式</p>
<ul>
<li><strong>含义</strong>：在<strong>同一时间段内</strong>只允许<strong>一个进程</strong>访问资源。</li>
<li><strong>特点</strong>：
<ul>
<li>这类资源称为<strong>临界资源 (Critical Resource)</strong>。</li>
<li>必须通过<strong>互斥机制</strong>（如锁、信号量）来保护。</li>
</ul></li>
<li><strong>例子</strong>：
<ul>
<li><strong>磁带机</strong>：一次只能由一个进程控制。</li>
<li><strong>扫描仪</strong>：一次只能扫描一份文档。</li>
<li><strong>数据库中的某一行记录</strong>：如果两个事务同时修改同一行，会导致数据不一致。</li>
</ul></li>
</ul>
<p>🛠️ 操作系统如何管理共享？</p>
<ul>
<li><strong>提供显式资源共享机制</strong>：如 <code>fork()</code>,
<code>semaphore</code>, <code>mutex</code>, <code>lock</code>
等系统调用。</li>
<li><strong>将互斥访问下放给用户决策</strong>：程序员需要自己负责加锁和解锁，操作系统提供工具。</li>
</ul>
<h4 id="异步性-asynchrony">异步性 (Asynchrony)</h4>
<p>🔍 核心定义</p>
<blockquote>
<p><strong>异步性</strong>指在多道程序环境中，由于资源有限而进程众多，多数情况下，进程的执行不是一气呵成，而是“走走停停”。</p>
</blockquote>
<ul>
<li><strong>关键点</strong>：进程的执行是不可预测的，它的推进速度取决于系统调度、I/O
等待、中断等多种因素。</li>
</ul>
<p>📌 异步性的表现</p>
<ol type="1">
<li><strong>作业到达系统的时间和类型不确定</strong>：
<ul>
<li>用户随时可能启动一个新程序。</li>
</ul></li>
<li><strong>操作员发出命令或操作的时间和类型不确定</strong>：
<ul>
<li>用户可能随时按下键盘或点击鼠标。</li>
</ul></li>
<li><strong>程序运行发生错误或异常的类型和时刻不确定</strong>：
<ul>
<li>程序可能因为除零、内存溢出等原因崩溃。</li>
</ul></li>
<li><strong>中断事件发生的时刻不确定</strong>：
<ul>
<li>时钟中断、I/O 中断、硬件故障中断等都是随机发生的。</li>
</ul></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[并发性] --&gt; B[多个任务同时执行]</span><br><span class="line">    C[共享性] --&gt; D[资源被多个任务共同使用]</span><br><span class="line">    E[异步性] --&gt; F[任务执行“走走停停”]</span><br><span class="line"></span><br><span class="line">    B &amp; D &amp; F --&gt; G[现代操作系统的核心特征]</span><br><span class="line">    G --&gt; H[实现多任务、多用户环境]</span><br></pre></td></tr></table></figure>
<h3 id="多道程序设计">多道程序设计</h3>
<h4 id="核心思想">核心思想</h4>
<blockquote>
<p><strong>多道程序设计</strong>是指允许多个程序<strong>同时</strong>驻留在内存中，并由操作系统<strong>统一管理和调度</strong>，使它们<strong>交替</strong>（并发）地使用
CPU 和其他系统资源。</p>
</blockquote>
<ul>
<li><strong>核心目的</strong>：<strong>掩盖 I/O 等待时间，提高 CPU
和系统资源的利用率</strong>。</li>
<li><strong>终极目标</strong>：让昂贵的 CPU
<strong>永远不要闲着</strong>！</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gantt</span><br><span class="line">    title 单道程序 vs 多道程序</span><br><span class="line">    dateFormat  HH:mm:ss</span><br><span class="line">    axisFormat  %Ss</span><br><span class="line"></span><br><span class="line">    section 单道程序</span><br><span class="line">    作业A-CPU     :crit, a1, 00:00:00, 2s</span><br><span class="line">    作业A-I/O     :active, a2, after a1, 8s</span><br><span class="line">    作业A-CPU     :crit, a3, after a2, 2s</span><br><span class="line">    作业A-I/O     :active, a4, after a3, 8s</span><br><span class="line"></span><br><span class="line">    section 多道程序</span><br><span class="line">    作业A-CPU     :crit, b1, 00:00:00, 2s</span><br><span class="line">    作业B-CPU     :crit, b2, after b1, 2s</span><br><span class="line">    作业C-CPU     :crit, b3, after b2, 2s</span><br><span class="line">    作业A-I/O     :active, b4, after b1, 8s</span><br><span class="line">    作业B-I/O     :active, b5, after b2, 8s</span><br><span class="line">    作业C-I/O     :active, b6, after b3, 8s</span><br></pre></td></tr></table></figure>
<p><strong>对比</strong>：在多道程序中，当作业 A 在等待 I/O 时，CPU
立刻去执行作业 B 和 C。CPU 几乎没有空闲时间，利用率接近 100%！</p>
<h4 id="cpu利用率">cpu利用率</h4>
<p><code>CPU利用率 = 1 - p^n</code></p>
<p>🔍 假设条件</p>
<ol type="1">
<li><strong>系统中有 <code>n</code> 个程序</strong> 同时在内存中。</li>
<li><strong>每个程序平均有 <code>p</code> 的概率在等待 I/O
操作</strong>。
<ul>
<li>例如，<code>p = 0.8</code> 表示一个程序有 80%
的时间在等磁盘读写、键盘输入等，只有 20% 的时间在真正使用 CPU。</li>
</ul></li>
<li><strong>各个程序的等待操作是相互独立的</strong>。
<ul>
<li>这是一个关键假设，意味着一个程序是否在等 I/O，不影响其他程序。</li>
</ul></li>
</ol>
<p>💡 公式推导</p>
<ul>
<li><strong>CPU 空闲的概率</strong>：当且仅当<strong>所有 <code>n</code>
个程序都在等待 I/O</strong> 时，CPU 才会空闲。</li>
<li>因为每个程序等待 I/O 的概率是
<code>p</code>，且它们相互独立，所以<strong>所有 <code>n</code>
个程序都等待 I/O 的概率是 <code>p^n</code></strong>。</li>
<li><strong>因此，CPU 空闲的概率 = <code>p^n</code></strong>。</li>
<li><strong>CPU 利用率 = 1 - CPU 空闲的概率 =
<code>1 - p^n</code></strong>。</li>
</ul>
<p>若进程平均花费 80% 的时间等待 I/O，则为了使得 CPU 利用率不低于
80%，应至少有多少道程序在主存中运行？</p>
<h3 id="计算过程">计算过程</h3>
<p>根据公式：</p>
<p>CPU利用率 = 1 - p^n ≥ 0.8</p>
<p>移项得：</p>
<p>p^n ≤ 0.2</p>
<p>代入 <code>p = 0.8</code>：</p>
<p>0.8^n ≤ 0.2</p>
<p>两边取对数（以 10 为底或自然对数均可）：</p>
<p>n * log(0.8) ≤ log(0.2)</p>
<p>注意：<code>log(0.8)</code>
是负数，所以在除的时候要<strong>反转不等号方向</strong>：</p>
<p>n ≥ log(0.2) / log(0.8)</p>
<p>计算数值：</p>
<ul>
<li><code>log(0.2) ≈ -0.69897</code></li>
<li><code>log(0.8) ≈ -0.09691</code></li>
<li><code>n ≥ (-0.69897) / (-0.09691) ≈ 7.21</code></li>
</ul>
<p>因为 <code>n</code> 必须是整数，且要满足
<code>n ≥ 7.21</code>，所以：</p>
<blockquote>
<p><strong><code>n = 8</code></strong></p>
</blockquote>
<p>✅ 最终答案</p>
<p><strong>为了使得 CPU 利用率不低于 80%，应至少有 8
道程序在主存中运行。</strong></p>
<h4 id="是不是同时运行的程序越多越好">是不是同时运行的程序越多越好？</h4>
<p><strong>不是！同时运行的程序（道数）并不是越多越好。存在一个最优的“道数”，超过这个值，系统的整体效率反而会下降。</strong></p>
<p>当道数 <code>n</code>
超过某个临界值后，系统性能会急剧下降。主要原因有：</p>
<p>1️⃣ <strong>上下文切换开销 (Context Switching Overhead)</strong></p>
<p><strong>什么是上下文切换？</strong></p>
<ul>
<li>当操作系统从一个进程切换到另一个进程时，它需要保存当前进程的状态（寄存器、内存映射、程序计数器等），并加载下一个进程的状态。</li>
</ul>
<p>2️⃣ <strong>内存压力 (Memory Pressure)</strong></p>
<ul>
<li><strong>每个进程都需要内存</strong>：代码段、数据段、堆、栈、页表等。</li>
</ul>
<p>3️⃣ <strong>资源竞争加剧 (Resource Contention)</strong></p>
<ul>
<li><strong>锁竞争</strong>：多个进程同时访问共享资源（如数据库连接池、文件锁），需要排队等待，增加了延迟。</li>
<li><strong>缓存失效</strong>：多个进程的指令和数据交替进入 CPU
缓存，导致缓存命中率降低，CPU 需要更频繁地从内存读取数据。</li>
</ul>
<h3 id="处理器状态">处理器状态</h3>
<h4 id="为什么需要两种处理器状态">为什么需要两种处理器状态？</h4>
<p>现代计算机是一个多用户、多任务的环境。如果所有程序都能随意执行任何指令，那么一个不小心的
bug 或一个恶意程序就可能：</p>
<ul>
<li>格式化硬盘。</li>
<li>修改系统时间。</li>
<li>访问其他用户的隐私数据。</li>
<li>导致系统崩溃。</li>
</ul>
<p>为了避免这种情况，CPU 被设计成有两种工作模式：</p>
<ol type="1">
<li><strong>用户态 (User
Mode)</strong>：普通程序运行的状态，只能执行“安全”的指令。</li>
<li><strong>核心态 (Kernel Mode / Supervisor
Mode)</strong>：操作系统内核运行的状态，可以执行所有指令，包括“危险”的特权指令。</li>
</ol>
<h4 id="程序状态字-psw">程序状态字 (PSW)</h4>
<p><strong>Program Status Word (PSW)</strong>
是一个非常重要的寄存器。</p>
<ul>
<li><strong>定义</strong>：PSW 是 CPU
内部的一个特殊寄存器，用于存储当前处理器的各种状态信息。</li>
<li><strong>关键作用</strong>：PSW
中有一个<strong>标志位</strong>（通常是最高位或某一位），用来标识当前
CPU 处于<strong>用户态还是核心态</strong>。
<ul>
<li><code>PSW[bit] = 0</code> → 用户态</li>
<li><code>PSW[bit] = 1</code> → 核心态</li>
</ul></li>
</ul>
<blockquote>
<p>✅ <strong>这就是 CPU
判断当前是否可以执行特权指令的依据！</strong></p>
</blockquote>
<p>当 CPU 执行一条指令时，它会检查 PSW 中的这个标志位：</p>
<ul>
<li>如果是<strong>用户态</strong>，并且指令是<strong>特权指令</strong>，则触发一个<strong>异常
(Exception)</strong>，操作系统会介入处理（通常是终止该程序）。</li>
<li>如果是<strong>核心态</strong>，则允许执行。</li>
</ul>
<h4 id="cpu-如何判断当前是否可以执行特权指令">CPU
如何判断当前是否可以执行特权指令？</h4>
<p><strong>答案</strong>：CPU 通过检查 <strong>程序状态字 (PSW)</strong>
中的一个特定标志位来判断。</p>
<ul>
<li>如果该标志位表示当前处于<strong>用户态</strong>，并且遇到的是<strong>特权指令</strong>，则
CPU
会触发一个<strong>异常</strong>（通常是“非法指令”或“特权指令违规”），并将控制权交给操作系统内核。</li>
<li>操作系统内核会根据情况决定是终止该程序，还是进行其他处理。</li>
</ul>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116191358137.png" alt="image-20251116191358137">
<figcaption aria-hidden="true">image-20251116191358137</figcaption>
</figure>
<h2 id="进程控制和管理">进程控制和管理</h2>
<h3 id="进程定义与属性">进程定义与属性</h3>
<p>进程（Process）是<strong>程序在计算机上的一次执行</strong>实例，是<strong>操作系统进行资源分配、调度和保护的基本单位</strong>。</p>
<h4 id="为什么要引入进程">为什么要引入“进程”？</h4>
<p>1️⃣ <strong>刻画系统的动态性（Dynamic Nature）</strong></p>
<ul>
<li><strong>问题</strong>：程序是静态的代码，无法描述“执行中”的状态。</li>
<li><strong>解决方案</strong>：进程是一个<strong>动态实体</strong>，它有生命周期（创建
→ 运行 → 阻塞 → 终止）。</li>
<li><strong>意义</strong>：操作系统可以精确跟踪每个任务的当前状态，做出调度决策。</li>
</ul>
<p>2️⃣ <strong>发挥系统的并发性（Concurrency）</strong></p>
<ul>
<li><strong>问题</strong>：CPU 和 I/O 设备速度不匹配。程序在等待
I/O（如读文件、网络请求）时，CPU 就空闲了。</li>
<li><strong>解决方案</strong>：通过<strong>进程切换</strong>，让 CPU
在等待期间去执行其他任务。</li>
<li><strong>意义</strong>：提高了 CPU 利用率和系统吞吐量。</li>
</ul>
<p>3️⃣ <strong>解决资源共享与隔离的矛盾</strong></p>
<ul>
<li><strong>问题</strong>：多个程序可能需要共享资源（如文件、打印机），但又不能互相干扰。</li>
<li><strong>解决方案</strong>：
<ul>
<li><strong>共享性</strong>：进程可以通过合法机制（如共享内存、消息队列）共享资源。</li>
<li><strong>独立性/保护性</strong>：每个进程拥有独立的地址空间，操作系统通过内存管理单元（MMU）确保
A 进程不能访问 B 进程的内存。</li>
</ul></li>
<li><strong>意义</strong>：既实现了协作，又保证了安全和稳定。</li>
</ul>
<h4 id="进程的五大核心属性">进程的五大核心属性</h4>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 45%">
<col style="width: 43%">
</colgroup>
<thead>
<tr>
<th>属性</th>
<th>含义</th>
<th>举例说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1. 动态性</strong></td>
<td>进程是动态的，有生命周期（创建 → 运行 → 阻塞 → 终止）。</td>
<td><code>uvicorn</code> 启动时创建进程，<code>Ctrl+C</code>
终止时销毁进程。</td>
</tr>
<tr>
<td><strong>2. 并发性</strong></td>
<td>多个进程可以“同时”运行（宏观并发，微观交替）。</td>
<td>一台服务器同时处理成百上千个用户的 HTTP 请求。</td>
</tr>
<tr>
<td><strong>3. 独立性</strong></td>
<td>每个进程有独立的地址空间和资源，互不干扰。</td>
<td>一个 Python 进程崩溃，不会导致另一个 Python 进程退出。</td>
</tr>
<tr>
<td><strong>4. 制约性</strong></td>
<td>进程间可能存在同步或互斥关系（如竞争资源、等待结果）。</td>
<td>多个进程写同一个日志文件，需要用文件锁避免内容错乱。</td>
</tr>
<tr>
<td><strong>5. 共享性</strong></td>
<td>进程可以通过操作系统提供的机制共享资源（如内存、文件）。</td>
<td>多个 FastAPI worker 进程共享一个 Redis 缓存连接池。</td>
</tr>
</tbody>
</table>
<h3 id="进程状态转换">进程状态转换</h3>
<h4 id="五态模型">五态模型</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251115204410504.png" alt="image-20251115204410504">
<figcaption aria-hidden="true">image-20251115204410504</figcaption>
</figure>
<h4 id="七态模型">七态模型</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251115204451732.png" alt="image-20251115204451732">
<figcaption aria-hidden="true">image-20251115204451732</figcaption>
</figure>
<p>七态模型在五态模型的基础上，<strong>显式增加了“挂起（Suspend）”的概念</strong></p>
<blockquote>
<p>挂起 = 进程被换出到外存（Swap）</p>
<ul>
<li><strong>目的</strong>：当系统内存紧张时，操作系统会将一些<strong>暂时不活跃</strong>的进程（比如长时间阻塞的进程）从内存移到硬盘上的“交换区（Swap
Space）”，以腾出内存给更紧急的任务。</li>
</ul>
</blockquote>
<p><strong>挂起就绪态 (Ready/Suspend)</strong></p>
<p>定义：</p>
<blockquote>
<p><strong>进程具备运行条件（即它已经准备好执行），但目前在外存中。只有当它被换入内存后，才能被调度器选中运行。</strong></p>
</blockquote>
<p><strong>挂起等待态 (Blocked/Suspend)</strong></p>
<p>定义：</p>
<blockquote>
<p><strong>进程正在等待某一个事件发生（如 I/O
完成、用户输入、网络响应），并且目前在外存中。</strong></p>
</blockquote>
<h3 id="进程描述和组成">进程描述和组成</h3>
<h4 id="进程映像">进程映像</h4>
<p><strong>进程映像（Process
Image）是指进程在内存中的完整内容，包括代码、数据、堆、栈以及内核数据结构（如
PCB）等所有组成部分的集合。</strong></p>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251115210257885.png" alt="image-20251115210257885">
<figcaption aria-hidden="true">image-20251115210257885</figcaption>
</figure>
<h4 id="进程上下文">进程上下文</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251115210715693.png" alt="image-20251115210715693">
<figcaption aria-hidden="true">image-20251115210715693</figcaption>
</figure>
<blockquote>
<p>寄存器上下文 (Register Context)<strong>存储在 PCB 中</strong>
<strong>包含：通用寄存器、程序计数器、栈指针、程序状态字</strong></p>
<p>这是进程“灵魂”的一部分——CPU 执行时最直接依赖的状态。</p>
</blockquote>
<h4 id="pcbprocess-control-block进程控制块"><strong>PCB（Process Control
Block，进程控制块）</strong></h4>
<p><strong>PCB
是操作系统为每个进程创建的一个数据结构，用来记录和刻画该进程的所有状态和相关信息。</strong></p>
<p>1️⃣ <strong>进程标识信息 (Identification Information)</strong></p>
<table>
<colgroup>
<col style="width: 39%">
<col style="width: 60%">
</colgroup>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>PID (Process ID)</strong></td>
<td>进程的唯一数字标识，如 <code>12345</code>。</td>
</tr>
<tr>
<td><strong>PPID (Parent PID)</strong></td>
<td>父进程的 PID，用于构建进程树。</td>
</tr>
<tr>
<td><strong>UID/GID (User/Group ID)</strong></td>
<td>进程所属用户的 ID 和组 ID，用于权限控制。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>🌰 <strong>你的例子</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;当前进程 PID: <span class="subst">&#123;os.getpid()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;父进程 PID: <span class="subst">&#123;os.getppid()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure> 这些值就是从 PCB
中读取的！</p>
</blockquote>
<p>2️⃣ <strong>处理器状态信息 (Processor State Information)</strong> ——
<strong>这就是“寄存器上下文”</strong></p>
<p>这是 PCB 最关键的部分，用于<strong>上下文切换</strong>。</p>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 66%">
</colgroup>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>程序计数器 (PC)</strong></td>
<td>下一条要执行的指令地址。</td>
</tr>
<tr>
<td><strong>通用寄存器 (AX, BX, CX…)</strong></td>
<td>存放临时计算结果、变量地址等。</td>
</tr>
<tr>
<td><strong>程序状态字 (PSW)</strong></td>
<td>包含标志位（零标志 Z、进位标志 C、溢出标志 O
等）、中断允许位、特权级别。</td>
</tr>
<tr>
<td><strong>栈指针 (SP)</strong></td>
<td>指向当前函数调用栈的顶部。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>⚡ <strong>关键点</strong>：每次进程切换时，操作系统都会将当前 CPU
寄存器的值“倾倒”进 PCB，再从新进程的 PCB
“倒回”寄存器。这就是“上下文切换”的核心开销。</p>
</blockquote>
<p>3️⃣ <strong>进程调度信息 (Scheduling Information)</strong></p>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>进程状态</strong></td>
<td>就绪、运行、阻塞、挂起等。</td>
</tr>
<tr>
<td><strong>进程优先级</strong></td>
<td>决定调度顺序。</td>
</tr>
<tr>
<td><strong>时间片剩余量</strong></td>
<td>用于时间片轮转调度。</td>
</tr>
<tr>
<td><strong>等待事件</strong></td>
<td>如等待键盘输入、网络数据包到达等。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>🌰 <strong>你的例子</strong>： 在 FastAPI 中，当一个请求在
<code>await httpx.get(...)</code>
时，其对应协程/线程的状态会被标记为“阻塞”，并被放入等待队列。这就是 PCB
中“进程状态”字段的作用。</p>
</blockquote>
<p>4️⃣ <strong>内存管理信息 (Memory Management Information)</strong></p>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>页表基址 / 段表指针</strong></td>
<td>用于虚拟内存到物理内存的地址转换。</td>
</tr>
<tr>
<td><strong>内存分配情况</strong></td>
<td>代码段、数据段、堆、栈的起始地址和大小。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>💡
<strong>关键点</strong>：确保进程访问的是自己的内存空间，实现“内存保护”。</p>
</blockquote>
<p>5️⃣ <strong>I/O 状态信息 (I/O Status Information)</strong></p>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>打开的文件列表</strong></td>
<td>文件描述符（fd）、文件指针、访问模式等。</td>
</tr>
<tr>
<td><strong>分配的 I/O 设备</strong></td>
<td>如打印机、网卡等。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>🌰 <strong>你的例子</strong>： 当你在 Python 中
<code>f = open("log.txt", "a")</code> 时，操作系统会在 PCB
的“打开文件列表”中添加一条记录，记录这个文件句柄 <code>f</code> 对应的
fd。</p>
</blockquote>
<p>6️⃣ <strong>记账信息 (Accounting Information)</strong></p>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CPU 使用时间</strong></td>
<td>进程已使用的 CPU 时间总和。</td>
</tr>
<tr>
<td><strong>累计运行时间</strong></td>
<td>从创建到现在的总时间。</td>
</tr>
<tr>
<td><strong>最大内存使用量</strong></td>
<td>历史峰值。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>📊 <strong>用途</strong>：用于性能监控、计费、调试等。</p>
</blockquote>
<h3 id="进程队列">进程队列</h3>
<h4 id="链接方式">链接方式</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251115212223846.png" alt="image-20251115212223846">
<figcaption aria-hidden="true">image-20251115212223846</figcaption>
</figure>
<h4 id="索引方式">索引方式</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251115212241091.png" alt="image-20251115212241091">
<figcaption aria-hidden="true">image-20251115212241091</figcaption>
</figure>
<h3 id="进程切换和处理器状态转换">进程切换和处理器状态转换</h3>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251115212521578.png" alt="image-20251115212521578">
<figcaption aria-hidden="true">image-20251115212521578</figcaption>
</figure>
<h4 id="模式切换-vs.-进程切换">模式切换 vs. 进程切换</h4>
<ol type="1">
<li>模式切换 (Mode Switch)</li>
</ol>
<blockquote>
<p><strong>定义</strong>：CPU 在“用户态（User Mode）”和“核心态（Kernel
Mode）”之间的切换。
<strong>触发方式</strong>：由<strong>中断（Interrupt）或系统调用（System
Call）</strong> 引起。
<strong>目的</strong>：让操作系统获得控制权，执行特权指令（如访问硬件、修改内存映射）。</p>
</blockquote>
<ol start="2" type="1">
<li>进程切换 (Process Switch / Context Switch)</li>
</ol>
<blockquote>
<p><strong>定义</strong>：操作系统暂停当前正在运行的进程，保存其状态，并加载另一个进程的状态，使其开始运行。
<strong>触发方式</strong>：通常发生在<strong>核心态</strong>下，由中断或系统调用引发。
<strong>目的</strong>：实现多任务并发，公平分配 CPU 时间。</p>
</blockquote>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251115215300054.png" alt="image-20251115215300054">
<figcaption aria-hidden="true">image-20251115215300054</figcaption>
</figure>
<h4 id="当进程开始运行时操作系统如何重新获得控制">当进程开始运行时，操作系统如何重新获得控制？</h4>
<p>果进程一直在运行，操作系统就永远没机会调度其他进程了，系统就会卡死。</p>
<p><strong>答案：中断 (Interrupt) 是关键！</strong></p>
<ul>
<li><strong>什么是中断？</strong>
中断就像一个“<strong>紧急电话</strong>”，它能打断 CPU
当前正在执行的程序，强制 CPU
去处理一个更高优先级的事情——通常是操作系统内核。
<ul>
<li><strong>硬件中断</strong>：由外部设备触发，比如键盘敲击、鼠标移动、网络数据包到达、定时器到期。</li>
<li><strong>软件中断/异常</strong>：由程序自身触发，比如除零错误、访问非法内存地址、或者程序主动发起的<strong>系统调用</strong>（如
<code>open()</code>, <code>read()</code>）。</li>
</ul></li>
</ul>
<h4 id="进程需要保存哪些状态">进程需要保存哪些状态？</h4>
<p>当操作系统获得控制权后，它必须把当前正在运行的进程（比如进程0）的“工作状态”完整地记录下来，以便将来能恢复执行。这个过程叫做“<strong>保存现场
(Save Context)</strong>”。</p>
<p><strong>需要保存哪些状态？</strong></p>
<p>这些状态主要存储在一个叫做 <strong>PCB (Process Control Block,
进程控制块)</strong> 的数据结构里。PCB 就像是进程的“<strong>身份证 +
工作日志 + 资源清单</strong>”。</p>
<h4 id="如何选择下一个待执行的进程线程">如何选择下一个待执行的进程/线程？</h4>
<p>当操作系统保存完当前进程的状态后，它需要决定“<strong>接下来该让谁干活</strong>”。这个决策过程叫做“<strong>进程调度
(Process Scheduling)</strong>”。</p>
<p><strong>如何选择？</strong></p>
<p>这取决于操作系统的<strong>调度算法 (Scheduling
Algorithm)</strong>。</p>
<h3 id="线程">线程</h3>
<h4 id="为什么需要线程-引入线程的动机">为什么需要线程？——
引入线程的动机</h4>
<p>❓ 问题：进程模型有什么不足？</p>
<ol type="1">
<li><strong>切换开销大</strong>：进程切换需要保存/恢复整个内存空间（代码、数据、堆、栈）和
PCB，开销大。</li>
<li><strong>通信困难</strong>：进程间通信（IPC）需要管道、消息队列、共享内存等复杂机制，效率低。</li>
<li><strong>不适合细粒度并发</strong>：比如一个 Web
服务器，每个请求都创建一个进程，成本太高。</li>
</ol>
<p>✅ 解决方案：引入线程！</p>
<blockquote>
<p><strong>线程是进程内的一个执行单元，是 CPU
调度和分派的基本单位。</strong></p>
</blockquote>
<ul>
<li><strong>同一个进程内的所有线程</strong>：
<ul>
<li><strong>共享</strong>：代码段、数据段、堆、打开的文件等<strong>进程资源</strong>。</li>
<li><strong>私有</strong>：各自的<strong>栈</strong>和<strong>寄存器上下文</strong>。</li>
</ul></li>
</ul>
<blockquote>
<p>💡
<strong>核心价值</strong>：<strong>实现进程内部的并发，降低切换和通信开销</strong>。</p>
</blockquote>
<h4 id="什么是线程-核心定义">什么是线程？—— 核心定义</h4>
<blockquote>
<p><strong>线程（Thread）是进程中一个可并发执行的控制流，它拥有自己独立的栈和寄存器状态，但与其他线程共享进程的地址空间和资源。</strong></p>
</blockquote>
<h4 id="线程如何工作-线程的生命周期与切换">线程如何工作？——
线程的生命周期与切换</h4>
<ol type="1">
<li><strong>线程的生命周期状态</strong></li>
</ol>
<p>和进程类似，线程也有状态：<strong>新建 → 就绪 → 运行 → 阻塞 →
终止</strong>。</p>
<ol start="2" type="1">
<li><strong>线程切换（Thread Switching）</strong></li>
</ol>
<ul>
<li><strong>开销远小于进程切换</strong>！因为不需要切换地址空间（页表），只需要保存/恢复<strong>寄存器上下文和栈指针</strong>。</li>
<li>切换由<strong>线程调度器</strong>（在 OS
内核或用户态库中）管理。</li>
</ul>
<ol start="3" type="1">
<li><strong>线程的实现方式</strong></li>
</ol>
<table>
<colgroup>
<col style="width: 29%">
<col style="width: 45%">
<col style="width: 24%">
</colgroup>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
<th>例子</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>用户级线程 (User-Level Threads)</strong></td>
<td>由用户态线程库（如 Java Green Threads）管理，内核 unaware</td>
<td>Python 的 <code>greenlet</code>（非标准）</td>
</tr>
<tr>
<td><strong>内核级线程 (Kernel-Level Threads)</strong></td>
<td>由操作系统内核直接管理，每个线程对应一个内核调度实体</td>
<td>Python 的 <code>threading</code> 模块</td>
</tr>
<tr>
<td><strong>混合模式</strong></td>
<td>用户级线程映射到少量内核线程</td>
<td>Go 的 Goroutine</td>
</tr>
</tbody>
</table>
<blockquote>
<p>💡 <strong>Python 的 <code>threading</code>
是内核级线程</strong>，但受 GIL 限制，无法真正并行执行 Python
字节码。</p>
</blockquote>
<h2 id="处理器调度">处理器调度</h2>
<h3 id="调度层次">调度层次</h3>
<p>1️⃣ 高级调度（High-Level Scheduling）—— 作业调度 / 长程调度</p>
<blockquote>
<p><strong>目标</strong>：决定哪些“作业”被允许进入系统参与 CPU 竞争。
<strong>对象</strong>：作业（Job）→
通常是一个完整的程序或任务（如编译一个文件、运行一个脚本）。
<strong>发生频率</strong>：<strong>低</strong>（几分钟到几小时一次）。
<strong>执行者</strong>：操作系统内核。</p>
</blockquote>
<p>🔍 核心功能：</p>
<ul>
<li><strong>选作业进内存</strong>：从后备队列中选择作业，将其加载到内存，创建进程。</li>
<li><strong>控制多道程序的道数</strong>：决定同时在内存中运行多少个作业（即并发度）。太多会耗尽内存，太少会浪费
CPU。</li>
</ul>
<p>2️⃣ 中级调度（Medium-Level Scheduling）—— 平衡调度 / 内存调度</p>
<blockquote>
<p><strong>目标</strong>：根据内存状态，决定哪些进程可以在内存中运行，哪些需要换出到外存。
<strong>对象</strong>：进程（Process）。
<strong>发生频率</strong>：<strong>中等</strong>（几秒到几分钟一次）。
<strong>执行者</strong>：操作系统内核。</p>
</blockquote>
<p>🔍 核心功能：</p>
<ul>
<li><strong>选进程进出内存</strong>：当内存紧张时，将一些不活跃的进程（如长时间阻塞的进程）换出到
Swap 分区；当内存空闲时，再换回。</li>
<li><strong>平衡系统负载</strong>：防止内存溢出，提高系统吞吐量。</li>
</ul>
<p>3️⃣ 低级调度（Low-Level Scheduling）—— 进程调度 / CPU 调度</p>
<blockquote>
<p><strong>目标</strong>：决定哪个就绪队列中的进程/线程获得 CPU 执行权。
<strong>对象</strong>：进程或线程（内核级线程）。
<strong>发生频率</strong>：<strong>高</strong>（毫秒级，每几十到几百毫秒一次）。
<strong>执行者</strong>：操作系统内核 →
<strong>这是操作系统最核心的部分</strong>！</p>
</blockquote>
<p>🔍 核心功能：</p>
<ul>
<li><strong>选进程分配
CPU</strong>：从就绪队列中选出下一个要运行的进程/线程。</li>
<li><strong>执行上下文切换</strong>：保存当前进程上下文，恢复新进程上下文。</li>
<li><strong>实现公平与效率</strong>：通过调度算法（如
RR、优先级、MLFQ）保证所有进程都能得到 CPU 时间。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    A[高级调度] --&gt;|选作业进内存| B[中级调度]</span><br><span class="line">    B --&gt;|选进程进出内存| C[低级调度]</span><br><span class="line">    C --&gt;|选进程分配 CPU| D[CPU 执行]</span><br><span class="line"></span><br><span class="line">    style A fill:#f9d5e5,stroke:#333</span><br><span class="line">    style B fill:#e3eaa7,stroke:#333</span><br><span class="line">    style C fill:#b2d3c2,stroke:#333</span><br></pre></td></tr></table></figure>
<h3 id="调度算法评价指标">调度算法评价指标</h3>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116131448708.png" alt="image-20251116131448708">
<figcaption aria-hidden="true">image-20251116131448708</figcaption>
</figure>
<h3 id="七种调度策略">七种调度策略</h3>
<h4 id="先来先服务-first-come-first-serverd-fcfs">先来先服务 (First Come
First Serverd, FCFS)</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116132753390.png" alt="image-20251116132753390">
<figcaption aria-hidden="true">image-20251116132753390</figcaption>
</figure>
<h4 id="短作业优先-shortest-job-first-sjf">短作业优先 (Shortest Job
First, SJF)</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116132925377.png" alt="image-20251116132925377">
<figcaption aria-hidden="true">image-20251116132925377</figcaption>
</figure>
<h4 id="最短剩余时间优先-shortest-remaining-time-first-srtf">最短剩余时间优先
(Shortest Remaining Time First, SRTF)</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116133352988.png" alt="image-20251116133352988">
<figcaption aria-hidden="true">image-20251116133352988</figcaption>
</figure>
<h4 id="最高响应比优先-highest-response-ratio-first-hrrf">最高响应比优先
(Highest Response Ratio First, HRRF)</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116133432719.png" alt="image-20251116133432719">
<figcaption aria-hidden="true">image-20251116133432719</figcaption>
</figure>
<h4 id="优先级调度-priority-scheduling">优先级调度 (Priority
Scheduling)</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116141512909.png" alt="image-20251116141512909">
<figcaption aria-hidden="true">image-20251116141512909</figcaption>
</figure>
<h4 id="轮转调度-round-robin-scheduling-rr">轮转调度 (Round Robin
Scheduling, RR)</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116141611150.png" alt="image-20251116141611150">
<figcaption aria-hidden="true">image-20251116141611150</figcaption>
</figure>
<h4 id="多级反馈队列调度-multi-level-feedback-queue-mlfq">多级反馈队列调度
(Multi-Level Feedback Queue, MLFQ)</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116144745818.png" alt="image-20251116144745818">
<figcaption aria-hidden="true">image-20251116144745818</figcaption>
</figure>
<h2 id="并发互斥与同步">并发：互斥与同步</h2>
<h3 id="进程交互"><strong>进程交互</strong></h3>
<h4 id="为什么需要进程交互">为什么需要“进程交互”？</h4>
<p>在单进程时代，程序是“独占”的——它不需要考虑别人。但在现代操作系统中：</p>
<ul>
<li>多个进程/线程同时运行。</li>
<li>它们可能共享资源（如内存、文件、数据库连接）。</li>
<li>它们可能需要协同完成一个复杂任务（如一个 Web
请求涉及多个微服务）。</li>
</ul>
<p>这就产生了两个根本性问题：</p>
<ol type="1">
<li><strong>竞争（Competition）</strong>：多个进程争抢同一个资源，导致结果不可预测。</li>
<li><strong>协作（Cooperation）</strong>：多个进程需要按特定顺序执行，才能完成共同目标。</li>
</ol>
<blockquote>
<p>✅ <strong>进程交互就是解决这两个问题的机制</strong>。</p>
</blockquote>
<h4 id="竞争关系进程互斥">竞争关系（进程互斥）</h4>
<p>✅ 核心定义：</p>
<blockquote>
<p><strong>进程互斥是指若干进程因相互争夺独占型资源而产生的竞争制约关系。</strong></p>
</blockquote>
<p>📌 关键词解析：</p>
<ul>
<li><strong>“相互争夺”</strong>：多个进程都想使用同一个资源。</li>
<li><strong>“独占型资源”</strong>：一次只能被一个进程使用的资源，如打印机、临界区代码、全局变量、数据库连接等。</li>
<li><strong>“竞争制约关系”</strong>：一个进程的执行会制约另一个进程的执行。</li>
</ul>
<p>🧱 两个核心控制问题：</p>
<ol type="1">
<li><strong>死锁问题（Deadlock）</strong>
<ul>
<li><strong>定义</strong>：多个进程互相等待对方释放资源，导致所有进程都无法继续执行。</li>
<li><strong>经典例子</strong>：“哲学家就餐问题”——五个哲学家围坐圆桌，每人左右各有一根筷子。他们必须拿到两根筷子才能吃饭。如果每个人都拿起左边的筷子，然后等待右边的筷子，就会陷入死锁。</li>
<li><strong>四个必要条件</strong>：
<ul>
<li>互斥条件</li>
<li>请求与保持条件</li>
<li>不剥夺条件</li>
<li>环路等待条件</li>
</ul></li>
</ul></li>
<li><strong>饥饿问题（Starvation）</strong>
<ul>
<li><strong>定义</strong>：某个进程因为优先级低或资源分配策略不当，长时间得不到所需资源，导致无法执行。</li>
<li><strong>例子</strong>：在一个高优先级任务永远不结束的系统中，低优先级任务可能永远得不到
CPU。</li>
</ul></li>
</ol>
<h4 id="协作关系进程同步">协作关系（进程同步）</h4>
<p>✅ 核心定义：</p>
<blockquote>
<p><strong>进程同步是指为完成共同任务的并发进程基于某个条件来协调其活动，因为需要在某些位置上排定执行的先后次序而等待、传递信号或消息所产生的协作制约关系。</strong></p>
</blockquote>
<p>📌 关键词解析：</p>
<ul>
<li><strong>“完成共同任务”</strong>：多个进程/线程需要合作才能达成目标。</li>
<li><strong>“协调活动”</strong>：它们需要按特定顺序执行。</li>
<li><strong>“排定执行先后次序”</strong>：比如 A 必须在 B 之前执行。</li>
<li><strong>“等待、传递信号或消息”</strong>：通过同步机制（如信号量、条件变量、管道）实现通信和协调。</li>
</ul>
<p>🧱 核心思想：</p>
<ul>
<li><strong>“生产者-消费者”模型</strong>：生产者生成数据，消费者消费数据，它们必须同步。</li>
<li><strong>“读者-写者”模型</strong>：读者可以同时读，但写者必须独占。</li>
<li><strong>“屏障（Barrier）”</strong>：所有进程到达某个点后才能继续执行。</li>
</ul>
<h3 id="临界区管理">临界区管理</h3>
<h4 id="什么是临界区">什么是“临界区”？</h4>
<p>✅ 核心定义：</p>
<blockquote>
<p><strong>并发进程中，与共享变量有关的程序段叫做“临界区”（Critical
Section）。</strong></p>
</blockquote>
<p>📌 关键词解析：</p>
<ul>
<li><strong>“并发进程”</strong>：多个进程/线程同时运行。</li>
<li><strong>“共享变量”</strong>：多个进程都能访问和修改的变量（如全局变量、数据库连接、文件句柄）。</li>
<li><strong>“程序段”</strong>：一段代码，比如 <code>counter += 1</code>
这样的操作。</li>
</ul>
<blockquote>
<p>💡 <strong>简单说</strong>：<strong>临界区 =
操作共享资源的那一小段代码。</strong></p>
</blockquote>
<p>🎯 为什么重要？</p>
<p>因为这段代码如果被多个进程同时执行，会导致<strong>竞态条件（Race
Condition）</strong>，产生不可预测的结果。</p>
<h4 id="如何避免错误-互斥访问临界区">如何避免错误？——
互斥访问临界区</h4>
<blockquote>
<p><strong>如果保证进程在临界区执行时，不让另一个进程进入临界区，即各进程对共享变量的访问是互斥的，就不会造成与时间有关的错误。</strong></p>
</blockquote>
<p>这就是“<strong>进程互斥</strong>”的核心思想。</p>
<h4 id="临界区调度的三个原则经典">临界区调度的三个原则（经典！）</h4>
<p>这是解决临界区问题的黄金法则，任何同步机制都必须满足这三个条件：</p>
<p>✅ 原则 1：一次至多一个进程能够进入临界区内执行</p>
<blockquote>
<p><strong>互斥性（Mutual Exclusion）</strong></p>
</blockquote>
<ul>
<li>这是最基本的要求。任何时候，最多只能有一个进程在临界区内。</li>
<li>如果 A 在临界区，B 就不能进入，必须等待。</li>
</ul>
<p>✅ 原则 2：如果已有进程在临界区，其他试图进入的进程应等待</p>
<blockquote>
<p><strong>忙则等待（Progress）</strong></p>
</blockquote>
<ul>
<li>如果临界区空闲，想进入的进程可以立即进入。</li>
<li>如果临界区被占用，其他进程必须等待，不能“自旋”浪费
CPU（虽然有些实现会自旋，但理想情况下应该阻塞等待）。</li>
</ul>
<p>✅ 原则
3：进入临界区内的进程应在有限时间内退出，以便让等待进程中的一个进入</p>
<blockquote>
<p><strong>有限等待（Bounded Waiting）</strong></p>
</blockquote>
<ul>
<li>防止“饥饿”。不能让某个进程永远等下去。</li>
<li>例如，使用队列来管理等待的进程，确保每个进程最终都能获得进入临界区的机会。</li>
</ul>
<h3 id="实现临界区管理的软件方法一peterson方法">实现临界区管理的软件方法一Peterson方法</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int turn;           // turn 表示轮到谁进入</span><br><span class="line">boolean flag[2];   // flag[i] 表示进程 i 想进入临界区</span><br><span class="line"></span><br><span class="line">// 初始化</span><br><span class="line">flag[0] = flag[1] = false;</span><br><span class="line"></span><br><span class="line">Process P0() &#123;</span><br><span class="line">    flag[0] = true;</span><br><span class="line">    turn = 1;       // 谦让给 P1</span><br><span class="line">    while (flag[1] &amp;&amp; turn == 1); // 等待 P1 退出或谦让</span><br><span class="line">    /* critical section */</span><br><span class="line">    flag[0] = false;</span><br><span class="line">    /* remainder section */</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Process P1() &#123;</span><br><span class="line">    flag[1] = true;</span><br><span class="line">    turn = 0;       // 谦让给 P0</span><br><span class="line">    while (flag[0] &amp;&amp; turn == 0); // 等待 P0 退出或谦让</span><br><span class="line">    /* critical section */</span><br><span class="line">    flag[1] = false;</span><br><span class="line">    /* remainder section */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>✅ 1. 互斥性 (Mutual Exclusion)</p>
<blockquote>
<p><strong>定义</strong>：一次至多一个进程能进入临界区。</p>
</blockquote>
<p>📌 证明思路：</p>
<ul>
<li>假设 P0 和 P1 同时进入临界区。</li>
<li>那么 <code>flag[0] = true</code> 且
<code>flag[1] = true</code>。</li>
<li>根据算法，P0 在进入前设置了 <code>turn = 1</code>，P1 设置了
<code>turn = 0</code>。</li>
<li>由于 <code>turn</code> 只能取值 0 或 1，不可能同时为 0 和 1。</li>
<li>所以，当 P0 检查 <code>while (flag[1] &amp;&amp; turn == 1)</code>
时，如果 <code>turn == 0</code>，它就会阻塞。</li>
<li>同理，P1 也会被阻塞。</li>
<li><strong>结论</strong>：不可能同时进入。</li>
</ul>
<p>✅ 2. 空闲让进 (Progress)</p>
<blockquote>
<p><strong>定义</strong>：如果临界区空闲，且有进程想进入，则该进程应该能进入。</p>
</blockquote>
<p>📌 证明思路：</p>
<ul>
<li>如果 P1 不想进入临界区，则 <code>flag[1] = false</code>。</li>
<li>此时，无论 <code>turn</code> 是多少，P0 的
<code>while (flag[1] &amp;&amp; turn == 1)</code> 条件都会失败（因为
<code>flag[1]</code> 是 <code>false</code>），所以 P0
可以立即进入临界区。</li>
</ul>
<p>✅ 3. 有限等待 (Bounded Waiting)</p>
<blockquote>
<p><strong>定义</strong>：一个进程最多等待另一个进程执行完临界区一次，就能获得进入的机会。</p>
</blockquote>
<p>📌 证明思路：</p>
<ul>
<li>假设 P0 被阻塞，说明 <code>turn = 1</code> 且
<code>flag[1] = true</code>，即 P1 在临界区。</li>
<li>当 P1 执行完临界区后，它会设置 <code>flag[1] = false</code>。</li>
<li>此时，如果 P0 还想进入，它的 <code>while</code>
条件会失败，从而进入临界区。</li>
<li>如果 P1 在 <code>flag[1] = false</code> 后又想进入，则它会设置
<code>flag[1] = true</code> 和 <code>turn = 0</code>。</li>
<li>此时，P0 会被阻塞，但 P1 执行完后，P0 就能进入。</li>
<li><strong>结论</strong>：P0 最多等待 P1
执行一次临界区，就能进入。</li>
</ul>
<h3 id="信号量与pv操作">信号量与PV操作</h3>
<h4 id="信号量semaphore">信号量（Semaphore）</h4>
<p>✅ 核心定义：</p>
<blockquote>
<p><strong>信号量是一种软件资源，用于表示物理资源的实体，是一个与队列有关的整型变量。</strong></p>
</blockquote>
<p>📌 关键词解析：</p>
<ul>
<li><strong>“表示物理资源”</strong>：比如打印机、数据库连接池、线程池中的可用线程数。</li>
<li><strong>“整型变量”</strong>：信号量的值代表当前<strong>可用资源的数量</strong>。</li>
<li><strong>“与队列有关”</strong>：当资源不足时，等待的进程会被放入一个<strong>等待队列</strong>。</li>
</ul>
<h4 id="pv-操作信号量的原子操作">P/V 操作：信号量的“原子操作”</h4>
<p>✅ 定义：</p>
<blockquote>
<p><strong>P (Proberen, 尝试) 和 V (Verhogen, 增加)
是对信号量进行操作的原语。</strong></p>
</blockquote>
<ul>
<li><strong>P 操作</strong>：尝试获取资源。如果资源可用（信号量 &gt;
0），则减 1；否则，进程进入等待队列。</li>
<li><strong>V
操作</strong>：释放资源。增加信号量值，并唤醒一个等待的进程。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// P 操作 (Wait)</span><br><span class="line">void P(semaphore s) &#123;</span><br><span class="line">    s.value = s.value - 1;</span><br><span class="line">    if (s.value &lt; 0) &#123;</span><br><span class="line">        // 资源不足，将当前进程加入等待队列并阻塞</span><br><span class="line">        block(current_process);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// V 操作 (Signal)</span><br><span class="line">void V(semaphore s) &#123;</span><br><span class="line">    s.value = s.value + 1;</span><br><span class="line">    if (s.value &lt;= 0) &#123;</span><br><span class="line">        // 有进程在等待，唤醒一个</span><br><span class="line">        wakeup(one_waiting_process);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>⚠️ <strong>关键点</strong>：P/V 操作必须是<strong>原子操作（Atomic
Operation）</strong>，即在执行过程中不能被中断。否则会导致竞态条件。</p>
<h3 id="哲学家进餐问题">哲学家进餐问题</h3>
<h4 id="哲学家进餐问题核心描述">哲学家进餐问题：核心描述</h4>
<p>✅ 问题设定：</p>
<ul>
<li>有 <strong>5 位哲学家</strong> 围坐在一张圆桌旁。</li>
<li>每位哲学家面前有一盘<strong>意大利面</strong>。</li>
<li>桌子上有 <strong>5 把叉子</strong>，每两位哲学家之间放一把。</li>
<li>哲学家的生活只有两件事：
<ul>
<li><strong>思考（Think）</strong>：什么都不做。</li>
<li><strong>吃饭（Eat）</strong>：必须同时拿到<strong>左右两边的叉子</strong>才能吃。</li>
</ul></li>
<li>吃完后，会放下叉子，继续思考。</li>
</ul>
<blockquote>
<p>💡
<strong>目标</strong>：设计一个算法，让所有哲学家都能吃饱，且不会发生死锁或饥饿。</p>
</blockquote>
<h4 id="为什么会出现死锁">为什么会出现死锁？</h4>
<p>📌 死锁的四个必要条件：</p>
<ol type="1">
<li><strong>互斥条件</strong>：叉子一次只能被一个人使用。</li>
<li><strong>请求与保持条件</strong>：哲学家拿起一把叉子后，会继续等待另一把。</li>
<li><strong>不剥夺条件</strong>：不能强行从哲学家手中拿走叉子。</li>
<li><strong>环路等待条件</strong>：每位哲学家都在等右边的人放下叉子，形成一个循环等待链。</li>
</ol>
<h4 id="解决方案打破死锁的四个条件之一">解决方案：打破死锁的四个条件之一</h4>
<p>要避免死锁，只需破坏其中一个必要条件即可。以下是几种经典的解决方案：</p>
<p>✅ 解决方案 1：限制同时就餐的哲学家数量（破坏“环路等待”）</p>
<blockquote>
<p><strong>最多允许 4 位哲学家同时吃面。</strong></p>
</blockquote>
<p>📌 原理：</p>
<ul>
<li>如果只有 4 个人尝试拿叉子，那么至少有一把叉子是空闲的。</li>
<li>这样，总会有一个人能拿到两把叉子并吃完，从而释放资源。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"># 5 把叉子（信号量）</span><br><span class="line">forks = [threading.Semaphore(1) for _ in range(5)]</span><br><span class="line"># 限制同时就餐人数为 4</span><br><span class="line">dining_room = threading.Semaphore(4)</span><br><span class="line"></span><br><span class="line">def philosopher(i):</span><br><span class="line">    while True:</span><br><span class="line">        think()</span><br><span class="line">        dining_room.acquire()  # 进入餐厅（最多 4 人）</span><br><span class="line">        </span><br><span class="line">        forks[i].acquire()       # 拿起左边叉子</span><br><span class="line">        forks[(i + 1) % 5].acquire()  # 拿起右边叉子</span><br><span class="line">        </span><br><span class="line">        eat(i)</span><br><span class="line">        </span><br><span class="line">        forks[i].release()       # 放下左边叉子</span><br><span class="line">        forks[(i + 1) % 5].release()  # 放下右边叉子</span><br><span class="line">        </span><br><span class="line">        dining_room.release()    # 离开餐厅</span><br><span class="line"></span><br><span class="line">def think():</span><br><span class="line">    time.sleep(0.1)</span><br><span class="line"></span><br><span class="line">def eat(i):</span><br><span class="line">    print(f&quot;Philosopher &#123;i&#125; is eating...&quot;)</span><br><span class="line">    time.sleep(0.1)</span><br><span class="line"></span><br><span class="line"># 创建 5 个哲学家线程</span><br><span class="line">threads = []</span><br><span class="line">for i in range(5):</span><br><span class="line">    t = threading.Thread(target=philosopher, args=(i,))</span><br><span class="line">    threads.append(t)</span><br><span class="line">    t.start()</span><br><span class="line"></span><br><span class="line">for t in threads:</span><br><span class="line">    t.join()</span><br></pre></td></tr></table></figure>
<p>✅ 解决方案 2：奇偶号哲学家取叉子顺序不同（破坏“环路等待”）</p>
<blockquote>
<p><strong>奇数号哲学家先取左边叉子，再取右边；偶数号哲学家先取右边叉子，再取左边。</strong></p>
</blockquote>
<p>📌 原理：</p>
<ul>
<li>这样就不会形成环路等待。</li>
<li>例如，哲学家 0（偶数）先拿右边叉子（叉子 1），哲学家
1（奇数）先拿左边叉子（叉子 1）→
他们争抢同一把叉子，但最终只会有一个成功，另一个等待，从而打破环路。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def philosopher(i):</span><br><span class="line">    while True:</span><br><span class="line">        think()</span><br><span class="line">        </span><br><span class="line">        if i % 2 == 0:  # 偶数号哲学家</span><br><span class="line">            forks[(i + 1) % 5].acquire()  # 先拿右边叉子</span><br><span class="line">            forks[i].acquire()             # 再拿左边叉子</span><br><span class="line">        else:  # 奇数号哲学家</span><br><span class="line">            forks[i].acquire()             # 先拿左边叉子</span><br><span class="line">            forks[(i + 1) % 5].acquire()  # 再拿右边叉子</span><br><span class="line">        </span><br><span class="line">        eat(i)</span><br><span class="line">        </span><br><span class="line">        forks[i].release()                 # 放下左边叉子</span><br><span class="line">        forks[(i + 1) % 5].release()      # 放下右边叉子</span><br></pre></td></tr></table></figure>
<p>✅ 解决方案 3：拿起两把叉子才开始吃（破坏“请求与保持”）</p>
<blockquote>
<p><strong>每位哲学家必须同时拿到两把叉子才能开始吃，否则一把也不拿。</strong></p>
</blockquote>
<p>1️⃣ 全局变量定义</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> THINKING 0</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HUNGRY   1</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EATING   2</span></span><br><span class="line"></span><br><span class="line">semaphore s[<span class="number">5</span>];     <span class="comment">// 用于阻塞哲学家的信号量</span></span><br><span class="line">semaphore mutex = <span class="number">1</span>; <span class="comment">// 互斥锁，保护 state 和 s</span></span><br><span class="line"><span class="type">int</span> state[<span class="number">5</span>];      <span class="comment">// 哲学家的状态</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>s[i]</code> 初始值为 0，因为一开始没有人需要等待。</li>
<li><code>state[i]</code> 初始化为 <code>THINKING</code>。</li>
</ul>
<p>2️⃣ <code>take_fork(int i)</code> 函数</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">take_fork</span><span class="params">(<span class="type">int</span> i)</span> &#123;</span><br><span class="line">    P(mutex);           <span class="comment">// 获取互斥锁</span></span><br><span class="line">    state[i] = HUNGRY;  <span class="comment">// 哲学家 i 变成饥饿状态</span></span><br><span class="line">    test(i);            <span class="comment">// 尝试让 i 吃饭</span></span><br><span class="line">    V(mutex);           <span class="comment">// 释放互斥锁</span></span><br><span class="line">    P(s[i]);            <span class="comment">// 如果 test(i) 没有让 i 吃上饭，这里会阻塞</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>📌 关键点：</p>
<ul>
<li><strong><code>state[i] = HUNGRY</code></strong>:
告诉“管家”，我饿了。</li>
<li><strong><code>test(i)</code></strong>: “管家”检查我是否能吃。
<ul>
<li>如果能吃，<code>test(i)</code> 会执行
<code>V(s[i])</code>，唤醒我。</li>
<li>如果不能吃，<code>test(i)</code> 不做任何事。</li>
</ul></li>
<li><strong><code>P(s[i])</code></strong>:
如果我没被唤醒，我就在这里阻塞，等待邻居放叉子。</li>
</ul>
<blockquote>
<p>✅
<strong>这个函数是“非阻塞”的</strong>：它只负责声明“我饿了”，然后立即返回。真正的等待发生在
<code>P(s[i])</code>。</p>
</blockquote>
<p>3️⃣ <code>put_fork(int i)</code> 函数</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">put_fork</span><span class="params">(<span class="type">int</span> i)</span> &#123;</span><br><span class="line">    P(mutex);           <span class="comment">// 获取互斥锁</span></span><br><span class="line">    state[i] = THINKING; <span class="comment">// 哲学家 i 变成思考状态</span></span><br><span class="line">    test((i + <span class="number">1</span>) % <span class="number">5</span>);  <span class="comment">// 检查右边邻居</span></span><br><span class="line">    test((i + <span class="number">4</span>) % <span class="number">5</span>);  <span class="comment">// 检查左边邻居（(i+4)%5 == (i-1)%5）</span></span><br><span class="line">    V(mutex);           <span class="comment">// 释放互斥锁</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>📌 关键点：</p>
<ul>
<li><strong><code>state[i] = THINKING</code></strong>:
我吃饱了，不再占用叉子。</li>
<li><strong><code>test((i+1)%5)</code> 和
<code>test((i+4)%5)</code></strong>:
告诉“管家”，我的邻居们可能现在可以吃饭了。
<ul>
<li>例如，哲学家 0 放下叉子后，哲学家 1 和 4
可能现在能拿到两把叉子了。</li>
<li>“管家”会检查他们是否处于 <code>HUNGRY</code>
状态，并且邻居都不在吃，如果是，就唤醒他们。</li>
</ul></li>
</ul>
<p>4️⃣ <code>test(int i)</code> 函数 —— 核心逻辑！</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">test</span><span class="params">(<span class="type">int</span> i)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (state[i] == HUNGRY &amp;&amp;</span><br><span class="line">        state[(i + <span class="number">1</span>) % <span class="number">5</span>] != EATING &amp;&amp;</span><br><span class="line">        state[(i + <span class="number">4</span>) % <span class="number">5</span>] != EATING) &#123;</span><br><span class="line">        state[i] = EATING;  <span class="comment">// 可以吃了！</span></span><br><span class="line">        V(s[i]);            <span class="comment">// 唤醒哲学家 i</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>📌 关键点：</p>
<ul>
<li><strong>检查三个条件</strong>：
<ol type="1">
<li><code>state[i] == HUNGRY</code>: 我确实想吃饭。</li>
<li><code>state[(i+1)%5] != EATING</code>: 我右边的邻居没在吃。</li>
<li><code>state[(i+4)%5] != EATING</code>: 我左边的邻居没在吃。</li>
</ol></li>
<li><strong>如果都满足</strong>：说明我现在可以拿到两把叉子！
<ul>
<li>设置 <code>state[i] = EATING</code>。</li>
<li>执行 <code>V(s[i])</code>，唤醒我自己（因为我在
<code>take_fork</code> 中 <code>P(s[i])</code> 阻塞了）。</li>
</ul></li>
</ul>
<blockquote>
<p>✅ <strong>这个函数是“原子”的</strong>：因为它在 <code>mutex</code>
保护下执行，不会被其他哲学家打断。</p>
</blockquote>
<h3 id="生产者消费者问题">生产者消费者问题</h3>
<p><code>mutex</code> 的作用就是：</p>
<blockquote>
<p><strong>保护对共享变量（或临界区）的访问</strong>，
<strong>只在真正操作这些共享资源的前后“加锁”和“解锁”</strong>。</p>
</blockquote>
<p>（防死锁铁律）：</p>
<blockquote>
<p><strong>永远不要在持有互斥锁（mutex）的情况下，调用可能阻塞的操作（如
P(empty)、P(full)、sleep、wait 等）。</strong></p>
</blockquote>
<h3 id="什么是生产者-消费者问题">什么是生产者-消费者问题？</h3>
<p>这是一个经典的<strong>多线程同步问题</strong>，用于模拟现实中的“生产”与“消费”场景：</p>
<ul>
<li><strong>生产者 (Producer)</strong>：负责制造数据或产品。</li>
<li><strong>消费者
(Consumer)</strong>：负责处理或消费这些数据/产品。</li>
<li><strong>缓冲区
(Buffer)</strong>：一个有限大小的共享空间，用来暂存生产者的产品，供消费者取用。</li>
</ul>
<p>📌 核心挑战</p>
<ol type="1">
<li><strong>互斥 (Mutual
Exclusion)</strong>：多个生产者/消费者不能同时操作缓冲区的同一个位置，否则数据会错乱。</li>
<li><strong>同步 (Synchronization)</strong>：
<ul>
<li>生产者不能在缓冲区满时继续生产（要等待）。</li>
<li>消费者不能在缓冲区空时继续消费（要等待）。</li>
</ul></li>
</ol>
<h4 id="代码">代码</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">item B[n];</span><br><span class="line">Semaphore empty;  /*可用的空缓冲区个数*/</span><br><span class="line">Semaphore full;   /*可用的产品数*/</span><br><span class="line">Semaphore mutex;  /*互斥信号量*/</span><br><span class="line">empty = n; full = 0; mutex = 1;</span><br><span class="line">int in = 0; out = 0;  /*in为放入缓冲区指针, out为取出缓冲区指针*/</span><br><span class="line"></span><br><span class="line">Process producer_i( ) &#123;</span><br><span class="line">    while(true) &#123;</span><br><span class="line">        item product = produce();</span><br><span class="line">        P(empty);</span><br><span class="line">        P(mutex);</span><br><span class="line">        B[in] = product;</span><br><span class="line">        in = (in+1) % n;</span><br><span class="line">        V(mutex);</span><br><span class="line">        V(full);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Process consumer_i( ) &#123;</span><br><span class="line">    while(true) &#123;</span><br><span class="line">        P(full);</span><br><span class="line">        P(mutex);</span><br><span class="line">        Item product = B[out];</span><br><span class="line">        out = (out+1) % n;</span><br><span class="line">        V(mutex);</span><br><span class="line">        V(empty);</span><br><span class="line">        consume(product);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="问题如果将p操作的顺序交换会出现什么情况">问题：如果将P操作的顺序交换，会出现什么情况？</h4>
<p><strong>生产者霸占着 <code>mutex</code> 锁，等待
<code>empty</code>，消费者等待 <code>mutex</code>
锁，导致死锁。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">    participant Producer as 生产者 P1</span><br><span class="line">    participant Consumer as 消费者 C1</span><br><span class="line">    participant Mutex as 互斥锁 (mutex)</span><br><span class="line">    participant Empty as 空闲缓冲区 (empty)</span><br><span class="line"></span><br><span class="line">    Note over Producer,Consumer: 初始状态: empty=0 (缓冲区满), mutex=1</span><br><span class="line"></span><br><span class="line">    Producer-&gt;&gt;Mutex: P(mutex) // 成功获取锁，mutex=0</span><br><span class="line">    Producer-&gt;&gt;Empty: P(empty) // empty=0，阻塞！等待空位...</span><br><span class="line">    Note over Producer: 生产者 P1 霸占 mutex 锁，等待 empty</span><br><span class="line"></span><br><span class="line">    Consumer-&gt;&gt;Full: P(full) // full=1，成功，full=0</span><br><span class="line">    Consumer-&gt;&gt;Mutex: P(mutex) // mutex=0，阻塞！等待锁...</span><br><span class="line">    Note over Consumer: 消费者 C1 等待 mutex 锁</span><br><span class="line"></span><br><span class="line">    Note over Producer,Consumer: 💥 死锁！</span><br><span class="line">    Note right of Producer: 我要等 empty (需 C1 消费)</span><br><span class="line">    Note left of Consumer: 我要等 mutex (需 P1 释放)</span><br></pre></td></tr></table></figure>
<h4 id="问题当前生产者消费者共用一个互斥锁会造成竞争">问题：当前生产者消费者共用一个互斥锁会造成竞争</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Semaphore pmutex, cmutex; // 两个独立的互斥锁</span><br><span class="line">...</span><br><span class="line">P(pmutex); // 生产者只锁自己的写入区域</span><br><span class="line">P(cmutex); // 消费者只锁自己的读取区域</span><br></pre></td></tr></table></figure>
<p><strong>优势</strong>：</p>
<ul>
<li><strong>生产者之间</strong>：仍然需要 <code>pmutex</code>
来互斥，因为多个生产者可能同时想写入 <code>in</code>
指针指向的位置。</li>
<li><strong>消费者之间</strong>：仍然需要 <code>cmutex</code>
来互斥，因为多个消费者可能同时想读取 <code>out</code>
指针指向的位置。</li>
<li><strong>生产者 vs 消费者</strong>：<strong>它们可以并行！</strong>
只要生产者在写一个位置，消费者在读另一个位置，两者互不干扰，完全可以同时进行。</li>
</ul>
<h2 id="死锁">死锁</h2>
<h3 id="死锁产生">死锁产生</h3>
<h4 id="什么是死锁">什么是死锁</h4>
<p>在多进程/多线程系统中，<strong>死锁</strong>是指两个或多个进程因竞争资源而造成的一种互相等待的现象，若无外力作用，它们都将无法向前推进。</p>
<blockquote>
<p><strong>简单说：A 等 B，B 等 C，C 又等
A，大家谁也不让步，结果全都卡住。</strong></p>
</blockquote>
<h4 id="死锁的4个必要条件">死锁的4个必要条件</h4>
<p>只要系统发生死锁，以下4个条件<strong>必然同时成立</strong>。缺一不可！</p>
<p>1️⃣ 互斥访问 (Mutual Exclusion)</p>
<ul>
<li><strong>定义</strong>：系统中存在临界资源，进程应互斥地使用这些资源。</li>
<li><strong>通俗解释</strong>：资源一次只能被一个进程使用。比如，打印机、文件、数据库连接、内存中的某个变量等。</li>
<li><strong>为什么是必要条件</strong>？如果资源可以被多个进程同时共享（如只读文件），那就不存在竞争，也就不会死锁。</li>
</ul>
<p>2️⃣ 占有和等待 (Hold and Wait)</p>
<ul>
<li><strong>定义</strong>：进程在请求资源得不到满足而等待时，不释放已占有的资源。</li>
<li><strong>通俗解释</strong>：一个进程已经拿着一些资源，但它还需要其他资源才能完成工作，于是它一边等着新资源，一边还紧紧攥着自己手里的旧资源，不肯放手。</li>
<li><strong>为什么是必要条件</strong>？如果一个进程在等待新资源时能主动释放旧资源，那么它就不会阻塞别人，死锁也就不会形成。</li>
</ul>
<p>3️⃣ 不剥夺 (No Preemption)</p>
<ul>
<li><strong>定义</strong>：已被占用的资源只能由属主进程自愿释放，而不允许被其他进程剥夺。</li>
<li><strong>通俗解释</strong>：资源一旦被某个进程拿走，除非它自己愿意还回来，否则谁也不能强行抢走。这保证了进程的“自主性”，但也为死锁埋下了隐患。</li>
<li><strong>为什么是必要条件</strong>？如果系统能强行剥夺资源（比如操作系统强制回收），那么就可以打破死锁链。</li>
</ul>
<p>4️⃣ 循环等待 (Circular Wait)</p>
<ul>
<li><strong>定义</strong>：存在循环等待链，每个进程在链中等待下一个进程所持有的资源，造成这组进程处于永远等待状态。</li>
<li><strong>通俗解释</strong>：这是一个闭环。A 等 B 的资源，B 等 C
的资源，C 又等 A 的资源，形成了一个“等待环”。</li>
<li><strong>为什么是必要条件</strong>？如果没有循环，等待链最终会指向一个“不等待”的进程，这个进程完成后会释放资源，从而解开整个等待链。</li>
</ul>
<h3 id="死锁防止">死锁防止</h3>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116173459401.png" alt="image-20251116173459401">
<figcaption aria-hidden="true">image-20251116173459401</figcaption>
</figure>
<h3 id="死锁避免">死锁避免</h3>
<h4 id="银行家算法">银行家算法</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116181426684.png" alt="image-20251116181426684">
<figcaption aria-hidden="true">image-20251116181426684</figcaption>
</figure>
<h3 id="死锁检测和解除">死锁检测和解除</h3>
<h4 id="资源分配图">资源分配图</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116182605135.png" alt="image-20251116182605135">
<figcaption aria-hidden="true">image-20251116182605135</figcaption>
</figure>
<ul>
<li><strong>阻塞节点 (Blocked
Node)</strong>：一个进程，它<strong>正在请求一个或多个资源，但这些资源当前都被其他进程占用，且没有空闲实例可用</strong>。它必须等待。</li>
<li><strong>非阻塞节点 (Non-blocked
Node)</strong>：一个进程，它<strong>要么没有请求任何资源，要么它请求的资源当前有空闲实例可以立即满足</strong>。它可以继续执行。</li>
</ul>
<h4 id="如何通过资源分配图判断死锁">如何通过资源分配图判断死锁？</h4>
<p>✅ 死锁的充分条件（当资源类型只有一个实例时）</p>
<blockquote>
<p><strong>如果资源分配图中存在一个环，则系统一定发生死锁。</strong></p>
</blockquote>
<ul>
<li><strong>原因</strong>：在一个环中，每个进程都在等待下一个进程所持有的资源，而下一个进程又在等待再下一个……形成一个无限等待的闭环。</li>
</ul>
<p>⚠️ 当资源类型有多个实例时</p>
<blockquote>
<p><strong>环的存在是死锁的必要条件，但不是充分条件。</strong></p>
</blockquote>
<ul>
<li><strong>原因</strong>：即使图中有环，但如果环中的某个资源类型有多个实例，那么可能还有空闲实例可以满足某个进程的需求，从而打破死锁。</li>
</ul>
<h4 id="资源分配图的简化">资源分配图的简化</h4>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116182901353.png" alt="image-20251116182901353">
<figcaption aria-hidden="true">image-20251116182901353</figcaption>
</figure>
<h4 id="死锁检测算法">死锁检测算法</h4>
<p>与银行家算法的安全性检测类似</p>
<figure>
<img src="/2025/09/08/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/image-20251116184516361.png" alt="image-20251116184516361">
<figcaption aria-hidden="true">image-20251116184516361</figcaption>
</figure>
<h2 id="参考资料">参考资料</h2>
<p><a href="https://jyywiki.cn/OS/2025/">操作系统原理 (2025
春季学期)</a></p>
<p><a href="https://www.bilibili.com/video/BV1XZAbeqEyt/?spm_id_from=333.1387.collection.video_card.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">01
- AI 时代的操作系统课2025
南京大学操作系统原理]_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大三上</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>实习七月复盘</title>
    <url>/2025/08/05/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/%E4%B8%83%E6%9C%88%E5%A4%8D%E7%9B%98/</url>
    <content><![CDATA[<h3 id="文件处理阶段">文件处理阶段</h3>
<ol type="1">
<li>使用libreoffice将doc，docx文件处理成pdf文件，方便后续使用mineru进行提取</li>
<li>完成mineru的docker本地部署；搭建fastapi服务，与项目容器构建自定义网络，方便后续服务调用；使用locust完成对mineru的并发性能测试，和吞吐量测试</li>
<li>对mineru提取的html格式的表格进行预处理工作，将其转化成md格式，方便后续分块，节省tokens</li>
</ol>
<h4 id="部分技术细节">部分技术细节</h4>
<p><strong>mineru提取效果说明</strong></p>
<p>可以完整提取表格与图片，将图片以相对链接形式储存在images文件夹下；可以完成pdf与扫描件的提取，可以实现对图片中文字的识别；输出符合人类阅读顺序的文本，适用于单栏、多栏及复杂排版；删除页眉、页脚、脚注、页码等元素，确保语义连贯</p>
<p>目前问题：仍无法实现对多级标题的识别</p>
<p><strong>mineru的fastapi启动指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3 mineru-api --host 0.0.0.0 --port 30000 --dp-size 3 --enable-torch-compile</span><br></pre></td></tr></table></figure>
<blockquote>
<p>MinerU支持通过sglang的多GPU并行模式来提升推理速度。</p>
<ul>
<li>如果您有超过多张显卡，可以使用sglang的多卡并行模式来增加吞吐量：<code>--dp-size 2</code></li>
<li>同时您可以启用<code>torch.compile</code>来将推理速度加速约15%：<code>--enable-torch-compile</code></li>
</ul>
</blockquote>
<blockquote>
<p>注意设置环境变量<code>MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3</code>保证模型本地加载与调用指定gpu</p>
</blockquote>
<p><strong>mineru容器启动指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host -v /aisys/:/aisys/ --network network_test mineru-sglang:latest tail -f /dev/null</span><br><span class="line">docker start mineru-server</span><br></pre></td></tr></table></figure>
<p><strong>mineru三种后端模式测试</strong></p>
<p>pipeline (默认后端) ，vlm-sglang-engine，vlm-sglang-client</p>
<p>项目中使用的是vlm-sglang-engine，原因如下，pipeline应用场景更多是仅能cpu推理，解析速度大大落后与vlm模式，而我们gpu资源充足，自然不考虑；vlm-sglang-client应用场景更多是有SGLang服务器，这样客户端既可以不用安装sglang，同样不符合我们的条件</p>
<p><strong>mineru并发与吞吐量测试</strong></p>
<p><strong>测试场景</strong>：10页的pdf，50用户并发</p>
<p><strong>工具</strong>：locust</p>
<p><strong>测试结果</strong></p>
<p>对于推理模型的吞吐量，在3个gpu开启数据并行的情况下，平均每秒单个gpu处理tokens为1500左右</p>
<p>gpu状态如上:<strong>显存几乎打满 85–87 %</strong>,<strong>GPU 利用率
59–63 %</strong>,<strong>功耗 170–188 W / 350 W</strong></p>
<p>压测结果如下，选取部分指标</p>
<table>
<colgroup>
<col style="width: 18%">
<col style="width: 28%">
<col style="width: 52%">
</colgroup>
<thead>
<tr>
<th>指标</th>
<th>数值</th>
<th>通俗解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>平均响应时间</strong></td>
<td><strong>241 秒</strong> ≈ <strong>4 分钟</strong></td>
<td>上传一个 PDF → 拿到解析结果，平均要等 4 分钟。</td>
</tr>
<tr>
<td><strong>中位数</strong></td>
<td><strong>215 秒</strong> ≈ <strong>3.6 分钟</strong></td>
<td>一半请求在 3.6 分钟内完成。</td>
</tr>
<tr>
<td><strong>95% 用户</strong></td>
<td><strong>361 秒</strong> ≈ <strong>6 分钟</strong></td>
<td>最慢的 5% 要等 6 分钟以上。</td>
</tr>
<tr>
<td><strong>吞吐量</strong></td>
<td><strong>0.18 req/s</strong></td>
<td>这台 MinerU <strong>每分钟只能处理约11 个 PDF</strong>。</td>
</tr>
</tbody>
</table>
<h3 id="分块阶段">分块阶段</h3>
<p>当前主流的分块方式共五种：固定长度分块，语义分块，递归分块，文档结构分块，llm分块。</p>
<p>最后项目我选择了递归分块，原因如下：</p>
<ol type="1">
<li>mineru无法正确提取md文档结构，因此我舍弃了文档结构分块</li>
<li>测试了agentic
chunk（其主要思想是，先进行初步分段，按照长度或递归，然后让大模型生成这一段的概要，将段与段合并生成块），但是测试下来，我们这个一个文档的内容同质化很严重，基本上都分到一块里了，我猜测语义分块也是这种效果，因此舍弃</li>
<li>我们的文档中存在大量表格，我在预处理阶段增加了对表格的首尾标记，使用递归分块可以更好的保留这些结构</li>
</ol>
<h3 id="检索阶段">检索阶段</h3>
<p>基于langchain_elasticsearch完成了向量搜索，bm25，混合检索，模糊检索的检索函数的编写。</p>
<p>结果如下：</p>
<ol type="1">
<li>混合检索elasticsearch需要付费使用</li>
<li>bm25的多字段搜索有三种模式且字段的权重可以调整，后续评估时调整进行测试</li>
<li>检索的效果需要后续进行rag评估时判定</li>
</ol>
<h3 id="elasticsearch相关">elasticsearch相关</h3>
<p>完成对项目es模块的熟悉阅读；实现对elasticsearch的连接与字段的构建与存入。</p>
<p>关于字段的存储，我选取了report_name，report_url，page_content</p>
<h4 id="相关细节">相关细节</h4>
<h5 id="阅读elasticsearch代码相关记录"><strong>阅读elasticsearch代码相关记录:</strong></h5>
<ol type="1">
<li><strong>embedding_model</strong>.select_embeddings_model:根据指定的模型名称加载</li>
<li><strong>make_es_vector_store</strong>：
<ol type="1">
<li>docs_url =
pd.read_excel(‘docs_new.xlsx’)，从excel加载url并进行数据处理，保存筛选后的ur</li>
<li>完成文件加载测试：xizhang/retrival/docfile_test/test.py；</li>
<li>初始化es，使用elastic_search.load_es_index加载存储索引</li>
<li>完成测试elasticsearch连接与索引构建（索引名zxj_test）：/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_es_connect.py，/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_add_es.py</li>
<li>顺序批量处理文件：共16000多份，每十份为一批进行处理，使用download_pdf.py进行文件下载，使用，使用vector_base.rewrite_file对文件进行处理，这里可以修改代码，增加对mineru处理pdf的markdown文件的处理，返回Document对象列表；</li>
</ol></li>
<li><strong>elastic_search</strong></li>
</ol>
<p>重写了检索策略的函数，包括BM25，KNN，混合搜索</p>
<ol type="1">
<li><p>elastic_retriever创建Elasticsearch检索器：根据搜索类型选择对应的查询函数，创建Elasticsearch检索器ElasticsearchRetriever.from_es_params</p></li>
<li><p><strong>retrievers</strong></p>
<ol type="1">
<li>定义函数select_retriever，根据指定的名称选择并返回相应的检索器，目前只有bm25</li>
</ol></li>
</ol>
<h5 id="文档结构">文档结构</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">doc = Document(</span><br><span class="line">            page_content=text_content,</span><br><span class="line">            metadata=&#123;</span><br><span class="line">                &quot;report_name&quot;: folder_name,</span><br><span class="line">                &quot;report_url&quot;: report_url,</span><br><span class="line">                &quot;chunk_id&quot;: chunk_id</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h3 id="rag评估">rag评估</h3>
<p>待补充</p>
<h3 id="后续优化思考">后续优化思考</h3>
<ol type="1">
<li>重排序部分我没有做过，不知道怎么做，也不知道效果会怎样（我感觉在我们这个场景应该提升有限，听你说也是这样）</li>
<li>如何存入数据库的部分，可能也是优化的点，比如可以尝试agentic
rag这种，在存入数据库前再进行一步处理</li>
<li>还有一个点我比较好奇，我们项目在召回后是如何处理的，就是上下文拼接吗</li>
</ol>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习大作业</title>
    <url>/2025/11/24/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/</url>
    <content><![CDATA[<h1 id="mmgraphrag">MMGraphRAG</h1>
<h2 id="流程说明">流程说明：</h2>
<figure>
<img src="/2025/11/24/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/image-20251211192220984.png" alt="image-20251211192220984">
<figcaption aria-hidden="true">image-20251211192220984</figcaption>
</figure>
<h3 id="索引阶段-indexing"><strong>索引阶段 (Indexing)</strong></h3>
<p>◦ <strong>目标：</strong>
将原始的多模态数据（文本和图像）转化为结构化的多模态知识图谱（MMKG）。</p>
<p>◦ <strong>Text2Graph：</strong>
对文本输入进行分块并提取实体，构建<strong>文本知识图谱 (Text-based
KG)</strong>。</p>
<p>◦ <strong>Image2Graph：</strong> 图像通过<strong>场景图 (scene
graphs)</strong> 精炼视觉内容。这包括使用 YOLOv8
进行语义分割、使用多模态大语言模型（MLLM）生成特征块描述、提取实体和关系（包括显式和隐式关系），并构建描述整个图像的<strong>全局实体</strong>。从而构建<strong>图像知识图谱
(Image-based KG)</strong>。</p>
<p>◦ <strong>跨模态知识融合 (Cross-Modal Knowledge Fusion)：</strong>
这是核心步骤，通过<strong>跨模态实体链接 (CMEL)</strong> 将文本 KG
和图像 KG 融合。</p>
<p>​ ▪ 论文采用了<strong>基于谱聚类 (Spectral Clustering)</strong>
的优化策略来高效地生成候选实体对，该方法结合了实体间的语义和结构信息，从而增强了
CMEL 任务的准确性。</p>
<p>​ ▪
融合步骤还包括：对未对齐的图像实体进行描述增强，以及对全局图像实体进行对齐。</p>
<p>◦ <strong>输出：</strong> <strong>多模态知识图谱
(MMKG)</strong>。该框架采用<strong>基于节点的 MMKG (N-MMKG)</strong>
范式，将图像视为独立的节点，以保留更丰富的语义信息和可扩展性。</p>
<h3 id="检索阶段-retrieval"><strong>检索阶段 (Retrieval)</strong></h3>
<p>◦ <strong>目标：</strong> 根据用户查询，在 MMKG
中提取相关知识线索。</p>
<p>◦ <strong>混合粒度检索 (Hybrid Granularity Retriever)：</strong>
检索模块沿着 MMKG
中的<strong>多模态推理路径</strong>，提取相关的实体、关系和上下文信息。</p>
<h3 id="生成阶段-generation"><strong>生成阶段 (Generation)</strong></h3>
<p>◦ <strong>目标：</strong> 整合检索到的多模态线索，生成最终答案。</p>
<p>◦ <strong>混合生成策略 (Hybrid Generation Strategy)：</strong></p>
<p>​ ▪ 首先，<strong>大型语言模型 (LLM)</strong> 生成初步的文本响应。</p>
<p>​ ▪ 随后，<strong>多模态大语言模型 (MLLM)</strong>
基于视觉和文本信息生成多个多模态响应。</p>
<p>​ ▪ 最后，LLM 将这些响应整合并增强，输出一个统一且连贯的最终答案。</p>
<h2 id="概念解析">概念解析</h2>
<h3 id="场景图scene-graphs">场景图（Scene Graphs）</h3>
<p><strong>场景图</strong>是 MMGraphRAG
框架在<strong>索引阶段</strong>用于处理视觉信息的核心工具,d。</p>
<p>• <strong>定义和作用：</strong>
场景图用于<strong>精炼视觉内容</strong>，将图像信息转化为实体和关系。通过构建场景图，MMGraphRAG
能够将原始视觉输入转换为结构化的<strong>图像知识图谱（Image-based
KG）</strong>,。</p>
<p>• <strong>结构和信息捕获：</strong>
传统的场景图方法通常会忽略细粒度的语义细节和物体之间隐藏的信息，导致在下游推理任务中产生偏差。相比之下，MMGraphRAG
采用基于<strong>多模态大语言模型（MLLM）</strong>的方法来生成场景图。这种方法能够：</p>
<p>◦ 通过语义分割和 MLLM
的推理能力提取实体并推断出<strong>显式关系</strong>（例如：“女孩”——“拿着相机”——“相机”）和<strong>隐式关系</strong>（例如：“男孩”——“男孩和女孩看起来很亲密，可能是朋友或情侣”——“女孩”）,。</p>
<p>◦
为视觉实体提供更丰富的语义描述，例如将基本的标签“男孩”细化为更详细的表达，如“眼睛疲惫的大学生”。</p>
<p>• <strong>构建过程：</strong> 在 MMGraphRAG 的 <code>Img2Graph</code>
模块中，场景图的构建流程包括图像语义分割、为每个特征块生成文本描述、提取实体和关系，以及构建描述整个图像的<strong>全局实体</strong>,。</p>
<h3 id="跨模态实体链接cross-modal-entity-linking-cmel">跨模态实体链接（Cross-Modal
Entity Linking, CMEL）</h3>
<p><strong>CMEL</strong> 是实现跨模态融合和构建统一 MMKG
的<strong>关键组成部分</strong>。</p>
<p>• <strong>定义：</strong> CMEL
的目标是<strong>对齐从图像和文本中提取的实体</strong>，即识别指代同一现实世界概念的图像实体和文本实体对,。</p>
<p>• <strong>在 MMGraphRAG 中的作用：</strong>
它是<strong>跨模态融合模块</strong>的第一步，也是最关键的一步。它负责在<strong>文本知识图谱（Text-based
KG）</strong>和<strong>图像知识图谱（Image-based
KG）</strong>之间建立连接。</p>
<p>• <strong>与传统方法的区别：</strong></p>
<p>◦
<strong>传统实体链接（EL）</strong>：仅将文本实体与知识库中的对应条目关联，忽略非文本信息。</p>
<p>◦
<strong>多模态实体链接（MEL）</strong>：将视觉信息作为辅助属性来增强实体与知识库条目之间的对齐，但无法建立超出这些辅助关联的<strong>跨模态关系</strong>,。</p>
<p>◦
<strong>CMEL</strong>：更进一步，它将视觉内容视为独立的实体，并将这些<strong>视觉实体</strong>与其<strong>文本对应物</strong>对齐，从而构建
MMKG 并促进<strong>显式的跨模态推理</strong>。</p>
<h3 id="基于谱聚类spectral-clustering-based的方法">基于谱聚类（Spectral
Clustering-Based）的方法</h3>
<p>基于谱聚类的方法是 MMGraphRAG 针对 <strong>CMEL
任务</strong>中<strong>候选实体生成</strong>这一挑战提出的优化策略,。</p>
<p>• <strong>目标：</strong> 在 CMEL
任务中，由于文本实体数量通常大于视觉实体，需要高效且鲁棒地为每个视觉实体生成一组<strong>候选文本实体</strong>,。</p>
<p>• <strong>优势：</strong> 现有的聚类方法（如
KMeans、DBSCAN）依赖语义相似性，但忽略图结构；而图聚类方法（如
PageRank、Leiden）关注结构关系，但在稀疏图上表现不佳。<strong>基于谱聚类</strong>的方法解决了这两个方面的问题，它<strong>同时捕获实体间的语义信息和结构信息</strong>,。</p>
<p>• <strong>具体实现：</strong></p>
<p>◦ 该方法通过重新设计<strong>加权邻接矩阵</strong> <em>A</em>
和<strong>度矩阵</strong> <em>D</em> 来实现语义和结构的整合。</p>
<p>◦ <strong>邻接矩阵</strong> <em>A</em>
的构建同时反映了节点间的<strong>余弦相似性</strong>（语义信息）和它们之间关系的<strong>重要性</strong>（结构信息），其中关系的重要性由
LLM 评估。</p>
<p>◦ <strong>度矩阵</strong> <em>D</em>
的对角线值表示节点与其所有其他节点之间的<strong>总加权相似度</strong>。</p>
<p>◦
随后，遵循标准的谱聚类步骤，构建拉普拉斯矩阵并进行特征分解，然后利用
DBSCAN 在特征向量空间（矩阵 <em>Q</em>
的行空间）上进行聚类，从而获得簇划分,。</p>
<p>• <strong>效果：</strong> 实验结果显示，该方法在 CMEL
任务上的表现显著优于其他聚类和嵌入方法，将微观准确率提高了约
15%，宏观准确率提高了约 30%。</p>
<h3 id="混合粒度检索hybrid-granularity-retrieval">混合粒度检索（Hybrid
Granularity Retrieval）</h3>
<p><strong>混合粒度检索</strong>是 MMGraphRAG
<strong>检索阶段</strong>的核心功能,。</p>
<p>• <strong>定义：</strong>
在接收到用户查询后，检索模块在构建好的<strong>多模态知识图谱（MMKG）</strong>内部执行检索。</p>
<p>• <strong>检索内容：</strong>
这种检索方式会提取不同粒度的相关信息，包括<strong>实体（Entities）</strong>、<strong>关系（Relationships）</strong>
<strong>上下文信息/文本块（Contextual Information/Text
Chunks）</strong>,。</p>
<p>• <strong>机制：</strong> 检索是沿着 MMKG
内的<strong>多模态推理路径</strong>进行的,。由于 MMKG
将图像建模为独立的节点，并明确地链接了视觉和文本实体，这种结构化的检索（基于推理路径）能够比传统的基于嵌入相似度的检索（如
NaiveRAG）<strong>更精确地检索出与问题相关的视觉内容</strong>，并支持复杂的跨模态推理,,。检索结果随后用于指导生成过程,。</p>
<h2 id="核心贡献">核心贡献</h2>
<p>论文的<strong>三个主要核心贡献</strong>如下：</p>
<h3 id="提出首个基于知识图谱的多模态-rag-框架-mmgraphrag">提出首个基于知识图谱的多模态
RAG 框架 (MMGraphRAG)</h3>
<p>MMGraphRAG 是<strong>第一个基于知识图谱（KG）的多模态 RAG
框架</strong>。它旨在实现深度跨模态融合和推理，其设计具有强大的可扩展性和适应性。</p>
<p>A. 创新性的索引阶段（构建 MMKG）</p>
<p>MMGraphRAG
的核心在于其索引阶段，它将原始的多模态数据（文本和图像）转化为统一的<strong>多模态知识图谱
(MMKG)</strong>。</p>
<p>• <strong>视觉内容精炼：</strong>
图像信息首先通过<strong>场景图（Scene Graphs）</strong>
<strong>显式和隐式关系</strong>，从而生成高精度和细粒度的场景图，将原始视觉输入转化为<strong>图像知识图谱</strong>。</p>
<p>• <strong>MMKG 范式：</strong> 论文采用了<strong>基于节点的
MMKG（Node-based MMKG,
N-MMKG）</strong>范式。在这种范式中，图像被视为独立的节点，而非仅仅是文本实体的属性（Attribute-MMKG,
A-MMKG）。这种设计避免了将视觉数据存储为属性时带来的信息损失，保留了更丰富的语义信息，并显着增强了跨模态推理能力和图的灵活性与可扩展性。</p>
<p>B. 结构化检索与生成</p>
<p>• <strong>检索：</strong> 检索模块在 MMKG
内部沿着<strong>多模态推理路径</strong>执行<strong>混合粒度检索</strong>，从而提取相关的实体、关系和上下文信息，以指导生成过程。</p>
<p>• <strong>混合生成策略：</strong> 生成阶段采用混合策略，首先由
<strong>LLM</strong> 生成初步的文本响应，然后由 <strong>MLLM</strong>
根据视觉和文本信息生成多模态响应。最后，LLM
将两者整合为一个统一且连贯的最终答案。这种方法有效缓解了当前 MLLM
在推理上的限制，确保了高质量、上下文适当的响应。</p>
<h3 id="跨模态实体链接cmel的创新方法和基准数据集">跨模态实体链接（CMEL）的创新方法和基准数据集</h3>
<p>为解决构建 MMKG 中<strong>跨模态实体对齐</strong>的关键挑战，论文在
CMEL 任务上做出了重要贡献。</p>
<p>A. 提出基于谱聚类的 CMEL 优化策略</p>
<p>• <strong>挑战：</strong>
准确地为每个视觉实体从文本实体池中生成一组候选实体对，是一个高效且鲁棒性的挑战。</p>
<p>• <strong>解决方案：</strong>
论文设计了<strong>基于谱聚类的优化策略</strong>，用于高效生成候选实体。这种方法通过重新设计邻接矩阵
<em>A</em> 和度矩阵
<em>D</em>，<strong>同时捕获实体间的语义信息和结构信息</strong>。这极大地增强了
CMEL 任务的准确性，实验结果表明其在微观准确率上提升了约
15%，在宏观准确率上提升了约 30%，显著优于其他聚类和嵌入方法。</p>
<p>B. 构建并发布 CMEL 数据集</p>
<p>• <strong>目的：</strong>
为了解决该领域<strong>缺乏统一基准评估</strong>的问题。</p>
<p>• <strong>内容：</strong> 构建并发布了 <strong>CMEL
数据集</strong>，这是一个专门针对<strong>细粒度多实体对齐</strong>设计的新型基准，其在实体多样性和关系复杂性上都高于现有基准。该数据集包含来自<strong>新闻、学术和小说</strong>三个不同领域的文档，总共提供了
<strong>1,114 个对齐实例</strong>。</p>
<h3 id="实验验证实现最先进性能和高鲁棒性">实验验证：实现最先进性能和高鲁棒性</h3>
<p>MMGraphRAG
框架在多模态文档问答（DocQA）任务上进行了全面的评估，验证了其优势：</p>
<p>• <strong>达到 SOTA 性能：</strong> MMGraphRAG 在
<strong>DocBench</strong> 和 <strong>MMLongBench</strong> 这两个多模态
DocQA 基准数据集上均取得了<strong>最先进的性能</strong>，显着优于现有的
RAG 基线方法（包括 LLM、MLLM、NaiveRAG 和 GraphRAG）。</p>
<p>• <strong>跨域适应性：</strong> MMGraphRAG
表现出<strong>强大的跨领域适应性</strong>，尤其在具有高视觉结构复杂性的领域（如<strong>学术</strong>和<strong>金融</strong>）中，相比于纯文本的
RAG 方法有实质性提升。</p>
<p>• <strong>处理“不可回答”问题的优势：</strong>
该框架在处理<strong>不可回答（Unanswerable,
Una.）</strong>的问题时显示出明显的优势。由于其通过 MMKG
进行结构化推理，MMGraphRAG
能够更可靠地评估问题是否可答，从而减少生成误导性答案，增强了在真实世界场景中的鲁棒性。</p>
<p>• <strong>提供可解释性：</strong>
该框架通过<strong>可追溯的推理路径</strong>来指导多模态推理</p>
<h2 id="相关工作-related-work"><strong>相关工作 (Related
Work)</strong></h2>
<h3 id="graphrag">GraphRAG</h3>
<p><strong>多模态 GraphRAG 的尝试：</strong> 针对多模态数据，HM-RAG
提出了一个分层多智能体多模态 RAG
框架。该框架通过协调分解智能体、多源检索智能体和决策智能体，从结构化、非结构化和基于图的数据中动态地合成知识。</p>
<p>• <strong>HM-RAG 的不足：</strong> 尽管 HM-RAG
在多模态处理方面有所进步，但它<strong>仍然依赖于通过多模态大语言模型（MLLMs）将多模态内容转换为文本</strong>，<strong>未能充分捕获跨模态关系</strong>，从而导致逻辑链不完整</p>
<h3 id="实体链接-entity-linking">实体链接 (Entity Linking</h3>
<p>• <strong>传统实体链接（EL）：</strong> 传统 EL
方法将文本实体与其在知识库中的对应条目关联起来，但<strong>忽略了非文本信息</strong>。</p>
<p>• <strong>多模态实体链接（MEL）：</strong> MEL 扩展了
EL，它将视觉信息作为<strong>辅助属性</strong>纳入进来，以增强实体与知识库条目之间的对齐。</p>
<p>• <strong>MEL 的局限性：</strong> 然而，MEL
<strong>并未在这些辅助关联之外建立跨模态关系</strong>，从而限制了真正的跨模态交互。</p>
<p>• <strong>跨模态实体链接（CMEL）：</strong> CMEL
更进一步，它将<strong>视觉内容视为实体</strong>，并将这些视觉实体与其<strong>文本对应物</strong>进行对齐，从而构建<strong>多模态知识图谱（MMKGs）</strong>，并促进<strong>显式的跨模态推理</strong>。</p>
<p>• <strong>CMEL 研究现状与挑战：</strong> 当前，CMEL
领域的研究仍处于早期阶段，<strong>缺乏统一的理论框架和可靠的评估协议</strong>。例如，MATE
基准用于评估 CMEL 性能，但其合成的 3D
场景<strong>未能捕捉现实世界图像的复杂性和多样性</strong>。</p>
<p><strong>MMGraphRAG 对 CMEL 的贡献：</strong></p>
<p>• 为了弥补这一差距，MMGraphRAG
<strong>构建了一个具有更高现实世界复杂性的 CMEL 数据集</strong>。</p>
<p>• 同时，MMGraphRAG
提出了<strong>基于谱聚类的方法</strong>用于候选实体生成，旨在推动 CMEL
研究的进一步发展。</p>
<h2 id="image2graph-模块"><strong>Image2Graph 模块</strong></h2>
<p>Img2Graph 模块通过一个五步流程将图像映射为知识图谱：</p>
<h3 id="图像分割-image-segmentation"><strong>图像分割 (Image
Segmentation)：</strong></h3>
<p>◦ 这是第一步，使用 YOLOv8
等工具执行语义分割，将图像划分为具有独立语义意义的区域，这些区域被称为<strong>图像特征块（image
feature blocks）</strong>,。</p>
<p>◦ 分割的粒度会显著影响知识图谱中边缘描绘的精度。</p>
<h3 id="图像特征块描述-image-feature-block-description"><strong>图像特征块描述
(Image Feature Block Description)：</strong></h3>
<p>◦ 接下来，使用 MLLM
为每个分割后的特征块生成<strong>文本描述</strong>。</p>
<p>◦
这些描述不仅为图像模态构建了独立的实体，也为后续与文本模态的对齐提供了桥梁。模型会根据特征块的类别（物体、生物或人物）来生成详细描述，例如描述人物的性别、发型、衣着和姿势等,。</p>
<h3 id="实体和关系提取-entity-and-relation-extraction"><strong>实体和关系提取
(Entity and Relation Extraction)：</strong></h3>
<p>◦ 此步骤利用 MLLM
识别图像中的<strong>显式关系</strong>和<strong>隐式关系</strong>，并提取实体。</p>
<p>◦ 这些提取出的实体和关系为知识图谱的多模态扩展提供了结构化信息。</p>
<h3 id="图像特征块与实体的对齐-alignment-of-image-feature-blocks-with-entities"><strong>图像特征块与实体的对齐
(Alignment of Image Feature Blocks with Entities)：</strong></h3>
<p>◦ 通过 MLLM
的识别和推理能力，将分割生成的特征块与它们对应的<strong>视觉实体</strong>进行对齐,。</p>
<p>◦ 例如，将“特征块
2”识别为“男孩”的图像，并在知识图谱中建立关系，这加强了模态间的关联。</p>
<h3 id="全局实体构建-global-entity-construction"><strong>全局实体构建
(Global Entity Construction)：</strong></h3>
<p>◦
最后，为整个图像构建一个<strong>全局实体</strong>，作为知识图谱中的全局节点。</p>
<p>◦
该全局节点提供对图像整体信息的补充描述（例如：“在桥上相遇”），并通过与局部实体的连接，增强了知识图谱的完整性。</p>
<figure>
<img src="/2025/11/24/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E4%BD%9C%E4%B8%9A/image-20251212102050866.png" alt="image-20251212102050866">
<figcaption aria-hidden="true">image-20251212102050866</figcaption>
</figure>
<h2 id="基于谱聚类的候选实体生成spectral-clustering-based-candidate-generation">基于谱聚类的候选实体生成（Spectral
Clustering-Based Candidate Generation）</h2>
<p><strong>CMEL
的目标</strong>是识别指代同一现实世界概念的图像实体和文本实体对。<strong>由于文本实体的数量通常大于视觉实体</strong>，CMEL
任务被分解为两个阶段：</p>
<ol type="1">
<li>为每个视觉实体生成一组候选文本实体，以及 (2)
从该集合中选择最佳对齐的文本实体。</li>
</ol>
<h3 id="阶段一候选实体的生成">阶段一：候选实体的生成</h3>
<p>基于谱聚类的方法主要解决了第一个阶段，即候选实体的生成。</p>
<p><strong>方法创新</strong></p>
<p>现有的候选实体生成方法存在局限性：</p>
<ol type="1">
<li><strong>基于距离的聚类方法</strong>（如 KMeans 和
DBSCAN）依赖语义相似性，但忽略了图结构。</li>
<li><strong>基于图的聚类方法</strong>（如 PageRank 和
Leiden）捕获结构关系，但在稀疏图上效果不佳。</li>
</ol>
<p>为了解决这些问题，MMGraphRAG 提出了一种专门为 CMEL
定制的谱聚类算法，该算法能够同时捕获实体之间的<strong>语义信息和结构信息</strong>。</p>
<p><strong>核心机制</strong></p>
<p>该方法重新设计了<strong>加权邻接矩阵 A</strong> 和 <strong>度矩阵
D</strong>，以融合语义和结构信息:</p>
<ol type="1">
<li><strong>邻接矩阵 A 的构建：</strong> 矩阵 A
反映了节点之间的相似性以及它们之间关系的<strong>重要性</strong>。
<ul>
<li>其定义为 <span class="math inline"><em>A</em><sub><em>p</em><em>q</em></sub> = <em>s</em><em>i</em><em>m</em>(<em>v</em><sub><em>p</em></sub>, <em>v</em><sub><em>q</em></sub>) ⋅ <em>w</em><em>e</em><em>i</em><em>g</em><em>h</em><em>t</em>(<em>r</em><sub><em>p</em><em>q</em></sub>)</span>。</li>
<li>其中，<span class="math inline"><em>v</em><sub><em>p</em></sub></span> 是实体 <span class="math inline"><em>e</em><sub><em>p</em></sub></span>
的嵌入向量，<span class="math inline"><em>s</em><em>i</em><em>m</em>(⋅)</span>
表示余弦相似度。</li>
<li><span class="math inline"><em>w</em><em>e</em><em>i</em><em>g</em><em>h</em><em>t</em>(<em>r</em><sub><em>p</em><em>q</em></sub>)</span>
是由大型语言模型（LLM）评估的关系 <span class="math inline"><em>r</em><sub><em>p</em><em>q</em></sub></span>
的重要性标量（如果两个实体之间没有关系，则权重设置为 1）。</li>
</ul></li>
<li><strong>度矩阵 D 的构建：</strong> D
是一个对角矩阵，对角线上的每个值 <span class="math inline"><em>D</em><sub><em>p</em><em>p</em></sub></span>
表示节点 <span class="math inline"><em>p</em></span>
的总加权连接强度，即节点 <span class="math inline"><em>p</em></span>
与所有其他节点之间总的加权相似度。</li>
</ol>
<p>随后，按照标准的谱聚类步骤，构建拉普拉斯矩阵并执行特征分解。利用最小的
<span class="math inline"><em>m</em></span> 个特征向量形成矩阵 <span class="math inline"><em>Q</em></span>。</p>
<p><strong>候选实体生成</strong></p>
<p>最后，在矩阵 <span class="math inline"><em>Q</em></span>
的行空间上使用 <strong>DBSCAN</strong> 进行聚类，得到簇划分 <span class="math inline"><em>C</em><sub>1</sub>, <em>C</em><sub>2</sub>, …, <em>C</em><sub><em>n</em></sub></span>。对于每个视觉实体
<span class="math inline"><em>e</em><sub><em>k</em></sub><sup>(<em>I</em><sub><em>i</em></sub>)</sup></span>，算法会根据其嵌入向量
<span class="math inline"><em>v</em><sub><em>k</em></sub><sup>(<em>I</em><sub><em>i</em></sub>)</sup></span>
与簇成员之间的<strong>余弦相似度</strong>来选择最相关的簇。该簇中的所有实体构成了最终的候选实体集
<span class="math inline"><em>C</em>(<em>e</em><sub><em>k</em></sub><sup>(<em>I</em><sub><em>i</em></sub>)</sup>)</span>。</p>
<blockquote>
<h3 id="场景设定">0. 场景设定</h3>
<ul>
<li><strong>输入（视觉实体）</strong>：一张<strong>红富士苹果</strong>的照片
<span class="math inline"><em>e</em><sub><em>i</em><em>m</em><em>g</em></sub></span>。</li>
<li><strong>数据库（文本实体池）</strong>：我们有 5
个文本实体（节点），它们都包含“Apple”或相关概念，导致传统方法容易混淆。
<ol type="1">
<li><strong><span class="math inline"><em>T</em><sub>1</sub></span></strong>: “Fresh Fuji
Apple”（新鲜红富士苹果 - <strong>水果</strong>）</li>
<li><strong><span class="math inline"><em>T</em><sub>2</sub></span></strong>: “Red
Delicious Apple”（红蛇果 - <strong>水果</strong>）</li>
<li><strong><span class="math inline"><em>T</em><sub>3</sub></span></strong>: “Apple
iPhone 15”（苹果手机 - <strong>科技</strong>）</li>
<li><strong><span class="math inline"><em>T</em><sub>4</sub></span></strong>: “Apple
MacBook Pro”（苹果电脑 - <strong>科技</strong>）</li>
<li><strong><span class="math inline"><em>T</em><sub>5</sub></span></strong>: “Banana and
Fruit Salad”（香蕉水果沙拉 - <strong>水果</strong>，但没有 Apple
这个词）</li>
</ol></li>
</ul>
<hr>
<h3 id="第一步构建邻接矩阵-a-融合语义与-llm">第一步：构建邻接矩阵 A
(融合语义与 LLM)</h3>
<p>我们需要计算每两个文本实体之间的“亲密度”。公式是 <span class="math inline"><em>A</em><sub><em>p</em><em>q</em></sub> = sim(<em>v</em><sub><em>p</em></sub>, <em>v</em><sub><em>q</em></sub>) ⋅ weight(<em>r</em><sub><em>p</em><em>q</em></sub>)</span>。</p>
<ol type="1">
<li>语义相似度 (Sim)</li>
</ol>
<p>假设我们计算出 <span class="math inline"><em>T</em><sub>1</sub></span> (“Fresh Fuji Apple”)
与其他词的向量相似度：</p>
<ul>
<li>与 <span class="math inline"><em>T</em><sub>2</sub></span> (“Red
Delicious”): <strong>0.9</strong> (都很像)</li>
<li>与 <span class="math inline"><em>T</em><sub>3</sub></span> (“Apple
iPhone”): <strong>0.7</strong> (因为都有单词
“Apple”，向量空间里靠得较近，<strong>这是传统方法的陷阱</strong>)</li>
<li>与 <span class="math inline"><em>T</em><sub>5</sub></span>
(“Banana…”): <strong>0.5</strong> (属于水果，但词不一样)</li>
<li>LLM 权重 (Weight)</li>
</ul>
<p>这里 MMGraphRAG 的核心创新来了。我们问 LLM：“‘新鲜红富士’和‘iPhone
15’在现实世界中关系紧密吗？”</p>
<ul>
<li>LLM 答：关系很弱，它们属于不同领域。<span class="math inline"> → Weight = <strong>0.1</strong></span></li>
<li>LLM 答：‘新鲜红富士’和‘红蛇果’都是水果。<span class="math inline"> → Weight = <strong>1.0</strong></span></li>
<li>计算最终矩阵 A</li>
</ul>
<p>让我们看看 <span class="math inline"><em>T</em><sub>1</sub></span> 和
<span class="math inline"><em>T</em><sub>3</sub></span>
的连接发生了什么变化：</p>
<ul>
<li><strong><span class="math inline"><em>T</em><sub>1</sub></span> vs
<span class="math inline"><em>T</em><sub>2</sub></span> (水果 vs
水果)</strong>: <span class="math inline">0.9(Sim) × 1.0(LLM) = <strong>0.9</strong></span>
(强连接)</li>
<li><strong><span class="math inline"><em>T</em><sub>1</sub></span> vs
<span class="math inline"><em>T</em><sub>3</sub></span> (水果 vs
科技)</strong>: <span class="math inline">0.7(Sim) × 0.1(LLM) = <strong>0.07</strong></span>
(连接被切断！)</li>
</ul>
<blockquote>
<p><strong>关键点</strong>：LLM
成功把“水果苹果”和“科技苹果”原本虚高的相似度<strong>打压</strong>下去了。</p>
</blockquote>
<hr>
<h3 id="第二步构建度矩阵-d">第二步：构建度矩阵 D</h3>
<p>计算每个节点与其他所有节点的总连接强度。</p>
<ul>
<li><strong><span class="math inline"><em>T</em><sub>1</sub></span>
(Fuji Apple)</strong>: 连接 <span class="math inline"><em>T</em><sub>2</sub></span> (0.9) + 连接 <span class="math inline"><em>T</em><sub>5</sub></span> (0.4) + 连接 <span class="math inline"><em>T</em><sub>3</sub></span> (0.07)… <span class="math inline">≈</span> <strong>1.4</strong></li>
<li><strong><span class="math inline"><em>T</em><sub>3</sub></span>
(iPhone)</strong>: 连接 <span class="math inline"><em>T</em><sub>4</sub></span> (MacBook, 强连接 0.9)
+ 连接 <span class="math inline"><em>T</em><sub>1</sub></span> (0.07)…
<span class="math inline">≈</span> <strong>1.0</strong></li>
</ul>
<p>这反映了节点在各自簇内的“人缘”。</p>
<hr>
<h3 id="第三步谱变换与特征分解-生成矩阵-q">第三步：谱变换与特征分解
(生成矩阵 Q)</h3>
<p>构建拉普拉斯矩阵并分解后，我们将这 5
个文本实体映射到一个<strong>新的坐标系</strong>（比如 2D 平面）。</p>
<p>在这个新空间里，因为我们在第一步切断了“水果”和“科技”的强联系：</p>
<ul>
<li><span class="math inline"><em>T</em><sub>1</sub>, <em>T</em><sub>2</sub>, <em>T</em><sub>5</sub></span>
会紧紧聚在坐标系左下角。</li>
<li><span class="math inline"><em>T</em><sub>3</sub>, <em>T</em><sub>4</sub></span>
会紧紧聚在坐标系右上角。</li>
<li>它们之间的距离被拉得非常大，不再是原来混在一起的状态。</li>
</ul>
<hr>
<h3 id="第四步dbscan-聚类">第四步：DBSCAN 聚类</h3>
<p>在矩阵 Q 的坐标系上运行 DBSCAN。</p>
<ul>
<li><strong>输入</strong>：上述分散的坐标点。</li>
<li><strong>过程</strong>：
<ol type="1">
<li>DBSCAN 发现 <span class="math inline"><em>T</em><sub>1</sub>, <em>T</em><sub>2</sub>, <em>T</em><sub>5</sub></span>
密度很高，划分为 <strong>簇 C1 (水果簇)</strong>。</li>
<li>DBSCAN 发现 <span class="math inline"><em>T</em><sub>3</sub>, <em>T</em><sub>4</sub></span>
密度很高，划分为 <strong>簇 C2 (科技簇)</strong>。</li>
<li>如果有一个 <span class="math inline"><em>T</em><sub>6</sub></span>
“SpaceX Rocket”，它离谁都远，DBSCAN 可能会把它标记为噪声并扔掉（优于
K-Means 的点）。</li>
</ol></li>
</ul>
<hr>
<h3 id="第五步候选实体生成-匹配图片">第五步：候选实体生成
(匹配图片)</h3>
<p>现在我们有了两个干净的候选池：</p>
<ul>
<li><span class="math inline"><em>C</em><sub>1</sub></span>: {Fuji
Apple, Red Delicious, Banana Salad}</li>
<li><span class="math inline"><em>C</em><sub>2</sub></span>: {iPhone 15,
MacBook Pro}</li>
</ul>
<p><strong>最终匹配：</strong></p>
<ol type="1">
<li>输入图片的向量 <span class="math inline"><em>v</em><sub>img</sub></span> (红富士照片)。</li>
<li>计算 <span class="math inline"><em>v</em><sub>img</sub></span> 与
<span class="math inline"><em>C</em><sub>1</sub></span>
中成员的平均相似度 <span class="math inline">→</span>
<strong>0.85</strong> (很高)。</li>
<li>计算 <span class="math inline"><em>v</em><sub>img</sub></span> 与
<span class="math inline"><em>C</em><sub>2</sub></span>
中成员的平均相似度 <span class="math inline">→</span>
<strong>0.15</strong> (很低)。</li>
</ol>
<p>输出结果：</p>
<p>算法选择 簇 C1 作为最终的候选集合。</p>
</blockquote>
<h3 id="阶段二从筛选出的候选集中确定最佳对齐结果">阶段二：从筛选出的候选集中确定最佳对齐结果</h3>
<ol type="1">
<li><strong>背景：</strong> 在 CMEL
任务中，第二阶段是从为每个视觉实体（visual
entity）生成的<strong>候选实体集</strong>中选出最匹配的文本实体。这个过程通过基于
LLM 的推理来实现，因为 LLM
在复杂的对齐场景中展示了高准确性和适应性。</li>
<li><strong>提示（Prompt）内容：</strong> 为了指导 LLM
完成实体对齐，向其提供的提示中包含以下关键信息：
<ul>
<li><strong>视觉实体的名称和描述（the name and description of the visual
entity）</strong>。</li>
<li><strong>来自所选簇的候选实体的描述（descriptions of candidate
entities from the selected
cluster）</strong>。这些候选实体是通过前一步骤的<strong>基于谱聚类的候选生成</strong>方法（Spec）得到的。</li>
<li><strong>一套固定的对齐示例（a fixed set of alignment
examples）</strong>，用于指导 LLM。</li>
</ul></li>
<li><strong>最终输出：</strong> LLM
基于上述提示内容进行推理判断后，其输出<strong>被采纳为最终的对齐结果（The
output is adopted as the final alignment result）</strong>。</li>
</ol>
<p>简而言之，这段文字是 <strong>MMGraphRAG
框架</strong>中<strong>跨模态知识融合模块（Cross-Modal Fusion
Module）*<em>执行 CMEL 任务时，利用 **LLM
进行最终实体对齐**的*</em>输入信息（Prompt）构成</strong>和<strong>结果决定</strong>的说明。</p>
<h2 id="cmel-cross-modal-entity-linking-数据集"><strong>CMEL
(Cross-Modal Entity Linking) 数据集</strong></h2>
<p>您提供的这段文字是对 <strong>CMEL (Cross-Modal Entity Linking)
数据集</strong>
的详细介绍，该数据集是为了解决跨模态实体链接任务中缺乏评估基准而专门构建和发布的。</p>
<p>以下是对这段内容的详细解释：</p>
<h3 id="cmel-数据集的构成和领域多样性">1. CMEL
数据集的构成和领域多样性</h3>
<p>CMEL
数据集是一个新颖的基准，专门用于评估复杂多模态场景下的细粒度<strong>跨实体对齐（cross-entity
alignment）</strong>任务。</p>
<ul>
<li><strong>数据来源和领域：</strong> CMEL
数据集包含来自三个不同领域的文件，确保了广泛的领域多样性和实际适用性：
<ul>
<li>新闻（news）</li>
<li>学术（academia）</li>
<li>小说（novels）</li>
</ul></li>
<li><strong>每个样本的内容：</strong>
数据集中的每个样本都包含三个核心组件：
<ul>
<li><strong>(i) 基于文本块构建的文本知识图谱（text-based KG built from
text chunks）</strong>。</li>
<li><strong>(ii) 源自每张图像的场景图的基于图像的知识图谱（image-based
KG derived from per-image scene graphs）</strong>。</li>
<li><strong>(iii) 原始 PDF 格式文档（the original PDF-format
document）</strong>。</li>
</ul></li>
<li><strong>对齐实例总数和分布：</strong> CMEL 数据集总共提供了
<strong>1,114 个对齐实例</strong>（alignment
instances）。这些实例按领域分布如下：
<ul>
<li>来自新闻文章的实例：87 个。</li>
<li>来自学术论文的实例：475 个。</li>
<li>来自小说的实例：552 个。</li>
</ul></li>
</ul>
<p>CMEL 数据集相比现有基准（如
MATE）具有更强的实体多样性和关系复杂性，并且支持通过半自动化流程进行扩展。</p>
<h3 id="评估指标evaluation-metrics">2. 评估指标（Evaluation
Metrics）</h3>
<p>为了全面评估跨模态实体链接（CMEL）的性能，该研究采用了两种不同的准确率指标：<strong>微观准确率（micro-accuracy）*<em>和*</em>宏观准确率（macro-accuracy）</strong>。</p>
<table>
<colgroup>
<col style="width: 20%">
<col style="width: 39%">
<col style="width: 39%">
</colgroup>
<thead>
<tr>
<th>指标</th>
<th>计算方式</th>
<th>目的/反映的性能</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>微观准确率 (Micro-accuracy)</strong></td>
<td><strong>按实体（per-entity）</strong>计算。即所有正确预测的实体数占总实体数的比例。</td>
<td>反映了整体预测的正确性，是<strong>全局性能</strong>的指标。</td>
</tr>
<tr>
<td><strong>宏观准确率 (Macro-accuracy)</strong></td>
<td><strong>按文档（per
document）</strong>计算平均准确率。即每个文档的准确率的平均值。</td>
<td>旨在<strong>减轻评估偏差</strong>，这种偏差由不同文档中实体分布不平衡引起。更好地突出了不同方法在<strong>不同领域</strong>的性能。</td>
</tr>
</tbody>
</table>
<h2 id="实验设置与结果experimental-setup-and-results">实验设置与结果（Experimental
Setup and Results）</h2>
<p>“实验设置与结果”（Experimental Setup and Results）部分详细介绍了
MMGraphRAG 框架的评估方法，主要分为两部分：针对 CMEL
任务的评估，以及针对多模态文档问答（DocQA）任务的整体框架性能评估。</p>
<h3 id="跨模态实体链接cmel实验设置与结果">1.
跨模态实体链接（CMEL）实验设置与结果</h3>
<p>CMEL 实验的目的是验证 MMGraphRAG
提出的<strong>基于谱聚类的候选实体生成方法（Spec）</strong>在复杂多模态场景下的有效性。</p>
<h4 id="实验设置">实验设置</h4>
<ul>
<li><p><strong>数据集：</strong> 实验基于新构建和发布的 <strong>CMEL
数据集</strong>，该数据集专为细粒度多实体对齐设计，包含来自<strong>新闻、学术和小说</strong>三个不同领域的
1,114 个对齐实例。</p></li>
<li><p><strong>评估指标：</strong> 采用<strong>微观准确率
(micro-accuracy)</strong> 和<strong>宏观准确率
(macro-accuracy)</strong>。</p>
<ul>
<li>微观准确率按实体计算，反映了<strong>整体预测的正确性</strong>（全局性能）。</li>
<li>宏观准确率按文档计算平均准确率，旨在<strong>减轻实体分布不平衡导致的评估偏差</strong>，并更好地突出方法在不同领域中的性能。</li>
</ul></li>
<li><p><strong>对比方法：</strong>
实验涵盖三类方法，并与主流聚类算法进行了全面比较：</p>
<ol type="1">
<li><strong>基于嵌入的方法 (Emb)：</strong> 使用预训练嵌入模型（如
stella-en-1.5B-v5），通过计算余弦相似度来确定候选实体。</li>
<li><strong>基于 LLM 的方法 (LLM)：</strong> 利用 LLM（如
Qwen2.5-72B-Instruct）直接基于上下文理解能力生成候选实体集。</li>
<li><strong>聚类基线：</strong> 包括 DBSCAN (DB)、KMeans (KM)、PageRank
(PR) 和 Leiden (Lei)。</li>
</ol>
<ul>
<li><strong>统一处理：</strong>
所有聚类方法和基线，其候选集内的最终实体对齐都是通过统一的基于 LLM
的推理完成的。</li>
</ul></li>
</ul>
<h4 id="关键实验结果cmel">关键实验结果（CMEL）</h4>
<ul>
<li><strong>聚类方法的优势：</strong> 总体而言，基于聚类的方法在 CMEL
任务中的表现显著优于基于嵌入和基于 LLM 的方法。</li>
<li><strong>Spec 性能最佳：</strong> MMGraphRAG 的<strong>基于谱聚类的
Spec 方法表现最佳</strong>。与其他聚类方法相比，Spec
将<strong>微观准确率提高了约 15%</strong>，<strong>宏观准确率提高了约
30%</strong>。</li>
<li><strong>具体结果（Table 1 所示最佳配置）：</strong> Spec
在整体微观/宏观准确率上达到了
<strong>65.5%/56.9%</strong>，明显优于排名第二的 Leiden
(54.8%/44.7%)。</li>
</ul>
<h3 id="多模态文档问答docqa实验设置与结果">2.
多模态文档问答（DocQA）实验设置与结果</h3>
<p>DocQA 实验用于评估 MMGraphRAG
框架在多模态信息集成、复杂推理和领域适应性方面的整体性能。</p>
<h4 id="实验设置-1">实验设置</h4>
<ul>
<li><strong>评估任务：</strong> 选择 DocQA
作为主要评估任务，因为它能全面评估方法在处理长文档、集成多样格式以及跨领域适应性的能力。</li>
<li><strong>基准数据集：</strong>
<ul>
<li><strong>DocBench：</strong> 包含 229 份 PDF
文档，涵盖<strong>学术、金融、政府、法律和新闻</strong>五个领域，问题类型包括纯文本
(Txt.)、多模态 (Mm.) 和不可回答 (Una.)。</li>
<li><strong>MMLongBench：</strong> 包含 135 份长 PDF
文档，证据格式包括文本 (Txt.)、图表/表格 (C.T.)、布局 (Lay.) 和图
(Fig.)。</li>
</ul></li>
<li><strong>评估基线：</strong>
<ul>
<li><strong>LLM：</strong> 通过 MLLM 将图像转换为文本后，输入 LLM（例如
Qwen2.5-72B-Instruct）。</li>
<li><strong>MLLM：</strong>
直接输入图像块和问题，评估其多模态推理能力（例如
InternVL2.5-38B-MPO）。</li>
<li><strong>NaiveRAG (NRAG)：</strong> 基于嵌入相似度的文本块检索。</li>
<li><strong>GraphRAG (GRAG)：</strong> 基于知识图谱的
RAG，使用局部模式查询。</li>
</ul></li>
</ul>
<h4 id="关键实验结果docqa">关键实验结果（DocQA）</h4>
<ul>
<li><strong>MMGraphRAG (MMGR) 表现：</strong> MMGraphRAG 在 DocBench 和
MMLongBench 数据集上都显著优于所有现有的 RAG 基线方法。
<ul>
<li>在 DocBench 上的总体准确率达到 <strong>60.5%</strong>（对比 NRAG 的
43.6% 和 GRAG 的 39.6%）。</li>
<li>在 MMLongBench 上的总体准确率达到 <strong>39.6%</strong>，F1
分数达到 <strong>34.1%</strong>（对比 NRAG 的 22.3%/20.9% 和 GRAG 的
18.2%/19.3%）。</li>
</ul></li>
<li><strong>多模态融合优势：</strong> MMGraphRAG
在多模态问题上的准确率（DocBench 上 MMGR 88.7%）显著高于
GraphRAG（26.0%），证明了跨模态融合对于复杂推理至关重要。</li>
<li><strong>跨领域适应性：</strong> 相比纯文本 RAG 方法，MMGraphRAG
在<strong>学术和金融</strong>等具有高视觉结构复杂性的领域获得了显著提升，表明其在专业领域中具有出色的适应性和泛化能力。</li>
<li><strong>不可回答问题处理：</strong> MMGraphRAG
在处理不可回答问题（Una.）时表现出明显优势。这归因于其通过 CMEL
实现完整和细粒度的跨模态信息交互，并在 MMKG
上进行结构化推理，从而更可靠地评估问题是否可回答，减少了误导性答案的生成。</li>
</ul>
<h2 id="docbench-数据集"><strong>DocBench 数据集</strong></h2>
<p>DocBench 数据集是 MMGraphRAG
框架在<strong>多模态文档问答（DocQA）任务</strong>中用于评估其整体性能的主要基准之一</p>
<p>以下是关于 DocBench 数据集的详细介绍：</p>
<h3 id="目的与作用">1. 目的与作用</h3>
<p>DocBench
的主要作用是作为一个<strong>综合性基准</strong>，用于评估<strong>基于大型语言模型的文档阅读系统</strong>（LLM-based
document reading systems）的性能,。</p>
<p>在 MMGraphRAG 的实验中，选择 DocQA（文档问答）作为主要评估任务，因为
DocBench 这类基准能够<strong>全面评估</strong>方法在以下方面的能力：</p>
<ul>
<li>多模态信息集成。</li>
<li>复杂推理。</li>
<li>领域适应性。</li>
<li>处理长文档和集成多种格式的能力。</li>
</ul>
<h3 id="数据构成与领域覆盖">2. 数据构成与领域覆盖</h3>
<p>DocBench 数据集包含来自公开在线资源的 <strong>229 份 PDF
文档</strong>。</p>
<p>它涵盖了<strong>五个</strong>不同的领域（Domains），确保了评估的广泛性：</p>
<ol type="1">
<li><strong>学术 (academia/Aca.)</strong>,。</li>
<li><strong>金融 (finance/Fin.)</strong>,。</li>
<li><strong>政府 (government/Gov.)</strong>,。</li>
<li><strong>法律 (laws/Law.)</strong>,。</li>
<li><strong>新闻 (news/News)</strong>,。</li>
</ol>
<h3 id="问题类型-question-types">3. 问题类型 (Question Types)</h3>
<p>DocBench
数据集的问题涵盖了多种类型，以测试模型的不同能力。它包括四种类型的问题，但在
MMGraphRAG 的实验中，排除了其中一类：</p>
<ol type="1">
<li><strong>Txt. (Pure Text Questions)</strong>：纯文本问题。</li>
<li><strong>Mm. (Multimodal
Questions)</strong>：多模态问题，需要整合文本和视觉信息才能回答。</li>
<li><strong>Una. (Unanswerable
Questions)</strong>：不可回答问题，文档中缺乏答案证据。</li>
<li><strong>Metadata Questions</strong>：元数据问题。</li>
</ol>
<blockquote>
<p><strong>注意：</strong> 在 MMGraphRAG
的实验中，由于信息被转换成了知识图谱（KG），因此<strong>元数据问题被排除在统计之外</strong>。</p>
</blockquote>
<h3 id="评估机制">4. 评估机制</h3>
<p>在实验中，DocBench
依靠大型语言模型（LLM）来确定答案的正确性。具体来说，在 MMGraphRAG
的实验中，<strong>Llama3.1-70B-Instruct</strong> 被用于评估 DocBench
上的答案正确性。</p>
<p>MMGraphRAG 在 DocBench 数据集上取得了显著的优势，其总体准确率达到了
<strong>60.5%</strong>，明显优于 NaiveRAG 和 GraphRAG 等现有 RAG
基线方法,,。特别是在处理多模态问题（Mm.）上，MMGraphRAG 的准确率高达
<strong>88.7%</strong>,。</p>
<h1 id="deepseek-ocr">DeepSeek-OCR</h1>
<h2 id="d-光学映射optical-2d-mapping"><strong>2D 光学映射（Optical 2D
Mapping）</strong></h2>
<p><strong>2D 光学映射（Optical 2D Mapping）*<em>是 DeepSeek-OCR
提出的一种创新技术，旨在*</em>利用视觉模态作为高效的压缩介质，将长文本上下文压缩为少量的视觉
Token</strong>。</p>
<p>以下是基于来源对 2D 光学映射的详细解析：</p>
<h3 id="核心概念与动机">1. 核心概念与动机</h3>
<p>大语言模型（LLM）在处理长文本时面临巨大的计算挑战，因为其计算量随序列长度呈平方级增长。<strong>2D
光学映射</strong>的思路在于：一张包含文档文字的图片（视觉模态）所代表的信息量，通常远超同等数量的数字文本
Token。因此，通过将文本“映射”为视觉表示，可以实现极高的<strong>光学压缩（Optical
Compression）</strong>率。</p>
<h3 id="技术实现方案deepseek-ocr">2. 技术实现方案：DeepSeek-OCR</h3>
<p>DeepSeek-OCR 是实现 2D
光学映射的实验性模型，它建立了一套完整的“压缩-解压”映射机制：</p>
<ul>
<li><strong>压缩（视觉编码器 - DeepEncoder）：</strong>
这是核心引擎，它将高分辨率的输入图像（包含文字内容）通过 16
倍卷积压缩器进行处理。它能在保持极少视觉 Token
数量的同时，捕捉到图像中的关键文本信息。</li>
<li><strong>解压（解码器 - MoE Decoder）：</strong> 采用 DeepSeek3B-MoE
架构，学习如何从 DeepEncoder 产生的压缩隐空间 Token
中重新构建原始文本表示。</li>
</ul>
<p><strong>2D
光学映射</strong>就像是将一叠厚厚的文字资料（长文本）拍摄成一张<strong>高像素的照片（视觉
Token）</strong>。虽然照片本身只占用了极小的存储空间（Token
数量少），但只要有一个视力极佳的观察者（解码器），依然能从照片中清晰地还原出原本所有的文字内容。</p>
<h2 id="压缩率compression-ratio"><strong>压缩率（Compression
Ratio）</strong></h2>
<p>根据提供的来源，在 DeepSeek-OCR
的研究语境下，<strong>压缩率（Compression
Ratio）*<em>是指*</em>视觉-文本 Token 压缩率（Vision-Text Token
Compression Ratio）</strong>。</p>
<p>以下是详细定义及其在技术中的重要性：</p>
<h3 id="核心定义与公式">1. 核心定义与公式</h3>
<p>压缩率用于衡量视觉 Token（Vision
Tokens）作为压缩介质存储文本信息的效率。根据来源，其具体的计算方式为：
<strong>压缩率 = 原始文本的 Token 数量（Ground Truth Text Tokens） /
模型使用的视觉 Token 数量（Vision Tokens Used）</strong>。</p>
<p>例如，如果一段包含 1000 个文字 Token 的文本被压缩成 100 个视觉
Token，其压缩率就是 <strong>10×</strong>。</p>
<h3 id="性能表现与阈值">2. 性能表现与阈值</h3>
<p>来源提供了 DeepSeek-OCR 在不同压缩率下的识别精度（Decoding
Precision）指标：</p>
<ul>
<li><strong>10倍以内（&lt; 10×）：</strong> 解码精度可达
<strong>97%</strong> 左右，被视为近乎无损的压缩。</li>
<li><strong>10-12倍（10-12×）：</strong> 识别准确率仍能保持在
<strong>90%</strong> 左右。</li>
<li><strong>20倍（20×）：</strong>
这是该技术的极限测试点，此时准确率下降至约 <strong>60%</strong>。</li>
</ul>
<h3 id="为什么需要这个指标">3. 为什么需要这个指标？</h3>
<ul>
<li><strong>解决计算瓶颈：</strong>
大语言模型（LLM）处理长文本时，计算量随序列长度呈平方级增长。通过高压缩率，可以用极少的
Token 代表极其丰富的信息，从而大幅降低计算开销。</li>
<li><strong>探索记忆机制：</strong>
压缩率的调整可以模拟人类的<strong>遗忘机制</strong>。通过降低分辨率（即增加压缩率），可以让陈旧的信息变得模糊（消耗更少
Token），而让近期信息保持清晰（消耗更多
Token），从而实现理论上无限长的上下文处理。</li>
<li><strong>衡量模型效率：</strong> 相比其他模型（如使用近 7000 个 Token
的 MinerU2.0），DeepSeek-OCR 追求在更少的视觉 Token 下（如少于 800
个）实现同等或更优的解析效果，这直接体现在更高的压缩率上。</li>
</ul>
<p><strong>压缩率</strong>就像是<strong>行李箱的分层收纳效率</strong>。原本需要
10 个大箱子才能装下的散装衣服（长文本
Token），通过某种神奇的折叠技术（2D 光学映射），现在只需要 1
个箱子（视觉
Token）就能装走。压缩率越高，意味着这个箱子折叠衣服的技术越厉害，装下的东西越多。</p>
]]></content>
      <categories>
        <category>大三上</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>langgraph实战mcp</title>
    <url>/2025/08/01/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/langgraph%E5%AE%9E%E6%88%98mcp/</url>
    <content><![CDATA[<h3 id="环境配置">环境配置</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install langchain-mcp-adapters</span><br></pre></td></tr></table></figure>
<h3 id="使用langgraph调用mcp">使用langgraph调用mcp</h3>
<p>要点主要是利用MultiServerMCPClient构建服务，获取tool</p>
<p>利用预设的create_react_agent构建ReAct架构的智能体并调用工具</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import asyncio # 需要导入 asyncio 来运行异步函数</span><br><span class="line"># 从langchain_mcp_adapters.client模块导入MultiServerMCPClient类</span><br><span class="line"># 从langgraph.prebuilt模块导入create_react_agent函数</span><br><span class="line">from langchain_mcp_adapters.client import MultiServerMCPClient</span><br><span class="line">from langgraph.prebuilt import create_react_agent</span><br><span class="line"></span><br><span class="line"># 导入 LLM 相关库</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"># 将主要逻辑封装在一个异步函数中</span><br><span class="line">async def main():</span><br><span class="line">    # 创建MultiServerMCPClient实例，配置两个不同的服务</span><br><span class="line">    client = MultiServerMCPClient(</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;math&quot;: &#123;  # 数学计算服务</span><br><span class="line">                &quot;command&quot;: &quot;python&quot;,  # 使用python命令启动</span><br><span class="line">                # 替换为你的math_server.py文件的绝对路径</span><br><span class="line">                &quot;args&quot;: [&quot;/workspace/langgraph-mcp/math_server.py&quot;],</span><br><span class="line">                &quot;transport&quot;: &quot;stdio&quot;,  # 使用标准输入输出传输</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;weather&quot;: &#123;  # 天气服务</span><br><span class="line">                # 确保你的天气服务器在8000端口运行</span><br><span class="line">                # *** 确保这个 URL 是正确的，并且服务器正在运行 ***</span><br><span class="line">                &quot;url&quot;: &quot;http://localhost:8000/mcp&quot;,</span><br><span class="line">                &quot;transport&quot;: &quot;streamable_http&quot;,  # 使用可流式HTTP传输</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tools = []</span><br><span class="line">    try:</span><br><span class="line">        # 在异步函数内部正确使用 await</span><br><span class="line">        tools = await client.get_tools()</span><br><span class="line">        print(f&quot;成功获取到 &#123;len(tools)&#125; 个MCP工具。&quot;)</span><br><span class="line">        for tool_item in tools:</span><br><span class="line">            print(f&quot;  - &#123;tool_item.name&#125;: &#123;tool_item.description&#125;&quot;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;获取MCP工具失败: &#123;e&#125;&quot;)</span><br><span class="line">        print(&quot;请确保MCP服务URL有效且可访问，或者您已正确配置了认证信息。&quot;)</span><br><span class="line">        # 在函数内部，如果出错可以选择返回或继续处理</span><br><span class="line">        # return # 这里可以 return，但会结束 main 函数</span><br><span class="line"></span><br><span class="line">    if not tools:</span><br><span class="line">        print(&quot;没有获取到工具，无法创建代理。&quot;)</span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    # 创建ReAct代理</span><br><span class="line">    llm = ChatOpenAI(</span><br><span class="line">        model=&quot;qwen3-235b-a22b-thinking-2507&quot;,</span><br><span class="line">        api_key=&quot;sk-a8ef27c47ea84224ac6eed6d4bba1bab&quot;,</span><br><span class="line">        base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot; # 修正了末尾多余的空格</span><br><span class="line">    )</span><br><span class="line">    agent = create_react_agent(llm, tools)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    # 异步调用代理来解决数学问题</span><br><span class="line">    # 确保在异步函数内部使用 await</span><br><span class="line">    math_response = await agent.ainvoke(</span><br><span class="line">        &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what&#x27;s (3 + 5) x 12?&quot;&#125;]&#125;</span><br><span class="line">    )</span><br><span class="line">    print(&quot;\n--- 数学问题回答 ---&quot;)</span><br><span class="line">    print(math_response[&quot;messages&quot;][-1].content) # 打印最后一条消息（LLM的回答）</span><br><span class="line"></span><br><span class="line">    # 异步调用代理来查询天气</span><br><span class="line">    weather_response = await agent.ainvoke(</span><br><span class="line">        &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is the weather in nyc?&quot;&#125;]&#125;</span><br><span class="line">    )</span><br><span class="line">    print(&quot;\n--- 天气问题回答 ---&quot;)</span><br><span class="line">    print(weather_response[&quot;messages&quot;][-1].content) # 打印最后一条消息（LLM的回答）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># --- 这是脚本的入口点 ---</span><br><span class="line"># 使用 asyncio.run() 来运行你的主异步函数</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    asyncio.run(main())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://github.langchain.ac.cn/langgraph/agents/mcp/">使用
MCP - LangChain 框架</a></p>
<h3 id="框架流程">框架流程</h3>
<figure>
<img src="/2025/08/01/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/langgraph%E5%AE%9E%E6%88%98mcp/image-20250801164905578.png" alt="image-20250801164905578">
<figcaption aria-hidden="true">image-20250801164905578</figcaption>
</figure>
<p>✅ 三个角色（系统组件）</p>
<table>
<colgroup>
<col style="width: 28%">
<col style="width: 72%">
</colgroup>
<thead>
<tr>
<th>角色</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Client</strong></td>
<td>前端或用户界面，发起请求</td>
</tr>
<tr>
<td><strong>Auth Provider</strong></td>
<td>认证服务（如 OAuth、JWT 提供者），负责登录和签发 token</td>
</tr>
<tr>
<td><strong>LangGraph Backend</strong></td>
<td>应用的后端服务，处理业务逻辑</td>
</tr>
<tr>
<td><strong>Secret Store</strong></td>
<td>存放用户敏感信息（如 token、密钥等）</td>
</tr>
<tr>
<td><strong>MCP Server</strong></td>
<td>后端工具服务，提供具体的工具或资源接口</td>
</tr>
</tbody>
</table>
<p>✅ 流程详解（12步）</p>
<p>🔐 阶段一：用户登录 &amp; 获取 Token（1~6）</p>
<ol type="1">
<li><p><strong>用户登录</strong><br>
Client 提交用户名和密码给 Auth Provider。</p></li>
<li><p><strong>返回 Token</strong><br>
Auth Provider 验证成功后，返回一个访问令牌（token）。</p></li>
<li><p><strong>携带 Token 请求</strong><br>
Client 将 token 附加在请求头中，发给 LangGraph Backend。</p></li>
<li><p><strong>验证 Token</strong><br>
LangGraph Backend 使用 <code>@auth.authenticate</code> 中间件验证 token
是否有效。</p></li>
<li><p><strong>获取用户信息</strong><br>
验证通过后，LangGraph Backend 从 Auth Provider
拉取用户详细信息。</p></li>
<li><p><strong>确认有效性</strong><br>
后端确认用户信息无误，流程继续。</p></li>
</ol>
<p>🔑 阶段二：获取用户权限 Token（6a~6b）</p>
<p>6a. <strong>拉取用户权限 Token</strong><br>
LangGraph Backend 从 Secret Store 获取该用户对应的权限 token（可能是 MCP
所需的访问凭证）。</p>
<p>6b. <strong>返回权限 Token</strong><br>
Secret Store 返回该 token。</p>
<p>🛠️ 阶段三：调用工具 &amp; 返回结果（7~12）</p>
<ol start="7" type="1">
<li><p><strong>权限控制检查</strong><br>
LangGraph Backend 使用 <code>@auth.on.*</code>
权限控制逻辑，确认用户是否有权调用该工具。</p></li>
<li><p><strong>构建 MCP Client</strong><br>
后端用用户的权限 token 构建一个 MCP 客户端。</p></li>
<li><p><strong>调用 MCP 工具</strong><br>
MCP Client 发起请求，调用某个具体工具，携带
token（通常放在请求头中）。</p></li>
<li><p><strong>MCP 验证并执行</strong><br>
MCP Server 验证 token 是否有效，确认无误后执行工具逻辑。</p></li>
<li><p><strong>工具返回结果</strong><br>
MCP Server 返回工具执行结果或资源数据。</p></li>
<li><p><strong>返回给前端</strong><br>
LangGraph Backend 将结果返回给 Client，完成整个链路。</p></li>
</ol>
]]></content>
      <categories>
        <category>mcp</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP 服务端实战</title>
    <url>/2025/08/01/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/mcp%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h3 id="配置环境">配置环境</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create a new directory for our project</span><br><span class="line">uv init weather</span><br><span class="line">cd weather</span><br><span class="line"></span><br><span class="line"># Create virtual environment and activate it</span><br><span class="line">uv venv</span><br><span class="line">source .venv/bin/activate</span><br><span class="line"></span><br><span class="line"># Install dependencies</span><br><span class="line">uv add &quot;mcp[cli]&quot; httpx</span><br><span class="line"></span><br><span class="line"># Create our server file</span><br><span class="line">touch weather.py</span><br></pre></td></tr></table></figure>
<h3 id="mcp-studio样例">mcp studio样例</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from mcp.server.fastmcp import FastMCP</span><br><span class="line"></span><br><span class="line">mcp = FastMCP(&quot;Math&quot;)</span><br><span class="line"></span><br><span class="line">@mcp.tool()</span><br><span class="line">def add(a: int, b: int) -&gt; int:</span><br><span class="line">    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;</span><br><span class="line">    return a + b</span><br><span class="line"></span><br><span class="line">@mcp.tool()</span><br><span class="line">def multiply(a: int, b: int) -&gt; int:</span><br><span class="line">    &quot;&quot;&quot;Multiply two numbers&quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    mcp.run(transport=&quot;stdio&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="mcp-streamable-http-样例">mcp streamable-http 样例</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from mcp.server.fastmcp import FastMCP</span><br><span class="line"></span><br><span class="line">mcp = FastMCP(&quot;Weather&quot;)</span><br><span class="line"></span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_weather(location: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;Get weather for location.&quot;&quot;&quot;</span><br><span class="line">    return &quot;It&#x27;s always sunny in New York&quot;</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    mcp.run(transport=&quot;streamable-http&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="使用">使用</h3>
<p>mcp市场<a href="https://www.modelscope.cn/mcp">MCP 广场 ·
魔搭社区</a></p>
<p><strong>使用 uv（推荐）</strong></p>
<p>当使用 <a href="https://docs.astral.sh/uv/"><code>uv</code></a>
时不需要特定的安装步骤。我们将使用 <a href="https://docs.astral.sh/uv/guides/tools/"><code>uvx</code></a>
直接运行 <em>mcp-server-fetch</em>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;mcpServers&quot;: &#123;</span><br><span class="line">  &quot;fetch&quot;: &#123;</span><br><span class="line">    &quot;command&quot;: &quot;uvx&quot;,</span><br><span class="line">    &quot;args&quot;: [&quot;mcp-server-fetch&quot;]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>使用 PIP</strong></p>
<p>或者，您可以通过 pip 安装 <code>mcp-server-fetch</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install mcp-server-fetch</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;mcpServers&quot;: &#123;</span><br><span class="line">  &quot;fetch&quot;: &#123;</span><br><span class="line">    &quot;command&quot;: &quot;python&quot;,</span><br><span class="line">    &quot;args&quot;: [&quot;-m&quot;, &quot;mcp_server_fetch&quot;]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>远程托管</strong></p>
<figure>
<img src="/2025/08/01/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/mcp%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%AE%9E%E6%88%98/image-20250802120145192.png" alt="image-20250802120145192">
<figcaption aria-hidden="true">image-20250802120145192</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;mcpServers&quot;: &#123;</span><br><span class="line">    &quot;fetch&quot;: &#123;</span><br><span class="line">      &quot;type&quot;: &quot;sse&quot;,</span><br><span class="line">      &quot;url&quot;: &quot;https://mcp.api-inference.modelscope.net/991cf46/sse&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://modelcontextprotocol.io/quickstart/server#core-mcp-concepts">构建
MCP 服务器 - 模型上下文协议 — Build an MCP Server - Model Context
Protocol</a></p>
]]></content>
      <categories>
        <category>mcp</category>
      </categories>
      <tags>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP 学习笔记</title>
    <url>/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h3 id="什么是-mcp">什么是 MCP？</h3>
<ul>
<li><strong>全称</strong>：Model Context Protocol</li>
<li><strong>作用</strong>：让 AI 助手（如 Claude、Cline
等）在对话过程中，动态调用外部工具（Tool）完成复杂任务（读写文件、查询数据库、调用
API 等）。</li>
<li><strong>组成</strong>：
<ol type="1">
<li><strong>MCP Host</strong>（宿主，如 Cline、Claude Desktop）</li>
<li><strong>MCP Server</strong>（提供 Tool 的后台服务）</li>
<li><strong>Tool</strong>（具体功能单元，如 <code>read_file</code>,
<code>exec_command</code> 等）</li>
</ol></li>
</ul>
<h3 id="核心概念速记">核心概念速记</h3>
<ul>
<li><strong>MCP Server</strong>
<ul>
<li>一个独立进程，提供 1-N 个 Tool。</li>
<li>可以用任何语言编写，只要暴露标准 MCP 接口。</li>
</ul></li>
<li><strong>Tool</strong>
<ul>
<li>最小执行单元，必须包含：
<ul>
<li>name（唯一）</li>
<li>description（让 LLM 理解何时调用）</li>
<li>input schema（参数结构，JSON Schema）</li>
</ul></li>
</ul></li>
<li><strong>交互流程（重点）</strong>
<ul>
<li>在启动mcp server时，server将tool信息传送给host</li>
<li>用户在 Host 输入自然语言需求。</li>
<li>Host 将需求 + 可用 Tool 列表发给 LLM。</li>
<li>LLM 判断调用哪个 Tool，并填充参数。</li>
<li>Host 通过 MCP 协议向对应 Server 发送请求。</li>
<li>Server 执行 Tool 并返回结果。</li>
<li>Host 将结果合并上下文，继续对话。</li>
</ul></li>
</ul>
<h3 id="mcp和fuction-calling的区别">mcp和fuction calling的区别</h3>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 46%">
<col style="width: 46%">
</colgroup>
<thead>
<tr>
<th>维度</th>
<th>Function Calling（FC）</th>
<th>MCP（Model Context Protocol）</th>
</tr>
</thead>
<tbody>
<tr>
<td>本质</td>
<td><strong>能力</strong> ——
某个大模型原生就带的一种「调用函数」功能</td>
<td><strong>协议</strong> —— 定义 AI
与外部世界如何长期、标准、可复用地交互</td>
</tr>
<tr>
<td>工作方式</td>
<td>模型在一次推理里<strong>主动</strong>决定要调用哪个函数，并吐出结构化参数</td>
<td>通过「客户端-服务器」架构，由 MCP Server
<strong>被动</strong>等待模型或 Agent 的请求</td>
</tr>
<tr>
<td>是否标准化</td>
<td>否。OpenAI、Anthropic、百度等各家接口格式不同</td>
<td>是。统一 JSON-RPC 2.0 协议，跨模型通用</td>
</tr>
<tr>
<td>上下文管理</td>
<td>单次调用，无状态；复杂多轮任务需自己维护</td>
<td>协议层面支持会话、状态、长链路任务</td>
</tr>
<tr>
<td>复用/共享</td>
<td>函数代码往往紧耦合在项目里，换模型就得重写</td>
<td>一次写成 MCP Server，可被任何支持 MCP 的模型/IDE/Agent 直接插用</td>
</tr>
</tbody>
</table>
<p>一句话总结： <strong>Function Calling
是「某个模型自带的快捷指令」，MCP
是「让任何模型都能统一插拔工具的工业标准」。</strong> 二者并非互斥——MCP
的实现里仍然可以用 Function Calling
去触发具体函数，但它把「怎么描述工具、怎么发现工具、怎么保持会话」这些事都标准化了，从而解决了
FC 带来的碎片化、难维护、难共享的问题 。</p>
<h3 id="安装mcp">安装mcp</h3>
<p>在mcp server市场查找自己想用的mcp服务，如<a href="https://mcp.so/server/fetch/modelcontextprotocol?tab=content">Fetch
MCP Server</a></p>
<p>复制mcp配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;mcpServers&quot;: &#123;</span><br><span class="line">    &quot;fetch&quot;: &#123;</span><br><span class="line">      &quot;command&quot;: &quot;uvx&quot;,</span><br><span class="line">      &quot;args&quot;: [</span><br><span class="line">        &quot;mcp-server-fetch&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在mcp host 中安装，如trae</p>
<p>host会自动完成对mcp的配置</p>
<h3 id="创建一个mcp-server">创建一个mcp server</h3>
<p>初始化项目</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uv init weather</span><br><span class="line"></span><br><span class="line">uv sync</span><br><span class="line"></span><br><span class="line">source .venv/bin/activate </span><br><span class="line"></span><br><span class="line">#添加依赖</span><br><span class="line">uv add &quot;mcp[cli]&quot; httpx</span><br></pre></td></tr></table></figure>
<p>创建weather.py</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 导入类型提示模块，用于类型注解</span><br><span class="line">from typing import Any</span><br><span class="line"></span><br><span class="line"># 导入httpx库，用于发送HTTP请求</span><br><span class="line">import httpx</span><br><span class="line"></span><br><span class="line"># 从mcp.server.fastmcp模块导入FastMCP类</span><br><span class="line"># FastMCP是一个快速构建MCP（Model Control Protocol）服务器的框架</span><br><span class="line">from mcp.server.fastmcp import FastMCP</span><br><span class="line"></span><br><span class="line"># 创建FastMCP实例，命名为&quot;weather&quot;，日志级别设置为ERROR（只显示错误信息）</span><br><span class="line">mcp = FastMCP(&quot;weather&quot;, log_level=&quot;ERROR&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 常量定义</span><br><span class="line"># NWS（National Weather Service）API的基础URL</span><br><span class="line">NWS_API_BASE = &quot;https://api.weather.gov&quot;</span><br><span class="line"># 用户代理字符串，用于标识应用程序</span><br><span class="line">USER_AGENT = &quot;weather-app/1.0&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">async def make_nws_request(url: str) -&gt; dict[str, Any] | None:</span><br><span class="line">    &quot;&quot;&quot;向NWS API发起请求并处理错误。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        url: 要请求的API URL</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        成功时返回解析后的JSON数据字典，失败时返回None</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 设置请求头信息</span><br><span class="line">    headers = &#123;</span><br><span class="line">        &quot;User-Agent&quot;: USER_AGENT,           # 用户代理标识</span><br><span class="line">        &quot;Accept&quot;: &quot;application/geo+json&quot;    # 接受的数据格式</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    # 创建异步HTTP客户端</span><br><span class="line">    async with httpx.AsyncClient() as client:</span><br><span class="line">        try:</span><br><span class="line">            # 发起GET请求，设置超时时间为30秒</span><br><span class="line">            response = await client.get(url, headers=headers, timeout=30.0)</span><br><span class="line">            # 如果响应状态码不是2xx，抛出异常</span><br><span class="line">            response.raise_for_status()</span><br><span class="line">            # 返回解析后的JSON数据</span><br><span class="line">            return response.json()</span><br><span class="line">        except Exception:</span><br><span class="line">            # 捕获所有异常，返回None表示请求失败</span><br><span class="line">            return None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def format_alert(feature: dict) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;将警报数据格式化为可读的字符串。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        feature: 包含警报信息的字典</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的警报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 获取警报属性</span><br><span class="line">    props = feature[&quot;properties&quot;]</span><br><span class="line">    # 格式化警报信息，使用get方法提供默认值防止键不存在</span><br><span class="line">    return f&quot;&quot;&quot;</span><br><span class="line">事件: &#123;props.get(&#x27;event&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">区域: &#123;props.get(&#x27;areaDesc&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">严重程度: &#123;props.get(&#x27;severity&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">描述: &#123;props.get(&#x27;description&#x27;, &#x27;无描述信息&#x27;)&#125;</span><br><span class="line">指示: &#123;props.get(&#x27;instruction&#x27;, &#x27;无具体指示&#x27;)&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 使用@mcp.tool()装饰器将函数注册为MCP工具</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_alerts(state: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定美国州的天气警报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        state: 两个字母的美国州代码（例如：CA, NY）</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的警报信息字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 构建获取州警报的URL</span><br><span class="line">    url = f&quot;&#123;NWS_API_BASE&#125;/alerts/active/area/&#123;state&#125;&quot;</span><br><span class="line">    # 发起API请求获取数据</span><br><span class="line">    data = await make_nws_request(url)</span><br><span class="line"></span><br><span class="line">    # 检查数据是否有效</span><br><span class="line">    if not data or &quot;features&quot; not in data:</span><br><span class="line">        return &quot;无法获取警报或未找到警报。&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否有警报</span><br><span class="line">    if not data[&quot;features&quot;]:</span><br><span class="line">        return &quot;该州无活动警报。&quot;</span><br><span class="line"></span><br><span class="line">    # 格式化所有警报</span><br><span class="line">    alerts = [format_alert(feature) for feature in data[&quot;features&quot;]]</span><br><span class="line">    # 用分隔符连接所有警报</span><br><span class="line">    return &quot;\n---\n&quot;.join(alerts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 注册为MCP工具的天气预报函数</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_forecast(latitude: float, longitude: float) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定位置的天气预报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        latitude: 位置的纬度</span><br><span class="line">        longitude: 位置的经度</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的天气预报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 首先获取预报网格端点</span><br><span class="line">    points_url = f&quot;&#123;NWS_API_BASE&#125;/points/&#123;latitude&#125;,&#123;longitude&#125;&quot;</span><br><span class="line">    points_data = await make_nws_request(points_url)</span><br><span class="line"></span><br><span class="line">    # 检查点数据是否获取成功</span><br><span class="line">    if not points_data:</span><br><span class="line">        return &quot;无法获取此位置的预报数据。&quot;</span><br><span class="line"></span><br><span class="line">    # 从点响应中获取预报URL</span><br><span class="line">    forecast_url = points_data[&quot;properties&quot;][&quot;forecast&quot;]</span><br><span class="line">    forecast_data = await make_nws_request(forecast_url)</span><br><span class="line"></span><br><span class="line">    # 检查预报数据是否获取成功</span><br><span class="line">    if not forecast_data:</span><br><span class="line">        return &quot;无法获取详细预报。&quot;</span><br><span class="line"></span><br><span class="line">    # 将时间段格式化为可读的预报</span><br><span class="line">    periods = forecast_data[&quot;properties&quot;][&quot;periods&quot;]</span><br><span class="line">    forecasts = []</span><br><span class="line">    # 只显示接下来的5个时间段</span><br><span class="line">    for period in periods[:5]:</span><br><span class="line">        forecast = f&quot;&quot;&quot;</span><br><span class="line">&#123;period[&#x27;name&#x27;]&#125;:</span><br><span class="line">温度: &#123;period[&#x27;temperature&#x27;]&#125;°&#123;period[&#x27;temperatureUnit&#x27;]&#125;</span><br><span class="line">风力: &#123;period[&#x27;windSpeed&#x27;]&#125; &#123;period[&#x27;windDirection&#x27;]&#125;</span><br><span class="line">预报: &#123;period[&#x27;detailedForecast&#x27;]&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">        forecasts.append(forecast)</span><br><span class="line"></span><br><span class="line">    # 用分隔符连接所有预报</span><br><span class="line">    return &quot;\n---\n&quot;.join(forecasts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 初始化并运行服务器，使用stdio传输方式</span><br><span class="line">    mcp.run(transport=&#x27;stdio&#x27;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><span class="citation" data-cites="mcp.tool">@mcp.tool</span>()可以将函数内的字符串，参数类型等信息传给大模型，以供大模型决定何时调用这个tool</p>
<p>mcp.run(transport=‘stdio’)说明mcp
server和host的传输方式是输入和输出</p>
</blockquote>
<p>mcp server 配置信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;weather&quot;: &#123;</span><br><span class="line">    &quot;disabled&quot;: false,</span><br><span class="line">    &quot;timeout&quot;: 60,</span><br><span class="line">    &quot;command&quot;: &quot;uv&quot;,</span><br><span class="line">    &quot;args&quot;: [</span><br><span class="line">      &quot;--directory&quot;,</span><br><span class="line">      &quot;/Users/joeygreen/PycharmProjects/weather&quot;,</span><br><span class="line">      &quot;run&quot;,</span><br><span class="line">      &quot;weather.py&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;transportType&quot;: &quot;stdio&quot;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>“disabled”: false表示该服务是否被禁用。<code>false</code>
表示该服务是启用状态，可以正常运行。</p>
<p>“timeout”: 60设置该服务的超时时间，单位为秒。</p>
<p>“command”: “uv”指定执行该服务时使用的命令。</p>
<p>“args”出了执行 <code>command</code> 时需要传递的参数。</p>
<p>“transportType”: “stdio”指定服务的通信方式。<code>stdio</code>
表示标准输入输出流（Standard Input Output），通常用于进程间通信。</p>
</blockquote>
<h3 id="解析mcp-server与host的通信">解析mcp server与host的通信</h3>
<figure>
<img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727154739013.png" alt="image-20250727154739013">
<figcaption aria-hidden="true">image-20250727154739013</figcaption>
</figure>
<p>输入为host对server发送，输出为server对host发送，以下将列举几个重要的说明</p>
<p>输入中：<code>method</code>字段为host告诉server接下来要干什么，如<strong>初始化
(Initialization)</strong>，<strong>通知已初始化
(Notification)</strong>，<strong>查询可用工具 (Listing
Tools)</strong>，<strong>调用工具 (Calling a Tool)</strong></p>
<p><code>protocolVersion</code>说明了mcp使用的协议版本</p>
<p>以下见server返回的tool信息，其中的一个参数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;get_forecast&quot;,</span><br><span class="line">    &quot;description&quot;: &quot;Get weather forecast for a location.\n\nArgs:\n    latitude: Latitude of the location\n    longitude: Longitude of the location\n&quot;,</span><br><span class="line">    &quot;inputSchema&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;latitude&quot;: &#123;</span><br><span class="line">                &quot;title&quot;: &quot;Latitude&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;number&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;longitude&quot;: &#123;</span><br><span class="line">                &quot;title&quot;: &quot;Longitude&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;number&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;required&quot;: [</span><br><span class="line">            &quot;latitude&quot;,</span><br><span class="line">            &quot;longitude&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;title&quot;: &quot;get_forecastArguments&quot;,</span><br><span class="line">        &quot;type&quot;: &quot;object&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以和定义的函数对比学习</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 注册为MCP工具的天气预报函数</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_forecast(latitude: float, longitude: float) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定位置的天气预报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        latitude: 位置的纬度</span><br><span class="line">        longitude: 位置的经度</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的天气预报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 首先获取预报网格端点</span><br><span class="line">    points_url = f&quot;&#123;NWS_API_BASE&#125;/points/&#123;latitude&#125;,&#123;longitude&#125;&quot;</span><br><span class="line">    points_data = await make_nws_request(points_url)</span><br><span class="line"></span><br><span class="line">    # 检查点数据是否获取成功</span><br><span class="line">    if not points_data:</span><br><span class="line">        return &quot;无法获取此位置的预报数据。&quot;</span><br><span class="line"></span><br><span class="line">    # 从点响应中获取预报URL</span><br><span class="line">    forecast_url = points_data[&quot;properties&quot;][&quot;forecast&quot;]</span><br><span class="line">    forecast_data = await make_nws_request(forecast_url)</span><br><span class="line"></span><br><span class="line">    # 检查预报数据是否获取成功</span><br><span class="line">    if not forecast_data:</span><br><span class="line">        return &quot;无法获取详细预报。&quot;</span><br><span class="line"></span><br><span class="line">    # 将时间段格式化为可读的预报</span><br><span class="line">    periods = forecast_data[&quot;properties&quot;][&quot;periods&quot;]</span><br><span class="line">    forecasts = []</span><br><span class="line">    # 只显示接下来的5个时间段</span><br><span class="line">    for period in periods[:5]:</span><br><span class="line">        forecast = f&quot;&quot;&quot;</span><br><span class="line">&#123;period[&#x27;name&#x27;]&#125;:</span><br><span class="line">温度: &#123;period[&#x27;temperature&#x27;]&#125;°&#123;period[&#x27;temperatureUnit&#x27;]&#125;</span><br><span class="line">风力: &#123;period[&#x27;windSpeed&#x27;]&#125; &#123;period[&#x27;windDirection&#x27;]&#125;</span><br><span class="line">预报: &#123;period[&#x27;detailedForecast&#x27;]&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">        forecasts.append(forecast)</span><br><span class="line"></span><br><span class="line">    # 用分隔符连接所有预报</span><br><span class="line">    return &quot;\n---\n&quot;.join(forecasts)</span><br></pre></td></tr></table></figure>
<p><code>description</code>内容即为我们在定义这个tool的时候写的<strong>文档字符串</strong>（Documentation
String），通常简称为 <strong>docstring</strong></p>
<p><code>inputSchema</code> 是在MCP（Model Control
Protocol）中用来<strong>描述工具（tool）所需参数的结构和类型的规范</strong>。它本质上是一个JSON
Schema。</p>
<blockquote>
<p>JSON Schema 是一个用于<strong>描述和验证 JSON
数据结构的规范</strong>。你可以把它理解为 JSON
数据的“蓝图”或“模板”。</p>
</blockquote>
<p><code>required</code>指明哪些参数是必需的，哪些是可选的。</p>
<h3 id="理解mcp的本质">理解mcp的本质</h3>
<p>以上内容皆是server与host直接的交互，本质上可以理解成host对server提供的工具进行注册与使用。这其中并不涉及到host与大模型的交互，也就是大模型是如何使用host提供的信息。实际上不同的mcp
host与模型的交互协议也不同，如cline使用的是xml格式；cherry
studio使用的则是fuction calling</p>
<p>再看mcp的全称Model Context
Protocol，模型上下文协议，也就是mcp增加模型的扩展性，使他可以获取更多信息，而server就是为模型提供更多信息的工具</p>
<h3 id="mcp-host与模型的交互">mcp host与模型的交互</h3>
<p>使用中转服务器截获日志</p>
<figure>
<img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727163811531-1753605912284-1.png" alt="image-20250727163811531">
<figcaption aria-hidden="true">image-20250727163811531</figcaption>
</figure>
<p>以下为cline发送给模型的请求</p>
<figure>
<img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727164527797.png" alt="image-20250727164527797">
<figcaption aria-hidden="true">image-20250727164527797</figcaption>
</figure>
<p><code>messages</code>包含了系统提示词与用户输入</p>
<p>先来看系统提示词，cline提供的提示词包括工具使用格式，工具信息，工具使用方法等。这里重点说一下，cline的工具使用格式xml</p>
<p>结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;tool_name&gt;</span><br><span class="line">&lt;parameter1_name&gt;value1&lt;/parameter1_name&gt;</span><br><span class="line">&lt;parameter2_name&gt;value2&lt;/parameter2_name&gt;</span><br><span class="line">...</span><br><span class="line">&lt;/tool_name&gt;</span><br></pre></td></tr></table></figure>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;read_file&gt;</span><br><span class="line">src/main.js</span><br><span class="line">&lt;/read_file&gt;</span><br></pre></td></tr></table></figure>
<p>再举个例子</p>
<p>use_mcp_tool 描述：请求使用由连接的 MCP 服务器提供的工具。每个 MCP
服务器可以提供具有不同功能的多个工具。工具有定义的输入模式，用于指定必需和可选参数。
参数：</p>
<p>server_name: (必需) 提供该工具的 MCP 服务器的名称 tool_name: (必需)
要执行的工具的名称 arguments: (必需) 一个 JSON
对象，包含工具的输入参数，遵循工具的输入模式 用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;use_mcp_tool&gt;</span><br><span class="line">&lt;server_name&gt;服务器名称在此&lt;/server_name&gt;</span><br><span class="line">&lt;tool_name&gt;工具名称在此&lt;/tool_name&gt;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">&quot;param1&quot;: &quot;value1&quot;,</span><br><span class="line">&quot;param2&quot;: &quot;value2&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&lt;/use_mcp_tool&gt;</span><br></pre></td></tr></table></figure>
<p>模型返回响应如下</p>
<figure>
<img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727174504506.png" alt="image-20250727174504506">
<figcaption aria-hidden="true">image-20250727174504506</figcaption>
</figure>
<p>sse连接，流式输出</p>
<blockquote>
<p>SSE 是一种<strong>基于标准
HTTP</strong>、<strong>只允许服务器向客户端单向推送文本流</strong>的实时通信技术，浏览器原生支持，自动重连，常用于<strong>AI
流式回答</strong>、<strong>实时日志</strong>、<strong>股价/监控推送</strong>等场景。</p>
<p>即客户端发送一次请求，连续接受多次响应直到结束</p>
</blockquote>
<h3 id="mcp的三种传输协议">mcp的三种传输协议</h3>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 29%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 19%">
</colgroup>
<thead>
<tr>
<th>协议名称</th>
<th>通信方式</th>
<th>适用场景</th>
<th>优势</th>
<th>局限</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Stdio</strong>（标准输入输出）</td>
<td>使用进程的标准输入（stdin）和标准输出（stdout）进行本地通信，基于
JSON-RPC 2.0 格式</td>
<td>本地开发、调试、IDE插件、命令行工具</td>
<td>简单易实现、跨平台、低延迟</td>
<td>仅支持本地通信，无法跨网络，低并发</td>
</tr>
<tr>
<td><strong>SSE</strong>（Server-Sent Events）</td>
<td>客户端通过 HTTP POST 发送请求，服务器通过 SSE 单向推送流式响应</td>
<td>实时监控、新闻推送、远程服务调用</td>
<td>基于 HTTP，浏览器友好，支持流式数据</td>
<td>仅支持单向通信，MCP官方已标记为“即将废弃”</td>
</tr>
<tr>
<td><strong>Streamable HTTP</strong>（新型流式HTTP）</td>
<td>支持双向流式通信的现代 HTTP 协议，替代 SSE，支持会话恢复、OAuth
认证等</td>
<td>分布式系统、高并发、双向实时交互</td>
<td>双向通信、高性能、企业级安全机制</td>
<td>实现较复杂，生态仍在发展中</td>
</tr>
</tbody>
</table>
<h3 id="react">ReAct</h3>
<p>ReAct
是一种用于增强大型语言模型（LLMs）推理和行动能力的技术框架，它通过结合“推理”（Reasoning）和“行动”（Acting）来提升模型处理复杂任务的能力。</p>
<p>其工作流程通常包括以下几个步骤：</p>
<ol type="1">
<li><strong>思考（Reasoning）</strong>：模型对当前问题进行分析，思考下一步需要采取的行动。</li>
<li><strong>行动（Acting）</strong>：模型决定调用哪些工具或函数，并提供必要的参数。</li>
<li><strong>观察（Observation）</strong>：工具执行后返回结果，模型对结果进行观察。</li>
<li><strong>响应（Response）</strong>：根据观察结果，模型生成最终的用户响应。</li>
</ol>
<p>实际应用上就是告诉大模型用ReAct这种模式来思考</p>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV1uronYREWR?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">MCP终极指南
- 从原理到实战，带你深入掌握MCP（基础篇）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>mcp</category>
      </categories>
      <tags>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>常用mcp</title>
    <url>/2025/12/09/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/%E5%B8%B8%E7%94%A8mcp/</url>
    <content><![CDATA[<h3 id="常用mcp">常用mcp</h3>
<h2 id="supabase">supabase</h2>
<p><a href="https://supabase.com/docs/guides/getting-started/mcp">模型上下文协议
(MCP) | Supabase 文档 — Model context protocol (MCP) | Supabase
Docs</a></p>
<p>codex mcp login supabase</p>
<h2 id="context7">context7</h2>
<p><a href="https://github.com/upstash/context7/blob/master/i18n/README.zh-CN.md">context7/i18n/README.zh-CN.md
at master · upstash/context7</a></p>
<p>claude mcp add –transport http context7 https://mcp.context7.com/mcp
–header “CONTEXT7_API_KEY:
ctx7sk-7f2ea2a0-d309-4ba7-97d0-af20a783540f”</p>
<p>[mcp_servers.context7] url = “https://mcp.context7.com/mcp”
http_headers = { “CONTEXT7_API_KEY” =
“ctx7sk-7f2ea2a0-d309-4ba7-97d0-af20a783540f” }</p>
<h2 id="vercel">vercel</h2>
<p><a href="https://vercel.com/docs/mcp/vercel-mcp">Use Vercel’s MCP
server</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[mcp_servers.vecel]</span><br><span class="line">command = &quot;cmd&quot;</span><br><span class="line">args = [</span><br><span class="line">    &quot;/c&quot;,</span><br><span class="line">    &quot;npx&quot;,</span><br><span class="line">    &quot;-y&quot;,</span><br><span class="line">    &quot;mcp-remote@latest&quot;,</span><br><span class="line">    &quot;https://mcp.vercel.com&quot;</span><br><span class="line">]</span><br><span class="line">env = &#123; SystemRoot=&quot;C:\\Windows&quot;, PROGRAMFILES=&quot;C:\\Program Files&quot; &#125;</span><br><span class="line">startup_timeout_ms = 60_000</span><br></pre></td></tr></table></figure>
<h2 id="chrome-devtools">Chrome DevTools</h2>
<p><a href="https://github.com/ChromeDevTools/chrome-devtools-mcp">ChromeDevTools/chrome-devtools-mcp:
Chrome DevTools for coding agents</a></p>
<h2 id="langchain-docs">langchain docs</h2>
<p>https://docs.langchain.com/mcp</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;Docs by LangChain&quot;: &#123;</span><br><span class="line">			&quot;url&quot;: &quot;https://docs.langchain.com/mcp&quot;,</span><br><span class="line">			&quot;type&quot;: &quot;http&quot;</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[mcp_servers.docs_by_langchain]</span><br><span class="line">url = &quot;https://docs.langchain.com/mcp&quot;</span><br></pre></td></tr></table></figure>
<h2 id="vscode-mcp配置文档">vscode mcp配置文档</h2>
<p><a href="https://code.visualstudio.com/docs/copilot/customization/mcp-servers">Use
MCP servers in VS Code</a></p>
<h2 id="codex-mcp配置文档">codex mcp配置文档</h2>
<p><a href="https://developers.openai.com/codex/mcp">模型上下文协议 —
Model Context Protocol</a></p>
<h2 id="其他">其他</h2>
<p>figma</p>
<p>stripe</p>
<p>shadcn</p>
<p><a href="https://ui.shadcn.com/docs/mcp#codex">MCP Server -
shadcn/ui</a></p>
<p>semgrep</p>
<p><a href="https://github.com/semgrep/semgrep/tree/develop/cli/src/semgrep/mcp">semgrep/cli/src/semgrep/mcp
at develop · semgrep/semgrep</a></p>
<h2 id="mcp市场">mcp市场</h2>
<p><a href="https://mcpservers.org/">Awesome MCP Servers</a></p>
<h2 id="参考">参考</h2>
<p><a href="https://www.bilibili.com/video/BV1ZJsBznEt3/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">用过上百款编程MCP，只有这15个真正好用，Claude
Code与Codex配置MCP详细教程_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>mcp</category>
      </categories>
      <tags>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP 客户端实战</title>
    <url>/2025/08/01/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h3 id="配置环境">配置环境</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建项目目录</span><br><span class="line">uv init mcp-client</span><br><span class="line">cd mcp-client</span><br><span class="line"></span><br><span class="line"># 创建虚拟环境</span><br><span class="line">uv venv</span><br><span class="line"></span><br><span class="line"># 激活虚拟环境</span><br><span class="line"># 在 Windows 上:</span><br><span class="line">.venv\Scripts\activate</span><br><span class="line"># 在 Unix 或 MacOS 上:</span><br><span class="line">source .venv/bin/activate</span><br><span class="line"></span><br><span class="line"># 安装所需包</span><br><span class="line">uv add mcp anthropic python-dotenv</span><br><span class="line">#使用镜像源安装</span><br><span class="line">uv add mcp anthropic python-dotenv --index-url https://pypi.tuna.tsinghua.edu.cn/simple/</span><br><span class="line"></span><br><span class="line"># 删除样板文件</span><br><span class="line"># 在 Windows 上:</span><br><span class="line">del main.py</span><br><span class="line"># 在 Unix 或 MacOS 上:</span><br><span class="line">rm main.py</span><br><span class="line"></span><br><span class="line"># 创建我们的主文件</span><br><span class="line">touch client.py</span><br></pre></td></tr></table></figure>
<h3 id="设置-api-密钥">设置 API 密钥</h3>
<p>创建一个 <code>.env</code> 文件来存储它：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create .env file</span><br><span class="line">touch .env</span><br></pre></td></tr></table></figure>
<p>将您的密钥添加到 <code>.env</code> 文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ANTHROPIC_API_KEY=&lt;your key here&gt;</span><br></pre></td></tr></table></figure>
<p>将 <code>.env</code> 添加到您的 <code>.gitignore</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo &quot;.env&quot; &gt;&gt; .gitignore</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将 <code>.env</code> 文件名添加到 <code>.gitignore</code>
文件中，这样 Git 就会忽略 <code>.env</code>
文件，不会将其纳入版本控制。</p>
</blockquote>
<h3 id="创建客户端">创建客户端</h3>
<h4 id="基本客户端结构">基本客户端结构</h4>
<p>首先，让我们设置我们的导入并创建基本的客户端类：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">from typing import Optional</span><br><span class="line">from contextlib import AsyncExitStack</span><br><span class="line"></span><br><span class="line">from mcp import ClientSession, StdioServerParameters</span><br><span class="line">from mcp.client.stdio import stdio_client</span><br><span class="line"></span><br><span class="line">from anthropic import Anthropic</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line"></span><br><span class="line">load_dotenv()  # 从 .env 文件加载环境变量</span><br><span class="line"></span><br><span class="line">class MCPClient:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        # 初始化会话和客户端对象</span><br><span class="line">        self.session: Optional[ClientSession] = None  # MCP客户端会话</span><br><span class="line">        self.exit_stack = AsyncExitStack()  # 异步上下文管理器堆栈，用于资源清理</span><br><span class="line">        self.anthropic = Anthropic()  # Anthropic AI 客户端</span><br><span class="line">        </span><br><span class="line">    # 后续方法将在这里定义</span><br></pre></td></tr></table></figure>
<h4 id="服务器连接管理">服务器连接管理</h4>
<p>接下来，我们将实现连接到 MCP 服务器的功能：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def connect_to_server(self, server_script_path: str):</span><br><span class="line">    &quot;&quot;&quot;连接到MCP服务器</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        server_script_path: 服务器脚本路径 (.py 或 .js 文件)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 检查是否为Python文件</span><br><span class="line">    is_python = server_script_path.endswith(&#x27;.py&#x27;)</span><br><span class="line">    # 检查是否为JavaScript文件</span><br><span class="line">    is_js = server_script_path.endswith(&#x27;.js&#x27;)</span><br><span class="line">    </span><br><span class="line">    # 如果不是Python或JavaScript文件，则抛出错误</span><br><span class="line">    if not (is_python or is_js):</span><br><span class="line">        raise ValueError(&quot;服务器脚本必须是 .py 或 .js 文件&quot;)</span><br><span class="line"></span><br><span class="line">    # 根据文件类型确定执行命令</span><br><span class="line">    command = &quot;python&quot; if is_python else &quot;node&quot;</span><br><span class="line">    </span><br><span class="line">    # 创建服务器参数对象</span><br><span class="line">    server_params = StdioServerParameters(</span><br><span class="line">        command=command,           # 执行命令</span><br><span class="line">        args=[server_script_path], # 脚本路径作为参数</span><br><span class="line">        env=None                   # 环境变量（使用默认环境）</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 建立stdio客户端连接并将其添加到异步上下文管理器中</span><br><span class="line">    stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))</span><br><span class="line">    self.stdio, self.write = stdio_transport</span><br><span class="line">    </span><br><span class="line">    # 创建客户端会话并将其添加到异步上下文管理器中</span><br><span class="line">    self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))</span><br><span class="line"></span><br><span class="line">    # 初始化会话</span><br><span class="line">    await self.session.initialize()</span><br><span class="line"></span><br><span class="line">    # 列出可用的工具</span><br><span class="line">    response = await self.session.list_tools()</span><br><span class="line">    tools = response.tools</span><br><span class="line">    </span><br><span class="line">    # 打印连接的服务器提供的工具列表</span><br><span class="line">    print(&quot;\n已连接到服务器，可用工具:&quot;, [tool.name for tool in tools])</span><br></pre></td></tr></table></figure>
<h4 id="查询处理逻辑">查询处理逻辑</h4>
<p>现在让我们添加处理查询和调用工具的核心功能：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def process_query(self, query: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;使用Claude和可用工具处理查询&quot;&quot;&quot;</span><br><span class="line">    # 构建消息列表</span><br><span class="line">    messages = [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;role&quot;: &quot;user&quot;,      # 用户角色</span><br><span class="line">            &quot;content&quot;: query     # 用户查询内容</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    # 获取可用工具列表</span><br><span class="line">    response = await self.session.list_tools()</span><br><span class="line">    available_tools = [&#123;</span><br><span class="line">        &quot;name&quot;: tool.name,           # 工具名称</span><br><span class="line">        &quot;description&quot;: tool.description,  # 工具描述</span><br><span class="line">        &quot;input_schema&quot;: tool.inputSchema  # 工具输入模式</span><br><span class="line">    &#125; for tool in response.tools]</span><br><span class="line"></span><br><span class="line">    # 初始Claude API调用</span><br><span class="line">    response = self.anthropic.messages.create(</span><br><span class="line">        model=&quot;qwen3-235b-a22b&quot;,  # 使用的模型</span><br><span class="line">        max_tokens=1000,                     # 最大返回令牌数</span><br><span class="line">        messages=messages,                   # 消息历史</span><br><span class="line">        tools=available_tools               # 可用工具</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 处理响应并处理工具调用</span><br><span class="line">    final_text = []  # 存储最终文本结果</span><br><span class="line"></span><br><span class="line">    assistant_message_content = []  # 存储助手消息内容</span><br><span class="line">    for content in response.content:  # 遍历响应内容</span><br><span class="line">        if content.type == &#x27;text&#x27;:  # 如果是文本内容</span><br><span class="line">            final_text.append(content.text)  # 添加到最终结果</span><br><span class="line">            assistant_message_content.append(content)  # 添加到助手消息</span><br><span class="line">        elif content.type == &#x27;tool_use&#x27;:  # 如果是工具调用</span><br><span class="line">            tool_name = content.name    # 工具名称</span><br><span class="line">            tool_args = content.input   # 工具参数</span><br><span class="line"></span><br><span class="line">            # 执行工具调用</span><br><span class="line">            result = await self.session.call_tool(tool_name, tool_args)</span><br><span class="line">            final_text.append(f&quot;[调用工具 &#123;tool_name&#125;，参数 &#123;tool_args&#125;]&quot;)</span><br><span class="line"></span><br><span class="line">            assistant_message_content.append(content)</span><br><span class="line">            # 添加助手消息到历史</span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                &quot;content&quot;: assistant_message_content</span><br><span class="line">            &#125;)</span><br><span class="line">            # 添加工具执行结果到历史</span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;tool_result&quot;,      # 工具结果类型</span><br><span class="line">                        &quot;tool_use_id&quot;: content.id,  # 工具使用ID</span><br><span class="line">                        &quot;content&quot;: result.content   # 工具执行结果</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">            # 获取Claude的下一个响应</span><br><span class="line">            response = self.anthropic.messages.create(</span><br><span class="line">                model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">                max_tokens=1000,</span><br><span class="line">                messages=messages,</span><br><span class="line">                tools=available_tools</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            # 添加响应文本到最终结果</span><br><span class="line">            final_text.append(response.content[0].text)</span><br><span class="line"></span><br><span class="line">    # 返回连接后的最终文本结果</span><br><span class="line">    return &quot;\n&quot;.join(final_text)</span><br></pre></td></tr></table></figure>
<h4 id="交互式聊天界面">交互式聊天界面</h4>
<p>现在我们将添加聊天循环和清理功能：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def chat_loop(self):</span><br><span class="line">    &quot;&quot;&quot;运行交互式聊天循环&quot;&quot;&quot;</span><br><span class="line">    print(&quot;\nMCP客户端已启动!&quot;)</span><br><span class="line">    print(&quot;输入您的问题或输入&#x27;quit&#x27;退出。&quot;)</span><br><span class="line"></span><br><span class="line">    while True:  # 无限循环，持续接收用户输入</span><br><span class="line">        try:</span><br><span class="line">            query = input(&quot;\n问题: &quot;).strip()  # 获取用户输入并去除首尾空格</span><br><span class="line"></span><br><span class="line">            if query.lower() == &#x27;quit&#x27;:  # 如果用户输入&#x27;quit&#x27;（不区分大小写）</span><br><span class="line">                break  # 退出循环</span><br><span class="line"></span><br><span class="line">            # 处理用户查询并获取响应</span><br><span class="line">            response = await self.process_query(query)</span><br><span class="line">            print(&quot;\n&quot; + response)  # 打印AI响应结果</span><br><span class="line"></span><br><span class="line">        except Exception as e:  # 捕获所有异常</span><br><span class="line">            print(f&quot;\n错误: &#123;str(e)&#125;&quot;)  # 打印错误信息</span><br><span class="line"></span><br><span class="line">async def cleanup(self):</span><br><span class="line">    &quot;&quot;&quot;清理资源&quot;&quot;&quot;</span><br><span class="line">    await self.exit_stack.aclose()  # 异步关闭所有在exit_stack中管理的资源</span><br></pre></td></tr></table></figure>
<h4 id="主入口点">主入口点</h4>
<p>最后，我们将添加主要的执行逻辑：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def main():</span><br><span class="line">    # 检查命令行参数数量，如果少于2个则显示使用说明</span><br><span class="line">    if len(sys.argv) &lt; 2:</span><br><span class="line">        print(&quot;用法: python client.py &lt;服务器脚本路径&gt;&quot;)</span><br><span class="line">        sys.exit(1)  # 退出程序，返回错误码1</span><br><span class="line"></span><br><span class="line">    # 创建MCP客户端实例</span><br><span class="line">    client = MCPClient()</span><br><span class="line">    try:</span><br><span class="line">        # 连接到服务器，sys.argv[1]是第一个命令行参数（服务器脚本路径）</span><br><span class="line">        await client.connect_to_server(sys.argv[1])</span><br><span class="line">        # 启动交互式聊天循环</span><br><span class="line">        await client.chat_loop()</span><br><span class="line">    finally:</span><br><span class="line">        # 确保程序结束时清理资源</span><br><span class="line">        await client.cleanup()</span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    import sys  # 导入sys模块用于处理命令行参数</span><br><span class="line">    # 运行异步主函数</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/08/01/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/QQ20250801-164738.png" alt="QQ20250801-164738">
<figcaption aria-hidden="true">QQ20250801-164738</figcaption>
</figure>
<h3 id="运行客户端">运行客户端</h3>
<p>要使您的客户端与任何 MCP 服务器运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uv run client.py path/to/server.py # python server</span><br><span class="line">uv run client.py path/to/build/index.js # node server</span><br></pre></td></tr></table></figure>
<p>客户端将：</p>
<ol type="1">
<li>连接到指定服务器</li>
<li>列出可用工具</li>
<li>开始一个交互式聊天会话，您可以在其中：
<ul>
<li>输入查询</li>
<li>查看工具执行情况</li>
<li>从 Claude 获取响应</li>
</ul></li>
</ol>
<h3 id="运作流程">运作流程</h3>
<p>当你提交查询时：</p>
<ol type="1">
<li>客户端从服务器获取可用工具列表</li>
<li>你的查询连同工具描述一起发送给 Claude</li>
<li>Claude 决定使用哪些工具（如果有的话）</li>
<li>客户端通过服务器执行任何请求的工具调用</li>
<li>结果会发送回 Claude</li>
<li>Claude 提供自然语言响应</li>
<li>响应显示给您</li>
</ol>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://modelcontextprotocol.io/quickstart/client#main-entry-point">Build
an MCP Client - Model Context Protocol</a></p>
<h3 id="适配openai版本">适配openai版本</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import json</span><br><span class="line">import sys</span><br><span class="line">from typing import Optional</span><br><span class="line">from contextlib import AsyncExitStack</span><br><span class="line"></span><br><span class="line">from mcp import ClientSession, StdioServerParameters</span><br><span class="line">from mcp.client.stdio import stdio_client</span><br><span class="line"></span><br><span class="line">from openai import OpenAI</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">load_dotenv()  # 从 .env 文件加载环境变量</span><br><span class="line"></span><br><span class="line">class MCPClient:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        # 初始化会话和客户端对象</span><br><span class="line">        self.session: Optional[ClientSession] = None  # MCP客户端会话</span><br><span class="line">        self.exit_stack = AsyncExitStack()  # 异步上下文管理器堆栈，用于资源清理</span><br><span class="line">        self.anthropic = OpenAI(</span><br><span class="line">            api_key=os.getenv(&quot;DASHSCOPE_API_KEY&quot;),</span><br><span class="line">            base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">        )  # 使用OpenAI兼容模式连接通义千问</span><br><span class="line">        </span><br><span class="line">    async def connect_to_server(self, server_script_path: str):</span><br><span class="line">        &quot;&quot;&quot;连接到MCP服务器</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            server_script_path (str): 服务器脚本路径，支持.py或.js文件</span><br><span class="line">        </span><br><span class="line">        Raises:</span><br><span class="line">            ValueError: 当脚本文件不是.py或.js格式时抛出</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 检查是否为Python文件</span><br><span class="line">        is_python = server_script_path.endswith(&#x27;.py&#x27;)</span><br><span class="line">        # 检查是否为JavaScript文件</span><br><span class="line">        is_js = server_script_path.endswith(&#x27;.js&#x27;)</span><br><span class="line">        </span><br><span class="line">        # 如果不是Python或JavaScript文件，则抛出错误</span><br><span class="line">        if not (is_python or is_js):</span><br><span class="line">            raise ValueError(&quot;服务器脚本必须是 .py 或 .js 文件&quot;)</span><br><span class="line"></span><br><span class="line">        # 根据文件类型确定执行命令</span><br><span class="line">        command = &quot;python&quot; if is_python else &quot;node&quot;</span><br><span class="line">        </span><br><span class="line">        # 创建服务器参数对象</span><br><span class="line">        server_params = StdioServerParameters(</span><br><span class="line">            command=command,           # 执行命令</span><br><span class="line">            args=[server_script_path], # 脚本路径作为参数</span><br><span class="line">            env=None                   # 环境变量（使用默认环境）</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 建立stdio客户端连接并将其添加到异步上下文管理器中</span><br><span class="line">        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))</span><br><span class="line">        self.stdio, self.write = stdio_transport</span><br><span class="line">        </span><br><span class="line">        # 创建客户端会话并将其添加到异步上下文管理器中</span><br><span class="line">        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))</span><br><span class="line"></span><br><span class="line">        # 初始化会话</span><br><span class="line">        await self.session.initialize()</span><br><span class="line"></span><br><span class="line">        # 列出可用的工具</span><br><span class="line">        response = await self.session.list_tools()</span><br><span class="line">        tools = response.tools</span><br><span class="line">        </span><br><span class="line">        # 打印连接的服务器提供的工具列表</span><br><span class="line">        print(&quot;\n已连接到服务器，可用工具:&quot;, [tool.name for tool in tools])</span><br><span class="line"></span><br><span class="line">    async def process_query(self, query: str) -&gt; str:</span><br><span class="line">        &quot;&quot;&quot;使用Qwen和可用工具处理查询&quot;&quot;&quot;</span><br><span class="line">        # 构建消息列表</span><br><span class="line">        messages = [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: query</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        # 获取可用工具列表并转换为OpenAI格式</span><br><span class="line">        response = await self.session.list_tools()</span><br><span class="line">        available_tools = []</span><br><span class="line">        for tool in response.tools:</span><br><span class="line">            schema = tool.inputSchema</span><br><span class="line">            if isinstance(schema, str):</span><br><span class="line">                schema = json.loads(schema)</span><br><span class="line">            if isinstance(schema, dict) and &quot;properties&quot; in schema:</span><br><span class="line">                schema = &#123;&quot;type&quot;: &quot;object&quot;, **schema&#125;</span><br><span class="line"></span><br><span class="line">            available_tools.append(&#123;</span><br><span class="line">                &quot;type&quot;: &quot;function&quot;,</span><br><span class="line">                &quot;function&quot;: &#123;</span><br><span class="line">                    &quot;name&quot;: tool.name,</span><br><span class="line">                    &quot;description&quot;: tool.description,</span><br><span class="line">                    &quot;parameters&quot;: schema</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">        # 第一次调用模型</span><br><span class="line">        response = self.anthropic.chat.completions.create(</span><br><span class="line">            model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">            max_tokens=1000,</span><br><span class="line">            messages=messages,</span><br><span class="line">            tools=available_tools,</span><br><span class="line">            extra_body=&#123;&quot;enable_thinking&quot;: False&#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        final_text = []</span><br><span class="line">        message = response.choices[0].message</span><br><span class="line"></span><br><span class="line">        # 处理文本内容</span><br><span class="line">        if message.content:</span><br><span class="line">            final_text.append(message.content)</span><br><span class="line"></span><br><span class="line">        # 处理工具调用</span><br><span class="line">        if message.tool_calls:</span><br><span class="line">            for tool_call in message.tool_calls:</span><br><span class="line">                tool_name = tool_call.function.name</span><br><span class="line">                tool_args = json.loads(tool_call.function.arguments)</span><br><span class="line">                </span><br><span class="line">                # 执行工具调用</span><br><span class="line">                result = await self.session.call_tool(tool_name, tool_args)</span><br><span class="line">                final_text.append(f&quot;[调用工具 &#123;tool_name&#125;，参数 &#123;tool_args&#125;]&quot;)</span><br><span class="line">                </span><br><span class="line">                # 处理工具结果</span><br><span class="line">                tool_result_content = &quot;&quot;</span><br><span class="line">                if result.content:</span><br><span class="line">                    for item in result.content:</span><br><span class="line">                        if hasattr(item, &#x27;type&#x27;) and item.type == &#x27;text&#x27;:</span><br><span class="line">                            tool_result_content += item.text</span><br><span class="line">                        else:</span><br><span class="line">                            tool_result_content += str(item)</span><br><span class="line"></span><br><span class="line">                # 添加助手消息到历史</span><br><span class="line">                messages.append(&#123;</span><br><span class="line">                    &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                    &quot;content&quot;: None,</span><br><span class="line">                    &quot;tool_calls&quot;: [tool_call]</span><br><span class="line">                &#125;)</span><br><span class="line">                </span><br><span class="line">                # 添加工具执行结果到历史</span><br><span class="line">                messages.append(&#123;</span><br><span class="line">                    &quot;role&quot;: &quot;tool&quot;,</span><br><span class="line">                    &quot;tool_call_id&quot;: tool_call.id,</span><br><span class="line">                    &quot;content&quot;: tool_result_content</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">                # 再次调用模型</span><br><span class="line">                response = self.anthropic.chat.completions.create(</span><br><span class="line">                    model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">                    max_tokens=1000,</span><br><span class="line">                    messages=messages,</span><br><span class="line">                    tools=available_tools,</span><br><span class="line">                    extra_body=&#123;&quot;enable_thinking&quot;: False&#125;</span><br><span class="line">                )</span><br><span class="line">                </span><br><span class="line">                # 处理最终响应</span><br><span class="line">                if response.choices and response.choices[0].message.content:</span><br><span class="line">                    final_text.append(response.choices[0].message.content)</span><br><span class="line"></span><br><span class="line">        return &quot;\n&quot;.join(final_text)</span><br><span class="line"></span><br><span class="line">    async def chat_loop(self):</span><br><span class="line">        &quot;&quot;&quot;运行交互式聊天循环&quot;&quot;&quot;</span><br><span class="line">        print(&quot;\nMCP客户端已启动!&quot;)</span><br><span class="line">        print(&quot;输入您的问题或输入&#x27;quit&#x27;退出。&quot;)</span><br><span class="line"></span><br><span class="line">        while True:  # 无限循环，持续接收用户输入</span><br><span class="line">            try:</span><br><span class="line">                query = input(&quot;\n问题: &quot;).strip()  # 获取用户输入并去除首尾空格</span><br><span class="line"></span><br><span class="line">                if query.lower() == &#x27;quit&#x27;:  # 如果用户输入&#x27;quit&#x27;（不区分大小写）</span><br><span class="line">                    break  # 退出循环</span><br><span class="line"></span><br><span class="line">                # 处理用户查询并获取响应</span><br><span class="line">                response = await self.process_query(query)</span><br><span class="line">                print(&quot;\n&quot; + response)  # 打印AI响应结果</span><br><span class="line"></span><br><span class="line">            except Exception as e:  # 捕获所有异常</span><br><span class="line">                print(f&quot;\n错误: &#123;str(e)&#125;&quot;)  # 打印错误信息</span><br><span class="line">                import traceback</span><br><span class="line">                traceback.print_exc()  # 打印详细错误信息</span><br><span class="line"></span><br><span class="line">    async def cleanup(self):</span><br><span class="line">        &quot;&quot;&quot;清理资源&quot;&quot;&quot;</span><br><span class="line">        await self.exit_stack.aclose()  # 异步关闭所有在exit_stack中管理的资源</span><br><span class="line"></span><br><span class="line">async def main():</span><br><span class="line">    # 检查命令行参数数量，如果少于2个则显示使用说明</span><br><span class="line">    if len(sys.argv) &lt; 2:</span><br><span class="line">        print(&quot;用法: python client.py &lt;服务器脚本路径&gt;&quot;)</span><br><span class="line">        sys.exit(1)  # 退出程序，返回错误码1</span><br><span class="line"></span><br><span class="line">    # 创建MCP客户端实例</span><br><span class="line">    client = MCPClient()</span><br><span class="line">    try:</span><br><span class="line">        # 连接到服务器，sys.argv[1]是第一个命令行参数（服务器脚本路径）</span><br><span class="line">        await client.connect_to_server(sys.argv[1])</span><br><span class="line">        # 启动交互式聊天循环</span><br><span class="line">        await client.chat_loop()</span><br><span class="line">    finally:</span><br><span class="line">        # 确保程序结束时清理资源</span><br><span class="line">        await client.cleanup()</span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 运行异步主函数</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>
<h3 id="openai和claude在工具调用的差异">openai和claude在工具调用的差异</h3>
<ol type="1">
<li><strong>工具格式转换修复</strong></li>
</ol>
<p><strong>问题</strong>：MCP工具格式与OpenAI API不兼容
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原错误格式</span></span><br><span class="line">available_tools = [&#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">    <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">    <span class="string">&quot;input_schema&quot;</span>: tool.inputSchema</span><br><span class="line">&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后格式（符合OpenAI规范）</span></span><br><span class="line">available_tools = [&#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">    <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">        <span class="string">&quot;parameters&quot;</span>: schema  <span class="comment"># 正确的JSON Schema格式</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure></p>
<ol start="2" type="1">
<li><strong>API响应处理修复</strong></li>
</ol>
<p><strong>问题</strong>：错误访问了OpenAI响应对象的属性
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原错误代码</span></span><br><span class="line"><span class="keyword">for</span> content <span class="keyword">in</span> response.content:  <span class="comment"># ❌ response没有content属性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后代码</span></span><br><span class="line">message = response.choices[<span class="number">0</span>].message  <span class="comment"># ✅ 正确的访问路径</span></span><br><span class="line"><span class="keyword">if</span> message.content:</span><br><span class="line">    final_text.append(message.content)</span><br><span class="line"><span class="keyword">if</span> message.tool_calls:</span><br><span class="line">    <span class="keyword">for</span> tool_call <span class="keyword">in</span> message.tool_calls:</span><br><span class="line">        <span class="comment"># 处理工具调用</span></span><br></pre></td></tr></table></figure></p>
<ol start="3" type="1">
<li><strong>工具调用结果处理修复</strong></li>
</ol>
<p><strong>问题</strong>：错误处理MCP工具调用返回的结果结构
<strong>修复</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原错误代码</span></span><br><span class="line"><span class="string">&quot;content&quot;</span>: result.content  <span class="comment"># ❌ 可能包含复杂对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后代码</span></span><br><span class="line">tool_result_content = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> result.content:</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> result.content:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(item, <span class="string">&#x27;type&#x27;</span>) <span class="keyword">and</span> item.<span class="built_in">type</span> == <span class="string">&#x27;text&#x27;</span>:</span><br><span class="line">            tool_result_content += item.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tool_result_content += <span class="built_in">str</span>(item)</span><br></pre></td></tr></table></figure>
<ol start="4" type="1">
<li><strong>消息历史构建修复</strong></li>
</ol>
<p><strong>问题</strong>：工具调用后消息历史格式不正确
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 正确的消息历史格式</span></span><br><span class="line">messages.append(&#123;</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>,</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: <span class="literal">None</span>,</span><br><span class="line">    <span class="string">&quot;tool_calls&quot;</span>: [tool_call]</span><br><span class="line">&#125;)</span><br><span class="line">messages.append(&#123;</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">    <span class="string">&quot;tool_call_id&quot;</span>: tool_call.<span class="built_in">id</span>,</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: tool_result_content</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p>
<ol start="5" type="1">
<li><strong>JSON Schema兼容性处理</strong></li>
</ol>
<p><strong>问题</strong>：MCP返回的schema可能缺少必要的根类型定义
<strong>修复</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">schema = tool.inputSchema</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(schema, <span class="built_in">str</span>):</span><br><span class="line">    schema = json.loads(schema)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(schema, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&quot;properties&quot;</span> <span class="keyword">in</span> schema:</span><br><span class="line">    schema = &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>, **schema&#125;  <span class="comment"># 确保有根类型</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>mcp</category>
      </categories>
      <tags>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第一章：第三节探索性数据分析</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%89%E8%8A%82%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>在前面我们已经学习了Pandas基础，知道利用Pandas读取csv数据的增删查改，今天我们要学习的就是<strong>探索性数据分析</strong>，主要介绍如何利用Pandas进行排序、算术计算以及计算描述函数describe()的使用。</p>
<h1 id="第一章探索性数据分析">1 第一章：探索性数据分析</h1>
<h4 id="开始之前导入numpypandas包和数据">开始之前，导入numpy、pandas包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载所需的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#载入之前保存的train_chinese.csv数据，关于泰坦尼克号的任务，我们就使用这个数据</span></span><br><span class="line">train_chinese = pd.read_csv(<span class="string">&#x27;./titanic/train_chinese.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="了解你的数据吗">1.6 了解你的数据吗？</h3>
<p>教材《Python for Data Analysis》第五章</p>
<h4 id="任务一利用pandas对示例数据进行排序要求升序">1.6.1
任务一：利用Pandas对示例数据进行排序，要求升序</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 具体请看《利用Python进行数据分析》第五章 排序和排名 部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己构建一个都为数字的DataFrame数据</span></span><br><span class="line">frame = pd.DataFrame(np.arange(<span class="number">8</span>).reshape((<span class="number">2</span>, <span class="number">4</span>)), </span><br><span class="line">                     index=[<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;1&#x27;</span>], </span><br><span class="line">                     columns=[<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">frame</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
</tr>
</tbody>
</table>
<p>【代码解析】</p>
<p>pd.DataFrame() ：创建一个DataFrame对象</p>
<p>np.arange(8).reshape((2, 4)) :
生成一个二维数组（2*4）,第一列：0，1，2，3 第二列：4，5，6，7</p>
<p>index=[’2, 1] ：DataFrame 对象的索引列</p>
<p>columns=[‘d’, ‘a’, ‘b’, ‘c’] ：DataFrame 对象的索引行</p>
<p>【问题】：大多数时候我们都是想根据列的值来排序,所以将你构建的DataFrame中的数据根据某一列，升序排列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#回答代码</span></span><br><span class="line"><span class="comment">#指定按列名 &#x27;b&#x27; 的值进行排序，ascending=False设置降序排列（默认是升序）</span></span><br><span class="line">frame.sort_values(by=<span class="string">&#x27;b&#x27;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<p>【思考】通过书本你能说出Pandas对DataFrame数据的其他排序方式吗？</p>
<p>【总结】下面将不同的排序方式做一个总结</p>
<p>1.让行索引升序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame.sort_index(ascending=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<p>2.让列索引升序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line"><span class="comment">#axis=1指定对 列索引（columns） 进行排序（默认 axis=0 是对行索引排序）。</span></span><br><span class="line">frame.sort_index(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
<th>
d
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
<p>3.让列索引降序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame.sort_index(axis=<span class="number">1</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
c
</th>
<th>
b
</th>
<th>
a
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
3
</td>
<td>
2
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
7
</td>
<td>
6
</td>
<td>
5
</td>
</tr>
</tbody>
</table>
<p>4.让任选两列数据同时降序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame.sort_values(by=[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>],ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<h4 id="任务二对泰坦尼克号数据trian.csv按票价和年龄两列进行综合排序降序排列从这个数据中你可以分析出什么">1.6.2
任务二：对泰坦尼克号数据（trian.csv）按票价和年龄两列进行综合排序（降序排列），从这个数据中你可以分析出什么？</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">在开始我们已经导入了train_chinese.csv数据，而且前面我们也学习了导入数据过程，根据上面学习，我们直接对目标列进行排序即可</span></span><br><span class="line"><span class="string">head(20) : 读取前20条数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">train_chinese.sort_values(by=[<span class="string">&#x27;票价&#x27;</span>,<span class="string">&#x27;年龄&#x27;</span>], ascending=<span class="literal">False</span>).head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
乘客ID
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
姓名
</th>
<th>
性别
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
船票信息
</th>
<th>
票价
</th>
<th>
客舱
</th>
<th>
登船港口
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
679
</th>
<td>
680
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cardeza, Mr. Thomas Drake Martinez
</td>
<td>
male
</td>
<td>
36.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
PC 17755
</td>
<td>
512.3292
</td>
<td>
B51 B53 B55
</td>
<td>
C
</td>
</tr>
<tr>
<th>
258
</th>
<td>
259
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Ward, Miss. Anna
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17755
</td>
<td>
512.3292
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
<tr>
<th>
737
</th>
<td>
738
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Lesurer, Mr. Gustave J
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17755
</td>
<td>
512.3292
</td>
<td>
B101
</td>
<td>
C
</td>
</tr>
<tr>
<th>
438
</th>
<td>
439
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Fortune, Mr. Mark
</td>
<td>
male
</td>
<td>
64.0
</td>
<td>
1
</td>
<td>
4
</td>
<td>
19950
</td>
<td>
263.0000
</td>
<td>
C23 C25 C27
</td>
<td>
S
</td>
</tr>
<tr>
<th>
341
</th>
<td>
342
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Fortune, Miss. Alice Elizabeth
</td>
<td>
female
</td>
<td>
24.0
</td>
<td>
3
</td>
<td>
2
</td>
<td>
19950
</td>
<td>
263.0000
</td>
<td>
C23 C25 C27
</td>
<td>
S
</td>
</tr>
<tr>
<th>
88
</th>
<td>
89
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Fortune, Miss. Mabel Helen
</td>
<td>
female
</td>
<td>
23.0
</td>
<td>
3
</td>
<td>
2
</td>
<td>
19950
</td>
<td>
263.0000
</td>
<td>
C23 C25 C27
</td>
<td>
S
</td>
</tr>
<tr>
<th>
27
</th>
<td>
28
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Fortune, Mr. Charles Alexander
</td>
<td>
male
</td>
<td>
19.0
</td>
<td>
3
</td>
<td>
2
</td>
<td>
19950
</td>
<td>
263.0000
</td>
<td>
C23 C25 C27
</td>
<td>
S
</td>
</tr>
<tr>
<th>
742
</th>
<td>
743
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Ryerson, Miss. Susan Parker “Suzette”
</td>
<td>
female
</td>
<td>
21.0
</td>
<td>
2
</td>
<td>
2
</td>
<td>
PC 17608
</td>
<td>
262.3750
</td>
<td>
B57 B59 B63 B66
</td>
<td>
C
</td>
</tr>
<tr>
<th>
311
</th>
<td>
312
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Ryerson, Miss. Emily Borie
</td>
<td>
female
</td>
<td>
18.0
</td>
<td>
2
</td>
<td>
2
</td>
<td>
PC 17608
</td>
<td>
262.3750
</td>
<td>
B57 B59 B63 B66
</td>
<td>
C
</td>
</tr>
<tr>
<th>
299
</th>
<td>
300
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Baxter, Mrs. James (Helene DeLaudeniere Chaput)
</td>
<td>
female
</td>
<td>
50.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
PC 17558
</td>
<td>
247.5208
</td>
<td>
B58 B60
</td>
<td>
C
</td>
</tr>
<tr>
<th>
118
</th>
<td>
119
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Baxter, Mr. Quigg Edmond
</td>
<td>
male
</td>
<td>
24.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
PC 17558
</td>
<td>
247.5208
</td>
<td>
B58 B60
</td>
<td>
C
</td>
</tr>
<tr>
<th>
380
</th>
<td>
381
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Bidois, Miss. Rosalie
</td>
<td>
female
</td>
<td>
42.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17757
</td>
<td>
227.5250
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
<tr>
<th>
716
</th>
<td>
717
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Endres, Miss. Caroline Louise
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17757
</td>
<td>
227.5250
</td>
<td>
C45
</td>
<td>
C
</td>
</tr>
<tr>
<th>
700
</th>
<td>
701
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Astor, Mrs. John Jacob (Madeleine Talmadge Force)
</td>
<td>
female
</td>
<td>
18.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17757
</td>
<td>
227.5250
</td>
<td>
C62 C64
</td>
<td>
C
</td>
</tr>
<tr>
<th>
557
</th>
<td>
558
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Robbins, Mr. Victor
</td>
<td>
male
</td>
<td>
NaN
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17757
</td>
<td>
227.5250
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
<tr>
<th>
527
</th>
<td>
528
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Farthing, Mr. John
</td>
<td>
male
</td>
<td>
NaN
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17483
</td>
<td>
221.7792
</td>
<td>
C95
</td>
<td>
S
</td>
</tr>
<tr>
<th>
377
</th>
<td>
378
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Widener, Mr. Harry Elkins
</td>
<td>
male
</td>
<td>
27.0
</td>
<td>
0
</td>
<td>
2
</td>
<td>
113503
</td>
<td>
211.5000
</td>
<td>
C82
</td>
<td>
C
</td>
</tr>
<tr>
<th>
779
</th>
<td>
780
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Robert, Mrs. Edward Scott (Elisabeth Walton Mc…
</td>
<td>
female
</td>
<td>
43.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
24160
</td>
<td>
211.3375
</td>
<td>
B3
</td>
<td>
S
</td>
</tr>
<tr>
<th>
730
</th>
<td>
731
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Allen, Miss. Elisabeth Walton
</td>
<td>
female
</td>
<td>
29.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
24160
</td>
<td>
211.3375
</td>
<td>
B5
</td>
<td>
S
</td>
</tr>
<tr>
<th>
689
</th>
<td>
690
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Madill, Miss. Georgette Alexandra
</td>
<td>
female
</td>
<td>
15.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
24160
</td>
<td>
211.3375
</td>
<td>
B5
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【思考】排序后，如果我们仅仅关注年龄和票价两列。根据常识我知道发现票价越高的应该客舱越好，所以我们会明显看出，票价前20的乘客中存活的有14人，这是相当高的一个比例，那么我们后面是不是可以进一步分析一下票价和存活之间的关系，年龄和存活之间的关系呢？当你开始发现数据之间的关系了，数据分析就开始了。</p>
<p>当然，这只是我的想法，你还可以有更多想法，欢迎写在你的学习笔记中。</p>
<p><strong>多做几个数据的排序</strong></p>
<h4 id="任务三利用pandas进行算术计算计算两个dataframe数据相加结果">1.6.3
任务三：利用Pandas进行算术计算，计算两个DataFrame数据相加结果</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 具体请看《利用Python进行数据分析》第五章 算术运算与数据对齐 部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己构建两个都为数字的DataFrame数据</span></span><br><span class="line"></span><br><span class="line">frame1_a = pd.DataFrame(np.arange(<span class="number">9.</span>).reshape(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                     columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">                     index=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>])</span><br><span class="line">frame1_b = pd.DataFrame(np.arange(<span class="number">12.</span>).reshape(<span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">                     columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">                     index=[<span class="string">&#x27;first&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;second&#x27;</span>])</span><br><span class="line">frame1_a, frame1_b</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>(         a    b    c
 one    0.0  1.0  2.0
 two    3.0  4.0  5.0
 three  6.0  7.0  8.0,
           a     e     c
 first   0.0   1.0   2.0
 one     3.0   4.0   5.0
 two     6.0   7.0   8.0
 second  9.0  10.0  11.0)</code></pre>
<p>将frame_a和frame_b进行相加</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame1_a+frame1_b</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
<th>
e
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
first
</th>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
one
</th>
<td>
3.0
</td>
<td>
NaN
</td>
<td>
7.0
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
second
</th>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
three
</th>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
two
</th>
<td>
9.0
</td>
<td>
NaN
</td>
<td>
13.0
</td>
<td>
NaN
</td>
</tr>
</tbody>
</table>
<p>【提醒】两个DataFrame相加后，会返回一个新的DataFrame，对应的行和列的值会相加，没有对应的会变成空值NaN。<br>
当然，DataFrame还有很多算术运算，如减法，除法等，有兴趣的同学可以看《利用Python进行数据分析》第五章
算术运算与数据对齐 部分，多在网络上查找相关学习资料。</p>
<h4 id="任务四通过泰坦尼克号数据如何计算出在船上最大的家族有多少人">1.6.4
任务四：通过泰坦尼克号数据如何计算出在船上最大的家族有多少人？</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">还是用之前导入的chinese_train.csv如果我们想看看在船上，最大的家族有多少人（‘兄弟姐妹个数’+‘父母子女个数’），我们该怎么做呢？</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">max</span>(train_chinese[<span class="string">&#x27;兄弟姐妹个数&#x27;</span>] + train_chinese[<span class="string">&#x27;父母子女个数&#x27;</span>])</span><br></pre></td></tr></table></figure>
<pre><code>10</code></pre>
<p>【提醒】我们只需找出”兄弟姐妹个数“和”父母子女个数“之和最大的数，当然你还可以想出很多方法和思考角度，欢迎你来说出你的看法。</p>
<p><strong>多做几个数据的相加，看看你能分析出什么？</strong></p>
<h4 id="任务五学会使用pandas-describe函数查看数据基本统计信息">1.6.5
任务五：学会使用Pandas describe()函数查看数据基本统计信息</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#(1) 关键知识点示例做一遍（简单数据）</span></span><br><span class="line"><span class="comment"># 具体请看《利用Python进行数据分析》第五章 汇总和计算描述统计 部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己构建一个有数字有空值的DataFrame数据</span></span><br><span class="line"></span><br><span class="line">frame2 = pd.DataFrame([[<span class="number">1.4</span>, np.nan], </span><br><span class="line">                       [<span class="number">7.1</span>, -<span class="number">4.5</span>],</span><br><span class="line">                       [np.nan, np.nan], </span><br><span class="line">                       [<span class="number">0.75</span>, -<span class="number">1.3</span>]</span><br><span class="line">                      ], index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>], columns=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>])</span><br><span class="line">frame2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
one
</th>
<th>
two
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
a
</th>
<td>
1.40
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
b
</th>
<td>
7.10
</td>
<td>
-4.5
</td>
</tr>
<tr>
<th>
c
</th>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
d
</th>
<td>
0.75
</td>
<td>
-1.3
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame2.describe()  <span class="comment">#描述统计</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">count : 样本数据大小</span></span><br><span class="line"><span class="string">mean : 样本数据的平均值</span></span><br><span class="line"><span class="string">std : 样本数据的标准差</span></span><br><span class="line"><span class="string">min : 样本数据的最小值</span></span><br><span class="line"><span class="string">25% : 样本数据25%的时候的值</span></span><br><span class="line"><span class="string">50% : 样本数据50%的时候的值</span></span><br><span class="line"><span class="string">75% : 样本数据75%的时候的值</span></span><br><span class="line"><span class="string">max : 样本数据的最大值</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
one
</th>
<th>
two
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
count
</th>
<td>
3.000000
</td>
<td>
2.000000
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
3.083333
</td>
<td>
-2.900000
</td>
</tr>
<tr>
<th>
std
</th>
<td>
3.493685
</td>
<td>
2.262742
</td>
</tr>
<tr>
<th>
min
</th>
<td>
0.750000
</td>
<td>
-4.500000
</td>
</tr>
<tr>
<th>
25%
</th>
<td>
1.075000
</td>
<td>
-3.700000
</td>
</tr>
<tr>
<th>
50%
</th>
<td>
1.400000
</td>
<td>
-2.900000
</td>
</tr>
<tr>
<th>
75%
</th>
<td>
4.250000
</td>
<td>
-2.100000
</td>
</tr>
<tr>
<th>
max
</th>
<td>
7.100000
</td>
<td>
-1.300000
</td>
</tr>
</tbody>
</table>

<p>调用 describe 函数，观察frame2的数据基本信息</p>
<h4 id="任务六分别看看泰坦尼克号数据集中-票价父母子女-这列数据的基本统计数据你能发现什么">1.6.6
任务六：分别看看泰坦尼克号数据集中 票价、父母子女
这列数据的基本统计数据，你能发现什么？</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">看看泰坦尼克号数据集中 票价 这列数据的基本统计数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<pre><code>&#39;\n看看泰坦尼克号数据集中 票价 这列数据的基本统计数据\n&#39;</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">train_chinese[<span class="string">&#x27;票价&#x27;</span>].describe()</span><br></pre></td></tr></table></figure>
<pre><code>count    891.000000
mean      32.204208
std       49.693429
min        0.000000
25%        7.910400
50%       14.454200
75%       31.000000
max      512.329200
Name: 票价, dtype: float64</code></pre>
<p>【思考】从上面数据我们可以看出， 一共有891个票价数据，
平均值约为：32.20， 标准差约为49.69，说明票价波动特别大，
25%的人的票价是低于7.91的，50%的人的票价低于14.45，75%的人的票价低于31.00，
票价最大值约为512.33，最小值为0。
当然，答案只是我的想法，你还可以有更多想法，欢迎写在你的学习笔记中。</p>
<p><strong>多做几个组数据的统计，看看你能分析出什么？</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写下你的其他分析</span></span><br><span class="line">train_chinese[<span class="string">&#x27;父母子女个数&#x27;</span>].describe()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>count    891.000000
mean       0.381594
std        0.806057
min        0.000000
25%        0.000000
50%        0.000000
75%        0.000000
max        6.000000
Name: 父母子女个数, dtype: float64</code></pre>
<p>【思考】有更多想法，欢迎写在你的学习笔记中。</p>
<p>【总结】本节中我们通过Pandas的一些内置函数对数据进行了初步统计查看，这个过程最重要的不是大家得掌握这些函数，而是看懂从这些函数出来的数据，构建自己的数据分析思维，这也是第一章最重要的点，希望大家学完第一章能对数据有个基本认识，了解自己在做什么，为什么这么做，后面的章节我们将开始对数据进行清洗，进一步分析。</p>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第一章：第一节数据载入及初步观察</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%80%E8%8A%82%E6%95%B0%E6%8D%AE%E8%BD%BD%E5%85%A5%E5%8F%8A%E5%88%9D%E6%AD%A5%E8%A7%82%E5%AF%9F-%E8%AF%BE%E7%A8%8B-checkpoint/</url>
    <content><![CDATA[<p><strong>复习</strong>:这门课程得主要目的是通过真实的数据，以实战的方式了解数据分析的流程和熟悉数据分析python的基本操作。知道了课程的目的之后，我们接下来我们要正式的开始数据分析的实战教学，完成kaggle上<a href="https://www.kaggle.com/c/titanic/overview">泰坦尼克的任务</a>，实战数据分析全流程。
这里有两份资料： 教材《Python for Data Analysis》和 baidu.com &amp;
google.com（善用搜索引擎）</p>
<h2 id="第一章数据载入及初步观察">1 第一章：数据载入及初步观察</h2>
<h3 id="载入数据">1.1 载入数据</h3>
<p>数据集下载 https://www.kaggle.com/c/titanic/overview</p>
<h4 id="任务一导入numpy和pandas">1.1.1 任务一：导入numpy和pandas</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【提示】如果加载失败，学会如何在你的python环境下安装numpy和pandas这两个库</p>
<h4 id="任务二载入数据">1.1.2 任务二：载入数据</h4>
<ol type="1">
<li>使用相对路径载入数据<br>
</li>
<li>使用绝对路径载入数据</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.getcwd()</span><br><span class="line">test=pd.read_csv(<span class="string">&#x27;./titanic/test.csv&#x27;</span>)</span><br><span class="line">train=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">abs_path_test=os.path.abspath(<span class="string">&#x27;./titanic/test.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(abs_path_test)</span><br><span class="line">test=pd.read_csv(abs_path_test)</span><br><span class="line">abs_path_train=os.path.abspath(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(abs_path_train)</span><br><span class="line">train=pd.read_csv(abs_path_train)</span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<pre><code>/workspace/WuTeachingAI/hands-on-data-analysis/myself/titanic/test.csv
/workspace/WuTeachingAI/hands-on-data-analysis/myself/titanic/train.csv</code></pre>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p>【提示】相对路径载入报错时，尝试使用os.getcwd()查看当前工作目录。<br>
【思考】知道数据加载的方法后，试试pd.read_csv()和pd.read_table()的不同，如果想让他们效果一样，需要怎么做？了解一下’.tsv’和’.csv’的不同，如何加载这两个数据集？<br>
【总结】加载的数据是所有工作的第一步，我们的工作会接触到不同的数据格式（eg:.csv;.tsv;.xlsx）,但是加载的方法和思路都是一样的，在以后工作和做项目的过程中，遇到之前没有碰到的问题，要多多查资料吗，使用googel，了解业务逻辑，明白输入和输出是什么。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pd.read_csv() 和 pd.read_table() 本质上非常相似，主要区别在于默认的分隔符参数。</span></span><br><span class="line"><span class="comment"># 通过显式设置 `sep` 参数，可以让它们处理各种以不同字符分隔的文本文件。</span></span><br><span class="line"><span class="comment"># &#x27;.csv&#x27; 文件用逗号分隔，&#x27;.tsv&#x27; 文件用制表符分隔。选择合适的pandas读取函数或正确设置`sep`参数即可加载。</span></span><br></pre></td></tr></table></figure>
<h4 id="任务三每1000行为一个数据模块逐块读取">1.1.3
任务三：每1000行为一个数据模块，逐块读取</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">chunker=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>,chunksize=<span class="number">1000</span>)</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> chunker:</span><br><span class="line">    <span class="built_in">print</span>(chunk)</span><br></pre></td></tr></table></figure>
<pre><code>     PassengerId  Survived  Pclass  \
0              1         0       3   
1              2         1       1   
2              3         1       3   
3              4         1       1   
4              5         0       3   
..           ...       ...     ...   
886          887         0       2   
887          888         1       1   
888          889         0       3   
889          890         1       1   
890          891         0       3   

                                                  Name     Sex   Age  SibSp  \
0                              Braund, Mr. Owen Harris    male  22.0      1   
1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   
2                               Heikkinen, Miss. Laina  female  26.0      0   
3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   
4                             Allen, Mr. William Henry    male  35.0      0   
..                                                 ...     ...   ...    ...   
886                              Montvila, Rev. Juozas    male  27.0      0   
887                       Graham, Miss. Margaret Edith  female  19.0      0   
888           Johnston, Miss. Catherine Helen &quot;Carrie&quot;  female   NaN      1   
889                              Behr, Mr. Karl Howell    male  26.0      0   
890                                Dooley, Mr. Patrick    male  32.0      0   

     Parch            Ticket     Fare Cabin Embarked  
0        0         A/5 21171   7.2500   NaN        S  
1        0          PC 17599  71.2833   C85        C  
2        0  STON/O2. 3101282   7.9250   NaN        S  
3        0            113803  53.1000  C123        S  
4        0            373450   8.0500   NaN        S  
..     ...               ...      ...   ...      ...  
886      0            211536  13.0000   NaN        S  
887      0            112053  30.0000   B42        S  
888      2        W./C. 6607  23.4500   NaN        S  
889      0            111369  30.0000  C148        C  
890      0            370376   7.7500   NaN        Q  

[891 rows x 12 columns]</code></pre>
<p>【思考】什么是逐块读取？为什么要逐块读取呢？</p>
<p>【提示】大家可以chunker(数据块)是什么类型？用<code>for</code>循环打印出来出处具体的样子是什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **什么是逐块读取？**</span></span><br><span class="line"><span class="comment"># 逐块读取（Chunking）是指在读取大型数据集时，不一次性将整个文件加载到内存中，而是将文件分成若干个小的数据块（chunks），每次只加载和处理一个数据块。</span></span><br><span class="line"><span class="comment"># 在pandas中，可以通过在 `pd.read_csv()` 或类似的读取函数中设置 `chunksize` 参数来实现逐块读取。`chunksize` 定义了每个数据块包含的行数。</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># **为什么要逐块读取呢？**</span></span><br><span class="line"><span class="comment"># 1.  **处理内存不足的大文件**：</span></span><br><span class="line"><span class="comment">#     *   当数据集非常大，其大小超过了计算机可用内存时，一次性加载整个文件会导致内存溢出错误（MemoryError）。逐块读取允许我们分批处理数据，每次只在内存中保留一小部分数据，从而有效避免内存问题。</span></span><br><span class="line"><span class="comment"># 2.  **提高处理效率（特定场景下）**：</span></span><br><span class="line"><span class="comment">#     *   对于某些类型的操作，例如对数据进行迭代处理、过滤或聚合，如果不需要同时访问所有数据，逐块处理可以使得程序更快地开始处理数据，而不是等待整个大文件加载完毕。</span></span><br><span class="line"><span class="comment">#     *   可以边读取边处理，实现流式数据处理的效果。</span></span><br><span class="line"><span class="comment"># 3.  **数据清洗和预处理**：</span></span><br><span class="line"><span class="comment">#     *   在对大型原始数据进行初步的清洗、转换或特征工程时，可以逐块进行，将处理后的数据块追加到新的存储中，或者在每个块上计算统计量并逐步累积。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务四将表头改成中文索引改为乘客id-对于某些英文资料我们可以通过翻译来更直观的熟悉我们的数据">1.1.4
任务四：将表头改成中文，索引改为乘客ID
[对于某些英文资料，我们可以通过翻译来更直观的熟悉我们的数据]</h4>
<p>PassengerId =&gt; 乘客ID<br>
Survived =&gt; 是否幸存<br>
Pclass =&gt; 乘客等级(1/2/3等舱位)<br>
Name =&gt; 乘客姓名<br>
Sex =&gt; 性别<br>
Age =&gt; 年龄<br>
SibSp =&gt; 堂兄弟/妹个数<br>
Parch =&gt; 父母与小孩个数<br>
Ticket =&gt; 船票信息<br>
Fare =&gt; 票价<br>
Cabin =&gt; 客舱<br>
Embarked =&gt; 登船港口</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将&quot;乘客ID&quot;列作为行索引</span></span><br><span class="line">df=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>,names=[<span class="string">&#x27;乘客ID&#x27;</span>,<span class="string">&#x27;是否幸存&#x27;</span>,<span class="string">&#x27;仓位等级&#x27;</span>,<span class="string">&#x27;姓名&#x27;</span>,<span class="string">&#x27;性别&#x27;</span>,<span class="string">&#x27;年龄&#x27;</span>,<span class="string">&#x27;兄弟姐妹个数&#x27;</span>,<span class="string">&#x27;父母子女个数&#x27;</span>,<span class="string">&#x27;船票信息&#x27;</span>,<span class="string">&#x27;票价&#x27;</span>,<span class="string">&#x27;客舱&#x27;</span>,<span class="string">&#x27;登船港口&#x27;</span>],index_col=<span class="string">&#x27;乘客ID&#x27;</span>,header=<span class="number">0</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
姓名
</th>
<th>
性别
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
船票信息
</th>
<th>
票价
</th>
<th>
客舱
</th>
<th>
登船港口
</th>
</tr>
<tr>
<th>
乘客ID
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p>【思考】所谓将表头改为中文其中一个思路是：将英文列名表头替换成中文。还有其他的方法吗？</p>
<h3 id="初步观察">1.2 初步观察</h3>
<p>导入数据后，你可能要对数据的整体结构和样例进行概览，比如说，数据大小、有多少列，各列都是什么格式的，是否包含null等</p>
<h4 id="任务一查看数据的基本信息">1.2.1 任务一：查看数据的基本信息</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.info()</span><br><span class="line">df.describe()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 891 entries, 1 to 891
Data columns (total 11 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   是否幸存    891 non-null    int64  
 1   仓位等级    891 non-null    int64  
 2   姓名      891 non-null    object 
 3   性别      891 non-null    object 
 4   年龄      714 non-null    float64
 5   兄弟姐妹个数  891 non-null    int64  
 6   父母子女个数  891 non-null    int64  
 7   船票信息    891 non-null    object 
 8   票价      891 non-null    float64
 9   客舱      204 non-null    object 
 10  登船港口    889 non-null    object 
dtypes: float64(2), int64(4), object(5)
memory usage: 83.5+ KB</code></pre>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
票价
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
count
</th>
<td>
891.000000
</td>
<td>
891.000000
</td>
<td>
714.000000
</td>
<td>
891.000000
</td>
<td>
891.000000
</td>
<td>
891.000000
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
0.383838
</td>
<td>
2.308642
</td>
<td>
29.699118
</td>
<td>
0.523008
</td>
<td>
0.381594
</td>
<td>
32.204208
</td>
</tr>
<tr>
<th>
std
</th>
<td>
0.486592
</td>
<td>
0.836071
</td>
<td>
14.526497
</td>
<td>
1.102743
</td>
<td>
0.806057
</td>
<td>
49.693429
</td>
</tr>
<tr>
<th>
min
</th>
<td>
0.000000
</td>
<td>
1.000000
</td>
<td>
0.420000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
</tr>
<tr>
<th>
25%
</th>
<td>
0.000000
</td>
<td>
2.000000
</td>
<td>
20.125000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
<td>
7.910400
</td>
</tr>
<tr>
<th>
50%
</th>
<td>
0.000000
</td>
<td>
3.000000
</td>
<td>
28.000000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
<td>
14.454200
</td>
</tr>
<tr>
<th>
75%
</th>
<td>
1.000000
</td>
<td>
3.000000
</td>
<td>
38.000000
</td>
<td>
1.000000
</td>
<td>
0.000000
</td>
<td>
31.000000
</td>
</tr>
<tr>
<th>
max
</th>
<td>
1.000000
</td>
<td>
3.000000
</td>
<td>
80.000000
</td>
<td>
8.000000
</td>
<td>
6.000000
</td>
<td>
512.329200
</td>
</tr>
</tbody>
</table>
<p>【提示】有多个函数可以这样做，你可以做一下总结</p>
<h4 id="任务二观察表格前10行的数据和后15行的数据">1.2.2
任务二：观察表格前10行的数据和后15行的数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.head(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
姓名
</th>
<th>
性别
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
船票信息
</th>
<th>
票价
</th>
<th>
客舱
</th>
<th>
登船港口
</th>
</tr>
<tr>
<th>
乘客ID
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
6
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Moran, Mr. James
</td>
<td>
male
</td>
<td>
NaN
</td>
<td>
0
</td>
<td>
0
</td>
<td>
330877
</td>
<td>
8.4583
</td>
<td>
NaN
</td>
<td>
Q
</td>
</tr>
<tr>
<th>
7
</th>
<td>
0
</td>
<td>
1
</td>
<td>
McCarthy, Mr. Timothy J
</td>
<td>
male
</td>
<td>
54.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
17463
</td>
<td>
51.8625
</td>
<td>
E46
</td>
<td>
S
</td>
</tr>
<tr>
<th>
8
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Palsson, Master. Gosta Leonard
</td>
<td>
male
</td>
<td>
2.0
</td>
<td>
3
</td>
<td>
1
</td>
<td>
349909
</td>
<td>
21.0750
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
9
</th>
<td>
1
</td>
<td>
3
</td>
<td>
Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)
</td>
<td>
female
</td>
<td>
27.0
</td>
<td>
0
</td>
<td>
2
</td>
<td>
347742
</td>
<td>
11.1333
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
10
</th>
<td>
1
</td>
<td>
2
</td>
<td>
Nasser, Mrs. Nicholas (Adele Achem)
</td>
<td>
female
</td>
<td>
14.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
237736
</td>
<td>
30.0708
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
<tr>
<th>
11
</th>
<td>
1
</td>
<td>
3
</td>
<td>
Sandstrom, Miss. Marguerite Rut
</td>
<td>
female
</td>
<td>
4.0
</td>
<td>
1
</td>
<td>
1
</td>
<td>
PP 9549
</td>
<td>
16.7000
</td>
<td>
G6
</td>
<td>
S
</td>
</tr>
<tr>
<th>
12
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Bonnell, Miss. Elizabeth
</td>
<td>
female
</td>
<td>
58.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
113783
</td>
<td>
26.5500
</td>
<td>
C103
</td>
<td>
S
</td>
</tr>
<tr>
<th>
13
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Saundercock, Mr. William Henry
</td>
<td>
male
</td>
<td>
20.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
A/5. 2151
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
14
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Andersson, Mr. Anders Johan
</td>
<td>
male
</td>
<td>
39.0
</td>
<td>
1
</td>
<td>
5
</td>
<td>
347082
</td>
<td>
31.2750
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
15
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Vestrom, Miss. Hulda Amanda Adolfina
</td>
<td>
female
</td>
<td>
14.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
350406
</td>
<td>
7.8542
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.tail()</span><br></pre></td></tr></table></figure>
<h4 id="任务三判断数据是否为空为空的地方返回true其余地方返回false">1.2.4
任务三：判断数据是否为空，为空的地方返回True，其余地方返回False</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.isnull().head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
姓名
</th>
<th>
性别
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
船票信息
</th>
<th>
票价
</th>
<th>
客舱
</th>
<th>
登船港口
</th>
</tr>
<tr>
<th>
乘客ID
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
<td>
False
</td>
</tr>
<tr>
<th>
2
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
</tr>
<tr>
<th>
3
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
<td>
False
</td>
</tr>
<tr>
<th>
4
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
</tr>
<tr>
<th>
5
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
<td>
False
</td>
</tr>
</tbody>
</table>
<p>【总结】上面的操作都是数据分析中对于数据本身的观察</p>
<p>【思考】对于一个数据，还可以从哪些方面来观察？找找答案，这个将对下面的数据分析有很大的帮助</p>
<h3 id="保存数据">1.3 保存数据</h3>
<h4 id="任务一将你加载并做出改变的数据在工作目录下保存为一个新文件train_chinese.csv">1.3.1
任务一：将你加载并做出改变的数据，在工作目录下保存为一个新文件train_chinese.csv</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 注意：不同的操作系统保存下来可能会有乱码。大家可以加入`encoding=&#x27;GBK&#x27; 或者 ’encoding = ’utf-8‘‘`</span></span><br><span class="line">df.to_csv(<span class="string">&#x27;./titanic/train_chinese.csv&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>【总结】数据的加载以及入门，接下来就要接触数据本身的运算，我们将主要掌握numpy和pandas在工作和项目场景的运用。</p>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第三节数据重构2</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%89%E8%8A%82%E6%95%B0%E6%8D%AE%E9%87%8D%E6%9E%842-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>在前面我们已经学习了Pandas基础，第二章我们开始进入数据分析的业务部分，在第二章第一节的内容中，我们学习了<strong>数据的清洗</strong>，这一部分十分重要，只有数据变得相对干净，我们之后对数据的分析才可以更有力。而这一节，我们要做的是数据重构，数据重构依旧属于数据理解（准备）的范围。</p>
<h4 id="开始之前导入numpypandas包和数据">开始之前，导入numpy、pandas包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入基本库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 载入上一个任务人保存的文件中:result.csv，并查看这个文件</span></span><br><span class="line">text = pd.read_csv(<span class="string">&#x27;result.csv&#x27;</span>)</span><br><span class="line">text.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Unnamed: 0
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h1 id="第二章数据重构">2 第二章：数据重构</h1>
<h2 id="第一部分数据聚合与运算">第一部分：数据聚合与运算</h2>
<h3 id="数据运用">2.6 数据运用</h3>
<h4 id="任务一通过教材python-for-data-analysisp303google-or-anything来学习了解groupby机制">2.6.1
任务一：通过教材《Python for Data Analysis》P303、Google or
anything来学习了解GroupBy机制</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入心得</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">GroupBy机制是Pandas中用于数据分组与聚合的核心操作，其本质是遵循&quot;Split-Apply-Combine&quot;模式：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Split：按指定键（列、函数、数组等）将数据分割成多个子集</span></span><br><span class="line"><span class="string">Apply：对每个子集独立应用聚合函数（如mean/max）、转换函数（如标准化）或过滤操作</span></span><br><span class="line"><span class="string">Combine：将结果合并为新的数据结构</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="任务二计算泰坦尼克号男性与女性的平均票价">2.4.2：任务二：计算泰坦尼克号男性与女性的平均票价</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">df  = text[<span class="string">&#x27;Fare&#x27;</span>].groupby(text[<span class="string">&#x27;Sex&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(df.groups)</span><br><span class="line">means = df.mean()</span><br><span class="line">means</span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;female&#39;: [1, 2, 3, 8, 9, 10, 11, 14, 15, 18, 19, 22, 24, 25, 28, 31, 32, 38, 39, 40, 41, 43, 44, 47, 49, 52, 53, 56, 58, 61, 66, 68, 71, 79, 82, 84, 85, 88, 98, 100, 106, 109, 111, 113, 114, 119, 123, 128, 132, 133, 136, 140, 141, 142, 147, 151, 156, 161, 166, 167, 172, 177, 180, 184, 186, 190, 192, 194, 195, 198, 199, 205, 208, 211, 215, 216, 218, 229, 230, 233, 235, 237, 240, 241, 246, 247, 251, 254, 255, 256, 257, 258, 259, 264, 268, 269, 272, 274, 275, 276, ...], &#39;male&#39;: [0, 4, 5, 6, 7, 12, 13, 16, 17, 20, 21, 23, 26, 27, 29, 30, 33, 34, 35, 36, 37, 42, 45, 46, 48, 50, 51, 54, 55, 57, 59, 60, 62, 63, 64, 65, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 107, 108, 110, 112, 115, 116, 117, 118, 120, 121, 122, 124, 125, 126, 127, 129, 130, 131, 134, 135, 137, 138, 139, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, ...]&#125;

Sex
female    44.479818
male      25.523893
Name: Fare, dtype: float64</code></pre>
<p>在了解GroupBy机制之后，运用这个机制完成一系列的操作，来达到我们的目的。</p>
<p>下面通过几个任务来熟悉GroupBy机制。</p>
<h4 id="任务三统计泰坦尼克号中男女的存活人数">2.4.3：任务三：统计泰坦尼克号中男女的存活人数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_sex = text[<span class="string">&#x27;Survived&#x27;</span>].groupby(text[<span class="string">&#x27;Sex&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line">survived_sex.head()</span><br></pre></td></tr></table></figure>
<pre><code>Sex
female    233
male      109
Name: Survived, dtype: int64</code></pre>
<h4 id="任务四计算客舱不同等级的存活人数">2.4.4：任务四：计算客舱不同等级的存活人数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_pclass = text[<span class="string">&#x27;Survived&#x27;</span>].groupby(text[<span class="string">&#x27;Pclass&#x27;</span>])</span><br><span class="line">survived_pclass.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<pre><code>Pclass
1    136
2     87
3    119
Name: Survived, dtype: int64</code></pre>
<p>【<strong>提示：</strong>】表中的存活那一栏，可以发现如果还活着记为1，死亡记为0</p>
<p>【<strong>思考</strong>】从数据分析的角度，上面的统计结果可以得出那些结论</p>
<p>【思考】从任务二到任务三中，这些运算可以通过agg()函数来同时计算。并且可以使用rename函数修改列名。你可以按照提示写出这个过程吗？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考心得</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">agg() 函数是 Pandas 中用于对分组后的数据 同时执行多个聚合操作 的核心工具，其全称为 Aggregate（聚合）。它允许你对不同列应用不同的聚合函数，并支持自定义函数，极大提升数据分析效率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">text.groupby(<span class="string">&#x27;Sex&#x27;</span>).agg(&#123;<span class="string">&#x27;Fare&#x27;</span>: <span class="string">&#x27;mean&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>: <span class="string">&#x27;count&#x27;</span>&#125;).rename(columns=</span><br><span class="line">                            &#123;<span class="string">&#x27;Fare&#x27;</span>: <span class="string">&#x27;mean_fare&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>: <span class="string">&#x27;count_pclass&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
mean_fare
</th>
<th>
count_pclass
</th>
</tr>
<tr>
<th>
Sex
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
female
</th>
<td>
44.479818
</td>
<td>
314
</td>
</tr>
<tr>
<th>
male
</th>
<td>
25.523893
</td>
<td>
577
</td>
</tr>
</tbody>
</table>
<h4 id="任务五统计在不同等级的票中的不同年龄的船票花费的平均值">2.4.5：任务五：统计在不同等级的票中的不同年龄的船票花费的平均值</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">temp=text.groupby([<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Age&#x27;</span>])[<span class="string">&#x27;Fare&#x27;</span>]</span><br><span class="line">temp.groups</span><br><span class="line">temp.mean().head()</span><br></pre></td></tr></table></figure>
<pre><code>Pclass  Age  
1       0.92     151.5500
        2.00     151.5500
        4.00      81.8583
        11.00    120.0000
        14.00    120.0000
Name: Fare, dtype: float64</code></pre>
<h4 id="任务六将任务二和任务三的数据合并并保存到sex_fare_survived.csv">2.4.6：任务六：将任务二和任务三的数据合并，并保存到sex_fare_survived.csv</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">result = pd.merge(means,survived_sex,on=<span class="string">&#x27;Sex&#x27;</span>)</span><br><span class="line">result</span><br><span class="line">result.to_csv(<span class="string">&#x27;sex_fare_survived.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="任务七得出不同年龄的总的存活人数然后找出存活人数最多的年龄段最后计算存活人数最高的存活率存活人数总人数">2.4.7：任务七：得出不同年龄的总的存活人数，然后找出存活人数最多的年龄段，最后计算存活人数最高的存活率（存活人数/总人数）</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_age = text[<span class="string">&#x27;Survived&#x27;</span>].groupby(text[<span class="string">&#x27;Age&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line">survived_age.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Age
0.42    1
0.67    1
0.75    2
0.83    2
0.92    1
Name: Survived, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_age[survived_age.values==survived_age.<span class="built_in">max</span>()]</span><br></pre></td></tr></table></figure>
<pre><code>Age
24.0    15
Name: Survived, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_<span class="built_in">sum</span> = text[<span class="string">&#x27;Survived&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(_<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure>
<pre><code>342</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sum of person:&quot;</span>+<span class="built_in">str</span>(_<span class="built_in">sum</span>))</span><br><span class="line"></span><br><span class="line">precetn =survived_age.<span class="built_in">max</span>()/_<span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最大存活率：&quot;</span>+<span class="built_in">str</span>(precetn))</span><br></pre></td></tr></table></figure>
<pre><code>sum of person:342
最大存活率：0.043859649122807015</code></pre>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第三章模型建立和评估--建模</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0--%E5%BB%BA%E6%A8%A1-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="第三章-模型搭建和评估建模">第三章 模型搭建和评估–建模</h2>
<p>经过前面的两章的知识点的学习，我可以对数数据的本身进行处理，比如数据本身的增删查补，还可以做必要的清洗工作。那么下面我们就要开始使用我们前面处理好的数据了。这一章我们要做的就是使用数据，我们做数据分析的目的也就是，运用我们的数据以及结合我的业务来得到某些我们需要知道的结果。那么分析的第一步就是建模，搭建一个预测模型或者其他模型；我们从这个模型的到结果之后，我们要分析我的模型是不是足够的可靠，那我就需要评估这个模型。今天我们学习建模，下一节我们学习评估。</p>
<p>我们拥有的泰坦尼克号的数据集，那么我们这次的目的就是，完成泰坦尼克号存活预测这个任务。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">6</span>)  <span class="comment"># 设置输出图片大小</span></span><br></pre></td></tr></table></figure>
<p>载入这些库，如果缺少某些库，请安装他们</p>
<p>【思考】这些库的作用是什么呢？你需要查一查</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考题回答</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Image 是 IPython.display 模块的一部分，用于在 Jupyter Notebook 或 IPython 环境中直接显示图像。支持从本地路径或网络 URL 加载图像，并控制显示格式（如宽度、高度、格式类型）</span></span><br><span class="line"><span class="string">seaborn 是一个基于 Matplotlib 的高级数据可视化库，专注于统计图形的绘制（如分布图、相关性图、分类图等），能快速生成美观且信息丰富的图表</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>&#39;\nImage 是 IPython.display 模块的一部分，用于在 Jupyter Notebook 或 IPython 环境中直接显示图像。支持从本地路径或网络 URL 加载图像，并控制显示格式（如宽度、高度、格式类型）\nseaborn 是一个基于 Matplotlib 的高级数据可视化库，专注于统计图形的绘制（如分布图、相关性图、分类图等），能快速生成美观且信息丰富的图表\n&#39;</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<p><strong>载入我们提供清洗之后的数据(clear_data.csv)，大家也将原始数据载入（train.csv），说说他们有什么不同</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">train.shape</span><br></pre></td></tr></table></figure>
<pre><code>(891, 12)</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>

<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;clear_data.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Pclass
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Fare
</th>
<th>
Sex_female
</th>
<th>
Sex_male
</th>
<th>
Embarked_C
</th>
<th>
Embarked_Q
</th>
<th>
Embarked_S
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
3
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
7.2500
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
1
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
71.2833
</td>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
3
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
7.9250
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
1
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
53.1000
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
3
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
8.0500
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
<h3 id="模型搭建">模型搭建</h3>
<ul>
<li>处理完前面的数据我们就得到建模数据，下一步是选择合适模型</li>
<li>在进行模型选择之前我们需要先知道数据集最终是进行<strong>监督学习</strong>还是<strong>无监督学习</strong></li>
<li>模型的选择一方面是通过我们的任务来决定的。</li>
<li>除了根据我们任务来选择模型外，还可以根据数据样本量以及特征的稀疏性来决定</li>
<li>刚开始我们总是先尝试使用一个基本的模型来作为其baseline，进而再训练其他模型做对比，最终选择泛化能力或性能比较好的模型</li>
</ul>
<p>这里我的建模，并不是从零开始，自己一个人完成完成所有代码的编译。我们这里使用一个机器学习最常用的一个库（sklearn）来完成我们的模型的搭建</p>
<p><strong>下面给出sklearn的算法选择路径，供大家参考</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sklearn模型算法选择路径图</span></span><br><span class="line">Image(<span class="string">&#x27;sklearn.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0--%E5%BB%BA%E6%A8%A1-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估--建模-课程_17_0.png" alt="第三章模型建立和评估–建模-课程_17_0">
<figcaption aria-hidden="true">第三章模型建立和评估–建模-课程_17_0</figcaption>
</figure>
<p>【思考】数据集哪些差异会导致模型在拟合数据是发生变化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务一切割训练集和测试集">任务一：切割训练集和测试集</h4>
<p>这里使用留出法划分数据集</p>
<ul>
<li>将数据集分为自变量和因变量</li>
<li>按比例切割训练集和测试集(一般测试集的比例有30%、25%、20%、15%和10%)</li>
<li>使用分层抽样</li>
<li>设置随机种子以便结果能复现</li>
</ul>
<p>【思考】 * 划分数据集的方法有哪些？ *
为什么使用分层抽样，这样的好处有什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 划分数据集的方法有哪些？</span></span><br><span class="line"><span class="comment"># 1.  **留出法 (Hold-out Cross Validation)**：</span></span><br><span class="line"><span class="comment">#     *   直接将数据集D划分为两个互斥的集合：训练集S和测试集T。</span></span><br><span class="line"><span class="comment">#     *   例如，70%的数据用于训练，30%用于测试。</span></span><br><span class="line"><span class="comment">#     *   优点：简单、计算开销小。</span></span><br><span class="line"><span class="comment">#     *   缺点：划分具有随机性，单次划分的结果可能不够稳定和准确，尤其是在数据集较小时。训练集和测试集的样本比例会影响评估结果。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.  **交叉验证法 (Cross Validation)**：</span></span><br><span class="line"><span class="comment">#     *   **k折交叉验证 (k-Fold Cross Validation)**：</span></span><br><span class="line"><span class="comment">#         *   将数据集D划分为k个大小相似的互斥子集 D1, D2, ..., Dk。</span></span><br><span class="line"><span class="comment">#         *   每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集。</span></span><br><span class="line"><span class="comment">#         *   这样可以获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值。</span></span><br><span class="line"><span class="comment">#         *   常用的k值为5或10。</span></span><br><span class="line"><span class="comment">#         *   优点：比留出法更稳定，更充分地利用了数据。</span></span><br><span class="line"><span class="comment">#         *   缺点：计算开销是k倍。</span></span><br><span class="line"><span class="comment">#     *   **留一法 (Leave-One-Out Cross Validation, LOOCV)**：</span></span><br><span class="line"><span class="comment">#         *   k折交叉验证的特例，当k等于样本数N时。</span></span><br><span class="line"><span class="comment">#         *   每次只留下一个样本作为测试集，其余N-1个样本作为训练集。</span></span><br><span class="line"><span class="comment">#         *   优点：评估结果通常被认为比较准确，因为几乎所有数据都用于训练。</span></span><br><span class="line"><span class="comment">#         *   缺点：计算开销非常大，尤其是在数据集很大时。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.  **自助法 (Bootstrapping)**：</span></span><br><span class="line"><span class="comment">#     *   以自助采样法为基础。给定包含m个样本的数据集D，对它进行采样产生数据集D&#x27;：每次随机从D中挑选一个样本，将其拷贝放入D&#x27;，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到。这个过程重复执行m次后，我们就得到了包含m个样本的数据集D&#x27;。</span></span><br><span class="line"><span class="comment">#     *   可以证明，初始数据集D中约有36.8%的样本未出现在采样数据集D&#x27;中。于是我们可将D&#x27;用作训练集，D\D&#x27;用作测试集。</span></span><br><span class="line"><span class="comment">#     *   优点：在数据集较小、难以有效划分训练/测试集时很有用；能从初始数据集中产生多个不同的训练集。</span></span><br><span class="line"><span class="comment">#     *   缺点：自助法产生的数据集改变了初始数据集的分布，会引入估计偏差。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为什么使用分层抽样，这样的好处有什么？</span></span><br><span class="line"><span class="comment"># **分层抽样 (Stratified Sampling)** 是一种抽样技术，它将总体（数据集）划分为若干个互不重叠的子群（称为“层”），然后从每个层中独立地进行简单随机抽样。在划分训练集和测试集时，特别是对于分类任务，通常是根据目标变量的类别进行分层。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># **好处：**</span></span><br><span class="line"><span class="comment"># 1.  **保持类别比例一致性**：</span></span><br><span class="line"><span class="comment">#     *   确保训练集和测试集中的各个类别的样本比例与原始数据集中各个类别的样本比例大致相同。</span></span><br><span class="line"><span class="comment">#     *   这对于类别不平衡的数据集尤为重要。如果进行纯随机抽样，可能会导致训练集或测试集中某些少数类别的样本过少，甚至没有，从而影响模型的训练效果和评估的可靠性。</span></span><br><span class="line"><span class="comment"># 2.  **提高模型的泛化能力和评估的准确性**：</span></span><br><span class="line"><span class="comment">#     *   由于训练集和测试集都较好地代表了原始数据的类别分布，模型在训练时能学习到各个类别的特征，评估时也能更准确地反映模型在所有类别上的表现。</span></span><br><span class="line"><span class="comment">#     *   避免了因随机划分导致训练集和测试集在类别分布上产生较大差异，从而使得模型评估结果更加稳定和可信。</span></span><br><span class="line"><span class="comment"># 3.  **减少抽样误差**：</span></span><br><span class="line"><span class="comment">#     *   相比于简单随机抽样，分层抽样通常能得到更具代表性的样本，从而减少因抽样带来的误差，使得基于样本的推断更加精确。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务提示1">任务提示1</h4>
<ul>
<li>切割数据集是为了后续能评估模型泛化能力</li>
<li>sklearn中切割数据集的方法为<code>train_test_split</code></li>
<li>查看函数文档可以在jupyter
noteboo里面使用<code>train_test_split?</code>后回车即可看到</li>
<li>分层和随机种子在参数里寻找</li>
</ul>
<p>要从clear_data.csv和train.csv中提取train_test_split()所需的参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 一般先取出X和y后再切割，有些情况会使用到未切割的，这时候X和y就可以用,x是清洗好的数据，y是我们要预测的存活数据&#x27;Survived&#x27;</span></span><br><span class="line">X = data</span><br><span class="line">y = train[<span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line"><span class="comment"># 对数据集进行切割</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">X_train.shape, X_test.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>((668, 11), (223, 11))</code></pre>
<p>【思考】 * 什么情况下切割数据集的时候不用进行随机选取</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 在以下情况下切割数据集时可能不需要或不适合进行随机选取：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.  **时间序列数据 (Time Series Data)**：</span></span><br><span class="line"><span class="comment">#     *   对于时间序列数据，数据的顺序至关重要，因为它包含了时间依赖性。随机打乱顺序会破坏这种依赖关系。</span></span><br><span class="line"><span class="comment">#     *   通常的做法是按时间顺序划分，例如，将较早的数据作为训练集，较晚的数据作为测试集（或验证集）。这更符合实际应用中用过去预测未来的场景。</span></span><br><span class="line"><span class="comment">#     *   例如，用前几年的股票数据训练模型，用最近一年的数据测试模型。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.  **数据已经预先排序或具有特定结构**：</span></span><br><span class="line"><span class="comment">#     *   如果数据集已经按照某种对分析有意义的顺序排列（例如，按地理区域、按实验批次等），并且你希望测试集来自与训练集不同的、特定的部分，那么可能需要按顺序或按特定规则划分，而不是随机划分。</span></span><br><span class="line"><span class="comment">#     *   例如，在一个全国性的调查数据中，你可能想用某些省份的数据做训练，用另一些省份的数据做测试，以检验模型的地域泛化能力。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.  **数据集非常大且分布均匀**：</span></span><br><span class="line"><span class="comment">#     *   当数据集非常庞大，并且可以合理假设数据是独立同分布 (i.i.d.) 且分布均匀时，简单地按顺序取一部分作为训练集，另一部分作为测试集，其效果可能与随机选取相差不大。随机选取的计算开销在这种情况下可能显得不必要。</span></span><br><span class="line"><span class="comment">#     *   然而，即使在这种情况下，随机选取通常仍然是更稳妥的做法，以避免潜在的未知偏差。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.  **特定的交叉验证策略**：</span></span><br><span class="line"><span class="comment">#     *   某些交叉验证方法本身就定义了非随机的划分方式。例如，在k折交叉验证中，虽然整体上数据被分成了k折，但每一折的选择是确定的（通常是按顺序分割）。留一法交叉验证更是每次只留一个特定的样本作为测试集。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.  **当需要完全复现特定的、非随机的划分结果时**：</span></span><br><span class="line"><span class="comment">#     *   如果之前的研究或实验使用了某种特定的非随机划分方式，为了比较或复现结果，也需要采用相同的划分方式。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.  **流式数据或在线学习场景**：</span></span><br><span class="line"><span class="comment">#     *   在数据持续不断流入的场景中，模型可能需要用新到达的数据进行测试或持续训练。这种情况下，测试集自然是最新的一部分数据，而不是从历史数据中随机抽取的。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务二模型创建">任务二：模型创建</h4>
<ul>
<li>创建基于线性模型的分类模型（逻辑回归）</li>
<li>创建基于树的分类模型（决策树、随机森林）</li>
<li>分别使用这些模型进行训练，分别的到训练集和测试集的得分</li>
<li>查看模型的参数，并更改参数值，观察模型变化</li>
</ul>
<h4 id="提示">提示</h4>
<ul>
<li>逻辑回归不是回归模型而是分类模型，不要与<code>LinearRegression</code>混淆</li>
<li>随机森林其实是决策树集成为了降低决策树过拟合的情况</li>
<li>线性模型所在的模块为<code>sklearn.linear_model</code></li>
<li>树模型所在的模块为<code>sklearn.ensemble</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 默认参数逻辑回归模型</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 查看训练集和测试集score值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr.score(X_train, y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr.score(X_test, y_test)))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Training set score: 0.80
Testing set score: 0.79</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 调整参数后的逻辑回归模型</span></span><br><span class="line">lr2 = LogisticRegression(C=<span class="number">100</span>)</span><br><span class="line">lr2.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr2.score(X_train, y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr2.score(X_test, y_test)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Training set score: 0.79
Testing set score: 0.78


/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认参数的随机森林分类模型</span></span><br><span class="line">rfc = RandomForestClassifier()</span><br><span class="line">rfc.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc.score(X_train, y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc.score(X_test, y_test)))</span><br></pre></td></tr></table></figure>
<pre><code>Training set score: 1.00
Testing set score: 0.82</code></pre>
<p>【思考】 * 为什么线性模型可以进行分类任务，背后是怎么的数学关系 *
对于多分类问题，线性模型是怎么进行分类的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 为什么线性模型可以进行分类任务，背后是怎么的数学关系</span></span><br><span class="line"><span class="comment"># 线性模型（如逻辑回归 Logistic Regression，或者支持向量机 SVM 的线性核）之所以能用于分类任务，是因为它们通过以下方式将线性组合的输入特征映射到类别预测：</span></span><br><span class="line"><span class="comment"># 1.  **线性组合**：首先，模型计算输入特征的线性组合，形式通常为 `z = w_1*x_1 + w_2*x_2 + ... + w_n*x_n + b`，或者用向量表示为 `z = w^T * x + b`。</span></span><br><span class="line"><span class="comment">#     *   `x` 是输入特征向量。</span></span><br><span class="line"><span class="comment">#     *   `w` 是模型学习到的权重（或系数）。</span></span><br><span class="line"><span class="comment">#     *   `b` 是偏置项（或截距）。</span></span><br><span class="line"><span class="comment">#     这个 `z` 值可以看作是样本点到决策边界的某种度量。</span></span><br><span class="line"><span class="comment"># 2.  **决策函数/激活函数**：然后，这个线性组合的结果 `z` 会被传递给一个决策函数或激活函数，该函数将其转换为类别预测或类别概率。</span></span><br><span class="line"><span class="comment">#     *   **对于逻辑回归 (Logistic Regression)**：</span></span><br><span class="line"><span class="comment">#         *   它使用 Sigmoid (Logistic) 函数：`p = 1 / (1 + e^(-z))`。</span></span><br><span class="line"><span class="comment">#         *   Sigmoid 函数将任意实数值 `z` 映射到 (0, 1) 区间，这个输出 `p` 可以解释为样本属于正类（通常是类别1）的概率。</span></span><br><span class="line"><span class="comment">#         *   通过设定一个阈值（通常是0.5），如果 `p &gt; 0.5` (即 `z &gt; 0`)，则预测为正类；否则预测为负类。</span></span><br><span class="line"><span class="comment">#         *   因此，决策边界是 `z = 0`，即 `w^T * x + b = 0`，这是一个超平面。</span></span><br><span class="line"><span class="comment">#     *   **对于线性支持向量机 (Linear SVM)**：</span></span><br><span class="line"><span class="comment">#         *   它直接使用 `z` 的符号来决定类别。如果 `z &gt; 0`，预测为一类；如果 `z &lt; 0`，预测为另一类。</span></span><br><span class="line"><span class="comment">#         *   SVM 的目标是找到一个能最大化两类样本之间间隔（margin）的决策边界（超平面）。</span></span><br><span class="line"><span class="comment"># 总结来说，线性模型通过学习一个线性决策边界（直线、平面或超平面）来分隔不同类别的样本。它们首先计算一个线性得分，然后通过一个非线性函数（如Sigmoid）或直接根据得分的符号来做出分类决策。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于多分类问题，线性模型是怎么进行分类的</span></span><br><span class="line"><span class="comment"># 当类别数量大于两个时（即多分类问题），线性模型通常采用以下两种主要策略之一将问题转化为多个二分类问题：</span></span><br><span class="line"><span class="comment"># 1.  **一对余 (One-vs-Rest, OvR) 或 一对所有 (One-vs-All, OvA)**：</span></span><br><span class="line"><span class="comment">#     *   **原理**：如果有个 `K` 个类别，OvR 策略会训练 `K` 个独立的二分类器。</span></span><br><span class="line"><span class="comment">#     *   第 `i` 个分类器 (`i` 从 1 到 `K`) 会将类别 `i` 的样本视为正类，而将所有其他 `K-1` 个类别的样本视为负类。</span></span><br><span class="line"><span class="comment">#     *   **预测**：对于一个新的样本，它会被输入到所有 `K` 个分类器中。每个分类器都会输出一个分数或概率，表示该样本属于其对应“正类”的置信度。最终，样本被分配给那个给出最高置信度分数的类别。</span></span><br><span class="line"><span class="comment">#     *   **优点**：直观，实现相对简单，计算效率较高（只需要训练K个分类器）。</span></span><br><span class="line"><span class="comment">#     *   **缺点**：当类别数量很多时，每个二分类器的负类可能包含非常多样化的样本，可能导致类别不平衡问题。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.  **一对一 (One-vs-One, OvO)**：</span></span><br><span class="line"><span class="comment">#     *   **原理**：如果有个 `K` 个类别，OvO 策略会为每一对类别 `(i, j)` 训练一个二分类器，其中 `i != j`。总共需要训练 `K * (K-1) / 2` 个分类器。</span></span><br><span class="line"><span class="comment">#     *   每个分类器只负责区分两个特定的类别。</span></span><br><span class="line"><span class="comment">#     *   **预测**：对于一个新的样本，它会被输入到所有 `K * (K-1) / 2` 个分类器中。每个分类器都会对样本属于其两个类别中的哪一个进行投票。最终，样本被分配给获得最多投票的类别。</span></span><br><span class="line"><span class="comment">#     *   **优点**：每个分类器只需要处理两个类别的数据，通常训练速度更快，且对于某些对类别不平衡不敏感的算法（如SVM）可能表现更好。</span></span><br><span class="line"><span class="comment">#     *   **缺点**：当类别数量 `K` 很大时，需要训练的分类器数量会急剧增加，导致计算成本和存储成本较高。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># **在 scikit-learn 中**：</span></span><br><span class="line"><span class="comment"># *   `LogisticRegression` 默认使用 OvR 策略进行多分类 (可以通过 `multi_class` 参数设置为 `&#x27;multinomial&#x27;` 来使用 Softmax 回归，这是一种直接处理多分类的方法，但其基础仍然是线性的)。</span></span><br><span class="line"><span class="comment"># *   `LinearSVC` (线性支持向量机) 默认使用 OvR 策略。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务三输出模型预测结果">任务三：输出模型预测结果</h4>
<ul>
<li>输出模型预测分类标签</li>
<li>输出不同分类标签的预测概率</li>
</ul>
<h4 id="提示3">提示3</h4>
<ul>
<li>一般监督模型在sklearn里面有个<code>predict</code>能输出预测标签，<code>predict_proba</code>则可以输出标签概率</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred = lr.predict(X_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([0, 1, 1, 1, 0, 0, 1, 0, 1, 1])</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred_proba = lr.predict_proba(X_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred_proba[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.60887905, 0.39112095],
       [0.17668722, 0.82331278],
       [0.40624596, 0.59375404],
       [0.18896449, 0.81103551],
       [0.87984221, 0.12015779],
       [0.91385758, 0.08614242],
       [0.13282516, 0.86717484],
       [0.90555878, 0.09444122],
       [0.05280619, 0.94719381],
       [0.10934565, 0.89065435]])</code></pre>
<p>【思考】 * 预测标签的概率对我们有什么帮助</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第二节数据重构1</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%BA%8C%E8%8A%82%E6%95%B0%E6%8D%AE%E9%87%8D%E6%9E%841-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>在前面我们已经学习了Pandas基础，第二章我们开始进入数据分析的业务部分，在第二章第一节的内容中，我们学习了<strong>数据的清洗</strong>，这一部分十分重要，只有数据变得相对干净，我们之后对数据的分析才可以更有力。而这一节，我们要做的是数据重构，数据重构依旧属于数据理解（准备）的范围。</p>
<h4 id="开始之前导入numpypandas包和数据">开始之前，导入numpy、pandas包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入基本库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 载入data文件中的:train-left-up.csv</span></span><br><span class="line">text=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-left-up.csv&#x27;</span>)</span><br><span class="line">text.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
</tr>
</tbody>
</table>
<h1 id="第二章数据重构">2 第二章：数据重构</h1>
<h3 id="数据的合并">2.4 数据的合并</h3>
<h4 id="任务一将data文件夹里面的所有数据都载入观察数据的之间的关系">2.4.1
任务一：将data文件夹里面的所有数据都载入，观察数据的之间的关系</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">text_left_up=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-left-up.csv&#x27;</span>)</span><br><span class="line">text_left_down=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-left-down.csv&#x27;</span>)</span><br><span class="line">text_right_up=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-right-up.csv&#x27;</span>)</span><br><span class="line">text_right_down=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-right-down.csv&#x27;</span>)</span><br><span class="line">text_left_up.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
</tr>
</tbody>
</table>
<p>【提示】结合之前我们加载的train.csv数据，大致预测一下上面的数据是什么</p>
<h4 id="任务二使用concat方法将数据train-left-up.csv和train-right-up.csv横向合并为一张表并保存这张表为result_up">2.4.2：任务二：使用concat方法：将数据train-left-up.csv和train-right-up.csv横向合并为一张表，并保存这张表为result_up</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#pandas.concat 是 Pandas 中用于连接 Series 或 DataFrame 对象的核心方法，支持横向（列方向）或纵向（行方向）拼接</span></span><br><span class="line">list_up = [text_left_up,text_right_up]</span><br><span class="line">result_up = pd.concat(list_up,axis=<span class="number">1</span>)</span><br><span class="line">result_up.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h4 id="任务三使用concat方法将train-left-down和train-right-down横向合并为一张表并保存这张表为result_down然后将上边的result_up和result_down纵向合并为result">2.4.3
任务三：使用concat方法：将train-left-down和train-right-down横向合并为一张表，并保存这张表为result_down。然后将上边的result_up和result_down纵向合并为result。</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">list_down=[text_left_down,text_right_down]</span><br><span class="line">result_down = pd.concat(list_down,axis=<span class="number">1</span>)</span><br><span class="line">result = pd.concat([result_up,result_down])</span><br><span class="line">result.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="任务四使用dataframe自带的方法join方法和append完成任务二和任务三的任务">2.4.4
任务四：使用DataFrame自带的方法join方法和append：完成任务二和任务三的任务</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">resul_up = text_left_up.join(text_right_up)</span><br><span class="line">result_down = text_left_down.join(text_right_down)</span><br><span class="line">result = result_up.append(result_down)</span><br><span class="line">result.head()</span><br></pre></td></tr></table></figure>
<h4 id="任务五使用panads的merge方法和dataframe的append方法完成任务二和任务三的任务">2.4.5
任务五：使用Panads的merge方法和DataFrame的append方法：完成任务二和任务三的任务</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">该代码使用 pandas.merge 方法，以索引（index）为键，将两个 DataFrame (text_left_up 和 text_right_up) 横向合并。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">result_up = pd.merge(text_left_up,text_right_up,left_index=<span class="literal">True</span>,right_index=<span class="literal">True</span>)</span><br><span class="line">result_down = pd.merge(text_left_down,text_right_down,left_index=<span class="literal">True</span>,right_index=<span class="literal">True</span>)</span><br><span class="line">result = resul_up.append(result_down)</span><br><span class="line">result.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【思考】对比merge、join以及concat的方法的不同以及相同。思考一下在任务四和任务五的情况下，为什么都要求使用DataFrame的append方法，如何只要求使用merge或者join可不可以完成任务四和任务五呢？</p>
<h4 id="任务六完成的数据保存为result.csv">2.4.6
任务六：完成的数据保存为result.csv</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">result.to_csv(<span class="string">&#x27;result.csv&#x27;</span>)</span><br><span class="line">result.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="换一种角度看数据">2.5 换一种角度看数据</h3>
<h4 id="任务一将我们的数据变为series类型的数据">2.5.1
任务一：将我们的数据变为Series类型的数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#text.stack() 是 Pandas 中用于将 DataFrame 的列旋转为行的方法</span></span><br><span class="line">text = pd.read_csv(<span class="string">&#x27;result.csv&#x27;</span>)</span><br><span class="line">unit_result=text.stack().head(<span class="number">20</span>)</span><br><span class="line">unit_result.head()</span><br></pre></td></tr></table></figure>
<pre><code>0  Unnamed: 0                           0
   PassengerId                          1
   Survived                             0
   Pclass                               3
   Name           Braund, Mr. Owen Harris
dtype: object</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">unit_result.to_csv(<span class="string">&#x27;unit_result.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第一章：第一节数据载入及初步观察</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%BA%8C%E8%8A%82pandas%E5%9F%BA%E7%A1%80-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>数据分析的第一步，加载数据我们已经学习完毕了。当数据展现在我们面前的时候，我们所要做的第一步就是认识他，今天我们要学习的就是<strong>了解字段含义以及初步观察数据</strong>。</p>
<h2 id="第一章数据载入及初步观察">1 第一章：数据载入及初步观察</h2>
<h3 id="知道你的数据叫什么">1.4 知道你的数据叫什么</h3>
<p>我们学习pandas的基础操作，那么上一节通过pandas加载之后的数据，其数据类型是什么呢？</p>
<p><strong>开始前导入numpy和pandas</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<h4 id="任务一pandas中有两个数据类型dateframe和series通过查找简单了解他们然后自己写一个关于这两个数据类型的小例子开放题">1.4.1
任务一：pandas中有两个数据类型DateFrame和Series，通过查找简单了解他们。然后自己写一个关于这两个数据类型的小例子🌰[开放题]</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#我们举的例子</span></span><br><span class="line">sdata = &#123;<span class="string">&#x27;Ohio&#x27;</span>: <span class="number">35000</span>, <span class="string">&#x27;Texas&#x27;</span>: <span class="number">71000</span>, <span class="string">&#x27;Oregon&#x27;</span>: <span class="number">16000</span>, <span class="string">&#x27;Utah&#x27;</span>: <span class="number">5000</span>&#125;</span><br><span class="line">example_1 = pd.Series(sdata)</span><br><span class="line">example_1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Ohio      35000
Texas     71000
Oregon    16000
Utah       5000
dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#我们举的例子</span></span><br><span class="line">data = &#123;<span class="string">&#x27;state&#x27;</span>: [<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2003</span>],<span class="string">&#x27;pop&#x27;</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>, <span class="number">3.2</span>]&#125;</span><br><span class="line">example_2 = pd.DataFrame(data)</span><br><span class="line">example_2</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
state
</th>
<th>
year
</th>
<th>
pop
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
Ohio
</td>
<td>
2000
</td>
<td>
1.5
</td>
</tr>
<tr>
<th>
1
</th>
<td>
Ohio
</td>
<td>
2001
</td>
<td>
1.7
</td>
</tr>
<tr>
<th>
2
</th>
<td>
Ohio
</td>
<td>
2002
</td>
<td>
3.6
</td>
</tr>
<tr>
<th>
3
</th>
<td>
Nevada
</td>
<td>
2001
</td>
<td>
2.4
</td>
</tr>
<tr>
<th>
4
</th>
<td>
Nevada
</td>
<td>
2002
</td>
<td>
2.9
</td>
</tr>
<tr>
<th>
5
</th>
<td>
Nevada
</td>
<td>
2003
</td>
<td>
3.2
</td>
</tr>
</tbody>
</table>
<h4 id="任务二根据上节课的方法载入train.csv文件">1.4.2
任务二：根据上节课的方法载入”train.csv”文件</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>也可以加载上一节课保存的”train_chinese.csv”文件。通过翻译版train_chinese.csv熟悉了这个数据集，然后我们对trian.csv来进行操作
#### 1.4.3 任务三：查看DataFrame数据的每列的名称</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.columns</span><br></pre></td></tr></table></figure>
<pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,
       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;],
      dtype=&#39;object&#39;)</code></pre>
<h4 id="任务四查看cabin这列的所有值有多种方法">1.4.4任务四：查看”Cabin”这列的所有值[有多种方法]</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[<span class="string">&#x27;Cabin&#x27;</span>].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<pre><code>0     NaN
1     C85
2     NaN
3    C123
4     NaN
5     NaN
6     E46
7     NaN
8     NaN
9     NaN
Name: Cabin, dtype: object</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.Cabin.values[:<span class="number">10</span>]</span><br><span class="line">df.Cabin.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<pre><code>0     NaN
1     C85
2     NaN
3    C123
4     NaN
5     NaN
6     E46
7     NaN
8     NaN
9     NaN
Name: Cabin, dtype: object</code></pre>
<h4 id="任务五加载文件test_1.csv然后对比train.csv看看有哪些多出的列然后将多出的列删除">1.4.5
任务五：加载文件”test_1.csv”，然后对比”train.csv”，看看有哪些多出的列，然后将多出的列删除</h4>
<p>经过我们的观察发现一个测试集test_1.csv有一列是多余的，我们需要将这个多余的列删去</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">test_1=pd.read_csv(<span class="string">&#x27;../第一单元项目集合/test_1.csv&#x27;</span>)</span><br><span class="line">test_1.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Unnamed: 0
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
a
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
100
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#test_1.columns</span></span><br><span class="line">test_1.drop(<span class="string">&#x27;Unnamed: 0&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">test_1.columns</span><br></pre></td></tr></table></figure>
<pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,
       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;, &#39;a&#39;],
      dtype=&#39;object&#39;)</code></pre>
<p>【思考】还有其他的删除多余的列的方式吗？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 思考回答</span></span><br><span class="line"><span class="keyword">del</span> test_1[<span class="string">&#x27;Unnamed: 0&#x27;</span>]</span><br><span class="line">test_1.columns</span><br></pre></td></tr></table></figure>
<pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,
       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;, &#39;a&#39;],
      dtype=&#39;object&#39;)</code></pre>
<h4 id="任务六-将passengeridnameageticket这几个列元素隐藏只观察其他几个列元素">1.4.6
任务六：
将[‘PassengerId’,‘Name’,‘Age’,‘Ticket’]这几个列元素隐藏，只观察其他几个列元素</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.drop([<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Ticket&#x27;</span>], axis=<span class="number">1</span>).head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Sex
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
3
</td>
<td>
male
</td>
<td>
1
</td>
<td>
0
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
1
</td>
<td>
female
</td>
<td>
1
</td>
<td>
0
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
3
</td>
<td>
female
</td>
<td>
0
</td>
<td>
0
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
1
</td>
<td>
female
</td>
<td>
1
</td>
<td>
0
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
0
</td>
<td>
3
</td>
<td>
male
</td>
<td>
0
</td>
<td>
0
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
3
</td>
<td>
male
</td>
<td>
0
</td>
<td>
0
</td>
<td>
8.4583
</td>
<td>
NaN
</td>
<td>
Q
</td>
</tr>
<tr>
<th>
6
</th>
<td>
0
</td>
<td>
1
</td>
<td>
male
</td>
<td>
0
</td>
<td>
0
</td>
<td>
51.8625
</td>
<td>
E46
</td>
<td>
S
</td>
</tr>
<tr>
<th>
7
</th>
<td>
0
</td>
<td>
3
</td>
<td>
male
</td>
<td>
3
</td>
<td>
1
</td>
<td>
21.0750
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
8
</th>
<td>
1
</td>
<td>
3
</td>
<td>
female
</td>
<td>
0
</td>
<td>
2
</td>
<td>
11.1333
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
9
</th>
<td>
1
</td>
<td>
2
</td>
<td>
female
</td>
<td>
1
</td>
<td>
0
</td>
<td>
30.0708
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
</tbody>
</table>
<p>【思考】对比任务五和任务六，是不是使用了不一样的方法(函数)，如果使用一样的函数如何完成上面的不同的要求呢？</p>
<p>【思考回答】</p>
<p>如果想要完全的删除你的数据结构，使用inplace=True，因为使用inplace就将原数据覆盖了，所以这里没有用</p>
<h3 id="筛选的逻辑">1.5 筛选的逻辑</h3>
<p>表格数据中，最重要的一个功能就是要具有可筛选的能力，选出我所需要的信息，丢弃无用的信息。</p>
<p>下面我们还是用实战来学习pandas这个功能。</p>
<h4 id="任务一-我们以age为筛选条件显示年龄在10岁以下的乘客信息">1.5.1
任务一： 我们以”Age”为筛选条件，显示年龄在10岁以下的乘客信息。</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="built_in">print</span>((df[<span class="string">&#x27;Age&#x27;</span>]&lt;<span class="number">10</span>).head(<span class="number">2</span>))</span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>]&lt;<span class="number">10</span>].head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>0    False
1    False
Name: Age, dtype: bool</code></pre>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
7
</th>
<td>
8
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Palsson, Master. Gosta Leonard
</td>
<td>
male
</td>
<td>
2.0
</td>
<td>
3
</td>
<td>
1
</td>
<td>
349909
</td>
<td>
21.075
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
10
</th>
<td>
11
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Sandstrom, Miss. Marguerite Rut
</td>
<td>
female
</td>
<td>
4.0
</td>
<td>
1
</td>
<td>
1
</td>
<td>
PP 9549
</td>
<td>
16.700
</td>
<td>
G6
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h4 id="任务二-以age为条件将年龄在10岁以上和50岁以下的乘客信息显示出来并将这个数据命名为midage">1.5.2
任务二：
以”Age”为条件，将年龄在10岁以上和50岁以下的乘客信息显示出来，并将这个数据命名为midage</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage=df[(df[<span class="string">&#x27;Age&#x27;</span>]&gt;<span class="number">10</span>) &amp; (df[<span class="string">&#x27;Age&#x27;</span>]&lt;<span class="number">50</span>)]</span><br><span class="line">midage</span><br></pre></td></tr></table></figure>
<p>【提示】了解pandas的条件筛选方式以及如何使用交集和并集操作</p>
<h4 id="任务三将midage的数据中第100行的pclass和sex的数据显示出来">1.5.3
任务三：将midage的数据中第100行的”Pclass”和”Sex”的数据显示出来</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage = midage.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(midage)</span><br><span class="line">midage.loc[<span class="number">1</span>][[<span class="string">&#x27;Pclass&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>]]</span><br></pre></td></tr></table></figure>
<pre><code>     PassengerId  Survived  Pclass  \
0              1         0       3   
1              2         1       1   
2              3         1       3   
3              4         1       1   
4              5         0       3   
..           ...       ...     ...   
571          886         0       3   
572          887         0       2   
573          888         1       1   
574          890         1       1   
575          891         0       3   

                                                  Name     Sex   Age  SibSp  \
0                              Braund, Mr. Owen Harris    male  22.0      1   
1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   
2                               Heikkinen, Miss. Laina  female  26.0      0   
3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   
4                             Allen, Mr. William Henry    male  35.0      0   
..                                                 ...     ...   ...    ...   
571               Rice, Mrs. William (Margaret Norton)  female  39.0      0   
572                              Montvila, Rev. Juozas    male  27.0      0   
573                       Graham, Miss. Margaret Edith  female  19.0      0   
574                              Behr, Mr. Karl Howell    male  26.0      0   
575                                Dooley, Mr. Patrick    male  32.0      0   

     Parch            Ticket     Fare Cabin Embarked  
0        0         A/5 21171   7.2500   NaN        S  
1        0          PC 17599  71.2833   C85        C  
2        0  STON/O2. 3101282   7.9250   NaN        S  
3        0            113803  53.1000  C123        S  
4        0            373450   8.0500   NaN        S  
..     ...               ...      ...   ...      ...  
571      5            382652  29.1250   NaN        Q  
572      0            211536  13.0000   NaN        S  
573      0            112053  30.0000   B42        S  
574      0            111369  30.0000  C148        C  
575      0            370376   7.7500   NaN        Q  

[576 rows x 12 columns]



Pclass         1
Sex       female
Name: 1, dtype: object</code></pre>
<p>【提示】在抽取数据中，我们希望数据的相对顺序保持不变，用什么函数可以达到这个效果呢？</p>
<h4 id="任务四使用loc方法将midage的数据中第100105108行的pclassname和sex的数据显示出来">1.5.4
任务四：使用loc方法将midage的数据中第100，105，108行的”Pclass”，“Name”和”Sex”的数据显示出来</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage.loc[[<span class="number">100</span>,<span class="number">105</span>,<span class="number">108</span>],[<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Name&#x27;</span>,<span class="string">&#x27;Sex&#x27;</span>]] </span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
100
</th>
<td>
2
</td>
<td>
Byles, Rev. Thomas Roussel Davids
</td>
<td>
male
</td>
</tr>
<tr>
<th>
105
</th>
<td>
3
</td>
<td>
Cribb, Mr. John Hatfield
</td>
<td>
male
</td>
</tr>
<tr>
<th>
108
</th>
<td>
3
</td>
<td>
Calic, Mr. Jovo
</td>
<td>
male
</td>
</tr>
</tbody>
</table>
<h4 id="任务五使用iloc方法将midage的数据中第100105108行的pclassname和sex的数据显示出来">1.5.5
任务五：使用iloc方法将midage的数据中第100，105，108行的”Pclass”，“Name”和”Sex”的数据显示出来</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage.iloc[[<span class="number">100</span>,<span class="number">105</span>,<span class="number">108</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]] </span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
149
</th>
<td>
2
</td>
<td>
Byles, Rev. Thomas Roussel Davids
</td>
<td>
male
</td>
</tr>
<tr>
<th>
160
</th>
<td>
3
</td>
<td>
Cribb, Mr. John Hatfield
</td>
<td>
male
</td>
</tr>
<tr>
<th>
163
</th>
<td>
3
</td>
<td>
Calic, Mr. Jovo
</td>
<td>
male
</td>
</tr>
</tbody>
</table>
<p>【思考】对比<code>iloc</code>和<code>loc</code>的异同</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># *   当你需要根据**标签名称**（如行索引名或列名）来选取数据时，使用 `loc`。这使得代码更具可读性，因为你可以直接看到你正在操作的标签。</span></span><br><span class="line"><span class="comment"># *   当你需要根据**整数位置**来选取数据时（不关心标签名称，或者标签不是整数），使用 `iloc`。这在处理没有有意义标签的 DataFrame，或者需要进行与位置相关的操作时很有用。</span></span><br><span class="line"><span class="comment"># *   **注意**：如果 DataFrame 的索引是默认的整数索引 (0, 1, 2, ...)，那么 `loc` 和 `iloc` 在使用单个整数或整数切片进行行选择时，行为可能会相似，但这可能会导致混淆。</span></span><br><span class="line"><span class="comment">#     *   例如，如果 `df.index` 是 `[0, 1, 2, 5, 6]`：</span></span><br><span class="line"><span class="comment">#         *   `df.loc[0]` 会选择索引标签为 `0` 的行。</span></span><br><span class="line"><span class="comment">#         *   `df.iloc[0]` 也会选择第一行（即索引标签为 `0` 的行）。</span></span><br><span class="line"><span class="comment">#         *   `df.loc[3]` 会报错，因为没有索引标签为 `3`。</span></span><br><span class="line"><span class="comment">#         *   `df.iloc[3]` 会选择第四行（即索引标签为 `5` 的行）。</span></span><br><span class="line"><span class="comment"># *   为了避免混淆，最佳实践是：当你知道你正在使用标签时，明确使用 `loc`；当你知道你正在使用整数位置时，明确使用 `iloc`。</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第四节数据可视化</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/</url>
    <content><![CDATA[<p><strong>复习：</strong>回顾学习完第一章，我们对泰坦尼克号数据有了基本的了解，也学到了一些基本的统计方法，第二章中我们学习了数据的清理和重构，使得数据更加的易于理解；今天我们要学习的是第二章第三节：<strong>数据可视化</strong>，主要给大家介绍一下Python数据可视化库Matplotlib，在本章学习中，你也许会觉得数据很有趣。在打比赛的过程中，数据可视化可以让我们更好的看到每一个关键步骤的结果如何，可以用来优化方案，是一个很有用的技巧。</p>
<h1 id="第二章数据可视化">2 第二章：数据可视化</h1>
<h4 id="开始之前导入numpypandas以及matplotlib包和数据">开始之前，导入numpy、pandas以及matplotlib包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载所需的库</span></span><br><span class="line"><span class="comment"># 如果出现 ModuleNotFoundError: No module named &#x27;xxxx&#x27;</span></span><br><span class="line"><span class="comment"># 你只需要在终端/cmd下 pip install xxxx 即可</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载result.csv这个数据</span></span><br><span class="line">text = pd.read_csv(<span class="string">r&#x27;result.csv&#x27;</span>)</span><br><span class="line">text.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Unnamed: 0
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h3 id="如何让人一眼看懂你的数据">2.7 如何让人一眼看懂你的数据？</h3>
<p>《Python for Data Analysis》第九章</p>
<h4 id="任务一跟着书本第九章了解matplotlib自己创建一个数据项对其进行基本可视化">2.7.1
任务一：跟着书本第九章，了解matplotlib，自己创建一个数据项，对其进行基本可视化</h4>
<p>【思考】最基本的可视化图案有哪些？分别适用于那些场景？（比如折线图适合可视化某个属性值随时间变化的走势）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment">#这一部分需要了解可视化图案的的逻辑，知道什么样的图案可以表达什么样的信号b</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务二可视化展示泰坦尼克号数据集中男女中生存人数分布情况用柱状图试试">2.7.2
任务二：可视化展示泰坦尼克号数据集中男女中生存人数分布情况（用柱状图试试）。</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line">sex = text.groupby(<span class="string">&#x27;Sex&#x27;</span>)[<span class="string">&#x27;Survived&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">sex.plot.bar()</span><br><span class="line">plt.title(<span class="string">&#x27;survived_count&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="./../../../../images/第二章：第四节数据可视化-课程%20(copy)/第二章：第四节数据可视化-课程_10_0.png" alt="第二章：第四节数据可视化-课程_10_0">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_10_0</figcaption>
</figure>
<p>【思考】计算出泰坦尼克号数据集中男女中死亡人数，并可视化展示？如何和男女生存人数可视化柱状图结合到一起？看到你的数据可视化，说说你的第一感受（比如：你一眼看出男生存活人数更多，那么性别可能会影响存活率）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考题回答</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务三可视化展示泰坦尼克号数据集中男女中生存人与死亡人数的比例图用柱状图试试">2.7.3
任务三：可视化展示泰坦尼克号数据集中男女中生存人与死亡人数的比例图（用柱状图试试）。</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"><span class="comment"># 提示：计算男女中死亡人数 1表示生存，0表示死亡</span></span><br><span class="line">text.groupby([<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].count().unstack().plot(kind=<span class="string">&#x27;bar&#x27;</span>,stacked=<span class="string">&#x27;True&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;survived_count&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Text(0, 0.5, &#39;count&#39;)</code></pre>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_14_1.png" alt="第二章：第四节数据可视化-课程_14_1">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_14_1</figcaption>
</figure>
<p>【提示】男女这两个数据轴，存活和死亡人数按比例用柱状图表示</p>
<h4 id="任务四可视化展示泰坦尼克号数据集中不同票价的人生存和死亡人数分布情况用折线图试试横轴是不同票价纵轴是存活人数">2.7.4
任务四：可视化展示泰坦尼克号数据集中不同票价的人生存和死亡人数分布情况。（用折线图试试）（横轴是不同票价，纵轴是存活人数）</h4>
<p>【提示】对于这种统计性质的且用折线表示的数据，你可以考虑将数据排序或者不排序来分别表示。看看你能发现什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"><span class="comment"># 计算不同票价中生存与死亡人数 1表示生存，0表示死亡</span></span><br><span class="line"><span class="comment">#print(text.groupby([&#x27;Fare&#x27;])[&#x27;Survived&#x27;].value_counts())</span></span><br><span class="line">fare_sur = text.groupby([<span class="string">&#x27;Fare&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].value_counts().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">fare_sur</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Fare     Survived
8.0500   0           38
7.8958   0           37
13.0000  0           26
7.7500   0           22
26.0000  0           16
                     ..
6.9500   0            1
6.9750   0            1
         1            1
7.0458   0            1
7.1417   1            1
Name: count, Length: 330, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 排序后绘折线图</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">18</span>))</span><br><span class="line">fare_sur.plot(grid=<span class="literal">True</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_19_0.png" alt="第二章：第四节数据可视化-课程_19_0">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_19_0</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line"><span class="comment"># 排序前绘折线图</span></span><br><span class="line">fare_sur1 = text.groupby([<span class="string">&#x27;Fare&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].value_counts()</span><br><span class="line">fare_sur1</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">18</span>))</span><br><span class="line">fare_sur1.plot(grid=<span class="literal">True</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_20_0.png" alt="第二章：第四节数据可视化-课程_20_0">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_20_0</figcaption>
</figure>
<h4 id="任务五可视化展示泰坦尼克号数据集中不同仓位等级的人生存和死亡人员的分布情况用柱状图试试">2.7.5
任务五：可视化展示泰坦尼克号数据集中不同仓位等级的人生存和死亡人员的分布情况。（用柱状图试试）</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"><span class="comment"># 1表示生存，0表示死亡</span></span><br><span class="line">pclass_sur = text.groupby([<span class="string">&#x27;Pclass&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].value_counts()</span><br><span class="line">pclass_sur</span><br></pre></td></tr></table></figure>
<pre><code>Pclass  Survived
1       1           136
        0            80
2       0            97
        1            87
3       0           372
        1           119
Name: count, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.countplot(x=<span class="string">&quot;Pclass&quot;</span>, hue=<span class="string">&quot;Survived&quot;</span>, data=text)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Axes: xlabel=&#39;Pclass&#39;, ylabel=&#39;count&#39;&gt;</code></pre>
<figure>
<img src="./../../../../images/第二章：第四节数据可视化-课程%20(copy)/第二章：第四节数据可视化-课程_23_1.png" alt="第二章：第四节数据可视化-课程_23_1">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_23_1</figcaption>
</figure>
<p>【思考】看到这个前面几个数据可视化，说说你的第一感受和你的总结</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考题回答</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务六可视化展示泰坦尼克号数据集中不同年龄的人生存与死亡人数分布情况不限表达方式">2.7.6
任务六：可视化展示泰坦尼克号数据集中不同年龄的人生存与死亡人数分布情况。(不限表达方式)</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line">facet = sns.FacetGrid(text, hue=<span class="string">&quot;Survived&quot;</span>,aspect=<span class="number">3</span>)</span><br><span class="line">facet.<span class="built_in">map</span>(sns.kdeplot,<span class="string">&#x27;Age&#x27;</span>,shade= <span class="literal">True</span>)</span><br><span class="line">facet.<span class="built_in">set</span>(xlim=(<span class="number">0</span>, text[<span class="string">&#x27;Age&#x27;</span>].<span class="built_in">max</span>()))</span><br><span class="line">facet.add_legend()</span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/seaborn/axisgrid.py:854: FutureWarning: 

`shade` is now deprecated in favor of `fill`; setting `fill=True`.
This will become an error in seaborn v0.14.0; please update your code.

  func(*plot_args, **plot_kwargs)
/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/seaborn/axisgrid.py:854: FutureWarning: 

`shade` is now deprecated in favor of `fill`; setting `fill=True`.
This will become an error in seaborn v0.14.0; please update your code.

  func(*plot_args, **plot_kwargs)

&lt;seaborn.axisgrid.FacetGrid at 0x7f9c6bce1f50&gt;</code></pre>
<figure>
<img src="./../../../../images/第二章：第四节数据可视化-课程%20(copy)/第二章：第四节数据可视化-课程_27_2.png" alt="第二章：第四节数据可视化-课程_27_2">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_27_2</figcaption>
</figure>
<h4 id="任务七可视化展示泰坦尼克号数据集中不同仓位等级的人年龄分布情况用折线图试试">2.7.7
任务七：可视化展示泰坦尼克号数据集中不同仓位等级的人年龄分布情况。（用折线图试试）</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"></span><br><span class="line">text.Age[text.Pclass == <span class="number">1</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">text.Age[text.Pclass == <span class="number">2</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">text.Age[text.Pclass == <span class="number">3</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;age&quot;</span>)</span><br><span class="line">plt.legend((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),loc=<span class="string">&quot;best&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f9c69946e90&gt;</code></pre>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_29_1.png" alt="第二章：第四节数据可视化-课程_29_1">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_29_1</figcaption>
</figure>
<p>【思考】上面所有可视化的例子做一个总体的分析，你看看你能不能有自己发现</p>
<p>【总结】到这里，我们的可视化就告一段落啦，如果你对数据可视化极其感兴趣，你还可以了解一下其他可视化模块，如：pyecharts，bokeh等。</p>
<p>如果你在工作中使用数据可视化，你必须知道数据可视化最大的作用不是炫酷，而是最快最直观的理解数据要表达什么，你觉得呢？</p>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第三章模型建立和评估---评价</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="第三章-模型搭建和评估-评估">第三章 模型搭建和评估-评估</h2>
<p>根据之前的模型的建模，我们知道如何运用sklearn这个库来完成建模，以及我们知道了的数据集的划分等等操作。那么一个模型我们怎么知道它好不好用呢？以至于我们能不能放心的使用模型给我的结果呢？那么今天的学习的评估，就会很有帮助。</p>
<p>加载下面的库</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">6</span>)  <span class="comment"># 设置输出图片大小</span></span><br></pre></td></tr></table></figure>
<p><strong>任务：加载数据并分割测试集和训练集</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 一般先取出X和y后再切割，有些情况会使用到未切割的，这时候X和y就可以用,x是清洗好的数据，y是我们要预测的存活数据&#x27;Survived&#x27;</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;clear_data.csv&#x27;</span>)</span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">X = data</span><br><span class="line">y = train[<span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 对数据集进行切割</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 默认参数逻辑回归模型</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
<h3 id="模型评估">模型评估</h3>
<ul>
<li>模型评估是为了知道模型的泛化能力。</li>
<li>交叉验证（cross-validation）是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。</li>
<li>在交叉验证中，数据被多次划分，并且需要训练多个模型。</li>
<li>最常用的交叉验证是 k 折交叉验证（k-fold cross-validation），其中 k
是由用户指定的数字，通常取 5 或 10。</li>
<li>准确率（precision）度量的是被预测为正例的样本中有多少是真正的正例</li>
<li>召回率（recall）度量的是正类样本中有多少被预测为正类</li>
<li>f-分数是准确率与召回率的调和平均</li>
</ul>
<p>【思考】：将上面的概念进一步的理解，大家可以做一下总结</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答：</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务一交叉验证">任务一：交叉验证</h4>
<ul>
<li>用10折交叉验证来评估之前的逻辑回归模型</li>
<li>计算交叉验证精度的平均值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提示：交叉验证</span></span><br><span class="line">Image(<span class="string">&#x27;Snipaste_2020-01-05_16-37-56.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_16_0.png" alt="第三章模型建立和评估—评价-课程_16_0">
<figcaption aria-hidden="true">第三章模型建立和评估—评价-课程_16_0</figcaption>
</figure>
<h4 id="提示4">提示4</h4>
<ul>
<li>交叉验证在sklearn中的模块为<code>sklearn.model_selection</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">lr = LogisticRegression(C=<span class="number">100</span>)</span><br><span class="line">scores = cross_val_score(lr, X_train, y_train, cv=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 平均交叉验证分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Average cross-validation score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(scores.mean()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Average cross-validation score: 0.78</code></pre>
<h4 id="思考4">思考4</h4>
<ul>
<li>k折越多的情况下会带来什么样的影响？</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 当 k 越大时：</span></span><br><span class="line"><span class="comment"># 1. 每次训练使用的数据更多，评估偏差（bias）降低</span></span><br><span class="line"><span class="comment"># 2. 每次测试集样本更少，评估方差（variance）增大</span></span><br><span class="line"><span class="comment"># 3. 需要训练 k 个模型，计算开销显著增加</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务二混淆矩阵">任务二：混淆矩阵</h4>
<ul>
<li>计算二分类问题的混淆矩阵</li>
<li>计算精确率、召回率以及f-分数</li>
</ul>
<p>【思考】什么是二分类问题的混淆矩阵，理解这个概念，知道它主要是运算到什么任务中的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 混淆矩阵（confusion matrix）是一个 2×2 的表格，用于二分类任务中展示模型预测结果与真实标签的对应关系：</span></span><br><span class="line"><span class="comment">#    - True Positive (TP)：真实为正类，预测也为正类</span></span><br><span class="line"><span class="comment">#    - False Positive (FP)：真实为负类，却被误预测为正类</span></span><br><span class="line"><span class="comment">#    - False Negative (FN)：真实为正类，却被误预测为负类</span></span><br><span class="line"><span class="comment">#    - True Negative (TN)：真实为负类，预测也为负类</span></span><br><span class="line"><span class="comment"># 通过混淆矩阵，可以进一步计算精确率（Precision）、召回率（Recall）、F1 分数等指标，</span></span><br><span class="line"><span class="comment"># 帮助我们评估模型在不同类型错误上的表现，常用于分类模型的性能评估和错误分析。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提示：混淆矩阵</span></span><br><span class="line">Image(<span class="string">&#x27;Snipaste_2020-01-05_16-38-26.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_27_0.png" alt="第三章模型建立和评估—评价-课程_27_0">
<figcaption aria-hidden="true">第三章模型建立和评估—评价-课程_27_0</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提示：准确率 (Accuracy),精确度（Precision）,Recall,f-分数计算方法</span></span><br><span class="line">Image(<span class="string">&#x27;Snipaste_2020-01-05_16-39-27.png&#x27;</span>)</span><br><span class="line">​    </span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_28_0.png" alt="第三章模型建立和评估—评价-课程_28_0">
<figcaption aria-hidden="true">第三章模型建立和评估—评价-课程_28_0</figcaption>
</figure>
<h4 id="提示5">提示5</h4>
<ul>
<li>混淆矩阵的方法在sklearn中的<code>sklearn.metrics</code>模块</li>
<li>混淆矩阵需要输入真实标签和预测标签</li>
<li>精确率、召回率以及f-分数可使用<code>classification_report</code>模块</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lr = LogisticRegression(C=<span class="number">100</span>)</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 模型预测结果</span></span><br><span class="line">pred = lr.predict(X_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 混淆矩阵</span></span><br><span class="line">confusion_matrix(y_train, pred)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>array([[355,  57],
       [ 82, 174]])</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="comment"># 精确率、召回率以及f1-score</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_train, pred))</span><br></pre></td></tr></table></figure>
<pre><code>              precision    recall  f1-score   support

           0       0.81      0.86      0.84       412
           1       0.75      0.68      0.71       256

    accuracy                           0.79       668
   macro avg       0.78      0.77      0.78       668
weighted avg       0.79      0.79      0.79       668</code></pre>
<p>【思考】 * 如果自己实现混淆矩阵的时候该注意什么问题</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 如果自己实现混淆矩阵，需要注意：</span></span><br><span class="line"><span class="comment"># 1. 明确行列含义：通常行是真实标签，列是预测标签，并保持一致。</span></span><br><span class="line"><span class="comment"># 2. 类别顺序要固定：最好指定 labels 列表，避免类别稀疏时错位。</span></span><br><span class="line"><span class="comment"># 3. 初始化大小为 n_classes×n_classes 的零矩阵。</span></span><br><span class="line"><span class="comment"># 4. 索引时使用整数或统一的类别映射，避免类型不一致。</span></span><br><span class="line"><span class="comment"># 5. 对每个样本累加到对应的 [真实, 预测] 单元格，最后矩阵元素之和应等于样本数。</span></span><br><span class="line"><span class="comment"># 6. 对于未出现的类别，矩阵对应行或列应保留 0。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务三roc曲线">任务三：ROC曲线</h4>
<ul>
<li>绘制ROC曲线</li>
</ul>
<p>【思考】什么是ROC曲线，OCR曲线的存在是为了解决什么问题？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考</span></span><br><span class="line"><span class="comment"># ROC曲线（Receiver Operating Characteristic Curve）是一条以假正例率（FPR）为横坐标、</span></span><br><span class="line"><span class="comment"># 真正例率（TPR）为纵坐标绘制的曲线，展示模型在不同阈值下的分类性能变化。</span></span><br><span class="line"><span class="comment"># 它解决了单一阈值下评估不全面的问题，通过曲线下的面积（AUC）能够衡量模型整体区分正负样本的能力；</span></span><br><span class="line"><span class="comment"># 对类别不平衡更稳健，可在不同模型或参数设置间进行客观比较。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="提示6">提示6</h4>
<ul>
<li>ROC曲线在sklearn中的模块为<code>sklearn.metrics</code></li>
<li>ROC曲线下面所包围的面积越大越好</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.decision_function(X_test))</span><br></pre></td></tr></table></figure>
<pre><code>[-1.7776276  -1.68901519 -2.9343385  -2.73339993 -0.7425476   0.1771919
  0.42300886 -0.95177507 -2.19297241 -2.09492243 -2.09876666 -2.24379328
 -0.72898893 -0.74448703  1.55206252  2.26736362 -3.0615053  -1.45551632
  1.82143942  1.10174703  2.80348253  2.20862227 -2.08595792 -1.98565326
 -2.62459231  2.61608127  2.52054836  0.46386814 -2.26805651 -1.89799476
 -4.40221097 -2.45118004 -2.11507984  0.25727282  1.56507901 -3.49922092
  0.09517543  3.1727335  -0.66659502 -2.16889122 -2.31738004 -0.75154631
  1.34173247 -0.68691348 -2.38317701 -1.48352807  3.30441868  0.37836543
  0.15120699 -2.39554116  0.71230509 -2.94049784  0.0526656  -0.12124772
  0.21937853 -0.95736671 -2.91315052  1.73227025 -2.30451919 -0.11949728
 -2.40406452 -1.23217853 -3.04709277 -2.51149884 -2.91275507  0.36741872
  1.88515182 -1.73344723  1.61180838 -2.64456699 -2.82671595 -1.32885535
 -1.89201447 -2.38194062  1.14830497  0.7324757   3.41575634 -0.04718518
  1.99047031  0.71098531 -2.5002286   2.11220527  1.35687779 -4.65208202
 -0.50164169 -2.21847127 -0.27744568 -2.1098023  -2.28203956 -2.24087733
  1.49913758 -0.46745632 -1.76590269 -3.13694507 -2.48969764 -2.52447108
 -0.31359417 -2.62456277  0.10812447 -3.22505518 -0.54301462 -1.31398633
 -2.45637232 -0.9392769  -1.99910791 -0.01952273  0.16386412  1.17043699
  0.83571934 -0.30892412 -2.56236834 -2.52630696 -2.15878988  3.38005162
 -1.63316112 -2.0470374   1.16802525  1.96428556 -0.85542758 -0.84711271
 -2.3923425  -2.27467461  1.27340371 -0.16738478  2.77379952 -0.91636487
  3.49337899  2.22265823 -1.03898765 -1.79576035  3.05405598 -1.72625544
 -2.08233698  0.14427761 -2.03826492 -1.87510703 -2.43040363  0.88364821
 -2.31722422  1.21479438 -2.19509856 -1.96948465  2.90456606  1.22909197
 -0.60993113 -2.40508898  1.79832298 -2.33619419 -1.76964851  0.54894164
  0.56920781 -1.65544357 -2.18783672 -2.51890544 -1.1167812   1.85506633
 -2.14366192  2.56003678  1.79741811  2.22038003 -0.93948297  2.11029939
  3.66773152  3.37255532 -1.62079149 -0.21922341 -2.93532548 -1.8851028
 -0.11223495 -0.89402373 -2.79168773  0.58319665 -1.20213471  2.11583429
 -1.78550619 -1.21648746 -2.91538781 -2.80005448 -2.74359191 -0.06775047
 -1.28645408 -1.17048578 -0.1176852  -1.59958242 -0.65901928 -2.40701243
  0.57575073 -3.0756839   1.53932753 -2.49031769 -3.03266822  0.30539932
 -0.05523861 -0.24431132 -2.36483723  3.25595248 -2.11664845 -1.97728592
 -2.04509461 -3.07727841 -1.11942703 -3.38920295 -2.59088459 -3.55978164
  0.22449105 -0.3214215   0.05735696  0.02061023 -3.01544378 -0.77973619
 -1.39798016 -3.10075724 -4.80621573 -3.01948006  3.44366918 -2.88193813
 -2.01992513 -0.09559774  0.91447527 -1.13270082 -2.45426968 -1.91415803
 -0.08403516]</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 计算ROC曲线的假正例率(FPR)、真正例率(TPR)和阈值</span></span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, lr.decision_function(X_test))</span><br><span class="line">plt.plot(fpr, tpr, label=<span class="string">&quot;ROC Curve&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;FPR&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;TPR (recall)&quot;</span>)</span><br><span class="line"><span class="comment"># 找到最接近于0的阈值</span></span><br><span class="line">close_zero = np.argmin(np.<span class="built_in">abs</span>(thresholds))</span><br><span class="line">plt.plot(fpr[close_zero], tpr[close_zero], <span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">10</span>, label=<span class="string">&quot;threshold zero&quot;</span>, fillstyle=<span class="string">&quot;none&quot;</span>, c=<span class="string">&#x27;k&#x27;</span>, mew=<span class="number">2</span>)</span><br><span class="line">plt.legend(loc=<span class="number">4</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_44_3.png" alt="第三章模型建立和评估—评价-课程_44_3">
<figcaption aria-hidden="true">第三章模型建立和评估—评价-课程_44_3</figcaption>
</figure>
<h4 id="思考6">思考6</h4>
<ul>
<li>对于多分类问题如何绘制ROC曲线</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【思考】你能从这条OCR曲线的到什么信息？这些信息可以做什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 从ROC曲线中可以得到以下信息：</span></span><br><span class="line"><span class="comment"># 1. 模型整体性能：曲线下的面积 (AUC - Area Under the Curve) 是一个常用的评估指标。</span></span><br><span class="line"><span class="comment">#    - AUC = 1：完美分类器。</span></span><br><span class="line"><span class="comment">#    - AUC = 0.5：随机分类器（无区分能力，ROC曲线接近对角线）。</span></span><br><span class="line"><span class="comment">#    - AUC &gt; 0.5：模型优于随机猜测。AUC越大，模型区分正负样本的能力越强。</span></span><br><span class="line"><span class="comment">#    - AUC &lt; 0.5：模型表现差于随机猜测（可能标签反了或者模型非常差）。</span></span><br><span class="line"><span class="comment"># 2. 不同阈值下的权衡：ROC曲线展示了在所有可能的分类阈值下，真正例率 (TPR) 与假正例率 (FPR) 之间的关系。</span></span><br><span class="line"><span class="comment">#    - 曲线上的每个点代表一个特定的阈值。</span></span><br><span class="line"><span class="comment">#    - 曲线越靠近左上角 (FPR低, TPR高)，说明模型在较低的假正例率下能达到较高的真正例率，性能越好。</span></span><br><span class="line"><span class="comment"># 3. 模型的区分能力：曲线的形状可以反映模型区分正负样本的能力。如果曲线显著高于对角线，说明模型具有较好的区分能力。</span></span><br><span class="line"><span class="comment"># 4. 阈值选择的依据：可以根据业务需求，在ROC曲线上选择一个合适的平衡点（即选择一个阈值）。</span></span><br><span class="line"><span class="comment">#    - 例如，如果更关注减少漏报（提高TPR），可以选择曲线上TPR较高的点，即使FPR可能略高。</span></span><br><span class="line"><span class="comment">#    - 如果更关注减少误报（降低FPR），可以选择曲线上FPR较低的点，即使TPR可能略低。</span></span><br><span class="line"><span class="comment">#    - 图中标记的 &quot;threshold zero&quot; 点通常是模型默认的分类阈值对应的性能点。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第一节数据清洗及特征处理</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%80%E8%8A%82%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E5%8F%8A%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p>【回顾&amp;引言】前面一章的内容大家可以感觉到我们主要是对基础知识做一个梳理，让大家了解数据分析的一些操作，主要做了数据的各个角度的观察。那么在这里，我们主要是做数据分析的流程性学习，主要是包括了数据清洗以及数据的特征处理，数据重构以及数据可视化。这些内容是为数据分析最后的建模和模型评价做一个铺垫。</p>
<h4 id="开始之前导入numpypandas包和数据">开始之前，导入numpy、pandas包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载所需的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载数据train.csv</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br><span class="line">df.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h2 id="第二章数据清洗及特征处理">2 第二章：数据清洗及特征处理</h2>
<p>我们拿到的数据通常是不干净的，所谓的不干净，就是数据中有缺失值，有一些异常点等，需要经过一定的处理才能继续做后面的分析或建模，所以拿到数据的第一步是进行数据清洗，本章我们将学习缺失值、重复值、字符串和数据转换等操作，将数据清洗成可以分析或建模的亚子。</p>
<h3 id="缺失值观察与处理">2.1 缺失值观察与处理</h3>
<p>我们拿到的数据经常会有很多缺失值，比如我们可以看到Cabin列存在NaN，那其他列还有没有缺失值，这些缺失值要怎么处理呢</p>
<h4 id="任务一缺失值观察">2.1.1 任务一：缺失值观察</h4>
<ol type="1">
<li>请查看每个特征缺失值个数<br>
</li>
<li>请查看Age， Cabin， Embarked列的数据
以上方式都有多种方式，所以大家多多益善</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<pre><code>PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[[<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Cabin&#x27;</span>,<span class="string">&#x27;Embarked&#x27;</span>]].head(<span class="number">3</span>)</span><br><span class="line"><span class="comment">#df[&#x27;Age&#x27;].head(3)</span></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Age
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
22.0
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
38.0
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
26.0
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p>外层 [] 是 DataFrame 的索引操作符。 内层 [] 是 Python
原生的列表语法，用于传递多个列名。</p>
<h4 id="任务二对缺失值进行处理">2.1.2 任务二：对缺失值进行处理</h4>
<p>(1)处理缺失值一般有几种思路</p>
<ol start="2" type="1">
<li><p>请尝试对Age列的数据的缺失值进行处理</p></li>
<li><p>请尝试使用不同的方法直接对整张表的缺失值进行处理</p></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#处理缺失值的一般思路：</span></span><br><span class="line"><span class="comment">#提醒：可使用的函数有---&gt;dropna函数与fillna函数</span></span><br><span class="line"><span class="comment">#print(df.head(3))</span></span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>]==<span class="literal">None</span>]=<span class="number">0</span></span><br><span class="line">df.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>].isnull()]</span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>].isnull()] = <span class="number">0</span> </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>] == np.nan] = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>【思考1】dropna和fillna有哪些参数，分别如何使用呢?</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#dropna() 是 Pandas 中用于删除包含缺失值（NaN 或 None）的行或列的函数。其核心作用是清理数据中的缺失值，适用于数据清洗阶段。</span></span><br><span class="line">df.dropna().head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0000
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#fillna() 是 Pandas 中用于填充缺失值（NaN 或 None）的核心函数，常用于数据清洗阶段。其核心作用是将缺失值替换为合理值，以便后续分析或建模。</span></span><br><span class="line">df.fillna(<span class="number">0</span>).head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
0
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
0
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
</div>
<p>【思考】检索空缺值用<code>np.nan</code>,<code>None</code>以及<code>.isnull()</code>哪个更好，这是为什么？如果其中某个方式无法找到缺失值，原因又是为什么？</p>
<p>【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html</p>
<p>【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html</p>
<h3 id="重复值观察与处理">2.2 重复值观察与处理</h3>
<p>由于这样那样的原因，数据中会不会存在重复值呢，如果存在要怎样处理呢</p>
<h4 id="任务一请查看数据中的重复值">2.2.1
任务一：请查看数据中的重复值</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#df.duplicated()返回一个布尔序列 (Series)，标记每一行是否为重复行</span></span><br><span class="line">df[df.duplicated()]</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
17
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
19
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
26
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
28
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
29
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
859
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
863
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
868
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
878
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
888
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
<p>
176 rows × 12 columns
</p>
<h4 id="任务二对重复值进行处理">2.2.2 任务二：对重复值进行处理</h4>
<p>(1)重复值有哪些处理方式呢？</p>
<p>(2)处理我们数据的重复值</p>
<p>方法多多益善</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#重复值有哪些处理方式：</span></span><br><span class="line"><span class="comment">#删除 DataFrame 中的重复行（完全相同的行只保留一次）。</span></span><br><span class="line">df = df.drop_duplicates()</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h4 id="任务三将前面清洗的数据保存为csv格式">2.2.3
任务三：将前面清洗的数据保存为csv格式</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">df.to_csv(<span class="string">&#x27;test_clear.csv&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="特征观察与处理">2.3 特征观察与处理</h3>
<p>我们对特征进行一下观察，可以把特征大概分为两大类：<br>
数值型特征：Survived ，Pclass， Age ，SibSp， Parch，
Fare，其中Survived， Pclass为离散型数值特征，Age，SibSp， Parch，
Fare为连续型数值特征<br>
文本型特征：Name， Sex， Cabin，Embarked， Ticket，其中Sex， Cabin，
Embarked，
Ticket为类别型文本特征，数值型特征一般可以直接用于模型的训练，但有时候为了模型的稳定性及鲁棒性会对连续变量进行离散化。文本型特征往往需要转换成数值型特征才能用于建模分析。</p>
<h4 id="任务一对年龄进行分箱离散化处理">2.3.1
任务一：对年龄进行分箱（离散化）处理</h4>
<ol type="1">
<li><p>分箱操作是什么？</p></li>
<li><p>将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示</p></li>
<li><p>将连续变量Age划分为[0,5) [5,15) [15,30) [30,50)
[50,80)五个年龄段，并分别用类别变量12345表示</p></li>
<li><p>将连续变量Age按10% 30% 50% 70%
90%五个年龄段，并用分类变量12345表示</p></li>
<li><p>将上面的获得的数据分别进行保存，保存为csv格式</p></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#分箱操作是什么：</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分箱操作（Binning）是数据预处理中的一种常用技术，主要用于将连续型数值转换为离散的区间（即“箱子”或“分组”）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示</span></span><br><span class="line">df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(df[<span class="string">&#x27;Age&#x27;</span>], <span class="number">5</span>,labels = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">df.head()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
AgeBand
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
2
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
3
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
2
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将连续变量Age划分为(0,5] (5,15] (15,30] (30,50] (50,80]五个年龄段，并分别用类别变量12345表示</span></span><br><span class="line">df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(df[<span class="string">&#x27;Age&#x27;</span>],[<span class="number">0</span>,<span class="number">5</span>,<span class="number">15</span>,<span class="number">30</span>,<span class="number">50</span>,<span class="number">80</span>],labels = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">df.head(<span class="number">3</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
AgeBand
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
4
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将连续变量Age按10% 30% 50 70% 90%五个年龄段，并用分类变量12345表示</span></span><br><span class="line">df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.qcut(df[<span class="string">&#x27;Age&#x27;</span>],[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">0.3</span>,<span class="number">0.5</span>,<span class="number">0.7</span>,<span class="number">0.9</span>],labels = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
AgeBand
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
2
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
5
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
<td>
4
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
<p>【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html</p>
<p>【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html</p>
<h4 id="任务二对文本变量进行转换">2.3.2 任务二：对文本变量进行转换</h4>
<ol type="1">
<li>查看文本变量名及种类<br>
</li>
<li>将文本变量Sex， Cabin ，Embarked用数值变量12345表示<br>
</li>
<li>将文本变量Sex， Cabin， Embarked用one-hot编码表示</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#方法一: value_counts</span></span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>].value_counts(),</span><br><span class="line">df[<span class="string">&#x27;Cabin&#x27;</span>].value_counts(),</span><br><span class="line">df[<span class="string">&#x27;Embarked&#x27;</span>].value_counts())</span><br></pre></td></tr></table></figure>
<pre><code>Sex
male      453
female    261
0           1
Name: count, dtype: int64 Cabin
B96 B98        4
G6             4
C23 C25 C27    4
F2             3
C22 C26        3
              ..
E36            1
D7             1
C118           1
C99            1
D37            1
Name: count, Length: 135, dtype: int64 Embarked
S    554
C    130
Q     28
0      1
Name: count, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>].unique()</span><br><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>].nunique()</span><br></pre></td></tr></table></figure>
<pre><code>3</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将类别文本转换为12345</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#方法一: replace</span></span><br><span class="line">df[<span class="string">&#x27;Sex_num&#x27;</span>] = df[<span class="string">&#x27;Sex&#x27;</span>].replace([<span class="string">&#x27;male&#x27;</span>,<span class="string">&#x27;female&#x27;</span>],[<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">df.head()</span><br><span class="line"><span class="comment">#方法二: map</span></span><br><span class="line">df[<span class="string">&#x27;Sex_num&#x27;</span>] = df[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;female&#x27;</span>: <span class="number">2</span>&#125;)</span><br><span class="line">df.head()</span><br><span class="line"><span class="comment">#方法三: 使用sklearn.preprocessing的LabelEncoder</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> [<span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Ticket&#x27;</span>]:</span><br><span class="line">    lbl = LabelEncoder()  </span><br><span class="line">    label_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(df[feat].unique(), <span class="built_in">range</span>(df[feat].nunique())))</span><br><span class="line">    <span class="comment">#print(label_dict)</span></span><br><span class="line">    df[feat + <span class="string">&quot;_labelEncode&quot;</span>] = df[feat].<span class="built_in">map</span>(label_dict)</span><br><span class="line">    df[feat + <span class="string">&quot;_labelEncode&quot;</span>] = lbl.fit_transform(df[feat].astype(<span class="built_in">str</span>))</span><br><span class="line"></span><br><span class="line">df.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/tmp/ipykernel_1400/2627332835.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option(&#39;future.no_silent_downcasting&#39;, True)`
  df[&#39;Sex_num&#39;] = df[&#39;Sex&#39;].replace([&#39;male&#39;,&#39;female&#39;],[1,2])</code></pre>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
…
</th>
<th>
Age_66.0
</th>
<th>
Age_70.0
</th>
<th>
Age_70.5
</th>
<th>
Age_71.0
</th>
<th>
Age_74.0
</th>
<th>
Age_80.0
</th>
<th>
Embarked_0
</th>
<th>
Embarked_C
</th>
<th>
Embarked_Q
</th>
<th>
Embarked_S
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
<td>
False
</td>
<td>
False
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
</tr>
</tbody>
</table>
<p>
5 rows × 109 columns
</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#将类别文本转换为one-hot编码</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#方法一: OneHotEncoder</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> [<span class="string">&quot;Age&quot;</span>, <span class="string">&quot;Embarked&quot;</span>]:</span><br><span class="line">    x = pd.get_dummies(df[<span class="string">&quot;Age&quot;</span>] // <span class="number">6</span>)</span><br><span class="line"><span class="comment">#     x = pd.get_dummies(pd.cut(df[&#x27;Age&#x27;],5))</span></span><br><span class="line">    x = pd.get_dummies(df[feat], prefix=feat)</span><br><span class="line">    df = pd.concat([df, x], axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#df[feat] = pd.get_dummies(df[feat], prefix=feat)</span></span><br><span class="line">    </span><br><span class="line">df.head()</span><br><span class="line">df.to_csv(<span class="string">&#x27;temp.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="任务三从纯文本name特征里提取出titles的特征所谓的titles就是mrmissmrs等">2.3.3
任务三：从纯文本Name特征里提取出Titles的特征(所谓的Titles就是Mr,Miss,Mrs等)</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#保存最终你完成的已经清理好的数据</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>python大作业-weatherweb</title>
    <url>/2025/06/01/%E5%AD%A6%E4%B9%A0/python-web/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/</url>
    <content><![CDATA[<h3 id="项目要求">项目要求</h3>
<p>智能天气提醒助手</p>
<p>描述：开发一款web应用，实时获取天气数据并支持个性化提醒（如雨天带伞）。</p>
<p>要求：</p>
<p>调用天气API获取实时数据（如OpenWeatherMap，每天1000次免费调用）</p>
<p>使用前端三件套设计交互界面，展示当前及未来天气信息，空气质量、体感温度、日出日落、月相等信息；</p>
<p>使用fastapi做后端</p>
<p>支持地点设置和天气提醒条件配置，在预设的提醒条件下提醒用户，并且将用户偏好保存至本地文件。</p>
<p>多城市切换、历史天气查询、全球地图展示等额外功能（可选*）。</p>
<h3 id="技术栈">技术栈</h3>
<p>fastapi，前端三件套(fetchapi)，apifox</p>
<h3 id="fetchapi">fetchapi</h3>
<p><strong>Fetch API</strong>
是现代浏览器提供的标准网络请求接口，允许开发者通过 JavaScript 发起异步
HTTP 请求（如 GET、POST、PUT、DELETE 等），并处理响应数据（如
JSON、文本、图片等）。它是传统
<code>XMLHttpRequest</code>（AJAX）的替代方案，语法更简洁，且支持
Promise 异步编程。</p>
<p><strong>简单来说，就是用作给后端发送请求，实现前后端分离</strong></p>
<figure>
<img src="/2025/06/01/%E5%AD%A6%E4%B9%A0/python-web/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/image-20250609163335375.png" alt="image-20250609163335375">
<figcaption aria-hidden="true">image-20250609163335375</figcaption>
</figure>
<h4 id="用法学习">用法学习</h4>
<p>在使用 <code>fetch</code> 发起 HTTP
请求时，<code>method</code>、<code>headers</code> 和 <code>body</code>
是配置请求的核心参数，它们共同决定了请求的行为和数据格式。以下是每个参数的具体作用及示例：</p>
<h5 id="method-post"><strong>1.
<code>method: 'POST'</code></strong></h5>
<p><strong>作用</strong></p>
<p>指定 HTTP 请求的方法（动词），<code>POST</code>
表示向服务器提交数据（如创建资源）。 - <strong>常见方法</strong>： -
<code>GET</code>：获取数据（默认方法，无需显式声明）。 -
<code>POST</code>：提交数据（如新增记录）。 -
<code>PUT</code>：更新数据。 - <code>DELETE</code>：删除数据。 -
<strong>与后端交互</strong>：FastAPI 的路由通过
<code>@app.post()</code>、<code>@app.get()</code>
等装饰器匹配请求方法。</p>
<p><strong>示例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="title function_">fetch</span>(<span class="string">&#x27;https://api.example.com/submit&#x27;</span>, &#123;</span><br><span class="line">  <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span>, <span class="comment">// 告诉服务器这是一个提交请求</span></span><br><span class="line">  <span class="comment">// ...其他配置</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="headers-请求头"><strong>2. <code>headers</code>
请求头</strong></h5>
<p><strong>作用</strong></p>
<p>定义请求的元信息，用于告知服务器如何处理请求和数据格式。 -
<strong>关键字段</strong>： -
<strong><code>Content-Type</code></strong>：指定请求体（<code>body</code>）的数据格式。
- <code>application/json</code>：表示发送 JSON 数据。 -
<code>application/x-www-form-urlencoded</code>：表示表单数据（键值对）。
- <code>multipart/form-data</code>：用于上传文件。 -
<strong><code>Authorization</code></strong>：携带身份凭证（如 Token）。
- <strong><code>Accept</code></strong>：声明客户端期望的响应格式（如
JSON、XML）。</p>
<p><strong>示例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="attr">headers</span>: &#123;</span><br><span class="line">  <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>, <span class="comment">// 告诉服务器请求体是 JSON</span></span><br><span class="line">  <span class="string">&#x27;Authorization&#x27;</span>: <span class="string">&#x27;Bearer your_token_here&#x27;</span> <span class="comment">// 身份验证（可选）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="body-json.stringifyitem"><strong>3.
<code>body: JSON.stringify(item)</code></strong></h5>
<p><strong>作用</strong></p>
<p>定义请求体（即发送给服务器的数据），需根据 <code>Content-Type</code>
的类型进行格式化。 -
<strong><code>JSON.stringify(item)</code></strong>：将 JavaScript
对象转换为 JSON 字符串。 - 因为 HTTP
协议只能传输文本，不能直接传输对象。 - <strong>注意事项</strong>： -
若未设置
<code>Content-Type: application/json</code>，服务器可能无法正确解析数据。
- 若使用 <code>FormData</code> 上传文件，需使用
<code>multipart/form-data</code> 格式。</p>
<p><strong>示例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> item = &#123; <span class="attr">name</span>: <span class="string">&quot;Apple&quot;</span>, <span class="attr">price</span>: <span class="number">1.99</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="attr">body</span>: <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(item) <span class="comment">// 转换为 &#x27;&#123;&quot;name&quot;:&quot;Apple&quot;,&quot;price&quot;:1.99&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<h5 id="完整示例向-fastapi-提交数据"><strong>完整示例：向 FastAPI
提交数据</strong></h5>
<p><strong>FastAPI 后端定义</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Item</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    price: <span class="built_in">float</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/items/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_item</span>(<span class="params">item: Item</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;Item created&quot;</span>, <span class="string">&quot;item&quot;</span>: item&#125;</span><br></pre></td></tr></table></figure>
<p><strong>前端调用</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> item = &#123; <span class="attr">name</span>: <span class="string">&quot;Banana&quot;</span>, <span class="attr">price</span>: <span class="number">0.99</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="title function_">fetch</span>(<span class="string">&#x27;http://localhost:8000/items/&#x27;</span>, &#123;</span><br><span class="line">  <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span>,</span><br><span class="line">  <span class="attr">headers</span>: &#123;</span><br><span class="line">    <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span> <span class="comment">// 必须与数据格式匹配</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">body</span>: <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(item) <span class="comment">// 将对象转为 JSON 字符串</span></span><br><span class="line">&#125;)</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">response</span> =&gt;</span> response.<span class="title function_">json</span>())</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">data</span> =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(data))</span><br><span class="line">  .<span class="title function_">catch</span>(<span class="function"><span class="params">error</span> =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&#x27;Error:&#x27;</span>, error));</span><br></pre></td></tr></table></figure>
<h5 id="总结"><strong>总结</strong></h5>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 45%">
<col style="width: 40%">
</colgroup>
<thead>
<tr>
<th>参数</th>
<th>作用</th>
<th>必填性</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>method</code></td>
<td>定义请求类型（如 <code>POST</code>）</td>
<td>必填（非 <code>GET</code> 时）</td>
</tr>
<tr>
<td><code>headers</code></td>
<td>声明数据格式、身份凭证等</td>
<td>必填（尤其 <code>Content-Type</code>）</td>
</tr>
<tr>
<td><code>body</code></td>
<td>发送的数据（需格式化为字符串）</td>
<td>必填（<code>POST</code>/<code>PUT</code> 时）</td>
</tr>
</tbody>
</table>
<p><strong>关键点</strong>：<br>
- <code>POST</code> 请求必须设置 <code>headers['Content-Type']</code> 和
<code>body</code>。 - <code>JSON.stringify()</code> 是发送 JSON
数据的关键步骤。 - FastAPI 会根据 <code>Content-Type</code>
自动解析请求体并进行数据校验（通过 Pydantic 模型）。</p>
<h3 id="cors">CORS</h3>
<h4 id="cors-是什么"><strong>CORS 是什么？</strong></h4>
<p><strong>CORS（Cross-Origin Resource Sharing）</strong>
是一种浏览器安全机制，用于解决 <strong>跨域请求</strong>
的问题。它允许服务器明确授权某些跨域请求，从而在保障安全的前提下，实现前后端分离架构中的跨域通信。</p>
<h4 id="为什么需要-cors"><strong>为什么需要 CORS？</strong></h4>
<p><strong>1. 同源策略（Same-Origin Policy）</strong></p>
<p>浏览器默认遵循 <strong>同源策略</strong>，即网页只能请求与自身
<strong>同源（相同域名、协议、端口）</strong> 的资源。<br>
<strong>例如</strong>：</p>
<ul>
<li>前端地址：<code>http://localhost:3000</code></li>
<li>后端地址：<code>http://localhost:8000</code><br>
此时，前端向后端发起的请求会被浏览器
<strong>拦截</strong>，因为端口不同（3000 vs 8000）。</li>
</ul>
<p><strong>2. 跨域场景</strong></p>
<p>跨域是前后端分离架构中的常见问题，例如： - 前端部署在
<code>https://example.com</code>，后端 API 在
<code>https://api.example.com</code>。 -
前端本地开发（<code>localhost:3000</code>）调用后端服务（<code>localhost:8000</code>）。</p>
<p><strong>3. CORS 的作用</strong></p>
<p>CORS 通过 <strong>服务器响应头</strong>
告诉浏览器：“这个跨域请求是安全的，允许它通过”。<br>
浏览器根据这些响应头决定是否放行请求。</p>
<h4 id="如何配置-cors"><strong>如何配置 CORS？</strong></h4>
<p>以 <strong>FastAPI</strong> 为例，配置允许跨域请求的步骤如下：</p>
<p><strong>启用 CORS 中间件</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.middleware.cors <span class="keyword">import</span> CORSMiddleware</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 CORS</span></span><br><span class="line">app.add_middleware(</span><br><span class="line">    CORSMiddleware,</span><br><span class="line">    allow_origins=[<span class="string">&quot;http://localhost:3000&quot;</span>],  <span class="comment"># 允许的源</span></span><br><span class="line">    allow_credentials=<span class="literal">True</span>,                    <span class="comment"># 允许携带凭证</span></span><br><span class="line">    allow_methods=[<span class="string">&quot;*&quot;</span>],                       <span class="comment"># 允许所有方法（GET、POST 等）</span></span><br><span class="line">    allow_headers=[<span class="string">&quot;*&quot;</span>],                       <span class="comment"># 允许所有头信息</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="cors-的实际应用场景"><strong>CORS 的实际应用场景</strong></h4>
<p><strong>1. 前后端分离开发</strong></p>
<ul>
<li>前端（React/Vue）运行在
<code>localhost:3000</code>，后端（FastAPI）运行在
<code>localhost:8000</code>。</li>
<li>配置 <code>allow_origins=["http://localhost:3000"]</code>
允许跨域通信。</li>
</ul>
<p><strong>2. 第三方 API 调用</strong></p>
<ul>
<li>前端直接调用第三方服务（如天气 API），需服务器启用 CORS。</li>
<li>示例：<code>Access-Control-Allow-Origin: *</code>
表示允许所有来源。</li>
</ul>
<p><strong>3. 需要凭证的场景</strong></p>
<ul>
<li>前端需携带 Cookie 或 Token 访问后端接口： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">app.add_middleware(</span><br><span class="line">    CORSMiddleware,</span><br><span class="line">    allow_origins=[<span class="string">&quot;http://localhost:3000&quot;</span>],</span><br><span class="line">    allow_credentials=<span class="literal">True</span>,  <span class="comment"># 允许携带凭证</span></span><br><span class="line">    allow_methods=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line">    allow_headers=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="总结-1"><strong>总结</strong></h4>
<table>
<colgroup>
<col style="width: 19%">
<col style="width: 45%">
<col style="width: 34%">
</colgroup>
<thead>
<tr>
<th>概念</th>
<th>作用</th>
<th>配置示例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>同源策略</strong></td>
<td>浏览器安全机制，阻止跨域请求</td>
<td>默认启用</td>
</tr>
<tr>
<td><strong>CORS</strong></td>
<td>服务器通过响应头授权跨域请求</td>
<td><code>Access-Control-Allow-Origin</code></td>
</tr>
<tr>
<td><strong>预检请求</strong></td>
<td>OPTIONS 请求，验证复杂跨域请求的合法性</td>
<td>自动触发</td>
</tr>
<tr>
<td><strong>FastAPI 配置</strong></td>
<td>使用 <code>CORSMiddleware</code> 中间件</td>
<td><code>app.add_middleware(...)</code></td>
</tr>
</tbody>
</table>
<p><strong>最佳实践</strong>： 1.
<strong>开发阶段</strong>：允许所有来源（<code>allow_origins=["*"]</code>），方便调试。
2.
<strong>生产环境</strong>：严格限制允许的源、方法、头信息，避免安全风险。
3. <strong>携带凭证</strong>：启用 <code>allow_credentials=True</code>
并明确指定允许的源（避免使用 <code>*</code>）。</p>
<h3 id="nginx">Nginx</h3>
<h4 id="nginx-是什么"><strong>Nginx 是什么？</strong></h4>
<p><strong>Nginx</strong>（发音为 “engine-x”）是一个高性能的开源
<strong>Web 服务器、反向代理服务器、负载均衡器和 HTTP
缓存</strong>，广泛用于现代 Web
架构中。它以轻量级、低资源消耗和高并发处理能力著称，常用于优化网站性能、管理流量和提升安全性。</p>
<h4 id="nginx-的核心功能"><strong>Nginx 的核心功能</strong></h4>
<p><strong>1. Web 服务器</strong></p>
<ul>
<li><strong>静态资源托管</strong>：直接提供
HTML、CSS、JS、图片等静态文件服务。</li>
<li><strong>动态请求转发</strong>：将动态请求（如
API）转发给后端应用（如 FastAPI、Django、Node.js）。</li>
</ul>
<p><strong>2. 反向代理</strong></p>
<ul>
<li><strong>作用</strong>：接收客户端请求，转发给后端服务器（如
FastAPI），隐藏真实服务器地址。</li>
<li><strong>优势</strong>：提高安全性、支持负载均衡、缓存和 SSL
终端。</li>
</ul>
<p><strong>3. 负载均衡</strong></p>
<ul>
<li><strong>作用</strong>：将请求分发到多个后端服务器（如多个 FastAPI
实例），避免单点故障。</li>
<li><strong>算法</strong>：轮询（Round Robin）、最少连接（Least
Connections）、IP 哈希（IP Hash）等。</li>
</ul>
<p><strong>4. SSL/TLS 终端</strong></p>
<ul>
<li><strong>作用</strong>：处理 HTTPS
加密和解密，减轻后端服务器的压力。</li>
<li><strong>配置</strong>：绑定证书和私钥，强制 HTTPS。</li>
</ul>
<p><strong>5. 缓存</strong></p>
<ul>
<li><strong>作用</strong>：缓存静态资源（如图片、CSS）或动态内容（如 API
响应），减少后端负载。</li>
</ul>
<p><strong>6. 高可用性和容错</strong></p>
<ul>
<li><strong>健康检查</strong>：自动检测后端服务器状态，故障时切换备用节点。</li>
</ul>
<h4 id="nginx-的典型应用场景"><strong>Nginx 的典型应用场景</strong></h4>
<p><strong>1. 反向代理 FastAPI 服务</strong></p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/nginx/sites-available/fastapi.conf</span></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server_name</span> example.com;</span><br><span class="line"></span><br><span class="line">    <span class="section">location</span> / &#123;</span><br><span class="line">        <span class="attribute">proxy_pass</span> http://127.0.0.1:8000;  <span class="comment"># FastAPI 服务地址</span></span><br><span class="line">        <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：将 <code>example.com</code>
的请求转发给运行在 <code>127.0.0.1:8000</code> 的 FastAPI 服务。</li>
</ul>
<p><strong>2. 静态文件托管</strong></p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">location</span> /static/ &#123;</span><br><span class="line">    <span class="attribute">alias</span> /var/www/static/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：直接提供 <code>/var/www/static/</code>
目录下的静态文件（如图片、CSS）。</li>
</ul>
<h4 id="nginx-与-fastapi-的协作流程"><strong>Nginx 与 FastAPI
的协作流程</strong></h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">客户端 -&gt; Nginx（反向代理） -&gt; FastAPI（处理业务逻辑） -&gt; 数据库/其他服务</span><br></pre></td></tr></table></figure>
<ol type="1">
<li><strong>静态资源</strong>：由 Nginx 直接返回（如
HTML、CSS、JS）。</li>
<li><strong>API 请求</strong>：Nginx 转发给 FastAPI，FastAPI 处理后返回
JSON 数据。</li>
<li><strong>HTTPS</strong>：Nginx 处理加密和解密，FastAPI 无需关心
SSL。</li>
</ol>
<p><strong>最佳实践</strong>：</p>
<ol type="1">
<li><strong>开发阶段</strong>：直接运行
FastAPI（<code>uvicorn main:app --reload</code>）。</li>
<li><strong>生产环境</strong>：Nginx + FastAPI（Gunicorn/Uvicorn） +
数据库。</li>
<li><strong>性能优化</strong>：启用 Gzip
压缩、HTTP/2、缓存静态资源。</li>
</ol>
<p>通过 Nginx 的反向代理和负载均衡，可以显著提升 FastAPI
应用的性能、安全性和可扩展性。</p>
<h3 id="反向代理是什么">反向代理是什么？</h3>
<p><strong>反向代理（Reverse Proxy）</strong>
是一种服务器角色，它位于客户端与服务器之间，接收客户端的请求后，将请求转发给后端服务器（如
FastAPI、Django、Node.js
等），并将后端服务器的响应返回给客户端。<strong>它的核心作用是隐藏后端服务器的真实地址，优化请求处理流程，并增强安全性</strong>。</p>
<p>反向代理是现代 Web
架构中不可或缺的组件，尤其在前后端分离、微服务、高并发场景下作用显著。通过
Nginx 等工具实现反向代理，可以： - 提升安全性（隐藏后端、过滤攻击）。 -
优化性能（负载均衡、缓存静态资源）。 - 简化运维（集中管理
SSL、日志）。</p>
<p>对于 FastAPI 项目，推荐在生产环境中使用 Nginx
作为反向代理，以充分发挥其高性能和灵活性优势。</p>
<h3 id="二级域名是什么">二级域名是什么？</h3>
<p><strong>二级域名（Second-Level Domain, SLD）</strong>
是域名系统（DNS）中的一个层级，通常位于顶级域名（TLD）之下，主域名（一级域名）之上。它是域名结构中的关键部分，用于标识网站或服务的主体。</p>
<p><strong>域名层级结构</strong></p>
<p>域名由多个层级组成，从右向左层级递增，具体如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mail.example.com</span><br><span class="line">|     |        |</span><br><span class="line">|     |        └── 顶级域名（TLD）：com/net/org</span><br><span class="line">|     └────────── 二级域名（SLD）：example</span><br><span class="line">└──────────────── 子域名（Subdomain）：mail</span><br></pre></td></tr></table></figure>
<p><strong>1. 顶级域名（TLD）</strong></p>
<ul>
<li><strong>定义</strong>：域名的最后一部分，表示域名的类别或国家/地区。</li>
<li><strong>示例</strong>：<code>.com</code>（商业）、<code>.org</code>（非营利组织）、<code>.net</code>（网络服务）、<code>.cn</code>（中国）、<code>.jp</code>（日本）。</li>
</ul>
<p><strong>2. 二级域名（SLD）</strong></p>
<ul>
<li><strong>定义</strong>：位于 TLD
之下的域名部分，是域名的主体，通常由用户注册并拥有。</li>
<li><strong>示例</strong>：在 <code>example.com</code>
中，<code>example</code> 是二级域名。</li>
</ul>
<p><strong>3. 子域名（Subdomain）</strong></p>
<ul>
<li><strong>定义</strong>：在二级域名前添加的前缀，用于进一步细分网站或服务。</li>
<li><strong>示例</strong>：在 <code>mail.example.com</code>
中，<code>mail</code> 是子域名。</li>
</ul>
<p><strong>二级域名的常见用途</strong></p>
<ol type="1">
<li><strong>品牌标识</strong>：<br>
二级域名是品牌的核心标识，如
<code>google.com</code>、<code>apple.com</code>。</li>
<li><strong>服务划分</strong>：<br>
通过子域名区分不同服务，例如：
<ul>
<li><code>mail.google.com</code>：邮件服务</li>
<li><code>drive.google.com</code>：云存储服务</li>
<li><code>maps.google.com</code>：地图服务</li>
</ul></li>
<li><strong>多语言或地区支持</strong>：<br>
通过二级域名提供本地化内容，例如：
<ul>
<li><code>fr.wikipedia.org</code>（法语版）</li>
<li><code>zh.wikipedia.org</code>（中文版）</li>
</ul></li>
</ol>
<h3 id="dom元素">DOM元素</h3>
<p><strong>DOM（Document Object Model，文档对象模型）</strong>
是浏览器将 HTML 或 XML 文档解析为树状结构的编程接口。<strong>DOM
元素</strong> 是构成这棵树的节点（如
<code>&lt;div&gt;</code>、<code>&lt;p&gt;</code>、<code>&lt;button&gt;</code>
等），它们不仅是页面内容的载体，更是实现动态交互的核心工具。</p>
<h3 id="开发日志">开发日志</h3>
<h4 id="api">api</h4>
<p>获取apihttps://home.openweathermap.org/api_keys</p>
<p>api文档<a href="https://openweathermap.org/api">Weather API -
OpenWeatherMap</a></p>
<h4 id="版本1.0">版本1.0</h4>
<figure>
<img src="/2025/06/01/%E5%AD%A6%E4%B9%A0/python-web/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/image-20250602191448931.png" alt="image-20250602191448931">
<figcaption aria-hidden="true">image-20250602191448931</figcaption>
</figure>
<p>完成基本天气功能的开发</p>
<h4 id="版本2.0">版本2.0</h4>
<figure>
<img src="/2025/06/01/%E5%AD%A6%E4%B9%A0/python-web/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/image-20250604095743649.png" alt="image-20250604095743649">
<figcaption aria-hidden="true">image-20250604095743649</figcaption>
</figure>
<p>完成ai建议功能</p>
]]></content>
      <categories>
        <category>python-web</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
        <tag>前端</tag>
        <tag>fastapi</tag>
        <tag>项目</tag>
      </tags>
  </entry>
  <entry>
    <title>milvus</title>
    <url>/2025/09/08/%E5%AD%A6%E4%B9%A0/python-web/milvus/milvus/</url>
    <content><![CDATA[<h3 id="为什么使用milvus">为什么使用milvus</h3>
<p>非结构化数据（如文本、图像和音频）格式各异，蕴含丰富的潜在语义，因此分析起来极具挑战性。为了处理这种复杂性，Embeddings
被用来将非结构化数据转换成能够捕捉其基本特征的数字向量。然后将这些向量存储在向量数据库中，从而实现快速、可扩展的搜索和分析。</p>
<p>Milvus
提供强大的数据建模功能，使您能够将非结构化或多模式数据组织成结构化的
Collections。它支持多种数据类型，适用于不同的属性模型，包括常见的数字和字符类型、各种向量类型、数组、集合和
JSON，为您节省了维护多个数据库系统的精力。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/python-web/milvus/milvus/image-20250908091053654.png" alt="image-20250908091053654">
<figcaption aria-hidden="true">image-20250908091053654</figcaption>
</figure>
<h3 id="部署windows">部署（windows）</h3>
<p><a href="https://milvus.io/docs/zh/install_standalone-windows.md">在
Docker（Linux）中运行 Milvus | Milvus 文档</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Download the configuration file and rename it as docker-compose.yml</span><br><span class="line">C:\&gt;Invoke-WebRequest https://github.com/milvus-io/milvus/releases/download/v2.6.0/milvus-standalone-docker-compose.yml -OutFile docker-compose.yml</span><br><span class="line"></span><br><span class="line"># Start Milvus</span><br><span class="line">C:\&gt;docker compose up -d</span><br></pre></td></tr></table></figure>
<p>注意设置环境变量DOCKER_VOLUME_DIRECTORY来决定卷映射的路径</p>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 31%">
<col style="width: 14%">
<col style="width: 46%">
</colgroup>
<thead>
<tr>
<th>容器</th>
<th>镜像</th>
<th>在 Milvus 中的角色</th>
<th>一句话说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>etcd</td>
<td>quay.io/coreos/etcd:v3.5.18</td>
<td>元数据与协调中心</td>
<td>负责“记帐”——存索引结构、集合信息、节点心跳等，相当于 Milvus
的“大脑备忘录”。</td>
</tr>
<tr>
<td>minio</td>
<td>minio/minio:RELEASE.2024-12-18T13-15-44Z</td>
<td>对象存储</td>
<td>负责“存文件”——把向量索引文件、大字段、日志快照等落地成对象，相当于
Milvus 的“硬盘”。</td>
</tr>
<tr>
<td>standalone</td>
<td>milvusdb/milvus:v2.6.0</td>
<td>计算节点（单机版）</td>
<td>负责“干活”——接受 SDK 请求、做向量检索、构建索引，相当于 Milvus
的“工人”。</td>
</tr>
</tbody>
</table>
<h3 id="安装">安装</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -U pymilvus</span><br></pre></td></tr></table></figure>
<h3 id="基本概念">基本概念</h3>
<h4 id="数据库">数据库</h4>
<p>在 Milvus
中，数据库是组织和管理数据的逻辑单元。为了提高数据安全性并实现多租户，你可以创建多个数据库，为不同的应用程序或租户从逻辑上隔离数据。例如，创建一个数据库用于存储用户
A 的数据，另一个数据库用于存储用户 B 的数据。</p>
<h4 id="collections">collections</h4>
<p>在 Milvus 上，您可以创建多个 Collections
来管理数据，并将数据作为实体插入到 Collections 中。Collections
和实体<strong>类似于关系数据库中的表和记录</strong>。</p>
<p>Collection
是一个二维表，具有固定的列和变化的行。每列代表一个字段，每行代表一个实体。</p>
<p>下图显示了一个有 8 列和 6 个实体的 Collection。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/python-web/milvus/milvus/image-20250908094418551.png" alt="image-20250908094418551">
<figcaption aria-hidden="true">image-20250908094418551</figcaption>
</figure>
<h4 id="schema">schema</h4>
<p>Schema 定义了 Collections 的数据结构。在创建一个 Collection
之前，你需要设计出它的 Schema。</p>
<p>设计良好的 Schema
至关重要，因为它抽象了数据模型，并决定能否通过搜索实现业务目标。此外，由于插入
Collections 的每一行数据都必须遵循
Schema，因此有助于保持数据的一致性和长期质量。从技术角度看，定义明确的
Schema
会带来组织良好的列数据存储和更简洁的索引结构，从而提升搜索性能。</p>
<p>一个 Collection Schema
有一个主键、最多四个向量字段和几个标量字段。下图说明了如何将文章映射到模式字段列表。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/python-web/milvus/milvus/image-20250908094645183.png" alt="image-20250908094645183">
<figcaption aria-hidden="true">image-20250908094645183</figcaption>
</figure>
<h3 id="与langchain集成">与langchain集成</h3>
<p><a href="https://python.langchain.com/docs/integrations/vectorstores/milvus/#query-directly">Milvus
| 🦜️🔗 LangChain</a></p>
<p><a href="https://milvus.io/docs/zh/integrate_with_langchain.md">使用
Milvus 和 LangChain 的检索增强生成（RAG） | Milvus 文档</a></p>
<p>本人实现的用于分块后存储入milvus的类</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class MilvusStorage:</span><br><span class="line">    &quot;&quot;&quot;Milvus向量存储管理类</span><br><span class="line">    </span><br><span class="line">    负责将分块后的文档内容存储到Milvus向量数据库中，</span><br><span class="line">    支持向量检索和BM25全文检索。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    def __init__(self, </span><br><span class="line">                 embedding_function: Embeddings,</span><br><span class="line">                 uri: Optional[str] = None, </span><br><span class="line">                 db_name: Optional[str] = None,</span><br><span class="line">                 token: Optional[str] = None,</span><br><span class="line">                 collection_name: Optional[str] = None):</span><br><span class="line">        &quot;&quot;&quot;初始化Milvus存储客户端</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            embedding_function: LangChain embedding模型实例（必需）</span><br><span class="line">            uri: Milvus服务地址，默认从环境变量MILVUS_URI获取</span><br><span class="line">            db_name: 数据库名称，默认从环境变量MILVUS_DB_NAME获取</span><br><span class="line">            token: 认证令牌，默认从环境变量MILVUS_TOKEN获取（可选）</span><br><span class="line">            collection_name: 集合名称，默认从环境变量MILVUS_COLLECTION_NAME获取</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 验证必需参数</span><br><span class="line">        if not embedding_function:</span><br><span class="line">            raise ValueError(&quot;embedding_function是必需参数，必须提供LangChain Embeddings实例&quot;)</span><br><span class="line">        </span><br><span class="line">        # 从环境变量读取配置，如果参数没有提供的话</span><br><span class="line">        self.uri = uri or os.getenv(&#x27;MILVUS_URI&#x27;, &#x27;http://localhost:19530&#x27;)</span><br><span class="line">        self.db_name = db_name or os.getenv(&#x27;MILVUS_DB_NAME&#x27;, &#x27;rag&#x27;)</span><br><span class="line">        self.token = token or os.getenv(&#x27;MILVUS_TOKEN&#x27;) or None</span><br><span class="line">        self.collection_name = collection_name or os.getenv(&#x27;MILVUS_COLLECTION_NAME&#x27;, &#x27;chunks&#x27;)</span><br><span class="line">        </span><br><span class="line">        # 设置embedding函数</span><br><span class="line">        self.embedding_function = embedding_function</span><br><span class="line">        </span><br><span class="line">        # 初始化LangChain Milvus向量存储</span><br><span class="line">        self.vector_store = Milvus(</span><br><span class="line">            embedding_function=self.embedding_function,</span><br><span class="line">            connection_args=&#123;</span><br><span class="line">                &quot;uri&quot;: self.uri,</span><br><span class="line">                &quot;db_name&quot;: self.db_name,</span><br><span class="line">                &quot;token&quot;: self.token</span><br><span class="line">            &#125; if self.token else &#123;</span><br><span class="line">                &quot;uri&quot;: self.uri,</span><br><span class="line">                &quot;db_name&quot;: self.db_name</span><br><span class="line">            &#125;,</span><br><span class="line">            collection_name=self.collection_name,</span><br><span class="line">            index_params=&#123;&quot;index_type&quot;: &quot;HNSW&quot;, &quot;metric_type&quot;: &quot;COSINE&quot;, &quot;params&quot;: &#123;&quot;M&quot;: 16, &quot;efConstruction&quot;: 200&#125;&#125;</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    def store_chunks(self, chunk_result: ChunkResult) -&gt; Dict[str, Any]:</span><br><span class="line">        &quot;&quot;&quot;存储分块结果到Milvus</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            chunk_result: 分块结果对象</span><br><span class="line">            </span><br><span class="line">        Returns:</span><br><span class="line">            Dict: 插入结果，包含插入状态和记录数</span><br><span class="line">            </span><br><span class="line">        Raises:</span><br><span class="line">            ValueError: 当向量存储未初始化时</span><br><span class="line">            Exception: Milvus操作异常</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if not self.vector_store:</span><br><span class="line">            raise ValueError(&quot;向量存储未初始化&quot;)</span><br><span class="line">        </span><br><span class="line">        if not chunk_result.chunks:</span><br><span class="line">            return &#123;</span><br><span class="line">                &quot;status&quot;: &quot;success&quot;, </span><br><span class="line">                &quot;inserted_count&quot;: 0,</span><br><span class="line">                &quot;message&quot;: &quot;无数据需要插入&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        </span><br><span class="line">        try:</span><br><span class="line">            # 转换为LangChain Document格式</span><br><span class="line">            documents = self._convert_chunks_to_langchain_docs(chunk_result)</span><br><span class="line">            </span><br><span class="line">            # 为每个文档生成UUID作为主键</span><br><span class="line">            from uuid import uuid4</span><br><span class="line">            uuids = [str(uuid4()) for _ in range(len(documents))]</span><br><span class="line">            </span><br><span class="line">            # 使用LangChain Milvus添加文档，指定IDs</span><br><span class="line">            ids = self.vector_store.add_documents(documents=documents, ids=uuids)</span><br><span class="line">            </span><br><span class="line">            return &#123;</span><br><span class="line">                &quot;status&quot;: &quot;success&quot;,</span><br><span class="line">                &quot;inserted_count&quot;: len(documents),</span><br><span class="line">                &quot;document_ids&quot;: ids,</span><br><span class="line">                &quot;document_name&quot;: chunk_result.document_name,</span><br><span class="line">                &quot;strategy&quot;: chunk_result.strategy.value,</span><br><span class="line">                &quot;collection_name&quot;: self.collection_name</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        except Exception as e:</span><br><span class="line">            raise Exception(f&quot;Milvus插入失败: &#123;str(e)&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    def _convert_chunks_to_langchain_docs(self, chunk_result: ChunkResult) -&gt; List[Document]:</span><br><span class="line">        &quot;&quot;&quot;为现有Documents添加存储所需的元数据</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            chunk_result: 分块结果，chunks已经是Document列表</span><br><span class="line">            </span><br><span class="line">        Returns:</span><br><span class="line">            List[Document]: 添加了元数据的Document列表</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        documents = []</span><br><span class="line">        </span><br><span class="line">        for idx, chunk in enumerate(chunk_result.chunks):</span><br><span class="line">            # 创建符合Milvus集合schema的元数据</span><br><span class="line">            # 注意：page_content会自动映射到text_content字段</span><br><span class="line">            updated_metadata = &#123;</span><br><span class="line">                **chunk.metadata,  # 保留原有元数据</span><br><span class="line">                &quot;document_name&quot;: chunk_result.document_name,</span><br><span class="line">                &quot;chunk_index&quot;: idx,</span><br><span class="line">                &quot;chunk_size&quot;: len(chunk.page_content)</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            # 创建新Document以避免修改原始数据</span><br><span class="line">            # LangChain会自动将page_content映射到Milvus的text_content字段</span><br><span class="line">            # embedding字段会由embedding_function自动生成</span><br><span class="line">            doc = Document(</span><br><span class="line">                page_content=chunk.page_content,</span><br><span class="line">                metadata=updated_metadata</span><br><span class="line">            )</span><br><span class="line">            documents.append(doc)</span><br><span class="line">        </span><br><span class="line">        return documents</span><br><span class="line">    </span><br><span class="line">    def store_chunks_batch(self, chunk_results: List[ChunkResult]) -&gt; Dict[str, Any]:</span><br><span class="line">        &quot;&quot;&quot;批量存储多个分块结果到Milvus</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            chunk_results: 分块结果列表</span><br><span class="line">            </span><br><span class="line">        Returns:</span><br><span class="line">            Dict: 批量插入结果</span><br><span class="line">            </span><br><span class="line">        Raises:</span><br><span class="line">            ValueError: 当向量存储未初始化时</span><br><span class="line">            Exception: Milvus操作异常</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        if not self.vector_store:</span><br><span class="line">            raise ValueError(&quot;向量存储未初始化&quot;)</span><br><span class="line">        </span><br><span class="line">        if not chunk_results:</span><br><span class="line">            return &#123;</span><br><span class="line">                &quot;status&quot;: &quot;success&quot;,</span><br><span class="line">                &quot;message&quot;: &quot;没有分块结果需要存储&quot;,</span><br><span class="line">                &quot;total_chunks&quot;: 0,</span><br><span class="line">                &quot;document_count&quot;: 0</span><br><span class="line">            &#125;</span><br><span class="line">        </span><br><span class="line">        try:</span><br><span class="line">            # 收集所有文档</span><br><span class="line">            all_documents = []</span><br><span class="line">            total_chunks = 0</span><br><span class="line">            </span><br><span class="line">            for chunk_result in chunk_results:</span><br><span class="line">                if chunk_result.chunks:</span><br><span class="line">                    documents = self._convert_chunks_to_langchain_docs(chunk_result)</span><br><span class="line">                    all_documents.extend(documents)</span><br><span class="line">                    total_chunks += len(documents)</span><br><span class="line">            </span><br><span class="line">            if not all_documents:</span><br><span class="line">                return &#123;</span><br><span class="line">                    &quot;status&quot;: &quot;success&quot;,</span><br><span class="line">                    &quot;message&quot;: &quot;没有文档需要存储&quot;,</span><br><span class="line">                    &quot;total_chunks&quot;: 0,</span><br><span class="line">                    &quot;document_count&quot;: len(chunk_results)</span><br><span class="line">                &#125;</span><br><span class="line">            </span><br><span class="line">            # 为所有文档生成UUID作为主键</span><br><span class="line">            from uuid import uuid4</span><br><span class="line">            uuids = [str(uuid4()) for _ in range(len(all_documents))]</span><br><span class="line">            </span><br><span class="line">            # 批量添加所有文档，指定IDs</span><br><span class="line">            ids = self.vector_store.add_documents(documents=all_documents, ids=uuids)</span><br><span class="line">            </span><br><span class="line">            return &#123;</span><br><span class="line">                &quot;status&quot;: &quot;success&quot;,</span><br><span class="line">                &quot;message&quot;: f&quot;成功存储 &#123;len(chunk_results)&#125; 个文档的 &#123;total_chunks&#125; 个分块&quot;,</span><br><span class="line">                &quot;total_chunks&quot;: total_chunks,</span><br><span class="line">                &quot;document_count&quot;: len(chunk_results),</span><br><span class="line">                &quot;ids&quot;: ids,</span><br><span class="line">                &quot;collection_name&quot;: self.collection_name</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        except Exception as e:</span><br><span class="line">            raise Exception(f&quot;Milvus批量插入失败: &#123;str(e)&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    def delete_document(self, </span><br><span class="line">                       document_name: str, </span><br><span class="line">                       collection_name: Optional[str] = None) -&gt; Dict[str, Any]:</span><br><span class="line">        &quot;&quot;&quot;删除指定文档的所有chunks</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            document_name: 文档名称</span><br><span class="line">            collection_name: collection名称</span><br><span class="line">            </span><br><span class="line">        Returns:</span><br><span class="line">            Dict: 删除结果</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        target_collection = collection_name or self.collection_name</span><br><span class="line">        </span><br><span class="line">        try:</span><br><span class="line">            if not self.vector_store:</span><br><span class="line">                raise ValueError(&quot;向量存储未初始化&quot;)</span><br><span class="line">            </span><br><span class="line">            # 使用LangChain Milvus删除功能</span><br><span class="line">            # 注意：LangChain Milvus可能不支持按元数据过滤删除，这里提供基本实现</span><br><span class="line">            return &#123;</span><br><span class="line">                &quot;status&quot;: &quot;error&quot;,</span><br><span class="line">                &quot;document_name&quot;: document_name,</span><br><span class="line">                &quot;error&quot;: &quot;LangChain Milvus不支持按文档名删除，请使用其他方式&quot;,</span><br><span class="line">                &quot;collection_name&quot;: target_collection</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        except Exception as e:</span><br><span class="line">            return &#123;</span><br><span class="line">                &quot;status&quot;: &quot;error&quot;, </span><br><span class="line">                &quot;document_name&quot;: document_name,</span><br><span class="line">                &quot;error&quot;: str(e)</span><br><span class="line">            &#125;</span><br><span class="line">    </span><br><span class="line">    def get_document_stats(self, </span><br><span class="line">                          document_name: Optional[str] = None,</span><br><span class="line">                          collection_name: Optional[str] = None) -&gt; Dict[str, Any]:</span><br><span class="line">        &quot;&quot;&quot;获取文档统计信息</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            document_name: 文档名称，None则统计所有文档</span><br><span class="line">            collection_name: collection名称</span><br><span class="line">            </span><br><span class="line">        Returns:</span><br><span class="line">            Dict: 统计信息</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        target_collection = collection_name or self.collection_name</span><br><span class="line">        </span><br><span class="line">        try:</span><br><span class="line">            if not self.vector_store:</span><br><span class="line">                raise ValueError(&quot;向量存储未初始化&quot;)</span><br><span class="line">            </span><br><span class="line">            # 使用LangChain Milvus获取基本信息</span><br><span class="line">            # 注意：LangChain Milvus没有直接的统计方法，这里提供基本信息</span><br><span class="line">            return &#123;</span><br><span class="line">                &quot;status&quot;: &quot;success&quot;,</span><br><span class="line">                &quot;collection_name&quot;: target_collection,</span><br><span class="line">                &quot;vector_store_type&quot;: &quot;LangChain Milvus&quot;,</span><br><span class="line">                &quot;embedding_function&quot;: str(type(self.embedding_function).__name__),</span><br><span class="line">                &quot;connection_uri&quot;: self.uri,</span><br><span class="line">                &quot;database_name&quot;: self.db_name,</span><br><span class="line">                &quot;message&quot;: &quot;详细统计信息需要通过其他方式获取&quot;</span><br><span class="line">            &#125;</span><br><span class="line">                </span><br><span class="line">        except Exception as e:</span><br><span class="line">            return &#123;</span><br><span class="line">                &quot;status&quot;: &quot;error&quot;,</span><br><span class="line">                &quot;error&quot;: str(e)</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<h3 id="基本ann搜索">基本ANN搜索</h3>
<p>近似近邻（ANN）搜索以记录向量嵌入排序顺序的索引文件为基础，根据接收到的搜索请求中携带的查询向量查找向量嵌入子集，将查询向量与子群中的向量进行比较，并返回最相似的结果。</p>
<p>ANN 和 k-Nearest Neighbors (kNN) 搜索是向量相似性搜索的常用方法。在
kNN
搜索中，必须将向量空间中的所有向量与搜索请求中携带的查询向量进行比较，然后找出最相似的向量，这既耗时又耗费资源。</p>
<p>与 kNN 搜索不同，ANN
搜索算法要求提供一个<strong>索引</strong>文件，记录向量 Embeddings
的排序顺序。当收到搜索请求时，可以使用索引文件作为参考，快速找到可能包含与查询向量最相似的向量嵌入的子组。然后，你可以使用指定的<strong>度量类型</strong>来测量查询向量与子组中的向量之间的相似度，根据与查询向量的相似度对组成员进行排序，并找出<strong>前
K 个</strong>组成员。</p>
<p>ANN
搜索依赖于预建索引，搜索吞吐量、内存使用量和搜索正确性可能会因选择的索引类型而不同。您需要在搜索性能和正确性之间取得平衡。</p>
<h3 id="混合检索">混合检索</h3>
<p><a href="https://milvus.io/docs/zh/multi-vector-search.md">多向量混合搜索 |
Milvus 文档</a></p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/python-web/milvus/milvus/image-20250908092720695.png" alt="image-20250908092720695">
<figcaption aria-hidden="true">image-20250908092720695</figcaption>
</figure>
<p>让我们考虑一个真实世界的使用案例，其中每个产品都包含文字描述和图片。根据可用数据，我们可以进行三种类型的搜索：</p>
<ul>
<li><strong>语义文本搜索：</strong>这涉及使用密集向量查询产品的文本描述。可以使用<a href="https://zilliz.com/learn/explore-colbert-token-level-embedding-and-ranking-model-for-similarity-search?_gl=1*d243m9*_gcl_au*MjcyNTAwMzUyLjE3NDMxMzE1MjY.*_ga*MTQ3OTI4MDc5My4xNzQzMTMxNTI2*_ga_KKMVYG8YF2*MTc0NTkwODU0Mi45NC4xLjE3NDU5MDg4MzcuMC4wLjA.&amp;__hstc=175614333.1360fa4d62338b70e9a0f2412f87e2d8.1757161116448.1757218172494.1757289528471.4&amp;__hssc=175614333.2.1757289528471&amp;__hsfp=990823879#A-Quick-Recap-of-BERT">BERT</a>和<a href="https://zilliz.com/learn/NLP-essentials-understanding-transformers-in-AI?_gl=1*d243m9*_gcl_au*MjcyNTAwMzUyLjE3NDMxMzE1MjY.*_ga*MTQ3OTI4MDc5My4xNzQzMTMxNTI2*_ga_KKMVYG8YF2*MTc0NTkwODU0Mi45NC4xLjE3NDU5MDg4MzcuMC4wLjA.&amp;__hstc=175614333.1360fa4d62338b70e9a0f2412f87e2d8.1757161116448.1757218172494.1757289528471.4&amp;__hssc=175614333.2.1757289528471&amp;__hsfp=990823879">Transformers</a>等模型或<a href="https://zilliz.com/learn/guide-to-using-openai-text-embedding-models?__hstc=175614333.1360fa4d62338b70e9a0f2412f87e2d8.1757161116448.1757218172494.1757289528471.4&amp;__hssc=175614333.2.1757289528471&amp;__hsfp=990823879">OpenAI</a>
等服务生成文本嵌入。</li>
<li><strong>全文搜索</strong>：在这里，我们使用稀疏向量的关键词匹配来查询产品的文本描述。<a href="https://zilliz.com/learn/mastering-bm25-a-deep-dive-into-the-algorithm-and-application-in-milvus?__hstc=175614333.1360fa4d62338b70e9a0f2412f87e2d8.1757161116448.1757218172494.1757289528471.4&amp;__hssc=175614333.2.1757289528471&amp;__hsfp=990823879">BM25</a>等算法或<a href="https://zilliz.com/learn/bge-m3-and-splade-two-machine-learning-models-for-generating-sparse-embeddings?_gl=1*1cde1oq*_gcl_au*MjcyNTAwMzUyLjE3NDMxMzE1MjY.*_ga*MTQ3OTI4MDc5My4xNzQzMTMxNTI2*_ga_KKMVYG8YF2*MTc0NTkwODU0Mi45NC4xLjE3NDU5MDg4MzcuMC4wLjA.&amp;__hstc=175614333.1360fa4d62338b70e9a0f2412f87e2d8.1757161116448.1757218172494.1757289528471.4&amp;__hssc=175614333.2.1757289528471&amp;__hsfp=990823879#BGE-M3">BGE-M3</a>或<a href="https://zilliz.com/learn/bge-m3-and-splade-two-machine-learning-models-for-generating-sparse-embeddings?_gl=1*ov2die*_gcl_au*MjcyNTAwMzUyLjE3NDMxMzE1MjY.*_ga*MTQ3OTI4MDc5My4xNzQzMTMxNTI2*_ga_KKMVYG8YF2*MTc0NTkwODU0Mi45NC4xLjE3NDU5MDg4MzcuMC4wLjA.&amp;__hstc=175614333.1360fa4d62338b70e9a0f2412f87e2d8.1757161116448.1757218172494.1757289528471.4&amp;__hssc=175614333.2.1757289528471&amp;__hsfp=990823879#SPLADE">SPLADE</a>等稀疏嵌入模型可用于此目的。</li>
<li><strong>多模态图像搜索：</strong>这种方法使用带有密集向量的文本查询对图像进行查询。可以使用<a href="https://zilliz.com/learn/exploring-openai-clip-the-future-of-multimodal-ai-learning?__hstc=175614333.1360fa4d62338b70e9a0f2412f87e2d8.1757161116448.1757218172494.1757289528471.4&amp;__hssc=175614333.2.1757289528471&amp;__hsfp=990823879&amp;_gl=1*90lcis*_gcl_au*MTI2OTI1Njc4OS4xNzU3MTYxMTEz*_ga*NTMyMTM0NTIwLjE3NTcxNjExMTM.*_ga_KKMVYG8YF2*czE3NTcyOTM4NzUkbzUkZzEkdDE3NTcyOTQ4MTMkajYwJGwwJGgw">CLIP</a>
等模型生成图像嵌入。</li>
</ul>
<p>混合检索的构建流程：</p>
<ol type="1">
<li><p>创建具有多个向量场的 Collections</p>
<ul>
<li>定义 Collections Schema</li>
<li>配置索引参数</li>
<li>创建 Collections</li>
</ul></li>
<li><p>插入数据‘</p></li>
<li><p>执行混合搜索</p>
<ul>
<li><p>创建多个 AnnSearchRequest 实例</p>
<p>混合搜索是通过在<code>hybrid_search()</code>
函数中创建多个<code>AnnSearchRequest</code>
来实现的，其中每个<code>AnnSearchRequest</code> 代表一个特定向量场的基本
ANN
搜索请求。因此，在进行混合搜索之前，有必要为每个向量场创建一个<code>AnnSearchRequest</code>
。</p></li>
<li><p>配置 Rerankers 策略</p></li>
</ul></li>
</ol>
<h3 id="rerankers-策略">Rerankers 策略</h3>
<p><a href="https://milvus.io/docs/zh/rrf-ranker.md">RRF 排序器 | Milvus
文档</a></p>
<p>要对 ANN
搜索结果集进行合并和重新排序，选择适当的重新排序策略至关重要。Milvus
提供两种重排策略：</p>
<ul>
<li><strong>加权排名</strong>：如果结果需要强调某个向量场，请使用该策略。WeightedRanker
可以为某些向量场赋予更大的权重，使其更加突出。</li>
<li><strong>RRFRanker（互易排名融合排名器）</strong>：在不需要特别强调的情况下选择此策略。RRFRanker
能有效平衡每个向量场的重要性。</li>
</ul>
<h4 id="加权排名">加权排名</h4>
<p>加权排名器通过为每个搜索路径分配不同的重要性权重，智能地组合来自多个搜索路径的结果并确定其优先级。与技艺高超的厨师平衡多种配料以制作完美菜肴的方式类似，加权排名器也会平衡不同的搜索结果，以提供最相关的综合结果。这种方法非常适合在多个向量场或模式中进行搜索，其中某些场对最终排名的贡献应比其他场更大。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/python-web/milvus/milvus/image-20250908092538807.png" alt="image-20250908092538807">
<figcaption aria-hidden="true">image-20250908092538807</figcaption>
</figure>
<h4 id="rrfranker">RRFRanker</h4>
<p>互惠排名融合（RRF）排名器是 Milvus
混合搜索的一种重新排名策略，它根据多个向量搜索路径的排名位置而不是原始相似度得分来平衡搜索结果。就像体育比赛考虑的是球员的排名而不是个人统计数据一样，RRF
Ranker
根据每个项目在不同搜索路径中的排名高低来组合搜索结果，从而创建一个公平、均衡的最终排名。</p>
<p>RRF Ranker
专门设计用于<strong>混合搜索场景</strong>，在这种场景中，您需要平衡来自多个向量搜索路径的结果，而无需分配明确的重要性权重。</p>
<figure>
<img src="/2025/09/08/%E5%AD%A6%E4%B9%A0/python-web/milvus/milvus/image-20250908092346065.png" alt="image-20250908092346065">
<figcaption aria-hidden="true">image-20250908092346065</figcaption>
</figure>
<h3 id="多租户">多租户</h3>
<p><a href="https://milvus.io/docs/zh/multi_tenancy.md#Partition-key-based-multi-tenancy">实施多租户
| Milvus 文档</a></p>
<p>Milvus
支持四个级别的多租户：<strong>数据库</strong>、<strong>Collection</strong>、<strong>Partition</strong>
和<strong>Partition Key</strong>。</p>
<table style="width:100%;">
<colgroup>
<col style="width: 11%">
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 14%">
<col style="width: 17%">
</colgroup>
<thead>
<tr>
<th>** 数据库级**</th>
<th><strong>Collections 级</strong></th>
<th><strong>分区级</strong></th>
<th><strong>分区 Key 级</strong></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>数据隔离</strong></td>
<td>物理</td>
<td>物理</td>
<td>物理</td>
<td>物理 + 逻辑</td>
</tr>
<tr>
<td><strong>最大租户数</strong></td>
<td>默认为 64 个。您可以通过修改 Milvus.yaml
配置文件中的<code>maxDatabaseNum</code> 参数来增加租户数。</td>
<td>默认为 65,536。可以通过修改 Milvus.yaml
配置文件中的<code>maxCollectionNum</code> 参数来增加。</td>
<td>每个 Collection 最多 1,024 个。</td>
<td>百万</td>
</tr>
<tr>
<td><strong>数据 Schema 灵活性</strong></td>
<td>高</td>
<td>中</td>
<td>低</td>
<td>低</td>
</tr>
<tr>
<td><strong>RBAC 支持</strong></td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td><strong>搜索性能</strong></td>
<td>强</td>
<td>强</td>
<td>中等</td>
<td>中等</td>
</tr>
<tr>
<td><strong>跨租户搜索支持</strong></td>
<td>不支持</td>
<td>支持</td>
<td>支持</td>
<td>是</td>
</tr>
<tr>
<td><strong>支持有效处理冷热数据</strong></td>
<td>是</td>
<td>是</td>
<td>支持</td>
<td>否 目前不支持 Partition Key 级策略。</td>
</tr>
</tbody>
</table>
<h3 id="比较有意思的教程">比较有意思的教程</h3>
<p>多模态rag<a href="https://milvus.io/docs/zh/multimodal_rag_with_milvus.md">用 Milvus
制作多模态 RAG | Milvus 文档</a></p>
<p><a href="https://milvus.io/docs/zh/text_image_search.md">使用 Milvus
进行文本到图像搜索 | Milvus 文档</a></p>
<p><a href="https://milvus.io/docs/zh/image_similarity_search.md">使用
Milvus 搜索图像 | Milvus 文档</a></p>
]]></content>
      <categories>
        <category>python-web</category>
        <category>milvus</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>postgresql</title>
    <url>/2025/09/11/%E5%AD%A6%E4%B9%A0/python-web/postgresql/postgresql/</url>
    <content><![CDATA[<h3 id="docker部署">docker部署</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull postgres</span><br><span class="line"></span><br><span class="line">docker run -d --name pgsql \</span><br><span class="line">  -p 5432:5432 \</span><br><span class="line">  -e POSTGRES_PASSWORD=123456 \</span><br><span class="line">  -v D:\database\postgresql:/var/lib/postgresql/data \</span><br><span class="line">  postgres</span><br><span class="line">  </span><br><span class="line">  docker run -d --name pgsql -p 5432:5432 -e POSTGRES_PASSWORD=123456 -v D:\database\postgresql:/var/lib/postgresql/data postgres</span><br></pre></td></tr></table></figure>
<p><a href="https://www.cnblogs.com/nulixuexipython/p/18040243">docker
运行postgresql 极限简洁教程 - 刘老六 - 博客园</a></p>
<h3 id="恢复数据库">恢复数据库</h3>
<p>使用pg_restore</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1. 删除现有数据库</span><br><span class="line">psql -U postgres -c &quot;DROP DATABASE dvdrental;&quot;</span><br><span class="line"></span><br><span class="line"># 2. 重建空数据库</span><br><span class="line">psql -U postgres -c &quot;CREATE DATABASE dvdrental;&quot;</span><br><span class="line"></span><br><span class="line">pg_restore --dbname=postgresql://postgres:123456@localhost:5432/dvdrental --no-owner /workspace/dvdrental</span><br></pre></td></tr></table></figure>
<p>以下是数据库导入的原理</p>
<ol type="1">
<li>toc.dat（目录文件）</li>
</ol>
<p>作用 ：Table of Contents，包含备份的元数据信息</p>
<p>内容 ：数据库结构、表定义、索引、约束、函数等的描述</p>
<p>格式 ：二进制格式，记录了所有数据库对象的信息</p>
<ol start="2" type="1">
<li>数据文件（3038.dat, 3040.dat, …）</li>
</ol>
<p>作用 ：存储实际的表数据</p>
<p>命名规则 ：数字对应数据库对象的 OID（Object Identifier）</p>
<ol start="3" type="1">
<li>restore.sql（可选的SQL脚本）</li>
</ol>
<p>作用 ：包含恢复数据库的 SQL 命令</p>
<p>内容 ：CREATE TABLE、INSERT、索引创建等语句</p>
<p><strong>pg_restore 工作流程</strong></p>
<ol type="1">
<li>读取 toc.dat</li>
<li>创建数据库结构</li>
<li>创建约束和索引</li>
</ol>
<h3 id="sqlalchemy-orm">SQLAlchemy ORM</h3>
<p>范例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">config:</span><br><span class="line">  layout: elk</span><br><span class="line">---</span><br><span class="line">erDiagram</span><br><span class="line">    零件（Part） ||--o&#123; 库存（Inventory） : &quot;存放&quot;</span><br><span class="line">    库房（Warehouse） ||--o&#123; 库存（Inventory） : &quot;包含&quot;</span><br><span class="line">    供应商（Supplier） ||--o&#123; 采购（Purchase） : &quot;供应&quot;</span><br><span class="line">    零件（Part） ||--o&#123; 采购（Purchase） : &quot;被采购&quot;</span><br><span class="line">    库房（Warehouse） ||--o&#123; 采购（Purchase） : &quot;接收&quot;</span><br><span class="line">    库房（Warehouse） &#125;|--|| 职工（Staff） : &quot;组长&quot;</span><br><span class="line">    库房（Warehouse） ||--o&#123; 职工（Staff） : &quot;雇佣&quot;</span><br><span class="line">    零件（Part） &#123;</span><br><span class="line">        string part_id PK &quot;零件编号&quot;</span><br><span class="line">        string name &quot;名称&quot;</span><br><span class="line">        decimal unit_price &quot;单价&quot;</span><br><span class="line">        string type &quot;类型&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    供应商（Supplier） &#123;</span><br><span class="line">        string supplier_id PK &quot;供应商编号&quot;</span><br><span class="line">        string name &quot;名称&quot;</span><br><span class="line">        string address &quot;地址&quot;</span><br><span class="line">        string phone &quot;电话&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    库房（Warehouse） &#123;</span><br><span class="line">        string warehouse_id PK &quot;库房号&quot;</span><br><span class="line">        string address &quot;地址&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    职工（Staff） &#123;</span><br><span class="line">        string staff_id PK &quot;职工号&quot;</span><br><span class="line">        string name &quot;姓名&quot;</span><br><span class="line">        string gender &quot;性别&quot;</span><br><span class="line">        date hire_date &quot;进厂时间&quot;</span><br><span class="line">        string title &quot;职称&quot;</span><br><span class="line">        string warehouse_id FK &quot;所属库房&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    库存（Inventory） &#123;</span><br><span class="line">        string warehouse_id PK,FK &quot;库房号&quot;</span><br><span class="line">        string part_id PK,FK &quot;零件编号&quot;</span><br><span class="line">        int stock_quantity &quot;库存数量&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    采购（Purchase） &#123;</span><br><span class="line">        string purchase_id PK &quot;采购单号&quot;</span><br><span class="line">        string part_id FK &quot;零件编号&quot;</span><br><span class="line">        string supplier_id FK &quot;供应商编号&quot;</span><br><span class="line">        string warehouse_id FK &quot;库房号&quot;</span><br><span class="line">        date purchase_date &quot;采购日期&quot;</span><br><span class="line">        int quantity &quot;进货数量&quot;</span><br><span class="line">        decimal actual_price &quot;实际单价&quot;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># models.py</span><br><span class="line">from sqlalchemy import (</span><br><span class="line">    create_engine, Column, String, Integer, DECIMAL, Date, CHAR,</span><br><span class="line">    ForeignKey, CheckConstraint, UniqueConstraint</span><br><span class="line">)</span><br><span class="line">from sqlalchemy.ext.declarative import declarative_base</span><br><span class="line">from sqlalchemy.orm import relationship</span><br><span class="line"></span><br><span class="line"># SQLAlchemy 的基类，所有模型类都需要继承这个 Base</span><br><span class="line"># declarative_base() 创建了一个基类，用于定义数据库表结构的映射</span><br><span class="line">Base = declarative_base()</span><br><span class="line"></span><br><span class="line">class Part(Base):</span><br><span class="line">    __tablename__ = &#x27;part&#x27;</span><br><span class="line">    </span><br><span class="line">    part_id = Column(String(20), primary_key=True)</span><br><span class="line">    name = Column(String(100), nullable=False)</span><br><span class="line">    unit_price = Column(DECIMAL(10, 2), nullable=False)</span><br><span class="line">    type = Column(String(50), nullable=False)</span><br><span class="line">    </span><br><span class="line">    # 约束：单价 &gt;= 0</span><br><span class="line">    __table_args__ = (</span><br><span class="line">        CheckConstraint(unit_price &gt;= 0, name=&#x27;check_unit_price_positive&#x27;),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">class Supplier(Base):</span><br><span class="line">    __tablename__ = &#x27;supplier&#x27;</span><br><span class="line">    </span><br><span class="line">    supplier_id = Column(String(20), primary_key=True)</span><br><span class="line">    name = Column(String(100), nullable=False)</span><br><span class="line">    address = Column(String(200))</span><br><span class="line">    phone = Column(String(20))</span><br><span class="line"></span><br><span class="line">class Warehouse(Base):</span><br><span class="line">    __tablename__ = &#x27;warehouse&#x27;</span><br><span class="line">    </span><br><span class="line">    warehouse_id = Column(String(20), primary_key=True)</span><br><span class="line">    address = Column(String(200), nullable=False)</span><br><span class="line"></span><br><span class="line">    # 可选：未来加组长时在此添加</span><br><span class="line">    # leader_staff_id = Column(String(20), ForeignKey(&#x27;staff.staff_id&#x27;), unique=True)</span><br><span class="line"></span><br><span class="line">class Staff(Base):</span><br><span class="line">    __tablename__ = &#x27;staff&#x27;</span><br><span class="line">    </span><br><span class="line">    staff_id = Column(String(20), primary_key=True)</span><br><span class="line">    name = Column(String(50), nullable=False)</span><br><span class="line">    gender = Column(CHAR(1))</span><br><span class="line">    hire_date = Column(Date, nullable=False)</span><br><span class="line">    title = Column(String(50))</span><br><span class="line">    warehouse_id = Column(String(20), ForeignKey(&#x27;warehouse.warehouse_id&#x27;), nullable=False)</span><br><span class="line">    </span><br><span class="line">    # 约束：性别只能是 M/F</span><br><span class="line">    __table_args__ = (</span><br><span class="line">        CheckConstraint(&quot;gender IN (&#x27;M&#x27;, &#x27;F&#x27;)&quot;, name=&#x27;check_gender&#x27;),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">class Inventory(Base):</span><br><span class="line">    __tablename__ = &#x27;inventory&#x27;</span><br><span class="line">    </span><br><span class="line">    warehouse_id = Column(String(20), ForeignKey(&#x27;warehouse.warehouse_id&#x27;), primary_key=True)</span><br><span class="line">    part_id = Column(String(20), ForeignKey(&#x27;part.part_id&#x27;), primary_key=True)</span><br><span class="line">    stock_quantity = Column(Integer, nullable=False)</span><br><span class="line">    </span><br><span class="line">    # 表级约束：确保库存数量不能为负数</span><br><span class="line">    # 当尝试插入或更新为负数时会触发数据库错误</span><br><span class="line">    __table_args__ = (</span><br><span class="line">        CheckConstraint(stock_quantity &gt;= 0, name=&#x27;check_stock_non_negative&#x27;),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">class Purchase(Base):</span><br><span class="line">    __tablename__ = &#x27;purchase&#x27;</span><br><span class="line">    </span><br><span class="line">    purchase_id = Column(String(30), primary_key=True)</span><br><span class="line">    part_id = Column(String(20), ForeignKey(&#x27;part.part_id&#x27;), nullable=False)</span><br><span class="line">    supplier_id = Column(String(20), ForeignKey(&#x27;supplier.supplier_id&#x27;), nullable=False)</span><br><span class="line">    warehouse_id = Column(String(20), ForeignKey(&#x27;warehouse.warehouse_id&#x27;), nullable=False)</span><br><span class="line">    purchase_date = Column(Date, nullable=False)</span><br><span class="line">    quantity = Column(Integer, nullable=False)</span><br><span class="line">    actual_price = Column(DECIMAL(10, 2), nullable=False)</span><br><span class="line">    </span><br><span class="line">    # 表级约束：确保采购业务逻辑的合理性</span><br><span class="line">    # - 采购数量必须为正数（不能为零或负数）</span><br><span class="line">    # - 实际采购价格必须为正数（不能为零或负数）</span><br><span class="line">    __table_args__ = (</span><br><span class="line">        CheckConstraint(quantity &gt; 0, name=&#x27;check_quantity_positive&#x27;),</span><br><span class="line">        CheckConstraint(actual_price &gt; 0, name=&#x27;check_price_positive&#x27;),</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>建立表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DATABASE_URL = &quot;postgresql://postgres:123456@localhost:5432/factory_db&quot;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># create_tables.py</span><br><span class="line">from sqlalchemy import create_engine</span><br><span class="line">from models import Base</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line"># 替换为你的 Docker PostgreSQL 地址</span><br><span class="line">DATABASE_URL = os.getenv(&quot;DATABASE_URL&quot;)</span><br><span class="line"></span><br><span class="line"># 创建数据库引擎，用于连接数据库</span><br><span class="line"># create_engine 会根据 DATABASE_URL 创建对应的数据库连接池</span><br><span class="line">engine = create_engine(DATABASE_URL)</span><br><span class="line">Base.metadata.create_all(engine)  # 自动建表！</span><br><span class="line">print(&quot;✅ 所有表已创建&quot;)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python-web</category>
        <category>postgresql</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>前端1——入门</title>
    <url>/2025/02/15/%E5%AD%A6%E4%B9%A0/python-web/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/</url>
    <content><![CDATA[<h2 id="环境">环境</h2>
<p>vscode</p>
<p>插件：</p>
<p>HTML CSS Support 写css代码</p>
<p>Live Serve 实时预览html网页</p>
<p>Auto Rename Tag 同步修改标签名称</p>
<h2 id="html">HTML</h2>
<p>html （hyper text markup language） 超文本标记语言</p>
<p>网页是又html标签描述出来的</p>
<p>html文件结构</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span>//文档编码格式</span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;viewport&quot;</span> <span class="attr">content</span>=<span class="string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Document<span class="tag">&lt;/<span class="name">title</span>&gt;</span>//文档标题</span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span>//页面内容</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>块元素（block）：块级元素通常用于组织和布局页面的主要结构和内容，例如段落、标题、列表、表格等。它们用于创建页面的主要部分，将内容分隔成逻辑块。</p>
<p>行内元素（inline）：行内元素通常用于添加文本样式或为文本中的一部分应用样式。它们可以在文本中插入小的元素，例如超链接、强调文本等。</p>
<p>常用标签</p>
<p><code>&lt;h1&gt; &lt;/h1&gt;</code>一级标签</p>
<p><code>&lt;p&gt; &lt;/p&gt;</code>段落标签</p>
<p><code>&lt;b&gt; &lt;/b&gt;</code> bold 文本加粗</p>
<p><code>&lt;u&gt; &lt;/u&gt;</code> 下划线</p>
<p><code>&lt;s&gt; &lt;/s&gt;</code> 删除线</p>
<p>无序列表</p>
<p><code>&lt;ul&gt;</code> <code>&lt;li&gt;1&lt;/li&gt;</code>
<code>&lt;li&gt;2&lt;/li&gt;</code> <code>&lt;/ul&gt;</code></p>
<p>有序列表</p>
<p><code>&lt;ol&gt;</code> <code>&lt;li&gt;1&lt;/li&gt;</code>
<code>&lt;li&gt;2&lt;/li&gt;</code> <code>&lt;/ol&gt;</code></p>
<p>表格</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">table</span> <span class="attr">border</span>=<span class="string">&quot;1&quot;</span>&gt;</span>//边框宽度为1</span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">th</span>&gt;</span>标题1<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">th</span>&gt;</span>标题2<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>元素1<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>元素2<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>html属性 基本语法：<开始标签 属性名="“属性值”"></开始标签></p>
<p><code>&lt;a href="www.zxj-2023.github.io" target="_blank"&gt;超链接&lt;/a&gt;</code>
超链接，target决定链接打开方式</p>
<p><code>&lt;br&gt;</code> 换行</p>
<p><code>&lt;hr&gt;</code> 分割线</p>
<p><code>&lt;img src="图片路径或链接" alt="代替文本" width="宽度" height="高度"&gt;&lt;/img&gt;</code>
图片</p>
<p><code>&lt;div class="名称"&gt;&lt;/div&gt;</code>块级标签，用于创建页面的布局结构，如导航栏，页眉等</p>
<p>优先级：id&gt;class&gt;标签名</p>
<p><code>&lt;span&gt;&lt;/span&gt;</code>包装文本以便对其使用css，js行为或样式等</p>
<p>form标签是html表单的容器</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;#&quot;</span>&gt;</span>//URL</span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">&quot;username&quot;</span>&gt;</span>用户名：<span class="tag">&lt;/<span class="name">label</span>&gt;</span>//与span类似，for用于和input的id绑定</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">id</span>=<span class="string">&quot;username&quot;</span> <span class="attr">placehoud</span>=<span class="string">&quot;请输入用户名&quot;</span>&gt;</span></span><br><span class="line">	//input其他属性，value：规定input内的值</span><br><span class="line">	<span class="tag">&lt;<span class="name">label</span>&gt;</span>密码：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placehoud</span>=<span class="string">&quot;请输入密码&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span>&gt;</span>性别：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span>&gt;</span> 男//单选择 名称一致</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span>&gt;</span> 女</span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span>&gt;</span>爱好：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span>&gt;</span> 唱歌//多选</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span>&gt;</span> 跳舞</span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span>&gt;</span>//提交按钮 提交表单数据</span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="css">CSS</h2>
<p>css cascading style sheets
用于定义网页样式和布局的样式表语言，通过CSS，可以指定页面中各个元素的颜色、字体、大小、间距、边框、背景等样式，从而实现更精确的页面设计。</p>
<p>语法：</p>
<p>选择器{</p>
<p>​ 属性1：属性值1；</p>
<p>​ 属性2：属性值2；</p>
<p>}</p>
<p>内部样式表：放在head里面</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css">        <span class="selector-tag">p</span>&#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">color</span>:bule;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">font-size</span>:<span class="number">16px</span>;//字体大小</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>:yellow//背景色</span></span><br><span class="line"><span class="language-css">            font-family:<span class="string">&#x27;KaiTi&#x27;</span>//修改字体，楷体</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">    </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">        内容</span><br><span class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>外部样式：需在head链接</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;路径&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>内联样式：标签内</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span> <span class="attr">style</span>=<span class="string">&quot;color=red;&quot;</span>&gt;</span></span><br><span class="line">    内容</span><br><span class="line"><span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>优先级：内联样式&gt;内部样式表&gt;外部样式</p>
<p>css选择器：</p>
<p>元素选择器：标签名</p>
<p>类选择器：.+类名</p>
<p>id选择器：#+id名</p>
<p>通用选择器：*</p>
<p>子代选择器：父+&gt;+子</p>
<p>后代选择器：父+空格+子</p>
<p>相邻元素选择器：1+2 需要满足相邻条件</p>
<p>伪类选择器</p>
<p>css属性：</p>
<p><a href="https://www.runoob.com/cssref/css-reference.html">CSS
参考手册 |菜鸟教程</a></p>
<p><code>&lt;h1 style="font: bolder 50px 'KaiTi';"&gt;复合属性&lt;/h1&gt;</code>
font符合属性示例</p>
<p>区分块、行内、行内块元素width和height的差异</p>
<p>通过display转换以上三者(block,inline,inline-block)</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.div-inline&#123;</span><br><span class="line">	display:inline;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>盒子模型：</p>
<ol type="1">
<li>内容（content）</li>
<li>内边距（padding）：内容与边框之间的空间</li>
<li>边框（border）：盒子的边界 上右下左</li>
<li>外边距（margin）：盒子与其他元素之间的空间</li>
</ol>
<figure>
<img src="/2025/02/15/%E5%AD%A6%E4%B9%A0/python-web/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/asdsdf.png" alt="asdsdf">
<figcaption aria-hidden="true">asdsdf</figcaption>
</figure>
<p>浮动：改变元素默认的排列顺序，使网页布局更加灵活多变(letf right)</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.son&#123;</span><br><span class="line">	float:left;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>清除浮动的方式</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.father&#123;</span><br><span class="line">	overflow: hidden;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定位布局：</p>
<p>相对定位(relative)∶相对于元素在文档流中的正常位置进行定位。</p>
<p>绝对定位(absolute)︰相对于其最近的已定位祖先元素进行定位，不占据文档流。</p>
<p>固定定位(fixed)︰相对于浏览器窗口进行定位。不占据文档流，固定在屏幕上的位置，不随滚动而移动。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.box-relative&#123;</span><br><span class="line">	position: relative;//相对定位</span><br><span class="line">	left:</span><br><span class="line">	right:</span><br><span class="line">	top:</span><br><span class="line">	bottom:</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="javascript">JavaScript</h2>
<p>JavaScript是一种轻量级、解释型、面向对象的脚本语言。它主要被设计用于在网页上实现动态效果，增加用户与网页的交互性。
作为一种客户端脚本语言，JavaScript可以直接嵌入HTML，并在浏览器中执行。
与HTML和CSS不同，JavaScript使得网页不再是静态的，而是可以根据用户的操作动态变化的。</p>
<p><code>客户端脚本</code>:用于在用户浏览器中执行，实现动态效果和用户交互。</p>
<p><code>网页开发</code>:与HTML和CSS协同工作，使得网页具有更强的交互性和动态性。</p>
<p><code>后端开发</code>︰使用Node.js，JavaScript
也可以在服务器端运行，实现服务器端应用的开发。</p>
<p>js的导入</p>
<p>内联</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">	<span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;hello,world&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>外联</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;相对路径&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;hello,world&#x27;</span>)<span class="comment">//控制台输出</span></span><br><span class="line"><span class="title function_">alert</span>(<span class="string">&#x27;&#x27;</span>)<span class="comment">//内联弹窗</span></span><br></pre></td></tr></table></figure>
<p>js语句</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//变量</span></span><br><span class="line"><span class="keyword">var</span> x;<span class="comment">//varible</span></span><br><span class="line"><span class="keyword">let</span> t=<span class="number">5</span>;<span class="comment">//块级作用域</span></span><br><span class="line"><span class="keyword">const</span> <span class="variable constant_">PI</span> =<span class="number">3.14</span>;<span class="comment">//常量</span></span><br><span class="line"><span class="comment">//条件语句</span></span><br><span class="line"><span class="keyword">if</span>()&#123;&#125;<span class="keyword">else</span>&#123;&#125;</span><br><span class="line"><span class="comment">//循环，for，while</span></span><br><span class="line"><span class="comment">//函数</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">function_name</span>(<span class="params"></span>)&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> 返回值;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用html属性触发事件</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span> <span class="attr">onclick</span>=<span class="string">&quot;click_event()&quot;</span>&gt;</span></span><br><span class="line">        点击事件</span><br><span class="line">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">onfocus</span>=<span class="string">&quot;focus_event()&quot;</span> <span class="attr">onblur</span>=<span class="string">&quot;blur_event()&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    	<span class="keyword">function</span> <span class="title function_">click_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">alert</span>(<span class="string">&#x27;触发点击事件&#x27;</span>)</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">        </span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">function</span> <span class="title function_">focus_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;获取焦点&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">        </span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">function</span> <span class="title function_">blur_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;失去焦点&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">    </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>DOM</p>
<p>当网页被加载时，浏览器会创建页面的文档对象模型，也就是DOM (Document
Object Model)
.每个HTML或XML文档都可以被视为一个文档树，文档树是整个文档的层次结构表示。</p>
<p>文档节点是整个文档树的根节点。</p>
<p>DOM为这个文档树提供了一个编程接口，开发者可以使用JavaScript来操作这个树状结构。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;box1&quot;</span>&gt;</span>ID选择器标签<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;box2&quot;</span>&gt;</span>类选择器标签<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span>&gt;</span></span><br><span class="line">        点击按钮</span><br><span class="line">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">scrip</span>&gt;</span></span><br><span class="line">    	var element_id = document.getElementById(&#x27;box1&#x27;);//id唯一，获取的是元素</span><br><span class="line">        console.log(element_id)</span><br><span class="line">		</span><br><span class="line">        var element_class = document.getElementsByClassName(&#x27;box2&#x27;)[0];//类不唯一，获取的是数组</span><br><span class="line">        console.log(element_id)</span><br><span class="line">        </span><br><span class="line">        element_id.innerHTML = &#x27;修改id标签内容&#x27;;</span><br><span class="line">        element_id.innerText</span><br><span class="line">        element_id.style.color</span><br><span class="line">        element_id.style.fontSize</span><br><span class="line">        </span><br><span class="line">        //DOM属性绑定事件</span><br><span class="line">        var button_element = document.getElementsByTagName(&#x27;button&#x27;);</span><br><span class="line">        </span><br><span class="line">        button_element.onclick = function()&#123;</span><br><span class="line">        	alert(&#x27;DOM 属性按键触发&#x27;)</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        button)element.addEventListener(&#x27;click&#x27;,click_event)</span><br><span class="line">        function click_event()&#123;</span><br><span class="line">        	alert(&#x27;通过addEventListener触发&#x27;)</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">scrip</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>对象</strong></p>
<p>对象（object）是 JavaScript 语言的核心概念，也是最重要的数据类型</p>
<p>简单说，对象就是一组“键值对”（key-value）的集合，是一种无序的复合数据集合</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> user = &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="string">&#x27;itbaizhan&#x27;</span>,</span><br><span class="line">  <span class="attr">age</span>: <span class="string">&#x27;13&#x27;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>对象的每一个键名又称为“属性”（property），它的“键</p>
<p>值”可以是任何数据类型。如果一个属性的值为函数，通常把这个属性称为“方法”，它可以像函数那样调用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> user = &#123;</span><br><span class="line">  <span class="attr">getName</span>: <span class="keyword">function</span> (<span class="params">name</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> name;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">user.<span class="title function_">getName</span>(<span class="string">&quot;itbaizhan&quot;</span>) <span class="comment">// itbaizhan</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/02/15/%E5%AD%A6%E4%B9%A0/python-web/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/image-20211025173456785.png" alt="image-20211025173456785">
<figcaption aria-hidden="true">image-20211025173456785</figcaption>
</figure>
<h2 id="参考视频">参考视频</h2>
<p><a href="https://www.bilibili.com/video/BV1BT4y1W7Aw/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">3小时前端入门教程（HTML+CSS+JS）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>python-web</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>前端2——巩固</title>
    <url>/2025/02/18/%E5%AD%A6%E4%B9%A0/python-web/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF2/</url>
    <content><![CDATA[<h3 id="vscode">vscode</h3>
<p>代码格式化：shift+alt+f</p>
<p>向上或向下移动一行:Alt+Up或Alt+Down</p>
<p>快速开始新一行：ctrl+enter</p>
<p>快速复制一行代码:Shift+Alt+Up 或Shift+Alt+Down</p>
<p>快速保存:Ctrl +S</p>
<p>快速查找:Ctrl + F</p>
<p>快速替换:Ctrl+ H</p>
<p>快速移动一行 alt + ↓或↑</p>
<p>多光标： alt + 鼠标左键</p>
<h3 id="html5">html5</h3>
<p><strong>合并单元格</strong></p>
<ul>
<li>水平合并：colspan</li>
<li>垂直合并：rowspan</li>
</ul>
<p><strong>h5新标签</strong></p>
<ol type="1">
<li><code>&lt;header&gt;&lt;/header&gt;</code> 头部</li>
<li><code>&lt;nav&gt;&lt;/nav&gt;</code> 导航</li>
<li><code>&lt;section&gt;&lt;/section&gt;</code>定义文档中的节,比如章节、页眉、页脚</li>
<li><code>&lt;aside&gt;&lt;/aside&gt;</code> 侧边栏</li>
<li><code>&lt;footer&gt;&lt;/footer&gt;</code> 脚部</li>
<li><code>&lt;article&gt;&lt;/article&gt;</code>
代表一个独立的、完整的相关内容块,例如一篇完整的论坛帖子，一篇博客文章，一个用户评论等</li>
</ol>
<p><strong>查漏补缺</strong></p>
<p><code>&lt;figure&gt;</code>元素表示文档流中独立的内容块。这个内容通常与主文档相关，但可以被移动到文档的其他位置（如侧边栏、脚注或独立的附件）而不会影响理解文档的其余部分。</p>
<p><code>&lt;section&gt;</code>元素用于定义文档中的一个区域（section），它通常表示文档中的一个主题或内容块。</p>
<p>图像标题（<code>figcaption</code>）元素用于添加标题以描述
<code>figure</code> 元素中包含的图像。<code>&lt;figcaption&gt;</code>
必须是 <code>&lt;figure&gt;</code> 元素的子元素，并且它必须是
<code>&lt;figure&gt;</code> 中的第一个或最后一个子元素</p>
<p>“URL” 是 “Uniform Resource Locator” 的缩写，中文意思是
“统一资源定位符”。它是一种用于在互联网上定位和访问资源（如网页、图像、视频等）的地址。</p>
<p><code>fieldset</code> 元素用于在 Web
表单中将相关的输入和标签组合在一起。 <code>fieldset</code>
元素是块级元素，这意味着它们出现在新的一行上。</p>
<p><code>legend</code> 元素充当 <code>fieldset</code> 元素中内容的标题。
它为用户提供了应该在表单的该部分中输入什么的上下文。</p>
<p><code>&lt;meta name="viewport" content="width=device-width, initial-scale=1.0" /&gt;</code>是一个非常重要的
HTML 元标签，用于控制网页在移动设备上的布局和显示方式</p>
<p>article和section</p>
<p>article标签表示文档、页面、应用或网站的一部分，具有独立性和完整性。它通常包含一些内容，如新闻报道、博客文章、论坛帖子等，这些内容可以被单独地分享、链接和索引。</p>
<p>section标签则表示文档或应用的一部分，但不具有独立性和完整性。它通常用于组织内容，将页面或应用分成不同的部分，例如头部、主体、脚注等。</p>
<p><code>method</code> 属性指定了如何将表单数据发送到
<code>action</code> 属性中指定的 URL。 表单数据可以通过 <code>GET</code>
请求作为 URL 参数发送（<code>method="get"</code>）或通过
<code>POST</code>
请求作为请求正文中的数据发送（<code>method="post"</code>）。</p>
<p>给密码 <code>input</code> 元素添加 <code>pattern</code>
属性，要求输入匹配 <code>[a-z0-5]&#123;8,&#125;</code>。上面是一个正则表达式，匹配
8 个以上的小写字母或数字 <code>0</code> 到 <code>5</code>。</p>
<p><code>&lt;select&gt;</code> 和 <code>&lt;option&gt;</code> 是 HTML
中用于创建下拉列表的元素</p>
<p><code>&lt;textarea&gt;</code> 是 HTML
中的一个表单元素，用于多行文本输入，允许用户输入和编辑大量文本。</p>
<p><strong>英文全称记忆</strong></p>
<p><code>&lt;ul&gt;</code> ： “Unordered List”</p>
<p><code>&lt;li&gt;</code> ： “List - item”</p>
<p><code>src</code>： “source”</p>
<p><code>css text-align</code>: “text alignment”（文本对齐方式）</p>
<p><code>link rel</code>:relationship</p>
<p><code>&lt;hr&gt;</code>:“Horizontal Rule”</p>
<h3 id="css3">css3</h3>
<p><strong>查漏补缺</strong></p>
<p><code>opacity</code> 是 CSS
中用于控制元素透明度的属性。它可以设置一个元素的透明度级别，取值范围从
<code>0</code>（完全透明）到 <code>1</code>（完全不透明）</p>
<p><code>box-shadow</code>
属性允许你在元素周围应用一个或多个阴影。<code>box-shadow: offsetX offsetY blurRadius color;</code></p>
<p><code>linear-gradient</code> 是 CSS
中用于创建线性渐变背景的属性。它允许你在元素的背景中定义多种颜色之间的平滑过渡效果</p>
<p><code>hsla</code>（Hue色相, Saturation饱和度, Lightness,
Alpha透明度）是一种在 CSS 中定义颜色的方式，基于
HSL（色相、饱和度、亮度）颜色模型，并且允许设置透明度（alpha 值）。</p>
<p><code>vh</code> 是 CSS 中的一种相对长度单位，表示视口高度（Viewport
Height）的百分比。具体来说，<code>1vh</code> 等于视口高度的
1%。视口是指浏览器窗口中可见的部分，不包括工具栏、地址栏等非内容区域。</p>
<p><code>em</code> 是 CSS
中的一种相对单位，用于表示元素的字体大小（<code>font-size</code>）的倍数。具体来说，<code>1em</code>
等于当前元素的字体大小。例如，如果一个元素的字体大小为
<code>16px</code>，那么 <code>1em</code> 就等于 <code>16px</code>。</p>
<p><code>rem</code>（Root Em）是 CSS
中的一种相对单位，表示相对于根元素（<code>html</code>
元素）的字体大小（<code>font-size</code>）的倍数。</p>
<p>在 CSS 中，<code>cursor</code>
属性用于定义鼠标指针位于元素上时的形状或图标。它对于改善用户体验非常重要，因为它为用户提供了视觉反馈，让他们知道可与页面上的不同元素进行哪些操作。</p>
<p><code>z-index</code>属性设置元素的堆叠顺序。拥有更高堆叠顺序的元素总是会处于堆叠顺序较低的元素的前面</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.box1</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">position</span>:absolute;</span><br><span class="line">    <span class="attribute">z-index</span>: <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.box2</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: green;</span><br><span class="line">    <span class="attribute">position</span>:absolute;</span><br><span class="line">    <span class="attribute">z-index</span>: <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>css3新特性</strong></p>
<p><strong>圆角</strong></p>
<p>使用 CSS3 <code>border-radius</code> 属性，你可以给任何元素制作
“圆角”</p>
<p><code>border-radius</code> 属性，可以使用以下规则：</p>
<ol type="1">
<li>四个值:
第一个值为左上角，第二个值为右上角，第三个值为右下角，第四个值为左下角</li>
<li>三个值: 第一个值为左上角,
第二个值为右上角和左下角，第三个值为右下角</li>
<li>两个值: 第一个值为左上角与右下角，第二个值为右上角与左下角</li>
<li>一个值： 四个圆角值相同</li>
</ol>
<p><strong>阴影</strong></p>
<p>box-shadow 向框添加一个或多个阴影。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">box-shadow</span>: h-shadow v-shadow blur color;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>h-shadow</td>
<td>必选，水平阴影的位置</td>
</tr>
<tr>
<td>v-shadow</td>
<td>必选，垂直阴影的位置</td>
</tr>
<tr>
<td>blur</td>
<td>可选，模糊距离</td>
</tr>
<tr>
<td>color</td>
<td>可选，阴影的颜色</td>
</tr>
</tbody>
</table>
<p><strong>动画</strong></p>
<p>使用<code>@keyframes</code>规则，你可以创建动画</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="keyword">@keyframes</span> name &#123;</span><br><span class="line">    <span class="selector-tag">from</span>|<span class="number">0%</span>&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">    percent&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="selector-tag">to</span>|<span class="number">100%</span>&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>name：动画名称，开发人员自己命名；</p>
<p>percent：为百分比值，可以添加多个百分比值；</p>
<p><strong>animation执行动画</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">animation</span>: name duration timing-function delay iteration-count direction;</span><br></pre></td></tr></table></figure>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 74%">
</colgroup>
<thead>
<tr>
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>设置动画的名称</td>
</tr>
<tr>
<td>duration</td>
<td>设置动画的持续时间</td>
</tr>
<tr>
<td>timing-function</td>
<td>设置动画效果的速率（如下）</td>
</tr>
<tr>
<td>delay</td>
<td>设置动画的开始时间（延时执行）</td>
</tr>
<tr>
<td>iteration-count</td>
<td>设置动画循环的次数，infinite为无限次数的循环</td>
</tr>
<tr>
<td>direction</td>
<td>设置动画播放的方向（如下）</td>
</tr>
<tr>
<td>animation-play-state</td>
<td>控制动画的播放状态：running代表播放，而paused代表停止播放</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>timing-function值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>ease</td>
<td>逐渐变慢（默认）</td>
</tr>
<tr>
<td>linear</td>
<td>匀速</td>
</tr>
<tr>
<td>ease-in</td>
<td>加速</td>
</tr>
<tr>
<td>ease-out</td>
<td>减速</td>
</tr>
<tr>
<td>ease-in-out</td>
<td>先加速后减速</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>direction值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>normal</td>
<td>默认值为normal表示向前播放</td>
</tr>
<tr>
<td>alternate</td>
<td>动画播放在第偶数次向前播放，第奇数次向反方向播放</td>
</tr>
</tbody>
</table>
<p><strong>切换背景颜色</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;animation&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.animation</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">animation</span>: anima <span class="number">5s</span> linear <span class="number">5s</span> infinite;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.animation</span><span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">    <span class="attribute">animation-play-state</span>: paused;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">@keyframes</span> anima &#123;</span><br><span class="line">    <span class="number">0%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: red;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">50%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: green;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">100%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: blueviolet;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>设置meta标签</strong></p>
<p>使用设备的宽度作为视图宽度并禁止初始的缩放。在<code>&lt;head&gt;</code>标签里加入这个meta标签。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&lt;meta name=&quot;viewport&quot; <span class="attribute">content</span>=&quot;<span class="attribute">width</span>=device-<span class="attribute">width</span>, initial-<span class="attribute">scale</span>=<span class="number">1</span>,maximum-<span class="attribute">scale</span>=<span class="number">1</span>, user-scalable=no&quot;&gt;</span><br></pre></td></tr></table></figure>
<p><strong>参数解释</strong></p>
<ol type="1">
<li><code>width = device-width</code> 宽度等于当前设备的宽度</li>
<li><code>initial-scale</code> 初始的缩放比例（默认设置为1.0）</li>
<li><code>maximum-scale</code>
允许用户缩放到的最大比例（默认设置为1.0）</li>
<li><code>user-scalable</code> 用户是否可以手动缩放（默认设置为no）</li>
</ol>
<h3 id="js">JS</h3>
<p><code>querySelector()</code></p>
<h3 id="es6">ES6</h3>
<p>常用命令行工具有两种</p>
<ol type="1">
<li><code>CMD</code> 命令行工具</li>
<li><code>PowerShell</code> 命令行工具</li>
</ol>
<p><strong>CMD命令行</strong></p>
<ol type="1">
<li>打开命令行窗口
<ol type="1">
<li>win：左下角开始，找到运行，点击，输入<code>cmd</code>，回车</li>
<li>win：<code>win+r</code> 快速打开命令行窗口</li>
</ol></li>
<li>选择盘符：盘符名加冒号<code>E:</code></li>
<li>查看盘符及目录下文件与文件夹：<code>win:dir</code></li>
<li>清空命令行信息：<code>win:cls</code></li>
<li>进入文件夹或目录：<code>cd  文件夹名称</code></li>
<li>返回到上一级目录：<code>cd ../</code></li>
<li>快速补全目录或文件夹名称：<code>tab</code></li>
<li>创建文件夹：<code>mkdir 文件夹名称</code></li>
<li>查看历史输入过的命令：上下按键</li>
</ol>
<p><strong>PowerShell</strong></p>
<ol type="1">
<li>打开方式
<ol type="1">
<li>在开始位置搜索<code>PowerShell</code>打开</li>
<li>在对应目录按住<code>shift</code>+右键，打开</li>
</ol></li>
<li>其他保持一直</li>
</ol>
<p>ECMAScript 和 JavaScript
的关系是，前者是后者的规格，后者是前者的一种实现，通常场合，这两个词是可以互换的。</p>
<p>ECMAScript 6（以下简称 ES6）是 JavaScript 语言的标准，在 2015 年 6
月发布。它的目标，是使得 JavaScript
语言可以用来编写复杂的大型应用程序，成为企业级开发语言。</p>
<h3 id="typescript">TypeScript</h3>
<p><a href="https://www.bilibili.com/video/BV1xL4y1B7DG/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">为什么你应当使用
TypeScript? TS 十分钟快速入门_哔哩哔哩_bilibili</a></p>
<h3 id="参考视频和网站推荐">参考视频和网站推荐</h3>
<p><a href="https://www.bilibili.com/video/BV1oz421q7BB/?spm_id_from=333.337.search-card.all.click">【HTML+CSS+JS+Vue】比大学课程还详细的Web前端教程，整整180集，学完即可兼职就业！附学习文档PDF，随时都能学_前端开发_WEB入门_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.freecodecamp.org/learn/">Learn to Code — For
Free — Coding Courses for Busy People</a></p>
]]></content>
      <categories>
        <category>python-web</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>python web——react</title>
    <url>/2025/08/15/%E5%AD%A6%E4%B9%A0/python-web/react/react/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>为了后续自己搭建全栈项目做准备，对react做一定的了解</p>
<p>学习目标：大致看懂react的基本语法，可以在ai的协助下完成前端的搭建</p>
<h3 id="介绍">介绍</h3>
<p>React 是 Facebook（现 Meta）于 2013 年开源的一套用于构建用户界面的
JavaScript 库，现由 React 核心团队与社区共同维护。</p>
<h3 id="项目搭建">项目搭建</h3>
<p>项目创建</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npx create-react-app my-app</span><br></pre></td></tr></table></figure>
<blockquote>
<p>npx 是什么？</p>
<p>npm 5.2+ 自带的“包运行器”（Node Package eXecute）。类似uv</p>
<p>脚手架（Scaffold / Boilerplate）是什么？</p>
<ol type="1">
<li>定义：官方或社区提供的“项目模板生成器”，一条命令就能创建带目录结构、配置、脚本、依赖的完整项目骨架。</li>
<li>目的： • 省掉繁琐的初始化、Webpack/Rollup/Vite
配置、ESLint/TypeScript/测试等环境搭建。 •
统一团队规范，降低新人上手成本。</li>
</ol>
</blockquote>
<p>启动开发服务器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> my-app</span><br><span class="line">npm start        <span class="comment"># 或 yarn start</span></span><br></pre></td></tr></table></figure>
<p>目录速览（核心）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">my-app</span><br><span class="line">├─ public/         # 静态资源，index.html 是页面模板</span><br><span class="line">├─ src/</span><br><span class="line">│  ├─ App.js       # 根组件</span><br><span class="line">│  ├─ index.js     # 应用入口（ReactDOM.createRoot）</span><br><span class="line">└─ package.json    # 依赖与脚本</span><br></pre></td></tr></table></figure>
<h3 id="jsx">JSX</h3>
<p>JSX（JavaScript XML 的缩写）是 React
引入的一种<strong>语法糖</strong>（syntactic sugar）。它让你在
JavaScript 文件里直接写<strong>类 HTML
标记</strong>，然后由构建工具（Babel、TypeScript、esbuild、swc）把它翻译成<strong>普通的
JavaScript 函数调用</strong>。</p>
<p>如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 1. 找到 public/index.html 中 id=&quot;root&quot; 的 DOM 节点，作为 React 应用的挂载点</span><br><span class="line">const root = ReactDOM.createRoot(document.getElementById(&#x27;root&#x27;));</span><br><span class="line"></span><br><span class="line">// 2. 将根组件 &lt;App /&gt; 渲染到该挂载点</span><br><span class="line">root.render(</span><br><span class="line">  // 3. &lt;React.StrictMode&gt; 是 React 提供的开发模式辅助工具</span><br><span class="line">  //    作用：在开发阶段自动检测潜在问题（如过时的 API、副作用重复执行等）</span><br><span class="line">  //    注意：它仅在开发环境生效，生产环境不会渲染任何额外 DOM</span><br><span class="line">  &lt;React.StrictMode&gt;</span><br><span class="line">    &#123;/* 4. 项目真正的根组件 App，所有业务逻辑都从这里开始 */&#125;</span><br><span class="line">    &lt;App /&gt;</span><br><span class="line">  &lt;/React.StrictMode&gt;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h3 id="箭头函数">箭头函数</h3>
<p>React（以及所有现代 JavaScript）里，“箭头”指的是
<strong>箭头函数（Arrow Function）</strong>，语法是：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> 函数名 = <span class="function">(<span class="params">参数</span>) =&gt;</span> 返回值或语句块</span><br></pre></td></tr></table></figure>
<p>它的作用可以概括为 <strong>“更简洁的函数声明 + 词法作用域的
this”</strong>。</p>
<p>通俗理解：把小括号的内容变成箭头后的内容</p>
<h3 id="函数组件">函数组件</h3>
<p>函数组件 + JSX 的组合作用是： <strong>以函数的形式返回“虚拟 DOM
描述”，交由 React 渲染成真实 DOM</strong>，而不是直接返回 HTML
组件或字符串。</p>
<ol type="1">
<li>函数组件的“返回值”</li>
</ol>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">Welcome</span>(<span class="params">props</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="language-xml"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>Hello &#123;props.name&#125;<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>经过 Babel 编译后等价于：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">Welcome</span>(<span class="params">props</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="title class_">React</span>.<span class="title function_">createElement</span>(<span class="string">&#x27;h1&#x27;</span>, <span class="literal">null</span>, <span class="string">&#x27;Hello &#x27;</span>, props.<span class="property">name</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>React.createElement</code> 会生成一个<strong>纯 JS
对象</strong>（虚拟节点），而不是一段 HTML 字符串。</p>
<p><strong>使用示例</strong></p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1. 接收父组件传来的 props</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">Card</span>(<span class="params">&#123; title, children &#125;</span>) &#123;</span><br><span class="line">  <span class="comment">// 2. 返回一段 JSX（最终会被编译成虚拟 DOM）</span></span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">className</span>=<span class="string">&quot;card&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;<span class="name">h2</span>&gt;</span>&#123;title&#125;<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      &#123;children&#125;</span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用：</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line">&lt;<span class="title class_">Card</span> title=<span class="string">&quot;函数组件&quot;</span>&gt;</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">p</span>&gt;</span>Hello, world!<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span></span><br><span class="line">&lt;/<span class="title class_">Card</span>&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>DOM（Document Object Model，文档对象模型）是浏览器在内存里把一份
HTML/XML
文档表示成<strong>树形结构</strong>的<strong>编程接口</strong>（API）。</p>
<p>每个节点（元素、文本、注释…）都是一个对象，拥有属性与方法，例如：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> title = <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;title&#x27;</span>);</span><br><span class="line">title.<span class="property">textContent</span> = <span class="string">&#x27;Hi React&#x27;</span>;   <span class="comment">// 改文本</span></span><br><span class="line">title.<span class="property">style</span>.<span class="property">color</span> = <span class="string">&#x27;red&#x27;</span>;        <span class="comment">// 改样式</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="插值写法">插值写法</h3>
<p>在 React 中，“插值”专指<strong>把一段 JavaScript 表达式的实时结果塞进
JSX</strong> 的写法。 核心符号只有一对花括号
<code>&#123; &#125;</code>，记住口诀：<strong>“JSX 里凡是 {} 包起来的，就是
JavaScript 运行后的值。”</strong></p>
<p><strong>基本文本插值</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const name = &#x27;React&#x27;;</span><br><span class="line">&lt;h1&gt;Hello, &#123;name&#125;!&lt;/h1&gt;          // → Hello, React!</span><br></pre></td></tr></table></figure>
<p><strong>属性插值</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function App() &#123;</span><br><span class="line">  const mytitle=&quot;hello&quot;</span><br><span class="line">  return (</span><br><span class="line">    &lt;div title=&#123;mytitle&#125;&gt;&lt;/div&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="数据渲染">数据渲染</h3>
<p><strong>条件渲染</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function App() &#123;</span><br><span class="line">  const mytitle=&quot;hello&quot;</span><br><span class="line"></span><br><span class="line">  let mycontent=null</span><br><span class="line">  const flag=true</span><br><span class="line">  if(flag)&#123;</span><br><span class="line">    mycontent=&lt;h2&gt;hello&lt;/h2&gt;</span><br><span class="line">  &#125;</span><br><span class="line">  else&#123;</span><br><span class="line">    mycontent=&lt;h2&gt;world&lt;/h2&gt;</span><br><span class="line">  &#125;</span><br><span class="line">  return (</span><br><span class="line">    &lt;div title=&#123;mytitle&#125;&gt;&#123;mycontent&#125;&lt;/div&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>列表渲染</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function App() &#123;</span><br><span class="line">  const list=[&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;]</span><br><span class="line">  const mycontent=list.map((item)=&gt;&#123;</span><br><span class="line">    return &lt;li&gt;&#123;item&#125;&lt;/li&gt;</span><br><span class="line">  &#125;)</span><br><span class="line">  return (</span><br><span class="line">    &lt;div&gt;&#123;mycontent&#125;&lt;/div&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<ol type="1">
<li><code>.map((item) =&gt; &#123; ... &#125;)</code> ‑
<code>Array.prototype.map</code>：遍历数组，把每个元素依次交给回调函数处理，并<strong>返回一个新数组</strong>。
‑ <code>(item)</code> 是每次循环拿到的当前元素。</li>
<li><code>return &lt;li&gt;&#123;item&#125;&lt;/li&gt;</code> ‑
每一次循环里，把当前元素 <code>item</code> 用 JSX 插值语法
<code>&#123;item&#125;</code> 放进 <code>&lt;li&gt;</code> 标签里。</li>
</ol>
</blockquote>
<h3 id="状态处理">状态处理</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import &#123; useState &#125; from &#x27;react&#x27;;</span><br><span class="line">function App() &#123;</span><br><span class="line">  const [mycontent,setmycontent]=useState(&quot;hello world&quot;);</span><br><span class="line">  function changeContent()&#123;</span><br><span class="line">    setmycontent(&quot;hello world2&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">  return (</span><br><span class="line">    &lt;&gt;</span><br><span class="line">      &lt;div&gt;&#123;mycontent&#125;&lt;/div&gt;</span><br><span class="line">      &lt;button onClick=&#123;changeContent&#125;&gt;change&lt;/button&gt;</span><br><span class="line">    &lt;/&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>useState 是 React 提供的
<strong>Hook</strong>，让<strong>函数组件也能拥有内部状态</strong>（state）。可以通过更新函数，调用后触发重新渲染。</p>
<p><strong>对象的状态更新</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import &#123; useState &#125; from &#x27;react&#x27;;</span><br><span class="line">function App() &#123;</span><br><span class="line">  const [mycontent,setmycontent]=useState(&#123;</span><br><span class="line">    title:&#x27;hello world&#x27;,</span><br><span class="line">    content :&#x27;hello world content&#x27;</span><br><span class="line">&#125;);</span><br><span class="line">  function changeContent()&#123;</span><br><span class="line">    setmycontent(&#123;</span><br><span class="line">      ...mycontent,</span><br><span class="line">      content:&#x27;new content&#x27;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">  return (</span><br><span class="line">    &lt;&gt;</span><br><span class="line">      &lt;div title=&#123;mycontent.title&#125;&gt;&#123;mycontent.content&#125;&lt;/div&gt;</span><br><span class="line">      &lt;button onClick=&#123;changeContent&#125;&gt;change&lt;/button&gt;</span><br><span class="line">    &lt;/&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>...mycontent</code> 是 ES6 的 <strong>对象展开运算符（object
spread）</strong>。 一句话：把 <code>mycontent</code>
里所有“旧属性”先抄出来，然后再覆盖/新增你后面写的属性。</p>
<h3 id="react组件的使用">react组件的使用</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import &#123; useState &#125; from &#x27;react&#x27;;</span><br><span class="line">function App() &#123;</span><br><span class="line">return (</span><br><span class="line">    &lt;&gt;</span><br><span class="line">      &lt;img src=&#123;logo&#125; className=&quot;App-logo&quot; alt=&quot;logo&quot; style=&#123;&#123; width: &#x27;100px&#x27;,backgroundColor: &#x27;grey&#x27;&#125;&#125;/&gt;</span><br><span class="line">    &lt;/&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol type="1">
<li><p><code>className</code> 代替 <code>class</code> 传统 HTML 写
<code>&lt;img class="App-logo"&gt;</code>；React 组件里必须用
<code>className</code>，因为 JSX 最终会被编译成 JavaScript 对象，而
<code>class</code> 是 JS 的保留关键字。</p></li>
<li><p>样式写成<strong>对象</strong></p></li>
</ol>
<p>HTML
写行内样式：<code>style="width:100px;background-color:grey"</code> React
必须写成对象：</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line">style=&#123;&#123;</span><br><span class="line">  <span class="attr">width</span>: <span class="string">&#x27;100px&#x27;</span>,</span><br><span class="line">  <span class="attr">backgroundColor</span>: <span class="string">&#x27;grey&#x27;</span>   <span class="comment">// 驼峰命名</span></span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>因为 JSX 属性最终会变成 JS
对象的键值对，键名必须合法（驼峰），值可以是任何 JS
值（数字、变量、计算结果）。</p>
<ol start="3" type="1">
<li>最终产物是<strong>虚拟 DOM 节点</strong></li>
</ol>
<p><code>&lt;img src=&#123;logo&#125; ... /&gt;</code> 在浏览器里不会直接变成
<code>&lt;img&gt;</code> 标签，而是先被编译成：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="title class_">React</span>.<span class="title function_">createElement</span>(<span class="string">&#x27;img&#x27;</span>, &#123;</span><br><span class="line">  <span class="attr">src</span>: logo,</span><br><span class="line">  <span class="attr">className</span>: <span class="string">&#x27;App-logo&#x27;</span>,</span><br><span class="line">  <span class="attr">alt</span>: <span class="string">&#x27;logo&#x27;</span>,</span><br><span class="line">  <span class="attr">style</span>: &#123; <span class="attr">width</span>: <span class="string">&#x27;100px&#x27;</span>, <span class="attr">backgroundColor</span>: <span class="string">&#x27;grey&#x27;</span> &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>React 再拿这个对象去做 diff、更新真实 DOM，而不是直接 innerHTML。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function App() &#123;</span><br><span class="line"></span><br><span class="line">  const imgdata=&#123;</span><br><span class="line">    className:&quot;App-logo&quot;,</span><br><span class="line">    style:&#123;</span><br><span class="line">      width:&#x27;100px&#x27;,</span><br><span class="line">      backgroundColor:&#x27;grey&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  return (</span><br><span class="line">    &lt;&gt;</span><br><span class="line">      &lt;img src=&#123;logo&#125; alt=&quot;logo&quot; &#123;...imgdata&#125;/&gt;</span><br><span class="line">    &lt;/&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用 <strong>JSX 展开运算符（spread attributes）</strong> 把
<code>imgdata</code> 里的所有键值一次性“拍平”到 <code>&lt;img&gt;</code>
标签上</p>
<h3 id="组件复用">组件复用</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function Article(props) &#123;</span><br><span class="line">  return (</span><br><span class="line">    &lt;div&gt;</span><br><span class="line">      &lt;h2&gt;&#123;props.title&#125;&lt;/h2&gt;</span><br><span class="line">      &lt;p&gt;&#123;props.content&#125;&lt;/p&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function App() &#123;</span><br><span class="line">  return (</span><br><span class="line">    &lt;&gt;</span><br><span class="line">      &lt;Article title=&quot;标签1&quot; content=&quot;内容1&quot; /&gt;</span><br><span class="line">      &lt;Article title=&quot;标签2&quot; content=&quot;内容2&quot; /&gt;</span><br><span class="line">    &lt;/&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="组件通信">组件通信</h3>
<p>组件通信的 4 条主线</p>
<p>1️⃣ 父 → 子：props 2️⃣ 子 → 父：回调函数 3️⃣ 隔代/任意：Context 4️⃣
全局/远端：状态管理库（Zustand、Redux、React Query）</p>
<h4 id="父-子">父 → 子</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function Parent() &#123;</span><br><span class="line">  const title = &#x27;Hello React&#x27;;</span><br><span class="line">  return &lt;Child title=&#123;title&#125; /&gt;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function Child(&#123; title &#125;) &#123;</span><br><span class="line">  return &lt;h1&gt;&#123;title&#125;&lt;/h1&gt;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="子-父">子 → 父</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">function Parent() &#123;</span><br><span class="line">  const [count, setCount] = useState(0);</span><br><span class="line">  return (</span><br><span class="line">    &lt;&gt;</span><br><span class="line">      &lt;p&gt;父：&#123;count&#125;&lt;/p&gt;</span><br><span class="line">      &lt;Child onInc=&#123;() =&gt; setCount(c =&gt; c + 1)&#125; /&gt;</span><br><span class="line">    &lt;/&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function Child(&#123; onInc &#125;) &#123;</span><br><span class="line">  return &lt;button onClick=&#123;onInc&#125;&gt;子按钮 +1&lt;/button&gt;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>父组件把“修改函数”通过 props
传给子组件，子组件在合适的时机调用它，把数据作为参数传回去。</strong></p>
<h3 id="react-hooks">react hooks</h3>
<p><strong>Hook 是什么？</strong> Hook 是 React 16.8 引入的
<strong>函数级 API</strong>，让函数组件拥有</p>
<ul>
<li>状态（useState）</li>
<li>生命周期（useEffect）</li>
<li>上下文（useContext）</li>
<li>自定义逻辑（自定义 Hook） 而不必写 class。</li>
</ul>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV1kc411D7F9?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">20分钟学会React
Hooks 前端开发必看 AI编程工具 CodeGeeX 体验_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>python-web</category>
        <category>react</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>python web——fastapi</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>代码仓库<a href="https://github.com/zxj-2023/learn_fastapi">zxj-2023/learn_fastapi</a></p>
<p>FastAPI 是一个用于构建 API 的现代、快速（高性能）的 web 框架，使用
Python 并基于标准的 Python 类型提示。</p>
<p>关键特性:</p>
<ul>
<li><strong>快速</strong>：可与 <strong>NodeJS</strong> 和
<strong>Go</strong> 并肩的极高性能（归功于 Starlette 和 Pydantic）。<a href="https://fastapi.tiangolo.com/zh/#_11">最快的 Python web
框架之一</a>。</li>
<li><strong>高效编码</strong>：提高功能开发速度约 200％ 至 300％。*</li>
<li><strong>更少 bug</strong>：减少约 40％
的人为（开发者）导致错误。*</li>
<li><strong>智能</strong>：极佳的编辑器支持。处处皆可自动补全，减少调试时间。</li>
<li><strong>简单</strong>：设计的易于使用和学习，阅读文档的时间更短。</li>
<li><strong>简短</strong>：使代码重复最小化。通过不同的参数声明实现丰富功能。bug
更少。</li>
<li><strong>健壮</strong>：生产可用级别的代码。还有自动生成的交互式文档。</li>
<li><strong>标准化</strong>：基于（并完全兼容）API 的相关开放标准：<a href="https://github.com/OAI/OpenAPI-Specification">OpenAPI</a>
(以前被称为 Swagger) 和 <a href="https://json-schema.org/">JSON
Schema</a>。</li>
</ul>
<h3 id="两个核心组件starlette-和-pydantic">两个核心组件：Starlette 和
Pydantic</h3>
<p>Starlette 负责web部分</p>
<p>Starlette 是 FastAPI 的底层 ASGI（异步服务器网关接口）框架，为
FastAPI 提供了异步编程能力和高性能的网络通信支持。</p>
<p>ASGI（<strong>Asynchronous Server Gateway Interface</strong>
）是一种用于连接 Python Web
服务器和应用程序框架的<strong>异步接口标准</strong> ，旨在支持现代 Web
协议（如 WebSocket、HTTP/2）和异步编程模型</p>
<p>Pydantic负责</p>
<p>Pydantic 负责 FastAPI 的数据验证、序列化和自动文档生成</p>
<h3 id="http协议">http协议</h3>
<h4 id="一简介">一、简介</h4>
<p><strong>HTTP协议</strong> 是Hyper Text Transfer
Protocol（超文本传输协议）的缩写，是用于万维网（WWW: World Wide
Web）服务器与本地浏览器之间传输超文本的传送协议。HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<h4 id="二http协议特性">二、http协议特性</h4>
<p>（1）基于 TCP/IP 协议</p>
<p>http 协议是基于 <strong>TCP/IP 协议</strong>之上的应用层协议。</p>
<p>（2）基于请求 - 响应模式</p>
<p>HTTP
协议规定，请求从客户端发出，最后服务器端响应应该请求并返回。换句话说，肯定是先<strong>从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应</strong>。</p>
<p>（3）无状态保存</p>
<p>HTTP 是一种不保存状态，即无状态（stateless）协议。HTTP
协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP
这个级别，协议对于发送过的请求或响应都不做持久化处理。</p>
<p>使用 HTTP
协议，每当有新的请求发送时，就会有对应的新响应产生。协议本身并<strong>不保留之前一切的请求或响应报文的信息</strong>。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把
HTTP 协议设计成如此简单的。</p>
<p>（4）短连接</p>
<p>HTTP 1.0 默认使用的是短连接。浏览器和服务器每进行一次 HTTP
操作，就建立一次连接，任务结束就中断连接。</p>
<p>HTTP 1.1 起，默认使用长连接。要使用长连接，客户端和服务器的 HTTP
首部的 Connection 都要设置为 keep - alive，才能支持长连接。</p>
<p>HTTP 长连接，指的是复用 TCP 连接。多个 HTTP 请求可以复用同一个 TCP
连接，这就节省了 TCP 连接建立和断开的消耗。</p>
<h4 id="三http请求协议与响应协议">三、http请求协议与响应协议</h4>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<blockquote>
<p>Socket（套接字）是计算机网络中用于实现进程间双向通信的端点抽象，它为应用层进程通过网络协议交换数据提供了统一的接口。具体来说，Socket
是应用层与 TCP/IP
协议族通信的中间软件抽象层，本质上是一组封装了复杂网络协议的接口，简化了开发者对底层通信细节的操作。</p>
<p>从功能上看，Socket
可以看作是网络通信的“电话插座”：两个设备（如客户端与服务器）通过 Socket
建立连接后，即可像电话通话一样进行数据交换，而端口号则类似于插座上的插孔，用于标识具体的通信进程，且不能被其他进程占用。此外，Socket
包含网络通信必需的五种核心信息，例如使用的协议（TCP/UDP）、本地与远程地址、端口等，构成了网络通信的基本操作单元。</p>
<p>总结而言，Socket
既是通信端点的逻辑概念，也是实现网络应用层交互的关键工具，其设计目标是屏蔽底层协议的复杂性，提供统一的编程接口。</p>
</blockquote>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/3.png" alt="3">
<figcaption aria-hidden="true">3</figcaption>
</figure>
<blockquote>
<p>GET ：请求参数通过 URL 的查询字符串（Query
String）传递，数据暴露在地址栏中，例如：https://example.com
?name=value</p>
<p>POST
：请求参数存储在请求体（Body）中传输，相对更安全，且支持传输非字符串数据（如文件、二进制等）</p>
</blockquote>
<blockquote>
<p>一个完整的URL包括：协议、ip、端口、路径、参数</p>
<p>例如：https://www.baidu.com/s?wd=yuan 其中https是协议，www.baidu.com
是IP，端口默认80，/s是路径，参数是wd=yuan</p>
<p>请求方式：get与post请求</p>
<ul>
<li>GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如EditBook?name=test1&amp;id=123456。POST方法是把提交的数据放在HTTP包的请求体中。</li>
<li>GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制</li>
</ul>
<p>响应状态码：状态码的职责是当客户端向服务器端发送请求时，返回的请求结果。借助状态码，用户可以知道服务器端是正常处理了请求，还是出现了问题。状态码如200
OK，以3位数字和原因组成。</p>
</blockquote>
<p>测试http协议格式：请求与响应</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#web应用程序：遵循http协议</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line">sock=socket.socket()</span><br><span class="line">sock.bind((<span class="string">&quot;127.0.0.1&quot;</span>,<span class="number">8080</span>))</span><br><span class="line">sock.listen(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    conn 表示新建立的套接字对象，用于在服务器和客户端之间进行数据传输。</span></span><br><span class="line"><span class="string">    addr 是一个元组，它包含了连接进来的客户端的 IP 地址和端口号。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    conn, addr = sock.accept()<span class="comment">#阻塞等待客户端连接</span></span><br><span class="line">    data=conn.recv(<span class="number">1024</span>)<span class="comment">#请求报文</span></span><br><span class="line">    <span class="comment"># data 是一个字节串，包含了客户端发送的请求信息。</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端发送的请求信息：\n&quot;</span>,data)</span><br><span class="line">    conn.send(<span class="string">b&quot;HTTP/1.1 200 ok\r\nserver:zxj\r\n\r\nhello world&quot;</span>)<span class="comment">#响应首行+响应头+响应体</span></span><br><span class="line">    conn.close()</span><br></pre></td></tr></table></figure>
<p>测试post请求：urlencoded格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 socket 连接</span></span><br><span class="line">client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">client.connect((<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">8080</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造 POST 请求报文</span></span><br><span class="line">path = <span class="string">&quot;/&quot;</span>  <span class="comment"># 目标路径</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;Host&quot;</span>: <span class="string">&quot;127.0.0.1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>,  <span class="comment"># 数据格式</span></span><br><span class="line">    <span class="string">&quot;Content-Length&quot;</span>: <span class="built_in">len</span>(<span class="string">&quot;username=admin&amp;password=123456&quot;</span>)  <span class="comment"># 数据长度</span></span><br><span class="line">&#125;</span><br><span class="line">body = <span class="string">&quot;username=admin&amp;password=123456&quot;</span>  <span class="comment"># 请求体（表单数据）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拼接请求报文</span></span><br><span class="line">request = <span class="string">f&quot;POST <span class="subst">&#123;path&#125;</span> HTTP/1.1\r\n&quot;</span></span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> headers.items():</span><br><span class="line">    request += <span class="string">f&quot;<span class="subst">&#123;k&#125;</span>: <span class="subst">&#123;v&#125;</span>\r\n&quot;</span></span><br><span class="line">request += <span class="string">&quot;\r\n&quot;</span>  <span class="comment"># 空行分隔头部与主体</span></span><br><span class="line">request += body</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送请求</span></span><br><span class="line">client.send(request.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接收响应</span></span><br><span class="line">response = client.recv(<span class="number">4096</span>)</span><br><span class="line"><span class="built_in">print</span>(response.decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">client.close()</span><br></pre></td></tr></table></figure>
<p>测试post请求：json格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义请求地址</span></span><br><span class="line">url = <span class="string">&quot;http://127.0.0.1:8080&quot;</span></span><br><span class="line"><span class="comment"># 定义 JSON 数据（字典格式）</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;username&quot;</span>: <span class="string">&quot;admin&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送 POST 请求</span></span><br><span class="line">response = requests.post(</span><br><span class="line">    url, </span><br><span class="line">    json=data  <span class="comment"># 使用 json 参数自动序列化字典并设置 Content-Type: application/json</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出响应结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;状态码:&quot;</span>, response.status_code)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;响应内容:&quot;</span>, response.text)  <span class="comment"># 使用 text 获取原始响应文本</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">客户端发送的请求信息：</span></span><br><span class="line"><span class="string"> b&#x27;POST / HTTP/1.1\r\nHost: 127.0.0.1:8080\r\nUser-Agent: python-requests/2.32.2\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 43\r\nContent-Type: application/json\r\n\r\n&#123;&quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;123456&quot;&#125;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>通过 <code>json=data</code> 参数，<code>requests</code>
会自动将字典转换为 JSON 字符串，并设置请求头
<code>Content-Type: application/json</code>，无需手动调用
<code>json.dumps()</code> 或配置 headers</p>
</blockquote>
<blockquote>
<p>SSL 验证是指通过 SSL
证书验证网站身份并确保通信安全的过程。其核心目标是确认服务器的真实性、防止身份伪造，并建立加密连接以保护数据传输的安全性</p>
<p>HTTPS（HyperText Transfer Protocol Secure）是以安全为目标的 HTTP
通道，通过在 HTTP
基础上加入加密和身份认证机制，确保数据传输的隐私性、完整性和服务器身份的真实性</p>
<p>https=http+ssl</p>
</blockquote>
<blockquote>
<p>通过 <code>Content-Type</code>，服务器可识别请求体（Body）的格式（如
JSON、表单数据），客户端可解析响应数据的类型（如 HTML、图片）</p>
<p>例如：conn.send(b”HTTP/1.1 200 ok:zxj*content-type:text/html**hello
world&lt;&gt;“)</p>
<p>再例如：‘HTTP/1.1 200 ok:zxj*content-type:application/json**’</p>
</blockquote>
<h5 id="api接口">api接口</h5>
<p>在开发web应用中，有两种应用模式：</p>
<p>1.前后端不分离：客户端看到的内容和所有页面效果都是有服务端提供出来的</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/4.png" alt="4">
<figcaption aria-hidden="true">4</figcaption>
</figure>
<p>2.前后端分离：把前端的页面效果（html，css，js分离到另一个服务端，python服务端只需要返回数据即可）</p>
<p>前端形成一个独立的网站，服务端构成一个独立的网站</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<p><strong>应用程序编程接口（Application Programming
Interface，API接口）</strong>，就是应用程序对外提供了一个操作数据的入口，这个入口可以是一个函数或类方法，也可以是一个url地址或者一个网络地址。当客户端调用这个入口，应用程序则会执行对应代码操作，给客户端完成相对应的功能。</p>
<p>当然，api接口在工作中是比较常见的开发内容，有时候，我们会调用其他人编写的api接口，有时候，我们也需要提供api接口给其他人操作。由此就会带来一个问题，api接口往往都是一个函数、类方法、或者url或其他网络地址，不断是哪一种，当api接口编写过程中，我们都要考虑一个问题就是这个接口应该怎么编写？接口怎么写的更加容易维护和清晰，这就需要大家在调用或者编写api接口的时候要有一个明确的编写规范！！！</p>
<p>为了在团队内部形成共识，防止个人习惯差异引起的混乱，我们都需要找到一种大家都觉得很好的接口实现规范，而且这种规范能够让后端写的接口，用途一目了然，减少客户端和服务端双方之间的合作成本。</p>
<p>目前市面上大部分公司开发人员使用的接口实现规范主要有：restful、RPC。</p>
<p>REST全称是Representational State
Transfer，中文意思是表述（编者注：通常译为表征）性状态转移。它首次出现在2000年Roy
Fielding的博士论文中。</p>
<p>RESTful是一种专门为Web开发而定义API接口的设计风格，尤其适用于前后端分离的应用模式中。</p>
<p><strong>关键：面向资源开发</strong></p>
<p>这种风格的理念认为后端开发任务就是提供数据的，对外提供的是数据资源的访问接口，所以在定义接口时，客户端访问的URL路径就表示这种要操作的数据资源。</p>
<p>而<strong>对于数据资源分别使用POST、DELETE、GET、UPDATE等请求动作来表达对数据的增删查改</strong>。</p>
<table>
<thead>
<tr>
<th>请求方法</th>
<th>请求地址</th>
<th>后端操作</th>
</tr>
</thead>
<tbody>
<tr>
<td>POST</td>
<td>/student/</td>
<td>增加学生</td>
</tr>
<tr>
<td>GET</td>
<td>/student/</td>
<td>获取所有学生</td>
</tr>
<tr>
<td>GET</td>
<td>/student/1</td>
<td>获取id为1的学生</td>
</tr>
<tr>
<td>PUT</td>
<td>/student/1</td>
<td>修改id为1的学生</td>
</tr>
<tr>
<td>DELETE</td>
<td>/student/1</td>
<td>删除id为1的学生</td>
</tr>
</tbody>
</table>
<p>restful规范是一种通用的规范，不限制语言和开发框架的使用。事实上，我们可以使用任何一门语言，任何一个框架都可以实现符合restful规范的API接口。</p>
<h3 id="fastapi快速开始">fastapi快速开始</h3>
<h4 id="简单案例">简单案例</h4>
<p>安装：<code>pip install fastapi</code></p>
<p>还需要一个ASGI服务器，生产环境使用Uvicorn：<code>pip install uvicorn</code></p>
<blockquote>
<p>ASGI（<strong>Asynchronous Server Gateway Interface</strong>
）是一种<strong>异步服务器网关接口</strong> ，为 Python Web
应用提供了标准接口，使其能够处理现代网络协议（如 WebSocket、HTTP/2
等）的异步请求。与传统的 WSGI 不同，ASGI
支持异步编程模型，允许单个请求处理多个事件（如长连接、双向通信），从而提升高并发场景下的性能</p>
<p>Uvicorn 是一个基于 ASGI 的高性能异步 Web 服务器，专为 Python
异步框架设计。</p>
</blockquote>
<blockquote>
<p>web应用程序=web框架+自己写的业务逻辑代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI<span class="comment">#fastapi类</span></span><br><span class="line"></span><br><span class="line">app= FastAPI()<span class="comment">#创建一个fastapi实例</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">home</span>():</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_id&quot;</span>:<span class="number">1001</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/shop&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">shop</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;shop_id&quot;</span>:<span class="number">1002</span>&#125;</span><br></pre></td></tr></table></figure>
<p>启动：<code>uvicorn "04 fastapi_begin:app" --reload</code></p>
<p>也可以：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(app=<span class="string">&quot;04 fastapi_begin:app&quot;</span>,port=<span class="number">8080</span>,reload=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>接口文档</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/6.png" alt="6">
<figcaption aria-hidden="true">6</figcaption>
</figure>
<blockquote>
<p>修饰器（Decorator）是 Python
中一种动态修改函数或类行为的高级功能，本质上是一个函数或类，它<strong>接受目标函数或类作为参数，并返回包装后的新函数或类对象</strong>，从而在<strong>不修改原始代码</strong>
的前提下为对象添加额外功能</p>
</blockquote>
<h3 id="路径操作">路径操作</h3>
<h4 id="路径操作修饰器">路径操作修饰器</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.get()</span></span><br><span class="line"><span class="meta">@app.post()</span></span><br><span class="line"><span class="meta">@app.put()</span></span><br><span class="line"><span class="meta">@app.patch()</span></span><br><span class="line"><span class="meta">@app.delete()</span></span><br><span class="line"><span class="meta">@app.options()</span></span><br><span class="line"><span class="meta">@app.head()</span></span><br><span class="line"><span class="meta">@app.trace()</span></span><br></pre></td></tr></table></figure>
<p>路径操作修饰器参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tags为接口添加标签，用于在自动生成的文档</span></span><br><span class="line"><span class="string">summary为接口添加描述</span></span><br><span class="line"><span class="string">description为接口添加详细描述</span></span><br><span class="line"><span class="string">response_description为接口返回值描述</span></span><br><span class="line"><span class="string">deprecated为过时的接口</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/post&quot;</span>, </span></span></span><br><span class="line"><span class="params"><span class="meta">        tags=[<span class="string">&quot;这是post方法&quot;</span>],</span></span></span><br><span class="line"><span class="params"><span class="meta">        summary=<span class="string">&quot;这是post方法的描述&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">        description=<span class="string">&quot;这是post方法的详细描述&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">        response_description=<span class="string">&quot;这是post方法的返回值描述&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">        deprecated=<span class="literal">True</span>, <span class="comment"># 过时的接口</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        </span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br></pre></td></tr></table></figure>
<h4 id="include_router">include_router</h4>
<p>文件路径如下</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/7.png" alt="7">
<figcaption aria-hidden="true">7</figcaption>
</figure>
<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> apps.app01.shop <span class="keyword">import</span> shop</span><br><span class="line"><span class="keyword">from</span> apps.app02.user <span class="keyword">import</span> user</span><br><span class="line"></span><br><span class="line">app= FastAPI()</span><br><span class="line"></span><br><span class="line">app.include_router(shop,</span><br><span class="line">                 prefix=<span class="string">&quot;/shop&quot;</span>, <span class="comment"># 路由前缀</span></span><br><span class="line">                 tags=[<span class="string">&quot;购物中心接口&quot;</span>], <span class="comment"># 标签</span></span><br><span class="line">                 responses=&#123;<span class="number">200</span>: &#123;<span class="string">&quot;description&quot;</span>: <span class="string">&quot;成功&quot;</span>&#125;&#125; <span class="comment"># 响应描述</span></span><br><span class="line">                 )</span><br><span class="line">app.include_router(user,</span><br><span class="line">                 prefix=<span class="string">&quot;/user&quot;</span>, <span class="comment"># 路由前缀</span></span><br><span class="line">                 tags=[<span class="string">&quot;用户接口&quot;</span>], <span class="comment"># 标签</span></span><br><span class="line">                 responses=&#123;<span class="number">200</span>: &#123;<span class="string">&quot;description&quot;</span>: <span class="string">&quot;成功&quot;</span>&#125;&#125; <span class="comment"># 响应描述</span></span><br><span class="line">                 )</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(<span class="string">&quot;main:app&quot;</span>, port=<span class="number">8080</span>,  reload=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>shop.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"></span><br><span class="line">shop=APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="meta">@shop.get(<span class="params"><span class="string">&quot;/food&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shop_food</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;food&quot;</span>:<span class="string">&quot;shop food&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@shop.get(<span class="params"><span class="string">&quot;/drink&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shop_drink</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;drink&quot;</span>:<span class="string">&quot;shop drink&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>user.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"></span><br><span class="line">user=APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="meta">@user.post(<span class="params"><span class="string">&quot;/login&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">user_login</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user&quot;</span>:<span class="string">&quot;user login&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@user.post(<span class="params"><span class="string">&quot;/register&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">user_register</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user&quot;</span>:<span class="string">&quot;user register&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>include_router</code> 是 FastAPI
框架中用于整合路由的核心方法，其作用是将通过 <code>APIRouter</code>
定义的路由模块添加到主应用程序实例中，使这些路由在应用中生效。</p>
</blockquote>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/8.png" alt="8">
<figcaption aria-hidden="true">8</figcaption>
</figure>
<h3 id="请求与响应">请求与响应</h3>
<h4 id="路径参数">4.1 路径参数</h4>
<h5 id="基本用法">（1）基本用法</h5>
<p>以使用与 Python 格式化字符串相同的语法来声明路径”参数”或”变量”：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/user/&#123;user_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user</span>(<span class="params">user_id</span>):</span><br><span class="line">    <span class="built_in">print</span>(user_id, <span class="built_in">type</span>(user_id))</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_id&quot;</span>: user_id&#125;</span><br></pre></td></tr></table></figure>
<p>路径参数 <code>user_id</code> 的值将作为参数 <code>user_id</code>
传递给你的函数。</p>
<h5 id="有类型的路径参数">（2）有类型的路径参数</h5>
<p>你可以使用标准的 Python 类型标注为函数中的路径参数声明类型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/user/&#123;user_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user</span>(<span class="params">user_id: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(user_id, <span class="built_in">type</span>(user_id))</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_id&quot;</span>: user_id&#125;</span><br></pre></td></tr></table></figure>
<p>在这个例子中，<code>user_id</code> 被声明为 int 类型。</p>
<blockquote>
<p>这将为你的函数提供编辑器支持，包括错误检查、代码补全等等。</p>
</blockquote>
<h5 id="注意顺序">（3）注意顺序</h5>
<p>在创建路径操作时，你会发现有些情况下路径是固定的。</p>
<p>比如
<code>/users/me</code>，我们假设它用来获取关于当前用户的数据。</p>
<p>然后，你还可以使用路径 <code>/user/&#123;username&#125;</code>
来通过用户名获取关于特定用户的数据。</p>
<p>由于路径操作是<strong>按顺序依次运行</strong>的，你需要确保路径
/<code>user/me</code> 声明在路径 <code>/user/&#123;username&#125;</code>
之前。</p>
<p>如下</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250516193934740.png" alt="image-20250516193934740">
<figcaption aria-hidden="true">image-20250516193934740</figcaption>
</figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250516201128482.png" alt="image-20250516201128482">
<figcaption aria-hidden="true">image-20250516201128482</figcaption>
</figure>
<blockquote>
<p>路由（Routing）是指在网络中<strong>选择数据传输路径</strong>的过程，其核心目标是将数据从源点高效、可靠地传输到目的地</p>
</blockquote>
<blockquote>
<p>cURL 是一个开源的命令行工具和跨平台的库（libcurl），用于基于 URL
语法在网络协议下进行数据传输。它支持多种协议（如 HTTP、HTTPS、FTP、SMTP
等），能够实现文件上传、下载以及与 Web 服务器的交互，常被开发者用于 API
测试、数据传输等场景</p>
</blockquote>
<h4 id="查询参数请求参数">4.2 查询参数（请求参数）</h4>
<p>路径函数中声明<strong>不属于路径参数的其他函数参数</strong>时，它们将被<strong>自动解释为查询字符串参数</strong>，就是
<code>url？</code>之后用 <code>&amp;</code> 分割的
<code>key-value 键值对</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app02.get(<span class="params"><span class="string">&quot;/jobs&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_jobs</span>(<span class="params">kind1: <span class="built_in">str</span>, kind2: <span class="built_in">str</span>, kind3: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="comment">#基于查询参数的值来执行不同的操作</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;kind1&quot;</span>: kind1,</span><br><span class="line">        <span class="string">&quot;kind2&quot;</span>: kind2,</span><br><span class="line">        <span class="string">&quot;kind3&quot;</span>: kind3</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250516201707589.png" alt="image-20250516201707589">
<figcaption aria-hidden="true">image-20250516201707589</figcaption>
</figure>
<p>增加路径参数：kind1为路径参数</p>
<p>增加默认参数值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app02.get(<span class="params"><span class="string">&quot;/jobs/&#123;kind1&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_jobs</span>(<span class="params">kind1: <span class="built_in">str</span>, kind2: <span class="built_in">str</span>=<span class="string">&quot;None&quot;</span>, kind3: <span class="built_in">str</span>=<span class="string">&quot;None&quot;</span></span>):<span class="comment">#增加默认值，可选填</span></span><br><span class="line">    <span class="comment">#基于查询参数的值来执行不同的操作</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;kind1&quot;</span>: kind1,</span><br><span class="line">        <span class="string">&quot;kind2&quot;</span>: kind2,</span><br><span class="line">        <span class="string">&quot;kind3&quot;</span>: kind3</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>Request URL：</p>
<p><code>http://127.0.0.1:8080/app02/jobs/11?kind2=22&amp;kind3=33</code></p>
<p>自python3.5开始，PEP484为python引入了类型注解(type
hints)，typing的主要作用有：</p>
<blockquote>
<p>1.类型检查，防止运行时出现参数、返回值类型不符。</p>
<p>2.作为开发文档附加说明，方便使用者调用时传入和返回参数类型。</p>
<p>3.模块加入不会影响程序的运行不会报正式的错误，pycharm支持typing检查错误时会出现黄色警告。</p>
</blockquote>
<p><code>type hints</code>主要是要指示函数的输入和输出的数据类型，数据类型在typing包中，基本类型有<code>str list dict</code>等等，</p>
<blockquote>
<p>Type Hints 是 Python 3.5
引入的功能，通过类型注解增强代码的可读性和可维护性。它允许开发者为变量、函数参数、返回值等指定预期的数据类型，从而帮助静态类型检查工具（如
<code>mypy</code>）捕获潜在错误，并提升 IDE 的智能提示能力。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">greet</span>(<span class="params">name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;Hello, <span class="subst">&#123;name&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>
<p>此处 <code>name: str</code>
表示参数需为字符串类型，<code>-&gt; str</code> 表示返回值类型为字符串
。</p>
</blockquote>
<p><code>Union</code>是当有多种可能的数据类型时使用，比如函数有可能根据不同情况有时返回str或返回list，那么就可以写成<code>Union[list, str]</code></p>
<blockquote>
<p>从 Python 3.10 起，<code>Union[X, Y]</code> 可简写为
<code>X | Y</code>。例如 <code>int | str</code> 等价于
<code>Union[int, str]</code> 。</p>
<p>再例如：<code>kind2:str|None=None</code></p>
</blockquote>
<p><code>Optional</code>是Union的一个简化，当数据类型中有可能是None时，比如有可能是str也有可能是None，则Optional[str]，相当于Union[str,
None]</p>
<h4 id="请求体数据">4.3 请求体数据</h4>
<p>当你需要将数据从客户端（例如浏览器）发送给 API
时，你将其作为「请求体」发送。请求体是客户端发送给 API 的数据。响应体是
API 发送给客户端的数据。</p>
<p>FastAPI 基于 <code>Pydantic</code> ，<code>Pydantic</code>
主要用来做类型强制检查（校验数据）。不符合类型要求就会抛出异常。</p>
<p>对于 API
服务，支持类型检查非常有用，会让服务更加健壮，也会加快开发速度，因为开发者再也不用自己写一行一行的做类型检查。</p>
<p>安装上手 <code>pip install pydantic</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel,Field,field_validator</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> date</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span>,<span class="type">Optional</span></span><br><span class="line"></span><br><span class="line">app03 = APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Address</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    province: <span class="built_in">str</span></span><br><span class="line">    city: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="comment">#正则表达式</span></span><br><span class="line">    <span class="comment">#username:str=Field(pattern=&quot;^[a-zA-Z0-9]&#123;3,10&#125;$&quot;,title=&quot;用户名&quot;,description=&quot;用户名长度在3-10之间，且只能包含字母和数字&quot;)</span></span><br><span class="line">    <span class="comment">#name: str|None = None</span></span><br><span class="line">    name:<span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span>=Field(default=<span class="number">0</span>,gt=<span class="number">0</span>,lt=<span class="number">100</span>)</span><br><span class="line">    birth:<span class="type">Union</span>[date,<span class="literal">None</span>] = <span class="literal">None</span></span><br><span class="line">    friends:<span class="built_in">list</span>[<span class="built_in">int</span>]=[]</span><br><span class="line">    description:<span class="type">Optional</span>[<span class="built_in">str</span>]=<span class="literal">None</span></span><br><span class="line">    <span class="comment">#嵌套</span></span><br><span class="line">    addr:Address|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    field_validator 的第一个参数必须是 cls，因为它是类方法 （classmethod），用于在验证字段时访问模型类的上下文。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">    @field_validator(<span class="params"><span class="string">&quot;name&quot;</span></span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name_must_alpha</span>(<span class="params">cls,value</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        value.isalpha() 会检查字符串是否只由字母组成，如果是则返回 True，否则返回 False。</span></span><br><span class="line"><span class="string">        如果返回 False，assert 触发，会抛出 AssertionError，并显示错误信息 &quot;name must be alpha&quot;。</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span> value.isalpha(), <span class="string">&quot;name must be alpha&quot;</span></span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="comment">#嵌套</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Data</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    data:<span class="built_in">list</span>[User]</span><br><span class="line"></span><br><span class="line"><span class="meta">@app03.post(<span class="params"><span class="string">&quot;/user&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">user</span>(<span class="params">user:User</span>):</span><br><span class="line">    <span class="built_in">print</span>(user,<span class="built_in">type</span>(user))</span><br><span class="line">    <span class="keyword">return</span> user</span><br><span class="line"></span><br><span class="line"><span class="meta">@app03.post(<span class="params"><span class="string">&quot;/data&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">data</span>(<span class="params">data:Data</span>):</span><br><span class="line">    <span class="built_in">print</span>(data,<span class="built_in">type</span>(data))</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>BaseModel</code>专门用于数据验证、数据转换和序列化。在定义数据结构时继承自
BaseModel，可以：</p>
<ul>
<li><strong>自动校验数据类型</strong>：根据类中字段的类型注解，自动校验输入数据是否符合预期类型。</li>
<li><strong>数据转换</strong>：可以自动将输入数据（例如 JSON
字符串）转换成相应的 Python 数据类型。</li>
<li><strong>序列化输出</strong>：支持将模型实例转换成
JSON、字典等格式，便于响应输出。</li>
</ul>
</blockquote>
<blockquote>
<p>在 Pydantic 中，<code>Field</code>
用于为模型字段提供额外的信息，比如设置默认值、描述信息、约束条件（例如长度、范围等）或别名。这可以帮助自动生成
OpenAPI 文档、增强验证或对字段进行更细粒度的控制。</p>
</blockquote>
<blockquote>
<p><code>field_validator</code> 是 Pydantic v2 中用于替代旧版
<code>@validator</code>
的新装饰器，专门用于为模型字段添加自定义验证逻辑。它通过更清晰的命名和更灵活的模式（如
<code>mode="before"</code> 或
<code>mode="after"</code>）提升代码可读性和验证逻辑的控制能力</p>
<p><code>field_validator</code>和<code>model_validator</code>区别</p>
<p><strong><code>field_validator</code></strong>专门针对<strong>单个字段</strong>
进行验证，适用于需要校验特定字段的规则（如长度、格式、类型约束）。例如验证用户名长度</p>
<p><strong><code>model_validator</code></strong>作用于<strong>整个模型实例</strong>
，适用于需要跨字段验证或全局逻辑的场景。例如检查两次密码是否一致</p>
</blockquote>
<h4 id="form表单数据">4.4 form表单数据</h4>
<p>在 <code>OAuth2</code>
规范的一种使用方式（密码流）中，需要将用户名、密码作为表单字段发送，而不是
JSON。</p>
<p>FastAPI 可以使用 <strong>Form 组件</strong>来接收表单数据，需要先使用
<code>pip install python-multipart</code> 命令进行安装。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app04.post(<span class="params"><span class="string">&quot;/register&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">data</span>(<span class="params">username:<span class="built_in">str</span>=Form(<span class="params"></span>),password:<span class="built_in">str</span>=Form(<span class="params"></span>)</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;username: <span class="subst">&#123;username&#125;</span>, password: <span class="subst">&#123;password&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;username&quot;</span>: username,</span><br><span class="line">        <span class="string">&quot;password&quot;</span>: password</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>发送post请求：form表单数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 目标 URL</span></span><br><span class="line">url = <span class="string">&quot;http://127.0.0.1:8080/app04/register&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 表单数据（键值对）</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;username&quot;</span>: <span class="string">&quot;test_user&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;secure_password_123&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送 POST 请求</span></span><br><span class="line">response = requests.post(</span><br><span class="line">    url, </span><br><span class="line">    data=data</span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>通过 requests.post() 的 data
参数传递表单数据，该参数接受字典或字符串格式的数据。requests
会自动将其编码为 application/x-www-form-urlencoded 格式</p>
</blockquote>
<h4 id="文件上传">4.5 文件上传</h4>
<p>导入必要库</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> File,UploadFile</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">app05 = APIRouter()</span><br></pre></td></tr></table></figure>
<p>通过字节上传</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app05.post(<span class="params"><span class="string">&quot;/file&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">file</span>(<span class="params">file: <span class="built_in">bytes</span> = File(<span class="params">...</span>)</span>):</span><br><span class="line">    <span class="comment">#适合小文件上传</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;filename&quot;</span>: <span class="string">&quot;file&quot;</span>,</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: <span class="built_in">len</span>(file)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>多文件上传</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app05.post(<span class="params"><span class="string">&quot;/files&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">files</span>(<span class="params">files: <span class="built_in">list</span>[<span class="built_in">bytes</span>] = File(<span class="params">...</span>)</span>):</span><br><span class="line">    <span class="comment">#多文件上传</span></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">len</span>(file))</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;filename&quot;</span>: <span class="string">&quot;files&quot;</span>,</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: <span class="built_in">len</span>(files)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>UploadFile上传，绝对路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app05.post(<span class="params"><span class="string">&quot;/uploadfile&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">upload_file</span>(<span class="params">file: UploadFile= File(<span class="params">...</span>)</span>):</span><br><span class="line">    <span class="comment">#适合大文件上传</span></span><br><span class="line">    <span class="comment"># 获取当前文件的绝对路径</span></span><br><span class="line">    base_dir = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line">    <span class="built_in">print</span>(base_dir)</span><br><span class="line">    img_dir = os.path.join(base_dir, <span class="string">&quot;../imgs&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(img_dir)</span><br><span class="line">    <span class="comment"># 创建目录</span></span><br><span class="line">    path = os.path.join(img_dir, file.filename)</span><br><span class="line">    <span class="comment">#path=os.path.join(&quot;../imgs&quot;,file.filename)</span></span><br><span class="line">    <span class="built_in">print</span>(path)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;文件名:&quot;</span>, file.filename)</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> file.file:</span><br><span class="line">            f.write(chunk)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;filename&quot;</span>: file.filename</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>UploadFile是 FastAPI
提供的一个类，用于处理文件上传。与直接将文件内容读取为字节流（例如
bytes相比，UploadFile有以下优点：</p>
<ul>
<li><strong>内存优化</strong>：它采用了文件对象的方式处理上传文件，不必将整个文件内容一次性加载到内存中，适合处理大文件。</li>
<li><strong>异步支持</strong>：支持异步操作，可以用异步方式读取文件内容，提高性能。</li>
<li><strong>文件元数据</strong>：提供文件名、内容类型等元数据信息，通过属性
<code>filename</code>、<code>content_type</code> 获取。</li>
<li><strong>文件接口</strong>：通过 file
属性获取一个类文件对象，可以像操作普通文件一样读取或保存上传的文件。</li>
</ul>
</blockquote>
<h4 id="request对象">4.6 Request对象</h4>
<p>有些情况下我们希望能直接访问 Request
对象。例如我们在路径操作函数中想获取客户端的 IP 地址，需要在函数中声明
Request 类型的参数，FastAPI 就会自动传递 Request
对象给这个参数，我们就可以获取到 Request 对象及其属性信息，例如
header、url、cookie、session 等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app06.post(<span class="params"><span class="string">&quot;/items&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">items</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;url:&quot;</span>, request.url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端ip:&quot;</span>, request.client.host)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求头:&quot;</span>, request.headers)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端宿主&quot;</span>,request.headers.get(<span class="string">&quot;user-agent&quot;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;cookie:&quot;</span>, request.cookies)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;url&quot;</span>: request.url,</span><br><span class="line">        <span class="string">&quot;client_ip&quot;</span>: request.client.host,</span><br><span class="line">        <span class="string">&quot;headers&quot;</span>: request.headers,</span><br><span class="line">        <span class="string">&quot;user_agent&quot;</span>: request.headers.get(<span class="string">&quot;user-agent&quot;</span>),</span><br><span class="line">        <span class="string">&quot;cookies&quot;</span>: request.cookies</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="请求静态文件">4.7请求静态文件</h4>
<p>在 Web 开发中，需要请求很多静态资源文件（不是由服务器生成的文件），如
css/js 和图片文件等。</p>
<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi.staticfiles <span class="keyword">import</span> StaticFiles</span><br><span class="line">app.mount(<span class="string">&quot;/static&quot;</span>, StaticFiles(directory=<span class="string">&quot;statics&quot;</span>))<span class="comment">#静态文件目录</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="./../../../../images/fastapi/image-20250517143857442.png" alt="image-20250517143857442">
<figcaption aria-hidden="true">image-20250517143857442</figcaption>
</figure>
<figure>
<img src="./../../../../images/fastapi/image-20250517143914772.png" alt="image-20250517143914772">
<figcaption aria-hidden="true">image-20250517143914772</figcaption>
</figure>
<blockquote>
<p><strong>静态网站</strong></p>
<p>完全由静态文件（HTML、CSS、JavaScript）组成，内容固定不变，所有页面在开发时已预生成，无需动态计算或数据库支持</p>
<p><strong>动态网站</strong></p>
<p>内容根据用户请求实时生成，通常依赖数据库和服务器端编程（如PHP、Python、Node.js），能提供个性化和交互功能</p>
</blockquote>
<blockquote>
<p><code>StaticFiles</code>是 FastAPI（实际来自
Starlette）提供的一个类，用于挂载和服务静态文件目录。
它的作用是让你可以通过 HTTP
路径直接访问服务器上的静态资源（如图片、CSS、JS 文件等）。</p>
</blockquote>
<blockquote>
<p><code>mount()</code>方法用于将一个完整的应用或静态文件目录挂载到主
FastAPI
应用的某个路径下。这样，访问指定路径时，请求会被转发到挂载的应用或目录。</p>
</blockquote>
<h4 id="响应模型相关参数">4.8 响应模型相关参数</h4>
<h5 id="response_model">response_model</h5>
<p><code>response_model</code>是 FastAPI 路由装饰器（如
<code>@app.post</code>、<code>@app.get</code>
等）中的一个参数，用于指定接口响应的数据模型。它的作用是：</p>
<ul>
<li><strong>自动校验和序列化</strong>：FastAPI 会根据你指定的 Pydantic
模型自动校验、过滤和格式化返回的数据。</li>
<li><strong>自动生成文档</strong>：接口文档会自动显示响应的数据结构。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UserIn</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    username: <span class="built_in">str</span></span><br><span class="line">    password: <span class="built_in">str</span></span><br><span class="line">    email: EmailStr</span><br><span class="line">    full_name: <span class="built_in">str</span>|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UserOut</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    username: <span class="built_in">str</span></span><br><span class="line">    email: EmailStr</span><br><span class="line">    full_name: <span class="built_in">str</span>|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app07.post(<span class="params"><span class="string">&quot;/user02&quot;</span>,response_model=UserOut</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_user</span>(<span class="params">user: UserIn</span>):</span><br><span class="line">    <span class="comment"># 这里可以进行一些处理，比如将用户信息存储到数据库中</span></span><br><span class="line">    <span class="keyword">return</span> user</span><br></pre></td></tr></table></figure>
<p>案例：</p>
<ul>
<li>注册功能</li>
<li>输入账号、密码、昵称、邮箱，注册成功后返回个人信息</li>
</ul>
<h5 id="response_model_exclude_unsettrue">response_model_exclude_unset=True</h5>
<p>通过上面的例子，我们学到了如何用 response_model
控制响应体结构，但是，如果它们实际上没有存储，则可能要从结果中忽略它们。例如，如果
model 在 NoSQL 数据库中具有很多可选属性，但是不想发送很长的 JSON
响应，其中包含默认值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Item</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name:<span class="built_in">str</span></span><br><span class="line">    description: <span class="built_in">str</span>|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line">    price: <span class="built_in">float</span></span><br><span class="line">    tax:<span class="built_in">float</span>=<span class="number">10.5</span></span><br><span class="line">    tags: <span class="built_in">list</span>[<span class="built_in">str</span>]|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#模拟数据库</span></span><br><span class="line">items=&#123;</span><br><span class="line">    <span class="string">&quot;item01&quot;</span>:Item(name=<span class="string">&quot;item01&quot;</span>,price=<span class="number">10.5</span>),</span><br><span class="line">    <span class="string">&quot;item02&quot;</span>:Item(name=<span class="string">&quot;item02&quot;</span>,description=<span class="string">&quot;item02&quot;</span>,price=<span class="number">20.5</span>,tax=<span class="number">20.5</span>,tags=[<span class="string">&quot;tag1&quot;</span>,<span class="string">&quot;tag2&quot;</span>]),</span><br><span class="line">    <span class="string">&quot;item03&quot;</span>:Item(name=<span class="string">&quot;item03&quot;</span>,description=<span class="string">&quot;item03&quot;</span>,price=<span class="number">30.5</span>,tax=<span class="number">30.5</span>,tags=[<span class="string">&quot;tag1&quot;</span>,<span class="string">&quot;tag2&quot;</span>]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app07.get(<span class="params"><span class="string">&quot;/items/&#123;item_id&#125;&quot;</span>,response_model=Item,response_model_exclude_unset=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">read_item</span>(<span class="params">item_id: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">return</span> items[item_id]</span><br></pre></td></tr></table></figure>
<p>设置后返回为：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">item01</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;item01&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">10.5</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>当你设置 <code>response_model_exclude_unset=True</code>
时，返回的响应数据只包含<strong>被显式设置过的字段</strong>，没有被赋值的（即使用默认值且未传递的）字段不会出现在响应中。</p>
</blockquote>
<h5 id="其他参数">其他参数</h5>
<p><strong>response_model_exclude_defaults
</strong>作用：排除所有值为默认值的字段。</p>
<p><strong>response_model_exclude_none</strong> 作用：排除所有值为
<code>None</code> 的字段。</p>
<p><strong>response_model_include</strong> 作用：只返回指定字段</p>
<p><strong>response_model_exclude</strong>
作用：排除指定字段，不在响应中返回。</p>
<h3 id="jinja2模板">jinja2模板</h3>
<p>要了解 jinja2，那么需要先理解模板的概念。模板在 Python 的 web
开发中广泛使用，它能够有效的将业务逻辑和页面逻辑分开，使代码可读性增强、并且更加容易理解和维护。</p>
<p>模板简单来说就是一个其中包涵占位变量表示动态的部分的文件，模板文件在经过动态赋值后，返回给用户。</p>
<p>jinja2 是 Flask 作者开发的一个模板系统，起初是仿 django
模板的一个模板引擎，为 Flask
提供模板支持，由于其灵活，快速和安全等优点被广泛使用。</p>
<p>在 jinja2 中，存在三种语法：</p>
<blockquote>
<ol type="1">
<li>变量取值 <code>&#123;&#123; &#125;&#125;</code></li>
<li>控制结构 <code>&#123;% %&#125;</code></li>
</ol>
</blockquote>
<blockquote>
<p>应用于前后端不分离，模板html+数据库，返回动态网站</p>
</blockquote>
<h4 id="变量">5.1 变量</h4>
<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi.templating <span class="keyword">import</span> Jinja2Templates</span><br><span class="line"></span><br><span class="line">templates=Jinja2Templates(directory=<span class="string">&quot;templates&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/index&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="comment">#数据库</span></span><br><span class="line">    name=<span class="string">&quot;World&quot;</span></span><br><span class="line">    books=[<span class="string">&quot;Python&quot;</span>, <span class="string">&quot;Java&quot;</span>, <span class="string">&quot;C++&quot;</span>]</span><br><span class="line">    user=&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;Tom&quot;</span>, <span class="string">&quot;age&quot;</span>:<span class="number">18</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> templates.TemplateResponse(</span><br><span class="line">        <span class="string">&quot;index.html&quot;</span>,<span class="comment">#模板文件</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;request&quot;</span>: request,<span class="comment"># FastAPI需要一个request对象</span></span><br><span class="line">            <span class="string">&quot;name&quot;</span>: name,</span><br><span class="line">            <span class="string">&quot;books&quot;</span>: books,</span><br><span class="line">            <span class="string">&quot;user&quot;</span>: user</span><br><span class="line">        &#125;<span class="comment">#context上下文对象</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>index.html</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=<span class="string">&quot;en&quot;</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=<span class="string">&quot;UTF-8&quot;</span>&gt;</span><br><span class="line">    &lt;meta name=<span class="string">&quot;viewport&quot;</span> content=<span class="string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span><br><span class="line">    &lt;title&gt;Document&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line"></span><br><span class="line">&lt;body&gt;</span><br><span class="line">    &lt;h1&gt;Hello, &#123;&#123; name &#125;&#125;!&lt;/h1&gt;</span><br><span class="line">    &lt;p&gt;Your favorite books are:&lt;/p&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">        &#123;% <span class="keyword">for</span> book <span class="keyword">in</span> books %&#125;</span><br><span class="line">        &lt;li&gt;&#123;&#123; book &#125;&#125;&lt;/li&gt;</span><br><span class="line">        &#123;% endfor %&#125;</span><br><span class="line">    &lt;/ul&gt;</span><br><span class="line">    &lt;p&gt;姓名：&#123;&#123; user.name &#125;&#125;&lt;/p&gt;</span><br><span class="line">    &lt;p&gt;年龄：&#123;&#123; user.age &#125;&#125;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line"></span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250517200643492.png" alt="image-20250517200643492">
<figcaption aria-hidden="true">image-20250517200643492</figcaption>
</figure>
<h4 id="过滤器">5.2 过滤器</h4>
<p>变量可以通过“过滤器”进行修改，过滤器可以理解为是 jinja2
里面的内置函数和字符串处理函数。常用的过滤器有：</p>
<table>
<thead>
<tr>
<th>过滤器名称</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>capitalize</td>
<td>把值的首字母转换成大写，其他字母转换为小写</td>
</tr>
<tr>
<td>lower</td>
<td>把值转换成小写形式</td>
</tr>
<tr>
<td>title</td>
<td>把值中每个单词的首字母都转换成大写</td>
</tr>
<tr>
<td>trim</td>
<td>把值的首尾空格去掉</td>
</tr>
<tr>
<td>striptags</td>
<td>渲染之前把值中所有的 HTML 标签都删掉</td>
</tr>
<tr>
<td>join</td>
<td>拼接多个值为字符串</td>
</tr>
<tr>
<td>round</td>
<td>默认对数字进行四舍五入，也可以用参数进行控制</td>
</tr>
<tr>
<td>safe</td>
<td>渲染时值不转义</td>
</tr>
</tbody>
</table>
<p>那么如何使用这些过滤器呢？只需要在变量后面使用管道 (|)
分割，多个过滤器可以链式调用，前一个过滤器的输出会作为后一个过滤器的输入。</p>
<p>例如：<code>&lt;h1&gt;Hello, &#123;&#123; name|upper &#125;&#125;!&lt;/h1&gt;</code>
<code>&lt;li&gt;&#123;&#123; book|title &#125;&#125;&lt;/li&gt;</code></p>
<h4 id="控制结构">5.3 控制结构</h4>
<p>jinja2中的if语句类似与Python的if语句，它也具有单分支，多分支等多种结构，不同的是，条件语句不需要使用冒号结尾，而结束控制语句，需要使用endif关键字</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&lt;p&gt;影视区&lt;/p&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% if age &gt;= <span class="number">18</span> %<span class="punctuation">&#125;</span></span><br><span class="line">&lt;ul&gt;</span><br><span class="line">    &lt;li&gt;成人影片&lt;/li&gt;</span><br><span class="line">    &lt;li&gt;成人游戏&lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% else %<span class="punctuation">&#125;</span></span><br><span class="line">&lt;ul&gt;</span><br><span class="line">    &lt;li&gt;儿童影片&lt;/li&gt;</span><br><span class="line">    &lt;li&gt;儿童游戏&lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% endif %<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>jinja2中的for循环用于迭代Python的数据类型，包括列表、元组和字典。在jinja2中不存在while循环。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>% for book in books %<span class="punctuation">&#125;</span></span><br><span class="line">&lt;li&gt;<span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> book|title <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>&lt;/li&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% endfor %<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="orm操作">ORM操作</h3>
<p>在大型的 Web 开发中，我们肯定会用到数据库操作，那么 FastAPI
也支持数据库的开发，你可以用 PostgreSQL、MySQL、SQLite、Oracle
等。本文用 SQLite 为例。我们看下在 FastAPI 是如何操作设计数据库的。</p>
<p>FastAPI 是一个很优秀的框架，但是缺少一个合适的
ORM，官方代码里面使用的是 SQLAlchemy，Tortoise ORM 是受 Django
启发的易于使用的异步 ORM（对象关系映射器）。</p>
<p>Tortoise ORM 目前支持以下数据库：</p>
<ul>
<li>PostgreSQL &gt;= 9.4（使用 asyncpg）</li>
<li>SQLite（使用 aiosqlite）</li>
<li>MySQL/MariaDB（使用 aiomysql 或使用 asyncmy）</li>
</ul>
<p>安装：<code>pip install tortoise-orm</code></p>
<h4 id="创建模型">6.1 创建模型</h4>
<p><strong>1. 一对一关系（One-to-One）</strong></p>
<ul>
<li><strong>定义</strong>
：一张表中的一条记录仅关联另一张表中的一条记录。</li>
<li><strong>示例</strong>
：用户表（User）与身份证信息表（IDCard），一个用户仅对应一张身份证信息。</li>
</ul>
<p><strong>2. 一对多关系（One-to-Many）</strong></p>
<ul>
<li><strong>定义</strong>
：一张表中的一条记录关联另一张表中的多条记录。</li>
<li><strong>示例</strong>
：班级表（Class）与学生表（Student），一个班级包含多个学生，但每个学生只能属于一个班级。</li>
</ul>
<p><strong>3. 多对多关系（Many-to-Many）</strong></p>
<ul>
<li><strong>定义</strong>
：两张表中的记录可以互相关联多条记录，通常通过中间表实现。</li>
<li><strong>示例</strong>
：学生表（Student）与课程表（Course），一个学生可选修多门课程，一门课程也可被多个学生选修。</li>
</ul>
<p><strong>4. 自引用关系（Self-Referencing）</strong></p>
<ul>
<li><strong>定义</strong>
：表内的记录通过字段关联自身，形成层级或树状结构。</li>
<li><strong>示例</strong>
：员工表（Employee），每个员工可能有直属上级（另一个员工）。</li>
</ul>
<p><strong>5. 继承关系（Inheritance）</strong></p>
<ul>
<li><strong>定义</strong>
：基于面向对象的继承概念，子表继承父表的字段和约束。</li>
<li><strong>示例</strong>
：用户表（User）作为基表，管理员表（Admin）和普通用户表（RegularUser）继承其字段（如用户名、密码）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tortoise.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tortoise <span class="keyword">import</span> fields</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Model 是所有数据模型的基类，通过继承 Model 可定义数据库表的结构。每个 Model 子类对应一张数据库表，其类属性定义了表的字段（列）及其约束。</span></span><br><span class="line"><span class="string">fields 提供了多种字段类型，用于定义数据库表的列及其约束。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> = fields.IntField(pk=<span class="literal">True</span>)<span class="comment">#该字段会被指定为模型的主键</span></span><br><span class="line">    name = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;姓名&quot;</span>)</span><br><span class="line">    pwd = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;密码&quot;</span>)</span><br><span class="line">    sno = fields.IntField(description=<span class="string">&quot;学号&quot;</span>)</span><br><span class="line">    <span class="comment">#一对多关系</span></span><br><span class="line">    Class_id = fields.ForeignKeyField(</span><br><span class="line">        <span class="string">&quot;models.Class&quot;</span>,<span class="comment">#关联的模型类</span></span><br><span class="line">        related_name=<span class="string">&quot;students&quot;</span>,<span class="comment">#反向查询时的名称</span></span><br><span class="line">        on_delete=fields.CASCADE,<span class="comment">#级联删除</span></span><br><span class="line">        description=<span class="string">&quot;班级&quot;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#多对多关系</span></span><br><span class="line">    Course_id = fields.ManyToManyField(</span><br><span class="line">        <span class="string">&quot;models.Course&quot;</span>,<span class="comment">#关联的模型类</span></span><br><span class="line">        related_name=<span class="string">&quot;students&quot;</span>,<span class="comment">#反向查询时的名称</span></span><br><span class="line">        description=<span class="string">&quot;课程&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Course</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> = fields.IntField(pk=<span class="literal">True</span>)</span><br><span class="line">    name = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;课程名称&quot;</span>)</span><br><span class="line">    teacher = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;授课老师&quot;</span>)</span><br><span class="line">    <span class="comment">#一对多关系</span></span><br><span class="line">    teacher_id = fields.ForeignKeyField(</span><br><span class="line">        <span class="string">&quot;models.Teacher&quot;</span>,<span class="comment">#关联的模型类</span></span><br><span class="line">        related_name=<span class="string">&quot;courses&quot;</span>,<span class="comment">#反向查询时的名称</span></span><br><span class="line">        on_delete=fields.CASCADE,<span class="comment">#级联删除</span></span><br><span class="line">        description=<span class="string">&quot;老师&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Class</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> = fields.IntField(pk=<span class="literal">True</span>)</span><br><span class="line">    name= fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;班级名称&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Teacher</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> =fields.IntField(pk=<span class="literal">True</span>)</span><br><span class="line">    name = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;老师姓名&quot;</span>)</span><br><span class="line">    pwd = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;密码&quot;</span>)</span><br><span class="line">    sno = fields.IntField(description=<span class="string">&quot;工号&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ORM（Object Relational
Mapping，对象关系映射）是一种程序设计技术，主要用于实现<strong>面向对象编程语言</strong>
与<strong>关系型数据库</strong>
之间的数据转换。其核心思想是通过对象模型与数据库表结构的映射，将数据库操作转化为面向对象的操作，从而简化开发流程并提升代码的可维护性</p>
</blockquote>
<blockquote>
<p>Tortoise ORM 是一款专为 Python
异步环境设计的轻量级对象关系映射（ORM）框架，其设计灵感来源于 Django
ORM，但专注于异步编程场景，适用于 FastAPI、Sanic 等基于
<code>asyncio</code> 的现代 Web 框架。</p>
</blockquote>
<blockquote>
<p>关系型数据库与非关系型数据库</p>
<p><strong>关系型数据库</strong>
以表格形式存储数据，数据按行和列组织，列代表属性（字段），行代表记录。例如，用户表可能包含
<code>id</code>、<code>name</code>、<code>email</code>
等列，每行对应一个用户记录。这种结构化设计支持严格的模式约束（Schema）17。</p>
<p><strong>典型代表</strong> ：MySQL、Oracle、PostgreSQL。</p>
<p><strong>非关系型数据库（NoSQL）</strong>
采用非结构化或半结构化存储，常见的类型包括：</p>
<ul>
<li><p><strong>文档型</strong> （如 MongoDB）：以 JSON 或 BSON
格式存储数据。</p></li>
<li><p><strong>键值型</strong> （如 Redis）：通过键直接访问值。</p></li>
<li><p><strong>列存储</strong> （如
Cassandra）：按列而非行组织数据。</p></li>
<li><p><strong>图数据库</strong></p>
<p>（如 Neo4j）：以节点和边表示数据关系</p></li>
</ul>
</blockquote>
<h4 id="aerich迁移工具">6.2 aerich迁移工具</h4>
<p><strong>docker 安装 mysql</strong>：</p>
<p>拉取 MySQL 镜像：<code>docker pull mysql</code></p>
<p>运行 MySQL 容器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run --name fastapi -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql</span><br></pre></td></tr></table></figure>
<blockquote>
<p>-p表示端口映射 –restart=always表示容器退出时总是重启
–name表示容器命名 –privileged=true表示赋予容器权限修改宿主文件权利 -v
/home/mysql/log:/var/log/mysql表示容器日志挂载到宿主机 -v
/home/mysql/data:/var/lib/mysql表示容器存储文件挂载到宿主机 -v
/home/mysql/conf/my.cnf:/etc/mysql/my.cnf表示容器配置文件挂载到宿主机 -e
MYSQL_ROOT_PASSWORD=a12bCd3_W45pUq6表示设置mysql的root用户密码,建议用强密码
-d表示后台运行</p>
</blockquote>
<p>启动这个 MySQL 容器：<code>docker start fastapi</code></p>
<p>进入 MySQL 容器：<code>docker exec -it fastapi bash</code></p>
<blockquote>
<p>这条命令的作用是：</p>
<ul>
<li><code>docker exec</code>：在已运行的 Docker 容器中执行命令。</li>
<li><code>-it</code>：<code>-i</code> 表示交互式操作，<code>-t</code>
分配一个伪终端（让你像在终端一样操作）。</li>
<li><code>fastapi</code>：这是你要进入的容器名称（你的 MySQL
容器名）。</li>
<li><code>bash</code>：在容器内启动 bash shell。</li>
</ul>
<p>这条命令会让你进入名为 <code>fastapi</code> 的容器，并获得一个 bash
命令行界面，就像登录到一台 Linux
服务器一样，可以在里面执行各种命令（比如登录 MySQL、查看日志等）。</p>
</blockquote>
<p>登录 MySQL：<code>mysql -u root -p</code></p>
<p>从主机直接连接：<code>mysql -h 127.0.0.1 -P 3306 -u root -p</code></p>
<h5 id="配置文件">配置文件</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TORTOISE_ORM = &#123;</span><br><span class="line">    &quot;connections&quot;: &#123;</span><br><span class="line">        &quot;default&quot;: &#123;</span><br><span class="line">            &quot;engine&quot;:&#x27;tortoise.backends.mysql&#x27;,#选择数据库引擎，mysql</span><br><span class="line">            &quot;credentials&quot;: &#123;</span><br><span class="line">                &quot;host&quot;: &quot;localhost&quot;,#数据库地址</span><br><span class="line">                &quot;port&quot;: 3306,#数据库端口</span><br><span class="line">                &quot;user&quot;: &quot;root&quot;,#数据库用户名</span><br><span class="line">                &quot;password&quot;: &quot;root&quot;,#数据库密码</span><br><span class="line">                &quot;database&quot;: &quot;fastapi_db&quot;,#数据库名称</span><br><span class="line">                &#x27;charset&#x27;: &quot;utf8mb4&quot;,#数据库编码</span><br><span class="line">                &#x27;echo&#x27;: True,#是否打印sql语句</span><br><span class="line">                &#x27;minsize&#x27;: 1,#连接池最小连接数</span><br><span class="line">                &#x27;maxsize&#x27;: 5#连接池最大连接数</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;apps&quot;: &#123;</span><br><span class="line">        &quot;models&quot;: &#123;</span><br><span class="line">            #db.models是我们自己定义的模型类,models在db文件夹下</span><br><span class="line">            &quot;models&quot;: [&quot;db.models&quot;,&quot;aerich.models&quot;],</span><br><span class="line">            &quot;default_connection&quot;: &quot;default&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;use_tz&#x27;: False,#是否使用时区</span><br><span class="line">    &#x27;timezone&#x27;: &#x27;Asia/Shanghai&#x27;,#时区</span><br><span class="line">    &quot;generate_schemas&quot;: True,</span><br><span class="line">    &quot;add_exception_handlers&quot;: True</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="初始化配置只需要使用一次">1.初始化配置，只需要使用一次</h5>
<p>aerich 是一种 ORM 迁移工具，需要结合 tortoise 异步 orm 框架使用。安装
aerich</p>
<p><code>pip install aerich</code></p>
<p><code>aerich init -t settings.TORTOISE_ORM  # TORTOISE_ORM 配置的位置</code></p>
<blockquote>
<p>初始化完会在当前目录生成一个文件：pyproject.toml
和一个文件夹：migrations</p>
<ul>
<li>pyproject.toml：保存配置文件路径，低版本可能是 aerich.ini</li>
<li>migrations：存放迁移文件</li>
</ul>
</blockquote>
<h5 id="初始化数据库一般情况下只用一次">2.初始化数据库，一般情况下只用一次</h5>
<p><code>aerich init-db</code></p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250521105044582.png" alt="image-20250521105044582">
<figcaption aria-hidden="true">image-20250521105044582</figcaption>
</figure>
<h5 id="更新模型并进行迁移">3.更新模型并进行迁移</h5>
<p>修改model类，重新生成迁移文件</p>
<p><code>aerich migrate</code></p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250521111024194.png" alt="image-20250521111024194">
<figcaption aria-hidden="true">image-20250521111024194</figcaption>
</figure>
<h5 id="重新执行迁移写入数据库">4.重新执行迁移，写入数据库</h5>
<p><code>aerich upgrade</code></p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250521111131931.png" alt="image-20250521111131931">
<figcaption aria-hidden="true">image-20250521111131931</figcaption>
</figure>
<h5 id="回到上一个版本">5.回到上一个版本</h5>
<p><code>aerich downgrade</code></p>
<h5 id="查看历史迁移记录">6.查看历史迁移记录</h5>
<p><code>aerich history</code></p>
<blockquote>
<p><code>register_tortoise</code> 是 Tortoise ORM
提供的一个工具函数，用于在 <strong>FastAPI</strong>
等异步框架中快速集成和管理 Tortoise ORM
的生命周期（如启动时初始化数据库连接，关闭时释放资源）。其核心作用是简化
Tortoise ORM
的配置和自动化管理，开发者只需一行代码即可完成复杂的初始化流程</p>
</blockquote>
<h4 id="orm查询操作">6.3 ORM查询操作</h4>
<p>api.stud</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"><span class="comment">#导入数据库</span></span><br><span class="line"><span class="keyword">from</span> db.models <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">student_api=APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.get(<span class="params"><span class="string">&quot;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_students</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    #查询所有学生信息</span></span><br><span class="line"><span class="string">    students= await Student.all()#获取所有学生信息</span></span><br><span class="line"><span class="string">    for student in students:</span></span><br><span class="line"><span class="string">        print(student.id,student.name)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #过滤查询filter</span></span><br><span class="line"><span class="string">    students= await Student.filter(name__contains=&quot;张&quot;).all()</span></span><br><span class="line"><span class="string">    for student in students:</span></span><br><span class="line"><span class="string">        print(student.id,student.name)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #get学生信息</span></span><br><span class="line"><span class="string">    stu = await Student.get(id=1)</span></span><br><span class="line"><span class="string">    print(stu.id,stu.name)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #模糊查询</span></span><br><span class="line"><span class="string">    #最大值</span></span><br><span class="line"><span class="string">    stu =await Student.filter(sno__gt=1000).all()</span></span><br><span class="line"><span class="string">    #最小值</span></span><br><span class="line"><span class="string">    #stu = await Student.filter(sno__lt=1000).all()</span></span><br><span class="line"><span class="string">    #范围查询</span></span><br><span class="line"><span class="string">    #stu = await Student.filter(sno__range=(1000,2000)).all()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #values查询</span></span><br><span class="line"><span class="string">    stu = await Student.all().values(&quot;sno&quot;,&quot;name&quot;)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">&quot;获取所有学生信息&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.post(<span class="params"><span class="string">&quot;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_student</span>():</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">&quot;创建学生信息&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.get(<span class="params"><span class="string">&quot;/&#123;student_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_student</span>(<span class="params">student_id:<span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">f&quot;获取学生信息，ID：<span class="subst">&#123;student_id&#125;</span>&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.put(<span class="params"><span class="string">&quot;/&#123;student_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">update_student</span>(<span class="params">student_id:<span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">f&quot;更新学生信息，ID：<span class="subst">&#123;student_id&#125;</span>&quot;</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在 FastAPI 和 Tortoise ORM 中，<code>async</code> 和
<code>await</code> 用于<strong>异步编程</strong>，主要原因如下：</p>
<ol type="1">
<li><strong>异步 I/O 操作</strong> 数据库查询（如
Student.all()）是耗时的 I/O 操作。使用
<code>async</code>/<code>await</code>
可以在等待数据库响应时，不阻塞主线程，提高应用的并发性能。</li>
<li><strong>FastAPI 支持异步路由</strong> FastAPI
支持异步（<code>async def</code>）的路由函数，这样可以充分利用 Python
的异步特性，提升 Web 服务的吞吐量。</li>
<li><strong>Tortoise ORM 的方法是异步的</strong> Tortoise ORM
的数据库操作方法（如 <code>.all()</code>、<code>.create()</code>
等）本身就是异步方法，必须用 <code>await</code> 调用，并且所在函数必须用
<code>async def</code> 声明。</li>
</ol>
</blockquote>
<h3 id="中间件">中间件</h3>
<p>FastAPI 的「中间件（middleware）」就是
<strong>在请求进入路由函数之前、响应离开路由函数之后</strong> 插入的
<strong>通用处理逻辑</strong>；</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250815144154925.png" alt="image-20250815144154925">
<figcaption aria-hidden="true">image-20250815144154925</figcaption>
</figure>
<h4 id="什么时候需要中间件">什么时候需要中间件</h4>
<p>真实场景举例 —— 统一鉴权 + 日志</p>
<p>需求 • 所有 API（/user、/order、/admin …）都必须验证 JWT； •
无论成功或失败，都记录一条结构化日志（URL、耗时、用户 ID、响应码）； •
鉴权失败直接 401，不再进入任何路由。</p>
<h4 id="实战">实战</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from fastapi import FastAPI, Request</span><br><span class="line">import uvicorn</span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line">@app.middleware(&quot;http&quot;)          # 注册一个全局中间件</span><br><span class="line">async def mid1(request: Request, call_next):</span><br><span class="line">    print(&quot;mid1 request&quot;)</span><br><span class="line">    response = await call_next(request)   #先让请求继续往后走</span><br><span class="line">    print(&quot;mid1 respones&quot;)</span><br><span class="line">    return response</span><br><span class="line"></span><br><span class="line">@app.middleware(&quot;http&quot;) </span><br><span class="line">async def mid2(request: Request, call_next):</span><br><span class="line">    print(&quot;mid2 request&quot;)</span><br><span class="line">    response = await call_next(request)</span><br><span class="line">    print(&quot;mid2 respones&quot;)</span><br><span class="line">    return response</span><br><span class="line"></span><br><span class="line">@app.get(&quot;/&quot;)                    # 任意路由</span><br><span class="line">def home():</span><br><span class="line">    print(&quot;home&quot;)</span><br><span class="line">    return &#123;&quot;msg&quot;: &quot;ok&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    uvicorn.run(app, host=&quot;127.0.0.1&quot;, port=8000)</span><br></pre></td></tr></table></figure>
<p>注意中间件添加的顺序</p>
<p>FastAPI/Starlette
把<strong>后添加的中间件包在最外层</strong>（洋葱最外层）</p>
<p>所以 <strong>mid2 在外层</strong>，请求先打印</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mid2 request</span><br><span class="line">mid1 request</span><br><span class="line">home</span><br><span class="line">mid1 response</span><br><span class="line">mid2 response</span><br></pre></td></tr></table></figure>
<h3 id="cors组件">cors组件</h3>
<p>CORS（Cross-Origin Resource Sharing，跨源资源共享）
一句话：<strong>浏览器为了安全，默认禁止网页去“别的域名/端口/协议”拿数据；CORS
是一套 HTTP
机制，让服务器告诉浏览器“我允许谁来拿、拿什么、怎么拿”。</strong></p>
<h4 id="同源与跨域">同源与跨域</h4>
<p>同源（Same-Origin）</p>
<p>浏览器把下面三个部分合称 <strong>“源”</strong>（origin）：</p>
<ol type="1">
<li>协议（<code>http:</code> / <code>https:</code>）</li>
<li>域名（<code>example.com</code> / <code>sub.example.com</code>
算不同）</li>
<li>端口（<code>:80</code> / <code>:8080</code>）</li>
</ol>
<p>只有当 <strong>协议 + 域名 + 端口</strong>
都完全一致时，才叫<strong>同源</strong>。 此时前端 JS
可以无限制地访问该源下的资源。</p>
<p>跨域（Cross-Origin）</p>
<p>只要 <strong>协议、域名、端口</strong>
中的任意一个不同，就是<strong>跨域</strong>。</p>
<p><strong>正常来说，服务器为了保护数据，会拒绝跨域的响应，但是通过cors可以允许跨域，因此，CORS
不是“绕过”安全限制，而是服务器主动声明的“安全白名单”。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 为 FastAPI 应用添加 CORS（跨源资源共享）中间件</span><br><span class="line"># 允许浏览器跨域访问本服务，开发阶段常用；生产环境请收窄范围</span><br><span class="line">app.add_middleware(</span><br><span class="line">    CORSMiddleware,</span><br><span class="line">    allow_origins=[&quot;*&quot;],        # 允许所有来源（生产建议改成具体域名列表，如 [&quot;https://foo.com&quot;]）</span><br><span class="line">    allow_credentials=False,    # 是否允许携带 Cookie/Authorization；True 时 origins 不能为 &quot;*&quot;</span><br><span class="line">    allow_methods=[&quot;GET&quot;],      # 允许的 HTTP 方法；[&quot;*&quot;] 表示全部</span><br><span class="line">    allow_headers=[&quot;*&quot;],        # 允许的自定义请求头；[&quot;*&quot;] 表示全部</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="知识点">知识点</h3>
<h4 id="端口查询">端口查询</h4>
<p>查看所有端口占用情况：<code>netstat -ano</code></p>
<p>查询特定端口是否被占用：<code>netstat -ano | findstr 8080</code></p>
<p>使用 <code>taskkill</code>
命令强制结束进程：<code>taskkill /PID 进程ID /F</code></p>
<p>通过 PID 查找进程：<code>tasklist | findstr PID</code></p>
<h4 id="获取绝对路径">获取绝对路径</h4>
<p>获取当前文件的绝对路径：<code>base_dir = os.path.dirname(os.path.abspath(__file__))</code></p>
<p>拼接路径：<code>img_dir = os.path.join(base_dir, "../imgs")</code></p>
<h4 id="mysql部分指令">mysql部分指令</h4>
<p><strong>查看数据库列表</strong>：<code>SHOW DATABASES;</code></p>
<p><strong>选择数据库</strong>：<code>USE 数据库名;</code></p>
<p><strong>删除数据库</strong>：<code>DROP DATABASE 数据库名;</code></p>
<p><strong>创建数据库</strong>：<code>CREATE DATABASE 数据库名;</code></p>
<p><strong>登录 MySQL</strong>：<code>mysql -u root -p</code></p>
<p><strong>退出</strong>：<code>exit</code></p>
<h4 id="docker部分指令">docker部分指令</h4>
<p><strong>linux安装docker</strong>：<code>sudo apt-get update &amp;&amp; sudo apt-get install docker.io</code></p>
<p><strong>查看 Docker
版本信息</strong>：<code>docker version</code></p>
<p><strong>查看镜像</strong>：<code>docker images</code></p>
<p><strong>查看所有的容器</strong>：<code>docker ps -a</code></p>
<blockquote>
<p><code>systemctl</code> 是 <strong>systemd</strong>
系统和服务管理器的核心工具，用于管理系统和服务的状态及配置。</p>
</blockquote>
<p><code>mysql-client</code> 是 MySQL
数据库的命令行客户端工具。它允许你通过命令行连接和操作 MySQL
数据库服务器，比如执行 SQL 查询、管理数据库和用户等。</p>
<p>常用命令格式如下：<code>mysql -h 主机地址 -P 端口号 -u 用户名 -p</code></p>
<p>你可以在终端输入以下命令来检查是否已安装
<code>mysql-client</code>：<code>mysql --version</code></p>
<p>可以使用以下命令安装：<code>sudo apt-get update  sudo apt-get install mysql-client</code></p>
<blockquote>
<p><code>sudo apt-get update</code>
这个命令的作用是<strong>更新本地软件包列表</strong>。</p>
</blockquote>
<p><strong>停止并删除容器</strong>：<code>docker stop fastapi  docker rm fastapi</code></p>
<h3 id="参考资料">参考资料</h3>
<p>fastapi一个项目<a href="https://www.bilibili.com/video/BV1TSVPzkE7Y?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">FastAPI进阶_哔哩哔哩_bilibili</a></p>
<p>教程<a href="https://www.bilibili.com/video/BV1Ya4y1D7et/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">fastapi框架快速学习_哔哩哔哩_bilibili</a></p>
<p>fastapi相关知识的补充<a href="https://www.bilibili.com/video/BV1zJ7mzdEc8?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Python
异步编程 - 搞明白 async, await (继续解释
yield)_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>python-web</category>
        <category>fastapi</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机3——逻辑回归（广告点击率预测）</title>
    <url>/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="广告点击率预测">广告点击率预测</h1>
<p>广告点击率(CTR)预测是广告行业的典型应用，是评估广告效果的一个非常重要的指标。通过历史数据训练预测模型，对于每天的增量数据进行预测，找出广告的CTR符合标准的样本进行投放。
## 数据集介绍
数据集来自于kaggle，数据包含了10天的Avazu的广告点击数据，训练集10000个，测试集1000个。每一条广告包含：广告id、时间、广告位置等属性。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/1682d3186a5d4fedab10c4ad3a7f3656e3db56852e5c4fdbb4fb26005c0ba811"></p>
<h2 id="任务1导入库和数据集与数据预处理">任务1：导入库和数据集与数据预处理</h2>
<ul>
<li>读入训练数据和测试数据，划分data和label</li>
<li>将string类型的特征转化为int型：1）进行 one-hot
编码处理，会得到高维稀疏的特征，增大内存开销；2）使用python内置的hash函数将那些类型为object的特征变量映射为一定范围内的整数(原来的string被映射成了integer)，可以大大降低内存的消耗。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">types_train = &#123;</span><br><span class="line">    <span class="string">&#x27;id&#x27;</span>: np.dtype(<span class="built_in">int</span>),</span><br><span class="line">    <span class="string">&#x27;click&#x27;</span>: np.dtype(<span class="built_in">int</span>),         <span class="comment">#是否点击,1表示被点击,0表示没被点击</span></span><br><span class="line">    <span class="string">&#x27;hour&#x27;</span>: np.dtype(<span class="built_in">int</span>),          <span class="comment">#广告被展现的日期+时间</span></span><br><span class="line">    <span class="string">&#x27;C1&#x27;</span>: np.dtype(<span class="built_in">int</span>),            <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;banner_pos&#x27;</span>: np.dtype(<span class="built_in">int</span>),    <span class="comment">#广告位置</span></span><br><span class="line">    <span class="string">&#x27;site_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),       <span class="comment">#站点Id</span></span><br><span class="line">    <span class="string">&#x27;site_domain&#x27;</span>: np.dtype(<span class="built_in">str</span>),   <span class="comment">#站点域名</span></span><br><span class="line">    <span class="string">&#x27;site_category&#x27;</span>: np.dtype(<span class="built_in">str</span>), <span class="comment">#站点分类</span></span><br><span class="line">    <span class="string">&#x27;app_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),        <span class="comment"># appId</span></span><br><span class="line">    <span class="string">&#x27;app_domain&#x27;</span>: np.dtype(<span class="built_in">str</span>),    <span class="comment"># app域名</span></span><br><span class="line">    <span class="string">&#x27;app_category&#x27;</span>: np.dtype(<span class="built_in">str</span>),  <span class="comment"># app分类</span></span><br><span class="line">    <span class="string">&#x27;device_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),     <span class="comment">#设备Id</span></span><br><span class="line">    <span class="string">&#x27;device_ip&#x27;</span>: np.dtype(<span class="built_in">str</span>),     <span class="comment">#设备Ip</span></span><br><span class="line">    <span class="string">&#x27;device_model&#x27;</span>: np.dtype(<span class="built_in">str</span>),  <span class="comment">#设备型号</span></span><br><span class="line">    <span class="string">&#x27;device_type&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#设备型号</span></span><br><span class="line">    <span class="string">&#x27;device_conn_type&#x27;</span>: np.dtype(<span class="built_in">int</span>),</span><br><span class="line">    <span class="string">&#x27;C14&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C15&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C16&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C17&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C18&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C19&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C20&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C21&#x27;</span>:np.dtype(<span class="built_in">int</span>)     <span class="comment">#匿名分类变量</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加列名</span></span><br><span class="line">header_row = [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;click&#x27;</span>, <span class="string">&#x27;hour&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;banner_pos&#x27;</span>, <span class="string">&#x27;site_id&#x27;</span>, <span class="string">&#x27;site_domain&#x27;</span>, <span class="string">&#x27;site_category&#x27;</span>, \</span><br><span class="line">              <span class="string">&#x27;app_id&#x27;</span>, <span class="string">&#x27;app_domain&#x27;</span>, <span class="string">&#x27;app_category&#x27;</span>, <span class="string">&#x27;device_id&#x27;</span>, <span class="string">&#x27;device_ip&#x27;</span>, <span class="string">&#x27;device_model&#x27;</span>,\</span><br><span class="line">              <span class="string">&#x27;device_type&#x27;</span>, <span class="string">&#x27;device_conn_type&#x27;</span>, <span class="string">&#x27;C14&#x27;</span>, <span class="string">&#x27;C15&#x27;</span>, <span class="string">&#x27;C16&#x27;</span>, <span class="string">&#x27;C17&#x27;</span>, <span class="string">&#x27;C18&#x27;</span>, <span class="string">&#x27;C19&#x27;</span>,\</span><br><span class="line">              <span class="string">&#x27;C20&#x27;</span>, <span class="string">&#x27;C21&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入训练数据和测试数据</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train_data.csv&#x27;</span>, names=header_row, dtype=types_train)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;test_data.csv&#x27;</span>, names=header_row, dtype=types_train)</span><br><span class="line"><span class="comment"># 去除第0行（表示列的编号，不是样本）</span></span><br><span class="line">train = train.drop(labels=train.index.values[<span class="number">0</span>])</span><br><span class="line">test = test.drop(labels=test.index.values[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(test.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分data和label</span></span><br><span class="line">train_data = train.drop(<span class="string">&#x27;click&#x27;</span>, axis=<span class="number">1</span>) <span class="comment">#去除click 这一列</span></span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br><span class="line">train_label = train[<span class="string">&#x27;click&#x27;</span>] <span class="comment">#提取click 这一列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="comment"># 使用pd.get_dummies对非数值型特征进行 one-hot 编码处理，得到高维稀疏的特征</span></span><br><span class="line">train_data1 = pd.get_dummies(train_data)</span><br><span class="line"><span class="built_in">print</span>(train_data1.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编写convert_obj_to_int()函数将string类型的特征转换为int型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_obj_to_int</span>(<span class="params">self</span>):</span><br><span class="line">    object_list_columns = <span class="variable language_">self</span>.columns</span><br><span class="line">    object_list_dtypes = <span class="variable language_">self</span>.dtypes</span><br><span class="line">    new_col_suffix = <span class="string">&#x27;_int&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(object_list_columns)):</span><br><span class="line">        <span class="keyword">if</span> object_list_dtypes[index] == <span class="built_in">object</span>:</span><br><span class="line">            <span class="comment"># 使用hash和map将string特征变量映射为一定范围内的整数</span></span><br><span class="line">            <span class="variable language_">self</span>[object_list_columns[index] + new_col_suffix] = <span class="variable language_">self</span>[object_list_columns[index]].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">hash</span>(x) % (<span class="number">1</span> &lt;&lt; <span class="number">32</span>))</span><br><span class="line">            <span class="variable language_">self</span>.drop([object_list_columns[index]], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用convert_obj_to_int()函数，将string类型转换为int型    </span></span><br><span class="line">train_data = convert_obj_to_int(train_data)</span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1000, 24)
(10000, 23)
(10000, 10531)
(10000, 23)


C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:</code></pre>
<h2 id="任务2特征分析">任务2：特征分析</h2>
<p>以广告在网页中的位置(banner_pos)为例，查看banner_pos和最终类标(click)之间的关系。
- 查看banner_pos在数据集中的取值分布； -
查看不同banner_pos对点击率click的贡献。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看banner_pos在数据集中的取值分布</span></span><br><span class="line"><span class="built_in">print</span>(train.banner_pos.value_counts()/<span class="built_in">len</span>(train))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看不同banner_pos对点击率click的贡献</span></span><br><span class="line">banner_pos_val = train.banner_pos.unique()</span><br><span class="line">banner_pos_val.sort()</span><br><span class="line">ctr_avg_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> banner_pos_val:</span><br><span class="line">    selected_data = train.loc[train.banner_pos == i]</span><br><span class="line">    ctr_avg = selected_data.click.mean()</span><br><span class="line">    ctr_avg_list.append(ctr_avg)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; banner 位置: &#123;&#125;,  点击率: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, ctr_avg))</span><br></pre></td></tr></table></figure>
<pre><code>banner_pos
0    0.8041
1    0.1951
2    0.0007
4    0.0001
Name: count, dtype: float64
 banner 位置: 0,  点击率: 0.16975500559631887
 banner 位置: 1,  点击率: 0.19067145053818554
 banner 位置: 2,  点击率: 0.14285714285714285
 banner 位置: 4,  点击率: 0.0</code></pre>
<h2 id="任务3模型训练与评估">任务3：模型训练与评估</h2>
<ul>
<li>调用sklearn的逻辑回归函数LogisticRegression()，进行模型训练</li>
<li>对测试集test_data进行预测，计算预测结果的各项指标acc, pre, recall,
auc</li>
<li>绘制ROC曲线（使用预测的概率值而不是预测的类标）</li>
<li><strong>选做</strong>：自定义逻辑回归函数MyLogisticRegression()，进行模型训练与预测，与上述结果比较。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_data = test.drop(<span class="string">&#x27;click&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">test_data = convert_obj_to_int(test_data)</span><br><span class="line">test_label = test[<span class="string">&#x27;click&#x27;</span>]</span><br><span class="line"><span class="comment"># 调用sklearn的逻辑回归函数LogisticRegression()</span></span><br><span class="line">clf = linear_model.LogisticRegression(max_iter=<span class="number">1000</span>)  <span class="comment"># 增加最大迭代次数防止不收敛</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">clf.fit(train_data, train_label)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Finish Training!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">pred = clf.predict(test_data)</span><br><span class="line">pred_proba = clf.predict_proba(test_data)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算模型的acc, pre, recall, auc，并输出</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line">acc = accuracy_score(test_label, pred)</span><br><span class="line">pre = precision_score(test_label, pred)</span><br><span class="line">recall = recall_score(test_label, pred)</span><br><span class="line">auc = roc_auc_score(test_label, pred_proba)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>, Precision: <span class="subst">&#123;pre:<span class="number">.4</span>f&#125;</span>, Recall: <span class="subst">&#123;recall:<span class="number">.4</span>f&#125;</span>, AUC: <span class="subst">&#123;auc:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># 绘制roc曲线</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line">fpr, tpr, _ = roc_curve(test_label, pred_proba)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(fpr, tpr, label=<span class="string">f&#x27;AUC = <span class="subst">&#123;auc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>], [<span class="number">0</span>,<span class="number">1</span>], <span class="string">&#x27;k--&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;ROC Curve (sklearn)&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 自定义实现逻辑回归函数MyLogisticRegression()</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Finish Training!
Accuracy: 0.8120, Precision: 0.0000, Recall: 0.0000, AUC: 0.4983


C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
f:\Anconda\Anconda\envs\general\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;&#123;metric.capitalize()&#125; is&quot;, len(result))</code></pre>
<figure>
<img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/main_5_2.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p>​<br>
Custom Model - Accuracy: 0.8240, Precision: 0.6875, Recall: 0.1170, AUC:
0.6580</p>
<figure>
<img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/main_5_4.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机3——线性回归（医疗保险费预测）</title>
    <url>/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="线性回归">线性回归</h1>
<h2 id="任务1.-一元线性回归">任务1. 一元线性回归</h2>
<h3 id="任务介绍">任务介绍：</h3>
<ul>
<li>自定义一元回归函数MyLinearRegression()，输入参数为x和y的数组xArr和yArr，输出为参数w1和w0，利用最小二乘法求得参数;</li>
<li>使用美国医疗保险费数据insurance.csv中的输入特征age和目标特征charges，输入MyLinearRegression()函数，得到回归参数值w1和w0，并保留到小数点后两位;</li>
<li>调用sklearn的LinearRegression()函数，比较其运行结果与上述自定义函数MyLinearRegression()的输出结果是否一致。</li>
<li>利用age与charges绘制真实样本点，利用w1与w0计算预测值，再绘制age与预测值的点图，观察真实样本点与预测点之间的拟合程度。</li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line">age = insurance[<span class="string">&#x27;age&#x27;</span>].values</span><br><span class="line">charges = insurance[<span class="string">&#x27;charges&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 定义一元线性回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># x均值, y均值计算</span></span><br><span class="line">    mean_x = xArr.mean()</span><br><span class="line">    mean_y = yArr.mean()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># w0, w1计算，公式</span></span><br><span class="line">    numerator = np.<span class="built_in">sum</span>((xArr - mean_x) * (yArr - mean_y))</span><br><span class="line">    denominator = np.<span class="built_in">sum</span>((xArr - mean_x)**<span class="number">2</span>)</span><br><span class="line">    w1 = numerator / denominator</span><br><span class="line">    w0 = mean_y - w1 * mean_x</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(w0,<span class="number">2</span>), <span class="built_in">round</span>(w1,<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型训练，得到参数值&quot;</span>)</span><br><span class="line">w0, w1 = MyLinearRegression(age, charges)</span><br><span class="line"><span class="built_in">print</span>(w1,<span class="string">&#x27;\n&#x27;</span>, w0)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sklearn的训练结果&quot;</span>)</span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment">#线性回归模型训练</span></span><br><span class="line">lr.fit(age.reshape(-<span class="number">1</span>, <span class="number">1</span>), charges)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.coef_[<span class="number">0</span>],<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.intercept_,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 观察真实样本点与预测点之间的拟合程度</span></span><br><span class="line">plt.scatter(age, charges, marker=<span class="string">&#x27;.&#x27;</span>)  <span class="comment"># 画样本点，随机散点</span></span><br><span class="line"><span class="comment"># 利用w1与w0计算预测值，绘制预测点</span></span><br><span class="line">plt.scatter(age, w1 * age + w0, marker=<span class="string">&#x27;+&#x27;</span>)  <span class="comment"># 画预测点，形成直线</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>模型训练，得到参数值
257.72 
 3165.89
sklearn的训练结果
257.72
3165.89</code></pre>
<figure>
<img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/main_2_1.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<h3 id="最小二乘法求解公式"><strong>最小二乘法求解公式</strong></h3>
<p><strong>目标</strong>：最小化预测值与真实值的平方误差之和： <span class="math display">$$ \min_{w_0, w_1} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$</span></p>
<p><strong>闭式解（Normal Equation）</strong>：<br>
1. <strong>斜率 ( w_1 )</strong>：<br>
<span class="math display">$$ w_1 = \frac{\sum_{i=1}^n (x_i -
\bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} $$</span><br>
其中 ({x}) 和 ({y}) 分别是 (x) 和 (y) 的均值。</p>
<ol start="2" type="1">
<li><strong>截距 ( w_0 )</strong>：<br>
<span class="math display"><em>w</em><sub>0</sub> = <em>ȳ</em> − <em>w</em><sub>1</sub><em>x̄</em></span></li>
</ol>
<p>round(w0, 2) 和 round(w1, 2)
的作用是对线性回归模型的参数进行四舍五入处理，保留两位小数。</p>
<p>这段代码使用 <code>scikit-learn</code> 的
<code>LinearRegression</code>
类实现线性回归，并输出模型参数。以下是逐行解释： ### 1.
<strong>创建线性回归模型实例</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr = LinearRegression()</span><br></pre></td></tr></table></figure> -
<code>LinearRegression()</code> 是 <code>scikit-learn</code>
中用于线性回归的类。 - <code>lr</code>
是该类的一个实例，后续通过它调用模型训练、预测等方法。 ### 2.
<strong>模型训练</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr.fit(age.reshape(-<span class="number">1</span>, <span class="number">1</span>), charges)</span><br></pre></td></tr></table></figure> -
<strong>作用</strong>：用输入数据 <code>age</code>（特征）和
<code>charges</code>（目标值）训练线性回归模型。 -
<strong>关键细节</strong>： - <code>age</code> 是一维数组（形状如
<code>(n,)</code>），但 <code>scikit-learn</code>
要求输入特征为二维数组（形状如 <code>(n, 1)</code>）。 -
<code>age.reshape(-1, 1)</code>
将一维数组转换为二维列向量（<code>n</code> 行 1 列），确保输入格式正确。
- <code>charges</code> 是目标值的一维数组，无需调整形状。 ### 3.
<strong>输出模型参数</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.coef_[<span class="number">0</span>], <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.intercept_, <span class="number">2</span>))</span><br></pre></td></tr></table></figure> -
<strong><code>lr.coef_</code></strong>： - 存储模型的回归系数（即
<code>w1</code>，特征权重）。 - 对于一元线性回归，<code>coef_</code>
是一个包含单个元素的数组（如 <code>[w1]</code>），因此用
<code>coef_[0]</code> 提取数值。 -
<strong><code>lr.intercept_</code></strong>： - 存储模型的截距项（即
<code>w0</code>）。 - 直接通过 <code>intercept_</code> 访问，无需索引。
-
<strong><code>round(..., 2)</code></strong>：将参数四舍五入保留两位小数，便于与自定义函数结果对比。</p>
<h2 id="任务2.-多元线性回归">任务2. 多元线性回归</h2>
<h3 id="任务介绍-1">任务介绍：</h3>
<ul>
<li>自定义多元线性回归函数MyLinearRegression2()，输入参数为X和y的数组xArr和yArr，输出为参数ws，利用最小二乘法求得参数;</li>
<li>使用美国医疗保险费数据insurance.csv中的输入特征age、bmi和children，目标特征charges，根据MyLinearRegression2()函数，得到回归参数值ws；注意判断（X^T
X）^{-1}是否为满秩，如果满秩，则引入正则项，参数为alpha，目标函数变为岭回归问题。</li>
<li>为了得到模型的截距，需要在矩阵X最后增加一列，并且该列所有行的值均为1。</li>
<li>调用sklearn的LinearRegression()函数，比较其运行结果与上述自定义函数MyLinearRegression2()的输出结果是否一致。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg, column_stack, ones, array</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># 定义多元线性回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression2</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用mat将Array转换为矩阵</span></span><br><span class="line">    xMat = np.asmatrix(xArr)</span><br><span class="line">    yMat = np.asmatrix(yArr).T  <span class="comment"># 转换为列向量</span></span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    <span class="comment"># 通过调用linalg计算行列式来判定协方差矩阵是否可逆</span></span><br><span class="line">    <span class="keyword">if</span> linalg.det(xTx) &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>( <span class="string">&quot;singular matrix, can&#x27;t do inverse&quot;</span>)</span><br><span class="line">        <span class="comment"># 引入正则项，即 岭回归</span></span><br><span class="line">        alpha = <span class="number">0.1</span></span><br><span class="line">        <span class="comment"># 添加岭回归正则项（单位矩阵大小为特征数+1）</span></span><br><span class="line">        xTx  += alpha * np.eye(xMat.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算参数向量</span></span><br><span class="line">    <span class="comment"># 计算参数并转为一维数组</span></span><br><span class="line">    ws = xTx.I * (xMat.T * yMat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练，得到参数值</span></span><br><span class="line">X = insurance[[<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;bmi&#x27;</span>, <span class="string">&#x27;children&#x27;</span>]].values</span><br><span class="line"><span class="comment"># 调用column_stack函数在矩阵X后增加一列，并且该列所有行的值均为1</span></span><br><span class="line"><span class="comment"># 添加截距列（全1）</span></span><br><span class="line">X = column_stack((X, ones(X.shape[<span class="number">0</span>])))</span><br><span class="line">y = insurance[<span class="string">&#x27;charges&#x27;</span>]</span><br><span class="line">ws = MyLinearRegression2(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自定义的训练结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ws)</span><br><span class="line"><span class="comment"># sklearn的训练结果</span></span><br><span class="line">lr = LinearRegression(fit_intercept=<span class="literal">False</span>)  <span class="comment"># 关键：禁用自动截距</span></span><br><span class="line"><span class="comment">#线性回归模型训练</span></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sklearn的训练结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(lr.coef_)</span><br><span class="line"><span class="built_in">print</span>(lr.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>自定义的训练结果
[[  239.99447429]
 [  332.0833645 ]
 [  542.86465225]
 [-6916.24334779]]
sklearn的训练结果
[  239.99447429   332.0833645    542.86465225 -6916.24334779]
0.0</code></pre>
<h2 id="任务3.-线性回归应用预测医疗费用">任务3.
线性回归应用：预测医疗费用</h2>
<h3 id="任务介绍-2">任务介绍</h3>
<ul>
<li>对insurance.csv中的名义型特征进行One-Hot编码，得到了数据变量insurance</li>
<li>请使用自定义的多元回归函数MyLinearRegression2()得到回归模型参数ws和预测值y_pred，并计算R2分数</li>
<li>比较使用sklearn进行模型训练和模型评价R2分数的结果</li>
</ul>
<p>复用上一节实验中实现的代码，可以复制粘贴代替下面的代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model, metrics</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array, mean, ones</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用get_dummies函数对非数值型特征进行 one-hot 编码处理，以便于运算</span></span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line">insurance = pd.get_dummies(insurance, drop_first=<span class="literal">True</span>)  <span class="comment"># One-Hot编码</span></span><br><span class="line"><span class="built_in">print</span>(insurance.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从insurance中获取X与y</span></span><br><span class="line">X = insurance.drop([<span class="string">&#x27;charges&#x27;</span>], axis=<span class="number">1</span>).values.astype(np.float64)</span><br><span class="line">y = insurance[<span class="string">&#x27;charges&#x27;</span>].values.astype(np.float64)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个特征与y的关系进行可视化，观察与y的相关性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">1</span>]):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">6</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.scatter(array(X)[:,i],y,s=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression2</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用mat将Array转换为矩阵</span></span><br><span class="line">    xMat = np.asmatrix(xArr)</span><br><span class="line">    yMat = np.asmatrix(yArr).T  <span class="comment"># 转换为列向量</span></span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    <span class="comment"># 通过调用linalg计算行列式来判定协方差矩阵是否可逆</span></span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(xTx) &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>( <span class="string">&quot;singular matrix, can&#x27;t do inverse&quot;</span>)</span><br><span class="line">        <span class="comment"># 引入正则项，即 岭回归</span></span><br><span class="line">        alpha = <span class="number">0.1</span></span><br><span class="line">        <span class="comment"># 添加岭回归正则项（单位矩阵大小为特征数+1）</span></span><br><span class="line">        xTx  += alpha * np.eye(xMat.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算参数向量</span></span><br><span class="line">    <span class="comment"># 计算参数并转为一维数组</span></span><br><span class="line">    ws = xTx.I * (xMat.T * yMat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据X、y和自定义函数MyLinearRegression2()训练模型参数ws，并计算X的预测值y_pred</span></span><br><span class="line">ws = MyLinearRegression2(X, y)</span><br><span class="line">y_pred = X.dot(ws)</span><br><span class="line">y_pred = array(y_pred).reshape(y_pred.shape[<span class="number">0</span>],) <span class="comment"># 将矩阵转换为一行多列的array格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用metrics中的r2_score函数根据y和y_pred计算决定系数score</span></span><br><span class="line">score = metrics.r2_score(y, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sklearn模型训练与预测</span></span><br><span class="line">lr = linear_model.LinearRegression(fit_intercept=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="comment"># 计算X的预测值y_pred_sk与R2分数score_sk</span></span><br><span class="line">y_pred_sk = lr.predict(X)              <span class="comment"># 使用训练好的sklearn模型进行预测</span></span><br><span class="line">score_sk = metrics.r2_score(y, y_pred_sk)  <span class="comment"># 计算决定系数R²</span></span><br><span class="line"><span class="built_in">print</span>(score_sk)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>(1338, 9)</code></pre>
<figure>
<img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/main_9_1.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<pre><code>0.7235368166092777</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——第二次上机——波士顿房价预测任务（线性回归、岭回归实现）</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%EF%BC%88%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0%EF%BC%89/</url>
    <content><![CDATA[<h1 id="波士顿房价预测任务线性回归岭回归实现">波士顿房价预测任务（线性回归、岭回归实现）</h1>
<p>包括数据准备、模型训练、模型评估与选择、性能度量、参数选择</p>
<h2 id="问题背景与数据集介绍">问题背景与数据集介绍</h2>
<p>波士顿房价预测是一个经典的机器学习任务，类似于程序员世界的“Hello
World”。和大家对房价的普遍认知相同，波士顿地区的房价受诸多因素影响。美国某经济杂志登出波士顿房价数据集，该数据集包含506条观测信息，统计了13种可能影响房价的因素（输入变量）和该类型房屋的均价（输出变量），其中每条观测信息包含城镇犯罪率、一氧化氮浓度、住宅平均房间数、到中心区域的加权距离以及自住房平均房价等关于波士顿周边或者城镇房价的描述，期望通过分析影响波士顿房价的因素来构建房价预测模型。相关属性描述如下图所示，其中最后一项就是想要预测的房屋均价。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/be005522b4c441ba89ee7a2ad8277f7c8706457a7a8e4b5f84f92591a32b701d"></p>
<p>观测数据的示例如下图所示。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/46fb2e80de2047ff8af2c16819a9e3f5114533f01e3c44c697cfdd66be7bf22f"></p>
<p>对于预测问题，可以根据预测输出的类型是连续的实数值，还是离散的标签，区分为回归任务和分类任务。因为房价是一个连续值，所以房价预测显然是一个回归任务。本次实验要求大家调用sklearn
的线性回归、岭回归模型来实现。</p>
<h3 id="实现过程">实现过程：</h3>
<ol type="1">
<li>数据准备：导入数据、特征可视化</li>
<li>数据预处理：数据集划分、数据标准化处理</li>
<li>模型训练：线性回归、岭回归</li>
<li>模型评估与选择、参数选择</li>
</ol>
<h2 id="数据准备">数据准备</h2>
<h3 id="导入数据">导入数据</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line"><span class="built_in">print</span>(boston.DESCR)</span><br></pre></td></tr></table></figure>
<h3 id="数据可视化">数据可视化</h3>
<p>通过观察不同属性与房价之间的关系，分析影响房价的主要因素。</p>
<p>boston.data 存储的是所有样本的属性值，boston.target
存储的是所有样本的房价。下段程序所展示的13幅图中，横坐标是该属性的取值，纵坐标是房价值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入matplotlib库中的pyplot模块，用于绘制图表</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表的大小，figsize指定了图表的宽度和高度，单位是英寸</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历波士顿数据集的13个特征</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>):</span><br><span class="line">    <span class="comment"># 创建一个2行7列的子图，并在当前子图中绘制散点图</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">7</span>, i + <span class="number">1</span>)  <span class="comment"># 2行7列的第i+1个子图</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 绘制散点图：x轴是第i个特征，y轴是目标值（房价中位数），s指定点的大小</span></span><br><span class="line">    plt.scatter(boston.data[:, i], boston.target, s=<span class="number">20</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置当前子图的标题，显示当前特征的名称</span></span><br><span class="line">    plt.title(boston.feature_names[i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存当前图表为PNG格式的图片，文件名为img.png</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;img.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示绘制的所有子图</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%EF%BC%88%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0%EF%BC%89/img.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="数据预处理">数据预处理</h2>
<h3 id="任务1数据集划分">任务1：数据集划分</h3>
<p>调用sklearn.model_selection中的train_test_split()函数，把boston数据集分为训练集和测试集，划分比例是4:1。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 加载波士顿房价数据集</span></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据集划分为训练集和测试集，test_size=0.2 表示测试集占20%，即训练集占80%</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<h3 id="结果">结果：</h3>
<ul>
<li><strong><code>X_train</code></strong>：训练集的特征数据，形状为
<code>(404, 13)</code>，即 80% 的数据（506 * 0.8 = 404
个样本），每个样本有 13 个特征。</li>
<li><strong><code>X_test</code></strong>：测试集的特征数据，形状为
<code>(102, 13)</code>，即 20% 的数据（506 * 0.2 = 102 个样本）。</li>
<li><strong><code>y_train</code></strong>：训练集的目标值，形状为
<code>(404,)</code>，即对应训练集的 404 个房价中位数。</li>
<li><strong><code>y_test</code></strong>：测试集的目标值，形状为
<code>(102,)</code>，即对应测试集的 102 个房价中位数。</li>
</ul>
<h3 id="总结">总结：</h3>
<ul>
<li><code>train_test_split()</code>
将数据集（包括特征和目标值）按照指定的比例随机划分为训练集和测试集。划分后的数据将用于模型的训练和评估，确保模型评估时使用的数据不会在训练过程中被“看见”。</li>
<li><code>test_size=0.2</code> 表示将 20% 的数据作为测试集，80%
的数据作为训练集。</li>
<li><code>random_state=42</code>
确保每次划分数据集时能得到一致的结果，保证实验的可复现性。</li>
</ul>
<h3 id="任务2数据标准化处理">任务2：数据标准化处理：</h3>
<h4 id="z-score标准化">1. Z-score标准化</h4>
<p>首先使用StandardScaler()函数初始化对属性值的标准化器，然后调用fit_transform()方法对训练数据进行Z-score标准化，再将这个标准化器调用transform()方法用于测试数据的标准化。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment"># 初始化对属性值的标准化器</span></span><br><span class="line">ss_X = StandardScaler()</span><br><span class="line"><span class="comment"># ss_X调用fit_transform()和transform()方法对训练数据和测试数据进行标准化</span></span><br><span class="line"><span class="comment"># 对训练数据进行标准化，fit_transform() 方法会计算训练数据的均值和标准差，并应用到训练数据</span></span><br><span class="line"><span class="comment"># 训练数据X_train会被标准化为均值0，标准差1</span></span><br><span class="line">X_train = ss_X.fit_transform(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对测试数据进行标准化，使用transform()方法来使用训练数据的均值和标准差来标准化测试数据</span></span><br><span class="line"><span class="comment"># 注意：测试数据不能再用fit_transform()，否则会使用测试数据的统计量，导致数据泄露</span></span><br><span class="line">X_test = ss_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p><strong>Z-score
标准化</strong>的过程是将数据转换为均值为0，标准差为1的分布。<code>StandardScaler()</code>
是 <code>scikit-learn</code>
提供的标准化工具，它通过去掉均值并除以标准差来实现这一标准化。</p>
<h4 id="代码解释">代码解释：</h4>
<p><strong>对训练数据进行标准化</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train = ss_X.fit_transform(X_train)</span><br></pre></td></tr></table></figure> -
<code>fit()</code>：计算训练数据的均值和标准差。 -
<code>transform()</code>：使用训练数据的均值和标准差将数据标准化。 -
<code>fit_transform()</code>：这两个操作结合在一起，计算并转换训练数据，使其均值为0，标准差为1。</p>
<p><strong>对测试数据进行标准化</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_test = ss_X.transform(X_test)</span><br></pre></td></tr></table></figure> -
对测试数据应用 <code>transform()</code>
方法时，不会重新计算均值和标准差，而是使用在训练数据上计算得到的均值和标准差对测试数据进行转换。
-
这确保了测试数据的标准化是基于训练数据的统计信息，而不是测试数据本身的统计信息。</p>
<h4 id="minmax标准化">2. MinMax标准化</h4>
<p>首先使用StandardScaler()函数初始化对属性值的标准化器，然后调用fit_transform()方法对训练数据进行Z-score标准化，再将这个标准化器调用transform()方法用于测试数据的标准化。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="comment"># 初始化对属性值的标准化器</span></span><br><span class="line">mm_X = MinMaxScaler()</span><br><span class="line"><span class="comment"># mm_X调用fit_transform()和transform()方法对训练数据和测试数据进行MinMax标准化</span></span><br><span class="line">X_train1 = mm_X.fit_transform(X_train)</span><br><span class="line">X_test1 = mm_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p>在 <strong>MinMax 标准化</strong>（也称为
<strong>归一化</strong>）中，数据将被缩放到指定的最小值和最大值之间，通常是将数据缩放到
<code>[0, 1]</code>
范围内。这对于那些对特征的绝对范围敏感的算法非常有效。</p>
<p><code>MinMaxScaler</code> 是 <code>scikit-learn</code>
提供的一个标准化工具，它会将每个特征缩放到一个指定的范围内，默认情况下是
<code>[0, 1]</code>。</p>
<h3 id="代码解释-1">代码解释：</h3>
<p><strong>对训练数据进行 MinMax 标准化</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train1 = mm_X.fit_transform(X_train)</span><br></pre></td></tr></table></figure> -
<code>fit_transform()</code>
方法会计算训练数据的最小值和最大值，并将数据缩放到 <code>[0, 1]</code>
范围内。 -
<strong><code>fit()</code></strong>：计算训练数据的最小值和最大值。 -
<strong><code>transform()</code></strong>：根据计算出的最小值和最大值，进行数据的转换。
- <code>fit_transform()</code>
是这两个操作的组合，直接返回标准化后的训练数据。</p>
<p><strong>对测试数据进行 MinMax 标准化</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_test1 = mm_X.transform(X_test)</span><br></pre></td></tr></table></figure> -
<code>transform()</code>
方法会使用训练数据上的最小值和最大值来转换测试数据。 -
<strong>注意</strong>：<code>transform()</code>
仅仅使用训练数据的统计量（即最小值和最大值）来对测试数据进行标准化，避免了数据泄露问题。如果对测试数据使用
<code>fit_transform()</code>，就会导致模型从测试数据中学习统计量，破坏了训练和测试数据的独立性。</p>
<p><strong>MinMax
标准化</strong>是一种常用的数据预处理方法，尤其适用于特征的取值范围差异较大时。它将每个特征的最小值映射到
0，最大值映射到
1，其他值则在该区间内按比例进行缩放。这样做的好处是避免了某些特征因数值范围较大而在训练模型时占据主导地位，尤其是对于需要计算距离或内积的模型，如
KNN、SVM 等，使用 MinMax 标准化后的数据会使模型训练更加稳定。</p>
<h2 id="模型训练与评估">模型训练与评估</h2>
<h3 id="任务3.1线性回归模型训练">任务3.1：线性回归模型训练</h3>
<p>调用sklearn.linear_model中的LinearRegression()函数，对训练集(X_train,y_train)进行模型训练，并预测测试集X_test的房价lr_y_predict。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="comment"># 初始化线性回归模型</span></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment"># 线性回归模型训练</span></span><br><span class="line">lr.fit(X_train, y_train)  <span class="comment"># 使用训练集数据训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">lr_y_predict = lr.predict(X_test)  <span class="comment"># 使用训练好的模型对测试集数据进行预测</span></span><br></pre></td></tr></table></figure>
<h3 id="代码解释-2">代码解释：</h3>
<p><strong>训练模型</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr.fit(X_train, y_train)</span><br></pre></td></tr></table></figure> - <code>fit()</code>
方法会使用训练集数据 <code>(X_train, y_train)</code>
来训练线性回归模型。训练过程就是计算线性回归模型的系数（权重）和截距，以使预测值最接近真实目标值。</p>
<p><strong>预测房价</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr_y_predict = lr.predict(X_test)</span><br></pre></td></tr></table></figure> - <code>predict()</code>
方法会使用已经训练好的模型来对测试集 <code>X_test</code>
进行预测，返回预测的房价（即预测值
<code>lr_y_predict</code>）。模型根据训练时学到的关系来预测测试集中的每个样本的房价。</p>
<h3 id="任务3.2线性回归模型评估">任务3.2：线性回归模型评估</h3>
<p>回归模型常用的三种评价指标：（1）R方分数（决定系数）、（2）MSE均方误差、以及（3）MAE平均绝对误差。</p>
<p>方法一：调用sklearn.metrics中的相关函数，计算测试结果lr_y_predict与真实结果y_test之间的误差或精度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score,mean_squared_error,mean_absolute_error</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;the value of R-squared of LR is&#x27;</span>,r2_score(y_test,lr_y_predict))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;the MSE of LR is&#x27;</span>,mean_squared_error(y_test,lr_y_predict))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;the MAE of LR is&#x27;</span>,mean_absolute_error(y_test,lr_y_predict))</span><br></pre></td></tr></table></figure>
<pre><code>the value of R-squared of LR is 0.7250808093832966
the MSE of LR is 23.56944609104811
the MAE of LR is 3.302381007591344</code></pre>
<p>方法二：自己编写函数，计算上述指标。本实验要求学生至少完成MSE均方误差的计算，并打印输出结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 计算R²（决定系数）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_r2</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># R² = 1 - (SS_res / SS_tot)</span></span><br><span class="line">    ss_res = ((y_true - y_pred) ** <span class="number">2</span>).<span class="built_in">sum</span>()  <span class="comment"># 残差平方和</span></span><br><span class="line">    ss_tot = ((y_true - y_true.mean()) ** <span class="number">2</span>).<span class="built_in">sum</span>()  <span class="comment"># 总平方和</span></span><br><span class="line">    r2_score = <span class="number">1</span> - (ss_res / ss_tot)  <span class="comment"># 决定系数</span></span><br><span class="line">    <span class="keyword">return</span> r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算MSE（均方误差）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_mse</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    mse = mean_squared_error(y_true, y_pred)</span><br><span class="line">    <span class="keyword">return</span> mse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算MAE（平均绝对误差）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_mae</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    mae = mean_absolute_error(y_true, y_pred)</span><br><span class="line">    <span class="keyword">return</span> mae</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">r2 = calculate_r2(y_test, lr_y_predict)  <span class="comment"># R²</span></span><br><span class="line">mse = calculate_mse(y_test, lr_y_predict)  <span class="comment"># MSE</span></span><br><span class="line">mae = calculate_mae(y_test, lr_y_predict)  <span class="comment"># MAE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;R² (决定系数): <span class="subst">&#123;r2&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;MSE (均方误差): <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;MAE (平均绝对误差): <span class="subst">&#123;mae&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>R² (决定系数): 0.7250808093832966
MSE (均方误差): 23.56944609104811
MAE (平均绝对误差): 3.302381007591344</code></pre>
<p>下面是
<strong>R²（决定系数）</strong>、<strong>MSE（均方误差）</strong> 和
<strong>MAE（平均绝对误差）</strong> 的计算公式：</p>
<h3 id="r²决定系数-计算公式">1. <strong>R²（决定系数）</strong>
计算公式：</h3>
<p>R² 衡量模型对目标变量变化的解释程度。它的取值范围为 0 到 1，越接近
1，表示模型越能解释数据的变异性。</p>
<p>公式: <span class="math display">$$
R^2=1-\frac{\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2}
$$</span></p>
<ul>
<li>( $y_i $)：实际值（真实的目标值）。</li>
<li>( <span class="math inline"><em>ŷ</em><sub><em>i</em></sub></span>
)：预测值（模型预测的目标值）。</li>
<li>( <span class="math inline"><em>ȳ</em></span> )：实际值的均值（
<span class="math inline">$\bar{y} = \frac{1}{n} \sum_{i=1}^{n}
y_i$</span> ）。</li>
<li>( <span class="math inline"><em>n</em></span> )：样本数。</li>
</ul>
<h4 id="解释">解释：</h4>
<ul>
<li>分子部分是
<strong>残差平方和（RSS）</strong>，衡量预测值与真实值之间的差异。</li>
<li>分母部分是
<strong>总平方和（TSS）</strong>，衡量真实值与均值之间的差异。</li>
<li>R² 越接近 1，表示模型的拟合度越好。</li>
</ul>
<h3 id="mse均方误差-计算公式">2. <strong>MSE（均方误差）</strong>
计算公式：</h3>
<p>MSE
衡量预测值与真实值之间差异的平方和的平均值，是一种常用的回归模型评估指标。</p>
<p>公式： <span class="math display">$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$</span></p>
<ul>
<li>( <span class="math inline"><em>y</em><sub><em>i</em></sub></span>
)：实际值。</li>
<li>( <span class="math inline"><em>ŷ</em><sub><em>i</em></sub></span>)：预测值。</li>
<li>( <span class="math inline"><em>n</em></span> )：样本数。</li>
</ul>
<h4 id="解释-1">解释：</h4>
<ul>
<li>MSE
是实际值与预测值之间差异的平方和的平均值，越小表示模型的预测误差越小。</li>
</ul>
<h3 id="mae平均绝对误差-计算公式">3.
<strong>MAE（平均绝对误差）</strong> 计算公式：</h3>
<p>MAE
衡量预测值与真实值之间差异的绝对值的平均值，也是一种常用的回归模型评估指标。</p>
<p>公式： <span class="math display">$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$</span></p>
<ul>
<li>( <span class="math inline"><em>y</em><sub><em>i</em></sub></span>
)：实际值。</li>
<li>( <span class="math inline"><em>ŷ</em><sub><em>i</em></sub></span>
)：预测值。</li>
<li>( <span class="math inline"><em>n</em></span> )：样本数。</li>
</ul>
<h4 id="解释-2">解释：</h4>
<ul>
<li>MAE
是实际值与预测值之间差异的绝对值的平均值，越小表示模型的预测性能越好。</li>
</ul>
<h3 id="总结-1">总结：</h3>
<ul>
<li><strong>R²（决定系数）</strong>：度量模型拟合优度，越接近 1
表示模型越好。</li>
<li><strong>MSE（均方误差）</strong>：越小，表示模型的预测误差越小。</li>
<li><strong>MAE（平均绝对误差）</strong>：越小，表示模型在预测时的绝对误差越小。</li>
</ul>
<h3 id="任务3.3岭回归模型训练">任务3.3：岭回归模型训练</h3>
<p>调用sklearn.linear_model中的Ridge()函数(参数设置为5)，对训练集(X_train,y_train)进行模型训练，并预测测试集X_test的房价rd_y_predict。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">rd = Ridge(alpha=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#岭回归模型训练</span></span><br><span class="line">rd.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 输出训练后的模型系数（回归系数）</span></span><br><span class="line"><span class="built_in">print</span>(rd.coef_)</span><br><span class="line"><span class="comment">#模型测试</span></span><br><span class="line">rd_y_predict = rd.predict(X_test)</span><br></pre></td></tr></table></figure>
<pre><code>[-0.89921997  1.17687007  0.06847273  0.58380163 -2.09273127  2.39227753
  0.15081088 -3.06269707  2.53630955 -1.8549535  -2.24256957  0.89722135
 -3.79040179]</code></pre>
<h3 id="岭回归ridge-regression">岭回归（Ridge Regression）</h3>
<p><strong>岭回归</strong>（Ridge Regression），又称 <strong>L2
正则化回归</strong>，是一种扩展了普通最小二乘回归（OLS）的回归模型。其核心思想是在最小化
<strong>残差平方和</strong>（即普通最小二乘回归的目标函数）的同时，加入一个
<strong>正则化项</strong>，用于惩罚模型的复杂性，避免过拟合。</p>
<h3 id="岭回归的公式">岭回归的公式</h3>
<p>岭回归的目标函数为： <span class="math display">$$
\text{minimize} \quad \left( \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 + \alpha
\sum_{j=1}^{p} \beta_j^2 \right)
$$</span> 其中：</p>
<ul>
<li>( <span class="math inline"><em>y</em><sub><em>i</em></sub></span>
)：实际观测值。</li>
<li>( <span class="math inline"><em>ŷ</em><sub><em>i</em></sub></span>
)：模型预测值。</li>
<li>( <span class="math inline"><em>β</em><sub><em>j</em></sub></span>
)：模型的回归系数。</li>
<li>( <span class="math inline"><em>α</em></span>
)：正则化强度（超参数），控制正则化项的权重。</li>
</ul>
<h3 id="关键点">关键点：</h3>
<ol type="1">
<li><strong>残差平方和</strong>：普通最小二乘回归的目标函数是最小化预测值和真实值之间的差异平方和：<span class="math inline">$\sum_{i=1}^{n} (y_i - \hat{y}_i)^2$</span></li>
<li><strong>L2
正则化</strong>：岭回归在最小化残差平方和的同时，加上一个正则化项$ _{j=1}^{p}
_j^2
$，用来限制回归系数的大小。这个正则化项惩罚过大的系数，使得系数趋向于
0，但不会完全为 0（与 Lasso 回归不同，Lasso 是 L1
正则化，会使部分系数变为 0）。
<ul>
<li>$$：是岭回归的正则化参数，控制惩罚项的强度。较大的 ( )
值会增加正则化的惩罚，使模型的系数变得较小，从而减少过拟合。</li>
</ul></li>
</ol>
<h3 id="岭回归的作用">岭回归的作用</h3>
<ul>
<li><strong>防止过拟合</strong>：在普通的最小二乘回归中，若特征非常多，模型可能会在训练数据上表现得非常好，但却在测试数据上表现得较差（过拟合）。通过在回归系数上施加惩罚，岭回归减少了模型的复杂度，从而帮助防止过拟合。</li>
<li><strong>适应多重共线性</strong>：当特征之间存在强烈的相关性时（即多重共线性），普通的最小二乘回归可能无法得出稳定的回归系数。岭回归通过正则化项使得模型更稳定，避免共线性问题带来的不稳定性。</li>
</ul>
<h3 id="岭回归与普通最小二乘回归的区别">岭回归与普通最小二乘回归的区别</h3>
<ul>
<li><strong>普通最小二乘回归</strong>：最小化残差平方和，没有对回归系数施加任何惩罚。因此，模型会根据训练数据的噪声来拟合训练数据，可能导致过拟合。</li>
<li><strong>岭回归</strong>：最小化残差平方和，并加上正则化项，控制回归系数的大小，防止模型复杂度过高，减少过拟合。</li>
</ul>
<h3 id="岭回归的超参数-alpha">岭回归的超参数 ( <span class="math inline"><em>α</em></span> )</h3>
<ul>
<li><strong>( <span class="math inline"><em>α</em></span>
)</strong>：是岭回归中的超参数，控制正则化项的强度。
<ul>
<li>当 ( = 0 ) 时，岭回归退化为普通的最小二乘回归。</li>
<li>当 ( )
较大时，模型的回归系数被更多地惩罚，减少了过拟合的风险，但也可能导致欠拟合（即模型对数据的拟合能力不足）。</li>
</ul></li>
</ul>
<h3 id="任务3.4岭回归模型评估">任务3.4：岭回归模型评估</h3>
<p>与线性回归一样，岭回归模型有两种方法计算评价指标，这里调用sklearn.metrics来实现。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score,mean_squared_error,mean_absolute_error</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;the value of R-squared of Ridge is&#x27;</span>,r2_score(y_test,rd_y_predict ))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;the MSE of Ridge is&#x27;</span>,mean_squared_error(y_test,rd_y_predict))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;the MAE of Ridge is&#x27;</span>,mean_absolute_error(y_test,rd_y_predict))</span><br></pre></td></tr></table></figure>
<pre><code>the value of R-squared of Ridge is 0.7279447933421523
the MSE of Ridge is 23.323910246960786
the MAE of Ridge is 3.2535718613670053</code></pre>
<h2 id="参数选择">参数选择</h2>
<h3 id="任务4运用交叉验证选择模型参数">任务4：运用交叉验证选择模型参数</h3>
<p>岭回归模型参数是正则化参数alpha，前面把它设置为5。为了选择最优参数，对训练集进行10次10折交叉验证。具体地，参数选择在[0,10]范围内，以1为步长，进行选择。
1.
总共进行11次实验（不同alpha值），每次实验将训练数据随机分成10份，重复10次；
2. 每一次划分，任意9份做训练，剩余1份测试，共执行10次，测试结果取平均；
3. 再将所有划分的结果再取平均，作为这一次alpha取值的分数； 4.
比较不同alpha取值的交叉验证模型分数，来选择其中表现最好的（分数最高的）模型的alpha值；
5. 用上述选择的alpha值对训练数据重新训练模型，再测试评估。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv_score_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>):</span><br><span class="line">    <span class="comment"># alpha 取不同值</span></span><br><span class="line">    rd = Ridge(alpha=i)</span><br><span class="line">    avg_score_cross = []</span><br><span class="line">    <span class="comment"># 进行10次随机划分</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        <span class="comment">#调用KFold()实现10折划分</span></span><br><span class="line">        kf = KFold(n_splits=<span class="number">10</span>, shuffle=<span class="literal">True</span>, random_state=j)</span><br><span class="line">        <span class="comment">#调用cross_val_score()计算训练集本次10折划分的分数</span></span><br><span class="line">        score_cross = cross_val_score(rd, X_train, y_train, cv=kf, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>)</span><br><span class="line">        avg_score_cross.append(np.mean(score_cross))</span><br><span class="line">    cv_score_list.append(np.mean(avg_score_cross))</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">11</span>), cv_score_list)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># cv_score_list中找到分数最大的模型所对应的alpha取值</span></span><br><span class="line">index = np.argmax(cv_score_list)</span><br><span class="line">rd = Ridge(alpha=index)</span><br><span class="line"><span class="comment">#岭回归模型训练</span></span><br><span class="line">rd.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#模型测试</span></span><br><span class="line">rd_y_predict = rd.predict(X_test)</span><br><span class="line"><span class="comment"># 打印模型评估结果</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, mean_absolute_error</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Best Alpha: <span class="subst">&#123;index&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Squared Error: <span class="subst">&#123;mean_squared_error(y_test, rd_y_predict)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Absolute Error: <span class="subst">&#123;mean_absolute_error(y_test, rd_y_predict)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Best Alpha: 4
Mean Squared Error: 23.35986469628359
Mean Absolute Error: 3.260923268350155</code></pre>
<h2 id="二分类问题">二分类问题</h2>
<h3 id="任务5波士顿房价二分类问题">任务5：波士顿房价二分类问题</h3>
<p>为了了解分类问题的建模与评估，本任务将连续值的波士顿房价数值使用阈值进行二值化（0,1，例如：廉价房、品质房），可以将房价预测的回归问题，改为简单的二分类问题。</p>
<p>同样是包括四个步骤：数据准备、数据预处理、模型训练、模型评估与选择。</p>
<p>下面的程序使用方法一调用sklearn.metrics中的相应函数计算预测结果的准确率accuracy、f1
score、auc值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, f1_score, roc_auc_score</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"><span class="comment"># 房价数值二值化</span></span><br><span class="line">threshold = np.mean(boston.target)</span><br><span class="line">labels = (boston.target&gt;threshold).astype(np.int_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集划分</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(boston.data, labels, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment"># 省略数据预处理步骤</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment"># 模型训练：我们使用 LogisticRegression（线性回归常用于回归问题，但 Logistic Regression 更适合于二分类问题）</span></span><br><span class="line">lr = LogisticRegression(max_iter=<span class="number">10000</span>)  <span class="comment"># 设置最大迭代次数为10000以确保收敛</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测：对测试集进行预测</span></span><br><span class="line">lr_y_predict = lr.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The accuracy score of LR is&#x27;</span>, accuracy_score(y_test, lr_y_predict))  <span class="comment"># 准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The f1 score of LR is&#x27;</span>, f1_score(y_test, lr_y_predict))  <span class="comment"># F1 分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The auc of LR is&#x27;</span>, roc_auc_score(y_test, lr_y_predict))  <span class="comment"># AUC（曲线下面积）</span></span><br></pre></td></tr></table></figure>
<pre><code>The accuracy score of LR is 0.9117647058823529
The f1 score of LR is 0.8695652173913043
The auc of LR is 0.89002079002079


f:\project python\.conda\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.

    The Boston housing prices dataset has an ethical problem. You can refer to
    the documentation of this function for further details.

    The scikit-learn maintainers therefore strongly discourage the use of this
    dataset unless the purpose of the code is to study and educate about
    ethical issues in data science and machine learning.

    In this special case, you can fetch the dataset from the original
    source::

        import pandas as pd
        import numpy as np

        data_url = &quot;http://lib.stat.cmu.edu/datasets/boston&quot;
        raw_df = pd.read_csv(data_url, sep=&quot;\s+&quot;, skiprows=22, header=None)
        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
        target = raw_df.values[1::2, 2]

    Alternative datasets include the California housing dataset (i.e.
    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing
    dataset. You can load the datasets as follows::

        from sklearn.datasets import fetch_california_housing
        housing = fetch_california_housing()

    for the California housing dataset and::

        from sklearn.datasets import fetch_openml
        housing = fetch_openml(name=&quot;house_prices&quot;, as_frame=True)

    for the Ames housing dataset.
  warnings.warn(msg, category=FutureWarning)</code></pre>
<p>方法二：自己编写函数，计算上述指标。</p>
<p>本实验要求学生至少完成accuracy与f1 score的计算，并打印输出结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="comment"># 计算准确率（Accuracy）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_accuracy</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    correct = np.<span class="built_in">sum</span>(y_true == y_pred)  <span class="comment"># 计算正确预测的数量</span></span><br><span class="line">    total = <span class="built_in">len</span>(y_true)  <span class="comment"># 总样本数</span></span><br><span class="line">    accuracy = correct / total  <span class="comment"># 准确率</span></span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算F1分数（F1 Score）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_f1_score</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    cm = confusion_matrix(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 提取混淆矩阵中的 TP, FP, FN</span></span><br><span class="line">    tp = cm[<span class="number">1</span>, <span class="number">1</span>]  <span class="comment"># True Positives</span></span><br><span class="line">    fp = cm[<span class="number">0</span>, <span class="number">1</span>]  <span class="comment"># False Positives</span></span><br><span class="line">    fn = cm[<span class="number">1</span>, <span class="number">0</span>]  <span class="comment"># False Negatives</span></span><br><span class="line">    precision = tp / (tp + fp) <span class="keyword">if</span> (tp + fp) != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    recall = tp / (tp + fn) <span class="keyword">if</span> (tp + fn) != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="comment"># 计算 F1 分数</span></span><br><span class="line">    f1 = <span class="number">2</span> * (precision * recall) / (precision + recall) <span class="keyword">if</span> (precision + recall) != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> f1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">accuracy = calculate_accuracy(y_test, lr_y_predict)</span><br><span class="line">f1_score = calculate_f1_score(y_test, lr_y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;F1 Score: <span class="subst">&#123;f1_score&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy: 0.9117647058823529
F1 Score: 0.8695652173913043</code></pre>
<h3 id="准确率-accuracy">1. <strong>准确率 (Accuracy)</strong>：</h3>
<p>准确率是正确分类的样本数与总样本数之比。</p>
<p>公式： <span class="math display">$$
\text{Accuracy} = \frac{\text{正确预测的数量}}{\text{总样本数}}
$$</span></p>
<h3 id="f1-分数-f1-score">2. <strong>F1 分数 (F1 Score)</strong>：</h3>
<p>F1 分数是准确率 (Precision) 和召回率 (Recall) 的调和平均数。</p>
<p>公式： <span class="math display">$$
F1 = 2 \times \frac{\text{Precision} \times
\text{Recall}}{\text{Precision} + \text{Recall}}
$$</span> 其中： <span class="math display">$$
\text{Precision} = \frac{\text{True Positive}}{\text{True Positive} +
\text{False Positive}}
$$</span></p>
<p><span class="math display">$$
\text{Recall} = \frac{\text{True Positive}}{\text{True Positive} +
\text{False Negative}}
$$</span></p>
<h3 id="auc-area-under-the-curve">3. <strong>AUC (Area Under the
Curve)</strong>：</h3>
<p>AUC 是 ROC 曲线下面积，用于衡量分类模型的性能，范围在 0 到 1
之间，越接近 1，模型表现越好。AUC
是一个广泛使用的评估二分类问题模型的性能的指标。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——第二次上机——数据预处理基础</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="机器学习数据预处理基础">机器学习数据预处理基础</h1>
<h1 id="one-hot编码">1. One-Hot编码</h1>
<h2 id="任务介绍">任务介绍</h2>
<ul>
<li>使用Pandas中的value_counts()函数，查看data中的特征User
continent的取值类型， 并打印输出的内容；</li>
<li>使用pandas中的get_dummies()函数对data中的特征User
continent进行One-Hot编码，参数prefix为User continent_；</li>
<li>将编码后的结果保存在encode_uc中，并输出变量的前5行内容。</li>
</ul>
<h2 id="预期实验结果">预期实验结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/bac5b83fc21a435fabddd64a5ab463600c7d80dc00e44fd6ae1715ae25355db6">
<img src="https://ai-studio-static-online.cdn.bcebos.com/2f183364e29348079537f8ad38d9489004d4498e9b5d483fa9432f2bae06654e"></p>
<blockquote>
<p>补全代码;</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># value_counts() 函数统计并输出 &quot;User continent&quot; 列中各大陆出现的次数</span></span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;User continent&#x27;</span>].value_counts())</span><br><span class="line"><span class="comment"># 使用 get_dummies() 对 &quot;User continent&quot; 列进行 One-Hot 编码</span></span><br><span class="line"><span class="comment"># One-hot编码是一种将类别变量转换为多个二进制特征列的技术，</span></span><br><span class="line"><span class="comment"># 每个类别对应一列，如果该行数据属于该类别则取值为1，否则为0</span></span><br><span class="line">encode_uc = pd.get_dummies(data[<span class="string">&#x27;User continent&#x27;</span>], prefix=<span class="string">&#x27;User continent_&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(encode_uc)</span><br></pre></td></tr></table></figure>
<p>​ User continent ​ North America 296 ​ Europe 118 ​ Oceania 41 ​ Asia 36 ​
Africa 7 ​ South America 6 ​ Name: count, dtype: int64 ​ User
continent__Africa User continent__Asia User continent__Europe<br>
​0 False False False<br>
​1 False False False<br>
​2 False False False<br>
​3 False False True<br>
​4 False False False<br>
​.. … … …<br>
​499 False False True<br>
​500 False False False<br>
​501 False False False<br>
​502 False False False<br>
​503 False False False<br>
​<br>
​User continent__North America User continent__Oceania<br>
​0 True False<br>
​1 True False<br>
​2 True False<br>
​3 False False<br>
​4 True False<br>
​.. … …<br>
​499 False False<br>
​500 True False<br>
​501 True False<br>
​502 True False<br>
​503 True False<br>
​<br>
​User continent__South America<br>
​0 False<br>
​1 False<br>
​2 False<br>
​3 False<br>
​4 False<br>
​.. …<br>
​499 False<br>
​500 False<br>
​501 False<br>
​502 False<br>
​503 False<br>
​<br>
​[504 rows x 6 columns] ​</p>
<h1 id="缺失值填补">2. 缺失值填补</h1>
<h2 id="任务介绍-1">任务介绍</h2>
<ul>
<li>使用pandas中的value_counts()函数打印输出data中的特征Traveler
type的取值统计信息， 并查看其是否含有缺失值；</li>
<li>如果存在缺失值，将特征Traveler
type在其他样本中取值频数最多的值保存在变量freq_v中，并使用freq_v进行缺失值填充；</li>
<li>再次打印输出特征Traveler type的取值统计信息。</li>
</ul>
<h2 id="预期实验结果-1">预期实验结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/573d921570d34dc08c44f863ee8732f8d5816c88af7b467aa8cae7a2ce188129"></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># value_counts(dropna=False) 会包括缺失值（NaN）在内</span></span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;Traveler type&#x27;</span>].value_counts(dropna=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># idxmax()会获取频数最多的取值</span></span><br><span class="line">freq_v = data[<span class="string">&#x27;Traveler type&#x27;</span>].value_counts().idxmax()</span><br><span class="line"></span><br><span class="line"><span class="comment"># freq_v会替代缺失值</span></span><br><span class="line">data[<span class="string">&#x27;Traveler type&#x27;</span>] = data[<span class="string">&#x27;Traveler type&#x27;</span>].fillna(freq_v)</span><br><span class="line"></span><br><span class="line"><span class="comment">### 打印</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&#x27;缺失值填充完之后：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;Traveler type&#x27;</span>].value_counts(dropna=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure>
<h1 id="特征标准化">3. 特征标准化</h1>
<h2 id="任务1">任务1:</h2>
<ul>
<li>使用sklearn中preprocessing模块下的StandardScaler()函数对data的特征Score进行Z-score标准化；</li>
<li>将特征取值的均值保存在变量score_mean中，并打印；</li>
<li>将特征取值的方差保存在变量score_var中，并打印。</li>
</ul>
<h2 id="预期实验结果-2">预期实验结果</h2>
<figure>
<img src="/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/fa64d89b-3dc9-4b07-b27f-210b56e583ed-1741258230441-1.png" alt="fa64d89b-3dc9-4b07-b27f-210b56e583ed">
<figcaption aria-hidden="true">fa64d89b-3dc9-4b07-b27f-210b56e583ed</figcaption>
</figure>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="comment"># sklearn是一个用于机器学习的Python库，提供了各种分类、回归、聚类算法，</span></span><br><span class="line"><span class="comment"># 包括支持向量机、随机森林、梯度提升等。它还包含了用于数据预处理、特征提取和模型选择的工具。</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment">## 创建Z-score对象</span></span><br><span class="line"><span class="comment">## Z-score标准化是一种将数据转换为均值为0，标准差为1的标准正态分布的方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 初始化StandardScaler对象，用于执行Z-score标准化</span></span><br><span class="line">std_scaler = StandardScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment">## Score特征标准化，使用fit_transform()方法</span></span><br><span class="line"><span class="comment"># fit_transform() 会先计算出该特征的均值和标准差，然后进行标准化</span></span><br><span class="line">normal_df = std_scaler.fit_transform(data[[<span class="string">&#x27;Score&#x27;</span>]])  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 均值</span></span><br><span class="line"><span class="comment"># StandardScaler 会自动计算并存储 &#x27;Score&#x27; 列的均值，这个值在标准化过程中用来进行数据转换</span></span><br><span class="line">score_mean = std_scaler.mean_</span><br><span class="line"></span><br><span class="line"><span class="comment">## 方差</span></span><br><span class="line"><span class="comment"># 方差也是 StandardScaler 会计算的一个参数，表示数据的离散程度</span></span><br><span class="line">score_var = std_scaler.var_</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印</span></span><br><span class="line"><span class="built_in">print</span> (score_mean)</span><br><span class="line"><span class="built_in">print</span> (score_var)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印前五行内容</span></span><br><span class="line">normal_df[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p>​ [4.12301587] ​ [1.01264487] ​</p>
<p>​ array([[ 0.87149149], ​ [-1.11598231], ​ [ 0.87149149], ​
[-0.12224541], ​ [-0.12224541]])</p>
<h2 id="任务2">任务2：</h2>
<ul>
<li>自定义函数min_max()实现MinMax标准化，输入参数data为要进行标准化的数据，输出为标准化后的数据。</li>
<li>使自定义的min_max()函数对data的特征Score进行MinMax标准化，输出结果保存在score_transformed中，并打印变量的前5行内容</li>
</ul>
<h2 id="预期结果">预期结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/98a830f8c5594920883029b03ae2882f516aef4a6af244ff93061ef21aa09836"></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">min_max</span>(<span class="params">data</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 最小值</span></span><br><span class="line">    data_min = data.<span class="built_in">min</span>()</span><br><span class="line">    <span class="comment">## 最大值</span></span><br><span class="line">    data_max = data.<span class="built_in">max</span>()</span><br><span class="line">    <span class="comment">## 最大值与最小值之间的差值</span></span><br><span class="line">    data_range=data_max-data_min</span><br><span class="line">    <span class="comment">## 根据MinMax标准化的定义实现</span></span><br><span class="line">    <span class="comment">#MinMax 标准化（最小-最大标准化）是一种数据预处理方法，</span></span><br><span class="line">    <span class="comment"># 旨在将数据的所有特征（列）缩放到一个指定的范围，通常是 [0, 1]。</span></span><br><span class="line">    <span class="comment"># 这种标准化方法将原始数据通过线性变换映射到新的范围。</span></span><br><span class="line">    new_data = (data-data_min)/data_range<span class="comment"># MinMax标准化公式： (x - min) / (max - min)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 返回结果</span></span><br><span class="line">    <span class="keyword">return</span> new_data</span><br><span class="line"></span><br><span class="line"><span class="comment">## 调用min_max()函数</span></span><br><span class="line">score_transformed = min_max(data[<span class="string">&#x27;Score&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印变量的前5行内容</span></span><br><span class="line">score_transformed.head()</span><br></pre></td></tr></table></figure>
<p>​ 0 1.00 ​ 1 0.50 ​ 2 1.00 ​ 3 0.75 ​ 4 0.75 ​ Name: Score, dtype:
float64</p>
<h2 id="任务3">任务3：</h2>
<ul>
<li>自定义logistic()函数，输入参数为要进行标准化的数据，输出结果为经过标准化后的数据；</li>
<li>使用自定义函数对data的特征Member
years进行Logsitic标准化，结果保存在member_transformed中，并输出变量的前5行内容。</li>
</ul>
<h2 id="预期结果-1">预期结果：</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/22fd81b1a5614b418f88cbe90bf7f99ba6c553820c2542be80f1a90421779026"></p>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ogistic 标准化（Logistic Normalization）是一个将数据转换为 (0, 1) 范围的过程，</span></span><br><span class="line"><span class="comment"># 通常使用 Logistic 函数（也称为 Sigmoid 函数）。</span></span><br><span class="line"><span class="comment"># 它是一种非线性转换方法，常用于神经网络和其他需要将数据映射到概率范围的场景。</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">logistic</span>(<span class="params">data</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    <span class="keyword">import</span> warnings</span><br><span class="line">    warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 计算 1 + e^(-x)</span></span><br><span class="line">    denominator = <span class="number">1</span>+ np.exp(-data)<span class="comment"># 使用 np.exp() 计算 e^(-x)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 实现logistic标准化</span></span><br><span class="line">    new_data = <span class="number">1</span>/denominator</span><br><span class="line">    <span class="comment">## 返回结果</span></span><br><span class="line">    <span class="keyword">return</span> new_data</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对特征Member years进行logsitic标准化</span></span><br><span class="line">member_transformed = logistic(data[<span class="string">&#x27;Member years&#x27;</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印内容</span></span><br><span class="line">member_transformed.head()</span><br></pre></td></tr></table></figure>
<p>​ 0 0.999877 ​ 1 0.952574 ​ 2 0.880797 ​ 3 0.997527 ​ 4 0.999089 ​ Name:
Member years, dtype: float64</p>
<h1 id="特征离散化">4. 特征离散化</h1>
<h2 id="任务介绍-2">任务介绍</h2>
<ul>
<li>使用Pandas的qcut()函数对data中的特征Member
years进行等频离散化，结果保存在bins中；</li>
<li>使用pd.value_counts()函数统计categorical对象bins的取值信息。</li>
</ul>
<h2 id="预期结果-2">预期结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/a4729a315ee6483687f3a819d01d905b025fa5f90da04f3e893a7a80ce5e5107"></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 返回bins</span></span><br><span class="line"><span class="comment"># q=4 表示将数据分成 4 个区间</span></span><br><span class="line">bins = pd.qcut(data[<span class="string">&#x27;Member years&#x27;</span>], q=<span class="number">4</span>, labels=[<span class="string">&quot;(-1806.001, 2.0]&quot;</span>, <span class="string">&quot;(2.0, 4.0]&quot;</span>, <span class="string">&quot;(4.0, 6.0]&quot;</span>, <span class="string">&quot;(6.0, 13.0]&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 统计取值信息</span></span><br><span class="line"><span class="comment"># 使用value_counts()函数统计bins中每个类别的数量，得到离散化后的各个类别的分布情况</span></span><br><span class="line">value_counts = pd.value_counts(bins)  </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(value_counts)</span><br></pre></td></tr></table></figure>
<p>​ Member years ​ (-1806.001, 2.0] 156 ​ (6.0, 13.0] 124 ​ (2.0, 4.0] 123 ​
(4.0, 6.0] 101 ​ Name: count, dtype: int64 ​</p>
<h1 id="离群值检测">5. 离群值检测</h1>
<h2 id="任务介绍-3">任务介绍</h2>
<ul>
<li>使用拉依达准则对data的特征Member years进行离群值检测；</li>
<li>如果存在离群值，输出离群值的个数outlier_num，并将包含离群值的数据记录保存在变量outeliers中，并打印变量内容。</li>
</ul>
<h2 id="预期结果-3">预期结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/40e316267fc542339a74291e8438e340109ece96fc2a439591b75414e12085d2"></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取csv文件到DataFrame</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取&#x27;Member years&#x27;这一列</span></span><br><span class="line">member_data = data[[<span class="string">&#x27;Member years&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">拉伊达准则</span></span><br><span class="line"><span class="string">计算四分位数（Q1 和 Q3）：计算Member years特征的第25百分位数（Q1）和第75百分位数（Q3）。</span></span><br><span class="line"><span class="string">计算IQR（Interquartile Range）：IQR = Q3 - Q1。</span></span><br><span class="line"><span class="string">判断离群值：低于 Q1 - 1.5 * IQR 或高于 Q3 + 1.5 * IQR 的数据点视为离群值。</span></span><br><span class="line"><span class="string">统计离群值的个数，并提取包含离群值的记录。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算四分位数</span></span><br><span class="line">Q1 = member_data[<span class="string">&#x27;Member years&#x27;</span>].quantile(<span class="number">0.25</span>)  <span class="comment"># 第25百分位数</span></span><br><span class="line">Q3 = member_data[<span class="string">&#x27;Member years&#x27;</span>].quantile(<span class="number">0.75</span>)  <span class="comment"># 第75百分位数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算IQR（四分位间距）</span></span><br><span class="line">IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写出过滤条件：低于 Q1 - 1.5 * IQR 或 高于 Q3 + 1.5 * IQR 的值为离群值</span></span><br><span class="line">outlier_judge = (member_data[<span class="string">&#x27;Member years&#x27;</span>] &lt; (Q1 - <span class="number">1.5</span> * IQR)) | (member_data[<span class="string">&#x27;Member years&#x27;</span>] &gt; (Q3 + <span class="number">1.5</span> * IQR))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计离群值的个数</span></span><br><span class="line">outlier_num = outlier_judge.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取包含离群值的样本记录</span></span><br><span class="line">outliers = data[outlier_judge]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印离群值记录</span></span><br><span class="line"><span class="built_in">print</span>(outliers)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​ User country User continent Member years Traveler type<br>
​75 USA North America -1806 Solo<br>
​143 USA North America 13 Couples<br>
​<br>
​Hotel name Hotel stars Nr. rooms Score<br>
​75 Treasure Island- TI Hotel &amp; Casino 4.0 2884 5<br>
​143 Caesars Palace 5.0 3348 4<br>
​</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机4——决策树</title>
    <url>/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h1 id="上机实验决策树">上机实验：决策树</h1>
<h2 id="任务1分支节点的选择方法">任务1：分支节点的选择方法</h2>
<p>现有一个数据集
weekend.txt，目标是根据一个人的特征来预测其周末是否出行。</p>
<p>所有特征均为二元特征，取值为 0 或
1，其中“status”（目标特征也是类别）表示用户的周末是否出行，1 表示出行，0
表示不出行，“marriageStatus”表示申请人是否已婚、“hasChild”表示申请人是否有小孩、“hasAppointment”表示申请人是否有约、“weather”表示天气是否晴朗。</p>
<p>已知信息熵和信息增益的公式为：</p>
<p><span class="math display">$$\text{Entropy}(D)=-\sum_{k=1}^{C}p_k
\cdot log_2(p_k)$$</span></p>
<p><span class="math display">$$\text{InfoGain}(D,
a)=\text{Entropy}(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|}
\cdot\text{Entropy}(D^v)$$</span></p>
<p>请完成以下三个内容：</p>
<ul>
<li><p>请自定义函数 cal_entropy(data,
feature_name)计算数据集data关于feature_name的信息熵。输入参数 data 为
DataFrame，feature_name 为目标特征(或类别)的名称；</p></li>
<li><p>请调用 cal_entropy() 函数计算决策树分支之前的信息熵，保存为
data_entropy；</p></li>
<li><p>请自定义函数 cal_infoGain(data, base_entropy) 计算 weekend.txt
中各个特征的信息增益，保存为列表 infogains，并选择信息增益最大的分支节点
best_feature。</p></li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入必要库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据（假设文件为tab分隔，包含特征和目标变量&#x27;status&#x27;）</span></span><br><span class="line">weekend_data = pd.read_table(<span class="string">&#x27;weekend.txt&#x27;</span>, sep=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义熵计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数（如：status特征中&quot;出门&quot;和&quot;不出门&quot;的数量）</span></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（注意：熵公式为负数求和）</span></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算初始信息熵（假设目标特征列为&#x27;status&#x27;）</span></span><br><span class="line">data_entropy = cal_entropy(weekend_data, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义信息增益计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 获取所有特征名称</span></span><br><span class="line">    feature_list.remove(<span class="string">&#x27;status&#x27;</span>)  <span class="comment"># 移除目标特征（避免计算自身）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布（如：天气特征的&quot;晴朗/下雨/阴天&quot;）</span></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历特征的每个取值</span></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line">            <span class="comment"># 获取特征取当前值的子集</span></span><br><span class="line">            subset = data[data[feature] == value]</span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算子集的熵并累加加权熵</span></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算信息增益（信息增益 = 基础熵 - 条件熵）</span></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到信息增益最大的特征</span></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大增益值</span></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 对应的最优特征名称</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"><span class="comment">## 执行信息增益计算</span></span><br><span class="line">infogains, best_feature = cal_infoGain(weekend_data, data_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 结果输出</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;各特征的信息增益：&#x27;</span>, infogains)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n信息增益最大的特征：&#x27;</span>, best_feature)</span><br></pre></td></tr></table></figure>
<pre><code>各特征的信息增益： [0.0076, 0.0076, 0.0322, 0.0868]</code></pre>
<p>​</p>
<pre><code>信息增益最大的特征： weather</code></pre>
<blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc"></p>
<h2 id="任务2常见的决策树算法">任务2：常见的决策树算法</h2>
<p>现在有一份有关商品销量的数据集product.csv，数据集的离散型特征信息如下：</p>
<table>
<thead>
<tr>
<th>特征名称</th>
<th>取值说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>天气</td>
<td>1：天气好；0：天气坏</td>
</tr>
<tr>
<td>是否周末</td>
<td>1：是；0：不是</td>
</tr>
<tr>
<td>是否有促销</td>
<td>1：有促销；0：没有促销</td>
</tr>
<tr>
<td>销量</td>
<td>1：销量高；0：销量低</td>
</tr>
</tbody>
</table>
<p>请完成以下三个内容： - 请根据提供的商品销量数据集 data，使用 sklearn
中的
DecisionTreeClassifier()函数构建决策树模型，模型选择分支结点的特征以Gini指数为判定准则；
- 训练模型，并对测试集test_X进行预测，将预测结果存为
pred_y，进行模型评估； - 将构建的决策树模型进行可视化。</p>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz  <span class="comment"># 补全export_graphviz导入</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;product.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取除目标特征以外的其他特征的数据记录X</span></span><br><span class="line">X = data[[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>]]  <span class="comment"># 使用双括号选择多列</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取目标特征`销量`的数据记录y</span></span><br><span class="line">y = data[<span class="string">&quot;销量&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用train_test_split函数划分训练集train_X, train_y和测试集test_X, test_y</span></span><br><span class="line"><span class="comment">## 测试集所占比例为0.1,random_state为0</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 构建分支节点选择方法为基尼指数的决策树模型tree_model，进行模型训练、测试与性能评估</span></span><br><span class="line">tree_model = DecisionTreeClassifier(criterion=<span class="string">&#x27;gini&#x27;</span>)  <span class="comment"># 设置基尼指数准则</span></span><br><span class="line">tree_model.fit(train_X, train_y)  <span class="comment"># 模型训练</span></span><br><span class="line"></span><br><span class="line">pred_y = tree_model.predict(test_X)  <span class="comment"># 测试集预测</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型分类报告：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y))  <span class="comment"># 输出评估报告</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 决策树可视化（修正特征名称与数据列一致）</span></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line">dot_data = export_graphviz(</span><br><span class="line">    tree_model,</span><br><span class="line">    out_file=<span class="literal">None</span>,</span><br><span class="line">    feature_names=[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>],  <span class="comment"># 修正为完整特征名称</span></span><br><span class="line">    class_names=[<span class="string">&quot;销量低&quot;</span>, <span class="string">&quot;销量高&quot;</span>],</span><br><span class="line">    filled=<span class="literal">True</span>,</span><br><span class="line">    rounded=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph</span><br></pre></td></tr></table></figure>
<pre><code>模型分类报告：

              precision    recall  f1-score   support</code></pre>
<p>​</p>
<pre><code>           0       1.00      0.50      0.67         2

           1       0.67      1.00      0.80         2</code></pre>
<p>​</p>
<pre><code>    accuracy                           0.75         4

   macro avg       0.83      0.75      0.73         4

weighted avg       0.83      0.75      0.73         4</code></pre>
<p>​</p>
<p>​<br>
<img src="/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/main_7_1.svg" alt="svg"> ​</p>
<blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/f7c9f4d97660416b9ac354a1bcd6c87efcb7a0958cfa4579bf70a83d01ee64f7">
<img src="https://ai-studio-static-online.cdn.bcebos.com/eb46fe19bf43414290f904042a511f25140e1908a2eb4c2e81c52450f1de68bd"></p>
<h2 id="任务3利用任务1的cal_infogain函数自行实现id3决策树算法">任务3：利用任务1的cal_infoGain函数自行实现ID3决策树算法</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的熵计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line"></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数分布</span></span><br><span class="line"></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line"></span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（Σ -p_i log2(p_i)）</span></span><br><span class="line"></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的信息增益计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line"></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line"></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 所有特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自动识别目标特征（假设目标特征不在特征列表中）</span></span><br><span class="line"></span><br><span class="line">    target_feature = [col <span class="keyword">for</span> col <span class="keyword">in</span> feature_list <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> data.columns][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    feature_list = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]  <span class="comment"># 移除目标特征</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line"></span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布</span></span><br><span class="line"></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line"></span><br><span class="line">            subset = data[data[feature] == value]  <span class="comment"># 特征取当前值的子集</span></span><br><span class="line"></span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line"></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 累加加权熵</span></span><br><span class="line"></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, target_feature)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算信息增益</span></span><br><span class="line"></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line"></span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 选择最优特征</span></span><br><span class="line"></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大信息增益值</span></span><br><span class="line"></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line"></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 最优特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## ID3决策树实现</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ID3DecisionTree</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="literal">None</span>  <span class="comment"># 存储决策树结构</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = <span class="literal">None</span>  <span class="comment"># 目标特征名称</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, data, target_feature</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        训练决策树模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 包含特征和目标列的DataFrame</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param target_feature: 目标特征名称（如&#x27;销量&#x27;）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = target_feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取特征列表（排除目标特征）</span></span><br><span class="line"></span><br><span class="line">        features = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建决策树</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="variable language_">self</span>._build_tree(data, features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_tree</span>(<span class="params">self, data, features</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 当前节点的数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param features: 当前可用的特征列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 字典形式的树节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件1：所有样本属于同一类别</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(data[<span class="variable language_">self</span>.target].unique()) == <span class="number">1</span>:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: data[<span class="variable language_">self</span>.target].values[<span class="number">0</span>],  <span class="comment"># 叶节点类别</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件2：无剩余特征可用时选择多数类</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> features:</span><br><span class="line"></span><br><span class="line">            class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),  <span class="comment"># 多数类</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算当前数据集的熵</span></span><br><span class="line"></span><br><span class="line">        base_entropy = cal_entropy(data, <span class="variable language_">self</span>.target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取最优特征和信息增益列表</span></span><br><span class="line"></span><br><span class="line">        info_gains, best_feature = cal_infoGain(data, base_entropy)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建当前树节点</span></span><br><span class="line"></span><br><span class="line">        node = &#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;feature&#x27;</span>: best_feature,  <span class="comment"># 分裂特征</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;info_gain&#x27;</span>: info_gains[features.index(best_feature)],  <span class="comment"># 信息增益值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data),  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;children&#x27;</span>: &#123;&#125;  <span class="comment"># 子节点</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建子树（排除当前最优特征）</span></span><br><span class="line"></span><br><span class="line">        remaining_features = [f <span class="keyword">for</span> f <span class="keyword">in</span> features <span class="keyword">if</span> f != best_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历最优特征的所有取值</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> data[best_feature].unique():</span><br><span class="line"></span><br><span class="line">            subset = data[data[best_feature] == value]  <span class="comment"># 获取子集</span></span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 处理空子集（采用父节点多数类）</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> subset.empty:</span><br><span class="line"></span><br><span class="line">                class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;samples&#x27;</span>: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 递归构建子树</span></span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = <span class="variable language_">self</span>._build_tree(subset, remaining_features)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        对新样本进行预测</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param X: 特征数据（DataFrame格式）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 预测结果列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        predictions = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历每个样本</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _, sample <span class="keyword">in</span> X.iterrows():</span><br><span class="line"></span><br><span class="line">            current_node = <span class="variable language_">self</span>.tree</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 遍历树直到叶节点</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                feature = current_node[<span class="string">&#x27;feature&#x27;</span>]  <span class="comment"># 当前分裂特征</span></span><br><span class="line"></span><br><span class="line">                value = sample[feature]  <span class="comment"># 样本在该特征的取值</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 处理未见过的特征值（采用当前节点多数类）</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> value <span class="keyword">not</span> <span class="keyword">in</span> current_node[<span class="string">&#x27;children&#x27;</span>]:</span><br><span class="line"></span><br><span class="line">                    class_counts = <span class="variable language_">self</span>._get_class_counts(current_node)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 选择样本数最多的类别</span></span><br><span class="line"></span><br><span class="line">                    predictions.append(<span class="built_in">max</span>(class_counts, key=class_counts.get))</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">break</span>  <span class="comment"># 跳出循环</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 移动到子节点</span></span><br><span class="line"></span><br><span class="line">                current_node = current_node[<span class="string">&#x27;children&#x27;</span>][value]</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 记录叶节点类别</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                predictions.append(current_node[<span class="string">&#x27;class&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_class_counts</span>(<span class="params">self, node</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归统计节点中的类别分布</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 类别计数字典</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        counts = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果是叶节点直接返回</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;node[<span class="string">&#x27;class&#x27;</span>]: node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归统计子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].values():</span><br><span class="line"></span><br><span class="line">            child_counts = <span class="variable language_">self</span>._get_class_counts(child)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> cls, cnt <span class="keyword">in</span> child_counts.items():</span><br><span class="line"></span><br><span class="line">                counts[cls] = counts.get(cls, <span class="number">0</span>) + cnt</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> counts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">visualize</span>(<span class="params">self, feature_names, class_names</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        可视化决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: graphviz对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        dot = graphviz.Digraph()  <span class="comment"># 创建有向图</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建图形</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._build_graph(dot, <span class="variable language_">self</span>.tree, feature_names, class_names)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_graph</span>(<span class="params">self, dot, node, feature_names, class_names, parent=<span class="literal">None</span>, edge_label=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建graphviz图形</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param dot: graphviz.Digraph对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param parent: 父节点（用于连接边）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param edge_label: 边标签（特征取值）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 叶节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;class_names[<span class="built_in">int</span>(node[<span class="string">&#x27;class&#x27;</span>])]&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),  <span class="comment"># 唯一节点ID</span></span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;box&quot;</span>,  <span class="comment"># 矩形框</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,  <span class="comment"># 填充颜色</span></span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightblue&quot;</span>  <span class="comment"># 浅蓝色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 内部节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;node[<span class="string">&#x27;feature&#x27;</span>]&#125;</span>\\nIG=<span class="subst">&#123;node[<span class="string">&#x27;info_gain&#x27;</span>]:<span class="number">.3</span>f&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;ellipse&quot;</span>,  <span class="comment"># 椭圆</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,</span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightgreen&quot;</span>  <span class="comment"># 浅绿色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建父节点到当前节点的边</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> parent:</span><br><span class="line"></span><br><span class="line">            dot.edge(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(parent)),</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label=edge_label  <span class="comment"># 显示特征取值</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归处理子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> value, child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].items():</span><br><span class="line"></span><br><span class="line">                <span class="variable language_">self</span>._build_graph(</span><br><span class="line"></span><br><span class="line">                    dot,</span><br><span class="line"></span><br><span class="line">                    child,</span><br><span class="line"></span><br><span class="line">                    feature_names,</span><br><span class="line"></span><br><span class="line">                    class_names,</span><br><span class="line"></span><br><span class="line">                    node,  <span class="comment"># 当前节点作为父节点</span></span><br><span class="line"></span><br><span class="line">                    <span class="built_in">str</span>(value)  <span class="comment"># 边标签为特征取值</span></span><br><span class="line"></span><br><span class="line">                )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机实验11--核化分类器判定西瓜好坏</title>
    <url>/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/</url>
    <content><![CDATA[<h1 id="上机实验11核化分类器判定西瓜好坏">上机实验11：核化分类器判定西瓜好坏</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&quot;work/西瓜数据集3.0α.txt&quot;</span>)</span><br><span class="line">data</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">yes = data[data[<span class="string">&#x27;Good melon&#x27;</span>].isin([<span class="string">&#x27;是&#x27;</span>])]</span><br><span class="line">no = data[data[<span class="string">&#x27;Good melon&#x27;</span>].isin([<span class="string">&#x27;否&#x27;</span>])]</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax.scatter(yes[<span class="string">&#x27;Density&#x27;</span>], yes[<span class="string">&#x27;Sugar content&#x27;</span>], marker=<span class="string">&#x27;o&#x27;</span>, c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Yes&#x27;</span>)</span><br><span class="line">ax.scatter(no[<span class="string">&#x27;Density&#x27;</span>], no[<span class="string">&#x27;Sugar content&#x27;</span>], marker=<span class="string">&#x27;x&#x27;</span>, c=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;No&#x27;</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Sugar content&#x27;</span>)</span><br><span class="line">plt.show() <span class="comment"># 可以发现线性不可分</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_3_0.png" alt="output_3_0">
<figcaption aria-hidden="true">output_3_0</figcaption>
</figure>
<h2 id="任务1svm分类器判定西瓜好坏">任务1：SVM分类器判定西瓜好坏</h2>
<p>在SVM分类器中，使用线性核与高斯核进行比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用线性核与高斯核进行比较</span></span><br><span class="line">linear_svc = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>)  <span class="comment"># 线性核</span></span><br><span class="line">rbf_svc = svm.SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>)        <span class="comment"># 高斯核（RBF）</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp = &#123;<span class="string">&#x27;是&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;否&#x27;</span>: -<span class="number">1</span>&#125;</span><br><span class="line">X = np.array(data.iloc[:, :<span class="number">2</span>])</span><br><span class="line">y = np.array(data.iloc[:, <span class="number">2</span>].replace(temp))[<span class="literal">None</span>].T</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">linear_svc.fit(X, y)</span><br><span class="line">linear_svc.score(X,y)</span><br><span class="line"><span class="comment"># 查看支持向量</span></span><br><span class="line">linear_svc.support_vectors_</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)





array([[0.666, 0.091],
       [0.243, 0.267],
       [0.343, 0.099],
       [0.639, 0.161],
       [0.657, 0.198],
       [0.36 , 0.37 ],
       [0.593, 0.042],
       [0.719, 0.103],
       [0.697, 0.46 ],
       [0.774, 0.376],
       [0.634, 0.264],
       [0.608, 0.318],
       [0.556, 0.215],
       [0.403, 0.237],
       [0.481, 0.149],
       [0.437, 0.211]])</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rbf_svc.fit(X, y)</span><br><span class="line">rbf_svc.score(X,y)</span><br><span class="line"><span class="comment"># 查看支持向量</span></span><br><span class="line">rbf_svc.support_vectors_</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

array([[0.666, 0.091],
       [0.243, 0.267],
       [0.245, 0.057],
       [0.343, 0.099],
       [0.639, 0.161],
       [0.657, 0.198],
       [0.36 , 0.37 ],
       [0.593, 0.042],
       [0.719, 0.103],
       [0.697, 0.46 ],
       [0.774, 0.376],
       [0.634, 0.264],
       [0.608, 0.318],
       [0.556, 0.215],
       [0.403, 0.237],
       [0.481, 0.149],
       [0.437, 0.211]])</code></pre>
<h2 id="任务2kernel-logistic-regression-判定西瓜好坏">任务2：Kernel
Logistic Regression 判定西瓜好坏</h2>
<p>将原始的Logistic Regression 进行核化，使用不同的核函数进行比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.colors <span class="keyword">as</span> colors</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>:</span><br><span class="line">    kern_param = <span class="number">0</span></span><br><span class="line">    X = np.array([])</span><br><span class="line">    a = np.array([])</span><br><span class="line">    kernel = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel=<span class="string">&#x27;poly&#x27;</span>, kern_param=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> kernel == <span class="string">&#x27;poly&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__linear__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> kernel == <span class="string">&#x27;gaussian&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__gaussian__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">0.1</span></span><br><span class="line">        <span class="keyword">elif</span> kernel == <span class="string">&#x27;laplace&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__laplace__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y, max_rate=<span class="number">100</span>, min_rate=<span class="number">0.001</span>, gd_step=<span class="number">10</span>, epsilon=<span class="number">0.0001</span></span>):</span><br><span class="line">        m = <span class="built_in">len</span>(X)</span><br><span class="line">        <span class="variable language_">self</span>.X = np.vstack([X.T, np.ones(m)]).T</span><br><span class="line">        <span class="comment"># Construct kernel matrix</span></span><br><span class="line">        K =<span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X, <span class="variable language_">self</span>.X, <span class="variable language_">self</span>.kern_param)  <span class="comment"># 填空1：计算核矩阵</span></span><br><span class="line">        <span class="comment"># Gradient descent</span></span><br><span class="line">        <span class="variable language_">self</span>.a = np.zeros([m])</span><br><span class="line">        prev_cost = <span class="number">0</span></span><br><span class="line">        next_cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">        <span class="keyword">while</span> np.fabs(prev_cost-next_cost) &gt; epsilon:</span><br><span class="line">            neg_grad = -<span class="variable language_">self</span>.__gradient__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">            best_rate = rate = max_rate</span><br><span class="line">            min_cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">            <span class="keyword">while</span> rate &gt;= min_rate:</span><br><span class="line">                cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a+neg_grad*rate)</span><br><span class="line">                <span class="keyword">if</span> cost &lt; min_cost:</span><br><span class="line">                    min_cost = cost</span><br><span class="line">                    best_rate = rate</span><br><span class="line">                rate /= gd_step</span><br><span class="line">            <span class="variable language_">self</span>.a += neg_grad * best_rate</span><br><span class="line">            prev_cost = next_cost</span><br><span class="line">            next_cost = min_cost</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 1. 添加偏置项（与训练数据处理一致）</span></span><br><span class="line">        X = np.vstack([X.T, np.ones(<span class="built_in">len</span>(X))]).T  <span class="comment"># 形状变为 (n_samples, n_features + 1)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 计算核矩阵（训练数据与测试数据之间的核函数值）</span></span><br><span class="line">        K = <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X, X, <span class="variable language_">self</span>.kern_param)  <span class="comment"># 形状：(训练样本数, 测试样本数)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 计算预测得分（关键修正：移除 self.Y 的乘法）</span></span><br><span class="line">        pred = np.dot(<span class="variable language_">self</span>.a, K) </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. Sigmoid转换为概率并二值化</span></span><br><span class="line">        prob = <span class="variable language_">self</span>.__sigmoid__(pred)</span><br><span class="line">        <span class="keyword">return</span> (prob &gt;= <span class="number">0.5</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Kernels</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__linear__</span>(<span class="params">a, b, parameter</span>):</span><br><span class="line">        <span class="keyword">return</span> np.dot(a, np.transpose(b))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__gaussian__</span>(<span class="params">a, b, kern_param</span>):</span><br><span class="line">        mat = np.zeros([<span class="built_in">len</span>(a), <span class="built_in">len</span>(b)])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(b)):</span><br><span class="line">                mat[i][j] = np.exp(-np.<span class="built_in">sum</span>(np.square(np.subtract(a[i], b[j]))) / (<span class="number">2</span> * kern_param * kern_param))</span><br><span class="line">        <span class="keyword">return</span> mat</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__laplace__</span>(<span class="params">a, b, kern_param</span>):</span><br><span class="line">        mat = np.zeros([<span class="built_in">len</span>(a), <span class="built_in">len</span>(b)])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(b)):</span><br><span class="line">                mat[i][j] = np.exp(-np.linalg.norm(np.subtract(a[i], b[j])) / kern_param)</span><br><span class="line">        <span class="keyword">return</span> mat</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__sigmoid__</span>(<span class="params">X</span>):</span><br><span class="line">        <span class="keyword">return</span> np.exp(X) / (<span class="number">1</span> + np.exp(X))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__cost__</span>(<span class="params">K, y, a</span>):</span><br><span class="line">        <span class="keyword">return</span> -np.dot(y, np.dot(a, K)) + np.<span class="built_in">sum</span>(np.log(<span class="number">1</span> + np.exp(np.dot(a, K))))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__gradient__</span>(<span class="params">cls, K, y, a</span>):</span><br><span class="line">        <span class="keyword">return</span> -np.dot(K, y - cls.__sigmoid__(np.dot(a, K)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read data</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;work/西瓜数据集3.0α.txt&quot;</span>)</span><br><span class="line">X = np.array(data[[<span class="string">&#x27;Density&#x27;</span>, <span class="string">&#x27;Sugar content&#x27;</span>]])</span><br><span class="line">y = np.array(data[<span class="string">&#x27;Good melon&#x27;</span>]) == <span class="string">&#x27;是&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Kernels</span></span><br><span class="line">kernels = [<span class="string">&#x27;poly&#x27;</span>, <span class="string">&#x27;gaussian&#x27;</span>, <span class="string">&#x27;laplace&#x27;</span>]</span><br><span class="line">titles = [<span class="string">&#x27;linear kernel&#x27;</span>, <span class="string">&#x27;gaussian kernel, σ=0.1&#x27;</span>, <span class="string">&#x27;laplace kernel, σ=0.1&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(kernels)):</span><br><span class="line">    <span class="comment"># Training</span></span><br><span class="line">    <span class="comment"># 填空3：实例化并训练模型</span></span><br><span class="line">    model = LogisticRegression(kernel=kernels[i])</span><br><span class="line">    model.fit(X, y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Plot</span></span><br><span class="line">    cmap = colors.LinearSegmentedColormap.from_list(<span class="string">&#x27;watermelon&#x27;</span>, [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>])</span><br><span class="line">    xx, yy = np.meshgrid(np.arange(<span class="number">0.2</span>, <span class="number">0.8</span>, <span class="number">0.01</span>), np.arange(<span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">0.01</span>))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    plt.contourf(xx, yy, Z, cmap=cmap, alpha=<span class="number">0.3</span>, antialiased=<span class="literal">True</span>)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sugar content&#x27;</span>)</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:97: RuntimeWarning: overflow encountered in exp</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_1.png" alt="output_10_1">
<figcaption aria-hidden="true">output_10_1</figcaption>
</figure>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_2.png" alt="output_10_2">
<figcaption aria-hidden="true">output_10_2</figcaption>
</figure>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_3.png" alt="output_10_3">
<figcaption aria-hidden="true">output_10_3</figcaption>
</figure>
<h3 id="线性核linear-kernel"><strong>1. 线性核（Linear
Kernel）</strong></h3>
<ul>
<li><strong>数学形式</strong>：<br>
[ K(x_i, x_j) = x_i^T x_j + c (c ) ]</li>
<li><strong>特点</strong>：
<ul>
<li>直接计算特征向量的内积，不进行非线性映射。<br>
</li>
<li>决策边界为线性超平面，计算效率高。<br>
</li>
</ul></li>
<li><strong>适用场景</strong>：
<ul>
<li>数据线性可分（如两类可通过一条直线/平面分开）。<br>
</li>
<li>特征维度较高时（避免核方法的计算开销）。<br>
</li>
</ul></li>
<li><strong>西瓜数据集表现</strong>：
<ul>
<li>生成直线决策边界，可能误分类非线性分布的样本。</li>
</ul></li>
</ul>
<hr>
<h3 id="高斯核gaussianrbf-kernel"><strong>2. 高斯核（Gaussian/RBF
Kernel）</strong></h3>
<ul>
<li><strong>数学形式</strong>：<br>
[ K(x_i, x_j) = (-|x_i - x_j|^2) (&gt; 0) ]</li>
<li><strong>特点</strong>：
<ul>
<li>基于样本间的欧氏距离（L2距离），隐式映射到无限维空间。<br>
</li>
<li>参数 <code>γ</code> 控制影响范围：<code>γ</code>
越大，局部性越强（对邻近点更敏感）。<br>
</li>
</ul></li>
<li><strong>适用场景</strong>：
<ul>
<li>数据非线性可分（如环形分布、复杂流形）。<br>
</li>
<li>特征维度较低或中等时效果最佳。<br>
</li>
</ul></li>
<li><strong>西瓜数据集表现</strong>：
<ul>
<li>生成平滑的非线性边界，能捕捉密度与含糖量的复杂交互关系。</li>
</ul></li>
</ul>
<hr>
<h3 id="拉普拉斯核laplace-kernel"><strong>3. 拉普拉斯核（Laplace
Kernel）</strong></h3>
<ul>
<li><strong>数学形式</strong>：<br>
[ K(x_i, x_j) = (-|x_i - x_j|_1) (&gt; 0) ]</li>
<li><strong>特点</strong>：
<ul>
<li>基于曼哈顿距离（L1距离），对异常值鲁棒性更强。<br>
</li>
<li>隐式映射到无限维空间，但形状更尖锐（适合非光滑边界）。<br>
</li>
</ul></li>
<li><strong>适用场景</strong>：
<ul>
<li>数据分布不规则或存在离群点。<br>
</li>
<li>特征具有稀疏性（如文本分类）。<br>
</li>
</ul></li>
<li><strong>西瓜数据集表现</strong>：
<ul>
<li>生成尖锐的非线性边界，可能更好地处理边缘样本。</li>
</ul></li>
</ul>
<p>以下是欧氏距离（Euclidean Distance）与曼哈顿距离（Manhattan
Distance）的详细对比：</p>
<hr>
<h3 id="数学定义"><strong>1. 数学定义</strong></h3>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 62%">
<col style="width: 26%">
</colgroup>
<thead>
<tr>
<th>距离类型</th>
<th>公式</th>
<th>几何意义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>欧氏距离</strong></td>
<td>( |x - y|_2 = )</td>
<td>两点之间的<strong>直线距离</strong></td>
</tr>
<tr>
<td><strong>曼哈顿距离</strong></td>
<td>( |x - y|<em>1 = </em>{i=1}^n</td>
<td>x_i - y_i</td>
</tr>
</tbody>
</table>
<h3 id="选择建议"><strong>5. 选择建议</strong></h3>
<ul>
<li><strong>优先欧氏距离</strong>：<br>
数据分布连续、特征维度较低、需要捕捉局部相似性时（如图像分类）。</li>
<li><strong>优先曼哈顿距离</strong>：<br>
数据稀疏（如文本）、存在噪声或异常值、特征维度较高时（如推荐系统）。</li>
</ul>
<hr>
<h3 id="示例对比"><strong>示例对比</strong></h3>
<p>假设两点 ( A(1, 1) ) 和 ( B(4, 5) )：</p>
<ul>
<li><strong>欧氏距离</strong>：<br>
[ = 5 ]</li>
<li><strong>曼哈顿距离</strong>：<br>
[ |4-1| + |5-1| = 3 + 4 = 7 ]</li>
</ul>
<hr>
<h3 id="总结"><strong>总结</strong></h3>
<ul>
<li><strong>欧氏距离</strong>：强调“直线最短”，适合低维连续数据。<br>
</li>
<li><strong>曼哈顿距离</strong>：强调“网格路径”，适合高维稀疏数据。<br>
</li>
<li><strong>在核函数中的体现</strong>：
<ul>
<li>高斯核通过欧氏距离捕捉平滑边界，拉普拉斯核通过曼哈顿距离增强鲁棒性。</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>redis</title>
    <url>/2025/10/23/%E5%AD%A6%E4%B9%A0/python-web/redis/redis/</url>
    <content><![CDATA[<h3 id="redis是什么">redis是什么</h3>
<p><a href="https://www.bilibili.com/video/BV1a1sgzfE5d?buvid=XX7932A7E9DD8A1DA92D4974AB535749A9B44&amp;from_spmid=tm.recommend.0.0&amp;is_story_h5=false&amp;mid=25yhOI1fPeVYa5V16BFcAw%3D%3D&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=6682182e-4a29-4dca-9b0f-7f42b6722151&amp;share_source=QQ&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1760971136&amp;unique_k=Zo1vE8S&amp;up_id=12890453&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">开发神器
Redis 自学指南，10分钟速通！_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>python-web</category>
        <category>milvus</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机实验10--支持向量机</title>
    <url>/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C10--%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<h1 id="上机实验10支持向量机">上机实验10–支持向量机</h1>
<h2 id="任务1sklearn中的svc与惩罚系数c">任务1：sklearn中的SVC与惩罚系数C</h2>
<ul>
<li>提供一份糖尿病患者数据集diabetes.csv，该数据集有768个数据样本，9个特征(最后一列为目标特征数据)，并且已经存入变量data。特征的具体信息如下：</li>
</ul>
<table>
<thead>
<tr>
<th>特征名称</th>
<th>特征含义</th>
<th>取值举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>feature1</td>
<td>怀孕次数</td>
<td>6</td>
</tr>
<tr>
<td>feature2</td>
<td>2小时口服葡萄糖耐受实验中的血浆葡萄浓度</td>
<td>148</td>
</tr>
<tr>
<td>feature3</td>
<td>舒张压 (mm Hg)</td>
<td>72</td>
</tr>
<tr>
<td>feature4</td>
<td>三头肌皮褶厚度(mm)</td>
<td>35</td>
</tr>
<tr>
<td>feature5</td>
<td>2小时血清胰岛素浓度 (mu U/ml)</td>
<td>0</td>
</tr>
<tr>
<td>feature6</td>
<td>体重指数(weight in kg/(height in m)^2)</td>
<td>33.6</td>
</tr>
<tr>
<td>feature7</td>
<td>糖尿病谱系功能(Diabetes pedigree function)</td>
<td>0.627</td>
</tr>
<tr>
<td>feature8</td>
<td>年龄</td>
<td>50</td>
</tr>
<tr>
<td>class</td>
<td>是否患有糖尿病</td>
<td>1：阳性；0：阴性</td>
</tr>
</tbody>
</table>
<p>主要任务如下： - 请先将数据使用sklearn中的StandardScaler进行标准化；
-
然后使用sklearn中的svm.SVC支持向量分类器，构建支持向量机模型（所有参数使用默认参数），对测试集进行预测，将预测结果存为pred_y，并对模型进行评价；
-
最后新建一个svm.SVC实例clf_new，并设置惩罚系数C=0.3，并利用该支持向量分类器对测试集进行预测，将预测结果存为pred_y_new，并比较两个模型的预测效果。</p>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># 将目标特征与其他特征分离</span></span><br><span class="line">X = data.drop(<span class="string">&#x27;class&#x27;</span>, axis=<span class="number">1</span>)  </span><br><span class="line">y = data[<span class="string">&#x27;class&#x27;</span>]  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集train_X, train_y和测试集train_X, train_y</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = <span class="number">.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集标准化，返回结果为scaled_train_X</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaled_train_X = scaler.fit_transform(train_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建支持向量机模型</span></span><br><span class="line">clf = SVC()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">clf.fit(scaled_train_X, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集标准化</span></span><br><span class="line">scaled_test_X = scaler.transform(test_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型返回预测值</span></span><br><span class="line">pred_y = clf.predict(scaled_test_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印支持向量的个数，返回结果为列表，[-1标签的支持向量，+1标签的支持向量]</span></span><br><span class="line"><span class="built_in">print</span>(clf.n_support_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用classification_report函数进行模型评价</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建惩罚系数C为0.3的模型，并与之前的模型做比较</span></span><br><span class="line">clf_new = SVC(C=<span class="number">0.3</span>)</span><br><span class="line">clf_new.fit(scaled_train_X, train_y)</span><br><span class="line">pred_y_new = clf_new.predict(scaled_test_X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(clf_new.n_support_)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y_new))</span><br><span class="line"></span><br><span class="line"><span class="comment">#调整惩罚系数C寻优</span></span><br></pre></td></tr></table></figure>
<pre><code>[187 180]

              precision    recall  f1-score   support</code></pre>
<p>​</p>
<pre><code>           0       0.82      0.90      0.86       107

           1       0.70      0.55      0.62        47</code></pre>
<p>​</p>
<pre><code>    accuracy                           0.79       154

   macro avg       0.76      0.73      0.74       154

weighted avg       0.78      0.79      0.78       154</code></pre>
<p>​</p>
<pre><code>[197 196]

              precision    recall  f1-score   support</code></pre>
<p>​</p>
<pre><code>           0       0.83      0.92      0.87       107

           1       0.75      0.57      0.65        47</code></pre>
<p>​</p>
<pre><code>    accuracy                           0.81       154

   macro avg       0.79      0.75      0.76       154

weighted avg       0.81      0.81      0.80       154</code></pre>
<p>​</p>
<blockquote>
<p>预期结果</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/0768604ae0644fcdb3edd584090f6af7fae81344e0b14da789ec1324ee81bcf0"></p>
<h2 id="任务2svc选定rbf核函数并寻优核带宽参数gamma">任务2：SVC选定RBF核函数，并寻优核带宽参数gamma</h2>
<blockquote>
<p>在支持向量分类器中，核函数对其性能有直接的影响。已知径向基函数 RBF
及核矩阵元素为： <span class="math display"><em>K</em>(<strong>x</strong><sub><em>i</em></sub>, <strong>x</strong><sub><em>j</em></sub>) = exp (−<em>γ</em>∥<strong>x</strong><sub><em>i</em></sub> − <strong>x</strong><sub><em>j</em></sub>∥<sup>2</sup>)</span>
且对于核矩阵K，有<span class="math inline"><em>K</em><sub><em>i</em><em>j</em></sub> = <em>K</em>(<strong>x</strong><sub><em>i</em></sub>, <strong>x</strong><sub><em>j</em></sub>).</span></p>
</blockquote>
<p>主要任务如下： - 自定义函数实现径向基函数
rbf_kernel，要求输入参数为两个矩阵 X、Y，以及 gamma； -
利用rbf_kernel核函数，计算标准化后的训练集scaled_train_X的核矩阵，并存为
rbf_matrix； - 利用rbf_kernel核函数，训练支持向量分类器
clf，并预测标准化后的测试数据 scaled_test_X 的标签，最后评价模型效果。
&gt; 提示：先计算各自的 Gram 矩阵，然后再使用 np.diag
提取对角线元素，使用 np.tile 将列表扩展成一个矩阵。</p>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rbf_kernel</span>(<span class="params">X, Y, gamma=<span class="number">0.5</span></span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取X和Y的大小</span></span><br><span class="line">    num1 = X.shape[<span class="number">0</span>]</span><br><span class="line">    num2 = Y.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算X和X^T的矩阵乘积</span></span><br><span class="line">    gram_1 = X.dot(X.T)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取gram_1对角线位置的元素，组成大小(num1, 1)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component1</span></span><br><span class="line">    component1 = np.tile(np.diag(gram_1).reshape(-<span class="number">1</span>, <span class="number">1</span>), (<span class="number">1</span>, num2))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算Y和Y^T的乘积</span></span><br><span class="line">    gram_2 = Y.dot(Y.T)</span><br><span class="line">     </span><br><span class="line">    <span class="comment"># 获取gram_2对角线位置的元素，组成(1, num2)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component2</span></span><br><span class="line">    component2 = np.tile(np.diag(gram_2).reshape(<span class="number">1</span>, -<span class="number">1</span>), (num1, <span class="number">1</span>))</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># 计算2X和Y^T的内积 </span></span><br><span class="line">    component3 = <span class="number">2</span> * X.dot(Y.T)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 返回结果</span></span><br><span class="line">    result = np.exp(gamma*(component3 - component1 - component2))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算糖尿病患者训练数据集的核矩阵</span></span><br><span class="line">rbf_matrix = rbf_kernel(scaled_train_X, scaled_train_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练一个支持向量分类器</span></span><br><span class="line">clf = SVC(kernel=rbf_kernel)</span><br><span class="line">clf.fit(scaled_train_X, train_y)</span><br><span class="line">pred_y = clf.predict(scaled_test_X)</span><br><span class="line"><span class="built_in">print</span> (clf.n_support_)</span><br><span class="line"><span class="built_in">print</span> (classification_report(test_y, pred_y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整gamma值寻找最优</span></span><br></pre></td></tr></table></figure>
<pre><code>[250 208]

              precision    recall  f1-score   support

           0       0.84      0.89      0.86       107

           1       0.71      0.62      0.66        47

    accuracy                           0.81       154

   macro avg       0.77      0.75      0.76       154

weighted avg       0.80      0.81      0.80       154</code></pre>
<blockquote>
<p>预期结果</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/09cbd0f9a36e4802941289e87082169b6640e370714642d38606e76575bc5632"></p>
<h2 id="任务3自定义函数实现svm选做">任务3：自定义函数实现SVM（选做）</h2>
<p>主要任务如下： -
读取sklearn中的iris数据集，提取特征与标记，并进行数据划分为训练与测试集；
- 自定义函数实现SVM； -
调用SVM函数进行支持向量机训练，并对测试集进行测试。</p>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_data</span>():</span><br><span class="line">    iris = load_iris()</span><br><span class="line">    df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">    df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line">    df.columns = [<span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">    data = np.array(df.iloc[:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">        <span class="keyword">if</span> data[i,-<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">            data[i,-<span class="number">1</span>] = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># print(data)</span></span><br><span class="line">    <span class="keyword">return</span> data[:,:<span class="number">2</span>], data[:,-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据，拆分数据，训练测试集划分</span></span><br><span class="line">X, y = create_data()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.25</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SVM</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_iter=<span class="number">100</span>, kernel=<span class="string">&#x27;linear&#x27;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.max_iter = max_iter</span><br><span class="line">        <span class="variable language_">self</span>._kernel = kernel</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_args</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.m, <span class="variable language_">self</span>.n = features.shape</span><br><span class="line">        <span class="variable language_">self</span>.X = features</span><br><span class="line">        <span class="variable language_">self</span>.Y = labels</span><br><span class="line">        <span class="variable language_">self</span>.b = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将Ei保存在一个列表里</span></span><br><span class="line">        <span class="variable language_">self</span>.alpha = np.ones(<span class="variable language_">self</span>.m)</span><br><span class="line">        <span class="variable language_">self</span>.E = [<span class="variable language_">self</span>._E(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m)]</span><br><span class="line">        <span class="comment"># 松弛变量</span></span><br><span class="line">        <span class="variable language_">self</span>.C = <span class="number">1.0</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_KKT</span>(<span class="params">self, i</span>):</span><br><span class="line">        y_g = <span class="variable language_">self</span>._g(i)*<span class="variable language_">self</span>.Y[i]</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.alpha[i] == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> y_g &gt;= <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.alpha[i] &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">            <span class="keyword">return</span> y_g == <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> y_g &lt;= <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># g(x)预测值，输入xi（X[i]）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_g</span>(<span class="params">self, i</span>):</span><br><span class="line">        r = <span class="variable language_">self</span>.b</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m):</span><br><span class="line">            r += <span class="variable language_">self</span>.alpha[j] * <span class="variable language_">self</span>.Y[j] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[j], <span class="variable language_">self</span>.X[i])</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 核函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kernel</span>(<span class="params">self, x1, x2</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._kernel == <span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> np.dot(x1, x2)</span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>._kernel == <span class="string">&#x27;poly&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="built_in">sum</span>([x1[k]*x2[k] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.n)]) + <span class="number">1</span>)**<span class="number">2</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># E（x）为g(x)对输入x的预测值和y的差</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_E</span>(<span class="params">self, i</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._g(i) - <span class="variable language_">self</span>.Y[i]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_alpha</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 外层循环首先遍历所有满足0&lt;a&lt;C的样本点，检验是否满足KKT</span></span><br><span class="line">        index_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m) <span class="keyword">if</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.alpha[i] &lt; <span class="variable language_">self</span>.C]</span><br><span class="line">        <span class="comment"># 否则遍历整个训练集</span></span><br><span class="line">        non_satisfy_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m) <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> index_list]</span><br><span class="line">        index_list.extend(non_satisfy_list)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> index_list:</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>._KKT(i):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            E1 = <span class="variable language_">self</span>.E[i]</span><br><span class="line">            <span class="comment"># 如果E2是+，选择最小的；如果E2是负的，选择最大的</span></span><br><span class="line">            <span class="keyword">if</span> E1 &gt;= <span class="number">0</span>:</span><br><span class="line">                j = <span class="built_in">min</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.m), key=<span class="keyword">lambda</span> x: <span class="variable language_">self</span>.E[x])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                j = <span class="built_in">max</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.m), key=<span class="keyword">lambda</span> x: <span class="variable language_">self</span>.E[x])</span><br><span class="line">            <span class="keyword">return</span> i, j</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compare</span>(<span class="params">self, _alpha, L, H</span>):</span><br><span class="line">        <span class="keyword">if</span> _alpha &gt; H:</span><br><span class="line">            <span class="keyword">return</span> H</span><br><span class="line">        <span class="keyword">elif</span> _alpha &lt; L:</span><br><span class="line">            <span class="keyword">return</span> L</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> _alpha      </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.init_args(features, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.max_iter):</span><br><span class="line">            <span class="comment"># train</span></span><br><span class="line">            i1, i2 =<span class="variable language_">self</span>._init_alpha()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 边界</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.Y[i1] == <span class="variable language_">self</span>.Y[i2]:</span><br><span class="line">                L = <span class="built_in">max</span>(<span class="number">0</span>, <span class="variable language_">self</span>.alpha[i1]+<span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.C)</span><br><span class="line">                H = <span class="built_in">min</span>(<span class="variable language_">self</span>.C, <span class="variable language_">self</span>.alpha[i1]+<span class="variable language_">self</span>.alpha[i2])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                L = <span class="built_in">max</span>(<span class="number">0</span>, <span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.alpha[i1])</span><br><span class="line">                H = <span class="built_in">min</span>(<span class="variable language_">self</span>.C, <span class="variable language_">self</span>.C+<span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.alpha[i1])</span><br><span class="line">                </span><br><span class="line">            E1 = <span class="variable language_">self</span>.E[i1]</span><br><span class="line">            E2 = <span class="variable language_">self</span>.E[i2]</span><br><span class="line">            <span class="comment"># eta=K11+K22-2K12</span></span><br><span class="line">            eta = <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i1]) + \</span><br><span class="line">                  <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i2]) - \</span><br><span class="line">                  <span class="number">2</span> * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i2])</span><br><span class="line">            <span class="keyword">if</span> eta &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># print(&#x27;eta &lt;= 0&#x27;)</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            alpha2_new_unc = <span class="variable language_">self</span>.alpha[i2] + <span class="variable language_">self</span>.Y[i2] * (E2 - E1) / eta</span><br><span class="line">            alpha2_new = <span class="variable language_">self</span>._compare(alpha2_new_unc, L, H)</span><br><span class="line">            </span><br><span class="line">            alpha1_new = <span class="variable language_">self</span>.alpha[i1] + <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.Y[i2] * (<span class="variable language_">self</span>.alpha[i2] - alpha2_new)</span><br><span class="line">            </span><br><span class="line">            b1_new = -E1 - <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i1]) * (alpha1_new-<span class="variable language_">self</span>.alpha[i1]) - <span class="variable language_">self</span>.Y[i2] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i1]) * (alpha2_new-<span class="variable language_">self</span>.alpha[i2])+ <span class="variable language_">self</span>.b </span><br><span class="line">            b2_new = -E2 - <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i2]) * (alpha1_new-<span class="variable language_">self</span>.alpha[i1]) - <span class="variable language_">self</span>.Y[i2] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i2]) * (alpha2_new-<span class="variable language_">self</span>.alpha[i2])+ <span class="variable language_">self</span>.b </span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt; alpha1_new &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">                b_new = b1_new</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">0</span> &lt; alpha2_new &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">                b_new = b2_new</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 选择中点</span></span><br><span class="line">                b_new = (b1_new + b2_new) / <span class="number">2</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 更新参数</span></span><br><span class="line">            <span class="variable language_">self</span>.alpha[i1] = alpha1_new</span><br><span class="line">            <span class="variable language_">self</span>.alpha[i2] = alpha2_new</span><br><span class="line">            <span class="variable language_">self</span>.b = b_new</span><br><span class="line">            </span><br><span class="line">            <span class="variable language_">self</span>.E[i1] = <span class="variable language_">self</span>._E(i1)</span><br><span class="line">            <span class="variable language_">self</span>.E[i2] = <span class="variable language_">self</span>._E(i2)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;train done!&#x27;</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, data</span>):</span><br><span class="line">        r = <span class="variable language_">self</span>.b</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m):</span><br><span class="line">            r += <span class="variable language_">self</span>.alpha[i] * <span class="variable language_">self</span>.Y[i] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i], data)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> r &gt; <span class="number">0</span> <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self, X_test, y_test</span>):</span><br><span class="line">        right_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_test)):</span><br><span class="line">            result = <span class="variable language_">self</span>.predict(X_test[i])</span><br><span class="line">            <span class="keyword">if</span> result == y_test[i]:</span><br><span class="line">                right_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> right_count / <span class="built_in">len</span>(X_test)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_weight</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># linear model</span></span><br><span class="line">        yx = <span class="variable language_">self</span>.Y.reshape(-<span class="number">1</span>, <span class="number">1</span>)*<span class="variable language_">self</span>.X</span><br><span class="line">        <span class="variable language_">self</span>.w = np.dot(<span class="variable language_">self</span>.alpha, yx)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.w</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 调用SVM进行模型训练与测试评估</span></span><br><span class="line">svm = SVM(max_iter=<span class="number">100</span>)</span><br><span class="line">svm.fit(X_train, y_train)</span><br><span class="line">svm.score(X_test, y_test)</span><br></pre></td></tr></table></figure>
<pre><code>0.92</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机实验9--神经网络</title>
    <url>/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1 id="上机实验9神经网络">上机实验9：神经网络</h1>
<h2 id="任务1神经元模型">任务1：神经元模型</h2>
<ul>
<li>给定数据集X和y</li>
<li>请补全以下代码以实现一个简单的神经元模型（即不包含隐层），并计算模型的参数向量w_vec</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 输入X和y</span></span><br><span class="line">X = np.array([ [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">y = np.array([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]]).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># Sigmoid激活函数以及其导数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x, derivative = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># 计算sigmoid的输出</span></span><br><span class="line">    sigmoid_value =<span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">    <span class="keyword">if</span> derivative == <span class="literal">False</span>:     </span><br><span class="line">        <span class="keyword">return</span> sigmoid_value</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> derivative == <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 计算sigmoid的导数</span></span><br><span class="line">        <span class="keyword">return</span> sigmoid_value * (<span class="number">1</span> - sigmoid_value)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代次数</span></span><br><span class="line">iter_num  = <span class="number">1000</span></span><br><span class="line">eta = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化权重向量w</span></span><br><span class="line">num, dim = X.shape</span><br><span class="line">w_vec = np.ones((dim, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(iter_num):</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## X通过权重向量w_vec，实现线性加和，结果为z1</span></span><br><span class="line">    z_1 =  X.dot(w_vec)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 经过激活函数Sigmoid，获得输出a_1</span></span><br><span class="line">    a_1 = sigmoid(z_1)</span><br><span class="line">      </span><br><span class="line">    <span class="comment"># 模型输出a_1与真实值的误差</span></span><br><span class="line">    error = a_1 - y</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 权重更新</span></span><br><span class="line">    w_vec_delta = X.T.dot(error * sigmoid(z_1, derivative=<span class="literal">True</span>))</span><br><span class="line">    w_vec = w_vec + eta*w_vec_delta  </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (w_vec)</span><br></pre></td></tr></table></figure>
<pre><code>[[0.94321144]
 [1.83125284]
 [4.71149329]]</code></pre>
<h2 id="任务2-感知机">任务2： 感知机</h2>
<p>1．感知机是根据输入实例的特征向量<span class="math inline"><em>x</em></span>对其进行二类分类的线性分类模型：</p>
<p><span class="math display"><em>f</em>(<em>x</em>) = sign (<em>w</em> ⋅ <em>x</em> + <em>b</em>)</span></p>
<p>感知机模型对应于输入空间（特征空间）中的分离超平面<span class="math inline"><em>w</em> ⋅ <em>x</em> + <em>b</em> = 0</span>。</p>
<p>2．感知机学习的策略是极小化损失函数：</p>
<p><span class="math display">min<sub><em>w</em>, <em>b</em></sub><em>L</em>(<em>w</em>, <em>b</em>) = −∑<sub><em>x</em><sub><em>i</em></sub> ∈ <em>M</em></sub><em>y</em><sub><em>i</em></sub>(<em>w</em> ⋅ <em>x</em><sub><em>i</em></sub> + <em>b</em>)</span></p>
<p>损失函数对应于误分类点到分离超平面的总距离。</p>
<p>3．感知机学习算法是基于随机梯度下降法的对损失函数的最优化算法，有原始形式和对偶形式。算法简单且易于实现。原始形式中，首先任意选取一个超平面，然后用梯度下降法不断极小化目标函数。在这个过程中一次随机选取一个误分类点使其梯度下降。</p>
<p>4．当训练数据集线性可分时，感知机学习算法是收敛的。感知机算法在训练数据集上的误分类次数<span class="math inline"><em>k</em></span>满足不等式：</p>
<p><span class="math display">$$
k \leqslant\left(\frac{R}{\gamma}\right)^{2}
$$</span></p>
<p>当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同。</p>
<ol start="5" type="1">
<li>随机梯度下降算法 Stochastic Gradient Descent：</li>
</ol>
<p>随机抽取一个误分类点使其梯度下降。</p>
<p><span class="math inline"><em>w</em> = <em>w</em> + <em>η</em><em>y</em><sub><em>i</em></sub><em>x</em><sub><em>i</em></sub></span></p>
<p><span class="math inline"><em>b</em> = <em>b</em> + <em>η</em><em>y</em><sub><em>i</em></sub></span></p>
<p>当实例点被误分类，即位于分离超平面的错误侧，则调整<span class="math inline"><em>w</em></span>, <span class="math inline"><em>b</em></span>的值，使分离超平面向该无分类点的一侧移动，直至误分类点被正确分类。</p>
<p><strong>使用iris数据集中两个类别的数据和[sepal length，sepal
width]作为特征，进行感知机分类。</strong></p>
<ol type="1">
<li>自定义感知机模型，实现iris数据分类；</li>
<li>调用sklearn中Perceptron函数来分类；</li>
<li>验证感知机为什么不能表示异或（选做）。</li>
</ol>
<h3 id="自定义感知机模型实现iris数据分类">1.
自定义感知机模型，实现iris数据分类</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line"></span><br><span class="line">df.columns = [</span><br><span class="line">    <span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>, <span class="string">&#x27;label&#x27;</span></span><br><span class="line">]</span><br><span class="line">df.label.value_counts()</span><br><span class="line"></span><br><span class="line">data = np.array(df.iloc[:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">X, y = data[:,:-<span class="number">1</span>], data[:,-<span class="number">1</span>]</span><br><span class="line">y = np.array([<span class="number">1</span> <span class="keyword">if</span> i == <span class="number">1</span> <span class="keyword">else</span> -<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> y])</span><br><span class="line"></span><br><span class="line">plt.scatter(df[:<span class="number">50</span>][<span class="string">&#x27;sepal length&#x27;</span>], df[:<span class="number">50</span>][<span class="string">&#x27;sepal width&#x27;</span>], label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.scatter(df[<span class="number">50</span>:<span class="number">100</span>][<span class="string">&#x27;sepal length&#x27;</span>], df[<span class="number">50</span>:<span class="number">100</span>][<span class="string">&#x27;sepal width&#x27;</span>], label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f177628f110&gt;



/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_6_2.png" alt="output_6_2">
<figcaption aria-hidden="true">output_6_2</figcaption>
</figure>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据线性可分，二分类数据</span></span><br><span class="line"><span class="comment"># 此处为一元一次线性方程</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.w = np.ones(<span class="built_in">len</span>(data[<span class="number">0</span>]) - <span class="number">1</span>, dtype=np.float32)</span><br><span class="line">        <span class="variable language_">self</span>.b = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.l_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">self, x, w, b</span>):</span><br><span class="line">        y = np.sign(np.dot(x, w) + b)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机梯度下降法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X_train, y_train</span>):</span><br><span class="line">        is_wrong = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> is_wrong:</span><br><span class="line">            wrong_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train)):</span><br><span class="line">                X = X_train[d]</span><br><span class="line">                y = y_train[d]</span><br><span class="line">                <span class="keyword">if</span> y * (np.dot(X, <span class="variable language_">self</span>.w) + <span class="variable language_">self</span>.b) &lt;= <span class="number">0</span>: <span class="comment">#判断样本被误分类</span></span><br><span class="line">                    <span class="comment"># 更新权重和偏置</span></span><br><span class="line">                    <span class="variable language_">self</span>.w = <span class="variable language_">self</span>.w + <span class="variable language_">self</span>.l_rate * y * X</span><br><span class="line">                    <span class="variable language_">self</span>.b = <span class="variable language_">self</span>.b + <span class="variable language_">self</span>.l_rate * y</span><br><span class="line">                    wrong_count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> wrong_count == <span class="number">0</span>:</span><br><span class="line">                is_wrong = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Perceptron Model!&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进行模型训练</span></span><br><span class="line">perceptron = Model()</span><br><span class="line">perceptron.fit(X, y)</span><br><span class="line"></span><br><span class="line">x_points = np.linspace(<span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">y_ = -(perceptron.w[<span class="number">0</span>] * x_points + perceptron.b) / perceptron.w[<span class="number">1</span>]</span><br><span class="line">plt.plot(x_points, y_)</span><br><span class="line"></span><br><span class="line">plt.plot(data[:<span class="number">50</span>, <span class="number">0</span>], data[:<span class="number">50</span>, <span class="number">1</span>], <span class="string">&#x27;bo&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.plot(data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], <span class="string">&#x27;bo&#x27;</span>, color=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f1773a0c950&gt;</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_9_1.png" alt="output_9_1">
<figcaption aria-hidden="true">output_9_1</figcaption>
</figure>
<h3 id="调用sklearn中perceptron函数来分类">2.
调用sklearn中Perceptron函数来分类</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="comment"># 调用sklearn中Perceptron函数进行分类</span></span><br><span class="line">clf = Perceptron(</span><br><span class="line">    max_iter=<span class="number">5000</span>,      <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">    eta0=<span class="number">0.05</span>,           <span class="comment"># 调整学习率（原0.01可能过小）</span></span><br><span class="line">    shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 训练模型</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"><span class="comment"># Weights assigned to the features.</span></span><br><span class="line"><span class="built_in">print</span>(clf.coef_)</span><br><span class="line"><span class="comment"># 截距 Constants in decision function.</span></span><br><span class="line"><span class="built_in">print</span>(clf.intercept_)</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.16  -1.935]]
[-0.25]</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画布大小</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文标题</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.title(<span class="string">&#x27;鸢尾花线性数据示例&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(data[:<span class="number">50</span>, <span class="number">0</span>], data[:<span class="number">50</span>, <span class="number">1</span>], c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Iris-setosa&#x27;</span>,)</span><br><span class="line">plt.scatter(data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], c=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;Iris-versicolor&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画感知机的线</span></span><br><span class="line">x_ponits = np.arange(<span class="number">4</span>, <span class="number">8</span>)</span><br><span class="line">y_ = -(clf.coef_[<span class="number">0</span>][<span class="number">0</span>]*x_ponits + clf.intercept_)/clf.coef_[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">plt.plot(x_ponits, y_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他部分</span></span><br><span class="line">plt.legend()  <span class="comment"># 显示图例</span></span><br><span class="line">plt.grid(<span class="literal">False</span>)  <span class="comment"># 不显示网格</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f1769a4eb50&gt;



/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_12_2.png" alt="output_12_2">
<figcaption aria-hidden="true">output_12_2</figcaption>
</figure>
<h3 id="验证感知机为什么不能表示异或选做">3.
验证感知机为什么不能表示异或（选做）</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">x=np.array([[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line">y=np.array([<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">plt.plot(x[:<span class="number">2</span>,<span class="number">0</span>],x[:<span class="number">2</span>,<span class="number">1</span>],<span class="string">&#x27;bo&#x27;</span>,color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.plot(x[<span class="number">2</span>:<span class="number">4</span>,<span class="number">0</span>],x[<span class="number">2</span>:<span class="number">4</span>,<span class="number">1</span>],<span class="string">&#x27;bo&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>,label=<span class="string">&#x27;-1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 初始化感知机模型</span></span><br><span class="line">clf = Perceptron(</span><br><span class="line">    max_iter=<span class="number">1000</span>,      <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">    eta0=<span class="number">0.1</span>,           <span class="comment"># 学习率</span></span><br><span class="line">    random_state=<span class="number">42</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>        <span class="comment"># 每次迭代打乱数据</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出模型参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征权重 (w):&quot;</span>, clf.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;截距 (b):&quot;</span>, clf.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">predictions = clf.predict(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测结果:&quot;</span>, predictions)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;真实标签:&quot;</span>, y)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>特征权重 (w): [[0. 0.]]
截距 (b): [0.]
预测结果: [-1 -1 -1 -1]
真实标签: [ 1  1 -1 -1]


/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_14_2.png" alt="output_14_2">
<figcaption aria-hidden="true">output_14_2</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
</search>
