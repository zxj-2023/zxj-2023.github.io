<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>梦开始的地方</title>
    <url>/2024/10/13/diary/Blog/</url>
    <content><![CDATA[<p>这是梦开始的地方</p>
<p>我一直觉得写文章是一件很酷的事情，但奈何自己文采实在有限，又没有练习写作读书的勤奋劲，所以一直搁置，还记得刚上大学那一阵，看了两位学长自己搭的博客，写了很多自己的文章，记录着自己的成长，不仅是对自己成长的记录，也是对后辈的鼓励和启示，真的让我十分崇拜与鼓舞，于是就在心中埋下搭建自己心中埋下搭建自己博客的种子，但因学业和惰性一直搁置下来，还有个重要原因就是，我不知道我的博客应该写些什么，这使我没有动力继续前进。</p>
<p>直到前阵子，我与我的父亲在车上谈话，他与我聊起了他年轻时做贸易的故事，他说他对市场的判断总能先于他人，甚至08年金融危机，他也做出了正确的判断，他与我分享说，他一个很重要的习惯就是，把他读书看新闻遇到的信息整合，实实在在地写下来，记录下来到一个本子上。可能这对别人觉得很正常，但我却很震撼，我没想到不光是我的同龄人们这样做，我的父母辈也是如此，这样一个宝贵的经验我实在应该学习。</p>
<p>现在我已经步入大二，接触的事物也比大一扩展了很多，我绝对不能再等待，即使现在写不好，只要开始就是进步，后面我希望能把我的所思所想，进步痕迹通通记录下来，我的博客不光是我的名片，让大家更好地了解我，也是我自己宝贵的回忆！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>人生匆匆啊</title>
    <url>/2025/03/05/diary/%E5%8C%86%E5%8C%86%E5%95%8A/</url>
    <content><![CDATA[<h3 id="人生匆匆啊">人生匆匆啊</h3>
<p>今天是2025年3月5日，是我的20岁生日，现在是9点45分，刚上完算法课，逃了上机课来到了机房，在开始一天的学习之前，我还是决定写一篇随笔记录一下自己的心情，或许多年之后，我已经忘记当时的心情，但这些文字会保留下来，会见证我的成长。</p>
<p>小时候，或许人人都希望生日到来的那一天，因为生日的到来意味着成长，代表着长大成人，当时的自己得知自己又成长了一岁，心中确实是喜悦的；但今日的我，却没有了这份喜悦，换来的是感慨与思考。自从上大学之后，觉得时间真的好快，转眼我已经是大二下的学生，四年的大学生活已经过半，我到底做了什么，有没有成长与进步，有没有荒度这些时光，这些天我无时无刻不反问自己。我觉得我还有很多事情，很多方面需要成长，但是时间却仿佛没有这么多了，大学本科毕业那年我22岁，如果在国内读研究生，那就是3年，毕业之后我就是25岁，在我的认知里，25岁就算是开始步入中年了，而那时的我才研究生毕业初入社会，可以说是稚嫩一无所有，这是我不能接受的。所以，这也是很大一部分原因让我选择出国留学，我希望更早地步入社会，去闯去打拼，而且就我自身而言，我觉得我的性格，在社会中会更能展现出优势，而不是科研的料。希望我可以在25岁这个结点，能做到小有成就，能做到让自己满意。</p>
<p>再简单记录一下自己这个学期的情况，学校的课程基本要从早八上到下午三点，下课之后在图书馆学习到七点20左右，然后去吃饭，八点在健身房锻炼到9点半左右，十点多洗完澡跟好朋友玩一玩游戏到十二点左右。我秉承着德智体美劳全面发展与劳逸结合，学习不能光学书本上的知识，网上很多各种类型的视频也常常可以给我启发，学习劳累之后去运动运动把身体搞好，学就是学玩就是玩，我分的很开，所以我每天晚上多少会玩一会游戏让自己放松一下。</p>
<p>差不多就说到这吧，写一写随笔真的挺好的，我经常心中有很多话，仿佛构思鸿篇巨制，却常因懒惰没有记录下来，希望以后勤写勤记，加油！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>不要过分苛责自己</title>
    <url>/2024/11/25/diary/%E4%B8%8D%E8%A6%81%E8%BF%87%E5%88%86%E8%8B%9B%E8%B4%A3%E8%87%AA%E5%B7%B1/</url>
    <content><![CDATA[<h3 id="不要过分苛责自己">不要过分苛责自己</h3>
<p>​
数竞的成绩出来，没有看到自己名字，不知道为什么还是有些难受，理性告诉我这是理所应当，因为我根本没有为这个比赛花任何时间，只有前一天晚上临时抱佛脚的两个小时，对于报名，却没有复习的原因，如果别人让我做出解释，我可能会说，那段时间太累了，这不是借口，我记忆中那段时间确实是挺累的，但现在我已经不记得我那段时间忙些了什么，或者为自己留下了什么实际性的收获，似乎什么都没有。</p>
<p>​
结果上看，我对待这个比赛的态度是放弃的，那既然已经决定放弃的事情，为什么还会有些难受呢，我想，一方面，我还对不劳而获存在不切实际的幻想，幻想着不复习，幻想着靠自己脑子那一点点知识，就想在竞赛中占有一席之地，幻想着运气一次又一次眷顾自己，事实会告诉我这是不可能的；另一方面，每个人的精力确实是有限的，但我总是比较贪心，这也想要，那也想要，结果就是应接不暇，这是好强导致的吗，感觉还是比较幼稚，没有舍弃与选择的魄力，没有舍弃的勇气的人，什么也改变不了，hhh突然想起巨人的台词，有些中二嗷，扯远了扯远了。</p>
<p>​
其实，就算做不到也没关系，现实已经一次又一次地证明了，人无完人，这件事你做不好不代表其他事你做不好啊，我并不喜欢钻研数学啊物理啊做题做试卷这种，但我决定参加一些项目，学习新的知识很有意思，我也确实在其他一些科研比赛中获得不错的成绩，为什么要为一个小小的数竟，过分地苛责自己呢，况且你一开始就没有好好准备他，失败是理所应当的，你并没有损失什么，看得开一些，向前看，不要为一些小失败而驻足不前，不要为一些小失败过分地苛责自己。</p>
<p>​
突然发现把一些心里话写下来，心情真的舒畅了很多，继续加油，不要停止奔跑。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>简历备份</title>
    <url>/2024/10/14/diary/zxj/</url>
    <content><![CDATA[<ul>
<li><h1 id="张熙浚">🧑‍💻 张熙浚</h1>
电话：18114477496｜ 个人网站：https://zxj-2023.github.io/ ## 教育背景
<strong>南京师范大学 - 本科 - 人工智能专业（2023.09-2027.07）</strong>
<code>211</code> <code>双一流</code>
<ul>
<li><p><strong>语言：</strong>英语（CET4，589）</p></li>
<li><p><strong>校内任职：</strong>现任院学生会主任、班级学习委员；</p></li>
<li><p><strong>绩点综测：</strong>绩点综测排名均列专业前二；</p></li>
<li><p><strong>校园经历：</strong>在三次获得校优秀学生奖学金一等奖，校优秀学习奖，校三好学生；</p></li>
</ul>
<h2 id="个人荣誉">个人荣誉</h2>
<ul>
<li><p><strong>全国大学生计算机设计大赛 - 全国级三等奖</strong>
(2024)</p></li>
<li><p><strong>全国大学生数学建模大赛 - 江苏省一等奖</strong>
(2024)</p></li>
<li><p><strong>全国大学生蓝桥杯程序算法设计 -
江苏省三等奖</strong></p></li>
<li><p><strong>大学生创新创业项目 - 省重点项目</strong> (2024)</p></li>
<li><p><strong><em>蓝桥杯</em>AIGC 数字内容创意设计大赛 -
国家级三等奖</strong>（2024）</p></li>
</ul>
<h2 id="项目经验">项目经验</h2>
<strong>计算机设计大赛 - 基于 unity 的 2.5D 国风游戏设计 -（2024.03 -
2024.06）</strong>
<ul>
<li><p>围绕《九章算术》设计并开发了四大游戏场景，多个小游戏，动画，对话系统和ui界面。</p></li>
<li><p>在unity平台实现2.5D场景构建，利用playmaker插件实现可视化编程。</p></li>
<li><p>使用C#脚本完成游戏逻辑构建。</p></li>
</ul>
<strong>计算机设计大赛 - 基于 LightRAG 的本地安全大模型 -（2024.10 -
至今）</strong>
<ul>
<li><p>完成LightRAG与GraphRAG的对比，利用LightRAG实现知识检索增强功能,并利用neo4j实现知识图谱可视化。</p></li>
<li><p>采用pycharm+anaconda集成开发环境，使用ollama框架完成本地大模型部署。</p></li>
<li><p>后续会进行大模型的微调，数据集的清洗，网站搭建等工作。</p></li>
</ul>
<strong>25 年大学生创新创业项目 -
基于多模态特征融合的视频暴力行为识别方法研究 -（2024.09 -
至今）</strong>
<ul>
<li><p>完成了一种基于多模态特征融合的视频暴力行为识别算法，通过融合RGB模态、帧差模态以及Depth模态，使其能够准确、鲁棒地在复杂的真实环境下进行暴力行为识别。</p></li>
<li><p>完成了一种自适应的注意力算法用于多模态融合。让模型自适应地学习不同模态特征之间的权重关系。</p></li>
<li><p>完成了系统的设计，后续会继续进行开发。</p></li>
</ul>
<h2 id="竞赛经验">竞赛经验</h2>
<strong>全国大学生数学建模大赛 - 江苏省一等奖 - （2024.09）</strong>
<strong>认证杯数学建模大赛（小美赛）- s奖 -（2024.12）</strong>
<ul>
<li>担任编程手一职，协同建模手完成了部分公式的推导等</li>
</ul>
<strong>蓝桥杯AIGC中数杯 - 国家级三等奖 -（2024.10）</strong>
<ul>
<li>利用市面上现有AIGC技术完成视频制作，实现docker部署stable
Diffusion</li>
</ul>
<h2 id="自我评价">自我评价</h2>
<ul>
<li><p>交际能力强，具备良好的口头表达和书面沟通能力，长于社交，具备丰富的活动组织经验</p></li>
<li><p>学习能力强，陌生的知识与技术会积极学习，会积极请教问题并听取建议</p></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>天下英雄如过江之鲫</title>
    <url>/2025/06/24/diary/%E5%A4%A9%E4%B8%8B%E8%8B%B1%E9%9B%84%E5%A6%82%E8%BF%87%E6%B1%9F%E4%B9%8B%E9%B2%AB/</url>
    <content><![CDATA[<p>当你来到双非，你会艳羡211的牌子，当你拼死考上211，你会发现985的头衔会处处卡死你。当你侥幸考上末流
985，你就会发现华五c9的光芒压的你喘不过气。若你真问鼎华五，抬头看，京城中双日凌空。或许你是真正的天才，清北中的佼佼者，他们告诉你，世界不止中国。当你最终成为这一世最不折不扣的天才，你会发现欧拉，黎曼，还有7岁因为想快点放学而创造求和公式的高斯，
早已在山顶等候多时。</p>
<p>有时候想想，这学上到多高才算高啊，大专上面有本科，本科上面有硕博，好不容易毕业了吧，副高，正高，青基，博导，在上面还有杰青，院士。唉，天下英雄，如过江之鲫，无穷尽也。之前没有感觉，自从上了大学，这种感受就像一团乌云一直萦绕在我心头，不禁反思人这一生究竟在追求什么。</p>
<p>大多数人追求的东西，无非三者：权钱学。</p>
<p>有的人梦想升官，但官外有官，权外有权，科级处级厅级，省部级已经算是人中龙凤，但上面还有副国级正国级，大多数人忙忙碌碌一生也就当个副处级，他们真的甘心吗，那种拼劲全力也无法跨过的鸿沟，最后只剩下无奈，遗憾和释然。</p>
<p>有人的渴望财富，赚到了十万就想赚百万，赚到了百万又开始想办法，想赚千万，亿，觉得自己有能力了，开始创业投资，拿着钱去炒股炒币最后赔了个精光，更有甚者权钱勾结，做些不法勾当，不都是为了满足自己的贪婪，但欲望无穷无尽，何时才能填满这个无底洞，更可怕的是，多少人的欲望和他的能力并不符合，自身没有那么大的能力却渴望一切，最后只会反噬，自食其果。</p>
<p>有的人钻研学识，中国的大多数人都是通过高考这一途径踏进学识的殿堂，那些在高中自命不凡的天才们，进入了高校才发现，自己只是芸芸众生的普通一员，以前的光辉也变的暗淡无光，即便是清北级别，已经是很多人可望而不可即的存在，在面对越来越难的知识，在面对更聪明的身边人，在发现自己再努力也无法达成目标时，也会学习释然这一门课。</p>
<p>我想起来看过的一个清华物理系同学的采访，有一句话我印象很深刻，古人会说少壮不努力，老大徒伤悲，但不会说少壮不成功，老大徒伤悲，或许我上面说的这些，都太注重结果了，以结果的好坏判定了过程的意义，这是不对的，在追求这些目标的过程中，我们努力了，拼搏了，奋斗了，其实那就足够了，不应该把结果失利的压力强加在自己身上。</p>
<p>唉，这些说起来容易，真正能做到不为结果所动哪里容易呢，只跟自己比较，不与他人攀比，处之泰然地面对任何困难与挑战。这就是我所追求的心境吧，我什么时候能做到这种地步，可能才是真正的长大了吧。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>未来的选择</title>
    <url>/2025/03/01/diary/%E6%9C%AA%E6%9D%A5%E7%9A%84%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<h3 id="未来的选择">未来的选择</h3>
<p>前一阵子与很久不见的学长交谈了一阵，两个小时感觉转瞬即逝，从未来选择到现在学业，和学长的交谈总能让我醍醐灌顶。我很喜欢和优秀的人谈话，他们的想法和建议总能让我豁然开朗。我最近一直对未来的选择十分迷惘，想学的东西太多，但时间精力有限，这时候就不得不做出选择。我需要好好想想我未来到底想从事什么方向的工作，并以此为目标钻研下去，而不是像无头苍蝇一样这学一点那学一点，泛而不精的人企业是不会要的。</p>
<p>摆在我眼前的有三个选择，第一个，我最近一直在看前端的知识，并跟着网上的教程编点小项目实操一下，我考虑的是一方面大创需要前端，我近期就可以用得上，另一方面我学的并不是前端很深入的知识，做一个知识上的普及还是有必要的；第二个，近期又来到计算机设计大赛的时间点，我要不要重拾unity的学习，后面走unity游戏开发方向的工作呢。但其实现在这个我不考虑了；第三个，我个人对金融，投资很感兴趣，我自己又是人工智能专业，后续去香港留学也想走ai+金融的方向，我是不是应该把更多的时间用在学习ai相关呢。</p>
<p>学长建议我还是要把更多的时间花在ai相关的学习，现在ai正是主流方向，沿着这个方向努力肯定是不会有问题的，平时要把人工智能相关的专业课，比如机器学习等，学扎实，而且我既然打算香港读研也是这个方向，就更要把时间花在这个地方。后续我打算把手头的项目写完后，有时间就开始在网上学习相关知识。</p>
<p>感觉废话有点多了，特别是上大学之后，选择与方向真的太多，但不管是哪个选择，都要大步走下去，而不是犹犹豫豫原地踏步，任重而道远啊！</p>
<p>最后说点题外话，把能认识到像学长这样优秀的人，我着实感到十分幸运。这两天又看了看学长的博客，每次看都能让我受益良多，我能开始写博客很大部分也受他的影响，但相比之下，确实感到自惭形愧，向学长学习！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>笨鸟的共鸣</title>
    <url>/2024/11/25/diary/%E7%AC%A8%E9%B8%9F%E5%85%88%E9%A3%9E/</url>
    <content><![CDATA[<h2 id="笨鸟的共鸣">笨鸟的共鸣</h2>
<p>​
今天刷谈笑间，看的一位同学很沮丧，说自己在南师大感受到了前所未有的压力，自己是高考发挥超常才来到南师大的，而身边很多同学却是高考发挥失常，在大学的学习中感受同辈人巨大的压力，不禁让我引起共鸣。别人的失常发挥上的学校，却是高中三年竭尽全力的结晶，甚至是高考的超常发挥才带来的。想到这里，我不禁再次感慨人与人之间差距的巨大。</p>
<p>​
但是，大一一年已经过去，回望这一年，笨鸟变了吗，变了，这只原来的笨鸟也获得很多成就，也在成长，也遇到很多同行路上的好友，甚至也成了别人口中的优秀者。但他真的变了吗，其实没变，他还是那只笨鸟，天赋比他好的大有人在，比他努力者也数不胜数，他始终要以一种谦逊的态度，然后不断学习，不断奔跑。高中，大学，都只是一个跳板，这种笨鸟天生不会飞，通过这一个个跳板，爬至高处，才能看见世间美景。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>脚踏实地</title>
    <url>/2025/05/21/diary/%E8%84%9A%E8%B8%8F%E5%AE%9E%E5%9C%B0/</url>
    <content><![CDATA[<h3 id="脚踏实地">脚踏实地</h3>
<p>没有一夜暴富的美梦，天下掉馅饼的事情只有可能是诱惑，在得到某些好处前先想一想你配不配。</p>
<p>杜绝心浮气躁，用双手制造财富。.</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>总结与反思-11.20</title>
    <url>/2024/11/20/diary/%E9%9A%8F%E7%AC%94-11.20/</url>
    <content><![CDATA[<h3 id="总结与反思-11.20">总结与反思-11.20</h3>
<p>距离我正式开始写博客不知不觉已经过去一个多月，决定写一篇随笔，总结反思一下</p>
<p>期中已经考完了，回过头看，其实我对我这个学期的上半学期并不满意，大物的期中和线代的第一次阶段性考核实在是不理想，这跟我自己的学习状态有关，开学一开始给自己定的这学期的主基调是不要太累，导致一直对去图书馆学习十分反感，每天就是在宿舍玩一玩浪费时间，现在回想起来还是挺后悔的，除了期中考试的不如意，主要还因为一个事情让我启发很大，就是我同学的动态，他分享每天自己的收获，可能是学习可能是看书，我看了之后第一感觉是非常的佩服的，觉得他很有毅力很自律，但是他在动态下面评论的一句话让我深有感触，他说他并不觉得他很自律，他没有强迫自己学习，他是以一个享受地态度做这些事，当时我看了可以说大受震撼，因为在过去的一年大学生活中，我一直是以强迫的态度让自己去图书馆的，有时就算到图书馆也坐立不安，最后干脆去都不去了。相比之下，我发现我对自律的理解真是太浅薄了。自律不是强迫自己做某件事情，而是想做成什么事一定会做成的决心。于是，我以一种全新的态度重新审视学习。不想学线代了？那就别强迫自己，看看科研项目相关的事，这样坚持几天下来，我发现这几天过的十分充实，一种精神上的满足。这对我来说，确确实实是一大收获，希望这种享受学习的态度能伴我一直走下去。</p>
<blockquote>
<p>这里引用一下他的话，作为记录</p>
<p>有人爱一行干一行，有人干一行不爱一行，有人爱不干的那一行…感觉我是那种“干一行爱一行”的人，越做越觉得有趣，做一点就想知道更多（可能是我运气好刚好碰上的都是能爱上的..)如果单纯为了绩点不需要这样，刷题就好，但是我会把“学习”当做是我的一种生活或者说是娱乐方式</p>
<p>我很少痛苦地去学习，我要是觉得不舒服就会去学别的，去看书（或者刷刷手机)我也经常写很慢写很久停不下来，如果只是为了做题完全不需要。嗯希望给大家一个思路都能发现生活中的美好～导</p>
</blockquote>
<p>但令我感到开心的是，我在健身这件事上做到了坚持，以前我一直觉得自己总是三分钟热度，什么事情都做不长久，如今回想起来，我自高中以来，已经做成了很多很多我以前不敢想的事情，包括对英语的学习，包括高考的超常发挥，包括大学以来获得的很多成就，希望能对自己更有自信一些，向更好的自己前进！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>指数基金投资指南</title>
    <url>/2025/02/26/reading/%E6%8C%87%E6%95%B0%E5%9F%BA%E9%87%91%E6%8A%95%E8%B5%84%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<h2 id="为什么要读这本书">为什么要读这本书</h2>
<p>我觉得学会投资，学会钱生钱，是一件很重要的事情，一开始这是我父亲告诉我的，后来我自身也是深刻地感受到了。投资，可以避免通货膨胀带了的损失，如果做到了一定的境界，更可以真正实现财富自由。但是想要学好投资并不是一件容易的事。投资的成功，不仅需要敏锐的洞察力与眼光，社会经验的积累，还要有一种成熟的投资心态，进而探索出适合自身的投资理念。我觉得，这是需要一件长期实践的事情，所以我决定早些开始，虽然我现在并没有什么资产，但在投资的过程中，包括看新闻看热点，去搜索去了解一家公司，这都是在锻炼我的视野，为以后做铺垫吧</p>
<h2 id="习惯的力量">习惯的力量</h2>
<blockquote>
<p>因为“习惯”的力量，仍然有许多人把所有的收入存放在收益率较低的“储蓄”里，让通货膨胀</p>
</blockquote>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>读书笔记</tag>
        <tag>金融投资</tag>
      </tags>
  </entry>
  <entry>
    <title>读书笔记——前言</title>
    <url>/2024/10/15/reading/%E5%89%8D%E8%A8%80/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>我从小就不是一个喜欢读书的人，不管是小说还是文学作品，感觉文字始终无法对我产生兴趣，回忆起来，我自从初中开始，书读的可能最多的就是课本，课外甚至没有完整地看下来一本书。但我一直深知读书的重要性，而且把读书的感悟写下是很有意义的一件事，希望自己以后可以多读书，自勉。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>为何需要专一</title>
    <url>/2024/10/29/%E6%96%87%E6%A1%88/%E4%B8%BA%E4%BD%95%E4%B8%93%E4%B8%80/</url>
    <content><![CDATA[<h2 id="为何需要专一">为何需要专一</h2>
<p>以下源自网络</p>
<p>精神层次越高的人对感情越专一，因为善于处理自己内心欲望，因而不会把类似找备胎、和谁玩、玩过谁，这种肤浅的价值观当作得意的谈资。他们更愿意跟某个人担起生活的风雨，因为时间都用来做正经的事情，所以左顾右盼不代表你赢了，花哨是因为你层次太低。欲望是人性，克制是教养，新欢旧爱迎来送往，你以为的魅力难挡实则廉价百搭，得陇望蜀、骑驴找马、悲凉的让人生厌且鄙弃。道德不能杀掉带给我痛苦的人，所以我只能杀死理智和感性的自己。忠诚和专一是最基本的原则和底线，但它也只是三观正且有教养的人对感情中的自我约束</p>
]]></content>
      <categories>
        <category>文案</category>
      </categories>
      <tags>
        <tag>文案</tag>
      </tags>
  </entry>
  <entry>
    <title>大风起兮云飞扬</title>
    <url>/2024/10/15/%E6%96%87%E6%A1%88/%E5%88%98%E9%82%A6/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>史书上轻轻翻过的一页，便是他们波澜壮阔的一生。鉴史可以明志，知古方能鉴今，以史为镜，可以知兴替。我虽然是一位理科生，但我心里一直深知历史的重要，历史不是冰冷的文字，而是充满温度的生命轨迹。那些沉浮于历史长河中的伟大人物，用他们的智慧与勇气改写了时代的篇章，也为后人留下了宝贵的思想财富。迷茫时读史，退缩时读史，困惑时读史，或许都会有不一样的收获。</p>
<hr>
<p>刘邦，</p>
<p>38岁，一事无成，骗吃骗喝，娶了老婆。 48岁，被逼无奈，起兵反秦。
50岁，被项羽吓得跪地求饶。 51岁，被项羽打得丢盔弃甲，老婆、父亲都被抓。
54岁，建立汉朝，君临天下。 55岁，干翻曾经对他豪横的人。</p>
<p>七年时间，纵横四海，天下归一。 60岁，出征匈奴。
62岁，衣锦还乡时，写下大气磅礴的《大风歌》：</p>
<blockquote>
<p>大风起兮云飞扬， 威加海内兮归故乡， 安得猛士兮守四方。</p>
</blockquote>
<p>有人少年得志，有人大器晚成。人生从来没有太晚的开始，尽自己最大的努力，你也只是在等待一个时机。</p>
<hr>
]]></content>
      <categories>
        <category>文案</category>
      </categories>
      <tags>
        <tag>文案</tag>
      </tags>
  </entry>
  <entry>
    <title>名言警句</title>
    <url>/2024/10/15/%E6%96%87%E6%A1%88/%E5%90%8D%E8%A8%80/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>我语文不好，始终羡慕那些说话出口成章，底蕴深厚，时不时冒出几句金句的人，所以，为了让我这么一个没有什么文化底蕴的人，说话不至于太俗气，既然我不会说，那我便学名人说，便有了记录名言警句的习惯，此外，这些名言警句背后的哲理，也经常能让我醍醐灌顶。之前在网上看到一些名言警句，就会顺手记录在手机的备忘录上，现在整理下来，希望再看到时能有所收获。我说的名人警句，不光是真正意义上的名人说的，其中也有部分是我看到网友写的，我觉得，学习一切可以学习的，任何人都可以是我的老师，他们很多的文字也能给我很大感触。</p>
<hr>
<h3 id="励志与挑战">1. <strong>励志与挑战</strong></h3>
<ul>
<li><strong>十年运到龙困井，一朝得势入青云</strong></li>
<li><strong>命定的局限尽可永在，不屈的挑战却不可须臾或缺</strong>
——《霍乱时期的爱情》</li>
<li><strong>受任于败军之际,奉命于危难之间</strong>
——诸葛亮《出师表》</li>
<li><strong>他时若遂凌云志，敢笑黄巢不丈夫</strong> ——唐代罗隐</li>
<li><strong>燕雀安知鸿鹄之志</strong> ——《史记·陈涉世家》</li>
<li><strong>攻心为上,攻城为下</strong> ——《孙子兵法》</li>
<li><strong>技不外漏，海不露底，千两黄金不卖道，十字街头送故交</strong></li>
<li><strong>将军不下马，各自奔前程</strong></li>
<li><strong>胜败兵家事不期，包羞忍耻是男儿</strong>
——宋代陆游《秋夜将晓出篱门迎凉有感二首》</li>
<li><strong>大丈夫生于天地之间，岂能郁郁久居人下</strong>
——《三国志·蜀书》</li>
<li><strong>江东子弟多才俊，卷土重来未可知</strong>
——唐代杜牧《题乌江亭》</li>
<li><strong>一位大师曾经说过要像水一样，那我应该就是海啸吧！</strong></li>
<li><strong>命数如织，当为磐石</strong></li>
</ul>
<h3 id="爱情与亲密关系">2. <strong>爱情与亲密关系</strong></h3>
<ul>
<li><strong>我想要爱、激情、真诚和亲密的关系、性，这些使我鲜活，然唯有灵魂的交流使我平静</strong></li>
<li><strong>一顾倾人城，
再顾倾人国。宁不知倾城与倾国？佳人难再得</strong>
——《汉书·李延年传》</li>
<li><strong>不见鹿，不见鲸，亦不见你</strong></li>
</ul>
<h3 id="人生与哲理">3. <strong>人生与哲理</strong></h3>
<ul>
<li><strong>你不妨大胆去冒险，只因生命终将逝去</strong> ——尼采</li>
<li><strong>人生不需要意义，意义需要人生</strong></li>
<li><strong>我曾踏足山巅，也曾进入谷底，二者都让我受益良多</strong></li>
<li><strong>旧游无处不堪寻。无寻处、惟有少年心</strong>
——宋代辛弃疾《南乡子·登京口北固亭有怀》</li>
<li><strong>天下万般兵刃 唯有过往伤人最深</strong></li>
<li><strong>我见青山多妩媚,料青山见我应如是</strong>
——宋代辛弃疾《贺新郎·别茂嘉十二弟》</li>
<li><strong>如果真相带来痛苦，谎言只会雪上加霜</strong></li>
<li><strong>花团锦簇的节日用来铭记逝者，而我，宁愿被人遗忘</strong></li>
<li><strong>坟墓里寂静无比,埋葬你的是所有你没说出口的话</strong></li>
<li><strong>世界既不黑也不白，而是一道极致的灰</strong></li>
<li><strong>梦醒时夜续，惊慌失措</strong></li>
</ul>
<h3 id="自由与个性">4. <strong>自由与个性</strong></h3>
<ul>
<li><strong>因为生活过于教条，所以格外欣赏自由野性的东西</strong></li>
<li><strong>是俗是雅，我已经分不清了，我只知道月亮正圆，我若不看一眼，倒显得我不解风情了</strong></li>
<li><strong>国王们以世袭的权柄和虚名逼你下跪，诺克萨斯要你站起来，要你在荣耀中重获新生</strong></li>
</ul>
<h3 id="孤独与感伤">5. <strong>孤独与感伤</strong></h3>
<ul>
<li><strong>忽有清风化剑气,直斩少年二十意</strong></li>
<li><strong>生活的底片从来都不是遥远的白日梦，而是热爱生活的自己</strong></li>
<li><strong>黄昏见证虔诚的信徒，巅峰诞生虚伪的拥护</strong></li>
<li><strong>假作真时真亦假，无为有处有还无</strong> ——《红楼梦》</li>
<li><strong>林深时雾起，不见归处</strong></li>
<li><strong>海蓝时浪涌，望而却步</strong></li>
</ul>
<h3 id="经典与历史">6. <strong>经典与历史</strong></h3>
<ul>
<li><strong>朕非亡国之君，臣乃亡国之臣</strong>
——明代崇祯帝与大臣对话</li>
<li><strong>满腹经纶书香气,腹有诗书气自华</strong></li>
<li><strong>天下熙熙，皆为利往</strong> ——《史记·货殖列传》</li>
<li><strong>竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生</strong>
——宋代苏轼《定风波》</li>
<li><strong>回首向来萧瑟处，归去，也无风雨也无晴</strong>
——宋代苏轼《定风波》</li>
<li><strong>既生瑜何生亮</strong> ——《三国演义》</li>
<li><strong>欲买桂花同载酒，终不似，少年游</strong>
——宋代刘过《唐多令》</li>
<li><strong>愿以深心奉尘刹，不予自身求利益</strong> ——明代张居正</li>
</ul>
<h3 id="长文">7.长文</h3>
<p>最绝望的人有三种，第一种是始出初之人，他没有同类，而身边全是未知，他无时无刻都在害怕着，你无法想象他是如何作为第一个人活下去的，因为他活着这件事本身，就已经违背了他被创造出来的本能。第二种是终焉之人，他也曾拥有同类，而现在，他便是最后之人，在迎接终焉时，他并不会感到孤单，因为同类早已用别的方式存在于他身上。他只能在可以活动的范围内活动，这使他对环境非常了解，了解到令自己感到绝望。第三种是活着之人，活着本身就是一种折磨，当你足够冷静时，你会发现，你做的一切都对自己没有任何意义，你本是一粒尘埃，最后也终回归尘埃，你认为的有意义只是你本能对你的奴役</p>
<hr>
<p>我不喜欢读书，但却无比向往哲思的海洋，所以游戏常常成为引导我思考的老师，与其是娱乐消遣的工具，我更愿意把他当做一部艺术品，其背后可以是一次次引人深思的哲理，其背后也可以是作者对某种人，对某件事，对某个价值观的思考，其背后还可以是一部引人入胜的恢宏世界观与史诗，无论是哪一种都令我着迷，引领我思考</p>
<hr>
]]></content>
      <categories>
        <category>文案</category>
      </categories>
      <tags>
        <tag>文案</tag>
      </tags>
  </entry>
  <entry>
    <title>2024小美赛</title>
    <url>/2024/11/30/%E6%AF%94%E8%B5%9B/2024%E5%B0%8F%E7%BE%8E%E8%B5%9B/</url>
    <content><![CDATA[<h1 id="论文阅读jupiter-friend-or-foe-an-answer">论文阅读：Jupiter:
friend or foe? An answer</h1>
<p>奥尔特云：</p>
<p><a href="https://zh.wikipedia.org/zh-cn/奥尔特云#潮汐力效應">奥尔特云
- 维基百科，自由的百科全书</a></p>
<p>长周期彗星：这些天体来自奥尔特云，周期超过200年，具有完整的轨道倾角范围，由
1012-1013 个冰体组成，其中绝大多数的直径小于 10
公里，并占据一个距离太阳约 103-105 天文单位的厚球形壳</p>
<p>短周期彗星：一般认为来自于柯伊伯带或离散盘。周期在200年以下</p>
<p>短周期彗星有两大类：木星族彗星（<a href="https://zh.wikipedia.org/wiki/半長軸">半长轴</a>小于5天文单位）及哈雷类彗星</p>
<p><a href="https://zh.wikipedia.org/wiki/短周期彗星">短周期彗星 -
维基百科，自由的百科全书</a></p>
<p>木星族:<a href="https://baike.baidu.com/item/木星/0?fromModule=lemma_inlink">木星</a>有时会缩短一颗彗星的运动周期，有时会延长一颗彗星的运动周期，有时会改变彗星轨道，从而使得周期彗星变成<a href="https://baike.baidu.com/item/非周期彗星/407319?fromModule=lemma_inlink">非周期彗星</a>，反过来也一样。周期3-10年，远日点在木星轨道附近的彗
星称为木星族彗星。</p>
<p>改变木星轨道上巨星的质量Y来 自小行星带的轰击</p>
<p>我们研究了改变“木星”质量对地球从小行星带向内抛出的物体所经历的撞击率的影响。我们在模拟冲击通量时遇到了一些问题。小行星被认为构成了最大的威胁。然而，在创建一群可能进化到撞击地球轨道的测试小行星时，我们面临着巨大的不确定性，特别是<strong>与整合开始时小行星的分布有关的不确定性</strong>。</p>
<p>因为自木星形成以来，它一直在扰乱目前在小行星带中观察到的物体的轨道。因此，尝试为这颗小行星构建一个受干扰程度要小得多的初始种群是很重要的</p>
<p>我们 2008 年的论文详细介绍了我们如何确定小行星分布，<span class="math inline">$\ N_{0}(a)=k(a-a_{min})^\frac{1}{2}$</span>，其中
N（a） 是距离太阳 a 的小行星数量，k 是常数，<span class="math inline"> <em>a</em><sub><em>m</em><em>i</em><em>n</em></sub></span>
是小行星分布的内部边界。<span class="math inline"> <em>a</em><sub><em>m</em><em>i</em><em>n</em></sub></span>的值为1.558AU，相当于火星的轨道半长轴，1.52
AU，加上三个 希尔半径</p>
<p>归一化常数 k 的确定 为了使总的小行星数量 <span class="math inline"> <em>N</em><sub><em>t</em><em>o</em><em>t</em><em>a</em><em>l</em></sub></span>,
为一个固定值，我们需要对 N(a)进行归一化。通过对 N(a)在范
围[amin,amax]内积分，可以得到归一化常数 k</p>
<p><span class="math inline">$\
k=\frac{3N_{total}}{2(a_{max}-a_{min})^\frac{2}{3}}$</span></p>
<p>希尔半径<span class="math inline">$\
R_{H}=a_p(\frac{M_{planet}}{3M_{Sun}})^\frac{1}{3}$</span>，ap
是行星轨道的半长轴，M
表示质量。希尔球半径是一个天体对其周围物体产生重力影响的范围</p>
<p>以这种方式创建的物体代表一个碎片圆盘，在行星形成过程中受到了适度但不过度的搅拌（例如
Ward 2002）。</p>
<p>然后，在地球、火星、木星、土星、天星和海王星的影响下，使用 MERCURY
包中包含的混合积分器对测试粒子进行了 1000
万年的跟踪。进行了简单的测试积分，以检查地球横截面积对所经历的冲击通量的影响。<strong>正如预期的那样，发现撞击率与地球的横截面积成正比，引力聚焦的影响可以忽略不计</strong>。为了<strong>提高撞击率以获得合理的撞击统计数据</strong>，因此我们将地球膨胀到
<span class="math inline"> 10<sup>6</sup></span>
公里的半径。在我们的整合中，小行星与行星和太阳发生引力相互作用，但<strong>彼此之间没有相互作用</strong></p>
<p>我们运行中使用的 “Jupiter” 经过修改，因此我们运行了 12
个单独的质量。在木星质量 MJ
的倍数中，这些是：0.01、0.05、0.10、0.15、0.20、0.25、0.33、0.50、0.75、1.00、1.50
和
2.00。每个“木星”的轨道元素与今天的木星相同。同样，模拟中其他行星的元素与今天相同：一次运行和下一次运行之间行星<strong>设置的唯一区别是木星质量的变化——所有其他变量都是恒定的</strong>。</p>
<p>显示了我们的模拟中 通量与质量关系的形式，其中小行星是
源群体。这些结果令人惊讶。在 1.00 M J 时，对地球的撞击次数约为 0.01 M J
时的撞击次数的 3.5 倍Y几乎没 有屏蔽！在这两个”木星”质量之间， 在 0.2 M J
左右存在一个峰值，其中撞 击次数几乎是 1.00 M J 时的两倍。</p>
<figure>
<img src="/2024/11/30/%E6%AF%94%E8%B5%9B/2024%E5%B0%8F%E7%BE%8E%E8%B5%9B/asdasd.png" alt="asdasd">
<figcaption aria-hidden="true">asdasd</figcaption>
</figure>
<p>我们随机生成了 100 000 个测试群体粒子，近日点位于 0.1– 10 AU
范围内，远日点位于 10 000 和100 000 个AU。人口的结构是为
了模仿观察到的长周期彗星的远日点 分布。近日点距离 q 确定如下<span class="math inline">$\
q=0.1+[(q_{max}-q_{min})^\frac{2}{3}*random]^\frac{2}{3}$</span>其中
<span class="math inline"> <em>q</em><sub><em>m</em><em>a</em><em>x</em></sub></span>
和<span class="math inline"> <em>q</em><sub><em>m</em><em>i</em><em>n</em></sub></span>分别是
0.1 和 10 AU 的最大和最小可能近日点 距离，而 random 是在克隆程序中
生成的 0 到 1 之间的随机数。这导 致大约 3% 的初始样本具有与地球
轨道交叉的轨道（地球交叉轨 道），大约 38% 位于最初与木星 交叉的轨道（q
小于或等于 5.203 AU 的轨道）。这个分布是一个简
单但有效的尝试，试图拟合新奥尔 特云彗星的已知分布</p>
<p>我们计算了奥尔特云 彗星在（膨胀的）地球上的碰撞次
数。需要采取不同的方法。奥尔特 云彗星的轨道周期是如此之大，以 至于即使在
100 Myr 的模拟中，即 使地球严重膨胀，也很少会与地球
近距离接触。因此，为了直接确定 对地球的撞击率，我们必须模拟大
量的测试粒子，其数量级比所使用 的粒子高出许多数量级</p>
<p>我们模拟中使用的”木 星”的质量被修改了从一个场景到
下一个场景。总共考虑了五种不同 的场景。研究了质量为木星质量
0.25、0.50、1.00 和 2.00 倍 的”木星”系统，以及不存在木星
的系统。和以前一样，场景之间的 唯一区别是木星的质量Y所有其
他参数都是恒定的。</p>
<p>大质量情况下彗星的消失速度 明显快于低质量木星的情况。即使 仅在 1 Myr
后，木星质量较高的喷 射率就很明显，并且一直持续到我
们模拟的最后，到那时，在所有情 况下，仅保留了初始彗星种群的一
小部分。</p>
<p>值得注意的是，即使没有 木星存在，到运行结束时，长周期
彗星的数量仍然会显着减少。由于 木星不存在（“木星”质量为 零）</p>
<p>。当考虑基于喷射率的初始代理 的结果时，重要的是要确保该措施
是实际上是冲击通量的合适代理。 例如，地球上的碰撞率似乎可能并
不简单地与幸存的奥尔特云彗星的 数量成正比。特别是，另外两种可
能性似乎值得进一步研究，以确保 我们最初的假设是正确的：考虑到
所研究的彗星轨道的扩展，重要的 是要检查是否存在穿过地球轨道的
奥尔特云彗星的优先生存（ q &lt; 1 AU)，或那些不存在的 (q &gt; 1
AU)。</p>
<p>换句话说，当考虑到长周期彗星通量（与我们之前
的发现相反），一颗质量更大的木星 肯定会在不存在这样的行星的情况下
为地球提供一些可测量的屏蔽。</p>
<p>事实上，只有在来自奥尔特 云的彗星的情况下，我们的结果表
明木星确实是长期以来所假设的地 球的朋友！</p>
<p>然而，应该指出的 是，在长周期轨道上运动的物体平
均而言通常比在短周期或星状轨道 上运动的物体具有更大的碰撞速度
（这是由于它们较高的倾角[包括逆 行轨道]和更大的轨道）速度为 1 天
文单位），这增加了奥尔特云彗星 作为轰炸机群体的相对重要性。</p>
<p>作 为一个整体，我们的工作表明，而 不是充当作为地球的盾牌，木星反
而增加了我们星球所经历的冲击通 量，超过了如果这颗行星以某种方
式神奇地从我们的太阳系中移走时 所受到的冲击通量。然而，如果木
星的质量减少到土星的质量，地球 的情况会更糟</p>
<p>事实上，只有在来自奥尔特 云的彗星的情况下，我们的结果表
明木星确实是长期以来所假设的地 球的朋友！</p>
<figure>
<img src="/2024/11/30/%E6%AF%94%E8%B5%9B/2024%E5%B0%8F%E7%BE%8E%E8%B5%9B/4dd5a3dac2ad91f343c275db992ed5a.png" alt="4dd5a3dac2ad91f343c275db992ed5a">
<figcaption aria-hidden="true">4dd5a3dac2ad91f343c275db992ed5a</figcaption>
</figure>
<p>我们的结果令人震惊。对于当前时代威胁地球的两个主要种群（近地小行星
和短周期彗星），我们发现木星质量与撞击率之间的关系相当复杂。在”木星”质量
较低的情况下，两颗行星的撞击率都非常低，因为这些小行星很难在地球交叉轨道上
放置物体。同样，在高”木星”质量（类似于或大于我们的木星）时，两个种群的撞
击率都相对较低，尽管略高于质量最小的”木星”。然而，在这两个极端之间，我们
在模拟中发现地球上的撞击通量出现了显着的峰值。对于近地小行星(Horner
&amp; Jones, ̚ ̘ ̘ ̠ b)和短周期彗星(Horner &amp; Jones,
2009)，我们发现当模拟中的”木
星”在0.2到0.3倍之间时，撞击通量最大。和我们的木星一样大。换句话说，与质量
小得多的情况相比（例如，当它的质量与海王星相当时），我们的木星仅提供适度的
屏蔽，但如果它围绕土星的质量，那么地球上的撞击通量将是远远大于我们观察到
的。</p>
<p>当我们研究木星质量对第三种潜在危险天体M长周期彗星M的撞击率的影响时
（例如 Wiegert &amp; Tremaine, 1999, Levison, Dones &amp;Duncan, 2001,
Horner &amp; Evans,
2002），我们发现”木星”质量越大，对地球的撞击率就越低（Horner，Jones
&amp;钱伯斯，
2010）。那么，对于长周期彗星来说，木星似乎确实起到了盾牌的作用。然而，长周期彗星
被认为只对小行星和彗星对地球的影响贡献了一小部分（</p>
<p>这是否也在确定其宿主系统中潜在宜居行星的撞击通量中
发挥作用？在这项工作中，我们通过检查木星轨道偏心率和倾角的影响，建立在早期结果
的基础上。在这项工作中，我们只考虑两个主要的撞击星群M近地小行星和短周期彗星。
由于长周期彗星在轨道倾角基本上各向同性分布的轨道上运行，并且几乎不受太阳系引力
约束，因此可以合理地假设木星轨道的微小变化对彗星通量几乎没有影响或没有影响。</p>
<p>总体而言，很明显，巨行星轨道偏心率的增加会导致近地小行星和短周期彗星对地球的
撞击通量增加。</p>
]]></content>
      <categories>
        <category>竞赛</category>
        <category>数学建模</category>
      </categories>
      <tags>
        <tag>竞赛</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>AIGC——中数杯</title>
    <url>/2024/12/05/%E6%AF%94%E8%B5%9B/%E4%B8%AD%E6%95%B0%E6%9D%AF/</url>
    <content><![CDATA[<h1 id="老匠新传">《老匠新传》</h1>
<p><strong>背景剧情：</strong></p>
<p>在安徽省一个偏远小山村里，住着一位年迈的老匠人程老。他是村里最后一位木雕匠，祖传的技艺如今面临失传的窘境。一天，城市的女孩小林，来到了这个小山村。她被精致的雕刻作品和老人的精湛技艺所吸引，留下来悉心学习这传统技艺。</p>
<p>多年后，女孩学成回到城市。她呼吸着浮躁的空气，下定决心在城市的一隅开设了一家雕刻工作室。门口摆放着一只木雕鸟，和曾经吸引她踏入木雕门扉的那只一般，精致而美丽。但是简约的线条又让它显得轻盈而现代。</p>
<p>“那是一块文化的拼图，串起了过去岁月的技艺，和当代创新的潮流。”</p>
<p><strong>创作理念：</strong></p>
<p>我们的故事从安徽省一个偏远小山村的年迈木雕匠人程老为起点，通过他与来自城市的女孩小林之间的师徒传承，展现传统技艺在现代社会中的困境与重生。</p>
<p>文化传承：我们希望强调了传统技艺的文化价值，如木雕这一几代人相传的技艺，不仅是技艺本身，更是一种文化的延续。程老作为村里最后一位木雕匠，他的技艺和作品承载着丰富的历史和文化信息。</p>
<p>师徒传承：通过小林对程老技艺的学习和传承，我们希望展现师徒之间深厚的情感纽带和技艺的传递。这种传承不仅是对技艺的保存，更是对文化精神的延续。</p>
<p>创新融合：小林学成后，在城市开设雕刻工作室，将传统技艺与现代审美相结合，创作出既具有传统韵味又符合现代审美的作品。其中表达着对传统文化的创新和发展，以及传统技艺在现代社会中焕发出新的生命力。</p>
<p>文化自信：故事中的小林在回到城市后，能够自信地展示和推销自己的作品，体现了对传统文化的自信和自豪感。</p>
<p><strong>艺术表达：</strong></p>
<p>我们采用现代的技术载体讲述传统技艺的传承和新生，希望增添作品的现实意义。</p>
<p>细节描写：故事中对木雕作品的细节描写，如“精致的雕刻作品”和“一只木雕鸟”，不仅展现了程老技艺的精湛，也通过小林对这些作品的喜爱和学习，传递了她对传统文化的热爱和尊重。</p>
<p>情感渲染：通过小林与程老之间的互动，以及小林学成后回到城市的心理变化，渲染师徒之间的深厚情感和传统文化的厚重感。</p>
<p>象征手法：木雕鸟作为故事中的象征物，既代表了程老的技艺传承，也象征着传统技艺在现代社会中的重生和创新。它的“精致而美丽”和“简约的线条”既体现了传统技艺的精髓，又融入了现代审美元素。</p>
<p>语言风格：故事中的语言风格简洁明了，富有诗意。</p>
<p><strong>使用技术：</strong></p>
<p>图像生成：首先训练GPT-4成为Midjourney提示词生成器。然后通过文字描述剧本中的场景，获取提示词。最后使用Midjourney生成场景图片，进行筛选。</p>
<p>视频生成：我们利用可灵AI进行视频的制作，我们使用生成的图片生成初版视频，然后通过提示词进行多次约束，修改，最后剪辑合并。</p>
]]></content>
      <categories>
        <category>竞赛</category>
      </categories>
      <tags>
        <tag>竞赛</tag>
      </tags>
  </entry>
  <entry>
    <title>1912</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/1912/</url>
    <content><![CDATA[<h3 id="section">1912</h3>
<p>2025年的生日，与李哥在百家湖1912聚餐，李哥请我吃的铁板烧，超级美味</p>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784805-1745080945538-24.jpg" alt="1745080784805">
<figcaption aria-hidden="true">1745080784805</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784820-1745080945538-25.jpg" alt="1745080784820">
<figcaption aria-hidden="true">1745080784820</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784834-1745080945538-26.jpg" alt="1745080784834">
<figcaption aria-hidden="true">1745080784834</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784848-1745080945538-27.jpg" alt="1745080784848">
<figcaption aria-hidden="true">1745080784848</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784862-1745080945538-28.jpg" alt="1745080784862">
<figcaption aria-hidden="true">1745080784862</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784789-1745080968451-38.jpg" alt="1745080784789">
<figcaption aria-hidden="true">1745080784789</figcaption>
</figure>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>决战蓝桥杯</title>
    <url>/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>好久不编算法了，为了不让300r打水漂，废话不多说，决战蓝桥杯！！！</p>
<p>我是算法彩笔，而且python也不是很会用，所有刷题刷的很慢，后续会把文件整理上传GitHub</p>
<p>思考了一下，因为时间紧迫，没有时间复盘每一道题了，这一篇文章简单记录一下进度</p>
<h2 id="进度记录">进度记录</h2>
<p>3.13</p>
<p>贪心：1.力扣406. 根据身高重建队列2.P10387 [蓝桥杯 2024 省 A]
训练士兵3.蓝桥杯真题 谈判</p>
<p>3.14</p>
<p>贪心：1.蓝桥杯真题 翻硬币</p>
<p>bfs：1.蓝桥杯真题 扫雷2.蓝桥杯真题 长草3.力扣695.岛屿的最大面积</p>
<p>3.16</p>
<p>哈希：1.力扣 两数之和</p>
<p>前缀和：1.洛谷 求区间和</p>
<p>二分问题：1.洛谷 查找</p>
<p>dfs：1.蓝桥杯真题 小朋友崇拜圈2.蓝桥杯真题 最大数字</p>
<p>3.17</p>
<p>二分问题：1.力扣 统计公平数对的数目2.力扣
2226.每个小孩最多能分到多少糖果</p>
<p>3.18</p>
<p>二分答案：1.蓝桥杯真题 冶炼金属</p>
<p>并查集：1.洛谷P1551 亲戚2.洛谷P1536 村村通</p>
<p>3.19</p>
<p>哈希：1.力扣 3080.执行操作标记数组中的元素</p>
<p>堆：1.力扣 2530.执行k次操作后的最大分数</p>
<p>动态规划：1.力扣 70.爬楼梯2.力扣 198.打家劫舍3.P1048 [NOIP 2005
普及组] 采药4.力扣 494. 目标和5.力扣 322.零钱兑换</p>
<p>3.21</p>
<p>动态规划：1.力扣 2915.和为目标值的最长子序列的长度2.蓝桥杯真题
蓝桥课程抢购3.力扣518. 零钱兑换 II</p>
<p>图论：1.力扣1971.寻找图中是否存在路径</p>
<p>3.25</p>
<p>图论：1.力扣743.网络延迟时间</p>
<p>数论：1.蓝桥杯真题 数字诗意</p>
<p>3.26</p>
<p>贪心：1.蓝桥杯真题 回文数组</p>
<p>图论：1.力扣 1584.连接所有点的最小费用2.蓝桥杯真题 城市规划大师</p>
<p>3.27</p>
<p>动态规划：1.力扣1143.最长公共子序列2.蓝桥杯真题
查找最长公共子序列3.力扣583.两个字符串的删除操作</p>
<p>3.28</p>
<p>动态规划：1.蓝桥杯真题 砍柴</p>
<p>3.30</p>
<p>贪心：1.蓝桥杯真题 三国游戏2.蓝桥杯真题 平均</p>
<p>暴力：1.蓝桥杯真题 翻转</p>
<p>单调队列，单调栈：1.力扣239.滑动窗口最大值2.力扣739.每日温度3.力扣42.接雨水</p>
<p>双指针：1.力扣209.长度最小的子数组2.力扣3.无重复字符的最长字串3.力扣713.乘积小于k的子数组</p>
<p>3.31</p>
<p>二维单调队列：1.蓝桥杯真题 子矩阵（拼劲全力无法战胜，放弃）</p>
<p>4.1</p>
<p>数论：1.蓝桥杯真题 阶乘的和2.蓝桥杯真题 质因数个数</p>
<p>树：1.蓝桥杯真题 子树的大小</p>
<p>4.4</p>
<p>模拟：1.蓝桥杯真题 消除游戏</p>
<p>4.5</p>
<p>差分：1.蓝桥杯真题 重新排序2.力扣1094.拼车</p>
<p>动态规划：1.蓝桥杯真题 全排列的价值2.力扣300.最长递增子序列</p>
<p>贪心：1.蓝桥杯真题 优清零方案</p>
<p>4.9-11</p>
<p>刷填空题</p>
<p>4.12后记：也是考完蓝桥杯了，后面应该很长时间不碰算法了嘿嘿</p>
<h2 id="正文">正文</h2>
<h3 id="算法基础">算法基础</h3>
<h4 id="快读模板">快读模板</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入系统模块</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment"># 重定义input函数，用于快速读取输入</span></span><br><span class="line"><span class="comment"># sys.stdin.readline() 比 python 自带的 input() 快</span></span><br><span class="line"><span class="comment"># strip() 用于去除行末的换行符</span></span><br><span class="line"><span class="built_in">input</span> = <span class="keyword">lambda</span>:sys.stdin.readline().strip()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312124949702.png" alt="image-20250312124949702">
<figcaption aria-hidden="true">image-20250312124949702</figcaption>
</figure>
<h4 id="输入">输入</h4>
<figure>
<img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312130008507.png" alt="image-20250312130008507">
<figcaption aria-hidden="true">image-20250312130008507</figcaption>
</figure>
<h4 id="列表推导器">列表推导器</h4>
<figure>
<img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312131643035.png" alt="image-20250312131643035">
<figcaption aria-hidden="true">image-20250312131643035</figcaption>
</figure>
<h2 id="参考文献">参考文献</h2>
<p>竟然在b站刷到学长做的视频，太惊喜了，真是雪中送炭</p>
<p><a href="https://www.bilibili.com/video/BV1wcR3Y5EMg/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【蓝桥杯】Python速成
刷题指南_哔哩哔哩_bilibili</a></p>
<p><a href="https://wiki.dwj601.cn/ds-and-algo/templates-py/">代码模板
(Python) - Open Wiki Community</a></p>
<p><a href="https://github.com/TsingPig/LanQiao_Python">TsingPig/LanQiao_Python:
视频合集
https://space.bilibili.com/398421867/lists?sid=4898042&amp;spm_id_from=333.788.0.0</a></p>
<table>
<colgroup>
<col style="width: 60%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>补充资料</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>https://wiki.dwj601.cn/ds-and-algo/templates-py/</td>
<td>【★★★★★】Python代码模板</td>
</tr>
<tr class="even">
<td>https://www.lanqiao.cn/problems/?first_category_id=1</td>
<td>蓝桥题库</td>
</tr>
<tr class="odd">
<td>https://ac.nowcoder.com/acm/problem/collection/6999</td>
<td>牛客蓝桥寒假题单</td>
</tr>
<tr class="even">
<td>https://www.luogu.com.cn/training/list</td>
<td>洛谷题单</td>
</tr>
<tr class="odd">
<td>https://leetcode.cn/u/endlesscheng/</td>
<td>力扣分类题单（进入点击“讨论发布”）</td>
</tr>
<tr class="even">
<td>https://www.lanqiao.cn/paper/</td>
<td>【★★★★★】蓝桥杯真题卷模拟系统</td>
</tr>
<tr class="odd">
<td>https://leetcode.cn/problemset/</td>
<td>力扣题库</td>
</tr>
</tbody>
</table>
<p>讲的很好的视频</p>
<p><a href="https://leetcode.cn/discuss/post/3141566/ru-he-ke-xue-shua-ti-by-endlesscheng-q3yd/">分享｜如何科学刷题？-
讨论 - 力扣（LeetCode）</a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>蓝桥杯</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>前言</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E5%89%8D%E8%A8%80/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>我是一个很珍惜回忆的人，但是任何回忆都有忘却的那一天，所以我能做的就是尽可能把他ji’lu</p>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>我想听他扫弦的声音</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/</url>
    <content><![CDATA[<h3 id="我想听他扫弦的声音">我想听他扫弦的声音</h3>
<p>南京1701livehouse</p>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840515.jpg" alt="1745077840515">
<figcaption aria-hidden="true">1745077840515</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840490.jpg" alt="1745077840490">
<figcaption aria-hidden="true">1745077840490</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840469.jpg" alt="1745077840469">
<figcaption aria-hidden="true">1745077840469</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840480.jpg" alt="1745077840480">
<figcaption aria-hidden="true">1745077840480</figcaption>
</figure>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>梦龙</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/</url>
    <content><![CDATA[<h3 id="梦龙演唱会">梦龙演唱会</h3>
<p>4.6 Imagine Dragons 杭州
真的太嗨太嗨了，内场氛围巨好无比，所有人都在合唱，超值啊！
再记录一下这次比较特别的体验，在小红书找到了一个自驾去看演唱会的，五个人一辆车边走边聊边听歌，也是很不错啊</p>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837710.jpg" alt="1745078837710">
<figcaption aria-hidden="true">1745078837710</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837725.jpg" alt="1745078837725">
<figcaption aria-hidden="true">1745078837725</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837752.jpg" alt="1745078837752">
<figcaption aria-hidden="true">1745078837752</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837739.jpg" alt="1745078837739">
<figcaption aria-hidden="true">1745078837739</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837778.jpg" alt="1745078837778">
<figcaption aria-hidden="true">1745078837778</figcaption>
</figure>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>橘子海</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/</url>
    <content><![CDATA[<h3 id="橘子海">橘子海</h3>
<p>橘子海，现场超超超超级赞，嗨到爆，完全超出预期</p>
<p>Give me the faith that we broke</p>
<p>请重拾我们背叛过的誓言</p>
<p>Reminds me the verse that we spoke</p>
<p>不要让我遗忘共同诵读过的诗篇</p>
<p>There is no chance for start it over</p>
<p>一切已经永远无法重来</p>
<p>Back to the check point be my lover</p>
<p>回不去那个你我还是“我们”的存盘点</p>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894738.jpg" alt="1745079894738">
<figcaption aria-hidden="true">1745079894738</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894693.jpg" alt="1745079894693">
<figcaption aria-hidden="true">1745079894693</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894721.jpg" alt="1745079894721">
<figcaption aria-hidden="true">1745079894721</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894676.jpg" alt="1745079894676">
<figcaption aria-hidden="true">1745079894676</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894659.jpg" alt="1745079894659">
<figcaption aria-hidden="true">1745079894659</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894631.jpg" alt="1745079894631">
<figcaption aria-hidden="true">1745079894631</figcaption>
</figure>
<figure>
<img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894645.jpg" alt="1745079894645">
<figcaption aria-hidden="true">1745079894645</figcaption>
</figure>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo常用指令</title>
    <url>/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<p>以下是 Hexo 常用的指令整理，方便快速查阅：</p>
<hr>
<h3 id="基础操作"><strong>基础操作</strong></h3>
<ol type="1">
<li><p><strong>初始化博客</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init [文件夹名]  <span class="comment"># 创建新博客（不指定文件夹则在当前目录生成）</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>安装依赖</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install           <span class="comment"># 安装 Hexo 核心依赖（初始化后可能需要执行）</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>本地预览</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server           <span class="comment"># 启动本地服务器（默认端口 4000），缩写：hexo s</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>生成静态文件</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo generate         <span class="comment"># 生成 public 文件夹的静态文件，缩写：hexo g</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>部署到服务器</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo deploy           <span class="comment"># 部署到 GitHub Pages 或其他平台，缩写：hexo d</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
<hr>
<h3 id="文章与页面"><strong>文章与页面</strong></h3>
<ol type="1">
<li><p><strong>新建文章</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;文章标题&quot;</span>    <span class="comment"># 生成新文章（Markdown 文件），缩写：hexo n</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>新建页面</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new page <span class="string">&quot;页面名&quot;</span> <span class="comment"># 创建自定义页面（如 about、tags）</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
<hr>
<h3 id="清理与调试"><strong>清理与调试</strong></h3>
<ol type="1">
<li><p><strong>清理缓存</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean            <span class="comment"># 删除生成的 public 和缓存文件（修改主题后建议执行）</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>查看帮助</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo <span class="built_in">help</span>             <span class="comment"># 查看所有指令说明</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
<hr>
<h3 id="组合指令高效操作"><strong>组合指令（高效操作）</strong></h3>
<ul>
<li><p><strong>生成并部署</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g -d          <span class="comment"># 先生成静态文件，再部署（等同 hexo generate &amp;&amp; hexo deploy）</span></span><br><span class="line">hexo d -g          <span class="comment"># 同上，顺序不影响结果</span></span><br></pre></td></tr></table></figure></p></li>
<li><p><strong>生成并预览</strong><br>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo s -g          <span class="comment"># 先生成文件，再启动本地服务器</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
<hr>
<h3 id="注意事项"><strong>注意事项</strong></h3>
<ul>
<li><strong>部署前配置</strong>：需在 <code>_config.yml</code> 中设置
<code>deploy</code> 参数（如 GitHub 仓库地址）。</li>
<li><strong>安装部署插件</strong>：首次部署需运行
<code>npm install hexo-deployer-git</code>。</li>
<li><strong>主题安装</strong>：将主题克隆到 <code>themes/</code>
文件夹后，在配置文件中指定主题名称。</li>
</ul>
<p>如果需要更详细的操作说明，可以补充具体场景（如更换主题、设置分类等）！</p>
]]></content>
      <categories>
        <category>学习</category>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>weatherweb开发学习记录</title>
    <url>/2025/06/01/%E5%AD%A6%E4%B9%A0/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/</url>
    <content><![CDATA[<h3 id="项目要求">项目要求</h3>
<p>智能天气提醒助手</p>
<p>描述：开发一款web应用，实时获取天气数据并支持个性化提醒（如雨天带伞）。</p>
<p>要求：</p>
<p>调用天气API获取实时数据（如OpenWeatherMap，每天1000次免费调用）</p>
<p>使用前端三件套设计交互界面，展示当前及未来天气信息，空气质量、体感温度、日出日落、月相等信息；</p>
<p>使用fastapi做后端</p>
<p>支持地点设置和天气提醒条件配置，在预设的提醒条件下提醒用户，并且将用户偏好保存至本地文件。</p>
<p>多城市切换、历史天气查询、全球地图展示等额外功能（可选*）。</p>
<h3 id="技术栈">技术栈</h3>
<p>fastapi，前端三件套(fetchapi)，apifox</p>
<h3 id="fetchapi">fetchapi</h3>
<p><strong>Fetch API</strong>
是现代浏览器提供的标准网络请求接口，允许开发者通过 JavaScript 发起异步
HTTP 请求（如 GET、POST、PUT、DELETE 等），并处理响应数据（如
JSON、文本、图片等）。它是传统
<code>XMLHttpRequest</code>（AJAX）的替代方案，语法更简洁，且支持
Promise 异步编程。</p>
<p><strong>简单来说，就是用作给后端发送请求，实现前后端分离</strong></p>
<figure>
<img src="/2025/06/01/%E5%AD%A6%E4%B9%A0/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/image-20250609163335375.png" alt="image-20250609163335375">
<figcaption aria-hidden="true">image-20250609163335375</figcaption>
</figure>
<h4 id="用法学习">用法学习</h4>
<p>在使用 <code>fetch</code> 发起 HTTP
请求时，<code>method</code>、<code>headers</code> 和 <code>body</code>
是配置请求的核心参数，它们共同决定了请求的行为和数据格式。以下是每个参数的具体作用及示例：</p>
<h5 id="method-post"><strong>1.
<code>method: 'POST'</code></strong></h5>
<p><strong>作用</strong></p>
<p>指定 HTTP 请求的方法（动词），<code>POST</code>
表示向服务器提交数据（如创建资源）。 - <strong>常见方法</strong>： -
<code>GET</code>：获取数据（默认方法，无需显式声明）。 -
<code>POST</code>：提交数据（如新增记录）。 -
<code>PUT</code>：更新数据。 - <code>DELETE</code>：删除数据。 -
<strong>与后端交互</strong>：FastAPI 的路由通过
<code>@app.post()</code>、<code>@app.get()</code>
等装饰器匹配请求方法。</p>
<p><strong>示例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="title function_">fetch</span>(<span class="string">&#x27;https://api.example.com/submit&#x27;</span>, &#123;</span><br><span class="line">  <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span>, <span class="comment">// 告诉服务器这是一个提交请求</span></span><br><span class="line">  <span class="comment">// ...其他配置</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="headers-请求头"><strong>2. <code>headers</code>
请求头</strong></h5>
<p><strong>作用</strong></p>
<p>定义请求的元信息，用于告知服务器如何处理请求和数据格式。 -
<strong>关键字段</strong>： -
<strong><code>Content-Type</code></strong>：指定请求体（<code>body</code>）的数据格式。
- <code>application/json</code>：表示发送 JSON 数据。 -
<code>application/x-www-form-urlencoded</code>：表示表单数据（键值对）。
- <code>multipart/form-data</code>：用于上传文件。 -
<strong><code>Authorization</code></strong>：携带身份凭证（如 Token）。
- <strong><code>Accept</code></strong>：声明客户端期望的响应格式（如
JSON、XML）。</p>
<p><strong>示例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="attr">headers</span>: &#123;</span><br><span class="line">  <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>, <span class="comment">// 告诉服务器请求体是 JSON</span></span><br><span class="line">  <span class="string">&#x27;Authorization&#x27;</span>: <span class="string">&#x27;Bearer your_token_here&#x27;</span> <span class="comment">// 身份验证（可选）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="body-json.stringifyitem"><strong>3.
<code>body: JSON.stringify(item)</code></strong></h5>
<p><strong>作用</strong></p>
<p>定义请求体（即发送给服务器的数据），需根据 <code>Content-Type</code>
的类型进行格式化。 -
<strong><code>JSON.stringify(item)</code></strong>：将 JavaScript
对象转换为 JSON 字符串。 - 因为 HTTP
协议只能传输文本，不能直接传输对象。 - <strong>注意事项</strong>： -
若未设置
<code>Content-Type: application/json</code>，服务器可能无法正确解析数据。
- 若使用 <code>FormData</code> 上传文件，需使用
<code>multipart/form-data</code> 格式。</p>
<p><strong>示例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> item = &#123; <span class="attr">name</span>: <span class="string">&quot;Apple&quot;</span>, <span class="attr">price</span>: <span class="number">1.99</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="attr">body</span>: <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(item) <span class="comment">// 转换为 &#x27;&#123;&quot;name&quot;:&quot;Apple&quot;,&quot;price&quot;:1.99&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<h5 id="完整示例向-fastapi-提交数据"><strong>完整示例：向 FastAPI
提交数据</strong></h5>
<p><strong>FastAPI 后端定义</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Item</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    price: <span class="built_in">float</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/items/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_item</span>(<span class="params">item: Item</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;Item created&quot;</span>, <span class="string">&quot;item&quot;</span>: item&#125;</span><br></pre></td></tr></table></figure>
<p><strong>前端调用</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> item = &#123; <span class="attr">name</span>: <span class="string">&quot;Banana&quot;</span>, <span class="attr">price</span>: <span class="number">0.99</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="title function_">fetch</span>(<span class="string">&#x27;http://localhost:8000/items/&#x27;</span>, &#123;</span><br><span class="line">  <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span>,</span><br><span class="line">  <span class="attr">headers</span>: &#123;</span><br><span class="line">    <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span> <span class="comment">// 必须与数据格式匹配</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">body</span>: <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(item) <span class="comment">// 将对象转为 JSON 字符串</span></span><br><span class="line">&#125;)</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">response</span> =&gt;</span> response.<span class="title function_">json</span>())</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">data</span> =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(data))</span><br><span class="line">  .<span class="title function_">catch</span>(<span class="function"><span class="params">error</span> =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&#x27;Error:&#x27;</span>, error));</span><br></pre></td></tr></table></figure>
<h5 id="总结"><strong>总结</strong></h5>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 45%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>参数</th>
<th>作用</th>
<th>必填性</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>method</code></td>
<td>定义请求类型（如 <code>POST</code>）</td>
<td>必填（非 <code>GET</code> 时）</td>
</tr>
<tr class="even">
<td><code>headers</code></td>
<td>声明数据格式、身份凭证等</td>
<td>必填（尤其 <code>Content-Type</code>）</td>
</tr>
<tr class="odd">
<td><code>body</code></td>
<td>发送的数据（需格式化为字符串）</td>
<td>必填（<code>POST</code>/<code>PUT</code> 时）</td>
</tr>
</tbody>
</table>
<p><strong>关键点</strong>：<br>
- <code>POST</code> 请求必须设置 <code>headers['Content-Type']</code> 和
<code>body</code>。 - <code>JSON.stringify()</code> 是发送 JSON
数据的关键步骤。 - FastAPI 会根据 <code>Content-Type</code>
自动解析请求体并进行数据校验（通过 Pydantic 模型）。</p>
<h3 id="cors">CORS</h3>
<h4 id="cors-是什么"><strong>CORS 是什么？</strong></h4>
<p><strong>CORS（Cross-Origin Resource Sharing）</strong>
是一种浏览器安全机制，用于解决 <strong>跨域请求</strong>
的问题。它允许服务器明确授权某些跨域请求，从而在保障安全的前提下，实现前后端分离架构中的跨域通信。</p>
<h4 id="为什么需要-cors"><strong>为什么需要 CORS？</strong></h4>
<p><strong>1. 同源策略（Same-Origin Policy）</strong></p>
<p>浏览器默认遵循 <strong>同源策略</strong>，即网页只能请求与自身
<strong>同源（相同域名、协议、端口）</strong> 的资源。<br>
<strong>例如</strong>：</p>
<ul>
<li>前端地址：<code>http://localhost:3000</code></li>
<li>后端地址：<code>http://localhost:8000</code><br>
此时，前端向后端发起的请求会被浏览器
<strong>拦截</strong>，因为端口不同（3000 vs 8000）。</li>
</ul>
<p><strong>2. 跨域场景</strong></p>
<p>跨域是前后端分离架构中的常见问题，例如： - 前端部署在
<code>https://example.com</code>，后端 API 在
<code>https://api.example.com</code>。 -
前端本地开发（<code>localhost:3000</code>）调用后端服务（<code>localhost:8000</code>）。</p>
<p><strong>3. CORS 的作用</strong></p>
<p>CORS 通过 <strong>服务器响应头</strong>
告诉浏览器：“这个跨域请求是安全的，允许它通过”。<br>
浏览器根据这些响应头决定是否放行请求。</p>
<h4 id="如何配置-cors"><strong>如何配置 CORS？</strong></h4>
<p>以 <strong>FastAPI</strong> 为例，配置允许跨域请求的步骤如下：</p>
<p><strong>启用 CORS 中间件</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.middleware.cors <span class="keyword">import</span> CORSMiddleware</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 CORS</span></span><br><span class="line">app.add_middleware(</span><br><span class="line">    CORSMiddleware,</span><br><span class="line">    allow_origins=[<span class="string">&quot;http://localhost:3000&quot;</span>],  <span class="comment"># 允许的源</span></span><br><span class="line">    allow_credentials=<span class="literal">True</span>,                    <span class="comment"># 允许携带凭证</span></span><br><span class="line">    allow_methods=[<span class="string">&quot;*&quot;</span>],                       <span class="comment"># 允许所有方法（GET、POST 等）</span></span><br><span class="line">    allow_headers=[<span class="string">&quot;*&quot;</span>],                       <span class="comment"># 允许所有头信息</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="cors-的实际应用场景"><strong>CORS 的实际应用场景</strong></h4>
<p><strong>1. 前后端分离开发</strong></p>
<ul>
<li>前端（React/Vue）运行在
<code>localhost:3000</code>，后端（FastAPI）运行在
<code>localhost:8000</code>。</li>
<li>配置 <code>allow_origins=["http://localhost:3000"]</code>
允许跨域通信。</li>
</ul>
<p><strong>2. 第三方 API 调用</strong></p>
<ul>
<li>前端直接调用第三方服务（如天气 API），需服务器启用 CORS。</li>
<li>示例：<code>Access-Control-Allow-Origin: *</code>
表示允许所有来源。</li>
</ul>
<p><strong>3. 需要凭证的场景</strong></p>
<ul>
<li>前端需携带 Cookie 或 Token 访问后端接口： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">app.add_middleware(</span><br><span class="line">    CORSMiddleware,</span><br><span class="line">    allow_origins=[<span class="string">&quot;http://localhost:3000&quot;</span>],</span><br><span class="line">    allow_credentials=<span class="literal">True</span>,  <span class="comment"># 允许携带凭证</span></span><br><span class="line">    allow_methods=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line">    allow_headers=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="总结-1"><strong>总结</strong></h4>
<table>
<colgroup>
<col style="width: 19%">
<col style="width: 45%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>概念</th>
<th>作用</th>
<th>配置示例</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>同源策略</strong></td>
<td>浏览器安全机制，阻止跨域请求</td>
<td>默认启用</td>
</tr>
<tr class="even">
<td><strong>CORS</strong></td>
<td>服务器通过响应头授权跨域请求</td>
<td><code>Access-Control-Allow-Origin</code></td>
</tr>
<tr class="odd">
<td><strong>预检请求</strong></td>
<td>OPTIONS 请求，验证复杂跨域请求的合法性</td>
<td>自动触发</td>
</tr>
<tr class="even">
<td><strong>FastAPI 配置</strong></td>
<td>使用 <code>CORSMiddleware</code> 中间件</td>
<td><code>app.add_middleware(...)</code></td>
</tr>
</tbody>
</table>
<p><strong>最佳实践</strong>： 1.
<strong>开发阶段</strong>：允许所有来源（<code>allow_origins=["*"]</code>），方便调试。
2.
<strong>生产环境</strong>：严格限制允许的源、方法、头信息，避免安全风险。
3. <strong>携带凭证</strong>：启用 <code>allow_credentials=True</code>
并明确指定允许的源（避免使用 <code>*</code>）。</p>
<h3 id="nginx">Nginx</h3>
<h4 id="nginx-是什么"><strong>Nginx 是什么？</strong></h4>
<p><strong>Nginx</strong>（发音为 “engine-x”）是一个高性能的开源
<strong>Web 服务器、反向代理服务器、负载均衡器和 HTTP
缓存</strong>，广泛用于现代 Web
架构中。它以轻量级、低资源消耗和高并发处理能力著称，常用于优化网站性能、管理流量和提升安全性。</p>
<h4 id="nginx-的核心功能"><strong>Nginx 的核心功能</strong></h4>
<p><strong>1. Web 服务器</strong></p>
<ul>
<li><strong>静态资源托管</strong>：直接提供
HTML、CSS、JS、图片等静态文件服务。</li>
<li><strong>动态请求转发</strong>：将动态请求（如
API）转发给后端应用（如 FastAPI、Django、Node.js）。</li>
</ul>
<p><strong>2. 反向代理</strong></p>
<ul>
<li><strong>作用</strong>：接收客户端请求，转发给后端服务器（如
FastAPI），隐藏真实服务器地址。</li>
<li><strong>优势</strong>：提高安全性、支持负载均衡、缓存和 SSL
终端。</li>
</ul>
<p><strong>3. 负载均衡</strong></p>
<ul>
<li><strong>作用</strong>：将请求分发到多个后端服务器（如多个 FastAPI
实例），避免单点故障。</li>
<li><strong>算法</strong>：轮询（Round Robin）、最少连接（Least
Connections）、IP 哈希（IP Hash）等。</li>
</ul>
<p><strong>4. SSL/TLS 终端</strong></p>
<ul>
<li><strong>作用</strong>：处理 HTTPS
加密和解密，减轻后端服务器的压力。</li>
<li><strong>配置</strong>：绑定证书和私钥，强制 HTTPS。</li>
</ul>
<p><strong>5. 缓存</strong></p>
<ul>
<li><strong>作用</strong>：缓存静态资源（如图片、CSS）或动态内容（如 API
响应），减少后端负载。</li>
</ul>
<p><strong>6. 高可用性和容错</strong></p>
<ul>
<li><strong>健康检查</strong>：自动检测后端服务器状态，故障时切换备用节点。</li>
</ul>
<h4 id="nginx-的典型应用场景"><strong>Nginx 的典型应用场景</strong></h4>
<p><strong>1. 反向代理 FastAPI 服务</strong></p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/nginx/sites-available/fastapi.conf</span></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server_name</span> example.com;</span><br><span class="line"></span><br><span class="line">    <span class="section">location</span> / &#123;</span><br><span class="line">        <span class="attribute">proxy_pass</span> http://127.0.0.1:8000;  <span class="comment"># FastAPI 服务地址</span></span><br><span class="line">        <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：将 <code>example.com</code>
的请求转发给运行在 <code>127.0.0.1:8000</code> 的 FastAPI 服务。</li>
</ul>
<p><strong>2. 静态文件托管</strong></p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">location</span> /static/ &#123;</span><br><span class="line">    <span class="attribute">alias</span> /var/www/static/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：直接提供 <code>/var/www/static/</code>
目录下的静态文件（如图片、CSS）。</li>
</ul>
<h4 id="nginx-与-fastapi-的协作流程"><strong>Nginx 与 FastAPI
的协作流程</strong></h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">客户端 -&gt; Nginx（反向代理） -&gt; FastAPI（处理业务逻辑） -&gt; 数据库/其他服务</span><br></pre></td></tr></table></figure>
<ol type="1">
<li><strong>静态资源</strong>：由 Nginx 直接返回（如
HTML、CSS、JS）。</li>
<li><strong>API 请求</strong>：Nginx 转发给 FastAPI，FastAPI 处理后返回
JSON 数据。</li>
<li><strong>HTTPS</strong>：Nginx 处理加密和解密，FastAPI 无需关心
SSL。</li>
</ol>
<p><strong>最佳实践</strong>：</p>
<ol type="1">
<li><strong>开发阶段</strong>：直接运行
FastAPI（<code>uvicorn main:app --reload</code>）。</li>
<li><strong>生产环境</strong>：Nginx + FastAPI（Gunicorn/Uvicorn） +
数据库。</li>
<li><strong>性能优化</strong>：启用 Gzip
压缩、HTTP/2、缓存静态资源。</li>
</ol>
<p>通过 Nginx 的反向代理和负载均衡，可以显著提升 FastAPI
应用的性能、安全性和可扩展性。</p>
<h3 id="反向代理是什么">反向代理是什么？</h3>
<p><strong>反向代理（Reverse Proxy）</strong>
是一种服务器角色，它位于客户端与服务器之间，接收客户端的请求后，将请求转发给后端服务器（如
FastAPI、Django、Node.js
等），并将后端服务器的响应返回给客户端。<strong>它的核心作用是隐藏后端服务器的真实地址，优化请求处理流程，并增强安全性</strong>。</p>
<p>反向代理是现代 Web
架构中不可或缺的组件，尤其在前后端分离、微服务、高并发场景下作用显著。通过
Nginx 等工具实现反向代理，可以： - 提升安全性（隐藏后端、过滤攻击）。 -
优化性能（负载均衡、缓存静态资源）。 - 简化运维（集中管理
SSL、日志）。</p>
<p>对于 FastAPI 项目，推荐在生产环境中使用 Nginx
作为反向代理，以充分发挥其高性能和灵活性优势。</p>
<h3 id="二级域名是什么">二级域名是什么？</h3>
<p><strong>二级域名（Second-Level Domain, SLD）</strong>
是域名系统（DNS）中的一个层级，通常位于顶级域名（TLD）之下，主域名（一级域名）之上。它是域名结构中的关键部分，用于标识网站或服务的主体。</p>
<p><strong>域名层级结构</strong></p>
<p>域名由多个层级组成，从右向左层级递增，具体如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mail.example.com</span><br><span class="line">|     |        |</span><br><span class="line">|     |        └── 顶级域名（TLD）：com/net/org</span><br><span class="line">|     └────────── 二级域名（SLD）：example</span><br><span class="line">└──────────────── 子域名（Subdomain）：mail</span><br></pre></td></tr></table></figure>
<p><strong>1. 顶级域名（TLD）</strong></p>
<ul>
<li><strong>定义</strong>：域名的最后一部分，表示域名的类别或国家/地区。</li>
<li><strong>示例</strong>：<code>.com</code>（商业）、<code>.org</code>（非营利组织）、<code>.net</code>（网络服务）、<code>.cn</code>（中国）、<code>.jp</code>（日本）。</li>
</ul>
<p><strong>2. 二级域名（SLD）</strong></p>
<ul>
<li><strong>定义</strong>：位于 TLD
之下的域名部分，是域名的主体，通常由用户注册并拥有。</li>
<li><strong>示例</strong>：在 <code>example.com</code>
中，<code>example</code> 是二级域名。</li>
</ul>
<p><strong>3. 子域名（Subdomain）</strong></p>
<ul>
<li><strong>定义</strong>：在二级域名前添加的前缀，用于进一步细分网站或服务。</li>
<li><strong>示例</strong>：在 <code>mail.example.com</code>
中，<code>mail</code> 是子域名。</li>
</ul>
<p><strong>二级域名的常见用途</strong></p>
<ol type="1">
<li><strong>品牌标识</strong>：<br>
二级域名是品牌的核心标识，如
<code>google.com</code>、<code>apple.com</code>。</li>
<li><strong>服务划分</strong>：<br>
通过子域名区分不同服务，例如：
<ul>
<li><code>mail.google.com</code>：邮件服务</li>
<li><code>drive.google.com</code>：云存储服务</li>
<li><code>maps.google.com</code>：地图服务</li>
</ul></li>
<li><strong>多语言或地区支持</strong>：<br>
通过二级域名提供本地化内容，例如：
<ul>
<li><code>fr.wikipedia.org</code>（法语版）</li>
<li><code>zh.wikipedia.org</code>（中文版）</li>
</ul></li>
</ol>
<h3 id="dom元素">DOM元素</h3>
<p><strong>DOM（Document Object Model，文档对象模型）</strong>
是浏览器将 HTML 或 XML 文档解析为树状结构的编程接口。<strong>DOM
元素</strong> 是构成这棵树的节点（如
<code>&lt;div&gt;</code>、<code>&lt;p&gt;</code>、<code>&lt;button&gt;</code>
等），它们不仅是页面内容的载体，更是实现动态交互的核心工具。</p>
<h3 id="开发日志">开发日志</h3>
<h4 id="api">api</h4>
<p>获取apihttps://home.openweathermap.org/api_keys</p>
<p>api文档<a href="https://openweathermap.org/api">Weather API -
OpenWeatherMap</a></p>
<h4 id="版本1.0">版本1.0</h4>
<figure>
<img src="/2025/06/01/%E5%AD%A6%E4%B9%A0/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/image-20250602191448931.png" alt="image-20250602191448931">
<figcaption aria-hidden="true">image-20250602191448931</figcaption>
</figure>
<p>完成基本天气功能的开发</p>
<h4 id="版本2.0">版本2.0</h4>
<figure>
<img src="/2025/06/01/%E5%AD%A6%E4%B9%A0/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/image-20250604095743649.png" alt="image-20250604095743649">
<figcaption aria-hidden="true">image-20250604095743649</figcaption>
</figure>
<p>完成ai建议功能</p>
]]></content>
      <categories>
        <category>weatherweb开发日志</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
        <tag>项目</tag>
        <tag>fastapi</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>初识git</title>
    <url>/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/</url>
    <content><![CDATA[<h2 id="安装git">安装git</h2>
<p>Git是目前世界上最先进的分布式版本控制系统，没有之一！说到Git,另一个需要知道的便是GitHub，GitHub是目前使用最多的社交代码托管平台。</p>
<p>输入git –version 查看Git版本信息</p>
<p>配置本地信息
为了在后面上传项目到github时方便知道是谁上传的，需要给本机git配置用户名和邮箱：</p>
<p>git config –global user.name “zxj” git config –global user.email
“zxj2902065320@163.com” <strong>查看配置命令：git config
–list</strong></p>
<p><strong>配置SSH</strong></p>
<p>ssh key生成命令<code>ssh-keygen -t rsa -C “注册邮箱”</code></p>
<p>获取ssh
key公钥内容（id_rsa.pub）<code>cd ~/.ssh       cat id_rsa.pub</code></p>
<p>Github账号上添加公钥</p>
<p>验证是否配置成功 <code>ssh -T git@github.com</code></p>
<h3 id="问题">问题</h3>
<p>在检验ssh配置时，始终报错，问ai说是配置的原因，尝试删除后，报错<code>Could not resolve hostname github.com: Name or service not known</code>，琢磨无法解决，拼尽全力无法战胜，于是保留下来交给未来的自己</p>
<figure>
<img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311172436506.png" alt="image-20250311172436506">
<figcaption aria-hidden="true">image-20250311172436506</figcaption>
</figure>
<h2 id="git常用指令">git常用指令</h2>
<p>克隆仓库git clone
https://github.com/logan-zou/Chat_with_Datawhale_langchain.git</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git init：初始化一个git仓库</span><br><span class="line">git clone：clone一个git仓库</span><br><span class="line">git add 命令可将文件添加到缓存</span><br><span class="line">git status 命令来查看相关文件的状态</span><br><span class="line">git commit 将缓存区内容添加到仓库中，可以在后面加-m选项，以在命令行中提供提交注释</span><br><span class="line"></span><br><span class="line">git remote add：添加远程仓库</span><br><span class="line">git remote：查看当前的远程仓库</span><br><span class="line">git fetch、git pull：提取远程仓仓库</span><br><span class="line">git push：推送到远程仓库</span><br><span class="line">git remote rm：删除远程仓库</span><br></pre></td></tr></table></figure>
<p>先做记录，我没用过，我目前选择vscode+GitHub的可视化界面</p>
<h2 id="vscodegithub">vscode+GitHub</h2>
<figure>
<img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311173501909.png" alt="image-20250311173501909">
<figcaption aria-hidden="true">image-20250311173501909</figcaption>
</figure>
<p>输入仓库名称 点击commit提交</p>
<figure>
<img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311174519221.png" alt="image-20250311174519221">
<figcaption aria-hidden="true">image-20250311174519221</figcaption>
</figure>
<p>每次更改代码都可以命名后再次提交</p>
<p>代理配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global http.proxy &quot;http://127.0.0.1:8080&quot; </span><br><span class="line">git config --global https.proxy &quot;http://127.0.0.1:8080&quot;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311175047287.png" alt="image-20250311175047287">
<figcaption aria-hidden="true">image-20250311175047287</figcaption>
</figure>
<p>分别代码本地和远程仓库的位置</p>
<p>天呐这图形化太方便了</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/weixin_44406127/article/details/137540031">git安装配置教程(小白保姆教程2024最新版)_git安装及配置教程-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1Hkr7YYEh8/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">给傻子的Git教程_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/qq_36667170/article/details/79085301">Git教程
Git Bash详细教程-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/HD243608836/article/details/127869482">GIT
Proxy 一键设置代理 让你的 git clone Github
再也不像百度云一样内行-CSDN博客</a></p>
]]></content>
      <categories>
        <category>开发工具</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>前端1——入门</title>
    <url>/2025/02/15/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/</url>
    <content><![CDATA[<h2 id="环境">环境</h2>
<p>vscode</p>
<p>插件：</p>
<p>HTML CSS Support 写css代码</p>
<p>Live Serve 实时预览html网页</p>
<p>Auto Rename Tag 同步修改标签名称</p>
<h2 id="html">HTML</h2>
<p>html （hyper text markup language） 超文本标记语言</p>
<p>网页是又html标签描述出来的</p>
<p>html文件结构</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span>//文档编码格式</span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;viewport&quot;</span> <span class="attr">content</span>=<span class="string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Document<span class="tag">&lt;/<span class="name">title</span>&gt;</span>//文档标题</span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span>//页面内容</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>块元素（block）：块级元素通常用于组织和布局页面的主要结构和内容，例如段落、标题、列表、表格等。它们用于创建页面的主要部分，将内容分隔成逻辑块。</p>
<p>行内元素（inline）：行内元素通常用于添加文本样式或为文本中的一部分应用样式。它们可以在文本中插入小的元素，例如超链接、强调文本等。</p>
<p>常用标签</p>
<p><code>&lt;h1&gt; &lt;/h1&gt;</code>一级标签</p>
<p><code>&lt;p&gt; &lt;/p&gt;</code>段落标签</p>
<p><code>&lt;b&gt; &lt;/b&gt;</code> bold 文本加粗</p>
<p><code>&lt;u&gt; &lt;/u&gt;</code> 下划线</p>
<p><code>&lt;s&gt; &lt;/s&gt;</code> 删除线</p>
<p>无序列表</p>
<p><code>&lt;ul&gt;</code> <code>&lt;li&gt;1&lt;/li&gt;</code>
<code>&lt;li&gt;2&lt;/li&gt;</code> <code>&lt;/ul&gt;</code></p>
<p>有序列表</p>
<p><code>&lt;ol&gt;</code> <code>&lt;li&gt;1&lt;/li&gt;</code>
<code>&lt;li&gt;2&lt;/li&gt;</code> <code>&lt;/ol&gt;</code></p>
<p>表格</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">table</span> <span class="attr">border</span>=<span class="string">&quot;1&quot;</span>&gt;</span>//边框宽度为1</span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">th</span>&gt;</span>标题1<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">th</span>&gt;</span>标题2<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>元素1<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>元素2<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>html属性 基本语法：<开始标签 属性名="“属性值”"></开始标签></p>
<p><code>&lt;a href="www.zxj-2023.github.io" target="_blank"&gt;超链接&lt;/a&gt;</code>
超链接，target决定链接打开方式</p>
<p><code>&lt;br&gt;</code> 换行</p>
<p><code>&lt;hr&gt;</code> 分割线</p>
<p><code>&lt;img src="图片路径或链接" alt="代替文本" width="宽度" height="高度"&gt;&lt;/img&gt;</code>
图片</p>
<p><code>&lt;div class="名称"&gt;&lt;/div&gt;</code>块级标签，用于创建页面的布局结构，如导航栏，页眉等</p>
<p>优先级：id&gt;class&gt;标签名</p>
<p><code>&lt;span&gt;&lt;/span&gt;</code>包装文本以便对其使用css，js行为或样式等</p>
<p>form标签是html表单的容器</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;#&quot;</span>&gt;</span>//URL</span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">&quot;username&quot;</span>&gt;</span>用户名：<span class="tag">&lt;/<span class="name">label</span>&gt;</span>//与span类似，for用于和input的id绑定</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">id</span>=<span class="string">&quot;username&quot;</span> <span class="attr">placehoud</span>=<span class="string">&quot;请输入用户名&quot;</span>&gt;</span></span><br><span class="line">	//input其他属性，value：规定input内的值</span><br><span class="line">	<span class="tag">&lt;<span class="name">label</span>&gt;</span>密码：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placehoud</span>=<span class="string">&quot;请输入密码&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span>&gt;</span>性别：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span>&gt;</span> 男//单选择 名称一致</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span>&gt;</span> 女</span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span>&gt;</span>爱好：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span>&gt;</span> 唱歌//多选</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span>&gt;</span> 跳舞</span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span>&gt;</span>//提交按钮 提交表单数据</span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="css">CSS</h2>
<p>css cascading style sheets
用于定义网页样式和布局的样式表语言，通过CSS，可以指定页面中各个元素的颜色、字体、大小、间距、边框、背景等样式，从而实现更精确的页面设计。</p>
<p>语法：</p>
<p>选择器{</p>
<p>​ 属性1：属性值1；</p>
<p>​ 属性2：属性值2；</p>
<p>}</p>
<p>内部样式表：放在head里面</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css">        <span class="selector-tag">p</span>&#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">color</span>:bule;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">font-size</span>:<span class="number">16px</span>;//字体大小</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>:yellow//背景色</span></span><br><span class="line"><span class="language-css">            font-family:<span class="string">&#x27;KaiTi&#x27;</span>//修改字体，楷体</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">    </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">        内容</span><br><span class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>外部样式：需在head链接</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;路径&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>内联样式：标签内</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span> <span class="attr">style</span>=<span class="string">&quot;color=red;&quot;</span>&gt;</span></span><br><span class="line">    内容</span><br><span class="line"><span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>优先级：内联样式&gt;内部样式表&gt;外部样式</p>
<p>css选择器：</p>
<p>元素选择器：标签名</p>
<p>类选择器：.+类名</p>
<p>id选择器：#+id名</p>
<p>通用选择器：*</p>
<p>子代选择器：父+&gt;+子</p>
<p>后代选择器：父+空格+子</p>
<p>相邻元素选择器：1+2 需要满足相邻条件</p>
<p>伪类选择器</p>
<p>css属性：</p>
<p><a href="https://www.runoob.com/cssref/css-reference.html">CSS
参考手册 |菜鸟教程</a></p>
<p><code>&lt;h1 style="font: bolder 50px 'KaiTi';"&gt;复合属性&lt;/h1&gt;</code>
font符合属性示例</p>
<p>区分块、行内、行内块元素width和height的差异</p>
<p>通过display转换以上三者(block,inline,inline-block)</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.div-inline&#123;</span><br><span class="line">	display:inline;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>盒子模型：</p>
<ol type="1">
<li>内容（content）</li>
<li>内边距（padding）：内容与边框之间的空间</li>
<li>边框（border）：盒子的边界 上右下左</li>
<li>外边距（margin）：盒子与其他元素之间的空间</li>
</ol>
<figure>
<img src="/2025/02/15/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/asdsdf.png" alt="asdsdf">
<figcaption aria-hidden="true">asdsdf</figcaption>
</figure>
<p>浮动：改变元素默认的排列顺序，使网页布局更加灵活多变(letf right)</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.son&#123;</span><br><span class="line">	float:left;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>清除浮动的方式</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.father&#123;</span><br><span class="line">	overflow: hidden;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定位布局：</p>
<p>相对定位(relative)∶相对于元素在文档流中的正常位置进行定位。</p>
<p>绝对定位(absolute)︰相对于其最近的已定位祖先元素进行定位，不占据文档流。</p>
<p>固定定位(fixed)︰相对于浏览器窗口进行定位。不占据文档流，固定在屏幕上的位置，不随滚动而移动。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.box-relative&#123;</span><br><span class="line">	position: relative;//相对定位</span><br><span class="line">	left:</span><br><span class="line">	right:</span><br><span class="line">	top:</span><br><span class="line">	bottom:</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="javascript">JavaScript</h2>
<p>JavaScript是一种轻量级、解释型、面向对象的脚本语言。它主要被设计用于在网页上实现动态效果，增加用户与网页的交互性。
作为一种客户端脚本语言，JavaScript可以直接嵌入HTML，并在浏览器中执行。
与HTML和CSS不同，JavaScript使得网页不再是静态的，而是可以根据用户的操作动态变化的。</p>
<p><code>客户端脚本</code>:用于在用户浏览器中执行，实现动态效果和用户交互。</p>
<p><code>网页开发</code>:与HTML和CSS协同工作，使得网页具有更强的交互性和动态性。</p>
<p><code>后端开发</code>︰使用Node.js，JavaScript
也可以在服务器端运行，实现服务器端应用的开发。</p>
<p>js的导入</p>
<p>内联</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">	<span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;hello,world&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>外联</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;相对路径&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;hello,world&#x27;</span>)<span class="comment">//控制台输出</span></span><br><span class="line"><span class="title function_">alert</span>(<span class="string">&#x27;&#x27;</span>)<span class="comment">//内联弹窗</span></span><br></pre></td></tr></table></figure>
<p>js语句</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//变量</span></span><br><span class="line"><span class="keyword">var</span> x;<span class="comment">//varible</span></span><br><span class="line"><span class="keyword">let</span> t=<span class="number">5</span>;<span class="comment">//块级作用域</span></span><br><span class="line"><span class="keyword">const</span> <span class="variable constant_">PI</span> =<span class="number">3.14</span>;<span class="comment">//常量</span></span><br><span class="line"><span class="comment">//条件语句</span></span><br><span class="line"><span class="keyword">if</span>()&#123;&#125;<span class="keyword">else</span>&#123;&#125;</span><br><span class="line"><span class="comment">//循环，for，while</span></span><br><span class="line"><span class="comment">//函数</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">function_name</span>(<span class="params"></span>)&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> 返回值;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用html属性触发事件</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span> <span class="attr">onclick</span>=<span class="string">&quot;click_event()&quot;</span>&gt;</span></span><br><span class="line">        点击事件</span><br><span class="line">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">onfocus</span>=<span class="string">&quot;focus_event()&quot;</span> <span class="attr">onblur</span>=<span class="string">&quot;blur_event()&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    	<span class="keyword">function</span> <span class="title function_">click_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">alert</span>(<span class="string">&#x27;触发点击事件&#x27;</span>)</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">        </span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">function</span> <span class="title function_">focus_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;获取焦点&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">        </span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">function</span> <span class="title function_">blur_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;失去焦点&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">    </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>DOM</p>
<p>当网页被加载时，浏览器会创建页面的文档对象模型，也就是DOM (Document
Object Model)
.每个HTML或XML文档都可以被视为一个文档树，文档树是整个文档的层次结构表示。</p>
<p>文档节点是整个文档树的根节点。</p>
<p>DOM为这个文档树提供了一个编程接口，开发者可以使用JavaScript来操作这个树状结构。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;box1&quot;</span>&gt;</span>ID选择器标签<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;box2&quot;</span>&gt;</span>类选择器标签<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span>&gt;</span></span><br><span class="line">        点击按钮</span><br><span class="line">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">scrip</span>&gt;</span></span><br><span class="line">    	var element_id = document.getElementById(&#x27;box1&#x27;);//id唯一，获取的是元素</span><br><span class="line">        console.log(element_id)</span><br><span class="line">		</span><br><span class="line">        var element_class = document.getElementsByClassName(&#x27;box2&#x27;)[0];//类不唯一，获取的是数组</span><br><span class="line">        console.log(element_id)</span><br><span class="line">        </span><br><span class="line">        element_id.innerHTML = &#x27;修改id标签内容&#x27;;</span><br><span class="line">        element_id.innerText</span><br><span class="line">        element_id.style.color</span><br><span class="line">        element_id.style.fontSize</span><br><span class="line">        </span><br><span class="line">        //DOM属性绑定事件</span><br><span class="line">        var button_element = document.getElementsByTagName(&#x27;button&#x27;);</span><br><span class="line">        </span><br><span class="line">        button_element.onclick = function()&#123;</span><br><span class="line">        	alert(&#x27;DOM 属性按键触发&#x27;)</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        button)element.addEventListener(&#x27;click&#x27;,click_event)</span><br><span class="line">        function click_event()&#123;</span><br><span class="line">        	alert(&#x27;通过addEventListener触发&#x27;)</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">scrip</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>对象</strong></p>
<p>对象（object）是 JavaScript 语言的核心概念，也是最重要的数据类型</p>
<p>简单说，对象就是一组“键值对”（key-value）的集合，是一种无序的复合数据集合</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> user = &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="string">&#x27;itbaizhan&#x27;</span>,</span><br><span class="line">  <span class="attr">age</span>: <span class="string">&#x27;13&#x27;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>对象的每一个键名又称为“属性”（property），它的“键</p>
<p>值”可以是任何数据类型。如果一个属性的值为函数，通常把这个属性称为“方法”，它可以像函数那样调用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> user = &#123;</span><br><span class="line">  <span class="attr">getName</span>: <span class="keyword">function</span> (<span class="params">name</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> name;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">user.<span class="title function_">getName</span>(<span class="string">&quot;itbaizhan&quot;</span>) <span class="comment">// itbaizhan</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/02/15/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/image-20211025173456785.png" alt="image-20211025173456785">
<figcaption aria-hidden="true">image-20211025173456785</figcaption>
</figure>
<h2 id="参考视频">参考视频</h2>
<p><a href="https://www.bilibili.com/video/BV1BT4y1W7Aw/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">3小时前端入门教程（HTML+CSS+JS）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型开发学习之路——动手学大模型应用开发</title>
    <url>/2025/04/19/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/%E5%8A%A8%E6%89%8B%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<h3 id="笔记">笔记</h3>
<p>技术栈：streamlit，fastapi，Gradio，langchain，dify，coze</p>
<h4 id="conda常用指令">conda常用指令</h4>
<p><strong>列出所有环境</strong>conda env list</p>
<p><strong>删除指定环境</strong>conda env remove –name 环境名称</p>
<p>创建 Conda 环境conda create -n llm-universe python==3.9.0</p>
<p>激活 Conda 环境conda activate llm-universe</p>
<p>安装依赖项pip install -r requirements.txt</p>
<h3 id="参考文献">参考文献</h3>
<p><a href="https://www.datawhale.cn/learn/content/19/445">动手学大模型应用开发-课程详情
| Datawhale</a></p>
<p><a href="https://datawhalechina.github.io/llm-universe/#/">动手学大模型应用开发</a></p>
<p><a href="https://www.bilibili.com/video/BV1QuZAY2EW1?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">10
分钟！零基础彻底学会 Cursor AI 编程 | Cursor AI 编程｜Cursor 进阶技巧 |
Cursor 开发小程序 | 小白 AI 编程_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV12TLAzuEni?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=12">【Langchain进阶篇】12.Prompt
templates Few shot. Example
selector(提示模板：少镜头。示例选择器)_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.langchain.com.cn/docs/concepts/">概念指南 |
LangChain中文网</a></p>
]]></content>
      <categories>
        <category>大模型开发学习之路</category>
        <category>动手学大模型应用开发</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>开发</tag>
      </tags>
  </entry>
  <entry>
    <title>jupyter转markdown</title>
    <url>/2025/03/06/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/jupyter%E8%BD%ACmarkdown/</url>
    <content><![CDATA[<h2 id="jupyter转markdown">jupyter转markdown</h2>
<h3 id="一准备工作">一、准备工作</h3>
<p>安装nbconverter: <a href="https://link.zhihu.com/?target=https%3A//nbconvert.readthedocs.io/en/latest/">nbconvert:
Convert Notebooks to other formats</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install nbconvert</span><br></pre></td></tr></table></figure>
<p><strong>注意依赖项：</strong></p>
<ul>
<li><strong>基本依赖：pandoc</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install pandoc</span><br></pre></td></tr></table></figure>
<h3 id="二使用方法">二、使用方法</h3>
<p>命令行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ jupyter nbconvert --to FORMAT notebook.ipynb</span><br></pre></td></tr></table></figure>
<p>这里<code>FORMAT</code> 用具体的格式替换，如 <code>markdown</code>,
<code>html</code>等。</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ jupyter nbconvert --to markdown notebook.ipynb</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://zhuanlan.zhihu.com/p/371132826">Jupyter
Notebook文件转markdown - 知乎</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>杂项</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2025/05/10/%E5%AD%A6%E4%B9%A0/langchain/langchain%E4%B8%8Elanggraph/</url>
    <content><![CDATA[<p><a href="https://www.bilibili.com/video/BV12TLAzuEni/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">2025最新版！langchain入门到精通实战教程！结合实战案例，干货拉满！99%的人不知道的暴利玩法，学完敢谷歌工程师叫板！_哔哩哔哩_bilibili</a></p>
]]></content>
  </entry>
  <entry>
    <title>前端2——巩固</title>
    <url>/2025/02/18/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF2/</url>
    <content><![CDATA[<h3 id="vscode">vscode</h3>
<p>代码格式化：shift+alt+f</p>
<p>向上或向下移动一行:Alt+Up或Alt+Down</p>
<p>快速开始新一行：ctrl+enter</p>
<p>快速复制一行代码:Shift+Alt+Up 或Shift+Alt+Down</p>
<p>快速保存:Ctrl +S</p>
<p>快速查找:Ctrl + F</p>
<p>快速替换:Ctrl+ H</p>
<p>快速移动一行 alt + ↓或↑</p>
<p>多光标： alt + 鼠标左键</p>
<h3 id="html5">html5</h3>
<p><strong>合并单元格</strong></p>
<ul>
<li>水平合并：colspan</li>
<li>垂直合并：rowspan</li>
</ul>
<p><strong>h5新标签</strong></p>
<ol type="1">
<li><code>&lt;header&gt;&lt;/header&gt;</code> 头部</li>
<li><code>&lt;nav&gt;&lt;/nav&gt;</code> 导航</li>
<li><code>&lt;section&gt;&lt;/section&gt;</code>定义文档中的节,比如章节、页眉、页脚</li>
<li><code>&lt;aside&gt;&lt;/aside&gt;</code> 侧边栏</li>
<li><code>&lt;footer&gt;&lt;/footer&gt;</code> 脚部</li>
<li><code>&lt;article&gt;&lt;/article&gt;</code>
代表一个独立的、完整的相关内容块,例如一篇完整的论坛帖子，一篇博客文章，一个用户评论等</li>
</ol>
<p><strong>查漏补缺</strong></p>
<p><code>&lt;figure&gt;</code>元素表示文档流中独立的内容块。这个内容通常与主文档相关，但可以被移动到文档的其他位置（如侧边栏、脚注或独立的附件）而不会影响理解文档的其余部分。</p>
<p><code>&lt;section&gt;</code>元素用于定义文档中的一个区域（section），它通常表示文档中的一个主题或内容块。</p>
<p>图像标题（<code>figcaption</code>）元素用于添加标题以描述
<code>figure</code> 元素中包含的图像。<code>&lt;figcaption&gt;</code>
必须是 <code>&lt;figure&gt;</code> 元素的子元素，并且它必须是
<code>&lt;figure&gt;</code> 中的第一个或最后一个子元素</p>
<p>“URL” 是 “Uniform Resource Locator” 的缩写，中文意思是
“统一资源定位符”。它是一种用于在互联网上定位和访问资源（如网页、图像、视频等）的地址。</p>
<p><code>fieldset</code> 元素用于在 Web
表单中将相关的输入和标签组合在一起。 <code>fieldset</code>
元素是块级元素，这意味着它们出现在新的一行上。</p>
<p><code>legend</code> 元素充当 <code>fieldset</code> 元素中内容的标题。
它为用户提供了应该在表单的该部分中输入什么的上下文。</p>
<p><code>&lt;meta name="viewport" content="width=device-width, initial-scale=1.0" /&gt;</code>是一个非常重要的
HTML 元标签，用于控制网页在移动设备上的布局和显示方式</p>
<p>article和section</p>
<p>article标签表示文档、页面、应用或网站的一部分，具有独立性和完整性。它通常包含一些内容，如新闻报道、博客文章、论坛帖子等，这些内容可以被单独地分享、链接和索引。</p>
<p>section标签则表示文档或应用的一部分，但不具有独立性和完整性。它通常用于组织内容，将页面或应用分成不同的部分，例如头部、主体、脚注等。</p>
<p><code>method</code> 属性指定了如何将表单数据发送到
<code>action</code> 属性中指定的 URL。 表单数据可以通过 <code>GET</code>
请求作为 URL 参数发送（<code>method="get"</code>）或通过
<code>POST</code>
请求作为请求正文中的数据发送（<code>method="post"</code>）。</p>
<p>给密码 <code>input</code> 元素添加 <code>pattern</code>
属性，要求输入匹配 <code>[a-z0-5]&#123;8,&#125;</code>。上面是一个正则表达式，匹配
8 个以上的小写字母或数字 <code>0</code> 到 <code>5</code>。</p>
<p><code>&lt;select&gt;</code> 和 <code>&lt;option&gt;</code> 是 HTML
中用于创建下拉列表的元素</p>
<p><code>&lt;textarea&gt;</code> 是 HTML
中的一个表单元素，用于多行文本输入，允许用户输入和编辑大量文本。</p>
<p><strong>英文全称记忆</strong></p>
<p><code>&lt;ul&gt;</code> ： “Unordered List”</p>
<p><code>&lt;li&gt;</code> ： “List - item”</p>
<p><code>src</code>： “source”</p>
<p><code>css text-align</code>: “text alignment”（文本对齐方式）</p>
<p><code>link rel</code>:relationship</p>
<p><code>&lt;hr&gt;</code>:“Horizontal Rule”</p>
<h3 id="css3">css3</h3>
<p><strong>查漏补缺</strong></p>
<p><code>opacity</code> 是 CSS
中用于控制元素透明度的属性。它可以设置一个元素的透明度级别，取值范围从
<code>0</code>（完全透明）到 <code>1</code>（完全不透明）</p>
<p><code>box-shadow</code>
属性允许你在元素周围应用一个或多个阴影。<code>box-shadow: offsetX offsetY blurRadius color;</code></p>
<p><code>linear-gradient</code> 是 CSS
中用于创建线性渐变背景的属性。它允许你在元素的背景中定义多种颜色之间的平滑过渡效果</p>
<p><code>hsla</code>（Hue色相, Saturation饱和度, Lightness,
Alpha透明度）是一种在 CSS 中定义颜色的方式，基于
HSL（色相、饱和度、亮度）颜色模型，并且允许设置透明度（alpha 值）。</p>
<p><code>vh</code> 是 CSS 中的一种相对长度单位，表示视口高度（Viewport
Height）的百分比。具体来说，<code>1vh</code> 等于视口高度的
1%。视口是指浏览器窗口中可见的部分，不包括工具栏、地址栏等非内容区域。</p>
<p><code>em</code> 是 CSS
中的一种相对单位，用于表示元素的字体大小（<code>font-size</code>）的倍数。具体来说，<code>1em</code>
等于当前元素的字体大小。例如，如果一个元素的字体大小为
<code>16px</code>，那么 <code>1em</code> 就等于 <code>16px</code>。</p>
<p><code>rem</code>（Root Em）是 CSS
中的一种相对单位，表示相对于根元素（<code>html</code>
元素）的字体大小（<code>font-size</code>）的倍数。</p>
<p>在 CSS 中，<code>cursor</code>
属性用于定义鼠标指针位于元素上时的形状或图标。它对于改善用户体验非常重要，因为它为用户提供了视觉反馈，让他们知道可与页面上的不同元素进行哪些操作。</p>
<p><code>z-index</code>属性设置元素的堆叠顺序。拥有更高堆叠顺序的元素总是会处于堆叠顺序较低的元素的前面</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.box1</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">position</span>:absolute;</span><br><span class="line">    <span class="attribute">z-index</span>: <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.box2</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: green;</span><br><span class="line">    <span class="attribute">position</span>:absolute;</span><br><span class="line">    <span class="attribute">z-index</span>: <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>css3新特性</strong></p>
<p><strong>圆角</strong></p>
<p>使用 CSS3 <code>border-radius</code> 属性，你可以给任何元素制作
“圆角”</p>
<p><code>border-radius</code> 属性，可以使用以下规则：</p>
<ol type="1">
<li>四个值:
第一个值为左上角，第二个值为右上角，第三个值为右下角，第四个值为左下角</li>
<li>三个值: 第一个值为左上角,
第二个值为右上角和左下角，第三个值为右下角</li>
<li>两个值: 第一个值为左上角与右下角，第二个值为右上角与左下角</li>
<li>一个值： 四个圆角值相同</li>
</ol>
<p><strong>阴影</strong></p>
<p>box-shadow 向框添加一个或多个阴影。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">box-shadow</span>: h-shadow v-shadow blur color;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr class="header">
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>h-shadow</td>
<td>必选，水平阴影的位置</td>
</tr>
<tr class="even">
<td>v-shadow</td>
<td>必选，垂直阴影的位置</td>
</tr>
<tr class="odd">
<td>blur</td>
<td>可选，模糊距离</td>
</tr>
<tr class="even">
<td>color</td>
<td>可选，阴影的颜色</td>
</tr>
</tbody>
</table>
<p><strong>动画</strong></p>
<p>使用<code>@keyframes</code>规则，你可以创建动画</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="keyword">@keyframes</span> name &#123;</span><br><span class="line">    <span class="selector-tag">from</span>|<span class="number">0%</span>&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">    percent&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="selector-tag">to</span>|<span class="number">100%</span>&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>name：动画名称，开发人员自己命名；</p>
<p>percent：为百分比值，可以添加多个百分比值；</p>
<p><strong>animation执行动画</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">animation</span>: name duration timing-function delay iteration-count direction;</span><br></pre></td></tr></table></figure>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 74%">
</colgroup>
<thead>
<tr class="header">
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>name</td>
<td>设置动画的名称</td>
</tr>
<tr class="even">
<td>duration</td>
<td>设置动画的持续时间</td>
</tr>
<tr class="odd">
<td>timing-function</td>
<td>设置动画效果的速率（如下）</td>
</tr>
<tr class="even">
<td>delay</td>
<td>设置动画的开始时间（延时执行）</td>
</tr>
<tr class="odd">
<td>iteration-count</td>
<td>设置动画循环的次数，infinite为无限次数的循环</td>
</tr>
<tr class="even">
<td>direction</td>
<td>设置动画播放的方向（如下）</td>
</tr>
<tr class="odd">
<td>animation-play-state</td>
<td>控制动画的播放状态：running代表播放，而paused代表停止播放</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>timing-function值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ease</td>
<td>逐渐变慢（默认）</td>
</tr>
<tr class="even">
<td>linear</td>
<td>匀速</td>
</tr>
<tr class="odd">
<td>ease-in</td>
<td>加速</td>
</tr>
<tr class="even">
<td>ease-out</td>
<td>减速</td>
</tr>
<tr class="odd">
<td>ease-in-out</td>
<td>先加速后减速</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>direction值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>normal</td>
<td>默认值为normal表示向前播放</td>
</tr>
<tr class="even">
<td>alternate</td>
<td>动画播放在第偶数次向前播放，第奇数次向反方向播放</td>
</tr>
</tbody>
</table>
<p><strong>切换背景颜色</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;animation&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.animation</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">animation</span>: anima <span class="number">5s</span> linear <span class="number">5s</span> infinite;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.animation</span><span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">    <span class="attribute">animation-play-state</span>: paused;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">@keyframes</span> anima &#123;</span><br><span class="line">    <span class="number">0%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: red;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">50%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: green;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">100%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: blueviolet;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>设置meta标签</strong></p>
<p>使用设备的宽度作为视图宽度并禁止初始的缩放。在<code>&lt;head&gt;</code>标签里加入这个meta标签。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&lt;meta name=&quot;viewport&quot; <span class="attribute">content</span>=&quot;<span class="attribute">width</span>=device-<span class="attribute">width</span>, initial-<span class="attribute">scale</span>=<span class="number">1</span>,maximum-<span class="attribute">scale</span>=<span class="number">1</span>, user-scalable=no&quot;&gt;</span><br></pre></td></tr></table></figure>
<p><strong>参数解释</strong></p>
<ol type="1">
<li><code>width = device-width</code> 宽度等于当前设备的宽度</li>
<li><code>initial-scale</code> 初始的缩放比例（默认设置为1.0）</li>
<li><code>maximum-scale</code>
允许用户缩放到的最大比例（默认设置为1.0）</li>
<li><code>user-scalable</code> 用户是否可以手动缩放（默认设置为no）</li>
</ol>
<h3 id="js">JS</h3>
<p><code>querySelector()</code></p>
<h3 id="es6">ES6</h3>
<p>常用命令行工具有两种</p>
<ol type="1">
<li><code>CMD</code> 命令行工具</li>
<li><code>PowerShell</code> 命令行工具</li>
</ol>
<p><strong>CMD命令行</strong></p>
<ol type="1">
<li>打开命令行窗口
<ol type="1">
<li>win：左下角开始，找到运行，点击，输入<code>cmd</code>，回车</li>
<li>win：<code>win+r</code> 快速打开命令行窗口</li>
</ol></li>
<li>选择盘符：盘符名加冒号<code>E:</code></li>
<li>查看盘符及目录下文件与文件夹：<code>win:dir</code></li>
<li>清空命令行信息：<code>win:cls</code></li>
<li>进入文件夹或目录：<code>cd  文件夹名称</code></li>
<li>返回到上一级目录：<code>cd ../</code></li>
<li>快速补全目录或文件夹名称：<code>tab</code></li>
<li>创建文件夹：<code>mkdir 文件夹名称</code></li>
<li>查看历史输入过的命令：上下按键</li>
</ol>
<p><strong>PowerShell</strong></p>
<ol type="1">
<li>打开方式
<ol type="1">
<li>在开始位置搜索<code>PowerShell</code>打开</li>
<li>在对应目录按住<code>shift</code>+右键，打开</li>
</ol></li>
<li>其他保持一直</li>
</ol>
<p>ECMAScript 和 JavaScript
的关系是，前者是后者的规格，后者是前者的一种实现，通常场合，这两个词是可以互换的。</p>
<p>ECMAScript 6（以下简称 ES6）是 JavaScript 语言的标准，在 2015 年 6
月发布。它的目标，是使得 JavaScript
语言可以用来编写复杂的大型应用程序，成为企业级开发语言。</p>
<h3 id="typescript">TypeScript</h3>
<p><a href="https://www.bilibili.com/video/BV1xL4y1B7DG/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">为什么你应当使用
TypeScript? TS 十分钟快速入门_哔哩哔哩_bilibili</a></p>
<h3 id="参考视频和网站推荐">参考视频和网站推荐</h3>
<p><a href="https://www.bilibili.com/video/BV1oz421q7BB/?spm_id_from=333.337.search-card.all.click">【HTML+CSS+JS+Vue】比大学课程还详细的Web前端教程，整整180集，学完即可兼职就业！附学习文档PDF，随时都能学_前端开发_WEB入门_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.freecodecamp.org/learn/">Learn to Code — For
Free — Coding Courses for Busy People</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2025/07/12/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/dify/</url>
    <content><![CDATA[
]]></content>
  </entry>
  <entry>
    <title>docker</title>
    <url>/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/</url>
    <content><![CDATA[<h2 id="镜像image">镜像（Image）</h2>
<p>镜像可以被看作是一个轻量级、可执行的独立软件包，包含了运行某个应用所需的所有代码、库、环境变量和配置文件。它是容器的<strong>静态模板</strong>，在创建容器时用作基础。</p>
<p><strong>只读</strong>：镜像本身是只读的，无法修改。</p>
<p><strong>可重用</strong>：镜像是可以多次重用的，你可以基于相同的镜像创建多个容器。</p>
<h2 id="容器container">容器（Container）</h2>
<p>与虚拟机通过操作系统实现隔离不同，容器技术<strong>只隔离应用程序的运行时环境但容器之间可以共享同一个操作系统</strong>，这里的运行时环境指的是程序运行依赖的各种库以及配置。</p>
<p>容器更加的<strong>轻量级且占用的资源更少</strong>，与操作系统动辄几G的内存占用相比，容器技术只需数M空间，因此我们可以在同样规格的硬件上<strong>大量部署容器</strong>，这是虚拟机所不能比拟的，而且不同于操作系统数分钟的启动时间容器几乎瞬时启动，容器技术为<strong>打包服务栈</strong>提供了一种更加高效的方式</p>
<h2 id="镜像与容器的关系">镜像与容器的关系</h2>
<p><strong>镜像是静态的</strong>：它只包含应用和运行环境，不能进行任何运行时的操作。你可以把它看作是软件的<strong>安装包</strong>。</p>
<p><strong>容器是动态的</strong>：它是在镜像的基础上创建的，可以运行、执行代码、修改文件系统等。你可以把它看作是镜像的<strong>运行实例</strong>。</p>
<h2 id="docker">docker</h2>
<p>docker将程序以及程序所有的依赖都打包到<a href="https://zhida.zhihu.com/search?content_id=129800958&amp;content_type=Article&amp;match_order=1&amp;q=docker+container&amp;zhida_source=entity">docker
container</a>，这样你的程序可以在任何环境都会有一致的表现</p>
<p>此外docker的另一个好处就是<strong>快速部署</strong>，这是当前互联网公司最常见的一个应用场景，一个原因在于容器启动速度非常快，另一个原因在于只要确保一个容器中的程序正确运行，那么你就能确信无论在生产环境部署多少都能正确运行。</p>
<p>每一种容器都是一个完整的运行环境，容器之间互相隔离。</p>
<p>简单来说，docker将程序打包部署，方便了软件的部署，避免了环境冲突等问题</p>
<h2 id="常用命令">常用命令</h2>
<p>查看所有容器（包括停止的容器）：<code>docker ps -a</code></p>
<p>在Docker中运行容器：<code>docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</code></p>
<ul>
<li>•
<code>[OPTIONS]</code>：可选参数，用于配置容器的各种选项，如端口映射、容器名称等。</li>
<li>• <code>IMAGE</code>：要运行的镜像名称或ID。</li>
<li>•
<code>[COMMAND] [ARG...]</code>：可选的命令和参数，用于在容器内执行特定的命令。</li>
</ul>
<p>停止正在运行的容器：<code>docker stop [OPTIONS] CONTAINER [CONTAINER...]</code></p>
<p>启动已停止的容器：<code>docker start [OPTIONS] CONTAINER [CONTAINER...]</code></p>
<p>删除已停止的容器或镜像：<code>docker rm [OPTIONS] CONTAINER [CONTAINER...]   docker rmi [OPTIONS] IMAGE [IMAGE...]</code></p>
<ul>
<li>• <code>docker rm</code>：删除容器的命令。</li>
<li>• <code>docker rmi</code>：删除镜像的命令。</li>
</ul>
<p>从Docker仓库中拉取现有的镜像：<code>docker pull [OPTIONS] NAME[:TAG|@DIGEST]</code></p>
<ul>
<li>• <code>docker pull</code>：拉取镜像的命令。</li>
<li>•
<code>[OPTIONS]</code>：可选参数，用于配置拉取过程，如认证信息等。</li>
<li>•
<code>NAME[:TAG|@DIGEST]</code>：要拉取的镜像名称、标签或摘要。</li>
</ul>
<h2 id="docker部分指令">docker部分指令</h2>
<p><strong>linux安装docker</strong>：<code>sudo apt-get update &amp;&amp; sudo apt-get install docker.io</code></p>
<p><strong>查看 Docker
版本信息</strong>：<code>docker version</code></p>
<p><strong>查看镜像</strong>：<code>docker images</code></p>
<p><strong>查看所有的容器</strong>：<code>docker ps -a</code></p>
<blockquote>
<p><code>systemctl</code> 是 <strong>systemd</strong>
系统和服务管理器的核心工具，用于管理系统和服务的状态及配置。</p>
</blockquote>
<p><code>mysql-client</code> 是 MySQL
数据库的命令行客户端工具。它允许你通过命令行连接和操作 MySQL
数据库服务器，比如执行 SQL 查询、管理数据库和用户等。</p>
<p>常用命令格式如下：<code>mysql -h 主机地址 -P 端口号 -u 用户名 -p</code></p>
<p>你可以在终端输入以下命令来检查是否已安装
<code>mysql-client</code>：<code>mysql --version</code></p>
<p>可以使用以下命令安装：<code>sudo apt-get update  sudo apt-get install mysql-client</code></p>
<blockquote>
<p><code>sudo apt-get update</code>
这个命令的作用是<strong>更新本地软件包列表</strong>。</p>
</blockquote>
<p><strong>停止并删除容器</strong>：<code>docker stop fastapi  docker rm fastapi</code></p>
<p><strong>Linux修改镜像源</strong>：<a href="https://blog.csdn.net/couragehope/article/details/137777158">如何查看docker配置的镜像仓库_查看docker镜像地址-CSDN博客</a></p>
<h2 id="常见参数">常见参数</h2>
<p>基础参数：</p>
<table>
<thead>
<tr class="header">
<th><code>-d</code>或<code>--detach</code></th>
<th>后台运行容器（detached mode）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>--name &lt;name&gt;</code></td>
<td>为容器指定名称（如<code>--name my_container</code>）</td>
</tr>
<tr class="even">
<td><code>--rm</code></td>
<td>容器停止后自动删除（适用于临时容器）</td>
</tr>
</tbody>
</table>
<p>端口映射：</p>
<table>
<colgroup>
<col style="width: 45%">
<col style="width: 54%">
</colgroup>
<thead>
<tr class="header">
<th><code>-p &lt;主机端口&gt;:&lt;容器端口&gt;</code></th>
<th>映射主机端口到容器端口（如<code>-p 80:80</code>）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>-p &lt;主机IP&gt;:&lt;主机端口&gt;:&lt;容器端口&gt;</code></td>
<td>指定主机IP绑定（如<code>-p 127.0.0.1:8080:80</code>）</td>
</tr>
<tr class="even">
<td><code>-P</code>或<code>--publish-all</code></td>
<td>自动映射所有暴露的端口（随机分配主机端口）</td>
</tr>
</tbody>
</table>
<p>卷挂载：</p>
<table>
<thead>
<tr class="header">
<th><code>-v &lt;主机路径&gt;:&lt;容器路径&gt;</code></th>
<th>挂载主机目录到容器（如<code>-v //app</code>）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>-v &lt;卷名&gt;:&lt;容器路径&gt;</code></td>
<td>使用命名卷（如<code>-v my_volume:/data</code>）</td>
</tr>
</tbody>
</table>
<p>环境变量：</p>
<table>
<thead>
<tr class="header">
<th><code>-e &lt;KEY=VALUE&gt;</code></th>
<th>设置环境变量（如<code>-e DEBUG=true</code>）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>--env-file &lt;文件名&gt;</code></td>
<td>从文件加载环境变量（每行<code>KEY=VALUE</code>）</td>
</tr>
</tbody>
</table>
<p>网络配置：</p>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 72%">
</colgroup>
<thead>
<tr class="header">
<th><code>--network &lt;网络名&gt;</code></th>
<th>指定容器使用的网络（如<code>--network bridge</code>或自定义网络）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>--network host</code></td>
<td>使用主机网络（共享主机网络命名空间）</td>
</tr>
</tbody>
</table>
<h2 id="拯救被wsl占用的内存">拯救被wsl占用的内存</h2>
<p>以笔者的情况来说，我的wsl中只有一些必备的开发环境，项目源代码 和
docker。前两者显然没啥可操作的空间，所以只有一个靶子 —— docker。</p>
<p>首先，我们可以进入wsl，通过以下命令，看看 Docker
的磁盘使用情况和资源总量。</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">docker system df </span><br></pre></td></tr></table></figure>
<p>大家都知道，docker运行一段时间后，可能会产生一些无用的镜像文件。要清理无用的
Docker 镜像，则可以运行以下命令：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">docker image prune </span><br></pre></td></tr></table></figure>
<p>该命令可以删除所有未被任何容器使用的镜像。如果想清理所有已停止的容器和未使用的镜像：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">docker system prune -a</span><br></pre></td></tr></table></figure>
<p>执行完后咱们可以再运行第一个命令查看磁盘使用情况，大概率能看到释放了一部分磁盘空间。如果确实长时间为清理过，很大可能可释放几十G。</p>
<p>然而这时候我们退出wsl回到win10,
你可能会看到磁盘空间几乎没啥变化。这是因为wsl还需要我们手动释放这部分空间，即压缩磁盘。</p>
<h2 id="修改docker存储镜像位置">修改docker存储镜像位置</h2>
<p>windows</p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250709095041821.png" alt="image-20250709095041821">
<figcaption aria-hidden="true">image-20250709095041821</figcaption>
</figure>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250709092539404.png" alt="image-20250709092539404">
<figcaption aria-hidden="true">image-20250709092539404</figcaption>
</figure>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250709092605183.png" alt="image-20250709092605183">
<figcaption aria-hidden="true">image-20250709092605183</figcaption>
</figure>
<p>Linux</p>
<p><a href="https://blog.csdn.net/weixin_43412762/article/details/134571411">修改Docker默认镜像和容器存储位置（超详细！！！）_docker更改存储位置-CSDN博客</a></p>
<h2 id="修改镜像源">修改镜像源</h2>
<p>查看可用的镜像源<a href="https://tools.opsnote.top/registry-mirrors/">DockerHub加速器可用性监控</a></p>
<h2 id="buildpull与run">build，pull与run</h2>
<p><strong><code>docker build</code>：从源代码构建镜像</strong></p>
<ul>
<li><strong>作用</strong>：根据你提供的
<code>Dockerfile</code>（一个包含构建镜像所需指令的文本文件）以及上下文（通常是包含
<code>Dockerfile</code>
的目录及其子目录），<strong>创建</strong>一个新的 Docker 镜像。</li>
</ul>
<p><strong><code>docker pull</code>：从注册中心下载镜像</strong></p>
<ul>
<li><strong>作用</strong>：从 Docker 注册中心（默认是 Docker
Hub，也可以是私有注册中心如 Harbor, GitLab Registry, AWS ECR
等）<strong>下载</strong>一个已经构建好的 Docker
镜像到你的本地机器。</li>
</ul>
<p><strong><code>docker run</code>：创建并启动容器</strong></p>
<ul>
<li><strong>作用</strong>：基于一个<strong>本地已有的镜像</strong>（无论这个镜像是你刚
<code>build</code> 出来的，还是 <code>pull</code>
下来的，或是之前就存在的），<strong>创建</strong>一个新的容器实例，并按照指定的命令（或镜像默认的命令）<strong>启动</strong>它。</li>
</ul>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1ai421S7zj/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">改变软件行业的技术！程序员、软件爱好者必须掌握的Docker，到底是什么？_哔哩哔哩_bilibili</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/187505981">什么是Docker？看这一篇干货文章就够了！
- 知乎</a></p>
<p><a href="https://blog.csdn.net/Python_0011/article/details/140313812">Docker常用命令大全（非常详细）零基础入门到精通，收藏这一篇就够了-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1THKyzBER6/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">40分钟的Docker实战攻略，一期视频精通Docker_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>MinerU</title>
    <url>/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/</url>
    <content><![CDATA[<h3 id="docker部署">docker部署</h3>
<p>使用dockerfile构建镜像：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU@master/docker/china/Dockerfile</span><br><span class="line">docker build -t mineru-sglang:latest -f Dockerfile .</span><br></pre></td></tr></table></figure>
<p>使用<code>wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU @master/docker/china/Dockerfile -O Dockerfile</code>将指定的
Dockerfile 下载到本地</p>
<p>Dockerfile：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用官方的 sglang 镜像作为基础镜像</span><br><span class="line">FROM lmsysorg/sglang:v0.4.9-cu126</span><br><span class="line"></span><br><span class="line"># 安装 OpenCV 依赖库</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y libgl1 &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># 安装 mineru Python 包</span><br><span class="line">RUN python3 -m pip install -U &#x27;mineru[core]&#x27; -i https://mirrors.aliyun.com/pypi/simple --break-system-packages</span><br><span class="line"></span><br><span class="line"># 下载模型并配置</span><br><span class="line">RUN /bin/bash -c &quot;mineru-models-download -s modelscope -m all&quot;</span><br><span class="line"></span><br><span class="line"># 设置容器入口命令</span><br><span class="line">ENTRYPOINT [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;export MINERU_MODEL_SOURCE=local &amp;&amp; exec \&quot;$@\&quot;&quot;, &quot;--&quot;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>SGLang（全称可能为 <strong>Serving Large Language Models with
Golang</strong>
）是由斯坦福大学研究团队开发的一个<strong>高效的大语言模型（LLM）推理服务框架</strong>
，旨在通过优化模型推理过程，显著提升生成式AI服务的吞吐量和响应速度。</p>
<ul>
<li><strong>SGlang 版本</strong> ：<code>v0.4.8.post1</code>（SGlang
是一个用于大语言模型（LLM）推理和服务的高性能框架）。</li>
<li><strong>CUDA 版本</strong> ：<code>cu126</code> 表示使用
<strong>CUDA 12.6</strong> ，适用于 <strong>Turing/Ampere/Ada
Lovelace/Hopper 架构的 GPU</strong> （如 RTX 30/40
系列、A100、H100）。</li>
</ul>
</blockquote>
<h4 id="报错排查">报错排查</h4>
<p>之前由于默认dockerfile内容为<code>FROM lmsysorg/sglang:v0.4.8.post1-cu126</code>报错</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lmsysorg/sglang:v0.4.8.post1-cu126: failed to resolve source metadata for docker.io/lmsysorg/sglang:v0.4.8.post1-cu126: unexpected status from HEAD request to https://yaj2teeh.mirror.aliyuncs.com/v2/lmsysorg/sglang/manifests/v0.4.8.post1-cu126?ns=docker.io: 403 Forbidden</span><br></pre></td></tr></table></figure>
<p>之前以为是sglang版本问题，然后去dockerhub上查找，并通过<code>docker pull sglang:v0.4.8.post1-cu126</code>测试，是可以拉取的，最后认为原因还是网络问题</p>
<p>解决方法，更换了镜像源</p>
<h4 id="镜像源配置">镜像源配置</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;registry-mirrors&quot;: [</span><br><span class="line">  &quot;https://registry.docker-cn.com&quot;,</span><br><span class="line">  &quot;http://hub-mirror.c.163.com&quot;,</span><br><span class="line">  &quot;https://dockerhub.azk8s.cn&quot;,</span><br><span class="line">  &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class="line">  &quot;https://registry.cn-hangzhou.aliyuncs.com&quot;,</span><br><span class="line">  &quot;https://docker.mirrors.ustc.edu.cn&quot;,</span><br><span class="line">  &quot;https://docker.m.daocloud.io&quot;,  </span><br><span class="line">  &quot;https://noohub.ru&quot;, </span><br><span class="line">  &quot;https://huecker.io&quot;,</span><br><span class="line">  &quot;https://dockerhub.timeweb.cloud&quot; </span><br><span class="line"> ]</span><br></pre></td></tr></table></figure>
<p><a href="https://www.bilibili.com/video/BV1xHA3euEcn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">保姆级Docker安装+镜像加速
计算机系必备技能_哔哩哔哩_bilibili</a></p>
<h4 id="为什么要指定基础镜像">为什么要指定基础镜像</h4>
<ul>
<li><strong>提供操作系统和依赖</strong> 基础镜像包含操作系统（如
Ubuntu、Alpine）、运行时环境（如 Python、Node.js）或框架（如
TensorFlow、PyTorch）等核心组件，后续所有操作（如安装依赖、拷贝文件）都基于此环境。
<ul>
<li>例如：<code>FROM python:3.9</code> 提供了 Python 3.9
的运行环境，后续可以直接用 <code>pip install</code> 安装 Python
包。</li>
</ul></li>
<li><strong>避免重复造轮子</strong>
如果直接从空镜像（<code>scratch</code>）开始，需要手动安装所有依赖，效率低下且容易出错。使用现有基础镜像可以复用已验证的环境配置。</li>
</ul>
<h4 id="确认支持的cuda版本">确认支持的cuda版本</h4>
<p>命令<code>nvidia-smi</code></p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250708160948192.png" alt="image-20250708160948192">
<figcaption aria-hidden="true">image-20250708160948192</figcaption>
</figure>
<p><strong>CUDA Version</strong> 显示当前驱动支持的最高 CUDA 版本</p>
<h4 id="问题使用dockerfile直接部署始终出现网络问题">问题：使用dockerfile直接部署，始终出现网络问题</h4>
<p>解决方案</p>
<p>先修改了一下docker储存镜像的位置，太大了</p>
<p>先拉取基础镜像<code>docker pull lmsysorg/sglang:v0.4.8.post1-cu126</code></p>
<p>再使用<code>docker build -t mineru-sglang:latest -f Dockerfile .</code>，可以直接跳过基础镜像的拉取</p>
<h3 id="启动">启动</h3>
<p>官方启动命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name sglang-server \          # 容器命名（便于管理）</span><br><span class="line">  --gpus all \                   # 启用所有GPU</span><br><span class="line">  --shm-size 32g \               # 共享内存大小</span><br><span class="line">  -p 30000:30000 \               # 端口映射（主机端口:容器端口）</span><br><span class="line">  --ipc=host \                   # 共享主机IPC命名空间</span><br><span class="line">  mineru-sglang:latest \</span><br><span class="line">  mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name sglang-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host mineru-sglang:latest mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将mineru-sglang-server暴露到30000端口的作用</p>
<p>为了支持 vlm-sglang-client
后端模式，使得MinerU客户端可以通过网络连接到这个服务器，实现多个客户端可以同时连接到同一个服务器</p>
</blockquote>
<p>使用<code>docker exec -it sglang-server bash</code>命令进入容器</p>
<p>或</p>
<p>使用docker desk</p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250709152627120.png" alt="image-20250709152627120">
<figcaption aria-hidden="true">image-20250709152627120</figcaption>
</figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 -p 7860:7860 -p 8000:8000 --ipc=host \</span><br><span class="line">-v &quot;F:/project python/实习/mineru/demo/pdfs:/pdfs&quot; \</span><br><span class="line">-v &quot;F:/project python/实习/mineru/output:/output&quot; \</span><br><span class="line">mineru-sglang:latest \</span><br><span class="line">mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<p>使用挂载卷启动</p>
<ul>
<li>将本地的PDF文件目录挂载到容器内的 /pdfs 目录</li>
<li>将本地的输出目录挂载到容器内的 /output 目录</li>
<li>把8000，和7860端口暴露，方便调用fastapi与gradio webui 可视化</li>
</ul>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250710100047464.png" alt="image-20250710100047464">
<figcaption aria-hidden="true">image-20250710100047464</figcaption>
</figure>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250710103505453.png" alt="image-20250710103505453">
<figcaption aria-hidden="true">image-20250710103505453</figcaption>
</figure>
<h3 id="调用">调用</h3>
<h4 id="命令行调用sglang-serverclient-模式">命令行调用sglang-server/client
模式</h4>
<p><code>docker exec mineru-server mineru -p /pdfs/demo1.pdf -o /output -b vlm-sglang-client -u http://localhost:30000</code></p>
<p>这条命令在名为 mineru-server 的容器内执行 mineru 工具，处理 /pdfs
目录下的 demo1.pdf 文件，输出结果到 /output 目录，使用 vlm-sglang-client
后端，并连接到 http://localhost:30000 的SGLang服务器。</p>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250710103615272.png" alt="image-20250710103615272">
<figcaption aria-hidden="true">image-20250710103615272</figcaption>
</figure>
<h4 id="fastapi调用与gradio-webui-可视化">fastapi调用与gradio webui
可视化</h4>
<p>在完成docker的端口映射之后，运行<code>mineru-api --host 0.0.0.0 --port 8080</code>启动fastapi服务，</p>
<p>运行<code>mineru-gradio --server-name 0.0.0.0 --server-port 7860</code>启动gradio
webui服务</p>
<p>或<code>mineru-gradio --server-name 0.0.0.0 --server-port 7860 --enable-sglang-engine true</code></p>
<blockquote>
<p>注意，模型下载需要配置环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在容器内设置环境变量</span><br><span class="line">export MINERU_MODEL_SOURCE=modelscope</span><br><span class="line"># 验证环境变量是否设置成功</span><br><span class="line">echo $MINERU_MODEL_SOURCE</span><br></pre></td></tr></table></figure>
</blockquote>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/115678648318f55f1fe3a5baaeac2aaf.png" alt="115678648318f55f1fe3a5baaeac2aaf">
<figcaption aria-hidden="true">115678648318f55f1fe3a5baaeac2aaf</figcaption>
</figure>
<p><strong>在调用过程中关于端口的问题与思考</strong></p>
<p>调用过程中发现，在容器中使用<code>mineru-api --host 127.0.0.1 --port 8000</code>，宿主机无法访问<code>http://127.0.0.1:8000/docs/</code>，经过查询ai，命令改为<code>mineru-api --host 0.0.0.0 --port 8000</code>就可以正常访问，那么关键在于对这两个地址的理解</p>
<blockquote>
<p>查看端口<code>netstat -ano | findstr LISTENING</code></p>
</blockquote>
<p>127.0.0.1与0.0.0.0</p>
<ul>
<li>127.0.0.1 (localhost) ：仅表示本机回环地址，只能在 同一设备内
访问</li>
<li>0.0.0.0 ：表示监听所有可用的网络接口，允许 来自任何地址 的连接</li>
</ul>
<p>当您在Docker容器内运行服务时：</p>
<ol type="1">
<li><p>使用127.0.0.1作为绑定地址 ：</p>
<ul>
<li>服务只接受来自容器内部的连接</li>
<li>即使您映射了端口，宿主机也无法访问该服务</li>
<li>只有容器内的应用程序可以通过 127.0.0.1:端口 访问</li>
</ul></li>
<li><p>使用0.0.0.0作为绑定地址 ：</p>
<ul>
<li>服务接受来自任何网络接口的连接请求</li>
<li>允许从容器外部（包括宿主机）访问该服务</li>
<li>当您映射端口时（如 -p 8000:8000 ），宿主机可以通过 localhost:8000 或
127.0.0.1:8000 访问</li>
</ul></li>
</ol>
<p><strong>为什么需要在容器内使用0.0.0.0</strong></p>
<p>在Docker环境中，容器有自己独立的网络命名空间，这意味着容器内的
127.0.0.1 与宿主机的 127.0.0.1 是完全不同的两个环境。因此：</p>
<ul>
<li>当您在容器内使用 –host 0.0.0.0
启动服务时，该服务会监听容器的所有网络接口</li>
<li>当您在宿主机上访问 127.0.0.1:映射端口
时，Docker会将请求转发到容器内监听在 0.0.0.0:容器端口 的服务</li>
</ul>
<h3 id="参数">参数</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Usage: mineru [OPTIONS]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -v, --version                   显示版本并退出</span><br><span class="line">  -p, --path PATH                 输入文件路径或目录（必填）</span><br><span class="line">  -o, --output PATH               输出目录（必填）</span><br><span class="line">  -m, --method [auto|txt|ocr]     解析方法：auto（默认）、txt、ocr（仅用于 pipeline 后端）</span><br><span class="line">  -b, --backend [pipeline|vlm-transformers|vlm-sglang-engine|vlm-sglang-client]</span><br><span class="line">                                  解析后端（默认为 pipeline）</span><br><span class="line">  -l, --lang [ch|ch_server|ch_lite|en|korean|japan|chinese_cht|ta|te|ka|latin|arabic|east_slavic|cyrillic|devanagari]</span><br><span class="line">                                  指定文档语言（可提升 OCR 准确率，仅用于 pipeline 后端）</span><br><span class="line">  -u, --url TEXT                  当使用 sglang-client 时，需指定服务地址</span><br><span class="line">  -s, --start INTEGER             开始解析的页码（从 0 开始）</span><br><span class="line">  -e, --end INTEGER               结束解析的页码（从 0 开始）</span><br><span class="line">  -f, --formula BOOLEAN           是否启用公式解析（默认开启）</span><br><span class="line">  -t, --table BOOLEAN             是否启用表格解析（默认开启）</span><br><span class="line">  -d, --device TEXT               推理设备（如 cpu/cuda/cuda:0/npu/mps，仅 pipeline 后端）</span><br><span class="line">  --vram INTEGER                  单进程最大 GPU 显存占用(GB)（仅 pipeline 后端）</span><br><span class="line">  --source [huggingface|modelscope|local]</span><br><span class="line">                                  模型来源，默认 huggingface</span><br><span class="line">  --help                          显示帮助信息</span><br></pre></td></tr></table></figure>
<h4 id="后端的区别">后端的区别</h4>
<p>pipeline (默认后端) :</p>
<ul>
<li>含义 : 这是 MinerU 的默认后端，它使用本地安装的 mineru
库来执行文档解析任务。它通常不依赖于外部的
VLM（视觉语言模型）服务，而是直接在本地处理 PDF 文件。</li>
</ul>
<p>vlm-transformers :</p>
<ul>
<li>含义 : 这个后端利用 Hugging Face transformers 库中提供的 VLM
模型进行文档分析。它会在本地加载并运行一个基于 transformers 的 VLM
模型来处理 PDF 中的视觉信息和文本内容。</li>
</ul>
<blockquote>
<p>VLM（Vision-Language
Model，视觉语言模型）是一种结合计算机视觉和自然语言处理能力的多模态人工智能模型。</p>
<p>OCR 是 Optical Character
Recognition（光学字符识别）的缩写。它是一种技术，用于将图像中的手写、打印或打字文本转换为机器编码的文本，使其可以被计算机编辑、搜索、存储和处理。</p>
</blockquote>
<p>vlm-sglang-engine :</p>
<ul>
<li>含义 : 这个后端表示 MinerU 将直接集成并使用 SGLang 引擎进行 VLM
推理。SGLang 是一个高性能的推理引擎，旨在优化大型语言模型（LLM）和 VLM
的推理速度和效率。在这种模式下，SGLang 引擎作为 MinerU
进程的一部分运行。</li>
</ul>
<p>vlm-sglang-client :</p>
<ul>
<li>含义 : 这个后端表示 MinerU 作为 SGLang
服务器的客户端。在这种模式下，MinerU 不会直接运行 VLM 模型，而是将 PDF
处理请求发送到一个独立的 SGLang 服务器（通过 -u 参数指定的 URL，例如
http://localhost:30000 ）。SGLang 服务器负责执行实际的 VLM
推理，并将结果返回给 MinerU 客户端。</li>
</ul>
<blockquote>
<p>用场景 : 这是我们之前讨论的 Docker
容器部署场景中推荐的模式。它非常适合以下情况： - 资源隔离 : 将 VLM
推理的计算密集型任务从 MinerU 主进程中分离出来，允许独立扩展和管理
SGLang 服务器。 - 集中管理 : 可以在一个或多个 SGLang 服务器上集中管理
VLM 模型，供多个 MinerU 客户端共享使用。 - 性能优化 : SGLang
服务器可以针对 VLM 推理进行专门优化，提供更好的吞吐量和延迟。 - 灵活部署
: SGLang
服务器可以部署在不同的机器上，甚至作为微服务运行，提供更大的部署灵活性。</p>
</blockquote>
<h3 id="资料">资料</h3>
<p><a href="https://blog.csdn.net/liuzhenghua66/article/details/148980203">MinerU
2.0部署-CSDN博客</a></p>
<p>https://github.com/opendatalab/MinerU?tab=readme-ov-file#local-deployment</p>
<p>https://deepwiki.com/opendatalab/MinerU</p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>实习</tag>
        <tag>MineU</tag>
      </tags>
  </entry>
  <entry>
    <title>prompt Engineering与context Engineering</title>
    <url>/2025/07/13/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/prompt%20Engineering%E4%B8%8Econtext%20Engineering/</url>
    <content><![CDATA[<h3 id="prompt-engineering">prompt Engineering</h3>
<p>Prompt
Engineering是与大型语言模型（LLM）交互的基础，其核心在于精心设计输入内容，以引导模型生成期望的输出。</p>
<p>尽管 Prompt Engineering
至关重要，但对于构建稳健、可用于生产环境的系统而言，它存在固有的局限性：</p>
<ul>
<li><p><strong>脆弱性&amp;不可复现性：</strong>
提示中微小的措辞变化可能导致输出结果的巨大差异，使得这一过程更像是一种依赖反复试错的“艺术”，而非可复现的“科学”
。</p></li>
<li><p><strong>扩展性差：</strong>
手动、迭代地优化提示的过程，在面对大量用户、多样化用例和不断出现的边缘情况时，难以有效扩展
。</p></li>
<li><p><strong>用户负担：</strong>
这种方法将精心构建一套详尽指令的负担完全压在了用户身上，对于需要自主运行、或处理高并发请求的系统而言是不切实际的
。</p></li>
<li><p><strong>无状态性：</strong> Prompt Engineering
本质上是为单轮、“一次性”的交互而设计的，难以处理需要记忆和状态管理的长对话或多步骤任务
。</p></li>
</ul>
<h3 id="context-engineering">Context Engineering</h3>
<p><strong>Context
Engineering是一门设计、构建并优化动态自动化系统的学科，旨在为大型语言模型在正确的时间、以正确的格式，提供正确的信息和工具，从而可靠、可扩展地完成复杂任务</strong>
。</p>
<p><strong>prompt 告诉模型如何思考，而 Context
则赋予模型完成工作所需的知识和工具。</strong></p>
<ul>
<li><p>Context Engineering 决定<strong>用什么内容填充 Context
Window</strong> ，</p></li>
<li><p>Prompt Engineering 则负责优化<strong>窗口内的具体指令</strong>
。</p></li>
</ul>
<h3 id="context-engineering-的基石ragretrieval-augmented-generation">Context
Engineering 的基石：RAG（Retrieval-Augmented Generation）</h3>
<p>本部分将阐述检索增强生成（RAG）作为实现 Context Engineering
的主要架构模式。</p>
<h4 id="解决llm的核心弱点">解决LLM的核心弱点</h4>
<p>RAG直接解决了标准LLM在企业应用中存在的固有局限性：</p>
<ul>
<li><p><strong>知识冻结：</strong>
LLM的知识被冻结在<strong>其训练数据的时间点</strong>。RAG通过在推理时注入实时的、最新的信息来解决这个问题
。</p></li>
<li><p><strong>缺乏领域专有知识：</strong>
标准LLM无法访问组织的内部私有数据。RAG则能够将LLM连接到这些内部知识库，如技术手册、政策文件等
。</p></li>
<li><p><strong>幻觉（Hallucination）：</strong> LLM
会不同程度上地编造事实。RAG通过将模型的回答“锚定”在可验证的、检索到的证据上，提高事实的准确性和可信度
。</p></li>
</ul>
<h4 id="rag工作流">RAG工作流</h4>
<ol type="1">
<li><p><strong>索引（离线阶段）：</strong>
在这个阶段，系统会处理外部知识源。文档被加载、分割成更小的
chunks，然后通过Embedding Model
转换为向量表示，并最终存储在专门的向量数据库中以备检索 。</p></li>
<li><p><strong>推理（在线阶段）：</strong>
当用户提出请求时，系统执行以下步骤：</p>
<ol type="1">
<li><strong>检索（Retrieve）：</strong>
将用户的查询同样转换为向量，然后在向量数据库中进行相似性搜索，找出与查询最相关的文档块。</li>
<li><strong>增强（Augment）：</strong>
将检索到的这些文档块与原始的用户查询、系统指令等结合起来，构建一个内容丰富的、增强的最终提示。</li>
<li><strong>生成（Generate）：</strong>
将这个增强后的提示输入给LLM，LLM会基于提供的上下文生成一个有理有据的回答
。</li>
</ol></li>
</ol>
<h3 id="context-工程化如何判断和提取哪些内容应该进入上下文">Context
工程化：如何判断和提取哪些内容应该进入上下文？</h3>
<h4 id="chunking">1.chunking</h4>
<p>文本分块（Chunking）是RAG流程中最关键也最容易被忽视的一步。其目标是创建在语义上自成一体的文本块。</p>
<h4 id="reranking">2.Reranking</h4>
<p>为了平衡检索的速度和准确性，业界普遍采用两阶段检索流程。</p>
<ul>
<li><p><strong>两阶段流程：</strong></p>
<ul>
<li><strong>第一阶段（召回）：</strong>
使用一个快速、高效的检索器（如基于 bi-encoder
的向量搜索或BM25等词法搜索）进行广泛撒网，召回一个较大的候选文档集（例如，前100个）
。</li>
<li><strong>第二阶段（精排/重排序）：</strong>
使用一个更强大但计算成本更高的模型，对这个较小的候选集进行重新评估，以识别出最相关的少数几个文档（例如，前5个）
。</li>
</ul></li>
<li><p><strong>Cross-Encoder：</strong>
交叉编码器之所以在重排序阶段表现优越，是因为它与双编码器的工作方式不同。双编码器独立地为查询和文档生成嵌入向量，然后计算它们的相似度。而交叉编码器则是将查询和文档<strong>同时</strong>作为输入，让模型在内部通过
Attention Mechanism
对二者进行深度交互。这使得模型能够捕捉到更细微的语义关系，从而给出更准确的相关性评分
。</p></li>
<li><p><strong>实际影响：</strong>
重排序显著提高了最终送入LLM的上下文质量，从而产出更准确、幻觉更少的答案。在金融、法律等高风险领域，重排序被认为是必不可少而非可选的步骤
。</p></li>
</ul>
<h4 id="优化上下文窗口压缩与摘要">3.优化上下文窗口：压缩与摘要</h4>
<p>本节详细介绍用于主动管理上下文的技术，确保最有价值的信息被优先呈现。</p>
<ul>
<li><p><strong>上下文压缩的目标：</strong>
缩短检索到的文档列表和/或精简单个文档的内容，只将<strong>最相关的信息传递给LLM</strong>。这能有效降低API调用成本、减少延迟，并缓解
Lost in the Middle 的问题 。</p></li>
<li><p><strong>压缩方法：</strong></p>
<ul>
<li><strong>过滤式压缩：</strong>
这类方法决定是保留还是丢弃整个检索到的文档。
<ul>
<li><strong>LLMChainFilter：</strong>
利用一个LLM对每个文档的相关性做出简单的“是/否”判断 。</li>
<li><strong>EmbeddingsFilter：</strong>
更经济快速的方法，根据文档嵌入与查询嵌入的余弦相似度来过滤文档 。</li>
</ul></li>
<li><strong>内容提取式压缩：</strong> 这类方法会直接修改文档内容。
<ul>
<li><strong>LLMChainExtractor：</strong>
遍历每个文档，并使用LLM从中提取仅与查询相关的句子或陈述 。</li>
</ul></li>
<li><strong>用 top N 代替压缩：</strong>
像LLMListwiseRerank这样的技术，使用LLM对检索到的文档进行重排序，并只返回排名最高的N个，从而起到高质量过滤器的作用
。</li>
</ul></li>
<li><p><strong>作为压缩策略的摘要：</strong>
对于非常长的文档或冗长的对话历史，可以利用LLM生成摘要。这些摘要随后被注入上下文，既保留了关键信息，又大幅减少了
Token 数量。这是在长时程运行的智能体中管理上下文的关键技术 。</p></li>
</ul>
<h3 id="智能体架构中的数据流与工作流编排">智能体架构中的数据流与工作流编排</h3>
<h4 id="工作流workflow-vs.-智能体agent">工作流（Workflow）
vs. 智能体（Agent）</h4>
<ul>
<li><strong>工作流（Workflows）</strong>
<ul>
<li>指的是LLM和工具通过<strong>预定义的代码路径</strong>进行编排的系统。在这种模式下，数据流动的路径是固定的、由开发者明确设计的，类似于上世纪流行的“专家系统”。例如，“第一步：分析用户邮件；第二步：根据分析结果在日历中查找空闲时段；第三步：起草会议邀请邮件”。这种模式确定性高，易于调试和控制，非常适合有明确业务流程的场景（如风控需求高、数据敏感、安全等级要求）。</li>
</ul></li>
<li><strong>智能体（Agents）</strong>
<ul>
<li>指的是LLM<strong>动态地指导</strong>自己的流程和工具使用，自主控制如何完成任务的系统。在这种模式下，数据流动的路径不是预先固定的，而是由LLM在每一步根据当前情况和目标动态决定的。这种模式灵活性高，能处理开放式问题，但可控性和可预测性较低
。</li>
</ul></li>
</ul>
<p>复杂的智能体通常是这两种模式的混合体，在宏观层面遵循一个预定义的工作流，但在某些节点内部，又赋予LLM一定的自主决策权。管理这一切的核心，我们称之为<strong>编排层（Orchestration
Layer）</strong> 。</p>
<h4 id="核心架构预定义数据流的实现"><strong>核心架构：预定义数据流的实现</strong></h4>
<ol type="1">
<li><p><strong>链式工作流（Prompt Chaining）</strong></p></li>
<li><p><strong>路由工作流（Routing)</strong></p></li>
<li><p><strong>编排器-工作者模式（Orchestrator-Workers）</strong></p></li>
</ol>
<h4 id="框架与工具">框架与工具</h4>
<p>上述的架构和机制并非凭空存在，而是通过具体的开发框架实现的。其中，LangGraph作为LangChain的扩展，为构建具有显式数据流的智能体系统提供了强大的工具集。</p>
<p><strong>LangGraph：用图（Graph）定义工作流（Workflow）</strong></p>
<p>LangGraph的核心思想是将智能体应用构建成一个<strong>状态图（State
Graph）</strong>
。这个图由节点和边组成，清晰地定义了数据如何在不同模块间流动</p>
<ul>
<li><strong>状态（State）：</strong>
这是整个图的核心，一个所有节点共享的中央数据对象。
<ul>
<li>你可以把它想象成一个“数据总线”或共享内存。开发者需要预先定义State的结构，每个节点在执行时都可以读取和更新这个State对象
。</li>
</ul></li>
<li><strong>节点（Nodes）：</strong>
代表工作流中的一个计算单元或一个步骤。
<ul>
<li>每个节点通常是一个Python函数，它接收当前的State作为输入，执行特定任务（如调用LLM、执行工具、处理数据），然后返回对State的更新
。</li>
</ul></li>
<li><strong>边（Edges）</strong>：
连接节点，定义了工作流的路径，即数据在State更新后应该流向哪个节点。
<ul>
<li><strong>简单边（Simple Edges）：</strong>
定义了固定的、无条件的流向，用于实现链式工作流 。</li>
<li><strong>条件边（Conditional Edges）：</strong>
用于实现路由逻辑。它会根据一个函数的输出来决定接下来应该走向哪个节点，从而实现流程的分支
。</li>
</ul></li>
<li><strong>检查点（Checkpointer）：</strong>
LangGraph提供了持久化机制，可以在每一步执行后自动保存State的状态。这对于构建需要长期记忆、可中断和恢复、或需要
Human-in-the-Loop 的复杂业务流程至关重要 。</li>
</ul>
<p>复杂业务流程的AI智能体，其核心挑战已从单纯优化信息检索（如RAG）或提示词，转向了对内部<strong>工作流和数据流的精心设计与编排</strong>。</p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>学习</tag>
        <tag>实习</tag>
        <tag>rag</tag>
        <tag>prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>chunk分块策略</title>
    <url>/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<h3 id="分块策略">分块策略</h3>
<p>以下是 RAG 应用程序的典型工作流程：</p>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/6878b8fa-5e74-45a1-9a89-5aab92889126_2366x990.gif" alt="6878b8fa-5e74-45a1-9a89-5aab92889126_2366x990">
<figcaption aria-hidden="true">6878b8fa-5e74-45a1-9a89-5aab92889126_2366x990</figcaption>
</figure>
<p>主流主要有五种分块策略：</p>
<figure>
<img src="https___substack-post-media.s3.amazonaws.com_public_images_92c70184-ba0f-4877-9a55-e4add0e311ad_870x1116.gif" alt="https___substack-post-media.s3.amazonaws.com_public_images_92c70184-ba0f-4877-9a55-e4add0e311ad_870x1116">
<figcaption aria-hidden="true">https___substack-post-media.s3.amazonaws.com_public_images_92c70184-ba0f-4877-9a55-e4add0e311ad_870x1116</figcaption>
</figure>
<h4 id="fixed-size-chunking-固定大小的分块">Fixed-size chunking
固定大小的分块</h4>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/98c422a0-f0e2-457c-a256-4476a56a601f_943x232.png" alt="98c422a0-f0e2-457c-a256-4476a56a601f_943x232">
<figcaption aria-hidden="true">98c422a0-f0e2-457c-a256-4476a56a601f_943x232</figcaption>
</figure>
<p>将文本以固定长度分块，overlap为每个块的重合程度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">text = <span class="string">&quot;大家好，我是果粒奶优有果粒，欢迎关注我，让我们一起探索AI。&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> CharacterTextSplitter</span><br><span class="line"></span><br><span class="line">text_splitter = CharacterTextSplitter(</span><br><span class="line">    separator=<span class="string">&quot;&quot;</span>,<span class="comment">#按字切分</span></span><br><span class="line">    chunk_size=<span class="number">5</span>,</span><br><span class="line">    chunk_overlap=<span class="number">1</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span>,<span class="comment">#以长度计算</span></span><br><span class="line">    is_separator_regex=<span class="literal">False</span>,<span class="comment">#不视为正则表达式</span></span><br><span class="line">)</span><br><span class="line">text_splitter.split_text(text)</span><br></pre></td></tr></table></figure>
<h4 id="semantic-chunking-语义分块">Semantic chunking 语义分块</h4>
<figure>
<img src="https___substack-post-media.s3.amazonaws.com_public_images_a6ad83a6-2879-4c77-9e49-393f16577aef_1066x288.gif" alt="https___substack-post-media.s3.amazonaws.com_public_images_a6ad83a6-2879-4c77-9e49-393f16577aef_1066x288">
<figcaption aria-hidden="true">https___substack-post-media.s3.amazonaws.com_public_images_a6ad83a6-2879-4c77-9e49-393f16577aef_1066x288</figcaption>
</figure>
<p>先将文本分段，然后为每个段进行嵌入，若两个段有较高的余弦相似度，则合并成一个块，一直合并到余弦相似度显著下降，再从新的块开始</p>
<p>需要设定阈值来确定余弦相似度是否显著下降，这因文档而异。</p>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/image-20250710150106274.png" alt="image-20250710150106274">
<figcaption aria-hidden="true">image-20250710150106274</figcaption>
</figure>
<p>具体实现思路：利用滑动窗口，从第一句往后移动滑动窗口，如图，emed1与emed2相差sen3，计算出来的distance决定sen3是否加入chunk1，以此类推</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#利用langchain调用</span></span><br><span class="line"><span class="keyword">from</span> langchain_experimental.text_splitter <span class="keyword">import</span> SemanticChunker</span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> DashScopeEmbeddings</span><br><span class="line">embeddings_model = DashScopeEmbeddings(</span><br><span class="line">        model=<span class="string">&quot;text-embedding-v2&quot;</span>,</span><br><span class="line">        dashscope_api_key=<span class="string">&quot;&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">semantic_chunk=SemanticChunker(</span><br><span class="line">    embeddings=embeddings_model,<span class="comment">#嵌入模型</span></span><br><span class="line">    breakpoint_threshold_type=<span class="string">&quot;percentile&quot;</span>,<span class="comment">#定义如何计算语义断点阈值</span></span><br><span class="line">    breakpoint_threshold_amount=<span class="number">95</span>,<span class="comment">#设定阈值</span></span><br><span class="line">    <span class="comment">#min_chunk_size=500#限制生成块最小的字符数，避免生成无意义的块</span></span><br><span class="line">    sentence_split_regex=<span class="string">r&#x27;[。！？.\n]&#x27;</span>,<span class="comment">#语句切分</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>源代码理解见最后</p>
<h4 id="recursive-chunking-递归分块">Recursive chunking 递归分块</h4>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/f4009caa-34fc-48d6-8102-3d0f6f2c1386_1066x316.gif" alt="f4009caa-34fc-48d6-8102-3d0f6f2c1386_1066x316">
<figcaption aria-hidden="true">f4009caa-34fc-48d6-8102-3d0f6f2c1386_1066x316</figcaption>
</figure>
<p>先依据大的段落进行分块，再对每个块进行处理，若符合chunk-size的限制，则不会再分</p>
<p>结果可能如下</p>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/b0e40cc1-996f-48f4-9306-781b112536e4_984x428.png" alt="b0e40cc1-996f-48f4-9306-781b112536e4_984x428">
<figcaption aria-hidden="true">b0e40cc1-996f-48f4-9306-781b112536e4_984x428</figcaption>
</figure>
<p>首先，我们定义两个块（紫色的两个段落。接下来，第1段进一步拆分为更小的块。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">recursive_splitter_chinese = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">50</span>,</span><br><span class="line">    chunk_overlap=<span class="number">10</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span>,</span><br><span class="line">    separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;。&quot;</span>, <span class="string">&quot;，&quot;</span>, <span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>]<span class="comment">#中文的分隔符，可以用逗号句号</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="document-structure-based-chunking-基于文档结构的分块">Document
structure-based chunking 基于文档结构的分块</h4>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/e8febecd-ee68-42ff-ab06-41a0a3a43cd3_1102x306.gif" alt="e8febecd-ee68-42ff-ab06-41a0a3a43cd3_1102x306">
<figcaption aria-hidden="true">e8febecd-ee68-42ff-ab06-41a0a3a43cd3_1102x306</figcaption>
</figure>
<p>根据文档的固有结构进行分块，如markdown的一级标题二级标题等</p>
<p><code>langchain.text_splitter</code>中有两个用于md文档分块的类，<code>MarkdownTextSplitter</code>与<code>MarkdownHeaderTextSplitter</code></p>
<p>二者区别主要在：前者继承于<code>RecursiveCharacterTextSplitter</code>递归分块，它会尝试沿着
Markdown
格式的标题进行分割，但其核心仍然是基于字符的递归分割；后者专注于 基于
Markdown 标题的结构化分割 ，并能将标题信息作为元数据保留，更适合需要保持
Markdown 文档层级结构的应用场景。</p>
<p>需要注意的是<code>MarkdownHeaderTextSplitter</code>
本身不直接提供限制块内容长度的参数，但可以通过与
<code>RecursiveCharacterTextSplitter</code>
等其他文本分割器结合使用来有效控制块的大小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> MarkdownHeaderTextSplitter</span><br><span class="line">headers_to_split_on = [</span><br><span class="line">    (<span class="string">&quot;#&quot;</span>, <span class="string">&quot;Header 1&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;##&quot;</span>, <span class="string">&quot;Header 2&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;###&quot;</span>, <span class="string">&quot;Header 3&quot;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)</span><br><span class="line">md_header_splits = markdown_splitter.split_text(markdown_document)</span><br></pre></td></tr></table></figure>
<p>存储结构类似如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Document(metadata=&#123;&#x27;Header 1&#x27;: &#x27;Foo&#x27;, &#x27;Header 2&#x27;: &#x27;Bar&#x27;&#125;, page_content=&#x27;Hi this is Jim  \nHi this is Joe&#x27;),</span><br><span class="line"> Document(metadata=&#123;&#x27;Header 1&#x27;: &#x27;Foo&#x27;, &#x27;Header 2&#x27;: &#x27;Bar&#x27;, &#x27;Header 3&#x27;: &#x27;Boo&#x27;&#125;, page_content=&#x27;Hi this is Lance&#x27;),</span><br><span class="line"> Document(metadata=&#123;&#x27;Header 1&#x27;: &#x27;Foo&#x27;, &#x27;Header 2&#x27;: &#x27;Baz&#x27;&#125;, page_content=&#x27;Hi this is Molly&#x27;)]</span><br></pre></td></tr></table></figure>
<h4 id="llm-based-chunking-基于-llm-的分块">LLM-based chunking 基于 LLM
的分块</h4>
<figure>
<img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/4d1b6d60-8956-4030-8525-d899ee61a9d5_1140x198.gif" alt="4d1b6d60-8956-4030-8525-d899ee61a9d5_1140x198">
<figcaption aria-hidden="true">4d1b6d60-8956-4030-8525-d899ee61a9d5_1140x198</figcaption>
</figure>
<p>利用大模型进行分块</p>
<p>langchain没有提供官方的类实现LLM-based chunking</p>
<p>但是我在找到了别人实现的agentic_chunker<a href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/agentic_chunker.py">RetrievalTutorials/tutorials/LevelsOfTextSplitting/agentic_chunker.py
at main · FullStackRetrieval-com/RetrievalTutorials</a>，可供参考</p>
<h3 id="embedding">embedding</h3>
<p>之前对chunking和embedding的理解不够清晰，chunking是对文本进行分块，由于大多数文本嵌入模型对输入文本长度有严格限制，如果不分块则无法embedding，从而无法更好的进行向量化或者更好地储存在知识库中，提升retriever性能；embedding则是将文本映射到向量空间，为了更好的相似度计算</p>
<h3 id="语义分块的源代码实战">语义分块的源代码实战</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将文本划分成单句，可以按照标点符号划分</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">single_sentences_list = re.split(<span class="string">r&#x27;(?&lt;=[。！？])&#x27;</span>, essay)</span><br><span class="line"><span class="comment"># 移除可能存在的空字符串</span></span><br><span class="line">single_sentences_list = [s.strip() <span class="keyword">for</span> s <span class="keyword">in</span> single_sentences_list <span class="keyword">if</span> s.strip()]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">我们需要为单个句子拼接更多的句子，但是 `list` 添加比较困难。因此将其转换为字典列（`List[dict]`）</span></span><br><span class="line"><span class="string">&#123; &#x27;sentence&#x27; : XXX  , &#x27;index&#x27; : 0&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sentences = [&#123;<span class="string">&#x27;sentence&#x27;</span>: x, <span class="string">&#x27;index&#x27;</span> : i&#125; <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(single_sentences_list)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用滑动窗口分段</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">combine_sentences</span>(<span class="params">sentences, buffer_size=<span class="number">1</span></span>):</span><br><span class="line">    combined_sentences = [</span><br><span class="line">        <span class="string">&#x27; &#x27;</span>.join(sentences[j][<span class="string">&#x27;sentence&#x27;</span>] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">max</span>(i - buffer_size, <span class="number">0</span>), <span class="built_in">min</span>(i + buffer_size + <span class="number">1</span>, <span class="built_in">len</span>(sentences))))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences))</span><br><span class="line">    ]   </span><br><span class="line">    <span class="comment"># 更新原始字典列表，添加组合后的句子</span></span><br><span class="line">    <span class="keyword">for</span> i, combined_sentence <span class="keyword">in</span> <span class="built_in">enumerate</span>(combined_sentences):</span><br><span class="line">        sentences[i][<span class="string">&#x27;combined_sentence&#x27;</span>] = combined_sentence</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sentences</span><br><span class="line"></span><br><span class="line">sentences = combine_sentences(sentences)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">接下来使用**embedding model**对**sentences** 进行编码</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> DashScopeEmbeddings</span><br><span class="line">embeddings_model = DashScopeEmbeddings(</span><br><span class="line">        model=<span class="string">&quot;text-embedding-v2&quot;</span>,</span><br><span class="line">        dashscope_api_key=<span class="string">&quot;&quot;</span>,</span><br><span class="line"></span><br><span class="line">    )</span><br><span class="line"><span class="comment"># 提取所有组合后的句子用于 embedding</span></span><br><span class="line">combined_sentences_to_embed = [x[<span class="string">&#x27;combined_sentence&#x27;</span>] <span class="keyword">for</span> x <span class="keyword">in</span> sentences]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对句子进行 embedding</span></span><br><span class="line">embeddings = embeddings_model.embed_documents(combined_sentences_to_embed)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;成功对 <span class="subst">&#123;<span class="built_in">len</span>(embeddings)&#125;</span> 个句子进行了 embedding。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将embedding添加到sentence中</span></span><br><span class="line"><span class="keyword">for</span> i, sentence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentences):</span><br><span class="line">    sentence[<span class="string">&#x27;combined_sentence_embedding&#x27;</span>] = embeddings[i]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">接下来需要根据余弦相似度进行切分</span></span><br><span class="line"><span class="string">通过计算两个向量的夹角余弦值来衡量相似性</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cosine_similarity</span>(<span class="params">vec1, vec2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Calculate the cosine similarity between two vectors.&quot;&quot;&quot;</span></span><br><span class="line">    dot_product = np.dot(vec1, vec2)</span><br><span class="line">    norm_vec1 = np.linalg.norm(vec1)</span><br><span class="line">    norm_vec2 = np.linalg.norm(vec2)</span><br><span class="line">    <span class="keyword">return</span> dot_product / (norm_vec1 * norm_vec2)</span><br><span class="line"><span class="comment">#遍历，计算余弦相似度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_cosine_distances</span>(<span class="params">sentences</span>):</span><br><span class="line">    distances = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences) - <span class="number">1</span>):</span><br><span class="line">        embedding_current = sentences[i][<span class="string">&#x27;combined_sentence_embedding&#x27;</span>]</span><br><span class="line">        embedding_next = sentences[i + <span class="number">1</span>][<span class="string">&#x27;combined_sentence_embedding&#x27;</span>]</span><br><span class="line">        <span class="comment"># Calculate cosine similarity</span></span><br><span class="line">        similarity = cosine_similarity(embedding_current, embedding_next)</span><br><span class="line">        <span class="comment"># Convert to cosine distance</span></span><br><span class="line">        distance = <span class="number">1</span> - similarity</span><br><span class="line">        distances.append(distance)</span><br><span class="line">        <span class="comment"># Store distance in the dictionary</span></span><br><span class="line">        sentences[i][<span class="string">&#x27;distance_to_next&#x27;</span>] = distance</span><br><span class="line">    <span class="keyword">return</span> distances, sentences</span><br><span class="line"></span><br><span class="line">distances, sentences = calculate_cosine_distances(sentences)</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据阈值划分</span></span><br><span class="line">breakpoint_percentile_threshold = <span class="number">95</span></span><br><span class="line">breakpoint_distance_threshold = np.percentile(distances, breakpoint_percentile_threshold)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;距离的第95个百分位阈值是:&quot;</span>, breakpoint_distance_threshold)</span><br><span class="line"><span class="comment"># 找到所有距离大于阈值的点的索引，这些索引就是我们的切分点</span></span><br><span class="line">indices_above_thresh = [i <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(distances) <span class="keyword">if</span> x &gt; breakpoint_distance_threshold]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化块的起始句子索引。我们将根据之前计算出的语义分割点（`indices_above_thresh`）来切分句子列表。</span></span><br><span class="line">start_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个列表，用于存储最终组合成的、具有语义连贯性的文本块。</span></span><br><span class="line">chunks = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有识别出的语义分割点（这些是句子列表 `sentences` 中的索引）。</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> indices_above_thresh:</span><br><span class="line">    <span class="comment"># 确定当前文本块的结束点，即当前的分割点索引。</span></span><br><span class="line">    end_index = index</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从原始句子列表（`sentences`）中切片，提取从上一个分割点到当前分割点之间的所有句子。</span></span><br><span class="line">    <span class="comment"># `end_index + 1` 是为了在切片时包含结束索引指向的那个句子。</span></span><br><span class="line">    group = sentences[start_index:end_index + <span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将切分出的句子组（`group`）中的所有 &#x27;sentence&#x27; 字段的值合并成一个单独的字符串，句子之间用空格隔开。</span></span><br><span class="line">    combined_text = <span class="string">&#x27; &#x27;</span>.join([d[<span class="string">&#x27;sentence&#x27;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> group])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将合并后的文本块添加到 `chunks` 列表中。</span></span><br><span class="line">    chunks.append(combined_text)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新下一个文本块的起始索引，设置为当前分割点的下一个位置，为处理下一个块做准备。</span></span><br><span class="line">    start_index = index + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理最后一个文本块。</span></span><br><span class="line"><span class="comment"># 循环结束后，如果 `start_index` 仍然小于句子总数，说明从最后一个分割点到文本末尾还有剩余的句子。</span></span><br><span class="line"><span class="keyword">if</span> start_index &lt; <span class="built_in">len</span>(sentences):</span><br><span class="line">    <span class="comment"># 将这些剩余的句子合并成最后一个文本块。</span></span><br><span class="line">    combined_text = <span class="string">&#x27; &#x27;</span>.join([d[<span class="string">&#x27;sentence&#x27;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> sentences[start_index:]])</span><br><span class="line">    chunks.append(combined_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时，`chunks` 列表包含了所有根据语义距离切分和重组后的文本块。</span></span><br><span class="line"><span class="keyword">for</span> i, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(chunks):</span><br><span class="line">    buffer = <span class="number">200</span></span><br><span class="line">    <span class="built_in">print</span> (<span class="string">f&quot;Chunk #<span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span> (chunk[:buffer].strip())</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;...&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span> (chunk[-buffer:].strip())</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.dailydoseofds.com/p/5-chunking-strategies-for-rag/">RAG
的 5 种分块策略 — 5 Chunking Strategies For RAG</a></p>
<p><a href="https://blog.csdn.net/wjinjie/article/details/148660229">一文读懂
Qwen3 最新开源的 Embedding 和 Rerank
模型优势！_qwen-rerank-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1dr421x7Su/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">一站帮你选择RAG中的文本切分策略_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/The_Thieves/article/details/148747334">LangChain
语义文本拆分指南：基于语义相似度的智能分块技术实战_langchain
语义分割-CSDN博客</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>学习</tag>
        <tag>实习</tag>
        <tag>rag</tag>
        <tag>chunk</tag>
      </tags>
  </entry>
  <entry>
    <title>rag评估</title>
    <url>/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/</url>
    <content><![CDATA[<h3 id="rag评估的指标">rag评估的指标</h3>
<h4 id="忠诚度faithfulness">忠诚度Faithfulness</h4>
<p>Faithfulness：衡量生成答案与给定上下文之间的事实一致性。忠实度得分是基于答案和检索到的上下文
计算出来的，答案的评分范围在0到1之间，分数越高越好。</p>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711154457878.png" alt="image-20250711154457878">
<figcaption aria-hidden="true">image-20250711154457878</figcaption>
</figure>
<p>计算方式：将大模型给出的答案进行切片，检索给出的上下文，计算这些切片是否在上下文中</p>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711155257239.png" alt="image-20250711155257239">
<figcaption aria-hidden="true">image-20250711155257239</figcaption>
</figure>
<h4 id="答案相关性answerrelevance">答案相关性Answerrelevance</h4>
<p>Answerrelevance：答案相关性的评估指标旨在评估生成的答案与给定提示的相关程度。如果答案不完
整或包含冗余信息，则会被赋予较低的分数。这个指标使用问题和答案来计算，其值介于0到1之间，得
分越高表明答案的相关性越好</p>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711155128553.png" alt="image-20250711155128553">
<figcaption aria-hidden="true">image-20250711155128553</figcaption>
</figure>
<p>计算方式：根据答案生成多个问题，然后计算生成的答案与原答案的余弦相似度，再取平均</p>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711155407518.png" alt="image-20250711155407518">
<figcaption aria-hidden="true">image-20250711155407518</figcaption>
</figure>
<h4 id="上下文精确度contextprecision">上下文精确度ContextPrecision</h4>
<p>ContextPrecision：上下文精确度衡量上下文中所有相关的真实信息是否被排在了较高的位置。理想情
况下，所有相关的信息块都应该出现在排名的最前面。这个指标是根据问题和上下文来计算的，数值范
围在0到1之间，分数越高表示精确度越好。 <span class="math display">$$
\text{Context Precision} = \frac{\sum_{k=1}^{K} (\text{rel}(k) \times
\frac{\text{Precision@k}}{\text{Ideal Precision@k}})}{\text{Total
Relevant Documents}}
$$</span></p>
<ul>
<li><code>K</code>：检索返回的文档总数（如 top-5）</li>
<li><code>rel(k)</code>：第 <code>k</code>
个文档是否相关（相关=1，无关=0）</li>
<li><code>Precision@k</code>：前 <code>k</code>
个文档的精确率（相关文档数 / k）</li>
<li><code>Ideal Precision@k</code>：理想情况下前 <code>k</code>
个文档的精确率（假设所有相关文档都排在最前面）</li>
</ul>
<h4 id="上下文召回率contextrecall">上下文召回率ContextRecall</h4>
<p>ContextRecall：用来衡量检索到的上下文与被视为事实真相的标注答案的一致性程度。它根据事实真相
和检索到的上下文来计算，数值范围在0到1之间，数值越高表示性能越好。
为了从事实真相的答案中估计上下文召回率，需要分析答案中的每个句子是否可以归因于检索到的
上下文。在理想情况下，事实真相答案中的所有句子都应该能够对应到检索到的上下文中。
<span class="math display">$$
\text{Context Recall} = \frac{|\{\text{返回的相关文档}\} \cap
\{\text{标准相关文档}\}|}{|\{\text{标准相关文档}\}|}
$$</span> 计算方式：上下文是否包括了标准答案的内容</p>
<h3 id="利用ragas评估rag性能">利用RAGAS评估rag性能</h3>
<p><a href="https://github.com/zxj-2023/learn-rag-langchain/blob/main/RAGAS-langchian.ipynb">learn-rag-langchain/RAGAS-langchian.ipynb
at main · zxj-2023/learn-rag-langchain</a></p>
<p>检索器 1.Contextprecision(上下文精确度)：评估检索质量。 2.Context
Recall(上下文召回率)：衡量检索的完整性。 生成器
1.Faithfulness(忠实度)：衡量生成答案中的幻觉情况。
2.AnswerRelevance(答案相关性):衡量答案对问题的直接性(紧扣问题的核心)。</p>
<p>最终的RAGAS得分是以上各个指标得分的调和平均值。简而言之，这些指标用来综合评估
-个系统整体的性能。</p>
<h4 id="rag的构建">RAG的构建</h4>
<p>创建RAG文本分割、Embedding model 、 向量库存储Chroma</p>
<p>我们主要使用 <code>RecursiveCharacterTextSplitter</code>
切割文本，通过<code>OpenAIEmbeddings()</code>进行文本编码，存储到
<code>VectorStore</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.vectorstores import Chroma</span><br><span class="line">from langchain.embeddings import OpenAIEmbeddings</span><br><span class="line">from langchain.text_splitter import RecursiveCharacterTextSplitter</span><br><span class="line">from langchain_community.embeddings import DashScopeEmbeddings</span><br><span class="line">embeddings_model = DashScopeEmbeddings(</span><br><span class="line">        model=&quot;text-embedding-v2&quot;,</span><br><span class="line">        dashscope_api_key=openai.api_key,</span><br><span class="line">    )</span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)</span><br><span class="line">#进行文本分割，生成更小、更易于处理的文档块</span><br><span class="line">docs = text_splitter.split_documents(paper_docs)</span><br><span class="line"></span><br><span class="line">vectorstore = Chroma.from_documents(docs, embeddings_model)</span><br></pre></td></tr></table></figure>
<p>Chroma
向量数据库默认情况下是内存存储，这意味着数据在程序运行结束后不会保留。
但是，Chroma
也支持持久化存储，您可以指定一个路径将数据保存到磁盘上。这样，即使程序关闭，数据也会被保留，并在下次启动时自动加载。</p>
<h4 id="检索器的构建">检索器的构建</h4>
<p>现在我们可以利用 <code>Chroma</code> 向量库的
<code>.as_retriever()</code> 方式进行检索，需要控制的主要参数为
<code>k</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">base_retriever = vectorstore.as_retriever(search_kwargs=&#123;&quot;k&quot; : 3&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>ectorstore.as_retriever() : 这个方法的作用是将一个向量数据库实例（
vectorstore ）转换为 LangChain 中的一个检索器（ Retriever
）对象。检索器是 LangChain
中负责根据用户查询从数据源中获取相关文档的核心组件。</li>
<li>“k” : 这个键表示要检索的“最相似”文档的数量。在这里， “k” : 3
意味着当检索器接收到一个查询时，它将从向量存储中返回与该查询最相似的 3
个文档。这在
RAG（检索增强生成）系统中非常常见，用于限制传递给大型语言模型的上下文信息量，以提高效率和相关性。</li>
</ul>
<p>检索器的作用
检索器（Retriever）是一个核心组件，其主要作用是从一个数据源（如向量数据库、文档加载器等）中根据给定的查询（query）检索出相关的文档或信息。</p>
<h4 id="prompt的构建">prompt的构建</h4>
<p>我们需要利用<code>LLM</code>对<code>Context</code>
生成一系列的问题的<code>answer</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain import PromptTemplate</span><br><span class="line"></span><br><span class="line">template = &quot;&quot;&quot;You are an assistant for question-answering tasks. </span><br><span class="line">Use the following pieces of retrieved context to answer the question. </span><br><span class="line">If you don&#x27;t know the answer, just say that you don&#x27;t know. </span><br><span class="line"></span><br><span class="line">Question: &#123;question&#125; </span><br><span class="line"></span><br><span class="line">Context: &#123;context&#125; </span><br><span class="line"></span><br><span class="line">Answer:</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=template, </span><br><span class="line">    input_variables=[&quot;context&quot;,&quot;question&quot;]</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">print(prompt)</span><br></pre></td></tr></table></figure>
<h4 id="生成answer利用llm">生成<code>answer</code>,利用LLM</h4>
<p>利用 <code>Runnable</code> 定义一个 <code>chain</code>
实现rag全流程。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.schema.runnable import RunnablePassthrough</span><br><span class="line">from langchain.schema.output_parser import StrOutputParser</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model_name=&quot;qwen-plus-2025-04-28&quot;, </span><br><span class="line">    temperature=0,</span><br><span class="line">    api_key=&quot;&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">    )</span><br><span class="line">#RunnablePassthrough将输入数据原封不动地传递到输出</span><br><span class="line">#StrOutputParser() 它被用作 RAG 链的最后一步，确保最终的答案以字符串形式输出。</span><br><span class="line">rag_chain = (</span><br><span class="line">    &#123;&quot;context&quot;: base_retriever,  &quot;question&quot;: RunnablePassthrough()&#125; </span><br><span class="line">    | prompt </span><br><span class="line">    | llm</span><br><span class="line">    | StrOutputParser() </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="创建-ragas-所需的数据">创建 RAGAs 所需的数据</h4>
<p>question Answer contexts ground_truths</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Ragas 数据集格式要求  [&#x27;question&#x27;, &#x27;answer&#x27;, &#x27;contexts&#x27;, &#x27;ground_truths&#x27;]</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;question&quot;: [], &lt;-- 问题基于Context的</span><br><span class="line">    &quot;answer&quot;: [], &lt;-- 答案基于LLM生成的</span><br><span class="line">    &quot;contexts&quot;: [], &lt;-- context</span><br><span class="line">    &quot;ground_truths&quot;: [] &lt;-- 标准答案</span><br><span class="line">&#125;</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">from datasets import Dataset</span><br><span class="line">#构建问题与标准答案（黄金数据集）</span><br><span class="line">questions = [&quot;What is faithfulness ?&quot;, </span><br><span class="line">             &quot;How many pages are included in the WikiEval dataset, and which years do they cover information from?&quot;,</span><br><span class="line">             &quot;Why is evaluating Retrieval Augmented Generation (RAG) systems challenging?&quot;,</span><br><span class="line">            ]</span><br><span class="line">ground_truths = [&quot;Faithfulness refers to the idea that the answer should be grounded in the given context.&quot;,</span><br><span class="line">                  &quot; To construct the dataset, we first selected 50 Wikipedia pages covering events that have happened since the start of 2022.&quot;,</span><br><span class="line">                &quot;Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself.&quot;]              </span><br><span class="line">answers = []</span><br><span class="line">contexts = []</span><br><span class="line"></span><br><span class="line"># 生成答案</span><br><span class="line">for query in questions:</span><br><span class="line">    answers.append(rag_chain.invoke(query))</span><br><span class="line">    contexts.append([docs.page_content for docs in base_retriever.get_relevant_documents(query)])</span><br><span class="line"></span><br><span class="line"># 构建数据</span><br><span class="line">data = &#123;</span><br><span class="line">    &quot;user_input&quot;: questions,</span><br><span class="line">    &quot;response&quot;: answers,</span><br><span class="line">    &quot;retrieved_contexts&quot;: contexts,</span><br><span class="line">    &quot;reference&quot;: ground_truths</span><br><span class="line">&#125;</span><br><span class="line">dataset = Dataset.from_dict(data)</span><br></pre></td></tr></table></figure>
<h4 id="使用ragas-进行评估">使用RAGAs 进行评估</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#将评估数据转换成 Ragas 框架专用的格式 。</span><br><span class="line">from ragas import EvaluationDataset</span><br><span class="line">evaluation_dataset = EvaluationDataset.from_list(dataset)</span><br></pre></td></tr></table></figure>
<p>我们可以使用一组常用的RAG评估指标，在收集的数据集上评估我们的RAG系统。您可以选择任何模型作为评估用LLM来进行评估。
ragas默认使用openai的api</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from ragas.llms import LangchainLLMWrapper</span><br><span class="line">evaluator_llm = LangchainLLMWrapper(llm)</span><br></pre></td></tr></table></figure>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness</span><br><span class="line">from ragas import evaluate</span><br><span class="line">result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)</span><br><span class="line">result</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250713164037571.png" alt="image-20250713164037571">
<figcaption aria-hidden="true">image-20250713164037571</figcaption>
</figure>
<h4 id="查看结果">查看结果</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">pd.set_option(&quot;display.max_colwidth&quot;, None)</span><br><span class="line"></span><br><span class="line">df = result.to_pandas()</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://zhuanlan.zhihu.com/p/1892529470419736435">RAG系统效果难评？2025年必备的RAG评估框架与工具详解
- 知乎</a></p>
<p><a href="https://www.bilibili.com/video/BV1Jz421Q7Lw?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">如何利用RAGAs评估RAG系统的好坏_哔哩哔哩_bilibili</a></p>
<p>ragas中文文档<a href="https://www.aidoczh.com/ragas/getstarted/rag_eval/index.html#want-help-in-improving-your-ai-application-using-evals">Evaluate
a simple RAG - Ragas</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>学习</tag>
        <tag>实习</tag>
        <tag>rag</tag>
      </tags>
  </entry>
  <entry>
    <title>算法期末复习</title>
    <url>/2025/06/12/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/%E7%AE%97%E6%B3%95%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="贪心问题">贪心问题</h3>
<h4 id="找零钱">找零钱</h4>
<p>用最少数量的钱币凑出目标金额 m 元。</p>
<p><strong>核心思想</strong> ：
每次选择<strong>不超过剩余金额的最大面值</strong>
，直到凑够目标金额。</p>
<p><strong>步骤：</strong></p>
<ol type="1">
<li>将钱币面值按从大到小排序。</li>
<li>对于当前剩余金额，不断减去最大可用面值，直到金额为 0。</li>
</ol>
<p><strong>贪心策略的适用性</strong></p>
<p><strong>仅当钱币面值满足以下条件时有效</strong> ：</p>
<ul>
<li>面值序列中每个元素都是前一个元素的因数（如
<code>1, 2, 5, 10</code>）。</li>
<li>否则，贪心可能失败（例如面值 <code>[1, 3, 4]</code>，目标
<code>6</code>：贪心选 <code>4+1+1</code> 需 3 枚，而最优解是
<code>3+3</code> 需 2 枚）。</li>
</ul>
<p><strong>代码问题分析</strong></p>
<p>用户提供的代码是一个基于贪心策略的找零钱实现，但在<strong>硬币面值不满足贪心条件</strong>时可能无法得到最优解。以下是具体分析：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">findMinCoins</span>(<span class="params">coins, amount</span>):</span><br><span class="line">    coins.sort(reverse=<span class="literal">True</span>)  <span class="comment"># 降序排序</span></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(coins)):</span><br><span class="line">        <span class="keyword">while</span> amount &gt;= coins[i]:</span><br><span class="line">            res.append(coins[i])</span><br><span class="line">            amount -= coins[i]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">coins = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line">amount = <span class="number">1136</span></span><br><span class="line">out = findMinCoins(coins, amount)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;钱币数量为<span class="subst">&#123;<span class="built_in">len</span>(out)&#125;</span>.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>问题点：</strong></p>
<ol type="1">
<li><p><strong>贪心策略的局限性</strong><br>
仅当硬币面值满足 <strong>每种面值是前一种面值的因数</strong>（如
<code>[1, 2, 5, 10, 50, 100]</code>）时，贪心算法才能保证最优解。若面值不满足此条件（如
<code>[1, 3, 4]</code>），则可能失败。</p></li>
<li><p><strong>未处理特殊情况</strong></p>
<ul>
<li>若 <code>amount</code> 无法被硬币组合凑出（如硬币为
<code>[2, 5]</code>，目标
<code>3</code>），代码会返回非最优解或死循环。</li>
</ul></li>
</ol>
<p><strong>改进方案</strong></p>
<p>适用于任意硬币面值，确保最优解： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">min_coins_dp</span>(<span class="params">coins, amount</span>):</span><br><span class="line">    dp = [<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)] * (amount + <span class="number">1</span>)</span><br><span class="line">    dp[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, amount + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> coin <span class="keyword">in</span> coins:</span><br><span class="line">            <span class="keyword">if</span> a &gt;= coin <span class="keyword">and</span> dp[a - coin] + <span class="number">1</span> &lt; dp[a]:</span><br><span class="line">                dp[a] = dp[a - coin] + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dp[amount] <span class="keyword">if</span> dp[amount] != <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">coins = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line">amount = <span class="number">1136</span></span><br><span class="line"><span class="built_in">print</span>(min_coins_dp(coins, amount))  <span class="comment"># 输出 16</span></span><br></pre></td></tr></table></figure></p>
<h4 id="最优装载问题">最优装载问题</h4>
<p>🧮 问题描述</p>
<p>给定一个集装箱重量列表 <code>weights</code> 和轮船的最大载重
<code>W</code>，目标是
<strong>尽可能多地装载集装箱</strong>（不考虑体积限制）。</p>
<p>✅ 算法思路</p>
<ol type="1">
<li><strong>排序</strong>：将所有集装箱按重量从小到大排序。</li>
<li><strong>贪心装载</strong>：依次尝试装载每个集装箱，若当前总重量加上该集装箱的重量不超过
<code>W</code>，则装载；否则停止。</li>
<li><strong>返回结果</strong>：返回成功装载的集装箱数量。</li>
</ol>
<p>🧾 Python 实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">max_loaded_containers</span>(<span class="params">weights, W</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    返回在总载重 W 下，最多可以装载的集装箱数量。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    weights (list of int/float): 集装箱重量列表</span></span><br><span class="line"><span class="string">    W (int/float): 轮船的最大载重</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    int: 最多可以装载的集装箱数量</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 按重量从小到大排序</span></span><br><span class="line">    weights.sort()</span><br><span class="line">    </span><br><span class="line">    total_weight = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> weight <span class="keyword">in</span> weights:</span><br><span class="line">        <span class="keyword">if</span> total_weight + weight &lt;= W:</span><br><span class="line">            total_weight += weight</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    weights = [<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">    W = <span class="number">10</span></span><br><span class="line">    result = max_loaded_containers(weights, W)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;最多可以装载 <span class="subst">&#123;result&#125;</span> 个集装箱&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="活动选择问题最大相容活动子集">活动选择问题（最大相容活动子集）</h4>
<p>📌 问题描述</p>
<p>给定 $ n $ 个活动的集合 $ C = {1, 2, …, n} $，每个活动 $ i $
都有起始时间 $ s_i $ 和结束时间 $ f_i $（满足 $ s_i &lt; f_i
$）。要求选择一个<strong>最大相容活动子集</strong>，使得被选中的活动之间<strong>时间互不重叠</strong>。</p>
<p>两个活动 $ i $ 和 $ j $ 相容的条件为： <span class="math display"><em>s</em><sub><em>i</em></sub> ≥ <em>f</em><sub><em>j</em></sub>  或  <em>s</em><sub><em>j</em></sub> ≥ <em>f</em><sub><em>i</em></sub></span></p>
<p>✅ 贪心策略与正确性</p>
<p><strong>贪心策略</strong>：<br>
1. <strong>按活动结束时间 $ f_i $ 从小到大排序</strong>。 2.
<strong>依次选择结束最早的活动</strong>，并跳过与其冲突的所有活动。</p>
<p><strong>正确性证明（归纳法）</strong>：</p>
<ul>
<li><strong>基础情况</strong>：当只有一项活动时，显然选择它是最优的。</li>
<li><strong>归纳假设</strong>：对于前 $ k $
个活动，该策略能得到最大相容子集。</li>
<li><strong>归纳步骤</strong>：考虑第 $ k+1 $
个活动。若选择结束最早的活动 $ A $，则剩下的可用时间区间为 $ [f_A, +)
$，此时在该区间内继续应用该策略，仍能得到最大子集。若不选 $ A $
而选其他活动，则剩余时间更少，无法容纳更多活动。</li>
</ul>
<p>🧾 Python 实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">max_compatible_activities</span>(<span class="params">activities</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    返回最大相容活动子集的数量及具体活动列表。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    activities (list of tuples): 每个元素为 (s_i, f_i)，表示活动的起始和结束时间</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    tuple: (最大活动数量, 相容活动列表)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 按结束时间从小到大排序</span></span><br><span class="line">    sorted_activities = <span class="built_in">sorted</span>(activities, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    selected = []</span><br><span class="line">    last_end = -<span class="number">1</span>  <span class="comment"># 上一个选中的活动的结束时间</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> activity <span class="keyword">in</span> sorted_activities:</span><br><span class="line">        s, f = activity</span><br><span class="line">        <span class="keyword">if</span> s &gt;= last_end:</span><br><span class="line">            selected.append(activity)</span><br><span class="line">            last_end = f</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(selected), selected</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    activities = [</span><br><span class="line">        (<span class="number">1</span>, <span class="number">4</span>), (<span class="number">3</span>, <span class="number">5</span>), (<span class="number">0</span>, <span class="number">6</span>), (<span class="number">5</span>, <span class="number">7</span>), </span><br><span class="line">        (<span class="number">3</span>, <span class="number">8</span>), (<span class="number">5</span>, <span class="number">9</span>), (<span class="number">6</span>, <span class="number">10</span>), (<span class="number">8</span>, <span class="number">11</span>)</span><br><span class="line">    ]</span><br><span class="line">    count, selected = max_compatible_activities(activities)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;最大相容活动数: <span class="subst">&#123;count&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;所选活动:&quot;</span>, selected)</span><br></pre></td></tr></table></figure>
<h4 id="使用堆优化的-dijkstra-算法python-实现">使用堆优化的 Dijkstra
算法（Python 实现）</h4>
<p>🧠 <strong>核心思想</strong></p>
<ul>
<li>使用<strong>最小堆</strong>（优先队列）高效选择当前距离最小的节点，避免暴力遍历。</li>
<li>每次从堆中取出当前最短路径的节点，进行<strong>松弛操作</strong>（Relaxation）。</li>
<li>若发现堆中存在过时的路径记录，则跳过（因为已找到更优路径）。</li>
</ul>
<p>📦 <strong>图的表示</strong></p>
<p>使用邻接表（字典嵌套列表）： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">graph = &#123;</span><br><span class="line">    <span class="string">&#x27;A&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">4</span>)],</span><br><span class="line">    <span class="string">&#x27;B&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">5</span>)],</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">1</span>)],</span><br><span class="line">    <span class="string">&#x27;D&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">1</span>)]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>🧾 <strong>Python 代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dijkstra_with_heap</span>(<span class="params">graph, start</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用堆优化的 Dijkstra 算法求单源最短路径。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    graph (dict): 邻接表形式的图，格式为 &#123;节点: [(邻接节点, 权重), ...]&#125;</span></span><br><span class="line"><span class="string">    start (str/int): 起始节点</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    dict: 从起始节点到所有节点的最短路径长度</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 初始化距离字典，所有节点初始距离为无穷大</span></span><br><span class="line">    distances = &#123;node: <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">for</span> node <span class="keyword">in</span> graph&#125;</span><br><span class="line">    distances[start] = <span class="number">0</span>  <span class="comment"># 起始节点到自身的距离为 0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 优先队列（最小堆），存储 (距离, 节点)</span></span><br><span class="line">    heap = [(<span class="number">0</span>, start)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> heap:</span><br><span class="line">        current_distance, current_node = heapq.heappop(heap)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果当前弹出的距离大于记录的距离，说明该节点已被处理过，跳过</span></span><br><span class="line">        <span class="keyword">if</span> current_distance &gt; distances[current_node]:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历当前节点的所有邻接边</span></span><br><span class="line">        <span class="keyword">for</span> neighbor, weight <span class="keyword">in</span> graph[current_node]:</span><br><span class="line">            distance = current_distance + weight</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果找到更短路径，更新距离并推入堆</span></span><br><span class="line">            <span class="keyword">if</span> distance &lt; distances[neighbor]:</span><br><span class="line">                distances[neighbor] = distance</span><br><span class="line">                heapq.heappush(heap, (distance, neighbor))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> distances</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    graph = &#123;</span><br><span class="line">        <span class="string">&#x27;A&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">4</span>)],</span><br><span class="line">        <span class="string">&#x27;B&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">5</span>)],</span><br><span class="line">        <span class="string">&#x27;C&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">1</span>)],</span><br><span class="line">        <span class="string">&#x27;D&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">1</span>)]</span><br><span class="line">    &#125;</span><br><span class="line">    start_node = <span class="string">&#x27;A&#x27;</span></span><br><span class="line">    shortest_paths = dijkstra_with_heap(graph, start_node)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;从节点 <span class="subst">&#123;start_node&#125;</span> 出发的最短路径：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> node, dist <span class="keyword">in</span> shortest_paths.items():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;start_node&#125;</span> → <span class="subst">&#123;node&#125;</span> : <span class="subst">&#123;dist&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="哈夫曼编码"><strong>哈夫曼编码</strong></h4>
<p><strong>2. 构建哈夫曼树的步骤</strong></p>
<p><strong>步骤 1：统计字符频率</strong></p>
<p>假设输入字符串为
<code>"BCCABBDDAECCBAAAEC"</code>，统计每个字符的出现次数：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A: 6, B: 4, C: 5, D: 2, E: 1</span><br></pre></td></tr></table></figure></p>
<p><strong>步骤 2：创建最小堆（优先队列）</strong></p>
<ul>
<li>将每个字符及其频率构建成节点，并按频率升序排列。</li>
<li>初始堆：<code>[E(1), D(2), B(4), C(5), A(6)]</code></li>
</ul>
<p><strong>步骤 3：合并节点，构建哈夫曼树</strong></p>
<ol type="1">
<li>取出两个频率最小的节点 <code>E(1)</code> 和
<code>D(2)</code>，合并为新节点 <code>ED(3)</code>。</li>
<li>将新节点插入堆：<code>[B(4), C(5), ED(3), A(6)]</code> → 重新排序为
<code>[ED(3), B(4), C(5), A(6)]</code></li>
<li>重复上述步骤，直到堆中只剩一个根节点（哈夫曼树）。</li>
</ol>
<p>最终树结构示意图（频率越小越靠近叶子）： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">        (18)</span><br><span class="line">       /    \</span><br><span class="line">     (8)    A(6)</span><br><span class="line">    /   \</span><br><span class="line"> (4)   (4)</span><br><span class="line">B     C(5)</span><br></pre></td></tr></table></figure></p>
<p><strong>步骤 4：生成哈夫曼编码表</strong></p>
<p>从根节点出发，左子树标记为 <code>0</code>，右子树标记为
<code>1</code>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A: 11</span><br><span class="line">B: 00</span><br><span class="line">C: 01</span><br><span class="line">D: 100</span><br><span class="line">E: 101</span><br></pre></td></tr></table></figure></p>
<p><strong>4. Python 实现哈夫曼编码</strong></p>
<p>以下代码展示如何用 Python 构建哈夫曼树并生成编码表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HuffmanNode</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, char, freq</span>):</span><br><span class="line">        <span class="variable language_">self</span>.char = char</span><br><span class="line">        <span class="variable language_">self</span>.freq = freq</span><br><span class="line">        <span class="variable language_">self</span>.left = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.right = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__lt__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.freq &lt; other.freq</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_huffman_tree</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="comment"># 统计频率</span></span><br><span class="line">    frequency = Counter(text)</span><br><span class="line">    <span class="comment"># 创建最小堆</span></span><br><span class="line">    heap = [HuffmanNode(char, freq) <span class="keyword">for</span> char, freq <span class="keyword">in</span> frequency.items()]</span><br><span class="line">    heapq.heapify(heap)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 合并节点</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(heap) &gt; <span class="number">1</span>:</span><br><span class="line">        left = heapq.heappop(heap)</span><br><span class="line">        right = heapq.heappop(heap)</span><br><span class="line">        merged = HuffmanNode(<span class="literal">None</span>, left.freq + right.freq)</span><br><span class="line">        merged.left = left</span><br><span class="line">        merged.right = right</span><br><span class="line">        heapq.heappush(heap, merged)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> heapq.heappop(heap) <span class="keyword">if</span> heap <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_huffman_codes</span>(<span class="params">root</span>):</span><br><span class="line">    codes = &#123;&#125;</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">node, current_code</span>):</span><br><span class="line">        <span class="keyword">if</span> node:</span><br><span class="line">            <span class="keyword">if</span> node.char <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                codes[node.char] = current_code</span><br><span class="line">            dfs(node.left, current_code + <span class="string">&quot;0&quot;</span>)</span><br><span class="line">            dfs(node.right, current_code + <span class="string">&quot;1&quot;</span>)</span><br><span class="line">    dfs(root, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> codes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">text = <span class="string">&quot;BCCABBDDAECCBAAAEC&quot;</span></span><br><span class="line">root = build_huffman_tree(text)</span><br><span class="line">codes = build_huffman_codes(root)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;哈夫曼编码表:&quot;</span>, codes)</span><br></pre></td></tr></table></figure>
<p><strong>输出示例：</strong> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">哈夫曼编码表: &#123;&#x27;B&#x27;: &#x27;0&#x27;, &#x27;C&#x27;: &#x27;10&#x27;, &#x27;A&#x27;: &#x27;11&#x27;, &#x27;D&#x27;: &#x27;110&#x27;, &#x27;E&#x27;: &#x27;111&#x27;&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="prim">prim</h4>
<p>以下是 <strong>朴素 Prim 算法</strong>
的实现与详解，适用于稠密图（如邻接矩阵存储的图）：</p>
<p><strong>Prim 算法核心思想</strong></p>
<ol type="1">
<li>从任意顶点开始（如 <code>start=0</code>）。</li>
<li>维护一个集合 <code>selected</code>，记录已加入生成树的顶点。</li>
<li>每次从未选顶点中选择到当前生成树的最小权重边的顶点。</li>
<li>重复步骤 3，直到所有顶点加入生成树。</li>
</ol>
<p>时间复杂度：<strong>O(V²)</strong>，其中 V 是顶点数。</p>
<p><strong>Python 实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prim</span>(<span class="params">graph, start=<span class="number">0</span></span>):</span><br><span class="line">    V = <span class="built_in">len</span>(graph)  <span class="comment"># 顶点数量</span></span><br><span class="line">    selected = [<span class="literal">False</span>] * V  <span class="comment"># 标记顶点是否已加入生成树</span></span><br><span class="line">    key = [sys.maxsize] * V  <span class="comment"># 记录各顶点到生成树的最小权重</span></span><br><span class="line">    parent = [-<span class="number">1</span>] * V         <span class="comment"># 记录最小生成树的父节点</span></span><br><span class="line"></span><br><span class="line">    key[start] = <span class="number">0</span>  <span class="comment"># 起始顶点的权值设为0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(V):</span><br><span class="line">        <span class="comment"># 找到当前未选顶点中 key 最小的顶点 u</span></span><br><span class="line">        min_key = sys.maxsize</span><br><span class="line">        u = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(V):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> selected[v] <span class="keyword">and</span> key[v] &lt; min_key:</span><br><span class="line">                min_key = key[v]</span><br><span class="line">                u = v</span><br><span class="line">        <span class="keyword">if</span> u == -<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span>  <span class="comment"># 无连通顶点，生成树结束</span></span><br><span class="line">        </span><br><span class="line">        selected[u] = <span class="literal">True</span>  <span class="comment"># 将 u 加入生成树</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新 u 的所有邻接顶点的 key 值</span></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(V):</span><br><span class="line">            <span class="keyword">if</span> graph[u][v] &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> selected[v] <span class="keyword">and</span> graph[u][v] &lt; key[v]:</span><br><span class="line">                key[v] = graph[u][v]</span><br><span class="line">                parent[v] = u  <span class="comment"># 记录 v 的父节点为 u</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> key, parent</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：邻接矩阵表示的图</span></span><br><span class="line">graph = [</span><br><span class="line">    [<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">5</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>],</span><br><span class="line">    [<span class="number">6</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">0</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">key, parent = prim(graph)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最小生成树的总权重:&quot;</span>, <span class="built_in">sum</span>(key))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;父节点数组:&quot;</span>, parent)</span><br></pre></td></tr></table></figure>
<h4 id="kruskal">kruskal</h4>
<p><strong>2. Kruskal 算法的核心思想</strong></p>
<ol type="1">
<li><strong>按权重从小到大排序所有边</strong>。</li>
<li><strong>依次选择边</strong>：
<ul>
<li>如果这条边的两个顶点不在同一个连通分量中（即不形成环），则将这条边加入生成树。</li>
<li>否则跳过这条边。</li>
</ul></li>
<li><strong>重复步骤2，直到生成树中有 <code>V-1</code>
条边</strong>（<code>V</code> 是顶点数）。</li>
</ol>
<p><strong>6. Python 实现示例</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UnionFind</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size</span>):</span><br><span class="line">        <span class="variable language_">self</span>.parent = <span class="built_in">list</span>(<span class="built_in">range</span>(size))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.parent[x] != x:</span><br><span class="line">            <span class="variable language_">self</span>.parent[x] = <span class="variable language_">self</span>.find(<span class="variable language_">self</span>.parent[x])  <span class="comment"># 路径压缩</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.parent[x]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        rootX = <span class="variable language_">self</span>.find(x)</span><br><span class="line">        rootY = <span class="variable language_">self</span>.find(y)</span><br><span class="line">        <span class="keyword">if</span> rootX == rootY:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span>  <span class="comment"># 已在同一个集合</span></span><br><span class="line">        <span class="variable language_">self</span>.parent[rootY] = rootX  <span class="comment"># 合并</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kruskal</span>(<span class="params">n, edges</span>):</span><br><span class="line">    <span class="comment"># edges: [(权重, u, v), ...]</span></span><br><span class="line">    edges.sort()</span><br><span class="line">    uf = UnionFind(n)</span><br><span class="line">    mst = []</span><br><span class="line">    cost = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> weight, u, v <span class="keyword">in</span> edges:</span><br><span class="line">        <span class="keyword">if</span> uf.union(u, v):</span><br><span class="line">            mst.append((u, v))</span><br><span class="line">            cost += weight</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(mst) == n - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">break</span>  <span class="comment"># 已选够 n-1 条边</span></span><br><span class="line">    <span class="keyword">return</span> mst, cost</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">n = <span class="number">5</span>  <span class="comment"># 顶点数（0~4）</span></span><br><span class="line">edges = [</span><br><span class="line">    (<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>),  <span class="comment"># A(0)-B(1)</span></span><br><span class="line">    (<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>),  <span class="comment"># B(1)-C(2)</span></span><br><span class="line">    (<span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>),  <span class="comment"># C(2)-D(3)</span></span><br><span class="line">    (<span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>),  <span class="comment"># D(3)-E(4)</span></span><br><span class="line">    (<span class="number">5</span>, <span class="number">0</span>, <span class="number">4</span>),  <span class="comment"># A(0)-E(4)</span></span><br><span class="line">    (<span class="number">6</span>, <span class="number">1</span>, <span class="number">3</span>)   <span class="comment"># B(1)-D(3)</span></span><br><span class="line">]</span><br><span class="line">mst, total = kruskal(n, edges)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MST 边：&quot;</span>, mst)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;总权重：&quot;</span>, total)</span><br></pre></td></tr></table></figure>
<h3 id="动态规划">动态规划</h3>
<h4 id="完全背包">完全背包</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def unbounded_knapsack_2d(weights, values, capacity):</span><br><span class="line">    n = len(weights)</span><br><span class="line">    dp = [[0] * (capacity + 1) for _ in range(n + 1)]</span><br><span class="line"></span><br><span class="line">    for i in range(1, n + 1):</span><br><span class="line">        for j in range(1, capacity + 1):</span><br><span class="line">            if weights[i-1] &lt;= j:</span><br><span class="line">                dp[i][j] = max(</span><br><span class="line">                    dp[i-1][j],</span><br><span class="line">                    dp[i][j - weights[i-1]] + values[i-1]</span><br><span class="line">                )</span><br><span class="line">            else:</span><br><span class="line">                dp[i][j] = dp[i-1][j]</span><br><span class="line">    </span><br><span class="line">    return dp[n][capacity]</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">weights = [1, 2, 3]</span><br><span class="line">values = [15, 20, 50]</span><br><span class="line">capacity = 5</span><br><span class="line">print(unbounded_knapsack_2d(weights, values, capacity))  # 输出 80</span><br></pre></td></tr></table></figure>
<h4 id="最优二叉搜索树">最优二叉搜索树</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def optimal_bst(p, q, n):</span><br><span class="line">    # 初始化 dp 和 w 数组（大小为 (n+2) x (n+2)，避免越界）</span><br><span class="line">    dp = [[0] * (n+2) for _ in range(n+2)]</span><br><span class="line">    w = [[0] * (n+2) for _ in range(n+2)]</span><br><span class="line">    root = [[0] * (n+2) for _ in range(n+2)]</span><br><span class="line"></span><br><span class="line">    # 初始化虚拟键的权重</span><br><span class="line">    for i in range(n+1):</span><br><span class="line">        w[i][i] = q[i]</span><br><span class="line">    </span><br><span class="line">    # 填表顺序：链长从 1 到 n</span><br><span class="line">    for l in range(1, n+1):  # l 为关键字数量</span><br><span class="line">        for i in range(n - l + 1):</span><br><span class="line">            j = i + l</span><br><span class="line">            w[i][j] = w[i][j-1] + p[j] + q[j]</span><br><span class="line">            dp[i][j] = float(&#x27;inf&#x27;)</span><br><span class="line">            # 枚举根节点 r（i &lt; r ≤ j）</span><br><span class="line">            for r in range(i+1, j+1):</span><br><span class="line">                cost = dp[i][r-1] + dp[r][j]</span><br><span class="line">                if cost &lt; dp[i][j]:</span><br><span class="line">                    dp[i][j] = cost</span><br><span class="line">                    root[i][j] = r</span><br><span class="line">    </span><br><span class="line">    return dp[0][n], root</span><br><span class="line"></span><br><span class="line"># 示例输入</span><br><span class="line">p = [0, 0.15, 0.1, 0.05]  # 关键字概率（从 k₁ 开始）</span><br><span class="line">q = [0.05, 0.1, 0.05, 0.05]  # 虚拟键概率（从 d₀ 开始）</span><br><span class="line">n = 3  # 关键字数量</span><br><span class="line">min_cost, root = optimal_bst(p, q, n)</span><br><span class="line">print(&quot;最小期望搜索代价:&quot;, min_cost)</span><br></pre></td></tr></table></figure>
<h3 id="回溯法">回溯法</h3>
<h4 id="八皇后">八皇后</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">https://leetcode.cn/problems/n-queens/</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">n=4</span><br><span class="line">ans=[]</span><br><span class="line">path=[]</span><br><span class="line">onpath=[False]*n#记录哪一列有皇后</span><br><span class="line">diag1=[False]*(2*n-1)#记录主对角线是否有皇后</span><br><span class="line">diag2=[False]*(2*n-1)#记录副对角线是否有皇后</span><br><span class="line">def dfs(row,path:list):</span><br><span class="line">    if row==n:</span><br><span class="line">        #print(path)</span><br><span class="line">        chess=[]</span><br><span class="line">        # 生成棋盘</span><br><span class="line">        for i in range(n):</span><br><span class="line">            chess.append(&quot;.&quot;*path[i]+&quot;Q&quot;+&quot;.&quot;*(n-path[i]-1))</span><br><span class="line">        ans.append(chess)</span><br><span class="line">        return</span><br><span class="line">    for col in range(n):</span><br><span class="line">        if isvalid(row,col):</span><br><span class="line">            path.append(col)#放置皇后</span><br><span class="line">            onpath[col]=diag1[row+col]=diag2[row-col+n-1]=True</span><br><span class="line">            dfs(row+1,path)#递归下一行</span><br><span class="line">            path.pop()#回溯，取消放置</span><br><span class="line">            onpath[col]=diag1[row+col]=diag2[row-col+n-1]=False</span><br><span class="line">    </span><br><span class="line">def isvalid(row,col):</span><br><span class="line">    if onpath[col] or diag1[row+col] or diag2[row-col+n-1]:</span><br><span class="line">        return False</span><br><span class="line">    return True</span><br><span class="line">dfs(0,path)</span><br><span class="line">print(ans)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——初读论文与初步学习</title>
    <url>/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/</url>
    <content><![CDATA[<h1 id="视频异常检测初步了解">视频异常检测初步了解</h1>
<h2 id="传统方法检测异常样本">传统方法检测异常样本：</h2>
<ul>
<li>高斯分布 Gaussian Distribute</li>
<li>高斯混合模型 Gaussian Mixture Model</li>
</ul>
<h2 id="深度学习方法下的异常检测">深度学习方法下的异常检测：</h2>
<ul>
<li>两种主流的异常检测任务：
<ul>
<li>重构任务
Reconstruction：图像通过深度神经网络DNN输出一张重构图像，通过损失函数，先训练调整DNN，测试结果由AUC评判（AUC（Area
Under the Curve）是用于评估分类模型性能的一个重要指标）</li>
<li>预测任务
Prediction：连续输入图像，预测新图像，用预测与非预测比较</li>
</ul></li>
<li>自动编码器 Auto-Encoder：U-Net
是一种用于图像分割的深度学习模型，主要特点是采用了编码器-解码器结构（也叫对称结构），并在编码器和解码器之间引入了跳跃连接（skip
connections）</li>
</ul>
<blockquote>
<p><strong>编码器（Contracting
Path）</strong>：这一部分类似于卷积神经网络（CNN），用于提取输入图像的特征。</p>
<p><strong>瓶颈层（Bottleneck）</strong>：编码器和解码器之间的连接层，负责处理最深层次的特征。</p>
<p><strong>解码器（Expansive
Path）</strong>：这一部分用于将编码器提取的特征还原回原始图像的大小。</p>
<p><strong>跳跃连接（Skip
Connections）</strong>：解码器部分会与编码器的对应层进行直接连接，从而帮助模型在恢复空间分辨率的过程中更好地保留细节信息。</p>
<figure>
<img src="./../../images/大创/v2-39073bacc426f0e464b53336c83e19da_1440w.jpg" alt="v2-39073bacc426f0e464b53336c83e19da_1440w">
<figcaption aria-hidden="true">v2-39073bacc426f0e464b53336c83e19da_1440w</figcaption>
</figure>
</blockquote>
<h2 id="根据学习方法分类">根据学习方法分类：</h2>
<ul>
<li>无监督学习 unsupervised learning 只有正常样本训练</li>
<li>半监督学习 weakly spervised learning 以不平衡的样本比例训练</li>
<li>监督学习 spervised learning 都训练</li>
</ul>
<h2 id="视频异常检测领域未来挑战">视频异常检测领域未来挑战：</h2>
<ul>
<li>异常检测视频大部分采用mini-batch训练方法，非常消耗时间和资源，无法实时进行视频检测</li>
<li>现实的数据集，模型难以训练</li>
<li>异常的情况定义模糊</li>
<li>模型的迁移性差，shanghaiTech的数据集是多摄像头融合的数据集，大部分数据集表现一般</li>
</ul>
<h2 id="了解yolo">了解yolo</h2>
<p>YOLO（You Only Look Once）系列算法是计算机视觉领域中重要的<a href="https://so.csdn.net/so/search?q=目标检测技术&amp;spm=1001.2101.3001.7020">目标检测技术</a>。凭借其高效的实时处理能力，YOLO被广泛应用于视频监控、自动驾驶等多个领域。</p>
<h1 id="论文一human-action-recognition-from-various-data-modalities-a-review">论文一：Human
Action Recognition from Various Data Modalities: A Review</h1>
<h2 id="概述">概述</h2>
<p><strong>人类动作识别（Human Action Recognition,
HAR）</strong>旨在理解人类的行为，并为每个行为分配一个标签。</p>
<p>多种不同的数据形态都可以用来表示人类的动作和行为。这些模态可以分为2类：<strong>视觉模态和非视觉模态</strong></p>
<p>视觉模态和非视觉模态的主要区别在于：视觉模态的数据对人类行为的表示相对直观，但是非视觉模态的数据则不是。视觉模态主要包括：如RGB，骨架，深度，红外，点云，事件流（event
stream）等数据模态，而非视觉模态则主要包括音频，加速度，雷达，wifi信号等数据模态</p>
<p>然而，由于不同的模态对 HAR
具有不同的优势和局限性，因此多种数据模态的融合和跨模态的知识传递以提高
HAR 的准确性和稳健性，近年来也受到了极大的关注
[23]，[24]。更具体地说，融合是指将两种或多种模态的信息组合起来，以识别动作</p>
<p>该综述对基于不同数据模态的深度学习HAR方法的最新进展做了一个综合调研。介绍调研的主要内容分为三部分</p>
<ul>
<li>当前主流的单模态深度学习方法</li>
<li>当前主流的多模态深度学习方法，包括基于融合（fusion）和协同学习（co-learning）的学习框架</li>
<li>当前HAR任务的主流数据集</li>
</ul>
<h2 id="单一模态-single-modality">单一模态 SINGLE MODALITY</h2>
<h3 id="rgb模态-rgb-modality">RGB模态 RGB MODALITY</h3>
<p>RGB 模态通常是指由 RGB
相机捕获的图像或视频（图像序列），旨在重现人眼所见。</p>
<p>RGB模态优点主要有：（1）RGB数据容易收集，通常是最常用的数据模态。（2）RGB模态包含所捕获的场景上下文的信息。（3）基于RGB的HAR方法也可以用来做pretrained
model。</p>
<p>缺点主要有：（1）由于RGB数据中存在背景、视点、尺度和光照条件的变化，所以在RGB模态中进行识别通常具有挑战性。（2）RGB
视频通常具有较大的数据量，导致在为 HAR
的时空环境建模时会产生高计算成本。</p>
<p>下面介绍面向基于 RGB 的 HAR 的高级深度学习，主要可分为四大类，即双流
2D 卷积神经网络 （CNN）、递归神经网络 （RNN）、3D CNN 和基于 Transformer
的方法</p>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/v2-4ec2f54d013bb5ab6996585c53f7755d_1440w.png" alt="v2-4ec2f54d013bb5ab6996585c53f7755d_1440w">
<figcaption aria-hidden="true">v2-4ec2f54d013bb5ab6996585c53f7755d_1440w</figcaption>
</figure>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/sadasd.png" alt="sadasd">
<figcaption aria-hidden="true">sadasd</figcaption>
</figure>
<h3 id="骨骼模态-skeleton-modality">骨骼模态 SKELETON MODALITY</h3>
<p>骨骼序列编码人体关节的轨迹，这些轨迹表征了信息丰富的人体运动。因此，骨架数据也是
HAR 的合适模式。</p>
<p>骨架数据提供的是身体结构与姿态信息，其具有两个明显的优点：（1）具有比例不变性。（2）对服装纹理和背景是鲁棒的。</p>
<p>但同时也有两个缺点：（1）骨架信息的表示比较稀疏，存在噪声。（2）骨架数据缺少人-物交互时可能存在的形状信息。</p>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/v2-f3f49680590c848b02f3e7911c5d7d3c_1440w.png" alt="v2-f3f49680590c848b02f3e7911c5d7d3c_1440w">
<figcaption aria-hidden="true">v2-f3f49680590c848b02f3e7911c5d7d3c_1440w</figcaption>
</figure>
<h3 id="深度模态-depth-modality">深度模态 DEPTH MODALITY</h3>
<p>深度图其中像素值表示从给定视点到场景中的点的距离信息。深度模态通常对颜色和纹理的变化具有鲁棒性，提供了可靠的人体三维结构和几何形状信息，因此可用于
HAR。随着技术的发展，现在已经有多种设备可以捕获场景中的深度图。现有的对深度数据学习的方法大多数还是利用CNN提取深度图中的feature。深度数据可以提供几何形状信息，但是对外观数据的提供是缺失的，所以深度数据通常不单独使用，而是与其他模态的数据融合使用。</p>
<h3 id="红外模态-infrared-modality">红外模态 INFRARED MODALITY</h3>
<p>通常，红外传感器不需要依赖外部环境光，因此特别适用于夜间
HARat。红外传感技术可分为有源和无源两种。一些红外传感器（如
Kinect）依赖于主动红外技术，该技术发射红外线并利用目标反射光线来感知场景中的物体。在目前基于深度学习的方法中，比较多的做法是把红外图像作为其中一个stream输入双流或多流网络中。红外数据以其不需要依赖外部环境的可见光的特点，特别适合于夜间的HAR，但是，红外图像也有着对比度低和信噪比低的固有缺点。</p>
<h3 id="点云模态-point-cloudmodality">点云模态 POINT CLOUDMODALITY</h3>
<p>点云数据由许多点集合组成，这些点表示空间参考系统下目标的空间分布和表面特征。获取
3D 点云数据有两种主要方法，即 （1） 使用 3D 传感器，例如 LiDAR 和
Kinect，或 （2） 使用基于图像的 3D 重建。点云作为一种 3D
数据模态，具有强大的能力来表示主体的空间轮廓和 3D 几何形状，因此可以用于
HAR。但是点云中通常存在噪声和高度不均匀的点分布。</p>
<h3 id="事件流模态-event-stream-modality">事件流模态 EVENT STREAM
MODALITY</h3>
<p>事件照相机（event
camera）可以捕捉照明条件的变化并为每个像素独立产生异步事件。传统的摄像机通常会捕捉整个图像阵列，而事件摄像机仅响应视觉场景的变化。事件照相机能够有效地滤除背景信息，而只保留前景运动信息，这样可以避免视觉信息中的大量冗余，但是其捕捉到的信息通常在时间和空间维度上是稀疏的，而且是异步的。因此一些现有的方法主要聚焦于设计事件聚合策略，将事件摄像机的异步输出转换为同步的视觉帧。</p>
<h3 id="音频模态-audio-modality">音频模态 AUDIO MODALITY</h3>
<p>音频信号通常与视频信号一起提供，由于音频和视频是同步的，所以音频数据可以用定位动作。因为音频信号中的信息量是不足的，所以单独使用音频数据执行HAR任务相对比较少见。更常见的情况是音频信号作为HAR的补充信息，与其他模态（如rgb图像）一起使用。</p>
<h3 id="后续">后续</h3>
<p>还有加速度模态，雷达模态，wifi模态，我先不了解，后续若有需要再完善知识</p>
<h2 id="多模态-multi-modality">多模态 MULTI-MODALITY</h2>
<p>在现实生活中，人类经常以多模态认知方式感知环境。同样，多模态机器学习是一种建模方法，旨在处理和关联来自多种模态的感觉信息[358]。通过聚合各种数据模态的优势和功能，多模态机器学习通常可以提供更强大、更准确的
HAR。</p>
<p>多模态学习方法主要有两种，融合（fusion）和协同学习（co-learning）。其中融合指的是对来自两个或更多模态的信息进行集成，并将其用于训练或推理，而协同学习指的则是对不同模态之间的知识进行迁移。图4展示了多模态学习方法的分类</p>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/v2-04335982349266acffdb93355ce2686c_1440w.png" alt="v2-04335982349266acffdb93355ce2686c_1440w">
<figcaption aria-hidden="true">v2-04335982349266acffdb93355ce2686c_1440w</figcaption>
</figure>
<h3 id="har任务中的多模态融合">HAR任务中的多模态融合</h3>
<p>模态融合的目的是利用不同数据模态的互补优势，以达到更好的识别性能。现有的多模态融合方案主要有两种：（1）评分融合（score
fusion），即对不同模态输出的score做融合，例如使用加权平均或学习一个分数融合模型。（2）特征融合，即对来自不同模态的特征进行组合。数据融合（在特征提取之前就融合不同模态的输入数据）可以看成是特征融合，因为某一模态的数据数据可以被视为该模态的原始特征。</p>
<p>依据输入模态的不同，现有的多模态融合方法大概可以分为视觉模态之间的融合，与视觉+非视觉模态之间的融合两种</p>
<h4 id="视觉模态之间的融合"><strong>视觉模态之间的融合</strong></h4>
<ol type="1">
<li>RGB+深度模态：RGB和深度模态分别能够捕捉外观信息和3D形状信息，因此它们具有比较强的互补性。</li>
<li>RGB+骨架模态：骨架模态可以提供身体位置和关节运动信息，同样和RGB模态是互补的。[28]提出了一个双流深度网络，两个stream分别是CNN和RNN，用以分别处理RGB和骨架数据，融合方式同时尝试了特征融合和分数融合，并发现应用特征融合策略可以取得更好的效果。</li>
<li>深度图+骨架模态：[31]将身体的每个部分与其他部分之间的相对几何关系作为骨架特征，将不同身体部分周围的深度图像块作为外观特征，以编码身体-对象和身体部分-身体部分之间的关系，进而实现可靠的HAR。</li>
<li>RGB+深度图+骨架模态：这类方法大多是前文提到了三类多模态融合方法的扩展。</li>
</ol>
<h4 id="视觉模态非视觉模态的融合"><strong>视觉模态+非视觉模态的融合</strong></h4>
<ol type="1">
<li>视频与音频的融合：前文中已经提到，音频可以为视频的外观和运动信息提供补充信息。所以目前已经有一些基于深度学习的方法来融合这种模态的数据</li>
<li>视频与加速度模态的融合</li>
<li>其他类型的模态融合：[43]的核心思想是将非RGB模态的数据，包括骨架、加速度和wifi数据都转换成彩色图像，然后送入CNN中。</li>
</ol>
<h3 id="har任务中的多模态协同学习">HAR任务中的多模态协同学习</h3>
<p>多模态协同学习旨在探索如何利用辅助模态学习到的知识帮助另一个模态的学习，希望通过跨模态的知识传递和迁移可以克服单一模态的缺点，提高性能。多模态协同学习与多模态融合的一个关键区别在于，在多模态协同学习中，辅助模态的数据仅仅在训练阶段需要，测试阶段并不需要。所以多模态协同学习尤其适用于模态缺失的场景。此外对于模态样本数较小的场景，多模态协同学习也可以起到一定的帮助作用。</p>
<h4 id="视觉模态的协同学习"><strong>视觉模态的协同学习</strong></h4>
<ol type="1">
<li>RGB和深度模态的协同学习</li>
<li>RGB和骨架模态的协同学习。如[48]利用CNN+LSTM执行基于RGB视频的分类，并利用在骨架数据上训练的LSTM模型充当调节器，强制两个模型的输出特征相似。</li>
</ol>
<h4 id="视觉和非视觉模态的协同学习"><strong>视觉和非视觉模态的协同学习</strong></h4>
<p>第一种类型是在不同模态之间进行知识的迁移，如[50]中的teacher
network使用非视觉模态训练，而student
network使用RGB模态作为输入，通过强制teacher和student的attention
map相似以弥补模态间的形态差距，并实现知识的提炼。</p>
<p>第二种类型是利用不同模态之间的相关性进行自监督学习，比如[51]分别利用音频/视频模态中的无监督聚类结果作为视频/音频模态的监督信号。[52]使用视频和音频的时间同步信息作为自监督信号。</p>
<h1 id="论文二rwf-2000-an-open-large-scale-video-database-for-violence-detection">论文二：RWF-2000:
An Open Large Scale Video Database for Violence Detection</h1>
<p><a href="https://github.com/mchengny/RWF2000-Video-Database-for-Violence-Detection">mchengny/RWF2000-Video-Database-for-Violence-Detection：一个用于暴力检测的大型视频数据库，其中包含
2,000 个包含暴力或非暴力行为的视频剪辑。</a></p>
<h2 id="摘要">摘要</h2>
<p>近年来，监控摄像头在公共场所广泛部署，由于这些无处不在的设备，总体犯罪率已显著降低。通常，这些摄像头会在犯罪发生后提供线索和证据，而很少用于及时预防或制止犯罪活动。手动监控来自监控摄像头的大量视频数据既费时又费力。因此，从视频信号中自动识别暴力行为变得至关重要。</p>
<p>本文总结了几个现有的用于暴力检测的视频数据集，并提出了 RWF-2000
数据库，其中包含监控摄像头在真实场景中捕获的 2,000
个视频。此外，我们还提出了一种同时利用 3D-CNN
和光流优点的新方法，即流门控网络。所提出的方法在我们提出的数据库的测试集上获得了
87.25% 的准确率。数据库和源代码目前对 Access 1 开放。</p>
<h2 id="概述-1">概述</h2>
<p>通常，基于视频的暴力检测的定义是检测视频数据中的暴力行为。它是人类动作识别的一个子集，旨在识别常见的人类动作。与静止图像相比，视频数据具有额外的时间序列。一组连续的帧表示连续的运动，而相邻的帧由于帧间相关性高而包含冗余信息。</p>
<p>一些早期的方法依赖于检测高度相关物体（例如，枪击、火焰、血腥、爆炸）的存在，而不是直接识别暴力事件</p>
<p>此前数据的劣势：尽管存在一些用于暴力检测的视频数据集，但它们仍然存在规模小、多样性少和图像分辨率低的缺点。此外，一些具有高图像质量的相关数据集来自电影，这些电影与真实场景不够接近。为解决真实暴力活动中高质量数据不足的问题</p>
<p>本文工作：</p>
<ol type="1">
<li>为了解决真实暴力活动中高质量数据不足的问题，我们收集了一个新的视频数据集
（RWF-2000）
并将其免费发布给研究界。该数据集规模较大，包含从监控视频中提取的 2,000
个剪辑</li>
<li>我们提出了一种新的具有自学习池机制的模型，该模型可以很好地兼顾外观特征和时间特征。</li>
</ol>
<h2 id="先前数据集">先前数据集</h2>
<p>根据注释方法，仍然存在两种用于暴力检测的视频数据集：修剪和未修剪。裁剪后的数据集中的视频都是几秒长的短片，每个视频都有一个视频级标注。而视频未修剪的数据集通常具有更长的持续时间。此外，暴力活动的开始时间和结束时间都有帧级注释。</p>
<p>总结这些提议的数据集，每个数据集都至少具有以下一个或多个限制：</p>
<ul>
<li>图像质量低;缺乏足够的数据量</li>
<li>视频时长但注释粗糙</li>
<li>与现实暴力不够接近的视频混合来源</li>
</ul>
<p>为了解决上述问题，我们从 YouTube 网站收集了一个新的 RWF
2000（真实世界格斗）数据集，其中包括 2,000
个由监控枪式摄像机从真实场景中拍摄的修剪视频剪辑。</p>
<h2 id="先前方法">先前方法</h2>
<p>传统方法通常会尝试找到一个 powfer
特征提取算法，并实现一个基于机器学习的分类器来完成暴力检测任务。</p>
<p>总之，基于深度学习的方法通常优于传统的基于特征提取的模型。此外，大多数最先进的结果都使用多通道输入（例如，原始
RGB 图像、光流、加速度图）。同时，复杂模型对过拟合不是很鲁棒。</p>
<p>在本文中，我们只采用 RGB
图像和光流来构建神经网络，它可以处理空间和时间信息。此外，我们提出的
Flow-Gated
架构可以通过自学习来减少输入视频的时间通道，而不是传统的池化策略。</p>
<h2 id="rwf-2000-数据库和建议的方法">RWF-2000 数据库和建议的方法</h2>
<h3 id="数据采集">数据采集</h3>
<p>为了使暴力检测在现实应用中更加实用，我们从 YouTube
平台收集了一个新的真实世界格斗 （RWF）
数据集，其中包含监控摄像头在真实场景中拍摄的 2,000 个视频剪辑。</p>
<p>拟议的数据集有 2,000 个视频剪辑，分为两部分：训练集 （80%） 和测试集
（20%）。一半的视频包含暴力行为，而其他视频属于非暴力活动。</p>
<h3 id="flow-gated-network">Flow Gated Network</h3>
<p>以前的大多数方法都探索从单个帧中提取外观特征，然后将它们融合以对时间信息进行建模。由于粗略的池化机制，运动信息可能毫无用处，我们的目标是设计一种通过网络自学习实现的时间池化机制</p>
<figure>
<img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/asdasf.png" alt="asdasf">
<figcaption aria-hidden="true">asdasf</figcaption>
</figure>
<p>由四个部分组成：RGB 通道、光流通道、合并块和全连接层。RGB
通道和光流通道由级联的 3D CNN
组成，它们具有一致的结构，因此它们的输出可以融合。Merging Block
也由基本的 3D CNN 组成，这些 CNN
在自学时间池化后处理信息。最后，全连接层生成输出。</p>
<p>该模型的亮点是利用光流通道的一个分支来帮助构建池化机制。</p>
<h1 id="后续学习">后续学习</h1>
<p><a href="https://blog.csdn.net/qq_32892383/article/details/136413119">基于YOLOv8/YOLOv7/YOLOv6/YOLOv5的暴力行为检测系统（深度学习模型+UI界面+Python代码+训练数据集）-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/qq_42681787/article/details/134423818">YOLO8实战：暴力行为检测系统_yolov8
打架检测-CSDN博客</a></p>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://www.bilibili.com/video/BV1aR4y1J7uv/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">科研分享|视频异常检测_哔哩哔哩_bilibili</a></p>
<p>[<a href="https://zhuanlan.zhihu.com/p/553262457">领域综述] TPAMI
2022 | Human Action Recognition from Various Data Modalities: A Review -
知乎</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/105360879">RWF-2000
暴力行为检测视频数据集 - 知乎</a></p>
<p>另一个暴力行为数据集<a href="https://roc-ng.github.io/XD-Violence/">XD-暴力</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——基础知识储备</title>
    <url>/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/</url>
    <content><![CDATA[<h1 id="学习计划">学习计划</h1>
<ul class="task-list">
<li><label><input type="checkbox">yolo深入学习，代码初步运行尝试</label></li>
<li><label><input type="checkbox" checked>视频异常检测与视频动作识别的概念明晰与区分</label></li>
<li><label><input type="checkbox">实际操作知识储备：视频预处理，训练，测试</label></li>
<li><label><input type="checkbox" checked>具体算法知识储备：<strong>3D CNN</strong> ，<strong>2D CNN
+ RNN</strong>，<strong>LSTM</strong></label></li>
<li><label><input type="checkbox" checked>根据PPT初步构建立项书框架</label></li>
</ul>
<h1 id="视频异常检测与视频动作识别的概念明晰与区分">视频异常检测与视频动作识别的概念明晰与区分</h1>
<p>我们后续做的主要是<strong>暴力行为的识别</strong>，我个人原本概念并没有清楚，以为是属于视频异常检测领域，但这里更关注的是人的动作，应该与视频动作识别更贴合，以下是我结合网上文章理解的二者区别，用词不严谨处还请指正</p>
<p>视频异常检测系统能够检测明显偏离正常的异常行为或实体，例如在视频监控的先验知识有限的情况下识别多个移动物体，或检测特定事件，例如打架、踩踏、交通事故和流浪。<strong>视频异常通常是上下文的，并根据真实场景定义</strong>。具体来说，检测过程集中于识别所有视频中包含异常的视频片段，而定位致力于确定哪一帧是异常的，并解释该帧的哪一部分是异常的。</p>
<p><strong>视频动作识别</strong>是通过已标记的数据集训练模型实现视频理解视频分类的功能。动作识别的目标是识别出视频中出现的动作，通常是视频中人的动作。视频可以看作是由一组图像帧按时间顺序排列而成的数据结构，比图像多了一个时间维度。动作识别不仅要分析视频中每帧图像的内容，还需要从视频帧之间的时序信息中挖掘线索。动作识别是视频理解的核心领域，虽然动作识别主要是识别视频中人的动作，但是该领域发展出来的算法大多数不特定针对人，也可以用于其他视频分类场景。</p>
<h1 id="二维卷积-2d-cnn">二维卷积 2D CNN</h1>
<p>卷积神经网络（convolutional neural
network）是含有卷积层（convolutional
layer）的神经网络。它有高和宽两个空间维度，常用来处理图像数据。</p>
<h2 id="卷积神经网络的结构">卷积神经网络的结构</h2>
<p>层级网络，数据包括输入层，卷积层，激活层，池化层，全连接层等</p>
<p><strong>输入层</strong>：就是原始图像，非提取的信息，因此卷积神经网络是一个无监督的特征学习网络，数据输入层主要对原始图像数据进行预处理，基础的操作包括去均值、灰度归一化，数据增强等；</p>
<p><strong>卷积层</strong>：就是特征提取层，一般卷积神经网络包含多个卷积层，一个卷积层可以有多个不同的卷积核。通过不同的多个卷积核对图像进行预处理，提取特征，每个卷积核会映射出新的特征平面。再通过非线性激活函数对卷积结果进行处理；</p>
<p><strong>激活层</strong>：卷积神经网络需要激活层进行特征的选择和抑制；</p>
<p><strong>池化层</strong>：用于降低特征平面分辨率及抽象特征，可以有效的压缩网络参数和数据，减少过拟合。池化层最主要的作用就是压缩图像同时保存图像的特征不变；</p>
<p><strong>全连接层</strong>：是卷积神经网络的最后，具有卷积核和偏移量两个参数。（fully
connected
layers，FC）在整个卷积神经网络中起到“分类器”的作用，全连接层则起到将学到的“分布式特征表示”映射到样本标记空间的作用。在实际使用中，全连接层可由卷积操作实现：对前层是全连接的全连接层可以转化为卷积核为1x1的卷积；而前层是卷积层的全连接层可以转化为卷积核为hxw的全局卷积，h和w分别为前层卷积结果的高和宽</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/3c266da23107494b04b09683b8427f0e.png" alt="3c266da23107494b04b09683b8427f0e">
<figcaption aria-hidden="true">3c266da23107494b04b09683b8427f0e</figcaption>
</figure>
<p>卷积核的运算</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/7b8af7c9507e7652df6ff7e3c14f8a1f.png" alt="7b8af7c9507e7652df6ff7e3c14f8a1f">
<figcaption aria-hidden="true">7b8af7c9507e7652df6ff7e3c14f8a1f</figcaption>
</figure>
<h2 id="应用">应用</h2>
<p>2D卷积神经网络（2D CNN）则主要用于处理二维图像数据，如<a href="https://cloud.baidu.com/product/face">人脸识别</a>、物体检测和自动驾驶等任务。2D
CNN通过将图像划分为多个小的矩形区域（也称为滤波器或卷积核），可以对每个区域进行<strong>独立的特征提取</strong>。这种网络结构可以有效地减少计算量，同时提高特征提取的精度。在计算机视觉领域，2D
CNN已经成为许多重要应用的基石，如人脸识别和目标检测等。</p>
<h1 id="三维卷积-3d-cnn">三维卷积 3D CNN</h1>
<p>三维卷积输入多了深度C这个维度，输入是高度H<em>宽度W</em>深度C的三维矩阵。</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/7d1a499a0a3c3a43c7677e57c85e1890.png" alt="7d1a499a0a3c3a43c7677e57c85e1890">
<figcaption aria-hidden="true">7d1a499a0a3c3a43c7677e57c85e1890</figcaption>
</figure>
<p>3D
CNN是如何对时间维度进行操作的，如下图所示，我们将时间维度看成是第三维，这里是对连续的四帧图像进行卷积操作，3D卷积是通过堆叠多个连续的帧组成一个立方体，然后在立方体中运用3D卷积核。在这个结构中，卷积层中每一个特征map都会与上一层中多个邻近的连续帧相连，因此捕捉运动信息。
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/f8c08dd50063b71d02bbfe5c73c364dd.png" alt="f8c08dd50063b71d02bbfe5c73c364dd"></p>
<h2 id="三维卷积和多通道卷积的区别">三维卷积和多通道卷积的区别</h2>
<h3 id="多通道卷积">多通道卷积</h3>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/61bbb9de76c74320cb9d22077a128612.jpg" alt="61bbb9de76c74320cb9d22077a128612">
<figcaption aria-hidden="true">61bbb9de76c74320cb9d22077a128612</figcaption>
</figure>
<p>具体的实现过程为：</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/968772caaeba0e8b02257717f4019d97.png" alt="968772caaeba0e8b02257717f4019d97">
<figcaption aria-hidden="true">968772caaeba0e8b02257717f4019d97</figcaption>
</figure>
<p>3D CNN主要运用在视频分类、动作识别等领域，它是在2D
CNN的基础上改变而来。由于2D
CNN不能很好的捕获时序上的信息，因此我们采用3D
CNN，这样就能将视频中时序信息进行很好的利用。</p>
<h1 id="循环神经网络-rnn-与-长短期记忆-lstm">循环神经网络 RNN 与
长短期记忆 LSTM</h1>
<p><a href="https://zhuanlan.zhihu.com/p/123211148">史上最详细循环神经网络讲解（RNN/LSTM/GRU）
- 知乎</a></p>
<p><a href="https://www.bilibili.com/video/BV1z5411f7Bm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【循环神经网络】5分钟搞懂RNN，3D动画深入浅出_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1Z34y1k7mc?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【LSTM长短期记忆网络】3D模型一目了然，带你领略算法背后的逻辑_哔哩哔哩_bilibili</a></p>
<h1 id="立项书框架构建">立项书框架构建</h1>
<h2 id="工作清单">工作清单</h2>
<ol type="1">
<li>每个人写一份自我介绍，包括自身具备的知识条件、自己的特长、兴趣、已有的实践创新成果</li>
<li>每个人查找8篇关于人体动作识别或者暴力事件识别的相关论文，要求：1.国内外论文都要有
2.每个人找好后打成一个压缩包发群里，并把论文名发群里，后面发的就不要跟上面重复了
3.压缩包中除了包含论文，再有一个word文档，简单说明收集每个论文的主要内容</li>
<li>简单看一下我发群里的两份去年的立项书，结合立项书框架想一想，后续会进行分工</li>
</ol>
<h2 id="立项书框架">立项书框架</h2>
<ol type="1">
<li>项目研究背景
<ol type="1">
<li>研究意义</li>
<li>国内外研究现状
<ol type="1">
<li>人类动作识别现状</li>
<li>暴力行为识别现状</li>
</ol></li>
<li>项目研究目标及主要内容</li>
<li>项目创新特色概述</li>
<li>项目研究技术路线</li>
<li>项目方案设计</li>
</ol></li>
</ol>
<h2 id="ppt思路初步构建">PPT思路初步构建</h2>
<h3 id="背景与意义">背景与意义</h3>
<ol type="1">
<li>人体行为事件的含义与应用</li>
<li>视频暴力行为识别的意义</li>
<li>暴力行为的定义，早期与后续方法的比较，数据集的比较，暴力行为识别任务和应用</li>
</ol>
<h3 id="研究现状">研究现状</h3>
<p>单模态与多模态的优点和挑战</p>
<p>行为识别和暴力行为的识别和挑战</p>
<p>数据集的对比</p>
<p>解决方法的比较：3D CNN, 2D CNN+ RNN, 骨架</p>
<h3 id="研究方法抓住识别暴力的要素">研究方法：抓住识别暴力的要素</h3>
<p>一方面：抓住重要因素进行特征提取</p>
<p>另一方面：尽可能去除冗余信息（裁剪 / 去背景）</p>
<p>算法框架</p>
<p>注意力融合模块</p>
<h3 id="总结">总结</h3>
<ol type="1">
<li><p>提出了一种基于多模态特征融合的视频暴力行为识别算法。通过融合RGB模态提供的外观信息、RGB帧差提供的运动信息以及Depth模态提供的相对位置信息，丰富、完善了暴力行为的特征，使其能够准确、鲁棒地在复杂的真实环境下进行暴力行为识别。</p></li>
<li><p>提出了一种自适应的注意力算法用于多模态融合。让模型自适应地学习不同模态特征之间的权重关系，允许模型根据具体任务动态调整每个模态的重要性，从而更灵活地应对不同的场景。</p></li>
</ol>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://blog.csdn.net/qq_63019407/article/details/125805364">【视频异常检测综述-论文阅读】Deep
Video Anomaly Detection: Opportunities and Challenges-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/Yong_Qi2015/article/details/120837919">视频理解综述：动作识别、时序动作定位、视频Embedding-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/YOULANSHENGMENG/article/details/121328554">深度学习笔记—-三维卷积及其应用（3DCNN,PointNet,3D
U-Net）-CSDN博客</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——论文筛选</title>
    <url>/2024/11/19/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B3%E2%80%94%E2%80%94%E8%AE%BA%E6%96%87%E7%AD%9B%E9%80%89/</url>
    <content><![CDATA[<p>本文对目前已收集到的论文进行筛选工作，并简单概述可取之处</p>
<h1 id="视频监控中人体暴力行为检测系统设计与应用">视频监控中人体暴力行为检测系统设计与应用</h1>
<p>非常非常好的一篇，跟我们要做的方向很贴合，每个人都要看一下，以下是我认为可以学习的地方：</p>
<ol type="1">
<li><p>绪论部分：课题研究的背景和意义；从智能视频监控技术和行为识别算法两个方面介绍了研究现状</p></li>
<li><p>同样选用了RWF-2000数据集，并给出了理由，同时介绍了三大常见数据集并进行了比较（HMDB-51，UCF101，Kinetics）；在模型框架技术选型方面，简要介绍了
传统方法，然后对比了深度学习下的基于人体骨架的方法以及基于视频的方法。
之后详细介绍了三类基于视频的深度学习方法（双流法，3D卷积方法
和基于时序模型的方法）</p></li>
</ol>
<p>​ 本文文采用了双流模型 作为基础框架，我后续了解双流法与我们的
多模态方向是很贴合的</p>
<ol start="3" type="1">
<li>本文完成了人体暴力行为检测系统的设计与实现，包含离线分析和在线监测两种模式，这跟我们的设想很符合</li>
</ol>
<h1 id="基于注意力机制的暴力音视频检测方法研究">基于注意力机制的暴力音视频检测方法研究</h1>
<p>与上一篇同样是哈尔滨工业大学的硕士论文，侧重点也是多模态暴力检测，本文先提出分别基于视觉通道和基于听觉通道的暴力音频检测，再提出了基于视听觉通道的音视频特征融合的暴力音视频检测</p>
<p>本文开头的课题研究的背景和意义和研究现状同样值得参考</p>
<h1 id="基于多模态的校园暴力检测">基于多模态的校园暴力检测</h1>
<p>给我感觉一般，多模态的部分写的并不是很好，他还说的一个基于多模态的校园暴力检测，感觉什么都写到了什么都写的不是很精</p>
<p>但是他在相关理论基础详细地介绍了深度学习网络（RNN，LSTM，GRU）和人体动作识别（openpose），可以参考学习</p>
<h1 id="基于对比学习的视频暴力行为检测算法及-tensorrt-平台实现">基于对比学习的视频暴力行为检测算法及
TensorRT 平台实现</h1>
<p>里面的对比学习和注意力机制不是很看得懂，但感觉写的挺好的，这篇还把识别系统做在TensorRT
平台实现轻量化，这个跟我们关系不大，只做了解</p>
<h1 id="基于yolo和convlstm混合神经网络的暴力视频检测">基于YOLO和ConvLSTM混合神经网络的暴力视频检测</h1>
<p>有yolo相关知识，后续可做参考学习</p>
<h1 id="国外论文">国外论文</h1>
<p>因为英文看的太费劲，对国外论文暂时只做初步筛选</p>
<p>Conv3D-Based Video Violence Detection Network Using Optical Flow and
RGB Data：光流和RGB数据多模态</p>
<p>Multimodal vision-based human action recognition using deep learning:
a review：关于多模态的综述论文，这一篇写的不错，有时间值得啃一下</p>
<p>A Real-Time 3-Dimensional Object Detection Based Human Action
Recognition
Model：3D卷积神经网络（3DCNN）、LSTM乘法递归网络和YOLOv6实时目标检测</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——模型环境配置</title>
    <url>/2024/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h3 id="模型环境配置">模型环境配置</h3>
<p>利用yml导入conda虚拟环境</p>
<figure>
<img src="/2024/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/sad.png" alt="sad">
<figcaption aria-hidden="true">sad</figcaption>
</figure>
<p>安装cuda与cudnn</p>
<p><a href="https://blog.csdn.net/weixin_44779079/article/details/141528972">cuda和cudnn的安装教程(全网最详细保姆级教程)_cudnn安装-CSDN博客</a></p>
<p>使用国内源安装</p>
<p><code>pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p><code>pip install --upgrade tensorflow -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p>测试gpu运行</p>
<figure>
<img src="/2024/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/as.png" alt="as">
<figcaption aria-hidden="true">as</figcaption>
</figure>
<figure>
<img src="/2024/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/daf.png" alt="daf">
<figcaption aria-hidden="true">daf</figcaption>
</figure>
<p>根据提示补全依赖项</p>
<p>datasetProcess.py 将视频文件转换为 NumPy 数组（.npy
文件），并保存到指定目录中</p>
<p>models_rgb_depth.py 模型</p>
<p>evaluate_rgb_depth.py 跑数据集，返回准确度</p>
<figure>
<img src="/2024/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/asd.png" alt="asd">
<figcaption aria-hidden="true">asd</figcaption>
</figure>
<p>prediction_test.py 返回true or false</p>
<figure>
<img src="/2024/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/sadff.png" alt="sadff">
<figcaption aria-hidden="true">sadff</figcaption>
</figure>
<p>前两者需要输入命令行参数</p>
<p><code>python evaluate_rgb_depth.py --dataset rwf2000 --vidLen 32 --batchSize 4 --mode all --lstmType sepconv --fusionType C --weightsPath models/rgb_rgbdiff_depth_C_6/rwf2000_best_val_acc_Model</code></p>
<figure>
<img src="/2024/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/gadga.png" alt="gadga">
<figcaption aria-hidden="true">gadga</figcaption>
</figure>
<ul>
<li><code>--dataset rwf2000</code>: 指定数据集为
<code>rwf2000</code>。</li>
<li><code>--vidLen 32</code>: 每个视频序列的帧数为 32。</li>
<li><code>--batchSize 4</code>: 训练和评估的批量大小为 4。</li>
<li><code>--mode all</code>: 模型工作模式为
<code>all</code>，即使用视频帧、帧差和深度图三种输入。</li>
<li><code>--lstmType sepconv</code>: 使用 <code>sepconv</code> 类型的
LSTM 层。</li>
<li><code>--fusionType C</code>: 使用 <code>C</code>
类型的融合策略（特征拼接和注意力机制）。</li>
<li><code>--weightsPath models/rgb_rgbdiff_depth_C_6/rwf2000_best_val_acc_Model</code>:
指定预训练权重文件路径。</li>
</ul>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——Langchain与LLM集成解决方案</title>
    <url>/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/</url>
    <content><![CDATA[<h2 id="了解langchain">了解Langchain</h2>
<p>LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型
(LLM) 和聊天模型提供支持的应用程序的过程。LangChain
可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如
API 和数据库。</p>
<p>一句话概括就是：<strong>langchain
完成了对数据一个提炼、查找的完全链路。</strong>它并不能提供数据源、查找理由，只是一种方法的凝练。</p>
<p>数据源支持由用户等自行提供，因此它支持本地知识库的搭建，合理想象未来的学生课设系统将会是：金融知识系统（使用
langchain 爬取金融网站提取摘要凝练成知识）、图书简介系统（使用 langchain
对图书提取摘要进行展示）……</p>
<h2 id="安装">安装</h2>
<p>Jupyter 就是一个非常好用的 Python 语言编程工具。</p>
<p>或者说是一个 Python
编程语言、以及更多其他编程语言的，交互式集成开发环境。</p>
<p>Jupyter 的一个非常重要的优点，就是
写程序的界面，和运行程序的界面，在一起。</p>
<p>jubyter notebook的安装：<code>pip install jupyterlab</code></p>
<p>web页面的启动：<code>jupyter-lab</code></p>
<p>vscode：创建.ipynb格式的文件</p>
<hr>
<p>langchain的安装：<code>pip install langchain</code></p>
<h2 id="提供一种llm集成解决方案一份代码支持快速同时支持gpt大模型国产大模型通义千问文心一言百度千帆讯飞星火等本地开源大模型ollama">提供一种LLM集成解决方案，一份代码支持快速同时支持gpt大模型、国产大模型(通义千问、文心一言、百度千帆、讯飞星火等)、本地开源大模型(Ollama)</h2>
<p>项目地址：<a href="https://github.com/NanGePlus/LLMTest">NanGePlus/LLMTest:
为实现代码的高扩展性和兼容性，提出一套综合解决方案，支持多种大模型类型的无缝集成，包括GPT系列大模型、国内主流模型（如通义千问、智谱AI等），以及本地化部署的大模型（如qwen2.5）。</a></p>
<h3 id="前期准备">前期准备</h3>
<p>openai-api代理：<a href="https://api.wlai.vip/">云雾 API</a></p>
<p>安装One-Api</p>
<p><a href="https://github.com/songquanpeng/one-api">songquanpeng/one-api:
OpenAI 接口管理 &amp; 分发系统，支持 Azure、Anthropic Claude、Google
PaLM 2 &amp; Gemini、智谱
ChatGLM、百度文心一言、讯飞星火认知、阿里通义千问、360
智脑以及腾讯混元，可用于二次分发管理 key，仅单可执行文件，已打包好
Docker 镜像，一键部署，开箱即用. OpenAI key management &amp;
redistribution system, using a single API for all LLMs, and features an
English UI.</a></p>
<p>利用exe</p>
<p><a href="http://localhost:3000/">One API</a></p>
<p>默认账号密码：root 12345</p>
<p>创建渠道，这里以阿里通义千问为例</p>
<p>获取API-KEY：<a href="https://bailian.console.aliyun.com/?spm=5176.29619931.J__Z58Z6CX7MY__Ll8p1ZOR.1.136959fcA1q1xF&amp;accounttraceid=a01e32df30fa4776a42f6cb88a6f938dfnlu#/model-market/detail/qwen-plus">阿里云百炼</a></p>
<p><a href="https://blog.csdn.net/qq_26303031/article/details/140987551">2024年最新免费AI大模型API汇总及国内大模型使用教程（附代码）_免费大模型api-CSDN博客</a></p>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216103856131.png" alt="image-20241216103856131">
<figcaption aria-hidden="true">image-20241216103856131</figcaption>
</figure>
<hr>
<p>使用 Ollama 非常简单，只需要按照以下步骤：</p>
<ol type="1">
<li><strong>安装 Ollama</strong> ： 根据你的操作系统，从 <a href="https://ollama.com/">Ollama 官网</a>下载并安装最新版本。</li>
<li><strong>启动 Ollama</strong> ： 打开终端或命令行，输入
<code>ollama serve</code> 命令启动 Ollama 服务器。</li>
<li><strong>下载模型</strong>： 在<a href="https://ollama.com/library">模型仓库</a>找到想要的模型，然后使用
<code>ollama pull</code> 命令下载，例如
<code>ollama pull llama3:70b</code> 。</li>
<li><strong>运行模型</strong> ： 使用 <code>ollama run</code>
命令启动模型，例如 <code>ollama run llama3:70b</code> 。</li>
<li><strong>开始聊天</strong> ： 在终端中输入你的问题或指令，Ollama
会根据模型生成相应的回复。</li>
<li><strong>查看模型列表</strong> ：<code>ollama list</code></li>
</ol>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216115902772.png" alt="image-20241216115902772">
<figcaption aria-hidden="true">image-20241216115902772</figcaption>
</figure>
<h3 id="项目">项目</h3>
<p>初始化：采用pycharm+anaconda</p>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216120328229.png" alt="image-20241216120328229">
<figcaption aria-hidden="true">image-20241216120328229</figcaption>
</figure>
<p>安装依赖</p>
<p>pip install -r requirements.txt
每个软件包后面都指定了本次视频测试中固定的版本号 <strong>注意：</strong>
截止2024.10.18，langchain最新版本为0.3.3，langchain-openai最新版本为0.2.2</p>
<p>调整api，调整 utils/myLLM.py 内容</p>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216131346999.png" alt="image-20241216131346999">
<figcaption aria-hidden="true">image-20241216131346999</figcaption>
</figure>
<p>调整 llmTest.py 内容</p>
<p>LLM_TYPE = “oneapi” #
openai：调用gpt模型;oneapi：调用oneapi方案支持的模型（这里调用通义千问）</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://github.com/langchain-ai/langchain?tab=readme-ov-file">langchain-ai/langchain：🦜🔗构建上下文感知推理应用程序</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/680828606">LangChain
入门与避坑指北 - 知乎</a></p>
<p><a href="https://www.langchain.com.cn/docs/introduction/">LangChain中文网</a></p>
<p><a href="https://blog.csdn.net/franklfeng/article/details/117562667">Jupyter
是什么-CSDN博客</a></p>
<p><a href="https://vscode.github.net.cn/docs/datascience/jupyter-notebooks#_save-your-jupyter-notebook">在
Visual Studio Code 中使用 Jupyter Notebook_Vscode中文网</a></p>
<p><a href="https://cuterwrite.top/p/ollama/#:~:text=如何使用%20Ollama？%201%20安装%20Ollama：%20根据你的操作系统，从%20Ollama%20官网,ollama%20run%20llama3%3A70b%20。%205%20开始聊天：%20在终端中输入你的问题或指令，Ollama%20会根据模型生成相应的回复。">Ollama：从入门到进阶</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——LightRAG与GraphRAG</title>
    <url>/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/</url>
    <content><![CDATA[<h2 id="graphrag">GraphRAG</h2>
<p>最新消息是11.26凌晨，微软宣布将推出 GraphRAG
的全新迭代版本LazyGraphRAG
核心亮点是极低的使用成本，其数据索引成本仅为现有GraphRAG 的
0.1%。此外，LazyGraphRAG
引入了全新的混合数据检索方法，大幅提升了生成结果的准确性和效率。该版本将很快开源，并纳入到
GitHub GraphRAG 库中
原文链接如下:https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/</p>
<hr>
<p><strong>支持的检索方式</strong></p>
<p><strong>Naive Search</strong> Naive
模式是最简单的检索策略，它直接基于输入查询计算向量相似度，返回最接近的结果，不进行任何额外的优化或复杂处理
<strong>Local Search</strong> Local
模式只在本地上下文范围内进行检索。它聚焦于用户当前输入的特定领域或某部分数据，不会考虑全局数据
<strong>Global Search</strong> Global
模式会在整个知识库范围内进行检索，试图找到与查询最相关的信息，而不局限于当前上下文或局部区域
<strong>Hybrid Search</strong> Hybrid 模式结合了 Local 和 Global
的优势，同时考虑局部上下文和全局信息，综合结果以提高答案的相关性和覆盖范围</p>
<h2 id="anaconda">Anaconda</h2>
<p>Anaconda，中文大蟒蛇，是一个开源的Anaconda是专注于数据分析的Python发行版本，包含了conda、Python等190多个科学包及其依赖项。</p>
<p>Anaconda就是可以便捷获取包且对包能够进行管理，包括了python和很多常见的软件库和一个包管理器conda。常见的科学计算类的库都包含在里面了，使得安装比常规python安装要容易，同时对环境可以统一管理的发行版本</p>
<h3 id="为什么要安装anaconda">为什么要安装Anaconda？</h3>
<p>Anaconda对于python初学者而言及其友好，相比单独安装python主程序，选择Anaconda可以帮助省去很多麻烦，Anaconda里添加了许多常用的功能包，如果单独安装python，这些功能包则需要一条一条自行安装，在Anaconda中则不需要考虑这些，同时Anaconda还附带捆绑了两个非常好用的交互式代码编辑器（Spyder、Jupyter
notebook）。</p>
<p>简单来说，Anconda，可以理解成运输车，每当下载Anconda的时候，里面不仅包含了python，还有180多个库（武器)一同被打包下载下来。</p>
<p>下载完Anconda之后，再也不用一个个下载那些库了。</p>
<h3 id="集成开发环境搭建anacondapycharm">集成开发环境搭建Anaconda+PyCharm</h3>
<p><a href="https://www.bilibili.com/video/BV1q9HxeEEtT/?vd_source=30acb5331e4f5739ebbad50f7cc6b949">【大模型应用开发基础】集成开发环境搭建Anaconda+PyCharm_哔哩哔哩_bilibili</a></p>
<h2 id="lightrag与graphrag运行对比">LightRAG与GraphRAG运行对比</h2>
<p><a href="https://github.com/NanGePlus/LightRAGTest">NanGePlus/LightRAGTest:
LightRAG与GraphRAG在索引构建、检索测试中的耗时、模型请求次数、Token消耗金额、检索质量等方面进行对比</a></p>
<p>命令行终端中执行如下命令安装依赖包 cd LightRAG pip install -e . cd
GraphRAG pip install graphrag==0.5.0</p>
<hr>
<p><strong>测试文本</strong>
测试文本均为使用西游记白话文前九回内容，文件名为book.txt
<strong>模型配置</strong>
大模型使用OpenAI(代理方案)，Chat模型均使用gpt-4o-mini,Embedding模型均使用text-embedding-3-small
<strong>其他配置</strong> 笔记本均为MacBook
Pro2017,网速、python环境均相同</p>
<hr>
<p>LightRAG测试</p>
<p>(1)构建索引</p>
<p>打开命令行终端，执行如下指令 cd LightRAG/nangeAGICode python test.py
<strong>注意</strong>
在运行脚本之前，需要调整相关代码将如下代码块打开，检索相关的代码块注释</p>
<p>(2)逐一测试</p>
<p>执行如下指令 cd LightRAG/nangeAGICode python test.py
<strong>注意</strong>
在运行脚本之前，需要注释如下构建索引代码，取消检索相关的代码块注释</p>
<p>GraphRAG测试</p>
<p>(1)构建索引</p>
<p>打开命令行终端，执行如下指令 cd GraphRAG graphrag index –root ./</p>
<p>(2)逐一测试</p>
<p>graphrag query –root ./ –method local –query
“这个故事的核心主题是什么?” graphrag query –root ./ –method global
–query “这个故事的核心主题是什么?” graphrag query –root ./ –method drift
–query “这个故事的核心主题是什么?”</p>
<hr>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/img.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="利用neo4j可视化">利用neo4j可视化</h2>
<p><strong>测试文本</strong> 测试文本均为使用西游记白话文前九回内容
<strong>模型配置</strong>
大模型均使用OpenAI(代理方案)，Chat模型均使用gpt-4o,Embedding模型均使用text-embedding-3-small
<strong>其他配置</strong> 笔记本均为MacBook
Pro2017,网速、python环境均相同</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># gpt大模型相关配置根据自己的实际情况进行调整</span><br><span class="line">OPENAI_API_BASE = &quot;https://api.wlai.vip/v1&quot;</span><br><span class="line">OPENAI_CHAT_API_KEY = &quot;sk-Tuza9B8WYo1vkBAAmmLeQjuOl1VTP9Dd0nuKxqnLOaJJMZZd&quot;</span><br><span class="line">OPENAI_CHAT_MODEL = &quot;gpt-4o&quot;</span><br><span class="line">OPENAI_EMBEDDING_MODEL = &quot;text-embedding-3-small&quot;</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="lightrag构建索引测试">LightRAG构建索引测试</h3>
<h4 id="安装textract依赖包">(1)安装textract依赖包</h4>
<p>通过指令 pip install textract 安装时会报错，报错的原因是
其元数据文件中使用了不再被支持的版本约束符号（&lt;=0.29.*），而当前 pip
和 setuptools 不再接受这种格式
解决方案:下载依赖包源码，修改相应参数后本地进行安装
https://pypi.org/project/textract/1.6.5/#description cd textract-1.6.5
pip install .</p>
<h4 id="创建neo4j数据库实例">(2) 创建neo4j数据库实例</h4>
<p>推荐使用云服务进行测试，链接地址如下:
https://console-preview.neo4j.io/tools/query
注册登录成功，直接新建实例即可</p>
<p>也可以用本地neo4j</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据库连接相关参数配置</span></span><br><span class="line">NEO4J_URI=<span class="string">&quot;bolt://localhost:7687&quot;</span></span><br><span class="line">NEO4J_USERNAME=<span class="string">&quot;neo4j&quot;</span></span><br><span class="line">NEO4J_PASSWORD=<span class="string">&quot;zxj03051218&quot;</span></span><br><span class="line">NEO4J_DATABASE=<span class="string">&quot;neo4j&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="增量索引构建及知识图谱可视化测试">(3)增量索引构建及知识图谱可视化测试</h4>
<p>运行如下指令进行索引构建 cd LightRAG/nangeAGICode1201 python
insertTest.py python queryTest.py
每一次构建完成，先清除数据库中的数据再运行如下指令进行可视化
在运行之前需要根据自己的实际情况进行参数的调整 python
graph_visual_with_html.py</p>
<p>python graph_visual_with_neo4j.py
<strong>在数据库中进行查询测试</strong> MATCH (n:<code>PERSON</code>)
WHERE n.displayName CONTAINS ‘唐僧’ RETURN n LIMIT 25;</p>
<p>MATCH (n:<code>PERSON</code>) WHERE n.displayName CONTAINS ‘八戒’
RETURN n LIMIT 25;</p>
<p>MATCH (n:<code>PERSON</code>) WHERE n.displayName CONTAINS ‘沙和尚’
RETURN n LIMIT 25;</p>
<p><strong>清除数据</strong> MATCH (n) CALL { WITH n DETACH DELETE n }
IN TRANSACTIONS OF 25000 ROWS;</p>
<p>MATCH (n) OPTIONAL MATCH (n)-[r]-() DELETE n,r</p>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/image-20241221160947727.png" alt="image-20241221160947727">
<figcaption aria-hidden="true">image-20241221160947727</figcaption>
</figure>
<figure>
<img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/image-20241221160843951.png" alt="image-20241221160843951">
<figcaption aria-hidden="true">image-20241221160843951</figcaption>
</figure>
<h3 id="lightrag和graphrag生成的知识图谱对比">LightRAG和GraphRAG生成的知识图谱对比</h3>
<p>运行如下指令将GraphRAG生成的知识图谱进行可视化展示 cd GraphRAG/utils
python graph_visual_with_neo4j.py
在运行脚本前根据自己的实际情况进行调整,修改文件所在路径为存储增量数据的文件路径
GRAPHRAG_FOLDER=“/Users/janetjiang/Desktop/agi_code/LightRAGTest/GraphRAG/output”
<strong>在数据库中进行查询测试</strong> MATCH
(n:<code>__Entity__</code>) WHERE n.name CONTAINS ‘唐僧’ RETURN n LIMIT
25;</p>
<p>MATCH (n:<code>__Entity__</code>) WHERE n.name CONTAINS ‘八戒’ RETURN
n LIMIT 25;</p>
<p>MATCH (n:<code>__Entity__</code>) WHERE n.name CONTAINS ‘沙和尚’
RETURN n LIMIT 25;</p>
<p><strong>清除数据</strong> MATCH (n) CALL { WITH n DETACH DELETE n }
IN TRANSACTIONS OF 25000 ROWS;</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1CmzEYcEnS/?spm_id_from=333.1007.tianma.1-1-1.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">LightRAG与GraphRAG对比评测，从索引构建、本地检索、全局检索、混合检索等维度对请求大模型次数、Token消耗、金额消耗、检索质量等方面进行全面对比_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/weixin_56197703/article/details/124630222">还是搞不懂Anaconda是什么?读这一篇文章就够了-CSDN博客</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——Neo4j</title>
    <url>/2024/12/06/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94Neo4j/</url>
    <content><![CDATA[<h2 id="什么是-neo4j">什么是 Neo4j？</h2>
<p><strong>Neo4j</strong> 是一个开源的<strong>图形数据库</strong>，由
Neo4j 公司开发和维护。作为图数据库的代表，Neo4j
使用图理论中的节点和边（关系）来表示和存储数据，相较于传统的关系型数据库（如
MySQL、PostgreSQL）和其他 NoSQL 数据库（如文档型、键值型数据库），Neo4j
在处<strong>理复杂关系和连接性强的数据方面</strong>具有显著优势。</p>
<h3 id="主要特点">主要特点：</h3>
<ul>
<li><strong>图模型</strong>：使用节点、关系和属性来建模数据，直观地反映实体及其之间的关联。</li>
<li><strong>Cypher
查询语言</strong>：专为图数据库设计的声明式查询语言，语法简洁，易于表达复杂的图形查询。</li>
<li><strong>高性能</strong>：优化的存储和索引机制，能够高效地处理大规模图数据和复杂查询。</li>
<li><strong>ACID
事务支持</strong>：保证数据的一致性和可靠性，适用于需要强事务保障的应用场景。</li>
</ul>
<h2 id="为什么需要-neo4j">为什么需要 Neo4j？</h2>
<p>在许多应用场景中，<strong>数据之间存在复杂的关系和连接性</strong>。传统的关系型数据库在处理多层级的关联查询时，往往需要大量的联接操作（JOIN），这会导致查询性能下降，尤其是在数据规模庞大时。而
Neo4j
通过图模型天然适合表示和处理这种高度连接的数据，能够更高效地执行复杂的关系查询。</p>
<h3 id="主要需求原因">主要需求原因：</h3>
<ol type="1">
<li><strong>复杂关系处理</strong>：需要频繁进行多级关联查询，如社交网络、推荐系统等。</li>
<li><strong>灵活的数据模型</strong>：数据结构可能随时间变化，图数据库提供了更大的灵活性。</li>
<li><strong>性能需求</strong>：需要在大规模数据集上执行快速的关系查询和遍历操作。</li>
<li><strong>实时性</strong>：需要实时分析和处理数据关系，如欺诈检测、网络安全等。</li>
</ol>
<figure>
<img src="/2024/12/06/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94Neo4j/ed250b8ea580015278be07a9233448c2.png" alt="ed250b8ea580015278be07a9233448c2">
<figcaption aria-hidden="true">ed250b8ea580015278be07a9233448c2</figcaption>
</figure>
<h2 id="graphrag的理解">GraphRAG的理解</h2>
<p><strong>GraphRAG=Graph(知识图谱)+RAG技术</strong></p>
<p><strong>GraphRAG</strong>
是一种结合了<strong>图结构</strong>和<strong>检索增强生成（RAG）</strong>的方法，旨在增强语言模型（如大规模预训练的变换器模型）的推理能力和信息检索能力。这个方法通常用于处理复杂的推理任务，尤其是当涉及到大规模知识库或图形数据时，GraphRAG可以通过图的结构来有效地组织信息，从而提高模型在生成和推理时的效率和准确性。</p>
<p><strong>图结构（Graph）</strong>：</p>
<ul>
<li><strong>图</strong>通常用于表示节点之间的关系和依赖，在处理复杂知识结构时非常有用。在GraphRAG中，图结构帮助捕捉信息之间的关系，能够有效地组织和链接不同的知识点，尤其是在涉及多个实体和关系的任务中。</li>
</ul>
<p><strong>检索增强生成（RAG）</strong>：</p>
<ul>
<li>RAG
是一种将信息检索与生成模型结合的框架。它的核心思想是，模型在生成答案时不仅仅依赖于其预训练时获得的知识，还会从一个外部数据库或文档库中检索相关的信息来增强回答的准确性和上下文适应性。</li>
</ul>
<h2 id="neo4j的安装">Neo4j的安装</h2>
<ol type="1">
<li>官网下载社区版</li>
<li>安装JDK，java11</li>
<li>配置环境变量</li>
<li>启动Neo4j</li>
</ol>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">常用命令</span><br><span class="line"># 启动服务</span><br><span class="line">neo4j(.bat) start</span><br><span class="line"># 重启服务</span><br><span class="line">neo4j(.bat) restart</span><br><span class="line"># 停止服务</span><br><span class="line">neo4j(.bat) stop</span><br><span class="line"># 控制台模式启动</span><br><span class="line">neo4j(.bat) console</span><br></pre></td></tr></table></figure>
</blockquote>
<ol start="5" type="1">
<li>进入到 http://localhost:7474</li>
</ol>
<p>账号密码 neo4j zxj03051218</p>
<p>第一次进入前安装neo4j 的服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">neo4j install-service</span><br></pre></td></tr></table></figure>
<p>查看版本 neo4j –version</p>
<h2 id="apoc用处">apoc用处</h2>
<p>数据导入和导出：使用APOC插件可以轻松导入和导出不同格式的数据到Neo4j图数据库。您可以将数据从关系型数据库、CSV文件、JSON等转换为图形数据，并相反地，将图形数据导出到其他格式。
图形算法：APOC提供了许多有用的图形算法，如PageRank、社区发现（例如Louvain算法），路径分析等。这些算法可以帮助您发现数据之间的关联性和模式，并从中提取有价值的信息。
数据清洗和转换：APOC提供了丰富的过程和函数，用于数据清洗和转换。您可以使用它来处理字符串、时间、密码学等方面的数据，并进行必要的清洗和格式化。
可视化：APOC支持将图形数据转换为其他可视化工具所需的格式，例如Gephi、D3.js等。这使得您可以将您的图形数据以更直观的方式呈现，进一步探索和交流。
地理空间分析：APOC提供了与地理空间数据相关的功能，如计算两个地点之间的距离、查找附近的地点等。这对于在地理空间上分析和查询数据特别有用。</p>
<p>我应该是主要用到了数据导入和导出的功能，因为要将构建好的所以传到本地neo4j上</p>
<h2 id="apoc插件安装">apoc插件安装</h2>
<p><a href="https://blog.csdn.net/shdabai/article/details/132880323">知识图谱基本工具Neo4j使用笔记
五 ：APOC插件安装及简单应用_neo4j apoc-CSDN博客</a></p>
<p>版本 neo4j 4.4.39</p>
<p>APOC插件下载：apoc-4.4.0.9-all.jar（注意apoc要与neo4j版本对应）</p>
<p><a href="https://github.com/neo4j/apoc/releases?page=2">Releases ·
neo4j/apoc</a></p>
<p>将下载的 <code>apoc-4.4.0.9-all.jar</code>
直接复制到neo4j/plugins文件夹</p>
<p>修改APOC的配置文件</p>
<p>打开配置文件将，这一下内容的注释去掉</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dbms.security.procedures.unrestricted=apoc.*</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://segmentfault.com/a/1190000037690548#item-0-2">java -
我的Neo4j探索之旅 - 初识Neo4j（一） - 个人文章 - SegmentFault
思否</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——初识RAG</title>
    <url>/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<p>基于 <strong>LLM （Large Language
Model）</strong>最火热的应用技术是什么，检索增强生成（<strong>RAG，Retrieval
Augmented Generation</strong>）技术必占据重要的一席。RAG 最初是为了解决
LLM
的各类问题的产生的，但后面大家发现在现阶段的很多企业痛点上，使用RAG好像是更好的解决方案。</p>
<p>LLM的问题</p>
<p>尽管LLM拥有令人印象深刻的能力，但是它们还面临着一些问题和挑战：</p>
<ul>
<li><p>幻觉问题：大模型的底层原理是基于概率，在没有答案的情况下经常会胡说八道，提供虚假信息。</p></li>
<li><p>时效性问题：规模越大（参数越多、tokens
越多），大模型训练的成本越高。类似 ChatGPT3.5，起初训练数据是截止到 2021
年的，对于之后的事情就不知道了。而且对于一些高时效性的事情，大模型更加无能为力，比如帮我看看今天晚上有什么电影值得去看？这种任务是需要去淘票票、猫眼等网站先去获取最新电影信息的，大模型本身无法完成这个任务。</p></li>
<li><p>数据安全：OpenAI
已经遭到过几次隐私数据的投诉，而对于企业来说，如果把自己的经营数据、合同文件等机密文件和数据上传到互联网上的大模型，那想想都可怕。既要保证安全，又要借助
AI
能力，那么最好的方式就是<strong>把数据全部放在本地，企业数据的业务计算全部在本地完成</strong>。而在线的大模型仅仅完成一个归纳的功能，甚至，LLM
都可以完全本地化部署。</p></li>
</ul>
<hr>
<p>解决这些挑战对于 LLMs
在各个领域的有效利用至关重要。一个有效的解决方案是集成检索增强生成（RAG）技术，该技术通过获取外部数据来响应查询来补充模型，从而确保更准确和最新的输出。主要表现方面如下：</p>
<ul>
<li><p>有效避免幻觉问题：虽然无法 100% 解决大模型的幻觉问题，但通过 RAG
技术能够有效的降低幻觉，在软件系统中结合大模型提供幂等的API接口就可以发挥大模型的重要作用。</p></li>
<li><p>经济高效的处理知识&amp;开箱即用：只需要借助信息检索和向量技术，将用户的问题和知识库进行相关性搜索结合，就能高效的提供大模型不知道的知识，同时具有权威性。</p></li>
<li><p>数据安全：企业的数据可以得到有效的保护，通过私有化部署基于 RAG
系统开发的AI产品，能够在体验AI带来的便利性的同时，又能避免企业隐私数据的泄漏。</p></li>
</ul>
<h1 id="什么是rag">什么是RAG</h1>
<p>RAG 是检索增强生成（Retrieval Augmented Generation
）的简称，它为大语言模型 (LLMs)
提供了从数据源检索信息的能力，并以此为基础生成回答。简而言之，RAG
结合了信息检索技术和大语言模型的提示功能，即模型根据搜索算法找到的信息作为上下文来查询回答问题。无论是查询还是检索的上下文，都会被整合到发给大语言模型的提示中。
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/v2-76c9a386a70bbcd610f76f1f32423165_1440w.png" alt="v2-76c9a386a70bbcd610f76f1f32423165_1440w"></p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/e9280ebbd3c04d400de7c0619fd0bb50.jpg" alt="e9280ebbd3c04d400de7c0619fd0bb50">
<figcaption aria-hidden="true">e9280ebbd3c04d400de7c0619fd0bb50</figcaption>
</figure>
<p>RAG
的架构如图中所示。它既不是一个特定的开源代码库，也不是某个特定的应用，是一个开发框架。</p>
<p>完整的 RAG 应用流程主要包含两个阶段：</p>
<p>数据准备阶段：（A）数据提取–&gt; （B）分块（Chunking）–&gt;
（C）向量化（embedding）–&gt; （D）数据入库</p>
<p>检索生成阶段：（1）问题向量化–&gt; （2）根据问题查询匹配数据–&gt;
（3）获取索引数据 –&gt; （4）将数据注入Prompt–&gt; （5）LLM生成答案</p>
<h2 id="向量数据库">向量数据库</h2>
<h3 id="gpt-的缺陷">GPT 的缺陷</h3>
<p>GPT-3.5/4
带给我们无限震撼的同时，其天然的缺陷和诸多的限制也让开发者头痛不已，例如其输入端上下文（tokens）大小的限制困扰着很多的开发者和消费者，像
gpt-3.5-turbo 模型它的限制是 4K
tokens(～3000字)，这意味着使用者最多只能输入 3000 字给 GPT
来理解和推理答案。</p>
<h3 id="向量数据库的崛起">向量数据库的崛起</h3>
<p>在 GPT
模型的限制下，开发者们不得不寻找其他的解决方案，而向量数据库就是其中之一。向量数据库的核心思想是将文本转换成向量，然后将向量存储在数据库中，当用户输入问题时，将问题转换成向量，然后在数据库中搜索最相似的向量和上下文，最后将文本返回给用户。</p>
<p>当我们有一份文档需要 GPT
处理时，例如这份文档是客服培训资料或者操作手册，我们可以先将这份文档的所有内容转化成向量（这个过程称之为
Vector
Embedding），然后当用户提出相关问题时，我们将用户的搜索内容转换成向量，然后在数据库中搜索最相似的向量，匹配最相似的几个上下文，最后将上下文返回给
GPT。这样不仅可以大大减少 GPT
的计算量，从而提高响应速度，更重要的是降低成本，并绕过 GPT 的 tokens
限制。</p>
<h1 id="rag的挑战">RAG的挑战</h1>
<p>一个基本的 RAG 通常集成了一个向量数据库和一个 LLM，其中<a href="https://zilliz.com/learn/what-is-vector-database">向量数据库</a>存储并检索与用户查询相关的上下文信息，LLM
根据检索到的上下文生成答案。虽然这种方法在大部分情况下效果都很好，但在处理复杂任务时却面临一些挑战，如多跳推理（multi-hop
reasoning）或联系不同信息片段全面回答问题。</p>
<p>以这个问题为例：“<em>What name was given to the son of the man who
defeated the usurper Allectus?</em>”</p>
<p>一个基本的 RAG 通常会遵循以下步骤来回答这个问题：</p>
<ol type="1">
<li>识别那个人：确定谁打败了 Allectus。</li>
<li>研究那个人的儿子：查找有关这个人家庭的信息，特别是他的儿子。</li>
<li>找到名字：确定儿子的名字。</li>
</ol>
<p>通常第一步就会面临挑战，因为基本的 RAG 根据<a href="https://zilliz.com/glossary/semantic-similarity">语义相似性</a>检索文本，而不是基于在数据集中没有明确提及具体细节来回答复杂的查询问题。这种局限性让我们很难找到所需的确切信息。解决方案通常是为常见查询手动创建问答对。但这种解决方案通常十分昂贵甚至不切实际。</p>
<p>为了应对这些挑战，微软研究院引入了 <a href="https://microsoft.github.io/graphrag/">GraphRAG</a>，这是一种全新方法，它通过知识图谱增强
RAG 的检索和生成。</p>
<h1 id="graphrag的诞生">GraphRAG的诞生</h1>
<p>与使用向量数据库检索语义相似文本的基本 RAG 不同，GraphRAG
通过结合知识图谱（KGs）来增强
RAG。知识图谱是一种数据结构，它根据数据间的关系来存储和联系相关或不相关的数据。</p>
<p>GraphRAG 流程通常包括两个基本过程：索引和查询。</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/1_03c0dcc161.png" alt="1_03c0dcc161">
<figcaption aria-hidden="true">1_03c0dcc161</figcaption>
</figure>
<h1 id="graphrag的优势">GraphRAG的优势</h1>
<p>基础 RAG 和 GraphRAG
都被问到了同样的问题，这需要汇总整个数据集中的信息来构成答案。</p>
<p>问：What are the top 5 themes in the dataset?</p>
<p>下图为答案。基础 RAG
提供的结果与战争主题无关，因为向量搜索检索到了无关的文本，导致了答案的不准确。相比之下，GraphRAG
提供了一个清晰且高度相关的答案，识别了主要的主题和相关细节。结果与数据集一致，并引用了源材料。</p>
<p>上述例子展示了 GraphRAG
如何通过结合知识图谱和向量数据库，更有效地处理需要跨数据集整合信息的复杂查询，从而提高答案的相关性和准确性。</p>
<figure>
<img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/5_8bd8df7ac9.png" alt="5_8bd8df7ac9">
<figcaption aria-hidden="true">5_8bd8df7ac9</figcaption>
</figure>
<p>GraphRAG 在多跳推理和复杂信息总结方面性能明显更佳。研究表明GraphRAG
在全面性和多样性方面都超过了基础 RAG：</p>
<ul>
<li><strong>全面性</strong>：答案覆盖问题的所有方面。</li>
<li><strong>多样性</strong>：答案提供的观点和见解具有多样性和丰富性。</li>
</ul>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://blog.csdn.net/Python_0011/article/details/139752344">大模型RAG入门及实践（非常详细）零基础入门到精通，收藏这一篇就够了-CSDN博客</a></p>
<p><a href="https://cloud.tencent.com/developer/article/2312534">向量数据库｜一文全面了解向量数据库的基本概念、原理、算法、选型-腾讯云开发者社区-腾讯云</a></p>
<p><a href="https://zilliz.com.cn/blog/graphrag-explained-enhance-rag-with-knowledge-graphs">GraphRAG
详解: 通过知识图谱提升 RAG 系统 - Zilliz 向量数据库</a></p>
<p>论文： https://arxiv.org/pdf/2404.16130</p>
<p><a href="https://www.bilibili.com/video/av1256338452?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">GraphRAG：知识图谱+RAG、更高质量的检索_哔哩哔哩_bilibili</a></p>
<p>微软开源的GraphRAG代码： https://github.com/microsoft/graphrag</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——立项答辩</title>
    <url>/2024/12/08/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B4%E2%80%94%E2%80%94%E7%AB%8B%E9%A1%B9%E7%AD%94%E8%BE%A9/</url>
    <content><![CDATA[<h2 id="答辩稿">答辩稿</h2>
<p>各位评委老师大家好，我是我们组的主持人张熙浚，我们组的研究方向是基于多模态特征融合的视频暴力行为识别方法的研究</p>
<p>接下来我会从四个方面介绍我们的项目</p>
<p>首先是背景与意义，暴力行为对社会危害极大，即使公共场所存在大量监控摄像头，但这些视频片段通常被用来在暴力犯罪发生后提供线索和证据，而很少被用来实时监控并阻止暴力行为。</p>
<p>由于监控人员不可能实时监控每一个摄像头产生的视频，所以部署暴力行为监测系统，能够节约人力资源，降低监控人员因疲劳而造成的风险，这十分关键</p>
<p>接下来，我将讲述当前暴力行为检测的研究现状。主流的人体动作识别把数据模态分为2类：视觉模态和非视觉模态。不同模态的数据有着各自的独特优势。</p>
<p>目前主流的单模态深度学习方法存在以下缺点。但真实的暴力事件场景往往存在以下特点。因此，我们提出了基于多模态的暴力事件检测，通过结合多种数据来源，从多个角度捕捉行为特征，尤其是在面对复杂环境、多人交互和遮挡等问题时，具有显著的优势。</p>
<p>接下来我会通过几篇论文中的方法介绍行为识别算法的研究现状</p>
<p>这一篇提出了数据集Rwf-2000，同时提出一种的双流网络架构，他们充分利用了RGB数据提供的外观信息和光流提供的运动信息，但缺点在于光流法计算量大、存储成本高，仅仅适用于光照条件良好、不拥挤的情况</p>
<p>这一篇是基于骨架的方法，通过提取人体骨骼关节，构成三维骨架阵列，通过骨架点卷积，实现分类。</p>
<p>优点是骨架可以很好的表示人体运动信息，但问题在于仅使用骨架数据，效果高度依赖于位姿估计的精度，无法有效应对存在遮挡的情况，同时因为仅使用骨架数据，其他信息存在缺失</p>
<p>这一篇是基于 2D CNN + RNN 的方法，2D CNN
提供强大的空间特征提取能力，RNN
提供强大的时间序列建模能力。将两者结合，能够更好地理解视频中的空间和时间信息。这一篇使用简单快速的预处理方法减少了冗余的背景信息，但其仅使用RGB模态，提取的特征不够全面</p>
<p>接下来我将介绍我们的研究内容与方法</p>
<p>我们的研究内容大致包含三个部分：1.提出一种基于多模态特征融合的视频暴力行为识别算法2.提出一种自适应的注意力算法用于多模态融合3.完成人体暴力行为检测系统的设计，接下来我将依次为大家介绍</p>
<p>第一部分，在特征提取阶段，为了区分暴力行为与非暴力行为，我们选择了三个要素进行提取：人体姿态、运动趋势和幅度、人物之间的位置关系，为了获取以上三个要素，研究工作包括下列内容：</p>
<p>a.RGB模态的去除冗余信息
为了避免原生RGB图像冗余信息影响模型判断，我们决定对于原生RGB图像进行冗余信息去除工作，首先计算一个视频中所有帧的均值，记为平均帧，用每一帧减去平均帧：去除不变的背景，保留运动的人体。</p>
<p>b.运动趋势与幅度特征的提取
目前主流反映物体运动趋势的方法是光流法，但我们考虑到光流图像在低像素复杂场景下效果不佳，且易受光照条件改变，并且计算量巨大，于是我们决定采取帧差法，通过对视频图像序列中相邻两帧作差分运算，来获得运动目标轮廓，以很好地适用于存在多个运动目标的情况。</p>
<p>c.深度模态的提取
在原始的RGB模态，复杂场景中难以分辨人物间的相对位置关系。因此，我们选取深度模态，其去除了颜色和纹理信息，并提供三维结构信息和人体轮廓，我们利用该论文提出的深度估计算法，对原始RGB视频进行深度估计，得到深度图，其清晰地反映了三维空间中人物间的相对位置关系。</p>
<p>算法框架方面，我们选择了CNN-LSTM的深度学习网络<strong>。</strong>LSTM擅长处理时序数据，而CNN能够从视频帧中提取空间特征。通过结合两者的优势，并以此构建了算法框架。</p>
<p>第二部分我们提出了一种自适应的注意力算法用于多模态融合，动态调整每个模态的权重，强调有用的信息特征，抑制不太有用的特征，从而应对不同场景。</p>
<p>池化，全连接层，归一化函数</p>
<p>第三部分，我们完成了人体暴力行为检测系统的设计，刻画了系统的边界及大小，人体暴力行为检测系统是一个自动检测暴力行为的智能视频监控系统。该系统采用了四层架构，即访问层，表示层、业务层以及数据层。
包含暴力检测模块，用户管理模块，视频源管理模块</p>
<p>我们已经初步构建了暴力行为的检测流程，系统包含离线分析和在线监测两种模式</p>
<p>为了提高检测速度和避免资源浪费，根据传入视频的总帧数进行判断，采取提示过短、一次预测或是多轮预测。</p>
<p>离线分析不依赖实时的监控视频，可对任意视频进行分析。它
的优点是它不依赖于视频监控系统，可以直接选择视频开始分析。</p>
<p>在线监测是暴力行为检测系统提供的另一种检测方式。它旨在利用监控视频资源，进行实时的暴力行为检测，达到即时分析并报警提示的功能。</p>
<p>最后是进度安排，我们已经完成算法大部分的编写，后续会继续完成系统的开发</p>
<p>谢谢各位老师观看，请各位老师批评指正</p>
<h2 id="疑问与解惑">疑问与解惑</h2>
<h3 id="为什么暴力行为检测隶属于人体行为识别">为什么暴力行为检测隶属于人体行为识别</h3>
<p>人体行为识别（Human Activity Recognition,
HAR）是一个广泛的领域，旨在通过传感器或视频数据来识别和分析人的各种动作或行为。暴力行为检测（Violent
Behavior Detection,
VBD）是这一领域的一个子任务，其核心目标是识别出具有暴力性质的特定行为，如打斗、推搡、殴打等。</p>
<p>暴力行为检测隶属于人体行为识别，主要原因是暴力行为本质上也是一种“人体行为”，通过分析人体的运动模式、姿态变化、动作轨迹等特征，能够有效识别出暴力事件。</p>
<h3 id="对于暴力行为的定义是什么">对于暴力行为的定义是什么？</h3>
<p>暴力行为通常指的是一种以伤害他人或具有威胁性、攻击性目的的行为。</p>
<h3 id="之前的暴力行为检测方向是什么现在侧重于人体动作本身有什么好处吗">之前的暴力行为检测方向是什么，现在侧重于人体动作本身有什么好处吗？</h3>
<p>暴力行为的检测方法<strong>传统上</strong>主要依赖于视频监控中检测到的图像信息、声音信号以及动作的特征。早期的检测方法侧重于基于背景和环境的变化,声学信号分析</p>
<p>现代的暴力行为检测越来越注重<strong>人体动作本身的识别</strong>，这有几个显著的好处：</p>
<ol type="1">
<li><strong>精确度提高</strong>：通过分析人体动作的细节，尤其是肢体的动态变化（如运动轨迹、速度、姿势变化），可以更准确地判断是否为暴力行为。</li>
<li><strong>降低误报率</strong>：单纯依靠环境变化或者声学分析容易受其他因素干扰（如背景噪音、非暴力事件的运动），而人体动作本身可以提供更加直接、可靠的行为判定依据。</li>
<li><strong>多模态融合</strong>：现代的暴力行为检测往往不仅仅依赖于单一的视觉信息，还结合了深度学习、动作识别等技术，可以从多个角度进行判断。通过分析人体动作特征和其他环境数据（如声音、位置等），可以更好地识别暴力事件。</li>
<li><strong>实时监控</strong>：实时检测人体动作变化对于暴力行为的早期预警至关重要，尤其是在公共安全或视频监控系统中，动作识别可以即时检测到潜在的暴力行为并进行响应。</li>
</ol>
<p>综上，侧重人体动作本身不仅可以提升检测的准确性，还能更好地从动态和连续的角度识别暴力行为，提高系统的实时性和鲁棒性。</p>
<h3 id="单模态的人体动作识别的缺点有哪些">单模态的人体动作识别的缺点有哪些</h3>
<p>单模态人体动作识别（即仅使用一种数据模态，如视觉、声音、加速度等）存在以下主要缺点：</p>
<ol type="1">
<li><p><strong>信息局限性</strong>：</p>
<p>单一模态只能捕获动作的部分信息，可能导致对动作的理解不够全面。例如，仅依赖视觉模态可能无法捕获细微的物理接触或动作的力度变化。</p></li>
<li><p><strong>环境敏感性</strong>：</p>
<p>单模态方法对环境条件过于依赖。例如，视觉模态在光照不足或存在遮挡的情况下表现不佳，而非视觉模态（如加速度计）在传感器未正确佩戴或被干扰时表现不佳。</p></li>
<li><p><strong>无法应对模糊或模态冲突</strong>：</p>
<p>单模态方法难以处理模糊的行为信号或区分相似动作。例如，在视觉模态中，某些动作（如挥手与投掷）可能在外观上十分相似。</p></li>
<li><p><strong>鲁棒性差</strong>：</p>
<p>单模态在面对复杂场景（如多人交互、噪音、遮挡等）时，容易出现误判或漏判。例如，在仅依赖声音模态时，背景噪音可能干扰动作识别。</p></li>
<li><p><strong>缺乏上下文信息</strong>：</p>
<p>单模态通常难以捕获行为发生的上下文。例如，仅通过视觉识别到一个人弯腰的动作，可能无法判断是捡拾物品还是摔倒</p></li>
</ol>
<h3 id="暴力行为场景有哪些特点使用多模态对这些特点的优势有哪些">暴力行为场景有哪些特点，使用多模态对这些特点的优势有哪些</h3>
<p>暴力行为场景通常具有以下几个显著特点，这些特点对检测系统提出了更高的要求：</p>
<ol type="1">
<li><p><strong>动态性强</strong>：</p>
<p>暴力行为往往是迅速发生的，例如打斗、推搡、摔倒等动作可能在短时间内完成，导致动作的变化非常快。</p></li>
<li><p><strong>多人交互</strong>：</p>
<p>暴力行为通常涉及两个或更多个体之间的互动，如互相推搡、打斗或攻击等。多个目标的运动和交互增加了识别的复杂度。</p></li>
<li><p><strong>复杂的姿态变化</strong>：</p>
<p>暴力行为中的人物姿态变化通常非常剧烈，涉及肢体的快速摆动、抓握、推拉等动作，且可能伴随一定的身体接触。</p></li>
<li><p><strong>不规则的空间布局</strong>：</p>
<p>在暴力行为场景中，人物可能会在空间内迅速移动，动作的方向和速度可能会发生剧烈变化。背景也可能因为人物的动态而发生显著变化。</p></li>
<li><p><strong>潜在的遮挡</strong>：</p>
<p>在暴力行为中，人物之间的动作可能会出现遮挡（例如，两人打斗时，其中一个人可能被另一个人挡住）。这种情况给基于视觉的检测带来了挑战。</p></li>
<li><p><strong>噪声与干扰因素</strong>：</p>
<p>背景中的其他活动、环境变化、背景噪声等都可能干扰暴力行为的识别。例如，打斗声可能被背景音乐、交通噪声等因素掩盖。</p></li>
</ol>
<p>多模态（即结合多种数据来源或感知方式，如视觉、声音、传感器数据等）方法能够弥补单模态方法的不足，通过结合视觉、声音和传感器等多模态信息，可以更好地应对这些挑战，提升暴力行为检测的准确性、鲁棒性和实时性。多模态方法能够综合各类信息，从多个角度捕捉行为特征，尤其是在面对复杂环境、多人交互和遮挡等问题时，具有显著的优势。</p>
<h3 id="d-cnn-rnn-的优点">2D CNN + RNN 的优点</h3>
<p>2D CNN（卷积神经网络）与
RNN（递归神经网络）的结合是行为识别中的一种常见方法，尤其适用于视频行为识别任务。其主要优点包括：</p>
<ol type="1">
<li><strong>空间特征与时间依赖性的有效结合</strong>：</li>
</ol>
<ul>
<li><strong>2D
CNN</strong>：能够从视频帧中提取空间特征，如人物的姿态、背景和动作细节。通过多层卷积，CNN能够识别局部和全局的空间信息。</li>
<li><strong>RNN（LSTM/GRU）</strong>：RNN特别擅长处理时序数据，可以建模视频帧之间的时间依赖关系，捕捉动作的动态变化和时间长短的依赖，适应动作序列的连续性和长期依赖。</li>
<li><strong>优点</strong>：2D CNN 提供强大的空间特征提取能力，RNN
提供强大的时间序列建模能力。将两者结合，能够更好地理解视频中的空间和时间信息，提升行为识别的准确性。</li>
</ul>
<ol start="2" type="1">
<li><strong>自动特征学习</strong>：</li>
</ol>
<ul>
<li>传统方法依赖手工特征提取（如HOG、光流等），需要依赖专家知识且难以适应多样的场景。而
<strong>2D CNN</strong>
能够自动学习空间特征，减少了人工设计特征的依赖，提高了对复杂场景的适应能力。</li>
<li><strong>RNN</strong>
则可以自动从数据中学习到行为模式的时间序列特征，不需要事先设定固定的时间模型或参数。</li>
</ul>
<ol start="3" type="1">
<li><strong>鲁棒性强，适应性好</strong>：</li>
</ol>
<ul>
<li><strong>2D CNN</strong>
通过卷积层提取多层次的空间特征，具有较好的鲁棒性，能够应对不同背景和复杂场景中的视频数据。</li>
<li><strong>RNN</strong>
具有处理不规则、可变时间长度序列的能力，能够识别动态变化的动作和突发行为，提高了模型的适应性。</li>
</ul>
<ol start="4" type="1">
<li><strong>可扩展性强</strong>：</li>
</ol>
<ul>
<li>2D CNN 和 RNN
的组合能够很好地扩展到不同的视频数据规模、场景和复杂度上。随着数据集的增大，模型仍然能够通过更深的网络层次和更多的时序数据进行训练，进一步提升识别效果。</li>
</ul>
<h2 id="答辩稿初版">答辩稿——初版</h2>
<p>各位评委老师大家好，我是我们组的主持人张熙浚，我们组的研究方式是基于多模态特征融合的视频暴力行为识别方法研究</p>
<p>接下来我会从五个方面介绍我们的项目</p>
<p>首先是背景与意义，暴力行为对社会危害极大，即使诸如学校、商场、银行、车站等公共场所存在大量监控摄像头，产生了大量的视频片段，但这些片段通常被用来在暴力犯罪发生后提供线索和证据，而很少被用来实时识别并停止暴力行为。</p>
<p>这便引出了我们项目的目的，我们希望利用计算机视觉技术，赋予机器暴力行为的判别能力，从而及时发现暴力行为并能有效降低其带来的危害，而且大大降低了人力成本，在安防领域有极大的应用价值。</p>
<p>暴力行为的检测方法早期的检测方法主要是依靠设立一些规则，或是依靠背景和环境的变化，这些方法在很多方面存在不足，包括受环境因素影响大，特征提取和分析能力有限，计算效率低等问题</p>
<p>而现代的暴力行为检测越来越注重<strong>人体动作本身的识别</strong>，其通过分析人体动作的细节，尤其是肢体的动态变化，不仅可以提升检测的准确性，还能更好地从动态和连续的角度识别暴力行为，提高系统的实时性和鲁棒性。</p>
<p>由于监控人员不可能实时监控每一个摄像头产生的视频，所以部署视频暴力行为识别系统，能够节约用于监控的人力资源，降低监控人员因疲劳或走神而造成的漏检风险，一旦识别到暴力行为立即警示相关人员，进一步采取相应措施。由此可以得出我们项目研究的现实意义和应用场景。</p>
<p>接下来，我将讲述当前暴力行为检测的研究背景和挑战，并引出我们的解决方案。多种不同的数据形态都可以用来表示人类的动作和行为。主流的人体动作识别把这些模态分为2类：视觉模态和非视觉模态。这些数据模态是对不同的信息来源进行编码，根据应用场景的不同，不同模态的数据有着不同的独特优势。</p>
<p>目前主流的单模态深度学习方法存在以下缺点：信息单一、对环境敏感、鲁棒性较差，难以应对复杂场景等。但真实的暴力事件场景往往存在以下特点：存在复杂姿态变化，多人交互，大量环境噪声等。因此，我们提出了基于多模态的暴力事件检测，通过结合多种数据来源，从多个角度捕捉行为特征，尤其是在面对复杂环境、多人交互和遮挡等问题时，具有显著的优势。</p>
<p>随着深度学习和计算机视觉技术的发展，深度学习方法已经成为了行为识别算法的主流方向，接下来我会通过几篇论文中的方法介绍研究现状</p>
<p>这一篇是早提出使用深度学习方法解决视频暴力行为识别任务，直接将视频输入三维卷积进行建模</p>
<p>这一篇提出了数据集Rwf-2000，同时提出一种的双流网络架构，他们充分利用了RGB数据提供的外观信息和光流提供的运动信息，但缺点在于光流法计算、存储成本高，适用于光照条件良好、不拥挤的情况</p>
<p>这一篇提出了一种弱监督方法，即通过少量的标签（例如，仅标记视频是否包含暴力，而不是标记具体的暴力事件位置和类型）来训练模型。他选取视频帧最关键的区域，但使用I3D作为骨干网络，参数量巨大（1300万）</p>
<p>这一篇是基于骨架的方法，通过提取人体骨骼关节点构成三维骨架阵列，根据局部区域点的特征和时空位置信息，构建特定的权重分布策略，通过骨架点卷积实现分类。优点是骨架可以很好的表示人体运动信息，但问题在于仅使用骨架数据，效果高度依赖于位姿估计的精度，无法有效遮挡情况，同时因为仅使用骨架数据，其他信息缺失</p>
<p>这一篇是基于 2D CNN + RNN 的方法，2D CNN
提供强大的空间特征提取能力，RNN
提供强大的时间序列建模能力。将两者结合，能够更好地理解视频中的空间和时间信息，提升行为识别的准确性。这一篇使用简单快速的预处理方法突出了人体，减少了冗余的背景信息，但其仅使用RGB模态，提取的特征不够全面</p>
<p>我们的研究内容大致包含三个部分：1.提出一种基于多模态特征融合的视频暴力行为识别算法2.提出一种自适应的注意力算法用于多模态融合3.完成人体暴力行为检测系统的设计，接下来我将依次为大家介绍</p>
<p>第一部分，在特征提取阶段，为了区分暴力行为与非暴力行为，我们选择了三个要素进行提取：人体姿态、运动（趋势、幅度）、人物之间的位置关系，为了获取以上三个要素，并保证模型的通用性和现实性，需要从原始的RGB图像中提取以上特征，研究工作包括下列内容：</p>
<p>a.RGB模态的去除冗余信息
为了避免原生RGB图像冗余信息影响模型判断，减少计算量，我们决定对于原生RGB图像进行冗余信息去除工作，首先计算一个视频中所有帧的均值，记为平均帧（主要包含背景信息，因为背景在所有视频帧中几乎保持不变）用每一帧减去平均帧：去除（不变的）背景，保留（运动的）人体。通过简易的预处理，去除了冗余的背景信息，聚焦于人体的外观、姿态。</p>
<p>b.运动趋势与幅度特征的提取
目前主流反映物体运动趋势的方法是光流法，但我们考虑到光流图像在低像素复杂场景下效果不佳，且易受光照条件改变的影响，于是决定采取帧差法，通过对视频图像序列中相邻两帧作差分运算来获得运动目标轮廓的方法，以很好地适用于存在多个运动目标的情况，算法相对实现简单，程序设计复杂度低，对光线等场景变化不太敏感，能够适应各种动态环境，有着比较强的鲁棒。</p>
<p>c.深度模态的提取
在原始的RGB模态中，复杂场景中，人物多且受光照影响严重，难以分辨人物间的相对位置关系。为了反映人物之间的位置关系，我们选取深度模态，其去除了颜色和纹理信息并提供三维结构信息和人体轮廓，我们利用Depth
estimation算法，对原始RGB视频进行深度估计，得到视点到场景中各点之间的距离作为像素点的图片，即深度图，其划分了近景与远景，刻画了人物的轮廓，反映了三维空间中人物间的相对位置关系。</p>
<p>我们选择了CNN-LSTM的深度学习方法<strong>。</strong>LSTM擅长处理时序数据，可以建模视频帧之间的时间依赖关系，而CNN能够从视频帧中提取空间特征。通过结合两者的优势，我们可以让模型同时考虑到数据的时序信息和空间信息，减少参数降低过拟合风险，从而提供更精确的预测、更出色的性能以及更高的训练效率，并以此构建了算法思路。</p>
<p>第二部分，针对多模态融合中权重数值处理的问题，我们提出了一种自适应的注意力算法用于多模态融合，让模型自适应地学习不同模态特征之间的权重关系，允许模型根据具体任务动态调整每个模态的重要性，强调信息特征，抑制不太有用的特征,从而更灵活地应对不同的场景。</p>
<p>第三部分，我们完成了人体暴力行为检测系统的设计，刻画了系统的边界及大小，人体暴力行为检测系统是一个自动检测暴力行为的智能视频监控系统。该系统采用了三层架构，即表示层、业务层以及数据层。
它被设计成一个Web系统，主要以网页的形式显示在PC 显示器上</p>
<p>我们已经初步构建了暴力行为的检测流程，系统包含离线分析和在线监测两种模式</p>
<p>离线分析不依赖实时的监控视频，可对任意视频进行后处理式的分析。它
的优点是它不依赖于视频监控系统，可以直接选择视频开始分析，在视频来源
和分析时机的选择上更自由。</p>
<p>在线监测是人体暴力行为检测系统提供的另一种检测方式。它旨在利用监
控视频资源，进行实时的暴力行为检测，达到即时分析并报警提示的功能。这
一功能极大地降低了人工分析实时监控视频的成本，便于管理人员进行安全监
管，提高了监管的效率。</p>
<p>为了提高检测速度和避免资源浪费，根据传入视频的总帧数进行判断，采取提示过短、一次预测或是多轮预测。</p>
<p>最后是进度安排，我们已经完成算法大部分的编写，后续会继续完成系统的开发</p>
<p>谢谢各位老师观看，请各位老师批评指正</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——初识zinc</title>
    <url>/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94zinc/</url>
    <content><![CDATA[<p>安装，注意配置环境变量 $env:ZINC_FIRST_ADMIN_USER=“admin”
$env:ZINC_FIRST_ADMIN_PASSWORD=“admin” ..exe</p>
<p>加载示例数据，利用bash curl -L
https://github.com/zincsearch/zincsearch/releases/download/v0.1.1/olympics.ndjson.gz
-o olympics.ndjson.gz gzip -d olympics.ndjson.gz curl
http://localhost:4080/api/_bulk -i -u admin:Complexpass#123 –data-binary
“<span class="citation" data-cites="olympics.ndjson">@olympics.ndjson</span>”</p>
<p>概念 ZincSearch 是一个搜索引擎，允许您在上传到 ZincSearch
时搜索自己的数据。将其视为“Google”或“Bing”搜索，但仅用于您自己的数据。
ZincSearch 允许您索引 （json） 文档并允许进行全文搜索。</p>
<p>添加索引 使用 JSON 格式：{ “分析”： { “分析器”： { “默认”： {
“type”： “standard” } } } } { “index”: “my_index”, “settings”: {
“analysis”: { “analyzer”: { “default”: { “type”: “standard” } } } } }’
“index”: 指定你要创建的索引名称，这里是 my_index。 “settings”:
包含索引的设置。 “analysis”: 定义分析器的部分。 “analyzer”:
指定分析器的配置。 “default”: 定义默认分析器，类型为 standard。</p>
<p>索引的映射（mapping）
映射（mapping）是指在数据存储系统（如数据库或搜索引擎）中定义索引中字段的结构和属性的过程。它类似于数据库中的表结构定义
使用 JSON 格式：{ “属性”： { “内容”： { “type”： “text” } } }</p>
<p>参考文献 https://geekdaxue.co/read/ZincSearch-doc/create-update-index
https://prabhatsharma.in/blog/in-search-of-a-search-engine-beyond-elasticsearch-introducing-zinc/</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第一章：第一节数据载入及初步观察</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%BA%8C%E8%8A%82pandas%E5%9F%BA%E7%A1%80-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>数据分析的第一步，加载数据我们已经学习完毕了。当数据展现在我们面前的时候，我们所要做的第一步就是认识他，今天我们要学习的就是<strong>了解字段含义以及初步观察数据</strong>。</p>
<h2 id="第一章数据载入及初步观察">1 第一章：数据载入及初步观察</h2>
<h3 id="知道你的数据叫什么">1.4 知道你的数据叫什么</h3>
<p>我们学习pandas的基础操作，那么上一节通过pandas加载之后的数据，其数据类型是什么呢？</p>
<p><strong>开始前导入numpy和pandas</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<h4 id="任务一pandas中有两个数据类型dateframe和series通过查找简单了解他们然后自己写一个关于这两个数据类型的小例子开放题">1.4.1
任务一：pandas中有两个数据类型DateFrame和Series，通过查找简单了解他们。然后自己写一个关于这两个数据类型的小例子🌰[开放题]</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#我们举的例子</span></span><br><span class="line">sdata = &#123;<span class="string">&#x27;Ohio&#x27;</span>: <span class="number">35000</span>, <span class="string">&#x27;Texas&#x27;</span>: <span class="number">71000</span>, <span class="string">&#x27;Oregon&#x27;</span>: <span class="number">16000</span>, <span class="string">&#x27;Utah&#x27;</span>: <span class="number">5000</span>&#125;</span><br><span class="line">example_1 = pd.Series(sdata)</span><br><span class="line">example_1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Ohio      35000
Texas     71000
Oregon    16000
Utah       5000
dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#我们举的例子</span></span><br><span class="line">data = &#123;<span class="string">&#x27;state&#x27;</span>: [<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2003</span>],<span class="string">&#x27;pop&#x27;</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>, <span class="number">3.2</span>]&#125;</span><br><span class="line">example_2 = pd.DataFrame(data)</span><br><span class="line">example_2</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
state
</th>
<th>
year
</th>
<th>
pop
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
Ohio
</td>
<td>
2000
</td>
<td>
1.5
</td>
</tr>
<tr>
<th>
1
</th>
<td>
Ohio
</td>
<td>
2001
</td>
<td>
1.7
</td>
</tr>
<tr>
<th>
2
</th>
<td>
Ohio
</td>
<td>
2002
</td>
<td>
3.6
</td>
</tr>
<tr>
<th>
3
</th>
<td>
Nevada
</td>
<td>
2001
</td>
<td>
2.4
</td>
</tr>
<tr>
<th>
4
</th>
<td>
Nevada
</td>
<td>
2002
</td>
<td>
2.9
</td>
</tr>
<tr>
<th>
5
</th>
<td>
Nevada
</td>
<td>
2003
</td>
<td>
3.2
</td>
</tr>
</tbody>
</table>
<h4 id="任务二根据上节课的方法载入train.csv文件">1.4.2
任务二：根据上节课的方法载入”train.csv”文件</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>也可以加载上一节课保存的”train_chinese.csv”文件。通过翻译版train_chinese.csv熟悉了这个数据集，然后我们对trian.csv来进行操作
#### 1.4.3 任务三：查看DataFrame数据的每列的名称</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.columns</span><br></pre></td></tr></table></figure>
<pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,
       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;],
      dtype=&#39;object&#39;)</code></pre>
<h4 id="任务四查看cabin这列的所有值有多种方法">1.4.4任务四：查看”Cabin”这列的所有值[有多种方法]</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[<span class="string">&#x27;Cabin&#x27;</span>].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<pre><code>0     NaN
1     C85
2     NaN
3    C123
4     NaN
5     NaN
6     E46
7     NaN
8     NaN
9     NaN
Name: Cabin, dtype: object</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.Cabin.values[:<span class="number">10</span>]</span><br><span class="line">df.Cabin.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<pre><code>0     NaN
1     C85
2     NaN
3    C123
4     NaN
5     NaN
6     E46
7     NaN
8     NaN
9     NaN
Name: Cabin, dtype: object</code></pre>
<h4 id="任务五加载文件test_1.csv然后对比train.csv看看有哪些多出的列然后将多出的列删除">1.4.5
任务五：加载文件”test_1.csv”，然后对比”train.csv”，看看有哪些多出的列，然后将多出的列删除</h4>
<p>经过我们的观察发现一个测试集test_1.csv有一列是多余的，我们需要将这个多余的列删去</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">test_1=pd.read_csv(<span class="string">&#x27;../第一单元项目集合/test_1.csv&#x27;</span>)</span><br><span class="line">test_1.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Unnamed: 0
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
a
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
100
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
100
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#test_1.columns</span></span><br><span class="line">test_1.drop(<span class="string">&#x27;Unnamed: 0&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">test_1.columns</span><br></pre></td></tr></table></figure>
<pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,
       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;, &#39;a&#39;],
      dtype=&#39;object&#39;)</code></pre>
<p>【思考】还有其他的删除多余的列的方式吗？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 思考回答</span></span><br><span class="line"><span class="keyword">del</span> test_1[<span class="string">&#x27;Unnamed: 0&#x27;</span>]</span><br><span class="line">test_1.columns</span><br></pre></td></tr></table></figure>
<pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,
       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;, &#39;a&#39;],
      dtype=&#39;object&#39;)</code></pre>
<h4 id="任务六-将passengeridnameageticket这几个列元素隐藏只观察其他几个列元素">1.4.6
任务六：
将[‘PassengerId’,‘Name’,‘Age’,‘Ticket’]这几个列元素隐藏，只观察其他几个列元素</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.drop([<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Ticket&#x27;</span>], axis=<span class="number">1</span>).head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Sex
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
3
</td>
<td>
male
</td>
<td>
1
</td>
<td>
0
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
1
</td>
<td>
female
</td>
<td>
1
</td>
<td>
0
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
3
</td>
<td>
female
</td>
<td>
0
</td>
<td>
0
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
1
</td>
<td>
female
</td>
<td>
1
</td>
<td>
0
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
0
</td>
<td>
3
</td>
<td>
male
</td>
<td>
0
</td>
<td>
0
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
3
</td>
<td>
male
</td>
<td>
0
</td>
<td>
0
</td>
<td>
8.4583
</td>
<td>
NaN
</td>
<td>
Q
</td>
</tr>
<tr>
<th>
6
</th>
<td>
0
</td>
<td>
1
</td>
<td>
male
</td>
<td>
0
</td>
<td>
0
</td>
<td>
51.8625
</td>
<td>
E46
</td>
<td>
S
</td>
</tr>
<tr>
<th>
7
</th>
<td>
0
</td>
<td>
3
</td>
<td>
male
</td>
<td>
3
</td>
<td>
1
</td>
<td>
21.0750
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
8
</th>
<td>
1
</td>
<td>
3
</td>
<td>
female
</td>
<td>
0
</td>
<td>
2
</td>
<td>
11.1333
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
9
</th>
<td>
1
</td>
<td>
2
</td>
<td>
female
</td>
<td>
1
</td>
<td>
0
</td>
<td>
30.0708
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
</tbody>
</table>
<p>【思考】对比任务五和任务六，是不是使用了不一样的方法(函数)，如果使用一样的函数如何完成上面的不同的要求呢？</p>
<p>【思考回答】</p>
<p>如果想要完全的删除你的数据结构，使用inplace=True，因为使用inplace就将原数据覆盖了，所以这里没有用</p>
<h3 id="筛选的逻辑">1.5 筛选的逻辑</h3>
<p>表格数据中，最重要的一个功能就是要具有可筛选的能力，选出我所需要的信息，丢弃无用的信息。</p>
<p>下面我们还是用实战来学习pandas这个功能。</p>
<h4 id="任务一-我们以age为筛选条件显示年龄在10岁以下的乘客信息">1.5.1
任务一： 我们以”Age”为筛选条件，显示年龄在10岁以下的乘客信息。</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="built_in">print</span>((df[<span class="string">&#x27;Age&#x27;</span>]&lt;<span class="number">10</span>).head(<span class="number">2</span>))</span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>]&lt;<span class="number">10</span>].head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>0    False
1    False
Name: Age, dtype: bool</code></pre>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
7
</th>
<td>
8
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Palsson, Master. Gosta Leonard
</td>
<td>
male
</td>
<td>
2.0
</td>
<td>
3
</td>
<td>
1
</td>
<td>
349909
</td>
<td>
21.075
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
10
</th>
<td>
11
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Sandstrom, Miss. Marguerite Rut
</td>
<td>
female
</td>
<td>
4.0
</td>
<td>
1
</td>
<td>
1
</td>
<td>
PP 9549
</td>
<td>
16.700
</td>
<td>
G6
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h4 id="任务二-以age为条件将年龄在10岁以上和50岁以下的乘客信息显示出来并将这个数据命名为midage">1.5.2
任务二：
以”Age”为条件，将年龄在10岁以上和50岁以下的乘客信息显示出来，并将这个数据命名为midage</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage=df[(df[<span class="string">&#x27;Age&#x27;</span>]&gt;<span class="number">10</span>) &amp; (df[<span class="string">&#x27;Age&#x27;</span>]&lt;<span class="number">50</span>)]</span><br><span class="line">midage</span><br></pre></td></tr></table></figure>
<p>【提示】了解pandas的条件筛选方式以及如何使用交集和并集操作</p>
<h4 id="任务三将midage的数据中第100行的pclass和sex的数据显示出来">1.5.3
任务三：将midage的数据中第100行的”Pclass”和”Sex”的数据显示出来</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage = midage.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(midage)</span><br><span class="line">midage.loc[<span class="number">1</span>][[<span class="string">&#x27;Pclass&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>]]</span><br></pre></td></tr></table></figure>
<pre><code>     PassengerId  Survived  Pclass  \
0              1         0       3   
1              2         1       1   
2              3         1       3   
3              4         1       1   
4              5         0       3   
..           ...       ...     ...   
571          886         0       3   
572          887         0       2   
573          888         1       1   
574          890         1       1   
575          891         0       3   

                                                  Name     Sex   Age  SibSp  \
0                              Braund, Mr. Owen Harris    male  22.0      1   
1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   
2                               Heikkinen, Miss. Laina  female  26.0      0   
3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   
4                             Allen, Mr. William Henry    male  35.0      0   
..                                                 ...     ...   ...    ...   
571               Rice, Mrs. William (Margaret Norton)  female  39.0      0   
572                              Montvila, Rev. Juozas    male  27.0      0   
573                       Graham, Miss. Margaret Edith  female  19.0      0   
574                              Behr, Mr. Karl Howell    male  26.0      0   
575                                Dooley, Mr. Patrick    male  32.0      0   

     Parch            Ticket     Fare Cabin Embarked  
0        0         A/5 21171   7.2500   NaN        S  
1        0          PC 17599  71.2833   C85        C  
2        0  STON/O2. 3101282   7.9250   NaN        S  
3        0            113803  53.1000  C123        S  
4        0            373450   8.0500   NaN        S  
..     ...               ...      ...   ...      ...  
571      5            382652  29.1250   NaN        Q  
572      0            211536  13.0000   NaN        S  
573      0            112053  30.0000   B42        S  
574      0            111369  30.0000  C148        C  
575      0            370376   7.7500   NaN        Q  

[576 rows x 12 columns]



Pclass         1
Sex       female
Name: 1, dtype: object</code></pre>
<p>【提示】在抽取数据中，我们希望数据的相对顺序保持不变，用什么函数可以达到这个效果呢？</p>
<h4 id="任务四使用loc方法将midage的数据中第100105108行的pclassname和sex的数据显示出来">1.5.4
任务四：使用loc方法将midage的数据中第100，105，108行的”Pclass”，“Name”和”Sex”的数据显示出来</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage.loc[[<span class="number">100</span>,<span class="number">105</span>,<span class="number">108</span>],[<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Name&#x27;</span>,<span class="string">&#x27;Sex&#x27;</span>]] </span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
100
</th>
<td>
2
</td>
<td>
Byles, Rev. Thomas Roussel Davids
</td>
<td>
male
</td>
</tr>
<tr>
<th>
105
</th>
<td>
3
</td>
<td>
Cribb, Mr. John Hatfield
</td>
<td>
male
</td>
</tr>
<tr>
<th>
108
</th>
<td>
3
</td>
<td>
Calic, Mr. Jovo
</td>
<td>
male
</td>
</tr>
</tbody>
</table>
<h4 id="任务五使用iloc方法将midage的数据中第100105108行的pclassname和sex的数据显示出来">1.5.5
任务五：使用iloc方法将midage的数据中第100，105，108行的”Pclass”，“Name”和”Sex”的数据显示出来</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage.iloc[[<span class="number">100</span>,<span class="number">105</span>,<span class="number">108</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]] </span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
149
</th>
<td>
2
</td>
<td>
Byles, Rev. Thomas Roussel Davids
</td>
<td>
male
</td>
</tr>
<tr>
<th>
160
</th>
<td>
3
</td>
<td>
Cribb, Mr. John Hatfield
</td>
<td>
male
</td>
</tr>
<tr>
<th>
163
</th>
<td>
3
</td>
<td>
Calic, Mr. Jovo
</td>
<td>
male
</td>
</tr>
</tbody>
</table>
<p>【思考】对比<code>iloc</code>和<code>loc</code>的异同</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># *   当你需要根据**标签名称**（如行索引名或列名）来选取数据时，使用 `loc`。这使得代码更具可读性，因为你可以直接看到你正在操作的标签。</span></span><br><span class="line"><span class="comment"># *   当你需要根据**整数位置**来选取数据时（不关心标签名称，或者标签不是整数），使用 `iloc`。这在处理没有有意义标签的 DataFrame，或者需要进行与位置相关的操作时很有用。</span></span><br><span class="line"><span class="comment"># *   **注意**：如果 DataFrame 的索引是默认的整数索引 (0, 1, 2, ...)，那么 `loc` 和 `iloc` 在使用单个整数或整数切片进行行选择时，行为可能会相似，但这可能会导致混淆。</span></span><br><span class="line"><span class="comment">#     *   例如，如果 `df.index` 是 `[0, 1, 2, 5, 6]`：</span></span><br><span class="line"><span class="comment">#         *   `df.loc[0]` 会选择索引标签为 `0` 的行。</span></span><br><span class="line"><span class="comment">#         *   `df.iloc[0]` 也会选择第一行（即索引标签为 `0` 的行）。</span></span><br><span class="line"><span class="comment">#         *   `df.loc[3]` 会报错，因为没有索引标签为 `3`。</span></span><br><span class="line"><span class="comment">#         *   `df.iloc[3]` 会选择第四行（即索引标签为 `5` 的行）。</span></span><br><span class="line"><span class="comment"># *   为了避免混淆，最佳实践是：当你知道你正在使用标签时，明确使用 `loc`；当你知道你正在使用整数位置时，明确使用 `iloc`。</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第一章：第一节数据载入及初步观察</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%80%E8%8A%82%E6%95%B0%E6%8D%AE%E8%BD%BD%E5%85%A5%E5%8F%8A%E5%88%9D%E6%AD%A5%E8%A7%82%E5%AF%9F-%E8%AF%BE%E7%A8%8B-checkpoint/</url>
    <content><![CDATA[<p><strong>复习</strong>:这门课程得主要目的是通过真实的数据，以实战的方式了解数据分析的流程和熟悉数据分析python的基本操作。知道了课程的目的之后，我们接下来我们要正式的开始数据分析的实战教学，完成kaggle上<a href="https://www.kaggle.com/c/titanic/overview">泰坦尼克的任务</a>，实战数据分析全流程。
这里有两份资料： 教材《Python for Data Analysis》和 baidu.com &amp;
google.com（善用搜索引擎）</p>
<h2 id="第一章数据载入及初步观察">1 第一章：数据载入及初步观察</h2>
<h3 id="载入数据">1.1 载入数据</h3>
<p>数据集下载 https://www.kaggle.com/c/titanic/overview</p>
<h4 id="任务一导入numpy和pandas">1.1.1 任务一：导入numpy和pandas</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【提示】如果加载失败，学会如何在你的python环境下安装numpy和pandas这两个库</p>
<h4 id="任务二载入数据">1.1.2 任务二：载入数据</h4>
<ol type="1">
<li>使用相对路径载入数据<br>
</li>
<li>使用绝对路径载入数据</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.getcwd()</span><br><span class="line">test=pd.read_csv(<span class="string">&#x27;./titanic/test.csv&#x27;</span>)</span><br><span class="line">train=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">abs_path_test=os.path.abspath(<span class="string">&#x27;./titanic/test.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(abs_path_test)</span><br><span class="line">test=pd.read_csv(abs_path_test)</span><br><span class="line">abs_path_train=os.path.abspath(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(abs_path_train)</span><br><span class="line">train=pd.read_csv(abs_path_train)</span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<pre><code>/workspace/WuTeachingAI/hands-on-data-analysis/myself/titanic/test.csv
/workspace/WuTeachingAI/hands-on-data-analysis/myself/titanic/train.csv</code></pre>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p>【提示】相对路径载入报错时，尝试使用os.getcwd()查看当前工作目录。<br>
【思考】知道数据加载的方法后，试试pd.read_csv()和pd.read_table()的不同，如果想让他们效果一样，需要怎么做？了解一下’.tsv’和’.csv’的不同，如何加载这两个数据集？<br>
【总结】加载的数据是所有工作的第一步，我们的工作会接触到不同的数据格式（eg:.csv;.tsv;.xlsx）,但是加载的方法和思路都是一样的，在以后工作和做项目的过程中，遇到之前没有碰到的问题，要多多查资料吗，使用googel，了解业务逻辑，明白输入和输出是什么。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pd.read_csv() 和 pd.read_table() 本质上非常相似，主要区别在于默认的分隔符参数。</span></span><br><span class="line"><span class="comment"># 通过显式设置 `sep` 参数，可以让它们处理各种以不同字符分隔的文本文件。</span></span><br><span class="line"><span class="comment"># &#x27;.csv&#x27; 文件用逗号分隔，&#x27;.tsv&#x27; 文件用制表符分隔。选择合适的pandas读取函数或正确设置`sep`参数即可加载。</span></span><br></pre></td></tr></table></figure>
<h4 id="任务三每1000行为一个数据模块逐块读取">1.1.3
任务三：每1000行为一个数据模块，逐块读取</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">chunker=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>,chunksize=<span class="number">1000</span>)</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> chunker:</span><br><span class="line">    <span class="built_in">print</span>(chunk)</span><br></pre></td></tr></table></figure>
<pre><code>     PassengerId  Survived  Pclass  \
0              1         0       3   
1              2         1       1   
2              3         1       3   
3              4         1       1   
4              5         0       3   
..           ...       ...     ...   
886          887         0       2   
887          888         1       1   
888          889         0       3   
889          890         1       1   
890          891         0       3   

                                                  Name     Sex   Age  SibSp  \
0                              Braund, Mr. Owen Harris    male  22.0      1   
1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   
2                               Heikkinen, Miss. Laina  female  26.0      0   
3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   
4                             Allen, Mr. William Henry    male  35.0      0   
..                                                 ...     ...   ...    ...   
886                              Montvila, Rev. Juozas    male  27.0      0   
887                       Graham, Miss. Margaret Edith  female  19.0      0   
888           Johnston, Miss. Catherine Helen &quot;Carrie&quot;  female   NaN      1   
889                              Behr, Mr. Karl Howell    male  26.0      0   
890                                Dooley, Mr. Patrick    male  32.0      0   

     Parch            Ticket     Fare Cabin Embarked  
0        0         A/5 21171   7.2500   NaN        S  
1        0          PC 17599  71.2833   C85        C  
2        0  STON/O2. 3101282   7.9250   NaN        S  
3        0            113803  53.1000  C123        S  
4        0            373450   8.0500   NaN        S  
..     ...               ...      ...   ...      ...  
886      0            211536  13.0000   NaN        S  
887      0            112053  30.0000   B42        S  
888      2        W./C. 6607  23.4500   NaN        S  
889      0            111369  30.0000  C148        C  
890      0            370376   7.7500   NaN        Q  

[891 rows x 12 columns]</code></pre>
<p>【思考】什么是逐块读取？为什么要逐块读取呢？</p>
<p>【提示】大家可以chunker(数据块)是什么类型？用<code>for</code>循环打印出来出处具体的样子是什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **什么是逐块读取？**</span></span><br><span class="line"><span class="comment"># 逐块读取（Chunking）是指在读取大型数据集时，不一次性将整个文件加载到内存中，而是将文件分成若干个小的数据块（chunks），每次只加载和处理一个数据块。</span></span><br><span class="line"><span class="comment"># 在pandas中，可以通过在 `pd.read_csv()` 或类似的读取函数中设置 `chunksize` 参数来实现逐块读取。`chunksize` 定义了每个数据块包含的行数。</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># **为什么要逐块读取呢？**</span></span><br><span class="line"><span class="comment"># 1.  **处理内存不足的大文件**：</span></span><br><span class="line"><span class="comment">#     *   当数据集非常大，其大小超过了计算机可用内存时，一次性加载整个文件会导致内存溢出错误（MemoryError）。逐块读取允许我们分批处理数据，每次只在内存中保留一小部分数据，从而有效避免内存问题。</span></span><br><span class="line"><span class="comment"># 2.  **提高处理效率（特定场景下）**：</span></span><br><span class="line"><span class="comment">#     *   对于某些类型的操作，例如对数据进行迭代处理、过滤或聚合，如果不需要同时访问所有数据，逐块处理可以使得程序更快地开始处理数据，而不是等待整个大文件加载完毕。</span></span><br><span class="line"><span class="comment">#     *   可以边读取边处理，实现流式数据处理的效果。</span></span><br><span class="line"><span class="comment"># 3.  **数据清洗和预处理**：</span></span><br><span class="line"><span class="comment">#     *   在对大型原始数据进行初步的清洗、转换或特征工程时，可以逐块进行，将处理后的数据块追加到新的存储中，或者在每个块上计算统计量并逐步累积。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务四将表头改成中文索引改为乘客id-对于某些英文资料我们可以通过翻译来更直观的熟悉我们的数据">1.1.4
任务四：将表头改成中文，索引改为乘客ID
[对于某些英文资料，我们可以通过翻译来更直观的熟悉我们的数据]</h4>
<p>PassengerId =&gt; 乘客ID<br>
Survived =&gt; 是否幸存<br>
Pclass =&gt; 乘客等级(1/2/3等舱位)<br>
Name =&gt; 乘客姓名<br>
Sex =&gt; 性别<br>
Age =&gt; 年龄<br>
SibSp =&gt; 堂兄弟/妹个数<br>
Parch =&gt; 父母与小孩个数<br>
Ticket =&gt; 船票信息<br>
Fare =&gt; 票价<br>
Cabin =&gt; 客舱<br>
Embarked =&gt; 登船港口</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将&quot;乘客ID&quot;列作为行索引</span></span><br><span class="line">df=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>,names=[<span class="string">&#x27;乘客ID&#x27;</span>,<span class="string">&#x27;是否幸存&#x27;</span>,<span class="string">&#x27;仓位等级&#x27;</span>,<span class="string">&#x27;姓名&#x27;</span>,<span class="string">&#x27;性别&#x27;</span>,<span class="string">&#x27;年龄&#x27;</span>,<span class="string">&#x27;兄弟姐妹个数&#x27;</span>,<span class="string">&#x27;父母子女个数&#x27;</span>,<span class="string">&#x27;船票信息&#x27;</span>,<span class="string">&#x27;票价&#x27;</span>,<span class="string">&#x27;客舱&#x27;</span>,<span class="string">&#x27;登船港口&#x27;</span>],index_col=<span class="string">&#x27;乘客ID&#x27;</span>,header=<span class="number">0</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
姓名
</th>
<th>
性别
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
船票信息
</th>
<th>
票价
</th>
<th>
客舱
</th>
<th>
登船港口
</th>
</tr>
<tr>
<th>
乘客ID
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p>【思考】所谓将表头改为中文其中一个思路是：将英文列名表头替换成中文。还有其他的方法吗？</p>
<h3 id="初步观察">1.2 初步观察</h3>
<p>导入数据后，你可能要对数据的整体结构和样例进行概览，比如说，数据大小、有多少列，各列都是什么格式的，是否包含null等</p>
<h4 id="任务一查看数据的基本信息">1.2.1 任务一：查看数据的基本信息</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.info()</span><br><span class="line">df.describe()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 891 entries, 1 to 891
Data columns (total 11 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   是否幸存    891 non-null    int64  
 1   仓位等级    891 non-null    int64  
 2   姓名      891 non-null    object 
 3   性别      891 non-null    object 
 4   年龄      714 non-null    float64
 5   兄弟姐妹个数  891 non-null    int64  
 6   父母子女个数  891 non-null    int64  
 7   船票信息    891 non-null    object 
 8   票价      891 non-null    float64
 9   客舱      204 non-null    object 
 10  登船港口    889 non-null    object 
dtypes: float64(2), int64(4), object(5)
memory usage: 83.5+ KB</code></pre>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
票价
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
count
</th>
<td>
891.000000
</td>
<td>
891.000000
</td>
<td>
714.000000
</td>
<td>
891.000000
</td>
<td>
891.000000
</td>
<td>
891.000000
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
0.383838
</td>
<td>
2.308642
</td>
<td>
29.699118
</td>
<td>
0.523008
</td>
<td>
0.381594
</td>
<td>
32.204208
</td>
</tr>
<tr>
<th>
std
</th>
<td>
0.486592
</td>
<td>
0.836071
</td>
<td>
14.526497
</td>
<td>
1.102743
</td>
<td>
0.806057
</td>
<td>
49.693429
</td>
</tr>
<tr>
<th>
min
</th>
<td>
0.000000
</td>
<td>
1.000000
</td>
<td>
0.420000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
</tr>
<tr>
<th>
25%
</th>
<td>
0.000000
</td>
<td>
2.000000
</td>
<td>
20.125000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
<td>
7.910400
</td>
</tr>
<tr>
<th>
50%
</th>
<td>
0.000000
</td>
<td>
3.000000
</td>
<td>
28.000000
</td>
<td>
0.000000
</td>
<td>
0.000000
</td>
<td>
14.454200
</td>
</tr>
<tr>
<th>
75%
</th>
<td>
1.000000
</td>
<td>
3.000000
</td>
<td>
38.000000
</td>
<td>
1.000000
</td>
<td>
0.000000
</td>
<td>
31.000000
</td>
</tr>
<tr>
<th>
max
</th>
<td>
1.000000
</td>
<td>
3.000000
</td>
<td>
80.000000
</td>
<td>
8.000000
</td>
<td>
6.000000
</td>
<td>
512.329200
</td>
</tr>
</tbody>
</table>
<p>【提示】有多个函数可以这样做，你可以做一下总结</p>
<h4 id="任务二观察表格前10行的数据和后15行的数据">1.2.2
任务二：观察表格前10行的数据和后15行的数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.head(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
姓名
</th>
<th>
性别
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
船票信息
</th>
<th>
票价
</th>
<th>
客舱
</th>
<th>
登船港口
</th>
</tr>
<tr>
<th>
乘客ID
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
6
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Moran, Mr. James
</td>
<td>
male
</td>
<td>
NaN
</td>
<td>
0
</td>
<td>
0
</td>
<td>
330877
</td>
<td>
8.4583
</td>
<td>
NaN
</td>
<td>
Q
</td>
</tr>
<tr>
<th>
7
</th>
<td>
0
</td>
<td>
1
</td>
<td>
McCarthy, Mr. Timothy J
</td>
<td>
male
</td>
<td>
54.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
17463
</td>
<td>
51.8625
</td>
<td>
E46
</td>
<td>
S
</td>
</tr>
<tr>
<th>
8
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Palsson, Master. Gosta Leonard
</td>
<td>
male
</td>
<td>
2.0
</td>
<td>
3
</td>
<td>
1
</td>
<td>
349909
</td>
<td>
21.0750
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
9
</th>
<td>
1
</td>
<td>
3
</td>
<td>
Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)
</td>
<td>
female
</td>
<td>
27.0
</td>
<td>
0
</td>
<td>
2
</td>
<td>
347742
</td>
<td>
11.1333
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
10
</th>
<td>
1
</td>
<td>
2
</td>
<td>
Nasser, Mrs. Nicholas (Adele Achem)
</td>
<td>
female
</td>
<td>
14.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
237736
</td>
<td>
30.0708
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
<tr>
<th>
11
</th>
<td>
1
</td>
<td>
3
</td>
<td>
Sandstrom, Miss. Marguerite Rut
</td>
<td>
female
</td>
<td>
4.0
</td>
<td>
1
</td>
<td>
1
</td>
<td>
PP 9549
</td>
<td>
16.7000
</td>
<td>
G6
</td>
<td>
S
</td>
</tr>
<tr>
<th>
12
</th>
<td>
1
</td>
<td>
1
</td>
<td>
Bonnell, Miss. Elizabeth
</td>
<td>
female
</td>
<td>
58.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
113783
</td>
<td>
26.5500
</td>
<td>
C103
</td>
<td>
S
</td>
</tr>
<tr>
<th>
13
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Saundercock, Mr. William Henry
</td>
<td>
male
</td>
<td>
20.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
A/5. 2151
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
14
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Andersson, Mr. Anders Johan
</td>
<td>
male
</td>
<td>
39.0
</td>
<td>
1
</td>
<td>
5
</td>
<td>
347082
</td>
<td>
31.2750
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
15
</th>
<td>
0
</td>
<td>
3
</td>
<td>
Vestrom, Miss. Hulda Amanda Adolfina
</td>
<td>
female
</td>
<td>
14.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
350406
</td>
<td>
7.8542
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.tail()</span><br></pre></td></tr></table></figure>
<h4 id="任务三判断数据是否为空为空的地方返回true其余地方返回false">1.2.4
任务三：判断数据是否为空，为空的地方返回True，其余地方返回False</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.isnull().head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
姓名
</th>
<th>
性别
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
船票信息
</th>
<th>
票价
</th>
<th>
客舱
</th>
<th>
登船港口
</th>
</tr>
<tr>
<th>
乘客ID
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
<td>
False
</td>
</tr>
<tr>
<th>
2
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
</tr>
<tr>
<th>
3
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
<td>
False
</td>
</tr>
<tr>
<th>
4
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
</tr>
<tr>
<th>
5
</th>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
<td>
False
</td>
</tr>
</tbody>
</table>
<p>【总结】上面的操作都是数据分析中对于数据本身的观察</p>
<p>【思考】对于一个数据，还可以从哪些方面来观察？找找答案，这个将对下面的数据分析有很大的帮助</p>
<h3 id="保存数据">1.3 保存数据</h3>
<h4 id="任务一将你加载并做出改变的数据在工作目录下保存为一个新文件train_chinese.csv">1.3.1
任务一：将你加载并做出改变的数据，在工作目录下保存为一个新文件train_chinese.csv</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 注意：不同的操作系统保存下来可能会有乱码。大家可以加入`encoding=&#x27;GBK&#x27; 或者 ’encoding = ’utf-8‘‘`</span></span><br><span class="line">df.to_csv(<span class="string">&#x27;./titanic/train_chinese.csv&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>【总结】数据的加载以及入门，接下来就要接触数据本身的运算，我们将主要掌握numpy和pandas在工作和项目场景的运用。</p>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第一章：第三节探索性数据分析</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%89%E8%8A%82%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>在前面我们已经学习了Pandas基础，知道利用Pandas读取csv数据的增删查改，今天我们要学习的就是<strong>探索性数据分析</strong>，主要介绍如何利用Pandas进行排序、算术计算以及计算描述函数describe()的使用。</p>
<h1 id="第一章探索性数据分析">1 第一章：探索性数据分析</h1>
<h4 id="开始之前导入numpypandas包和数据">开始之前，导入numpy、pandas包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载所需的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#载入之前保存的train_chinese.csv数据，关于泰坦尼克号的任务，我们就使用这个数据</span></span><br><span class="line">train_chinese = pd.read_csv(<span class="string">&#x27;./titanic/train_chinese.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="了解你的数据吗">1.6 了解你的数据吗？</h3>
<p>教材《Python for Data Analysis》第五章</p>
<h4 id="任务一利用pandas对示例数据进行排序要求升序">1.6.1
任务一：利用Pandas对示例数据进行排序，要求升序</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 具体请看《利用Python进行数据分析》第五章 排序和排名 部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己构建一个都为数字的DataFrame数据</span></span><br><span class="line">frame = pd.DataFrame(np.arange(<span class="number">8</span>).reshape((<span class="number">2</span>, <span class="number">4</span>)), </span><br><span class="line">                     index=[<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;1&#x27;</span>], </span><br><span class="line">                     columns=[<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">frame</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
</tr>
</tbody>
</table>
<p>【代码解析】</p>
<p>pd.DataFrame() ：创建一个DataFrame对象</p>
<p>np.arange(8).reshape((2, 4)) :
生成一个二维数组（2*4）,第一列：0，1，2，3 第二列：4，5，6，7</p>
<p>index=[’2, 1] ：DataFrame 对象的索引列</p>
<p>columns=[‘d’, ‘a’, ‘b’, ‘c’] ：DataFrame 对象的索引行</p>
<p>【问题】：大多数时候我们都是想根据列的值来排序,所以将你构建的DataFrame中的数据根据某一列，升序排列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#回答代码</span></span><br><span class="line"><span class="comment">#指定按列名 &#x27;b&#x27; 的值进行排序，ascending=False设置降序排列（默认是升序）</span></span><br><span class="line">frame.sort_values(by=<span class="string">&#x27;b&#x27;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<p>【思考】通过书本你能说出Pandas对DataFrame数据的其他排序方式吗？</p>
<p>【总结】下面将不同的排序方式做一个总结</p>
<p>1.让行索引升序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame.sort_index(ascending=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<p>2.让列索引升序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line"><span class="comment">#axis=1指定对 列索引（columns） 进行排序（默认 axis=0 是对行索引排序）。</span></span><br><span class="line">frame.sort_index(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
<th>
d
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
<td>
0
</td>
</tr>
<tr>
<th>
1
</th>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
<p>3.让列索引降序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame.sort_index(axis=<span class="number">1</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
c
</th>
<th>
b
</th>
<th>
a
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
3
</td>
<td>
2
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
7
</td>
<td>
6
</td>
<td>
5
</td>
</tr>
</tbody>
</table>
<p>4.让任选两列数据同时降序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame.sort_values(by=[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>],ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
d
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
4
</td>
<td>
5
</td>
<td>
6
</td>
<td>
7
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
1
</td>
<td>
2
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<h4 id="任务二对泰坦尼克号数据trian.csv按票价和年龄两列进行综合排序降序排列从这个数据中你可以分析出什么">1.6.2
任务二：对泰坦尼克号数据（trian.csv）按票价和年龄两列进行综合排序（降序排列），从这个数据中你可以分析出什么？</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">在开始我们已经导入了train_chinese.csv数据，而且前面我们也学习了导入数据过程，根据上面学习，我们直接对目标列进行排序即可</span></span><br><span class="line"><span class="string">head(20) : 读取前20条数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">train_chinese.sort_values(by=[<span class="string">&#x27;票价&#x27;</span>,<span class="string">&#x27;年龄&#x27;</span>], ascending=<span class="literal">False</span>).head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
乘客ID
</th>
<th>
是否幸存
</th>
<th>
仓位等级
</th>
<th>
姓名
</th>
<th>
性别
</th>
<th>
年龄
</th>
<th>
兄弟姐妹个数
</th>
<th>
父母子女个数
</th>
<th>
船票信息
</th>
<th>
票价
</th>
<th>
客舱
</th>
<th>
登船港口
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
679
</th>
<td>
680
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cardeza, Mr. Thomas Drake Martinez
</td>
<td>
male
</td>
<td>
36.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
PC 17755
</td>
<td>
512.3292
</td>
<td>
B51 B53 B55
</td>
<td>
C
</td>
</tr>
<tr>
<th>
258
</th>
<td>
259
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Ward, Miss. Anna
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17755
</td>
<td>
512.3292
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
<tr>
<th>
737
</th>
<td>
738
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Lesurer, Mr. Gustave J
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17755
</td>
<td>
512.3292
</td>
<td>
B101
</td>
<td>
C
</td>
</tr>
<tr>
<th>
438
</th>
<td>
439
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Fortune, Mr. Mark
</td>
<td>
male
</td>
<td>
64.0
</td>
<td>
1
</td>
<td>
4
</td>
<td>
19950
</td>
<td>
263.0000
</td>
<td>
C23 C25 C27
</td>
<td>
S
</td>
</tr>
<tr>
<th>
341
</th>
<td>
342
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Fortune, Miss. Alice Elizabeth
</td>
<td>
female
</td>
<td>
24.0
</td>
<td>
3
</td>
<td>
2
</td>
<td>
19950
</td>
<td>
263.0000
</td>
<td>
C23 C25 C27
</td>
<td>
S
</td>
</tr>
<tr>
<th>
88
</th>
<td>
89
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Fortune, Miss. Mabel Helen
</td>
<td>
female
</td>
<td>
23.0
</td>
<td>
3
</td>
<td>
2
</td>
<td>
19950
</td>
<td>
263.0000
</td>
<td>
C23 C25 C27
</td>
<td>
S
</td>
</tr>
<tr>
<th>
27
</th>
<td>
28
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Fortune, Mr. Charles Alexander
</td>
<td>
male
</td>
<td>
19.0
</td>
<td>
3
</td>
<td>
2
</td>
<td>
19950
</td>
<td>
263.0000
</td>
<td>
C23 C25 C27
</td>
<td>
S
</td>
</tr>
<tr>
<th>
742
</th>
<td>
743
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Ryerson, Miss. Susan Parker “Suzette”
</td>
<td>
female
</td>
<td>
21.0
</td>
<td>
2
</td>
<td>
2
</td>
<td>
PC 17608
</td>
<td>
262.3750
</td>
<td>
B57 B59 B63 B66
</td>
<td>
C
</td>
</tr>
<tr>
<th>
311
</th>
<td>
312
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Ryerson, Miss. Emily Borie
</td>
<td>
female
</td>
<td>
18.0
</td>
<td>
2
</td>
<td>
2
</td>
<td>
PC 17608
</td>
<td>
262.3750
</td>
<td>
B57 B59 B63 B66
</td>
<td>
C
</td>
</tr>
<tr>
<th>
299
</th>
<td>
300
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Baxter, Mrs. James (Helene DeLaudeniere Chaput)
</td>
<td>
female
</td>
<td>
50.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
PC 17558
</td>
<td>
247.5208
</td>
<td>
B58 B60
</td>
<td>
C
</td>
</tr>
<tr>
<th>
118
</th>
<td>
119
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Baxter, Mr. Quigg Edmond
</td>
<td>
male
</td>
<td>
24.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
PC 17558
</td>
<td>
247.5208
</td>
<td>
B58 B60
</td>
<td>
C
</td>
</tr>
<tr>
<th>
380
</th>
<td>
381
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Bidois, Miss. Rosalie
</td>
<td>
female
</td>
<td>
42.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17757
</td>
<td>
227.5250
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
<tr>
<th>
716
</th>
<td>
717
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Endres, Miss. Caroline Louise
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17757
</td>
<td>
227.5250
</td>
<td>
C45
</td>
<td>
C
</td>
</tr>
<tr>
<th>
700
</th>
<td>
701
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Astor, Mrs. John Jacob (Madeleine Talmadge Force)
</td>
<td>
female
</td>
<td>
18.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17757
</td>
<td>
227.5250
</td>
<td>
C62 C64
</td>
<td>
C
</td>
</tr>
<tr>
<th>
557
</th>
<td>
558
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Robbins, Mr. Victor
</td>
<td>
male
</td>
<td>
NaN
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17757
</td>
<td>
227.5250
</td>
<td>
NaN
</td>
<td>
C
</td>
</tr>
<tr>
<th>
527
</th>
<td>
528
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Farthing, Mr. John
</td>
<td>
male
</td>
<td>
NaN
</td>
<td>
0
</td>
<td>
0
</td>
<td>
PC 17483
</td>
<td>
221.7792
</td>
<td>
C95
</td>
<td>
S
</td>
</tr>
<tr>
<th>
377
</th>
<td>
378
</td>
<td>
0
</td>
<td>
1
</td>
<td>
Widener, Mr. Harry Elkins
</td>
<td>
male
</td>
<td>
27.0
</td>
<td>
0
</td>
<td>
2
</td>
<td>
113503
</td>
<td>
211.5000
</td>
<td>
C82
</td>
<td>
C
</td>
</tr>
<tr>
<th>
779
</th>
<td>
780
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Robert, Mrs. Edward Scott (Elisabeth Walton Mc…
</td>
<td>
female
</td>
<td>
43.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
24160
</td>
<td>
211.3375
</td>
<td>
B3
</td>
<td>
S
</td>
</tr>
<tr>
<th>
730
</th>
<td>
731
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Allen, Miss. Elisabeth Walton
</td>
<td>
female
</td>
<td>
29.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
24160
</td>
<td>
211.3375
</td>
<td>
B5
</td>
<td>
S
</td>
</tr>
<tr>
<th>
689
</th>
<td>
690
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Madill, Miss. Georgette Alexandra
</td>
<td>
female
</td>
<td>
15.0
</td>
<td>
0
</td>
<td>
1
</td>
<td>
24160
</td>
<td>
211.3375
</td>
<td>
B5
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【思考】排序后，如果我们仅仅关注年龄和票价两列。根据常识我知道发现票价越高的应该客舱越好，所以我们会明显看出，票价前20的乘客中存活的有14人，这是相当高的一个比例，那么我们后面是不是可以进一步分析一下票价和存活之间的关系，年龄和存活之间的关系呢？当你开始发现数据之间的关系了，数据分析就开始了。</p>
<p>当然，这只是我的想法，你还可以有更多想法，欢迎写在你的学习笔记中。</p>
<p><strong>多做几个数据的排序</strong></p>
<h4 id="任务三利用pandas进行算术计算计算两个dataframe数据相加结果">1.6.3
任务三：利用Pandas进行算术计算，计算两个DataFrame数据相加结果</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 具体请看《利用Python进行数据分析》第五章 算术运算与数据对齐 部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己构建两个都为数字的DataFrame数据</span></span><br><span class="line"></span><br><span class="line">frame1_a = pd.DataFrame(np.arange(<span class="number">9.</span>).reshape(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                     columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">                     index=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>])</span><br><span class="line">frame1_b = pd.DataFrame(np.arange(<span class="number">12.</span>).reshape(<span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">                     columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">                     index=[<span class="string">&#x27;first&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;second&#x27;</span>])</span><br><span class="line">frame1_a, frame1_b</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>(         a    b    c
 one    0.0  1.0  2.0
 two    3.0  4.0  5.0
 three  6.0  7.0  8.0,
           a     e     c
 first   0.0   1.0   2.0
 one     3.0   4.0   5.0
 two     6.0   7.0   8.0
 second  9.0  10.0  11.0)</code></pre>
<p>将frame_a和frame_b进行相加</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame1_a+frame1_b</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
a
</th>
<th>
b
</th>
<th>
c
</th>
<th>
e
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
first
</th>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
one
</th>
<td>
3.0
</td>
<td>
NaN
</td>
<td>
7.0
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
second
</th>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
three
</th>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
two
</th>
<td>
9.0
</td>
<td>
NaN
</td>
<td>
13.0
</td>
<td>
NaN
</td>
</tr>
</tbody>
</table>
<p>【提醒】两个DataFrame相加后，会返回一个新的DataFrame，对应的行和列的值会相加，没有对应的会变成空值NaN。<br>
当然，DataFrame还有很多算术运算，如减法，除法等，有兴趣的同学可以看《利用Python进行数据分析》第五章
算术运算与数据对齐 部分，多在网络上查找相关学习资料。</p>
<h4 id="任务四通过泰坦尼克号数据如何计算出在船上最大的家族有多少人">1.6.4
任务四：通过泰坦尼克号数据如何计算出在船上最大的家族有多少人？</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">还是用之前导入的chinese_train.csv如果我们想看看在船上，最大的家族有多少人（‘兄弟姐妹个数’+‘父母子女个数’），我们该怎么做呢？</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">max</span>(train_chinese[<span class="string">&#x27;兄弟姐妹个数&#x27;</span>] + train_chinese[<span class="string">&#x27;父母子女个数&#x27;</span>])</span><br></pre></td></tr></table></figure>
<pre><code>10</code></pre>
<p>【提醒】我们只需找出”兄弟姐妹个数“和”父母子女个数“之和最大的数，当然你还可以想出很多方法和思考角度，欢迎你来说出你的看法。</p>
<p><strong>多做几个数据的相加，看看你能分析出什么？</strong></p>
<h4 id="任务五学会使用pandas-describe函数查看数据基本统计信息">1.6.5
任务五：学会使用Pandas describe()函数查看数据基本统计信息</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#(1) 关键知识点示例做一遍（简单数据）</span></span><br><span class="line"><span class="comment"># 具体请看《利用Python进行数据分析》第五章 汇总和计算描述统计 部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己构建一个有数字有空值的DataFrame数据</span></span><br><span class="line"></span><br><span class="line">frame2 = pd.DataFrame([[<span class="number">1.4</span>, np.nan], </span><br><span class="line">                       [<span class="number">7.1</span>, -<span class="number">4.5</span>],</span><br><span class="line">                       [np.nan, np.nan], </span><br><span class="line">                       [<span class="number">0.75</span>, -<span class="number">1.3</span>]</span><br><span class="line">                      ], index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>], columns=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>])</span><br><span class="line">frame2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
one
</th>
<th>
two
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
a
</th>
<td>
1.40
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
b
</th>
<td>
7.10
</td>
<td>
-4.5
</td>
</tr>
<tr>
<th>
c
</th>
<td>
NaN
</td>
<td>
NaN
</td>
</tr>
<tr>
<th>
d
</th>
<td>
0.75
</td>
<td>
-1.3
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame2.describe()  <span class="comment">#描述统计</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">count : 样本数据大小</span></span><br><span class="line"><span class="string">mean : 样本数据的平均值</span></span><br><span class="line"><span class="string">std : 样本数据的标准差</span></span><br><span class="line"><span class="string">min : 样本数据的最小值</span></span><br><span class="line"><span class="string">25% : 样本数据25%的时候的值</span></span><br><span class="line"><span class="string">50% : 样本数据50%的时候的值</span></span><br><span class="line"><span class="string">75% : 样本数据75%的时候的值</span></span><br><span class="line"><span class="string">max : 样本数据的最大值</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
one
</th>
<th>
two
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
count
</th>
<td>
3.000000
</td>
<td>
2.000000
</td>
</tr>
<tr>
<th>
mean
</th>
<td>
3.083333
</td>
<td>
-2.900000
</td>
</tr>
<tr>
<th>
std
</th>
<td>
3.493685
</td>
<td>
2.262742
</td>
</tr>
<tr>
<th>
min
</th>
<td>
0.750000
</td>
<td>
-4.500000
</td>
</tr>
<tr>
<th>
25%
</th>
<td>
1.075000
</td>
<td>
-3.700000
</td>
</tr>
<tr>
<th>
50%
</th>
<td>
1.400000
</td>
<td>
-2.900000
</td>
</tr>
<tr>
<th>
75%
</th>
<td>
4.250000
</td>
<td>
-2.100000
</td>
</tr>
<tr>
<th>
max
</th>
<td>
7.100000
</td>
<td>
-1.300000
</td>
</tr>
</tbody>
</table>

<p>调用 describe 函数，观察frame2的数据基本信息</p>
<h4 id="任务六分别看看泰坦尼克号数据集中-票价父母子女-这列数据的基本统计数据你能发现什么">1.6.6
任务六：分别看看泰坦尼克号数据集中 票价、父母子女
这列数据的基本统计数据，你能发现什么？</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">看看泰坦尼克号数据集中 票价 这列数据的基本统计数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<pre><code>&#39;\n看看泰坦尼克号数据集中 票价 这列数据的基本统计数据\n&#39;</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">train_chinese[<span class="string">&#x27;票价&#x27;</span>].describe()</span><br></pre></td></tr></table></figure>
<pre><code>count    891.000000
mean      32.204208
std       49.693429
min        0.000000
25%        7.910400
50%       14.454200
75%       31.000000
max      512.329200
Name: 票价, dtype: float64</code></pre>
<p>【思考】从上面数据我们可以看出， 一共有891个票价数据，
平均值约为：32.20， 标准差约为49.69，说明票价波动特别大，
25%的人的票价是低于7.91的，50%的人的票价低于14.45，75%的人的票价低于31.00，
票价最大值约为512.33，最小值为0。
当然，答案只是我的想法，你还可以有更多想法，欢迎写在你的学习笔记中。</p>
<p><strong>多做几个组数据的统计，看看你能分析出什么？</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写下你的其他分析</span></span><br><span class="line">train_chinese[<span class="string">&#x27;父母子女个数&#x27;</span>].describe()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>count    891.000000
mean       0.381594
std        0.806057
min        0.000000
25%        0.000000
50%        0.000000
75%        0.000000
max        6.000000
Name: 父母子女个数, dtype: float64</code></pre>
<p>【思考】有更多想法，欢迎写在你的学习笔记中。</p>
<p>【总结】本节中我们通过Pandas的一些内置函数对数据进行了初步统计查看，这个过程最重要的不是大家得掌握这些函数，而是看懂从这些函数出来的数据，构建自己的数据分析思维，这也是第一章最重要的点，希望大家学完第一章能对数据有个基本认识，了解自己在做什么，为什么这么做，后面的章节我们将开始对数据进行清洗，进一步分析。</p>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第三章模型建立和评估--建模</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0--%E5%BB%BA%E6%A8%A1-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="第三章-模型搭建和评估建模">第三章 模型搭建和评估–建模</h2>
<p>经过前面的两章的知识点的学习，我可以对数数据的本身进行处理，比如数据本身的增删查补，还可以做必要的清洗工作。那么下面我们就要开始使用我们前面处理好的数据了。这一章我们要做的就是使用数据，我们做数据分析的目的也就是，运用我们的数据以及结合我的业务来得到某些我们需要知道的结果。那么分析的第一步就是建模，搭建一个预测模型或者其他模型；我们从这个模型的到结果之后，我们要分析我的模型是不是足够的可靠，那我就需要评估这个模型。今天我们学习建模，下一节我们学习评估。</p>
<p>我们拥有的泰坦尼克号的数据集，那么我们这次的目的就是，完成泰坦尼克号存活预测这个任务。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">6</span>)  <span class="comment"># 设置输出图片大小</span></span><br></pre></td></tr></table></figure>
<p>载入这些库，如果缺少某些库，请安装他们</p>
<p>【思考】这些库的作用是什么呢？你需要查一查</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考题回答</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Image 是 IPython.display 模块的一部分，用于在 Jupyter Notebook 或 IPython 环境中直接显示图像。支持从本地路径或网络 URL 加载图像，并控制显示格式（如宽度、高度、格式类型）</span></span><br><span class="line"><span class="string">seaborn 是一个基于 Matplotlib 的高级数据可视化库，专注于统计图形的绘制（如分布图、相关性图、分类图等），能快速生成美观且信息丰富的图表</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>&#39;\nImage 是 IPython.display 模块的一部分，用于在 Jupyter Notebook 或 IPython 环境中直接显示图像。支持从本地路径或网络 URL 加载图像，并控制显示格式（如宽度、高度、格式类型）\nseaborn 是一个基于 Matplotlib 的高级数据可视化库，专注于统计图形的绘制（如分布图、相关性图、分类图等），能快速生成美观且信息丰富的图表\n&#39;</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<p><strong>载入我们提供清洗之后的数据(clear_data.csv)，大家也将原始数据载入（train.csv），说说他们有什么不同</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">train.shape</span><br></pre></td></tr></table></figure>
<pre><code>(891, 12)</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>

<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;clear_data.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Pclass
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Fare
</th>
<th>
Sex_female
</th>
<th>
Sex_male
</th>
<th>
Embarked_C
</th>
<th>
Embarked_Q
</th>
<th>
Embarked_S
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
3
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
7.2500
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
1
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
71.2833
</td>
<td>
1
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
3
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
7.9250
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
1
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
53.1000
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
3
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
8.0500
</td>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
</tbody>
</table>
<h3 id="模型搭建">模型搭建</h3>
<ul>
<li>处理完前面的数据我们就得到建模数据，下一步是选择合适模型</li>
<li>在进行模型选择之前我们需要先知道数据集最终是进行<strong>监督学习</strong>还是<strong>无监督学习</strong></li>
<li>模型的选择一方面是通过我们的任务来决定的。</li>
<li>除了根据我们任务来选择模型外，还可以根据数据样本量以及特征的稀疏性来决定</li>
<li>刚开始我们总是先尝试使用一个基本的模型来作为其baseline，进而再训练其他模型做对比，最终选择泛化能力或性能比较好的模型</li>
</ul>
<p>这里我的建模，并不是从零开始，自己一个人完成完成所有代码的编译。我们这里使用一个机器学习最常用的一个库（sklearn）来完成我们的模型的搭建</p>
<p><strong>下面给出sklearn的算法选择路径，供大家参考</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sklearn模型算法选择路径图</span></span><br><span class="line">Image(<span class="string">&#x27;sklearn.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0--%E5%BB%BA%E6%A8%A1-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估--建模-课程_17_0.png" alt="第三章模型建立和评估–建模-课程_17_0">
<figcaption aria-hidden="true">第三章模型建立和评估–建模-课程_17_0</figcaption>
</figure>
<p>【思考】数据集哪些差异会导致模型在拟合数据是发生变化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务一切割训练集和测试集">任务一：切割训练集和测试集</h4>
<p>这里使用留出法划分数据集</p>
<ul>
<li>将数据集分为自变量和因变量</li>
<li>按比例切割训练集和测试集(一般测试集的比例有30%、25%、20%、15%和10%)</li>
<li>使用分层抽样</li>
<li>设置随机种子以便结果能复现</li>
</ul>
<p>【思考】 * 划分数据集的方法有哪些？ *
为什么使用分层抽样，这样的好处有什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 划分数据集的方法有哪些？</span></span><br><span class="line"><span class="comment"># 1.  **留出法 (Hold-out Cross Validation)**：</span></span><br><span class="line"><span class="comment">#     *   直接将数据集D划分为两个互斥的集合：训练集S和测试集T。</span></span><br><span class="line"><span class="comment">#     *   例如，70%的数据用于训练，30%用于测试。</span></span><br><span class="line"><span class="comment">#     *   优点：简单、计算开销小。</span></span><br><span class="line"><span class="comment">#     *   缺点：划分具有随机性，单次划分的结果可能不够稳定和准确，尤其是在数据集较小时。训练集和测试集的样本比例会影响评估结果。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.  **交叉验证法 (Cross Validation)**：</span></span><br><span class="line"><span class="comment">#     *   **k折交叉验证 (k-Fold Cross Validation)**：</span></span><br><span class="line"><span class="comment">#         *   将数据集D划分为k个大小相似的互斥子集 D1, D2, ..., Dk。</span></span><br><span class="line"><span class="comment">#         *   每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集。</span></span><br><span class="line"><span class="comment">#         *   这样可以获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值。</span></span><br><span class="line"><span class="comment">#         *   常用的k值为5或10。</span></span><br><span class="line"><span class="comment">#         *   优点：比留出法更稳定，更充分地利用了数据。</span></span><br><span class="line"><span class="comment">#         *   缺点：计算开销是k倍。</span></span><br><span class="line"><span class="comment">#     *   **留一法 (Leave-One-Out Cross Validation, LOOCV)**：</span></span><br><span class="line"><span class="comment">#         *   k折交叉验证的特例，当k等于样本数N时。</span></span><br><span class="line"><span class="comment">#         *   每次只留下一个样本作为测试集，其余N-1个样本作为训练集。</span></span><br><span class="line"><span class="comment">#         *   优点：评估结果通常被认为比较准确，因为几乎所有数据都用于训练。</span></span><br><span class="line"><span class="comment">#         *   缺点：计算开销非常大，尤其是在数据集很大时。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.  **自助法 (Bootstrapping)**：</span></span><br><span class="line"><span class="comment">#     *   以自助采样法为基础。给定包含m个样本的数据集D，对它进行采样产生数据集D&#x27;：每次随机从D中挑选一个样本，将其拷贝放入D&#x27;，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到。这个过程重复执行m次后，我们就得到了包含m个样本的数据集D&#x27;。</span></span><br><span class="line"><span class="comment">#     *   可以证明，初始数据集D中约有36.8%的样本未出现在采样数据集D&#x27;中。于是我们可将D&#x27;用作训练集，D\D&#x27;用作测试集。</span></span><br><span class="line"><span class="comment">#     *   优点：在数据集较小、难以有效划分训练/测试集时很有用；能从初始数据集中产生多个不同的训练集。</span></span><br><span class="line"><span class="comment">#     *   缺点：自助法产生的数据集改变了初始数据集的分布，会引入估计偏差。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为什么使用分层抽样，这样的好处有什么？</span></span><br><span class="line"><span class="comment"># **分层抽样 (Stratified Sampling)** 是一种抽样技术，它将总体（数据集）划分为若干个互不重叠的子群（称为“层”），然后从每个层中独立地进行简单随机抽样。在划分训练集和测试集时，特别是对于分类任务，通常是根据目标变量的类别进行分层。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># **好处：**</span></span><br><span class="line"><span class="comment"># 1.  **保持类别比例一致性**：</span></span><br><span class="line"><span class="comment">#     *   确保训练集和测试集中的各个类别的样本比例与原始数据集中各个类别的样本比例大致相同。</span></span><br><span class="line"><span class="comment">#     *   这对于类别不平衡的数据集尤为重要。如果进行纯随机抽样，可能会导致训练集或测试集中某些少数类别的样本过少，甚至没有，从而影响模型的训练效果和评估的可靠性。</span></span><br><span class="line"><span class="comment"># 2.  **提高模型的泛化能力和评估的准确性**：</span></span><br><span class="line"><span class="comment">#     *   由于训练集和测试集都较好地代表了原始数据的类别分布，模型在训练时能学习到各个类别的特征，评估时也能更准确地反映模型在所有类别上的表现。</span></span><br><span class="line"><span class="comment">#     *   避免了因随机划分导致训练集和测试集在类别分布上产生较大差异，从而使得模型评估结果更加稳定和可信。</span></span><br><span class="line"><span class="comment"># 3.  **减少抽样误差**：</span></span><br><span class="line"><span class="comment">#     *   相比于简单随机抽样，分层抽样通常能得到更具代表性的样本，从而减少因抽样带来的误差，使得基于样本的推断更加精确。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务提示1">任务提示1</h4>
<ul>
<li>切割数据集是为了后续能评估模型泛化能力</li>
<li>sklearn中切割数据集的方法为<code>train_test_split</code></li>
<li>查看函数文档可以在jupyter
noteboo里面使用<code>train_test_split?</code>后回车即可看到</li>
<li>分层和随机种子在参数里寻找</li>
</ul>
<p>要从clear_data.csv和train.csv中提取train_test_split()所需的参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 一般先取出X和y后再切割，有些情况会使用到未切割的，这时候X和y就可以用,x是清洗好的数据，y是我们要预测的存活数据&#x27;Survived&#x27;</span></span><br><span class="line">X = data</span><br><span class="line">y = train[<span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line"><span class="comment"># 对数据集进行切割</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">X_train.shape, X_test.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>((668, 11), (223, 11))</code></pre>
<p>【思考】 * 什么情况下切割数据集的时候不用进行随机选取</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 在以下情况下切割数据集时可能不需要或不适合进行随机选取：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.  **时间序列数据 (Time Series Data)**：</span></span><br><span class="line"><span class="comment">#     *   对于时间序列数据，数据的顺序至关重要，因为它包含了时间依赖性。随机打乱顺序会破坏这种依赖关系。</span></span><br><span class="line"><span class="comment">#     *   通常的做法是按时间顺序划分，例如，将较早的数据作为训练集，较晚的数据作为测试集（或验证集）。这更符合实际应用中用过去预测未来的场景。</span></span><br><span class="line"><span class="comment">#     *   例如，用前几年的股票数据训练模型，用最近一年的数据测试模型。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.  **数据已经预先排序或具有特定结构**：</span></span><br><span class="line"><span class="comment">#     *   如果数据集已经按照某种对分析有意义的顺序排列（例如，按地理区域、按实验批次等），并且你希望测试集来自与训练集不同的、特定的部分，那么可能需要按顺序或按特定规则划分，而不是随机划分。</span></span><br><span class="line"><span class="comment">#     *   例如，在一个全国性的调查数据中，你可能想用某些省份的数据做训练，用另一些省份的数据做测试，以检验模型的地域泛化能力。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.  **数据集非常大且分布均匀**：</span></span><br><span class="line"><span class="comment">#     *   当数据集非常庞大，并且可以合理假设数据是独立同分布 (i.i.d.) 且分布均匀时，简单地按顺序取一部分作为训练集，另一部分作为测试集，其效果可能与随机选取相差不大。随机选取的计算开销在这种情况下可能显得不必要。</span></span><br><span class="line"><span class="comment">#     *   然而，即使在这种情况下，随机选取通常仍然是更稳妥的做法，以避免潜在的未知偏差。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.  **特定的交叉验证策略**：</span></span><br><span class="line"><span class="comment">#     *   某些交叉验证方法本身就定义了非随机的划分方式。例如，在k折交叉验证中，虽然整体上数据被分成了k折，但每一折的选择是确定的（通常是按顺序分割）。留一法交叉验证更是每次只留一个特定的样本作为测试集。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.  **当需要完全复现特定的、非随机的划分结果时**：</span></span><br><span class="line"><span class="comment">#     *   如果之前的研究或实验使用了某种特定的非随机划分方式，为了比较或复现结果，也需要采用相同的划分方式。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.  **流式数据或在线学习场景**：</span></span><br><span class="line"><span class="comment">#     *   在数据持续不断流入的场景中，模型可能需要用新到达的数据进行测试或持续训练。这种情况下，测试集自然是最新的一部分数据，而不是从历史数据中随机抽取的。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务二模型创建">任务二：模型创建</h4>
<ul>
<li>创建基于线性模型的分类模型（逻辑回归）</li>
<li>创建基于树的分类模型（决策树、随机森林）</li>
<li>分别使用这些模型进行训练，分别的到训练集和测试集的得分</li>
<li>查看模型的参数，并更改参数值，观察模型变化</li>
</ul>
<h4 id="提示">提示</h4>
<ul>
<li>逻辑回归不是回归模型而是分类模型，不要与<code>LinearRegression</code>混淆</li>
<li>随机森林其实是决策树集成为了降低决策树过拟合的情况</li>
<li>线性模型所在的模块为<code>sklearn.linear_model</code></li>
<li>树模型所在的模块为<code>sklearn.ensemble</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 默认参数逻辑回归模型</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 查看训练集和测试集score值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr.score(X_train, y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr.score(X_test, y_test)))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Training set score: 0.80
Testing set score: 0.79</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 调整参数后的逻辑回归模型</span></span><br><span class="line">lr2 = LogisticRegression(C=<span class="number">100</span>)</span><br><span class="line">lr2.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr2.score(X_train, y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr2.score(X_test, y_test)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Training set score: 0.79
Testing set score: 0.78


/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认参数的随机森林分类模型</span></span><br><span class="line">rfc = RandomForestClassifier()</span><br><span class="line">rfc.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc.score(X_train, y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc.score(X_test, y_test)))</span><br></pre></td></tr></table></figure>
<pre><code>Training set score: 1.00
Testing set score: 0.82</code></pre>
<p>【思考】 * 为什么线性模型可以进行分类任务，背后是怎么的数学关系 *
对于多分类问题，线性模型是怎么进行分类的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 为什么线性模型可以进行分类任务，背后是怎么的数学关系</span></span><br><span class="line"><span class="comment"># 线性模型（如逻辑回归 Logistic Regression，或者支持向量机 SVM 的线性核）之所以能用于分类任务，是因为它们通过以下方式将线性组合的输入特征映射到类别预测：</span></span><br><span class="line"><span class="comment"># 1.  **线性组合**：首先，模型计算输入特征的线性组合，形式通常为 `z = w_1*x_1 + w_2*x_2 + ... + w_n*x_n + b`，或者用向量表示为 `z = w^T * x + b`。</span></span><br><span class="line"><span class="comment">#     *   `x` 是输入特征向量。</span></span><br><span class="line"><span class="comment">#     *   `w` 是模型学习到的权重（或系数）。</span></span><br><span class="line"><span class="comment">#     *   `b` 是偏置项（或截距）。</span></span><br><span class="line"><span class="comment">#     这个 `z` 值可以看作是样本点到决策边界的某种度量。</span></span><br><span class="line"><span class="comment"># 2.  **决策函数/激活函数**：然后，这个线性组合的结果 `z` 会被传递给一个决策函数或激活函数，该函数将其转换为类别预测或类别概率。</span></span><br><span class="line"><span class="comment">#     *   **对于逻辑回归 (Logistic Regression)**：</span></span><br><span class="line"><span class="comment">#         *   它使用 Sigmoid (Logistic) 函数：`p = 1 / (1 + e^(-z))`。</span></span><br><span class="line"><span class="comment">#         *   Sigmoid 函数将任意实数值 `z` 映射到 (0, 1) 区间，这个输出 `p` 可以解释为样本属于正类（通常是类别1）的概率。</span></span><br><span class="line"><span class="comment">#         *   通过设定一个阈值（通常是0.5），如果 `p &gt; 0.5` (即 `z &gt; 0`)，则预测为正类；否则预测为负类。</span></span><br><span class="line"><span class="comment">#         *   因此，决策边界是 `z = 0`，即 `w^T * x + b = 0`，这是一个超平面。</span></span><br><span class="line"><span class="comment">#     *   **对于线性支持向量机 (Linear SVM)**：</span></span><br><span class="line"><span class="comment">#         *   它直接使用 `z` 的符号来决定类别。如果 `z &gt; 0`，预测为一类；如果 `z &lt; 0`，预测为另一类。</span></span><br><span class="line"><span class="comment">#         *   SVM 的目标是找到一个能最大化两类样本之间间隔（margin）的决策边界（超平面）。</span></span><br><span class="line"><span class="comment"># 总结来说，线性模型通过学习一个线性决策边界（直线、平面或超平面）来分隔不同类别的样本。它们首先计算一个线性得分，然后通过一个非线性函数（如Sigmoid）或直接根据得分的符号来做出分类决策。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于多分类问题，线性模型是怎么进行分类的</span></span><br><span class="line"><span class="comment"># 当类别数量大于两个时（即多分类问题），线性模型通常采用以下两种主要策略之一将问题转化为多个二分类问题：</span></span><br><span class="line"><span class="comment"># 1.  **一对余 (One-vs-Rest, OvR) 或 一对所有 (One-vs-All, OvA)**：</span></span><br><span class="line"><span class="comment">#     *   **原理**：如果有个 `K` 个类别，OvR 策略会训练 `K` 个独立的二分类器。</span></span><br><span class="line"><span class="comment">#     *   第 `i` 个分类器 (`i` 从 1 到 `K`) 会将类别 `i` 的样本视为正类，而将所有其他 `K-1` 个类别的样本视为负类。</span></span><br><span class="line"><span class="comment">#     *   **预测**：对于一个新的样本，它会被输入到所有 `K` 个分类器中。每个分类器都会输出一个分数或概率，表示该样本属于其对应“正类”的置信度。最终，样本被分配给那个给出最高置信度分数的类别。</span></span><br><span class="line"><span class="comment">#     *   **优点**：直观，实现相对简单，计算效率较高（只需要训练K个分类器）。</span></span><br><span class="line"><span class="comment">#     *   **缺点**：当类别数量很多时，每个二分类器的负类可能包含非常多样化的样本，可能导致类别不平衡问题。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.  **一对一 (One-vs-One, OvO)**：</span></span><br><span class="line"><span class="comment">#     *   **原理**：如果有个 `K` 个类别，OvO 策略会为每一对类别 `(i, j)` 训练一个二分类器，其中 `i != j`。总共需要训练 `K * (K-1) / 2` 个分类器。</span></span><br><span class="line"><span class="comment">#     *   每个分类器只负责区分两个特定的类别。</span></span><br><span class="line"><span class="comment">#     *   **预测**：对于一个新的样本，它会被输入到所有 `K * (K-1) / 2` 个分类器中。每个分类器都会对样本属于其两个类别中的哪一个进行投票。最终，样本被分配给获得最多投票的类别。</span></span><br><span class="line"><span class="comment">#     *   **优点**：每个分类器只需要处理两个类别的数据，通常训练速度更快，且对于某些对类别不平衡不敏感的算法（如SVM）可能表现更好。</span></span><br><span class="line"><span class="comment">#     *   **缺点**：当类别数量 `K` 很大时，需要训练的分类器数量会急剧增加，导致计算成本和存储成本较高。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># **在 scikit-learn 中**：</span></span><br><span class="line"><span class="comment"># *   `LogisticRegression` 默认使用 OvR 策略进行多分类 (可以通过 `multi_class` 参数设置为 `&#x27;multinomial&#x27;` 来使用 Softmax 回归，这是一种直接处理多分类的方法，但其基础仍然是线性的)。</span></span><br><span class="line"><span class="comment"># *   `LinearSVC` (线性支持向量机) 默认使用 OvR 策略。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务三输出模型预测结果">任务三：输出模型预测结果</h4>
<ul>
<li>输出模型预测分类标签</li>
<li>输出不同分类标签的预测概率</li>
</ul>
<h4 id="提示3">提示3</h4>
<ul>
<li>一般监督模型在sklearn里面有个<code>predict</code>能输出预测标签，<code>predict_proba</code>则可以输出标签概率</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred = lr.predict(X_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([0, 1, 1, 1, 0, 0, 1, 0, 1, 1])</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred_proba = lr.predict_proba(X_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred_proba[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.60887905, 0.39112095],
       [0.17668722, 0.82331278],
       [0.40624596, 0.59375404],
       [0.18896449, 0.81103551],
       [0.87984221, 0.12015779],
       [0.91385758, 0.08614242],
       [0.13282516, 0.86717484],
       [0.90555878, 0.09444122],
       [0.05280619, 0.94719381],
       [0.10934565, 0.89065435]])</code></pre>
<p>【思考】 * 预测标签的概率对我们有什么帮助</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第三章模型建立和评估---评价</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="第三章-模型搭建和评估-评估">第三章 模型搭建和评估-评估</h2>
<p>根据之前的模型的建模，我们知道如何运用sklearn这个库来完成建模，以及我们知道了的数据集的划分等等操作。那么一个模型我们怎么知道它好不好用呢？以至于我们能不能放心的使用模型给我的结果呢？那么今天的学习的评估，就会很有帮助。</p>
<p>加载下面的库</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">6</span>)  <span class="comment"># 设置输出图片大小</span></span><br></pre></td></tr></table></figure>
<p><strong>任务：加载数据并分割测试集和训练集</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 一般先取出X和y后再切割，有些情况会使用到未切割的，这时候X和y就可以用,x是清洗好的数据，y是我们要预测的存活数据&#x27;Survived&#x27;</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;clear_data.csv&#x27;</span>)</span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">X = data</span><br><span class="line">y = train[<span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 对数据集进行切割</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 默认参数逻辑回归模型</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
<h3 id="模型评估">模型评估</h3>
<ul>
<li>模型评估是为了知道模型的泛化能力。</li>
<li>交叉验证（cross-validation）是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。</li>
<li>在交叉验证中，数据被多次划分，并且需要训练多个模型。</li>
<li>最常用的交叉验证是 k 折交叉验证（k-fold cross-validation），其中 k
是由用户指定的数字，通常取 5 或 10。</li>
<li>准确率（precision）度量的是被预测为正例的样本中有多少是真正的正例</li>
<li>召回率（recall）度量的是正类样本中有多少被预测为正类</li>
<li>f-分数是准确率与召回率的调和平均</li>
</ul>
<p>【思考】：将上面的概念进一步的理解，大家可以做一下总结</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答：</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务一交叉验证">任务一：交叉验证</h4>
<ul>
<li>用10折交叉验证来评估之前的逻辑回归模型</li>
<li>计算交叉验证精度的平均值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提示：交叉验证</span></span><br><span class="line">Image(<span class="string">&#x27;Snipaste_2020-01-05_16-37-56.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_16_0.png" alt="第三章模型建立和评估—评价-课程_16_0">
<figcaption aria-hidden="true">第三章模型建立和评估—评价-课程_16_0</figcaption>
</figure>
<h4 id="提示4">提示4</h4>
<ul>
<li>交叉验证在sklearn中的模块为<code>sklearn.model_selection</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">lr = LogisticRegression(C=<span class="number">100</span>)</span><br><span class="line">scores = cross_val_score(lr, X_train, y_train, cv=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 平均交叉验证分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Average cross-validation score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(scores.mean()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Average cross-validation score: 0.78</code></pre>
<h4 id="思考4">思考4</h4>
<ul>
<li>k折越多的情况下会带来什么样的影响？</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 当 k 越大时：</span></span><br><span class="line"><span class="comment"># 1. 每次训练使用的数据更多，评估偏差（bias）降低</span></span><br><span class="line"><span class="comment"># 2. 每次测试集样本更少，评估方差（variance）增大</span></span><br><span class="line"><span class="comment"># 3. 需要训练 k 个模型，计算开销显著增加</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务二混淆矩阵">任务二：混淆矩阵</h4>
<ul>
<li>计算二分类问题的混淆矩阵</li>
<li>计算精确率、召回率以及f-分数</li>
</ul>
<p>【思考】什么是二分类问题的混淆矩阵，理解这个概念，知道它主要是运算到什么任务中的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 混淆矩阵（confusion matrix）是一个 2×2 的表格，用于二分类任务中展示模型预测结果与真实标签的对应关系：</span></span><br><span class="line"><span class="comment">#    - True Positive (TP)：真实为正类，预测也为正类</span></span><br><span class="line"><span class="comment">#    - False Positive (FP)：真实为负类，却被误预测为正类</span></span><br><span class="line"><span class="comment">#    - False Negative (FN)：真实为正类，却被误预测为负类</span></span><br><span class="line"><span class="comment">#    - True Negative (TN)：真实为负类，预测也为负类</span></span><br><span class="line"><span class="comment"># 通过混淆矩阵，可以进一步计算精确率（Precision）、召回率（Recall）、F1 分数等指标，</span></span><br><span class="line"><span class="comment"># 帮助我们评估模型在不同类型错误上的表现，常用于分类模型的性能评估和错误分析。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提示：混淆矩阵</span></span><br><span class="line">Image(<span class="string">&#x27;Snipaste_2020-01-05_16-38-26.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_27_0.png" alt="第三章模型建立和评估—评价-课程_27_0">
<figcaption aria-hidden="true">第三章模型建立和评估—评价-课程_27_0</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提示：准确率 (Accuracy),精确度（Precision）,Recall,f-分数计算方法</span></span><br><span class="line">Image(<span class="string">&#x27;Snipaste_2020-01-05_16-39-27.png&#x27;</span>)</span><br><span class="line">​    </span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_28_0.png" alt="第三章模型建立和评估—评价-课程_28_0">
<figcaption aria-hidden="true">第三章模型建立和评估—评价-课程_28_0</figcaption>
</figure>
<h4 id="提示5">提示5</h4>
<ul>
<li>混淆矩阵的方法在sklearn中的<code>sklearn.metrics</code>模块</li>
<li>混淆矩阵需要输入真实标签和预测标签</li>
<li>精确率、召回率以及f-分数可使用<code>classification_report</code>模块</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lr = LogisticRegression(C=<span class="number">100</span>)</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 模型预测结果</span></span><br><span class="line">pred = lr.predict(X_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 混淆矩阵</span></span><br><span class="line">confusion_matrix(y_train, pred)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>array([[355,  57],
       [ 82, 174]])</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="comment"># 精确率、召回率以及f1-score</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_train, pred))</span><br></pre></td></tr></table></figure>
<pre><code>              precision    recall  f1-score   support

           0       0.81      0.86      0.84       412
           1       0.75      0.68      0.71       256

    accuracy                           0.79       668
   macro avg       0.78      0.77      0.78       668
weighted avg       0.79      0.79      0.79       668</code></pre>
<p>【思考】 * 如果自己实现混淆矩阵的时候该注意什么问题</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 如果自己实现混淆矩阵，需要注意：</span></span><br><span class="line"><span class="comment"># 1. 明确行列含义：通常行是真实标签，列是预测标签，并保持一致。</span></span><br><span class="line"><span class="comment"># 2. 类别顺序要固定：最好指定 labels 列表，避免类别稀疏时错位。</span></span><br><span class="line"><span class="comment"># 3. 初始化大小为 n_classes×n_classes 的零矩阵。</span></span><br><span class="line"><span class="comment"># 4. 索引时使用整数或统一的类别映射，避免类型不一致。</span></span><br><span class="line"><span class="comment"># 5. 对每个样本累加到对应的 [真实, 预测] 单元格，最后矩阵元素之和应等于样本数。</span></span><br><span class="line"><span class="comment"># 6. 对于未出现的类别，矩阵对应行或列应保留 0。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务三roc曲线">任务三：ROC曲线</h4>
<ul>
<li>绘制ROC曲线</li>
</ul>
<p>【思考】什么是ROC曲线，OCR曲线的存在是为了解决什么问题？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考</span></span><br><span class="line"><span class="comment"># ROC曲线（Receiver Operating Characteristic Curve）是一条以假正例率（FPR）为横坐标、</span></span><br><span class="line"><span class="comment"># 真正例率（TPR）为纵坐标绘制的曲线，展示模型在不同阈值下的分类性能变化。</span></span><br><span class="line"><span class="comment"># 它解决了单一阈值下评估不全面的问题，通过曲线下的面积（AUC）能够衡量模型整体区分正负样本的能力；</span></span><br><span class="line"><span class="comment"># 对类别不平衡更稳健，可在不同模型或参数设置间进行客观比较。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="提示6">提示6</h4>
<ul>
<li>ROC曲线在sklearn中的模块为<code>sklearn.metrics</code></li>
<li>ROC曲线下面所包围的面积越大越好</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.decision_function(X_test))</span><br></pre></td></tr></table></figure>
<pre><code>[-1.7776276  -1.68901519 -2.9343385  -2.73339993 -0.7425476   0.1771919
  0.42300886 -0.95177507 -2.19297241 -2.09492243 -2.09876666 -2.24379328
 -0.72898893 -0.74448703  1.55206252  2.26736362 -3.0615053  -1.45551632
  1.82143942  1.10174703  2.80348253  2.20862227 -2.08595792 -1.98565326
 -2.62459231  2.61608127  2.52054836  0.46386814 -2.26805651 -1.89799476
 -4.40221097 -2.45118004 -2.11507984  0.25727282  1.56507901 -3.49922092
  0.09517543  3.1727335  -0.66659502 -2.16889122 -2.31738004 -0.75154631
  1.34173247 -0.68691348 -2.38317701 -1.48352807  3.30441868  0.37836543
  0.15120699 -2.39554116  0.71230509 -2.94049784  0.0526656  -0.12124772
  0.21937853 -0.95736671 -2.91315052  1.73227025 -2.30451919 -0.11949728
 -2.40406452 -1.23217853 -3.04709277 -2.51149884 -2.91275507  0.36741872
  1.88515182 -1.73344723  1.61180838 -2.64456699 -2.82671595 -1.32885535
 -1.89201447 -2.38194062  1.14830497  0.7324757   3.41575634 -0.04718518
  1.99047031  0.71098531 -2.5002286   2.11220527  1.35687779 -4.65208202
 -0.50164169 -2.21847127 -0.27744568 -2.1098023  -2.28203956 -2.24087733
  1.49913758 -0.46745632 -1.76590269 -3.13694507 -2.48969764 -2.52447108
 -0.31359417 -2.62456277  0.10812447 -3.22505518 -0.54301462 -1.31398633
 -2.45637232 -0.9392769  -1.99910791 -0.01952273  0.16386412  1.17043699
  0.83571934 -0.30892412 -2.56236834 -2.52630696 -2.15878988  3.38005162
 -1.63316112 -2.0470374   1.16802525  1.96428556 -0.85542758 -0.84711271
 -2.3923425  -2.27467461  1.27340371 -0.16738478  2.77379952 -0.91636487
  3.49337899  2.22265823 -1.03898765 -1.79576035  3.05405598 -1.72625544
 -2.08233698  0.14427761 -2.03826492 -1.87510703 -2.43040363  0.88364821
 -2.31722422  1.21479438 -2.19509856 -1.96948465  2.90456606  1.22909197
 -0.60993113 -2.40508898  1.79832298 -2.33619419 -1.76964851  0.54894164
  0.56920781 -1.65544357 -2.18783672 -2.51890544 -1.1167812   1.85506633
 -2.14366192  2.56003678  1.79741811  2.22038003 -0.93948297  2.11029939
  3.66773152  3.37255532 -1.62079149 -0.21922341 -2.93532548 -1.8851028
 -0.11223495 -0.89402373 -2.79168773  0.58319665 -1.20213471  2.11583429
 -1.78550619 -1.21648746 -2.91538781 -2.80005448 -2.74359191 -0.06775047
 -1.28645408 -1.17048578 -0.1176852  -1.59958242 -0.65901928 -2.40701243
  0.57575073 -3.0756839   1.53932753 -2.49031769 -3.03266822  0.30539932
 -0.05523861 -0.24431132 -2.36483723  3.25595248 -2.11664845 -1.97728592
 -2.04509461 -3.07727841 -1.11942703 -3.38920295 -2.59088459 -3.55978164
  0.22449105 -0.3214215   0.05735696  0.02061023 -3.01544378 -0.77973619
 -1.39798016 -3.10075724 -4.80621573 -3.01948006  3.44366918 -2.88193813
 -2.01992513 -0.09559774  0.91447527 -1.13270082 -2.45426968 -1.91415803
 -0.08403516]</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 计算ROC曲线的假正例率(FPR)、真正例率(TPR)和阈值</span></span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, lr.decision_function(X_test))</span><br><span class="line">plt.plot(fpr, tpr, label=<span class="string">&quot;ROC Curve&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;FPR&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;TPR (recall)&quot;</span>)</span><br><span class="line"><span class="comment"># 找到最接近于0的阈值</span></span><br><span class="line">close_zero = np.argmin(np.<span class="built_in">abs</span>(thresholds))</span><br><span class="line">plt.plot(fpr[close_zero], tpr[close_zero], <span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">10</span>, label=<span class="string">&quot;threshold zero&quot;</span>, fillstyle=<span class="string">&quot;none&quot;</span>, c=<span class="string">&#x27;k&#x27;</span>, mew=<span class="number">2</span>)</span><br><span class="line">plt.legend(loc=<span class="number">4</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_44_3.png" alt="第三章模型建立和评估—评价-课程_44_3">
<figcaption aria-hidden="true">第三章模型建立和评估—评价-课程_44_3</figcaption>
</figure>
<h4 id="思考6">思考6</h4>
<ul>
<li>对于多分类问题如何绘制ROC曲线</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【思考】你能从这条OCR曲线的到什么信息？这些信息可以做什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 从ROC曲线中可以得到以下信息：</span></span><br><span class="line"><span class="comment"># 1. 模型整体性能：曲线下的面积 (AUC - Area Under the Curve) 是一个常用的评估指标。</span></span><br><span class="line"><span class="comment">#    - AUC = 1：完美分类器。</span></span><br><span class="line"><span class="comment">#    - AUC = 0.5：随机分类器（无区分能力，ROC曲线接近对角线）。</span></span><br><span class="line"><span class="comment">#    - AUC &gt; 0.5：模型优于随机猜测。AUC越大，模型区分正负样本的能力越强。</span></span><br><span class="line"><span class="comment">#    - AUC &lt; 0.5：模型表现差于随机猜测（可能标签反了或者模型非常差）。</span></span><br><span class="line"><span class="comment"># 2. 不同阈值下的权衡：ROC曲线展示了在所有可能的分类阈值下，真正例率 (TPR) 与假正例率 (FPR) 之间的关系。</span></span><br><span class="line"><span class="comment">#    - 曲线上的每个点代表一个特定的阈值。</span></span><br><span class="line"><span class="comment">#    - 曲线越靠近左上角 (FPR低, TPR高)，说明模型在较低的假正例率下能达到较高的真正例率，性能越好。</span></span><br><span class="line"><span class="comment"># 3. 模型的区分能力：曲线的形状可以反映模型区分正负样本的能力。如果曲线显著高于对角线，说明模型具有较好的区分能力。</span></span><br><span class="line"><span class="comment"># 4. 阈值选择的依据：可以根据业务需求，在ROC曲线上选择一个合适的平衡点（即选择一个阈值）。</span></span><br><span class="line"><span class="comment">#    - 例如，如果更关注减少漏报（提高TPR），可以选择曲线上TPR较高的点，即使FPR可能略高。</span></span><br><span class="line"><span class="comment">#    - 如果更关注减少误报（降低FPR），可以选择曲线上FPR较低的点，即使TPR可能略低。</span></span><br><span class="line"><span class="comment">#    - 图中标记的 &quot;threshold zero&quot; 点通常是模型默认的分类阈值对应的性能点。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第三节数据重构2</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%89%E8%8A%82%E6%95%B0%E6%8D%AE%E9%87%8D%E6%9E%842-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>在前面我们已经学习了Pandas基础，第二章我们开始进入数据分析的业务部分，在第二章第一节的内容中，我们学习了<strong>数据的清洗</strong>，这一部分十分重要，只有数据变得相对干净，我们之后对数据的分析才可以更有力。而这一节，我们要做的是数据重构，数据重构依旧属于数据理解（准备）的范围。</p>
<h4 id="开始之前导入numpypandas包和数据">开始之前，导入numpy、pandas包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入基本库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 载入上一个任务人保存的文件中:result.csv，并查看这个文件</span></span><br><span class="line">text = pd.read_csv(<span class="string">&#x27;result.csv&#x27;</span>)</span><br><span class="line">text.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Unnamed: 0
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h1 id="第二章数据重构">2 第二章：数据重构</h1>
<h2 id="第一部分数据聚合与运算">第一部分：数据聚合与运算</h2>
<h3 id="数据运用">2.6 数据运用</h3>
<h4 id="任务一通过教材python-for-data-analysisp303google-or-anything来学习了解groupby机制">2.6.1
任务一：通过教材《Python for Data Analysis》P303、Google or
anything来学习了解GroupBy机制</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入心得</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">GroupBy机制是Pandas中用于数据分组与聚合的核心操作，其本质是遵循&quot;Split-Apply-Combine&quot;模式：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Split：按指定键（列、函数、数组等）将数据分割成多个子集</span></span><br><span class="line"><span class="string">Apply：对每个子集独立应用聚合函数（如mean/max）、转换函数（如标准化）或过滤操作</span></span><br><span class="line"><span class="string">Combine：将结果合并为新的数据结构</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="任务二计算泰坦尼克号男性与女性的平均票价">2.4.2：任务二：计算泰坦尼克号男性与女性的平均票价</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">df  = text[<span class="string">&#x27;Fare&#x27;</span>].groupby(text[<span class="string">&#x27;Sex&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(df.groups)</span><br><span class="line">means = df.mean()</span><br><span class="line">means</span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;female&#39;: [1, 2, 3, 8, 9, 10, 11, 14, 15, 18, 19, 22, 24, 25, 28, 31, 32, 38, 39, 40, 41, 43, 44, 47, 49, 52, 53, 56, 58, 61, 66, 68, 71, 79, 82, 84, 85, 88, 98, 100, 106, 109, 111, 113, 114, 119, 123, 128, 132, 133, 136, 140, 141, 142, 147, 151, 156, 161, 166, 167, 172, 177, 180, 184, 186, 190, 192, 194, 195, 198, 199, 205, 208, 211, 215, 216, 218, 229, 230, 233, 235, 237, 240, 241, 246, 247, 251, 254, 255, 256, 257, 258, 259, 264, 268, 269, 272, 274, 275, 276, ...], &#39;male&#39;: [0, 4, 5, 6, 7, 12, 13, 16, 17, 20, 21, 23, 26, 27, 29, 30, 33, 34, 35, 36, 37, 42, 45, 46, 48, 50, 51, 54, 55, 57, 59, 60, 62, 63, 64, 65, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 107, 108, 110, 112, 115, 116, 117, 118, 120, 121, 122, 124, 125, 126, 127, 129, 130, 131, 134, 135, 137, 138, 139, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, ...]&#125;

Sex
female    44.479818
male      25.523893
Name: Fare, dtype: float64</code></pre>
<p>在了解GroupBy机制之后，运用这个机制完成一系列的操作，来达到我们的目的。</p>
<p>下面通过几个任务来熟悉GroupBy机制。</p>
<h4 id="任务三统计泰坦尼克号中男女的存活人数">2.4.3：任务三：统计泰坦尼克号中男女的存活人数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_sex = text[<span class="string">&#x27;Survived&#x27;</span>].groupby(text[<span class="string">&#x27;Sex&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line">survived_sex.head()</span><br></pre></td></tr></table></figure>
<pre><code>Sex
female    233
male      109
Name: Survived, dtype: int64</code></pre>
<h4 id="任务四计算客舱不同等级的存活人数">2.4.4：任务四：计算客舱不同等级的存活人数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_pclass = text[<span class="string">&#x27;Survived&#x27;</span>].groupby(text[<span class="string">&#x27;Pclass&#x27;</span>])</span><br><span class="line">survived_pclass.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<pre><code>Pclass
1    136
2     87
3    119
Name: Survived, dtype: int64</code></pre>
<p>【<strong>提示：</strong>】表中的存活那一栏，可以发现如果还活着记为1，死亡记为0</p>
<p>【<strong>思考</strong>】从数据分析的角度，上面的统计结果可以得出那些结论</p>
<p>【思考】从任务二到任务三中，这些运算可以通过agg()函数来同时计算。并且可以使用rename函数修改列名。你可以按照提示写出这个过程吗？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考心得</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">agg() 函数是 Pandas 中用于对分组后的数据 同时执行多个聚合操作 的核心工具，其全称为 Aggregate（聚合）。它允许你对不同列应用不同的聚合函数，并支持自定义函数，极大提升数据分析效率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">text.groupby(<span class="string">&#x27;Sex&#x27;</span>).agg(&#123;<span class="string">&#x27;Fare&#x27;</span>: <span class="string">&#x27;mean&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>: <span class="string">&#x27;count&#x27;</span>&#125;).rename(columns=</span><br><span class="line">                            &#123;<span class="string">&#x27;Fare&#x27;</span>: <span class="string">&#x27;mean_fare&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>: <span class="string">&#x27;count_pclass&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
mean_fare
</th>
<th>
count_pclass
</th>
</tr>
<tr>
<th>
Sex
</th>
<th>
</th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
female
</th>
<td>
44.479818
</td>
<td>
314
</td>
</tr>
<tr>
<th>
male
</th>
<td>
25.523893
</td>
<td>
577
</td>
</tr>
</tbody>
</table>
<h4 id="任务五统计在不同等级的票中的不同年龄的船票花费的平均值">2.4.5：任务五：统计在不同等级的票中的不同年龄的船票花费的平均值</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">temp=text.groupby([<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Age&#x27;</span>])[<span class="string">&#x27;Fare&#x27;</span>]</span><br><span class="line">temp.groups</span><br><span class="line">temp.mean().head()</span><br></pre></td></tr></table></figure>
<pre><code>Pclass  Age  
1       0.92     151.5500
        2.00     151.5500
        4.00      81.8583
        11.00    120.0000
        14.00    120.0000
Name: Fare, dtype: float64</code></pre>
<h4 id="任务六将任务二和任务三的数据合并并保存到sex_fare_survived.csv">2.4.6：任务六：将任务二和任务三的数据合并，并保存到sex_fare_survived.csv</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">result = pd.merge(means,survived_sex,on=<span class="string">&#x27;Sex&#x27;</span>)</span><br><span class="line">result</span><br><span class="line">result.to_csv(<span class="string">&#x27;sex_fare_survived.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="任务七得出不同年龄的总的存活人数然后找出存活人数最多的年龄段最后计算存活人数最高的存活率存活人数总人数">2.4.7：任务七：得出不同年龄的总的存活人数，然后找出存活人数最多的年龄段，最后计算存活人数最高的存活率（存活人数/总人数）</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_age = text[<span class="string">&#x27;Survived&#x27;</span>].groupby(text[<span class="string">&#x27;Age&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line">survived_age.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Age
0.42    1
0.67    1
0.75    2
0.83    2
0.92    1
Name: Survived, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_age[survived_age.values==survived_age.<span class="built_in">max</span>()]</span><br></pre></td></tr></table></figure>
<pre><code>Age
24.0    15
Name: Survived, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_<span class="built_in">sum</span> = text[<span class="string">&#x27;Survived&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(_<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure>
<pre><code>342</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sum of person:&quot;</span>+<span class="built_in">str</span>(_<span class="built_in">sum</span>))</span><br><span class="line"></span><br><span class="line">precetn =survived_age.<span class="built_in">max</span>()/_<span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最大存活率：&quot;</span>+<span class="built_in">str</span>(precetn))</span><br></pre></td></tr></table></figure>
<pre><code>sum of person:342
最大存活率：0.043859649122807015</code></pre>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第四节数据可视化</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/</url>
    <content><![CDATA[<p><strong>复习：</strong>回顾学习完第一章，我们对泰坦尼克号数据有了基本的了解，也学到了一些基本的统计方法，第二章中我们学习了数据的清理和重构，使得数据更加的易于理解；今天我们要学习的是第二章第三节：<strong>数据可视化</strong>，主要给大家介绍一下Python数据可视化库Matplotlib，在本章学习中，你也许会觉得数据很有趣。在打比赛的过程中，数据可视化可以让我们更好的看到每一个关键步骤的结果如何，可以用来优化方案，是一个很有用的技巧。</p>
<h1 id="第二章数据可视化">2 第二章：数据可视化</h1>
<h4 id="开始之前导入numpypandas以及matplotlib包和数据">开始之前，导入numpy、pandas以及matplotlib包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载所需的库</span></span><br><span class="line"><span class="comment"># 如果出现 ModuleNotFoundError: No module named &#x27;xxxx&#x27;</span></span><br><span class="line"><span class="comment"># 你只需要在终端/cmd下 pip install xxxx 即可</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载result.csv这个数据</span></span><br><span class="line">text = pd.read_csv(<span class="string">r&#x27;result.csv&#x27;</span>)</span><br><span class="line">text.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Unnamed: 0
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2
</td>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
3
</td>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
4
</td>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h3 id="如何让人一眼看懂你的数据">2.7 如何让人一眼看懂你的数据？</h3>
<p>《Python for Data Analysis》第九章</p>
<h4 id="任务一跟着书本第九章了解matplotlib自己创建一个数据项对其进行基本可视化">2.7.1
任务一：跟着书本第九章，了解matplotlib，自己创建一个数据项，对其进行基本可视化</h4>
<p>【思考】最基本的可视化图案有哪些？分别适用于那些场景？（比如折线图适合可视化某个属性值随时间变化的走势）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment">#这一部分需要了解可视化图案的的逻辑，知道什么样的图案可以表达什么样的信号b</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务二可视化展示泰坦尼克号数据集中男女中生存人数分布情况用柱状图试试">2.7.2
任务二：可视化展示泰坦尼克号数据集中男女中生存人数分布情况（用柱状图试试）。</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line">sex = text.groupby(<span class="string">&#x27;Sex&#x27;</span>)[<span class="string">&#x27;Survived&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">sex.plot.bar()</span><br><span class="line">plt.title(<span class="string">&#x27;survived_count&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="./../../../../images/第二章：第四节数据可视化-课程%20(copy)/第二章：第四节数据可视化-课程_10_0.png" alt="第二章：第四节数据可视化-课程_10_0">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_10_0</figcaption>
</figure>
<p>【思考】计算出泰坦尼克号数据集中男女中死亡人数，并可视化展示？如何和男女生存人数可视化柱状图结合到一起？看到你的数据可视化，说说你的第一感受（比如：你一眼看出男生存活人数更多，那么性别可能会影响存活率）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考题回答</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务三可视化展示泰坦尼克号数据集中男女中生存人与死亡人数的比例图用柱状图试试">2.7.3
任务三：可视化展示泰坦尼克号数据集中男女中生存人与死亡人数的比例图（用柱状图试试）。</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"><span class="comment"># 提示：计算男女中死亡人数 1表示生存，0表示死亡</span></span><br><span class="line">text.groupby([<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].count().unstack().plot(kind=<span class="string">&#x27;bar&#x27;</span>,stacked=<span class="string">&#x27;True&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;survived_count&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Text(0, 0.5, &#39;count&#39;)</code></pre>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_14_1.png" alt="第二章：第四节数据可视化-课程_14_1">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_14_1</figcaption>
</figure>
<p>【提示】男女这两个数据轴，存活和死亡人数按比例用柱状图表示</p>
<h4 id="任务四可视化展示泰坦尼克号数据集中不同票价的人生存和死亡人数分布情况用折线图试试横轴是不同票价纵轴是存活人数">2.7.4
任务四：可视化展示泰坦尼克号数据集中不同票价的人生存和死亡人数分布情况。（用折线图试试）（横轴是不同票价，纵轴是存活人数）</h4>
<p>【提示】对于这种统计性质的且用折线表示的数据，你可以考虑将数据排序或者不排序来分别表示。看看你能发现什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"><span class="comment"># 计算不同票价中生存与死亡人数 1表示生存，0表示死亡</span></span><br><span class="line"><span class="comment">#print(text.groupby([&#x27;Fare&#x27;])[&#x27;Survived&#x27;].value_counts())</span></span><br><span class="line">fare_sur = text.groupby([<span class="string">&#x27;Fare&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].value_counts().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">fare_sur</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Fare     Survived
8.0500   0           38
7.8958   0           37
13.0000  0           26
7.7500   0           22
26.0000  0           16
                     ..
6.9500   0            1
6.9750   0            1
         1            1
7.0458   0            1
7.1417   1            1
Name: count, Length: 330, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 排序后绘折线图</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">18</span>))</span><br><span class="line">fare_sur.plot(grid=<span class="literal">True</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_19_0.png" alt="第二章：第四节数据可视化-课程_19_0">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_19_0</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line"><span class="comment"># 排序前绘折线图</span></span><br><span class="line">fare_sur1 = text.groupby([<span class="string">&#x27;Fare&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].value_counts()</span><br><span class="line">fare_sur1</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">18</span>))</span><br><span class="line">fare_sur1.plot(grid=<span class="literal">True</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_20_0.png" alt="第二章：第四节数据可视化-课程_20_0">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_20_0</figcaption>
</figure>
<h4 id="任务五可视化展示泰坦尼克号数据集中不同仓位等级的人生存和死亡人员的分布情况用柱状图试试">2.7.5
任务五：可视化展示泰坦尼克号数据集中不同仓位等级的人生存和死亡人员的分布情况。（用柱状图试试）</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"><span class="comment"># 1表示生存，0表示死亡</span></span><br><span class="line">pclass_sur = text.groupby([<span class="string">&#x27;Pclass&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].value_counts()</span><br><span class="line">pclass_sur</span><br></pre></td></tr></table></figure>
<pre><code>Pclass  Survived
1       1           136
        0            80
2       0            97
        1            87
3       0           372
        1           119
Name: count, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.countplot(x=<span class="string">&quot;Pclass&quot;</span>, hue=<span class="string">&quot;Survived&quot;</span>, data=text)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Axes: xlabel=&#39;Pclass&#39;, ylabel=&#39;count&#39;&gt;</code></pre>
<figure>
<img src="./../../../../images/第二章：第四节数据可视化-课程%20(copy)/第二章：第四节数据可视化-课程_23_1.png" alt="第二章：第四节数据可视化-课程_23_1">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_23_1</figcaption>
</figure>
<p>【思考】看到这个前面几个数据可视化，说说你的第一感受和你的总结</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考题回答</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务六可视化展示泰坦尼克号数据集中不同年龄的人生存与死亡人数分布情况不限表达方式">2.7.6
任务六：可视化展示泰坦尼克号数据集中不同年龄的人生存与死亡人数分布情况。(不限表达方式)</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line">facet = sns.FacetGrid(text, hue=<span class="string">&quot;Survived&quot;</span>,aspect=<span class="number">3</span>)</span><br><span class="line">facet.<span class="built_in">map</span>(sns.kdeplot,<span class="string">&#x27;Age&#x27;</span>,shade= <span class="literal">True</span>)</span><br><span class="line">facet.<span class="built_in">set</span>(xlim=(<span class="number">0</span>, text[<span class="string">&#x27;Age&#x27;</span>].<span class="built_in">max</span>()))</span><br><span class="line">facet.add_legend()</span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/seaborn/axisgrid.py:854: FutureWarning: 

`shade` is now deprecated in favor of `fill`; setting `fill=True`.
This will become an error in seaborn v0.14.0; please update your code.

  func(*plot_args, **plot_kwargs)
/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/seaborn/axisgrid.py:854: FutureWarning: 

`shade` is now deprecated in favor of `fill`; setting `fill=True`.
This will become an error in seaborn v0.14.0; please update your code.

  func(*plot_args, **plot_kwargs)

&lt;seaborn.axisgrid.FacetGrid at 0x7f9c6bce1f50&gt;</code></pre>
<figure>
<img src="./../../../../images/第二章：第四节数据可视化-课程%20(copy)/第二章：第四节数据可视化-课程_27_2.png" alt="第二章：第四节数据可视化-课程_27_2">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_27_2</figcaption>
</figure>
<h4 id="任务七可视化展示泰坦尼克号数据集中不同仓位等级的人年龄分布情况用折线图试试">2.7.7
任务七：可视化展示泰坦尼克号数据集中不同仓位等级的人年龄分布情况。（用折线图试试）</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"></span><br><span class="line">text.Age[text.Pclass == <span class="number">1</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">text.Age[text.Pclass == <span class="number">2</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">text.Age[text.Pclass == <span class="number">3</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;age&quot;</span>)</span><br><span class="line">plt.legend((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),loc=<span class="string">&quot;best&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f9c69946e90&gt;</code></pre>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_29_1.png" alt="第二章：第四节数据可视化-课程_29_1">
<figcaption aria-hidden="true">第二章：第四节数据可视化-课程_29_1</figcaption>
</figure>
<p>【思考】上面所有可视化的例子做一个总体的分析，你看看你能不能有自己发现</p>
<p>【总结】到这里，我们的可视化就告一段落啦，如果你对数据可视化极其感兴趣，你还可以了解一下其他可视化模块，如：pyecharts，bokeh等。</p>
<p>如果你在工作中使用数据可视化，你必须知道数据可视化最大的作用不是炫酷，而是最快最直观的理解数据要表达什么，你觉得呢？</p>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第二节数据重构1</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%BA%8C%E8%8A%82%E6%95%B0%E6%8D%AE%E9%87%8D%E6%9E%841-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>在前面我们已经学习了Pandas基础，第二章我们开始进入数据分析的业务部分，在第二章第一节的内容中，我们学习了<strong>数据的清洗</strong>，这一部分十分重要，只有数据变得相对干净，我们之后对数据的分析才可以更有力。而这一节，我们要做的是数据重构，数据重构依旧属于数据理解（准备）的范围。</p>
<h4 id="开始之前导入numpypandas包和数据">开始之前，导入numpy、pandas包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入基本库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 载入data文件中的:train-left-up.csv</span></span><br><span class="line">text=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-left-up.csv&#x27;</span>)</span><br><span class="line">text.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
</tr>
</tbody>
</table>
<h1 id="第二章数据重构">2 第二章：数据重构</h1>
<h3 id="数据的合并">2.4 数据的合并</h3>
<h4 id="任务一将data文件夹里面的所有数据都载入观察数据的之间的关系">2.4.1
任务一：将data文件夹里面的所有数据都载入，观察数据的之间的关系</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">text_left_up=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-left-up.csv&#x27;</span>)</span><br><span class="line">text_left_down=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-left-down.csv&#x27;</span>)</span><br><span class="line">text_right_up=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-right-up.csv&#x27;</span>)</span><br><span class="line">text_right_down=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-right-down.csv&#x27;</span>)</span><br><span class="line">text_left_up.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
</tr>
</tbody>
</table>
<p>【提示】结合之前我们加载的train.csv数据，大致预测一下上面的数据是什么</p>
<h4 id="任务二使用concat方法将数据train-left-up.csv和train-right-up.csv横向合并为一张表并保存这张表为result_up">2.4.2：任务二：使用concat方法：将数据train-left-up.csv和train-right-up.csv横向合并为一张表，并保存这张表为result_up</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#pandas.concat 是 Pandas 中用于连接 Series 或 DataFrame 对象的核心方法，支持横向（列方向）或纵向（行方向）拼接</span></span><br><span class="line">list_up = [text_left_up,text_right_up]</span><br><span class="line">result_up = pd.concat(list_up,axis=<span class="number">1</span>)</span><br><span class="line">result_up.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h4 id="任务三使用concat方法将train-left-down和train-right-down横向合并为一张表并保存这张表为result_down然后将上边的result_up和result_down纵向合并为result">2.4.3
任务三：使用concat方法：将train-left-down和train-right-down横向合并为一张表，并保存这张表为result_down。然后将上边的result_up和result_down纵向合并为result。</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">list_down=[text_left_down,text_right_down]</span><br><span class="line">result_down = pd.concat(list_down,axis=<span class="number">1</span>)</span><br><span class="line">result = pd.concat([result_up,result_down])</span><br><span class="line">result.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="任务四使用dataframe自带的方法join方法和append完成任务二和任务三的任务">2.4.4
任务四：使用DataFrame自带的方法join方法和append：完成任务二和任务三的任务</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">resul_up = text_left_up.join(text_right_up)</span><br><span class="line">result_down = text_left_down.join(text_right_down)</span><br><span class="line">result = result_up.append(result_down)</span><br><span class="line">result.head()</span><br></pre></td></tr></table></figure>
<h4 id="任务五使用panads的merge方法和dataframe的append方法完成任务二和任务三的任务">2.4.5
任务五：使用Panads的merge方法和DataFrame的append方法：完成任务二和任务三的任务</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">该代码使用 pandas.merge 方法，以索引（index）为键，将两个 DataFrame (text_left_up 和 text_right_up) 横向合并。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">result_up = pd.merge(text_left_up,text_right_up,left_index=<span class="literal">True</span>,right_index=<span class="literal">True</span>)</span><br><span class="line">result_down = pd.merge(text_left_down,text_right_down,left_index=<span class="literal">True</span>,right_index=<span class="literal">True</span>)</span><br><span class="line">result = resul_up.append(result_down)</span><br><span class="line">result.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【思考】对比merge、join以及concat的方法的不同以及相同。思考一下在任务四和任务五的情况下，为什么都要求使用DataFrame的append方法，如何只要求使用merge或者join可不可以完成任务四和任务五呢？</p>
<h4 id="任务六完成的数据保存为result.csv">2.4.6
任务六：完成的数据保存为result.csv</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">result.to_csv(<span class="string">&#x27;result.csv&#x27;</span>)</span><br><span class="line">result.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="换一种角度看数据">2.5 换一种角度看数据</h3>
<h4 id="任务一将我们的数据变为series类型的数据">2.5.1
任务一：将我们的数据变为Series类型的数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#text.stack() 是 Pandas 中用于将 DataFrame 的列旋转为行的方法</span></span><br><span class="line">text = pd.read_csv(<span class="string">&#x27;result.csv&#x27;</span>)</span><br><span class="line">unit_result=text.stack().head(<span class="number">20</span>)</span><br><span class="line">unit_result.head()</span><br></pre></td></tr></table></figure>
<pre><code>0  Unnamed: 0                           0
   PassengerId                          1
   Survived                             0
   Pclass                               3
   Name           Braund, Mr. Owen Harris
dtype: object</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">unit_result.to_csv(<span class="string">&#x27;unit_result.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第一节数据清洗及特征处理</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%80%E8%8A%82%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E5%8F%8A%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p>【回顾&amp;引言】前面一章的内容大家可以感觉到我们主要是对基础知识做一个梳理，让大家了解数据分析的一些操作，主要做了数据的各个角度的观察。那么在这里，我们主要是做数据分析的流程性学习，主要是包括了数据清洗以及数据的特征处理，数据重构以及数据可视化。这些内容是为数据分析最后的建模和模型评价做一个铺垫。</p>
<h4 id="开始之前导入numpypandas包和数据">开始之前，导入numpy、pandas包和数据</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载所需的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载数据train.csv</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br><span class="line">df.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h2 id="第二章数据清洗及特征处理">2 第二章：数据清洗及特征处理</h2>
<p>我们拿到的数据通常是不干净的，所谓的不干净，就是数据中有缺失值，有一些异常点等，需要经过一定的处理才能继续做后面的分析或建模，所以拿到数据的第一步是进行数据清洗，本章我们将学习缺失值、重复值、字符串和数据转换等操作，将数据清洗成可以分析或建模的亚子。</p>
<h3 id="缺失值观察与处理">2.1 缺失值观察与处理</h3>
<p>我们拿到的数据经常会有很多缺失值，比如我们可以看到Cabin列存在NaN，那其他列还有没有缺失值，这些缺失值要怎么处理呢</p>
<h4 id="任务一缺失值观察">2.1.1 任务一：缺失值观察</h4>
<ol type="1">
<li>请查看每个特征缺失值个数<br>
</li>
<li>请查看Age， Cabin， Embarked列的数据
以上方式都有多种方式，所以大家多多益善</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<pre><code>PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[[<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Cabin&#x27;</span>,<span class="string">&#x27;Embarked&#x27;</span>]].head(<span class="number">3</span>)</span><br><span class="line"><span class="comment">#df[&#x27;Age&#x27;].head(3)</span></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Age
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
22.0
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
38.0
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
26.0
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<p>外层 [] 是 DataFrame 的索引操作符。 内层 [] 是 Python
原生的列表语法，用于传递多个列名。</p>
<h4 id="任务二对缺失值进行处理">2.1.2 任务二：对缺失值进行处理</h4>
<p>(1)处理缺失值一般有几种思路</p>
<ol start="2" type="1">
<li><p>请尝试对Age列的数据的缺失值进行处理</p></li>
<li><p>请尝试使用不同的方法直接对整张表的缺失值进行处理</p></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#处理缺失值的一般思路：</span></span><br><span class="line"><span class="comment">#提醒：可使用的函数有---&gt;dropna函数与fillna函数</span></span><br><span class="line"><span class="comment">#print(df.head(3))</span></span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>]==<span class="literal">None</span>]=<span class="number">0</span></span><br><span class="line">df.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>].isnull()]</span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>].isnull()] = <span class="number">0</span> </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>] == np.nan] = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>【思考1】dropna和fillna有哪些参数，分别如何使用呢?</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#dropna() 是 Pandas 中用于删除包含缺失值（NaN 或 None）的行或列的函数。其核心作用是清理数据中的缺失值，适用于数据清洗阶段。</span></span><br><span class="line">df.dropna().head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0000
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#fillna() 是 Pandas 中用于填充缺失值（NaN 或 None）的核心函数，常用于数据清洗阶段。其核心作用是将缺失值替换为合理值，以便后续分析或建模。</span></span><br><span class="line">df.fillna(<span class="number">0</span>).head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
0
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
0
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
</div>
<p>【思考】检索空缺值用<code>np.nan</code>,<code>None</code>以及<code>.isnull()</code>哪个更好，这是为什么？如果其中某个方式无法找到缺失值，原因又是为什么？</p>
<p>【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html</p>
<p>【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html</p>
<h3 id="重复值观察与处理">2.2 重复值观察与处理</h3>
<p>由于这样那样的原因，数据中会不会存在重复值呢，如果存在要怎样处理呢</p>
<h4 id="任务一请查看数据中的重复值">2.2.1
任务一：请查看数据中的重复值</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#df.duplicated()返回一个布尔序列 (Series)，标记每一行是否为重复行</span></span><br><span class="line">df[df.duplicated()]</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
17
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
19
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
26
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
28
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
29
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
<tr>
<th>
859
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
863
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
868
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
878
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
<tr>
<th>
888
</th>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
</tr>
</tbody>
</table>
<p>
176 rows × 12 columns
</p>
<h4 id="任务二对重复值进行处理">2.2.2 任务二：对重复值进行处理</h4>
<p>(1)重复值有哪些处理方式呢？</p>
<p>(2)处理我们数据的重复值</p>
<p>方法多多益善</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#重复值有哪些处理方式：</span></span><br><span class="line"><span class="comment">#删除 DataFrame 中的重复行（完全相同的行只保留一次）。</span></span><br><span class="line">df = df.drop_duplicates()</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
</tr>
</tbody>
</table>
<h4 id="任务三将前面清洗的数据保存为csv格式">2.2.3
任务三：将前面清洗的数据保存为csv格式</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">df.to_csv(<span class="string">&#x27;test_clear.csv&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="特征观察与处理">2.3 特征观察与处理</h3>
<p>我们对特征进行一下观察，可以把特征大概分为两大类：<br>
数值型特征：Survived ，Pclass， Age ，SibSp， Parch，
Fare，其中Survived， Pclass为离散型数值特征，Age，SibSp， Parch，
Fare为连续型数值特征<br>
文本型特征：Name， Sex， Cabin，Embarked， Ticket，其中Sex， Cabin，
Embarked，
Ticket为类别型文本特征，数值型特征一般可以直接用于模型的训练，但有时候为了模型的稳定性及鲁棒性会对连续变量进行离散化。文本型特征往往需要转换成数值型特征才能用于建模分析。</p>
<h4 id="任务一对年龄进行分箱离散化处理">2.3.1
任务一：对年龄进行分箱（离散化）处理</h4>
<ol type="1">
<li><p>分箱操作是什么？</p></li>
<li><p>将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示</p></li>
<li><p>将连续变量Age划分为[0,5) [5,15) [15,30) [30,50)
[50,80)五个年龄段，并分别用类别变量12345表示</p></li>
<li><p>将连续变量Age按10% 30% 50% 70%
90%五个年龄段，并用分类变量12345表示</p></li>
<li><p>将上面的获得的数据分别进行保存，保存为csv格式</p></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#分箱操作是什么：</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分箱操作（Binning）是数据预处理中的一种常用技术，主要用于将连续型数值转换为离散的区间（即“箱子”或“分组”）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示</span></span><br><span class="line">df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(df[<span class="string">&#x27;Age&#x27;</span>], <span class="number">5</span>,labels = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">df.head()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
AgeBand
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
2
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
3
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
2
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将连续变量Age划分为(0,5] (5,15] (15,30] (30,50] (50,80]五个年龄段，并分别用类别变量12345表示</span></span><br><span class="line">df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(df[<span class="string">&#x27;Age&#x27;</span>],[<span class="number">0</span>,<span class="number">5</span>,<span class="number">15</span>,<span class="number">30</span>,<span class="number">50</span>,<span class="number">80</span>],labels = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">df.head(<span class="number">3</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
AgeBand
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
4
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将连续变量Age按10% 30% 50 70% 90%五个年龄段，并用分类变量12345表示</span></span><br><span class="line">df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.qcut(df[<span class="string">&#x27;Age&#x27;</span>],[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">0.3</span>,<span class="number">0.5</span>,<span class="number">0.7</span>,<span class="number">0.9</span>],labels = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
Cabin
</th>
<th>
Embarked
</th>
<th>
AgeBand
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
2
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
C85
</td>
<td>
C
</td>
<td>
5
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
3
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
C123
</td>
<td>
S
</td>
<td>
4
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
NaN
</td>
<td>
S
</td>
<td>
4
</td>
</tr>
</tbody>
</table>
<p>【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html</p>
<p>【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html</p>
<h4 id="任务二对文本变量进行转换">2.3.2 任务二：对文本变量进行转换</h4>
<ol type="1">
<li>查看文本变量名及种类<br>
</li>
<li>将文本变量Sex， Cabin ，Embarked用数值变量12345表示<br>
</li>
<li>将文本变量Sex， Cabin， Embarked用one-hot编码表示</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#方法一: value_counts</span></span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>].value_counts(),</span><br><span class="line">df[<span class="string">&#x27;Cabin&#x27;</span>].value_counts(),</span><br><span class="line">df[<span class="string">&#x27;Embarked&#x27;</span>].value_counts())</span><br></pre></td></tr></table></figure>
<pre><code>Sex
male      453
female    261
0           1
Name: count, dtype: int64 Cabin
B96 B98        4
G6             4
C23 C25 C27    4
F2             3
C22 C26        3
              ..
E36            1
D7             1
C118           1
C99            1
D37            1
Name: count, Length: 135, dtype: int64 Embarked
S    554
C    130
Q     28
0      1
Name: count, dtype: int64</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>].unique()</span><br><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>].nunique()</span><br></pre></td></tr></table></figure>
<pre><code>3</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将类别文本转换为12345</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#方法一: replace</span></span><br><span class="line">df[<span class="string">&#x27;Sex_num&#x27;</span>] = df[<span class="string">&#x27;Sex&#x27;</span>].replace([<span class="string">&#x27;male&#x27;</span>,<span class="string">&#x27;female&#x27;</span>],[<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">df.head()</span><br><span class="line"><span class="comment">#方法二: map</span></span><br><span class="line">df[<span class="string">&#x27;Sex_num&#x27;</span>] = df[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;female&#x27;</span>: <span class="number">2</span>&#125;)</span><br><span class="line">df.head()</span><br><span class="line"><span class="comment">#方法三: 使用sklearn.preprocessing的LabelEncoder</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> [<span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Ticket&#x27;</span>]:</span><br><span class="line">    lbl = LabelEncoder()  </span><br><span class="line">    label_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(df[feat].unique(), <span class="built_in">range</span>(df[feat].nunique())))</span><br><span class="line">    <span class="comment">#print(label_dict)</span></span><br><span class="line">    df[feat + <span class="string">&quot;_labelEncode&quot;</span>] = df[feat].<span class="built_in">map</span>(label_dict)</span><br><span class="line">    df[feat + <span class="string">&quot;_labelEncode&quot;</span>] = lbl.fit_transform(df[feat].astype(<span class="built_in">str</span>))</span><br><span class="line"></span><br><span class="line">df.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/tmp/ipykernel_1400/2627332835.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option(&#39;future.no_silent_downcasting&#39;, True)`
  df[&#39;Sex_num&#39;] = df[&#39;Sex&#39;].replace([&#39;male&#39;,&#39;female&#39;],[1,2])</code></pre>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
PassengerId
</th>
<th>
Survived
</th>
<th>
Pclass
</th>
<th>
Name
</th>
<th>
Sex
</th>
<th>
Age
</th>
<th>
SibSp
</th>
<th>
Parch
</th>
<th>
Ticket
</th>
<th>
Fare
</th>
<th>
…
</th>
<th>
Age_66.0
</th>
<th>
Age_70.0
</th>
<th>
Age_70.5
</th>
<th>
Age_71.0
</th>
<th>
Age_74.0
</th>
<th>
Age_80.0
</th>
<th>
Embarked_0
</th>
<th>
Embarked_C
</th>
<th>
Embarked_Q
</th>
<th>
Embarked_S
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Braund, Mr. Owen Harris
</td>
<td>
male
</td>
<td>
22.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
A/5 21171
</td>
<td>
7.2500
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Cumings, Mrs. John Bradley (Florence Briggs Th…
</td>
<td>
female
</td>
<td>
38.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
PC 17599
</td>
<td>
71.2833
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
<td>
False
</td>
<td>
False
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3
</td>
<td>
1
</td>
<td>
3
</td>
<td>
Heikkinen, Miss. Laina
</td>
<td>
female
</td>
<td>
26.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
STON/O2. 3101282
</td>
<td>
7.9250
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4
</td>
<td>
1
</td>
<td>
1
</td>
<td>
Futrelle, Mrs. Jacques Heath (Lily May Peel)
</td>
<td>
female
</td>
<td>
35.0
</td>
<td>
1
</td>
<td>
0
</td>
<td>
113803
</td>
<td>
53.1000
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5
</td>
<td>
0
</td>
<td>
3
</td>
<td>
Allen, Mr. William Henry
</td>
<td>
male
</td>
<td>
35.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
373450
</td>
<td>
8.0500
</td>
<td>
…
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
False
</td>
<td>
True
</td>
</tr>
</tbody>
</table>
<p>
5 rows × 109 columns
</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#将类别文本转换为one-hot编码</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#方法一: OneHotEncoder</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> [<span class="string">&quot;Age&quot;</span>, <span class="string">&quot;Embarked&quot;</span>]:</span><br><span class="line">    x = pd.get_dummies(df[<span class="string">&quot;Age&quot;</span>] // <span class="number">6</span>)</span><br><span class="line"><span class="comment">#     x = pd.get_dummies(pd.cut(df[&#x27;Age&#x27;],5))</span></span><br><span class="line">    x = pd.get_dummies(df[feat], prefix=feat)</span><br><span class="line">    df = pd.concat([df, x], axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#df[feat] = pd.get_dummies(df[feat], prefix=feat)</span></span><br><span class="line">    </span><br><span class="line">df.head()</span><br><span class="line">df.to_csv(<span class="string">&#x27;temp.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="任务三从纯文本name特征里提取出titles的特征所谓的titles就是mrmissmrs等">2.3.3
任务三：从纯文本Name特征里提取出Titles的特征(所谓的Titles就是Mr,Miss,Mrs等)</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#保存最终你完成的已经清理好的数据</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——中缀表达式</title>
    <url>/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E4%B8%AD%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="数据结构中缀表达式">数据结构——中缀表达式</h1>
<h2 id="利用中缀表达式直接求值">利用中缀表达式直接求值</h2>
<p>要实现中缀表达式直接求值，必须设置两个栈，一个栈用于存放操作数，记作
<code>OPND</code>； 另一个栈用于存放操作符，记作 <code>OPTR</code>。</p>
<p>中缀表达式求值算法步骤如下：</p>
<ol type="1">
<li>初始化：操作符栈中放置一个元素 <code>@</code>。</li>
<li>依次读取中缀表达式中的每一个字符，对于不同类型的字符按以下情况处理：
<ol type="1">
<li>若读到的是操作数，则压入操作数栈，并读取下一个字符。</li>
<li>若读到的是操作符 <code>c</code>，则将操作符栈的栈顶元素
<code>pre_op</code>与之进行比较，会出现以下 3 种情况：
<ul>
<li>若 <code>pre_op &lt; c</code>，则将 <code>c</code>
入栈，并读取下一个字符。</li>
<li>若 <code>pre_op = c</code>，则将 <code>pre_op</code>
出栈，并读取下一个字符。</li>
<li>若 <code>pre_op &gt; c</code>，则将 <code>pre_op</code>
出栈，并在操作数栈中退栈 2 次，依次得到操作数 <code>b</code> 和
<code>a</code>，然后进行 <code>a pre_op b</code>
运算，将运算结果压入操作数栈。</li>
</ul></li>
</ol></li>
<li>扫描完毕时，操作数栈中只有一个元素，即计算结果。</li>
</ol>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E4%B8%AD%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/IMG_20241026_164151.jpg" alt="IMG_20241026_164151">
<figcaption aria-hidden="true">IMG_20241026_164151</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//中缀表达式，实数</span></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">Expression_Eval2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	SeqStack&lt;<span class="type">char</span>, <span class="number">100</span>&gt; OPTR;</span><br><span class="line">	SeqStack&lt;<span class="type">double</span>, <span class="number">100</span>&gt; OPND;</span><br><span class="line">	OPTR.<span class="built_in">Push</span>(<span class="string">&#x27;@&#x27;</span>);</span><br><span class="line">	<span class="type">char</span> ch = <span class="built_in">getchar</span>();</span><br><span class="line">	<span class="keyword">while</span> (ch != <span class="string">&#x27;@&#x27;</span> || OPTR.<span class="built_in">Top</span>() != <span class="string">&#x27;@&#x27;</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (<span class="built_in">isdigit</span>(ch) || ch == <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">// 处理多位数和小数</span></span><br><span class="line">			string number;</span><br><span class="line">			<span class="keyword">while</span> (<span class="built_in">isdigit</span>(ch) || ch == <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">			&#123;</span><br><span class="line">				number += ch;</span><br><span class="line">				ch = <span class="built_in">getchar</span>();</span><br><span class="line">			&#125;</span><br><span class="line">			OPND.<span class="built_in">Push</span>(<span class="built_in">stod</span>(number));</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="type">char</span> pre_op = OPTR.<span class="built_in">Top</span>();</span><br><span class="line">			<span class="keyword">switch</span> (<span class="built_in">Precede</span>(pre_op, ch))</span><br><span class="line">			&#123;</span><br><span class="line">			<span class="keyword">case</span> <span class="string">&#x27;&lt;&#x27;</span>:</span><br><span class="line">				OPTR.<span class="built_in">Push</span>(ch);</span><br><span class="line">				ch = <span class="built_in">getchar</span>();</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			<span class="keyword">case</span> <span class="string">&#x27;=&#x27;</span>:</span><br><span class="line">				OPTR.<span class="built_in">Pop</span>();</span><br><span class="line">				ch = <span class="built_in">getchar</span>();</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			<span class="keyword">case</span> <span class="string">&#x27;&gt;&#x27;</span>:</span><br><span class="line">				<span class="type">char</span> pre_op = OPTR.<span class="built_in">Pop</span>();</span><br><span class="line">				<span class="type">double</span> b = OPND.<span class="built_in">Pop</span>();</span><br><span class="line">				<span class="type">double</span> a = OPND.<span class="built_in">Pop</span>();</span><br><span class="line">				OPND.<span class="built_in">Push</span>(<span class="built_in">Operate</span>(a, pre_op, b));</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> OPND.<span class="built_in">Top</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>Precede(pre_op, ch)</code>为进行算符优先级比较的函数</p>
<p><code>Operate(a, pre_op, b)</code>为计算函数</p>
<h2 id="利用后缀表达式求值">利用后缀表达式求值</h2>
<h2 id="优点">优点</h2>
<p>后缀是指把操作符放在两个操作数的后面。采用后缀表示的算术表达式被称为<strong>后缀表达式</strong>或<strong>后缀算</strong>。
在后缀表达式中，<strong>完全按照操作符出现的先后顺序进行计算过程，不存在括号，也不存在优先级的差别</strong>。</p>
<p>将中缀表达式转换成等价的后缀表达式求值时，不需要再考虑操作符的优先级，只需从左到右扫描一边后缀表达式即可。只需设置一个OPND栈用于存放操作数</p>
<h3 id="先将中缀表达式转成后缀表达式">先将中缀表达式转成后缀表达式</h3>
<p>把中缀表达式转换为后缀表达式算法的基本思路如下：</p>
<ol type="1">
<li><p>初始化：操作符栈中放置一个元素 <code>@</code>。</p></li>
<li><p>依次读入中缀表达式中的每个字符</p>
<p>，对于不同类型的字符按不同情况进行处理：</p>
<ol type="1">
<li>若读到的是操作数，则输出该操作数，并读取下一个字符。</li>
<li>若读到的是左括号 <code>(</code>，则把它压入 <code>OPTR</code>
栈中，并读取下一个字符。</li>
<li>若读到的是右括号
<code>)</code>，则表明括号内的中缀表达式已经扫描完毕，将
<code>OPTR</code>
栈从栈顶直到左括号之前的操作符依次出栈并输出，然后将左括号出栈，并读取下一个字符。</li>
<li>若读到的是操作符 <code>c</code>，则将操作符栈的栈顶元素
<code>pre_op</code>与之进行比较：
<ul>
<li>若 <code>pre_op &lt; c</code>，则将 <code>c</code>
入栈，并读取下一个字符。</li>
<li>若 <code>pre_op &gt;= c</code>，则将 <code>pre_op</code>
出栈并输出。</li>
</ul></li>
<li>若读到的是结束符
<code>@</code>，则把栈中剩余的操作符依次出栈并输出，即可得到转换成的后缀表达式。</li>
</ol></li>
</ol>
<h2 id="后缀表达式求值">后缀表达式求值</h2>
<p>后缀表达式求值算法的基本思路如下</p>
<ol type="1">
<li><p>依次读入后缀表达式中的每个字符</p>
<p>，直至表达式结束。</p>
<ul>
<li>若读到的是操作数，则入 <code>OPND</code> 栈。</li>
<li>若读到的是操作符，则在 <code>OPND</code>
栈中退栈两个元素（先退出的是操作符右侧，后退出的是操作符左侧），然后用该操作符进行运算，并将运算结果压入
<code>OPND</code> 栈中。</li>
</ul></li>
<li><p><strong>后缀表达式扫描完毕时</strong>，若 <code>OPND</code>
栈中仅有一个元素，即为运算结果。</p></li>
</ol>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——图</title>
    <url>/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/</url>
    <content><![CDATA[<h2 id="图的基本概念和术语">图的基本概念和术语</h2>
<p>定义：一个图可以利用两个集合进行定义。第一个集合是点的集合,这些点在图术语中一般被称(Vertex);第二个集合是连接两个顶点的边(Edge)的集合。图的具体定义如下。
图是由顶点集合及顶点间的关系集合组成的一种数据结构:Graph = (V, E)</p>
<p>基本术语</p>
<ol type="1">
<li><p>有向图</p></li>
<li><p>无向图</p></li>
<li><p>邻接点</p></li>
<li><p>顶点的度，入度与出度</p></li>
<li><p>权和网：</p>
<ul>
<li><strong>权 ：</strong>
某些图的每条边都可能赋予一个数值，这个数值称为权。</li>
<li><strong>网 ：</strong> 带有权的图称为网。</li>
</ul></li>
<li><p><strong>无向完全图：</strong>
任意两个顶点之间都有一条边的无向图。</p>
<p><strong>有向完全图：</strong>
任意两个顶点之间都有方向相反的两条边的有向图。</p></li>
</ol>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202190122603.png" alt="image-20241202190122603">
<figcaption aria-hidden="true">image-20241202190122603</figcaption>
</figure>
<ol start="7" type="1">
<li><p>路径与路径长度</p></li>
<li><p><strong>简单路径</strong>：若路径上经过的各顶点均不重复，则称这样的路径为简单路径。</p>
<p><strong>回路或环</strong>：若路径上的第一个顶点与最后一个顶点相同，则称这样的路径为回路或环。</p></li>
</ol>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202190704319.png" alt="image-20241202190704319">
<figcaption aria-hidden="true">image-20241202190704319</figcaption>
</figure>
<ol start="9" type="1">
<li><p><strong>连通图：</strong>
在无向图中，若任意两个顶点之间都存在路径，则称该图为连通图。</p>
<p><strong>连通分量：</strong>
非连通图的极大连通子图称为连通分量。也就是说，一个连通分量是一个连通的子图，且不能再扩大。</p></li>
<li><p><strong>强连通图：</strong> 在有向图中，若对于任意一对顶点 u 和
v，都存在一条从 u 到 v 和从 v 到 u 的路径，则称该图为强连通图。</p>
<p><strong>强连通分量：</strong>
非强连通图的极大强连通子图称为强连通分量。</p></li>
<li><p><strong>生成树：</strong>
一个连通图的生成树是包含图中所有顶点的极小连通子图。也就是说，生成树是一棵树，且包含图中的所有顶点。</p>
<p><strong>生成森林：</strong>
非连通图的每个连通分量分别可以得到一棵生成树，这些生成树的集合称为生成森林。</p></li>
</ol>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202191533963.png" alt="image-20241202191533963">
<figcaption aria-hidden="true">image-20241202191533963</figcaption>
</figure>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202191543162.png" alt="image-20241202191543162">
<figcaption aria-hidden="true">image-20241202191543162</figcaption>
</figure>
<h2 id="图的储存结构">图的储存结构</h2>
<h3 id="邻接矩阵">邻接矩阵</h3>
<p>邻接矩阵表示法的基本思想是引入两个数组：</p>
<ul>
<li>一个用于记录图中各个顶点信息的—维数组，称为顶点表；</li>
<li>另一个用于表示图中各个顶点之间关系的二维数组，称为邻接矩阵。</li>
</ul>
<p>设图G=(V,
E)是具有n(n&gt;0)个顶点的图，则图G所对应的邻接矩阵A是一个n阶方阵</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202192441396.png" alt="image-20241202192441396">
<figcaption aria-hidden="true">image-20241202192441396</figcaption>
</figure>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202192456777.png" alt="image-20241202192456777">
<figcaption aria-hidden="true">image-20241202192456777</figcaption>
</figure>
<p>无向图的邻接矩阵可采用只存储上三角阵或下三角阵的压缩存储方法</p>
<hr>
<p>对于带权图，需要对邻接矩阵的元素值定义进行修改，让元素值表示相应顶点的权值</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202192636345.png" alt="image-20241202192636345">
<figcaption aria-hidden="true">image-20241202192636345</figcaption>
</figure>
<p>其中，∞可用计算机中的一个足够大的数代替，以与权重区分</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202193146935.png" alt="image-20241202193146935">
<figcaption aria-hidden="true">image-20241202193146935</figcaption>
</figure>
<h4 id="算法">算法</h4>
<p>图类MGraph的定义</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 图的类型定义: 无向图、无向网、有向图、有向网</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">GraphType</span> &#123; undigraph, digraph, undinetwork, dinetwork &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeType</span> &#123; <span class="comment">// 本类型定义也适用于后面的邻接表结构</span></span><br><span class="line">    T head, tail;</span><br><span class="line">    <span class="type">int</span> cost;</span><br><span class="line">    <span class="built_in">EdgeType</span>(T h, T t, <span class="type">int</span> c) &#123;</span><br><span class="line">        head = h;</span><br><span class="line">        tail = t;</span><br><span class="line">        cost = c;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MGraph</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> vexnum, edgenum;</span><br><span class="line">    GraphType kind;</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; edges; <span class="comment">// 邻接矩阵</span></span><br><span class="line">    vector&lt;T&gt; vexs;            <span class="comment">// 顶点表</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>无向有权图的邻接矩阵构建</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">createAdjMatrix</span><span class="params">(vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; adjMatrix, <span class="type">const</span> vector&lt;tuple&lt;<span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>&gt;&gt;&amp; edges, <span class="type">int</span> numVertices)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化邻接矩阵为无穷大</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numVertices; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; numVertices; ++j) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i != j) adjMatrix[i][j] = INT_MAX; <span class="comment">// 没有边的地方设置为无穷大，当i=j的值为0</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 填充边的信息</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; edge : edges) &#123;</span><br><span class="line">        <span class="type">int</span> u = <span class="built_in">get</span>&lt;<span class="number">0</span>&gt;(edge);  <span class="comment">// 获取第一个元素</span></span><br><span class="line">        <span class="type">int</span> v = <span class="built_in">get</span>&lt;<span class="number">1</span>&gt;(edge);  <span class="comment">// 获取第二个元素</span></span><br><span class="line">        <span class="type">int</span> weight = <span class="built_in">get</span>&lt;<span class="number">2</span>&gt;(edge);  <span class="comment">// 获取第三个元素</span></span><br><span class="line">        adjMatrix[u][v] = weight;</span><br><span class="line">        adjMatrix[v][u] = weight;  <span class="comment">// 无向图</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="邻接表">邻接表</h3>
<p>当一个图为稀疏图时（边数相对顶点较少），使用邻接矩阵法显然要浪费大量的存储空间，如下图所示：</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/dc28a71607451fd5adeb57fadf14659b.png" alt="dc28a71607451fd5adeb57fadf14659b">
<figcaption aria-hidden="true">dc28a71607451fd5adeb57fadf14659b</figcaption>
</figure>
<p>邻接表中存在两种结点:顶点表结点和边表结点，如下图所示。</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/5257342f8b24df2a6af18a35e74af60b.png" alt="5257342f8b24df2a6af18a35e74af60b">
<figcaption aria-hidden="true">5257342f8b24df2a6af18a35e74af60b</figcaption>
</figure>
<p>顶点表结点由顶点域(data)和指向第一条邻接边的指针(firstarc)
构成，边表(邻接表)结点由邻接点域(adjvex)和指向下一条邻接边的指针域(nextarc)
构成。</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241205203225293.png" alt="image-20241205203225293">
<figcaption aria-hidden="true">image-20241205203225293</figcaption>
</figure>
<h4 id="算法-1">算法</h4>
<p>基于邻接表存储表示的图类ALGraph定义</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 边节点</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeNode</span> &#123;</span><br><span class="line">    <span class="type">int</span> adjvex;  <span class="comment">// 邻接点下标</span></span><br><span class="line">    EdgeNode* next; <span class="comment">// 指向下一个邻接点</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 顶点节点</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">VexNode</span> &#123;</span><br><span class="line">    T data;</span><br><span class="line">    EdgeNode* firstEdge;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 图的邻接表表示</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ALGraph</span> &#123;</span><br><span class="line">    vector&lt;VexNode&lt;T&gt;&gt; vex;  <span class="comment">// 顶点数组</span></span><br><span class="line">    <span class="type">int</span> vexnum, edgenum;  <span class="comment">// 顶点数和边数</span></span><br><span class="line">	GraphType kind;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>无向图的构建</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">ALGraph&lt;T&gt;::<span class="built_in">ALGraph</span>(GraphType t, T vexs[], <span class="type">int</span> n, <span class="type">int</span> e) &#123;</span><br><span class="line">    <span class="comment">// 参数表示图的类型, 参数vexs为存储各顶点值的数组, 参数n和e分别为顶点数和边数</span></span><br><span class="line">    vexnum = n;</span><br><span class="line">    edgenum = e;</span><br><span class="line">    kind = t;</span><br><span class="line">    adjlist.<span class="built_in">resize</span>(vexnum);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化顶点表</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; ++i) &#123;</span><br><span class="line">        adjlist[i].data = vexs[i];</span><br><span class="line">        adjlist[i].firstEdge = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 依次输入所有的边的信息</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; edgenum; j++) &#123;</span><br><span class="line">        <span class="type">int</span> va, vb;</span><br><span class="line">        cin &gt;&gt; va &gt;&gt; vb;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 产生第一个表结点</span></span><br><span class="line">        EdgeNode* p = <span class="keyword">new</span> EdgeNode;</span><br><span class="line">        p-&gt;adjvex = vb;</span><br><span class="line">        p-&gt;nextedge = adjlist[va].firstEdge;</span><br><span class="line">        adjlist[va].firstEdge = p;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 产生第二个表结点</span></span><br><span class="line">        p = <span class="keyword">new</span> EdgeNode;</span><br><span class="line">        p-&gt;adjvex = va;</span><br><span class="line">        p-&gt;nextedge = adjlist[vb].firstEdge;</span><br><span class="line">        adjlist[vb].firstEdge = p;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="图的遍历">图的遍历</h2>
<p>为了防止已经访问过的结点重复访问的问题，提出了辅助数组
<code>visited[]</code></p>
<h3 id="深度优先遍历">深度优先遍历</h3>
<p><strong>深度优先搜索类似于树的先序遍历。</strong></p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241205210048064.png" alt="image-20241205210048064">
<figcaption aria-hidden="true">image-20241205210048064</figcaption>
</figure>
<p>算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> visited[MAX_VERTEX_NUM];	<span class="comment">//访问标记数组</span></span><br><span class="line"><span class="comment">/*从顶点出发，深度优先遍历图G*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFS</span><span class="params">(Graph G, <span class="type">int</span> v)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> w;</span><br><span class="line">	<span class="built_in">visit</span>(v);	<span class="comment">//访问顶点</span></span><br><span class="line">	visited[v] = TRUE;	<span class="comment">//设已访问标记</span></span><br><span class="line">	<span class="comment">//FirstNeighbor(G,v):求图G中顶点v的第一个邻接点，若有则返回顶点号，否则返回-1。</span></span><br><span class="line">	<span class="comment">//NextNeighbor(G,v,w):假设图G中顶点w是顶点v的一个邻接点，返回除w外顶点v</span></span><br><span class="line">	<span class="keyword">for</span>(w = <span class="built_in">FirstNeighbor</span>(G, v); w&gt;=<span class="number">0</span>; w=<span class="built_in">NextNeighor</span>(G, v, w))&#123;</span><br><span class="line">		<span class="keyword">if</span>(!visited[w])&#123;	<span class="comment">//w为u的尚未访问的邻接顶点</span></span><br><span class="line">			<span class="built_in">DFS</span>(G, w);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*对图进行深度优先遍历*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFSTraverse</span><span class="params">(MGraph G)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> v; </span><br><span class="line">	<span class="keyword">for</span>(v=<span class="number">0</span>; v&lt;G.vexnum; ++v)&#123;</span><br><span class="line">		visited[v] = FALSE;	<span class="comment">//初始化已访问标记数据</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span>(v=<span class="number">0</span>; v&lt;G.vexnum; ++v)&#123;	<span class="comment">//从v=0开始遍历</span></span><br><span class="line">		<span class="keyword">if</span>(!visited[v])&#123;</span><br><span class="line">			<span class="built_in">DFS</span>(G, v);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>DFS算法是一个递归算法，需要借助一个递归工作栈，故其空间复杂度为O(V)。</p>
<p>对于n个顶点e条边的图来说，邻接矩阵由于是二维数组，要查找每个顶点的邻接点需要访问矩阵中的所有元素，因此都需要O(V^2)的时间。而邻接表做存储结构时，找邻接点所需的时间取决于顶点和边的数量，所以是O(V＋E)。</p>
<h3 id="广度优先遍历">广度优先遍历</h3>
<p><strong>图的广度优先遍历就类似于树的层序遍历</strong></p>
<p>算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*邻接矩阵的广度遍历算法*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFSTraverse</span><span class="params">(MGraph G)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> i, j;</span><br><span class="line">	Queue Q;</span><br><span class="line">	<span class="keyword">for</span>(i = <span class="number">0</span>; i&lt;G,numVertexes; i++)&#123;</span><br><span class="line">		visited[i] = FALSE;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">InitQueue</span>(&amp;Q);	<span class="comment">//初始化一辅助用的队列</span></span><br><span class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;G.numVertexes; i++)&#123;</span><br><span class="line">		<span class="comment">//若是未访问过就处理</span></span><br><span class="line">		<span class="keyword">if</span>(!visited[i])&#123;</span><br><span class="line">			vivited[i] = TRUE;	<span class="comment">//设置当前访问过</span></span><br><span class="line">			<span class="built_in">visit</span>(i);	<span class="comment">//访问顶点</span></span><br><span class="line">			<span class="built_in">EnQueue</span>(&amp;Q, i);	<span class="comment">//将此顶点入队列</span></span><br><span class="line">			<span class="comment">//若当前队列不为空</span></span><br><span class="line">			<span class="keyword">while</span>(!<span class="built_in">QueueEmpty</span>(Q))&#123;</span><br><span class="line">				<span class="built_in">DeQueue</span>(&amp;Q, &amp;i);	<span class="comment">//顶点i出队列</span></span><br><span class="line">				<span class="comment">//FirstNeighbor(G,v):求图G中顶点v的第一个邻接点，若有则返回顶点号，否则返回-1。</span></span><br><span class="line">				<span class="comment">//NextNeighbor(G,v,w):假设图G中顶点w是顶点v的一个邻接点，返回除w外顶点v</span></span><br><span class="line">				<span class="keyword">for</span>(j=<span class="built_in">FirstNeighbor</span>(G, i); j&gt;=<span class="number">0</span>; j=<span class="built_in">NextNeighbor</span>(G, i, j))&#123;</span><br><span class="line">					<span class="comment">//检验i的所有邻接点</span></span><br><span class="line">					<span class="keyword">if</span>(!visited[j])&#123;</span><br><span class="line">						<span class="built_in">visit</span>(j);	<span class="comment">//访问顶点j</span></span><br><span class="line">						visited[j] = TRUE;	<span class="comment">//访问标记</span></span><br><span class="line">						<span class="built_in">EnQueue</span>(Q, j);	<span class="comment">//顶点j入队列</span></span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>无论是邻接表还是邻接矩阵的存储方式，BFS算法都需要借助一个辅助队列Q,
n个顶点均需入队一次，在最坏的情况下，空间复杂度为O(V)。
采用邻接表存储方式时，每个顶点均需搜索一次(或入队一次)，在搜索任一顶点的邻接点时，每条边至少访问一次，算法总的时间复杂度为O(V＋E)。采用邻接矩阵存储方式时，查找每个顶点的邻接点所需的时间为O(V)，故算法总的时间复杂度为O(V^2)。</p>
<blockquote>
<p>注意:图的邻接矩阵表示是唯一的，但对于邻接表来说，若边的输入次序不同，生成的邻接表也不同。因此，对于同样一个图，基于邻接矩阵的遍历所得到的DFS序列和BFS序列是唯一的，基于邻接表的遍历所得到的DFS序列和BFS序列是不唯一的。</p>
</blockquote>
<h3 id="应用">应用</h3>
<p>简单路径的搜索算法 dfs</p>
<p>二部图的判定算法</p>
<h2 id="最小生成树">最小生成树</h2>
<p>生成树变成非连通图;若给它增加一条边，则会形成图中的一条回路。对于一个带权连通无向图G=(V,E)，生成树不同，其中边的权值之和最小的那棵生成树（构造连通网的最小代价生成树)，称为G的<strong>最小生成树(Minimum-Spanning-Tree,MST)</strong>。</p>
<h3 id="普里姆prim算法">普里姆（Prim）算法</h3>
<p><strong>从一个顶点出发，在保证不形成回路的前提下，每找到并添加一条最短的边，就把当前形成的连通分量当做一个整体或者一个点看待，然后重复“找最短的边并添加”的操作。</strong></p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/d0daac1cd8df11a443697ee6bc3fcf03.png" alt="d0daac1cd8df11a443697ee6bc3fcf03">
<figcaption aria-hidden="true">d0daac1cd8df11a443697ee6bc3fcf03</figcaption>
</figure>
<p>引入辅助数组<code>miniedges[]</code>，用于存放每个节点到节点v的边的权值，并每次挑选出权值最小的那个边所对应的节点加入生成树，辅助数组<code>miniedges[]</code>的数据类型如下</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Edge</span> &#123;</span><br><span class="line">    <span class="type">int</span> adjvex;  <span class="comment">// 与当前生成树连接的节点的编号</span></span><br><span class="line">    <span class="type">int</span> lowcost; <span class="comment">// 到当前生成树的最小边权值</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>若将某个数组元素<code>miniedges[i]</code>的
lowcost成员值设为0，则表示相应的顶点v,已加入到最小生成树中。</p>
<p>为便于算法在执行过程中读取任意两个顶点之间边的权值，对图宜采用<strong>邻接矩阵存储结构</strong>。</p>
<p>算法思路：</p>
<ol type="1">
<li><p>初始化辅助数组，从节点v开始，将v的lowcost设为0，说明已经加入生成树</p></li>
<li><p>循环vexnum-1次，利用函数<code>MiniNum</code>找到权值最小的节点并输出</p>
<p>函数<code>MiniNum</code>循环vexnum次，找到当前所有节点中，<strong>未加入生成树的</strong>，lowcost最小的节点</p></li>
<li><p>更新辅助数组<code>miniedges[]</code>的每个节点的lowcost：循环vexnum次，如果通过当前节点k能找到比原先更小的边，更新该节点的lowcost；如果大，则保留原lowcost的值，更新后代表生成树节点的集合到未加入节点的集合的权值最小的vexnum条边</p></li>
</ol>
<p>时间复杂度：O(n^2)</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Prim</span><span class="params">(<span class="type">const</span> vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; graph, <span class="type">int</span> v, <span class="type">int</span> vexnum)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化 miniedges 数组</span></span><br><span class="line">    Edge* miniedges = <span class="keyword">new</span> Edge[vexnum];</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化 miniedges，每个节点到起始点v的边的权值</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        miniedges[i].adjvex = <span class="built_in">GetVexValue</span>(v);        <span class="comment">// 初始时节点的连接为起始节点v</span></span><br><span class="line">        miniedges[i].lowcost = <span class="built_in">GetEdgeValue</span>(graph, v, i);   <span class="comment">// 初始化每个节点到v的边权值</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    miniedges[v].lowcost = <span class="number">0</span>; <span class="comment">// 将起始节点v的lowcost设为0，表示已经加入生成树</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 循环执行，每次选取一个未加入生成树的权值最小的节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        <span class="comment">// 找到最小的lowcost</span></span><br><span class="line">        <span class="type">int</span> k = <span class="built_in">MiniNum</span>(miniedges, vexnum);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输出当前加入生成树的边</span></span><br><span class="line">        cout &lt;&lt; miniedges[k].adjvex &lt;&lt; <span class="string">&quot; --&gt; &quot;</span> &lt;&lt; <span class="built_in">GetVexValue</span>(k) &lt;&lt; endl;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将选中的节点k加入生成树</span></span><br><span class="line">        miniedges[k].lowcost = <span class="number">0</span>; <span class="comment">// 表示节点k已加入生成树</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 更新与当前生成树连接的节点的lowcost（最小边权值）</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; vexnum; j++) &#123;</span><br><span class="line">            <span class="comment">// 如果通过当前节点k能找到比原先更小的边，更新该节点的lowcost</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">GetEdgeValue</span>(graph, k, j) &lt; miniedges[j].lowcost) &#123;</span><br><span class="line">                miniedges[j].adjvex = <span class="built_in">GetVexValue</span>(k);   <span class="comment">// 记录当前节点k</span></span><br><span class="line">                miniedges[j].lowcost = <span class="built_in">GetEdgeValue</span>(graph, k, j); <span class="comment">// 更新到生成树的最小边权值</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放动态分配的内存</span></span><br><span class="line">    <span class="keyword">delete</span>[] miniedges;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>函数<code>MiniNum</code>用于在数组miniedges中查找集合V-U中的具有最小权值的顶点,可以将它定义为私有成员函数</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 找到当前所有节点中，未加入生成树的，lowcost最小的节点</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">MiniNum</span><span class="params">(Edge miniedges[], <span class="type">int</span> vexnum)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> min = INT_MAX;</span><br><span class="line">    <span class="type">int</span> k = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (miniedges[i].lowcost != <span class="number">0</span> &amp;&amp; miniedges[i].lowcost &lt; min) &#123; <span class="comment">// 如果该节点未加入生成树</span></span><br><span class="line">            min = miniedges[i].lowcost;</span><br><span class="line">            k = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> k; <span class="comment">// 返回最小权值的节点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="克鲁斯卡尔kruskal算法">克鲁斯卡尔（Kruskal）算法</h3>
<p><strong>与Prim算法从顶点开始扩展最小生成树不同，Kruskal
算法是一种按权值的递增次序选择合适的边来构造最小生成树的方法。</strong></p>
<p>每次挑选为加入生成树的最小边，若不构成回路，则加入生成树，若构成则挑选下一个</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/6b95ef2bc34f407c122e931cf06b11e6.png" alt="6b95ef2bc34f407c122e931cf06b11e6">
<figcaption aria-hidden="true">6b95ef2bc34f407c122e931cf06b11e6</figcaption>
</figure>
<p>为提高算法执行过程中<strong>查找最小权值边的速度</strong>，可以采用一种排序算法(如堆排序算法)对边集数组中的边按权值进行排序。</p>
<p>接下来，Kruskal算法的关键问题就是<strong>如何判断所选取的边加入T中是否会产生回路</strong>，这里通过引入称为<strong>并查集</strong>的数据结构来解决</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/fb9515df040633c09b3c136601c8dbd7-1743416415437-1.png" alt="fb9515df040633c09b3c136601c8dbd7">
<figcaption aria-hidden="true">fb9515df040633c09b3c136601c8dbd7</figcaption>
</figure>
<p>在下面描述的Kruskal 算法实现中，首先利用私有成员
<code>GetGraph()函数</code><strong>将图的边按权值排好序后存入边集数组graph中</strong>，而<code>边集数组tree</code>则用于<strong>保存和返回算法所构造的最小生成树T</strong>。</p>
<p>算法思路：</p>
<ol type="1">
<li>初始话数组<code>graph</code>，用于存放所有的边，并对其排序</li>
<li>并查集的使用利用<code>数组components</code>，先进行初始化，每个节点的祖先都是自己，也可以理解成每个节点都构成一个集合，后续并查集的过程即为集合合并的过程</li>
<li>循环直到找到最小生成树的所有边（vexnum -
1条），对于每条边，查找他的起点和终点节点的祖先，若是一个祖先则说明在同一集合，不能加入到生成树；若不是一个，则可以加入到<code>生成树数组tree</code>，并要修改节点的祖先，使他们集合合并</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">Kruskal</span>(vector&lt;EdgeType&gt; &amp;tree) &#123;</span><br><span class="line">    <span class="comment">// 创建一个图的边集合，用于存放所有的边</span></span><br><span class="line">    vector&lt;EdgeType&gt; graph;</span><br><span class="line">    <span class="comment">// GetGraph函数将图的所有边按权值从小到大存放到graph数组中</span></span><br><span class="line">    <span class="built_in">GetGraph</span>(graph);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化最小生成树数组，并且初始化并查集组件</span></span><br><span class="line">    tree.<span class="built_in">resize</span>(vexnum - <span class="number">1</span>);  <span class="comment">// 最小生成树包含的边数量是vexnum - 1</span></span><br><span class="line">    <span class="type">int</span> *components = <span class="keyword">new</span> <span class="type">int</span>[vexnum];  <span class="comment">// 记录每个节点所属的集合</span></span><br><span class="line">    <span class="comment">// 初始时，每个节点都属于自己的集合</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        components[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> k = <span class="number">0</span>, j = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 循环直到找到最小生成树的所有边（vexnum - 1条）</span></span><br><span class="line">    <span class="keyword">while</span> (k &lt; vexnum - <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// 从排序好的边中选择一条边</span></span><br><span class="line">        <span class="type">int</span> h1 = graph[j].head;  <span class="comment">// 边的起点</span></span><br><span class="line">        <span class="type">int</span> t1 = graph[j].tail;  <span class="comment">// 边的终点</span></span><br><span class="line">        <span class="type">int</span> h2 = components[h1];  <span class="comment">// 获取起点所在的集合</span></span><br><span class="line">        <span class="type">int</span> t2 = components[t1];  <span class="comment">// 获取终点所在的集合</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果起点和终点属于不同的集合，则这条边可以加入最小生成树</span></span><br><span class="line">        <span class="keyword">if</span> (h2 != t2) &#123;</span><br><span class="line">            <span class="comment">// 将这条边加入最小生成树中</span></span><br><span class="line">            tree[k].head = h1;</span><br><span class="line">            tree[k].tail = t1;</span><br><span class="line">            tree[k].cost = graph[j].cost;  <span class="comment">// 边的权值</span></span><br><span class="line">            k++;  <span class="comment">// 记录已选择的边的数量</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 合并两个集合，统一编号</span></span><br><span class="line">            <span class="comment">// 将所有属于终点集合t2的顶点，集合编号更新为起点集合h2的编号</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (components[i] == t2) &#123;</span><br><span class="line">                    components[i] = h2;  <span class="comment">// 更新组件编号</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        j++;  <span class="comment">// 继续检查下一条边</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放动态分配的内存</span></span><br><span class="line">    <span class="keyword">delete</span>[] components;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>显然，Kruskal算法的效率与所选择的<strong>排序算法的效率</strong>以及<strong>并查集数据结构的实现效率</strong>有关。若采用第10章介绍的比较高效的<strong>堆排序算法</strong>排序，<strong>并查集采用树结构</strong>实现，则Kruskal算法的时间复杂度可达到O(<span class="math inline"> <em>e</em><em>l</em><em>o</em><em>g</em><sub>2</sub><em>e</em></span>)。相比
Prim
算法而言，Kruskal算法更适用于求解稀疏网(指边数较少的网)的最小生成树。</p>
<h2 id="最短路径">最短路径</h2>
<p>在网图和非网图中，最短路径的含义是不同的。由于非网图它没有边上的权值，所谓的最短路径，其实就是指两顶点之间经过的边数最少的路径；而<strong>对于网图来说，最短路径，是指两顶点之间经过的边上权值之和最少的路径，并且我们称路径上的第一个顶点是源点，最后一个顶点是终点。</strong></p>
<p>求图的最短路径问题通常可分为两类。一类是求图中某顶点到其余各顶点的最短路径问题，也称为<strong>单源最短路径问题</strong>;另一类是求图中每对顶点之间的最短路径问题。</p>
<h3 id="迪杰斯特拉-dijkstra-算法">迪杰斯特拉( Dijkstra )算法</h3>
<p>Dijkstra算法用于构建单源点的最短路径—，即图中某个点到任何其他点的距离都是最短的。例如，构建地图应用时查找自己的坐标离某个地标的最短距离。可以用于有向图，但是不能存在负权值。</p>
<p><strong>通俗点说，迪杰斯特拉(Dijkstra)算法，它并不是一下子求出了<span class="math inline"> <em>v</em><sub><em>i</em></sub></span>到<span class="math inline"> <em>v</em><sub><em>j</em></sub></span>的最短路径，而是一步步求出它们之间顶点的最短路径，过程中都是基于已经求出的最短路径的基础上，求得更远顶点的最短路径，最终得到你要的结果。</strong></p>
<p>下面介绍
Dijkstra算法的具体实现。为便于在算法执行过程中快速地求得任意两个顶点之间边的权值，图的存储结构宜采用邻接矩阵方式。</p>
<p>为标识图中各顶点在算法执行过程中<strong>是否已求出最短路径</strong>，设置一个<code>一维数组s[]</code></p>
<p>为记录
Dijkstra算法所求出的从源点到各顶点的最短路径，引入<code>数组 path[]</code>,
path[i]中保存了从源点到终点v,的最短路径上该顶点的<strong>前驱顶点的序号</strong>。算法结束时，可根据数组path[
]找到源点到v,的最短路径上每个顶点的前驱顶点，并一直回溯至源点，从而推出从源点到v的最短路径。</p>
<p>为便于每次从V-S中选择当前离源点距离最短的顶点，需要引人一个<code>辅助数组dist[]</code>。它的每一个分量dist[i]表示当前所确定的从源点<span class="math inline"> <em>v</em><sub>0</sub></span>,到终点<span class="math inline"> <em>v</em><sub><em>i</em></sub></span>的最短路径.</p>
<p>算法思路：</p>
<ol type="1">
<li>初始化，s[]所有值为0，s[0]设置为1，代表从<span class="math inline"> <em>v</em><sub>0</sub></span>节点开始，path[]所有值设为0，path[0]设为-1，dist[]通过查找邻接矩阵，得到<span class="math inline"> <em>v</em><sub>0</sub></span>到各个顶点的值</li>
<li>查找dist中最小的值，从该节点继续完成最小路径，将该节点对应s[]设为1</li>
<li>遍历尚未找到最短路径的节点，即s[]为0，dist[i] = Min{dist[i]，dist[j]
+cost(j,i)}，选择是借用上一个最短路径的节点到达还是直接到达，更新dist的值</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Dijkstra算法：计算从起点start到其他所有节点的最短路径</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dijkstra</span><span class="params">(<span class="type">int</span> start, <span class="type">int</span> dist[], <span class="type">int</span> path[])</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = numVertices;  <span class="comment">// 获取图中节点的数量</span></span><br><span class="line">    <span class="type">bool</span> visited[n];  <span class="comment">// 访问标记数组，用于标记节点是否已经被访问</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化dist数组和path数组</span></span><br><span class="line">    <span class="comment">// dist[i] 表示从起点到节点i的最短距离</span></span><br><span class="line">    <span class="comment">// path[i] 表示从起点到节点i的最短路径的前驱节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">        visited[i] = <span class="literal">false</span>;  <span class="comment">// 初始时，所有节点均未被访问</span></span><br><span class="line">        dist[i] = adjMatrix[start][i];  <span class="comment">// dist数组初始化为起点到各节点的初始距离</span></span><br><span class="line">        <span class="keyword">if</span> (dist[i] != INT_MAX || i == start) &#123;  <span class="comment">// 如果有边（距离不为无穷大），或者是起点本身</span></span><br><span class="line">            path[i] = start;  <span class="comment">// 将路径的前驱节点设置为起点</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            path[i] = <span class="number">-1</span>;  <span class="comment">// 如果节点无法从起点到达，前驱节点为-1</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    dist[start] = <span class="number">0</span>;  <span class="comment">// 起点到起点的距离为0</span></span><br><span class="line">    visited[start] = <span class="literal">true</span>;  <span class="comment">// 标记起点为已访问</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进行n-1轮循环，逐步更新最短路径</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> count = <span class="number">0</span>; count &lt; n - <span class="number">1</span>; ++count) &#123;</span><br><span class="line">        <span class="type">int</span> min = INT_MAX, min_index;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到未访问的节点中距离最小的节点</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v = <span class="number">0</span>; v &lt; n; ++v) &#123;</span><br><span class="line">            <span class="comment">// 选择距离最小且未被访问的节点</span></span><br><span class="line">            <span class="keyword">if</span> (visited[v] == <span class="literal">false</span> &amp;&amp; dist[v] &lt;= min) &#123;</span><br><span class="line">                min = dist[v];  <span class="comment">// 更新最小距离</span></span><br><span class="line">                min_index = v;  <span class="comment">// 记录最小距离节点的索引</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        visited[min_index] = <span class="literal">true</span>;  <span class="comment">// 标记该节点为已访问</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 更新与该最小距离节点相邻的节点的距离</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v = <span class="number">0</span>; v &lt; n; ++v) &#123;</span><br><span class="line">            <span class="comment">// 如果v节点未被访问，并且从min_index到v有边，且经过min_index节点的路径更短</span></span><br><span class="line">            <span class="keyword">if</span> (!visited[v] &amp;&amp;  </span><br><span class="line">                dist[v] &gt; dist[min_index] + adjMatrix[min_index][v]) &#123;</span><br><span class="line">                dist[v] = dist[min_index] + adjMatrix[min_index][v];  <span class="comment">// 更新v的最短距离</span></span><br><span class="line">                path[v] = min_index;  <span class="comment">// 更新v的前驱节点</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241209092422699.png" alt="image-20241209092422699">
<figcaption aria-hidden="true">image-20241209092422699</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 打印从源节点到目标节点v的路径</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintPath</span><span class="params">(<span class="type">const</span> vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; g, vector&lt;<span class="type">int</span>&gt; path, vector&lt;<span class="type">int</span>&gt; dist, <span class="type">int</span> v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (dist[v] == INF) &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;节点 &quot;</span> &lt;&lt; v &lt;&lt; <span class="string">&quot; 无法到达&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 递归打印路径</span></span><br><span class="line">    <span class="keyword">if</span> (path[v] != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="built_in">PrintPath</span>(g, path, dist, path[v]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; v &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>时间复杂度O(n^2)</p>
<h3 id="弗洛伊德-floyd-算法">弗洛伊德( Floyd )算法</h3>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/e00a2f6ecb05b16c2cae4adfb9da8698.png" alt="e00a2f6ecb05b16c2cae4adfb9da8698">
<figcaption aria-hidden="true">e00a2f6ecb05b16c2cae4adfb9da8698</figcaption>
</figure>
<p>算法原理：递归</p>
<p>n阶数组D：用于保留每一步所求得的所有顶点对之间的当前最短路径长度</p>
<p>初始化：<span class="math inline"> <em>D</em>[<em>i</em>][<em>j</em>] = <em>c</em><em>o</em><em>s</em><em>t</em>(<em>i</em>,<em>j</em>)</span>用邻接矩阵进行初始化</p>
<p>状态转移方程：<span class="math inline"> <em>D</em><sup><em>k</em></sup>[<em>i</em>][<em>j</em>] = <em>m</em><em>i</em><em>n</em>{<em>D</em><sup><em>k</em> − 1</sup>[<em>i</em>][<em>j</em>], <em>D</em><sup><em>k</em> − 1</sup>[<em>i</em>][<em>k</em>] + <em>D</em><sup><em>k</em> − 1</sup>[<em>k</em>][<em>j</em>]}</span>更新<span class="math inline"><em>v</em><sub><em>i</em></sub></span>到<span class="math inline"><em>v</em><sub><em>j</em></sub></span>的最短路径</p>
<p>path数组：用于存储最短路径，初始化若没有直接路径则<span class="math inline"> <em>p</em><em>a</em><em>t</em><em>h</em>[<em>i</em>][<em>j</em>] =  − 1</span>，若有则<span class="math inline"> <em>p</em><em>a</em><em>t</em><em>h</em>[<em>i</em>][<em>j</em>] = <em>j</em></span></p>
<p>算法思路：</p>
<p>初始化数组，遍历n*n次，即<span class="math inline"><em>v</em><sub><em>i</em></sub></span>到<span class="math inline"><em>v</em><sub><em>j</em></sub></span>和<span class="math inline"><em>v</em><sub><em>j</em></sub></span>到<span class="math inline"><em>v</em><sub><em>i</em></sub></span>都遍历一遍，通过状态转移方程更新D数组的值，若找到短的路径，则同时也更新path数组</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Floyd算法</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">Floyd</span>(<span class="type">int</span> path[][MAXV], <span class="type">int</span> D[][MAXV]) &#123;</span><br><span class="line">    <span class="comment">// 初始化距离矩阵D和路径矩阵path</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; vexnum; ++j) &#123;</span><br><span class="line">            D[i][j] = edges[i][j];</span><br><span class="line">            <span class="comment">//初始化path</span></span><br><span class="line">            <span class="keyword">if</span> (D[i][j] &lt; INF &amp;&amp; i != j)</span><br><span class="line">                path[i][j] = j;  <span class="comment">// 若i到j有直接路径，记录路径</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                path[i][j] = <span class="number">-1</span>; <span class="comment">// 否则路径不存在</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 核心Floyd-Warshall算法</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; vexnum; ++k) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; vexnum; ++j) &#123;</span><br><span class="line">                <span class="keyword">if</span> (D[i][k] != INF &amp;&amp; D[k][j] != INF &amp;&amp; D[i][k] + D[k][j] &lt; D[i][j]) &#123;</span><br><span class="line">                    D[i][j] = D[i][k] + D[k][j];  <span class="comment">// 更新最短路径长度</span></span><br><span class="line">                    path[i][j] = path[i][k];      <span class="comment">// 更新路径</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>函数OutputPath用于输出保存于二维数组path中的所有路径以及保存于二维数组D中的路径长度</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">OutputPath</span><span class="params">(MGraph&lt;T&gt; &amp;G, <span class="type">int</span> path[][MAXV], <span class="type">int</span> D[][MAXV])</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 遍历所有顶点对，输出源点到目标点的最短路径及路径长度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; G.vexnum; ++i) &#123;      <span class="comment">// 遍历所有源点 i</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; G.vexnum; ++j) &#123;  <span class="comment">// 遍历所有目标点 j</span></span><br><span class="line">            <span class="keyword">if</span> (i != j) &#123; <span class="comment">// 排除自身到自身的情况</span></span><br><span class="line">                <span class="keyword">if</span> (D[i][j] == INF) &#123;  <span class="comment">// 若距离为无穷大，表示无路径</span></span><br><span class="line">                    std::cout &lt;&lt; <span class="string">&quot;Path from &quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; to &quot;</span> &lt;&lt; j &lt;&lt; <span class="string">&quot;: No path exists.\n&quot;</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;  <span class="comment">// 若存在路径</span></span><br><span class="line">                    std::cout &lt;&lt; <span class="string">&quot;Path from &quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; to &quot;</span> &lt;&lt; j &lt;&lt; <span class="string">&quot; (Length: &quot;</span> &lt;&lt; D[i][j] &lt;&lt; <span class="string">&quot;): &quot;</span>;</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">// 输出路径，使用 path 数组逐步跟踪中间节点</span></span><br><span class="line">                    <span class="type">int</span> temp = i;      <span class="comment">// 起始点</span></span><br><span class="line">                    std::cout &lt;&lt; temp; <span class="comment">// 输出源点</span></span><br><span class="line">                    <span class="keyword">while</span> (temp != j) &#123; <span class="comment">// 当未到达目标点时</span></span><br><span class="line">                        temp = path[temp][j];  <span class="comment">// 获取路径中的下一个节点</span></span><br><span class="line">                        std::cout &lt;&lt; <span class="string">&quot; -&gt; &quot;</span> &lt;&lt; temp; <span class="comment">// 输出中间节点或目标点</span></span><br><span class="line">                    &#125;</span><br><span class="line">                    std::cout &lt;&lt; std::endl; <span class="comment">// 换行</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="aov网与拓扑排序">AOV网与拓扑排序</h2>
<p><strong>有向无环图：不含环的有向图</strong></p>
<p><strong>AOV网</strong>：<strong>在一个表示工程的有向图中，用顶点表示活动，用弧表示活动之间的优先关系，这样的有向图为顶点表示活动的网</strong></p>
<p><strong>拓扑序列</strong>：<strong>设G=(V,E)是一个具有n个顶点的有向图，V中的顶点序列V,
V2 ,..V
n，满足若从顶点V到V;有一条路径，则在顶点序列中顶点V必在顶点V;之前。则我们称这样的顶点序列为一个拓扑序列。</strong></p>
<p><strong>拓扑排序</strong>：<strong>其实就是对一个有向图构造拓扑序列的过程</strong>。每个AOV网都有一个或多个拓扑排序序列。</p>
<figure>
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241215131046998.png" alt="image-20241215131046998">
<figcaption aria-hidden="true">image-20241215131046998</figcaption>
</figure>
<p>对一个AOV网进行拓扑排序的算法有很多，下面介绍比较常用的一种方法的步骤:</p>
<p>①从AOV网中选择一个没有前驱的顶点并输出。
②从网中删除该顶点和所有以它为起点的有向边。
③重复①和②直到当前的AOV网为空或当前网中不存在无前驱的顶点为止。如果输出顶点数少了，哪怕是少了一个，也说明这个网存在环(回路)，不是AOV网。
<img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241215131727207.png" alt="image-20241215131727207"></p>
<p>算法原理：dfs</p>
<p>对于AOV 网宜采用<strong>邻接表</strong>作为存储结构</p>
<p>数组indegree：用于存放各个顶点的入度</p>
<p>算法思路：</p>
<p>每次遍历数组indegree，查找入度为零的顶点，将其加入队列，再遍历邻接表，将遍历到的顶点的indegree值减一，并判断是否为零，若为零则加入队列</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 拓扑排序实现</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Graph::topologicalSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">indegree</span><span class="params">(V, <span class="number">0</span>)</span></span>; <span class="comment">// 入度数组</span></span><br><span class="line">    queue&lt;<span class="type">int</span>&gt; q;              <span class="comment">// 队列</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算所有顶点的入度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; V; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v : adj[i]) &#123;</span><br><span class="line">            indegree[v]++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将入度为0的顶点加入队列</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; V; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (indegree[i] == <span class="number">0</span>) &#123;</span><br><span class="line">            q.<span class="built_in">push</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> count = <span class="number">0</span>; <span class="comment">// 用于检测图是否存在环</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出拓扑排序</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;拓扑排序顺序为: &quot;</span>;</span><br><span class="line">    <span class="keyword">while</span> (!q.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="type">int</span> u = q.<span class="built_in">front</span>();</span><br><span class="line">        q.<span class="built_in">pop</span>();</span><br><span class="line">        cout &lt;&lt; u &lt;&lt; <span class="string">&quot; &quot;</span>; <span class="comment">// 输出顶点</span></span><br><span class="line">        count++;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 遍历该顶点的所有邻接点，并更新它们的入度</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v : adj[u]) &#123;</span><br><span class="line">            indegree[v]--;</span><br><span class="line">            <span class="keyword">if</span> (indegree[v] == <span class="number">0</span>) &#123;</span><br><span class="line">                q.<span class="built_in">push</span>(v);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果没有输出所有顶点，说明存在环</span></span><br><span class="line">    <span class="keyword">if</span> (count != V) &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;图中存在环，无法进行拓扑排序！&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/Real_Fool_/article/details/114141377">数据结构：图(Graph)【详解】_图数据结构-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1gT4y1v768/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">数据结构-图-prim（普里姆）算法最小生成树（过程分析+手写代码）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV19S4y1Y7MT?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">数据结构-图-最小生成树-克鲁斯卡尔（Kruskal)算法-手画+过程分析+代码_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——广义表</title>
    <url>/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="数据结构广义表">数据结构——广义表</h1>
<h2 id="广义表的定义和相关概念">广义表的定义和相关概念</h2>
<p>广义表是线性表的推广，其中的元素可以是原子（即不可再分的基本数据项），也可以是子表。广义表的一些常用术语包括：
- <strong>长度</strong>：广义表的长度是其顶层元素的个数。 -
<strong>深度</strong>：广义表中元素嵌套的最大深度。 -
<strong>表头</strong>：广义表中的第一个元素。 -
<strong>表尾</strong>：去掉表头后剩下的部分。</p>
<h3 id="例子">例子</h3>
<ul>
<li><strong>A = ()</strong></li>
<li><strong>B = (a, b, c)</strong>c)`</li>
<li><strong>C = (a, (b, c, d), e)</strong></li>
<li><strong>D = (a, b, (e, f, g))</strong></li>
<li><strong>E = ((a, b), c, (d, e, (f, g)))</strong></li>
<li><strong>F = ((), ((), ()))</strong></li>
</ul>
<p>下表展示了图片中的几个广义表的长度、深度、表头和表尾的具体值：</p>
<table>
<thead>
<tr class="header">
<th>广义表</th>
<th>长度</th>
<th>深度</th>
<th>表头</th>
<th>表尾</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>0</td>
<td>1</td>
<td>空</td>
<td>()</td>
</tr>
<tr class="even">
<td>B</td>
<td>3</td>
<td>1</td>
<td>a</td>
<td>(b, c)</td>
</tr>
<tr class="odd">
<td>C</td>
<td>3</td>
<td>2</td>
<td>a</td>
<td>((b, c, d), e)</td>
</tr>
<tr class="even">
<td>D</td>
<td>3</td>
<td>3</td>
<td>a</td>
<td>(b, (e, f, g))</td>
</tr>
<tr class="odd">
<td>E</td>
<td>4</td>
<td>3</td>
<td>(a, b)</td>
<td>(c, (d, e, (f, g)))</td>
</tr>
<tr class="even">
<td>F</td>
<td>3</td>
<td>3</td>
<td>()</td>
<td>((), ((), ()))</td>
</tr>
</tbody>
</table>
<h2 id="广义表的存储结构">广义表的存储结构</h2>
<figure>
<img src="/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/IMG_20241021_153619-1729496219467-9.jpg" alt="IMG_20241021_153619">
<figcaption aria-hidden="true">IMG_20241021_153619</figcaption>
</figure>
<p>由于广义表中的每个元素可能是原子或子表，因此在广义表的存储结构中存在两类结点：</p>
<ol type="1">
<li><strong>原子节点</strong>：用于存储单个元素。</li>
<li><strong>子表节点</strong>：用于存储子表的指针。</li>
</ol>
<p>为了区分元素是原子还是子表，结构中还设置了一个标识域
<code>type</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">GListNodeType</span> &#123; ATOM, LIST &#125;; <span class="comment">// 结点类型：原子或子表</span></span><br></pre></td></tr></table></figure>
<p>当type值为1，说明存入原子的值；为2，说明存入子广义表的头指针</p>
<p>广义表定义如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">char</span> ElemType; <span class="comment">// 原子的类型定义为字符类型</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">GListNode</span> &#123;</span><br><span class="line">    GListNodeType type; <span class="comment">// 类型域，表示该节点是原子还是子表</span></span><br><span class="line">    <span class="keyword">union</span> &#123;</span><br><span class="line">        ElemType data; <span class="comment">// 如果是原子节点，则存储数据</span></span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">GListNode</span> *sublist; <span class="comment">// 如果是子表节点，则存储指向子表的指针</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">GListNode</span> *next; <span class="comment">// 指向下一个表节点的指针</span></span><br><span class="line">&#125; GListNode, *GList; <span class="comment">// GList 表示广义表的指针类型</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/IMG_20241021_154058-1729496523052-14.jpg" alt="IMG_20241021_154058">
<figcaption aria-hidden="true">IMG_20241021_154058</figcaption>
</figure>
<h2 id="代码">代码</h2>
<h3 id="求广义表长度">求广义表长度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 求广义表的长度</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">LengthGList</span><span class="params">(GList list)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> length = <span class="number">0</span>;</span><br><span class="line">    GList current = list;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        length++;</span><br><span class="line">        current = current-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> length;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="求广义表深度">求广义表深度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 求广义表的深度</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">DepthGList</span><span class="params">(GList list)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (list == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;  <span class="comment">// 空表深度为 1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> maxDepth = <span class="number">1</span>;</span><br><span class="line">    GList current = list;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;type == LIST) &#123;</span><br><span class="line">            <span class="type">int</span> sublistDepth = <span class="built_in">DepthGList</span>(current-&gt;value.sublist) + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (sublistDepth &gt; maxDepth) &#123;</span><br><span class="line">                maxDepth = sublistDepth;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        current = current-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> maxDepth;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="打印">打印</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 打印广义表</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintGList</span><span class="params">(GList list)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (list == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;()&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;(&quot;</span>);</span><br><span class="line">    GList current = list;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;type == ATOM) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, current-&gt;value.data);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (current-&gt;type == LIST) &#123;</span><br><span class="line">            <span class="built_in">PrintGList</span>(current-&gt;value.sublist);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;next != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;, &quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        current = current-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;)&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="线性表章节小结">线性表章节小结</h1>
<figure>
<img src="/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/IMG_20241021_155320.jpg" alt="IMG_20241021_155320">
<figcaption aria-hidden="true">IMG_20241021_155320</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>python web——fastapi</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>FastAPI 是一个用于构建 API 的现代、快速（高性能）的 web 框架，使用
Python 并基于标准的 Python 类型提示。</p>
<p>关键特性:</p>
<ul>
<li><strong>快速</strong>：可与 <strong>NodeJS</strong> 和
<strong>Go</strong> 并肩的极高性能（归功于 Starlette 和 Pydantic）。<a href="https://fastapi.tiangolo.com/zh/#_11">最快的 Python web
框架之一</a>。</li>
<li><strong>高效编码</strong>：提高功能开发速度约 200％ 至 300％。*</li>
<li><strong>更少 bug</strong>：减少约 40％
的人为（开发者）导致错误。*</li>
<li><strong>智能</strong>：极佳的编辑器支持。处处皆可自动补全，减少调试时间。</li>
<li><strong>简单</strong>：设计的易于使用和学习，阅读文档的时间更短。</li>
<li><strong>简短</strong>：使代码重复最小化。通过不同的参数声明实现丰富功能。bug
更少。</li>
<li><strong>健壮</strong>：生产可用级别的代码。还有自动生成的交互式文档。</li>
<li><strong>标准化</strong>：基于（并完全兼容）API 的相关开放标准：<a href="https://github.com/OAI/OpenAPI-Specification">OpenAPI</a>
(以前被称为 Swagger) 和 <a href="https://json-schema.org/">JSON
Schema</a>。</li>
</ul>
<h3 id="两个核心组件starlette-和-pydantic">两个核心组件：Starlette 和
Pydantic</h3>
<p>Starlette 负责web部分</p>
<p>Starlette 是 FastAPI 的底层 ASGI（异步服务器网关接口）框架，为
FastAPI 提供了异步编程能力和高性能的网络通信支持。</p>
<p>ASGI（<strong>Asynchronous Server Gateway Interface</strong>
）是一种用于连接 Python Web
服务器和应用程序框架的<strong>异步接口标准</strong> ，旨在支持现代 Web
协议（如 WebSocket、HTTP/2）和异步编程模型</p>
<p>Pydantic负责</p>
<p>Pydantic 负责 FastAPI 的数据验证、序列化和自动文档生成</p>
<h3 id="http协议">http协议</h3>
<h4 id="一简介">一、简介</h4>
<p><strong>HTTP协议</strong> 是Hyper Text Transfer
Protocol（超文本传输协议）的缩写，是用于万维网（WWW: World Wide
Web）服务器与本地浏览器之间传输超文本的传送协议。HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<h4 id="二http协议特性">二、http协议特性</h4>
<p>（1）基于 TCP/IP 协议</p>
<p>http 协议是基于 <strong>TCP/IP 协议</strong>之上的应用层协议。</p>
<p>（2）基于请求 - 响应模式</p>
<p>HTTP
协议规定，请求从客户端发出，最后服务器端响应应该请求并返回。换句话说，肯定是先<strong>从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应</strong>。</p>
<p>（3）无状态保存</p>
<p>HTTP 是一种不保存状态，即无状态（stateless）协议。HTTP
协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP
这个级别，协议对于发送过的请求或响应都不做持久化处理。</p>
<p>使用 HTTP
协议，每当有新的请求发送时，就会有对应的新响应产生。协议本身并<strong>不保留之前一切的请求或响应报文的信息</strong>。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把
HTTP 协议设计成如此简单的。</p>
<p>（4）短连接</p>
<p>HTTP 1.0 默认使用的是短连接。浏览器和服务器每进行一次 HTTP
操作，就建立一次连接，任务结束就中断连接。</p>
<p>HTTP 1.1 起，默认使用长连接。要使用长连接，客户端和服务器的 HTTP
首部的 Connection 都要设置为 keep - alive，才能支持长连接。</p>
<p>HTTP 长连接，指的是复用 TCP 连接。多个 HTTP 请求可以复用同一个 TCP
连接，这就节省了 TCP 连接建立和断开的消耗。</p>
<h4 id="三http请求协议与响应协议">三、http请求协议与响应协议</h4>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<blockquote>
<p>Socket（套接字）是计算机网络中用于实现进程间双向通信的端点抽象，它为应用层进程通过网络协议交换数据提供了统一的接口。具体来说，Socket
是应用层与 TCP/IP
协议族通信的中间软件抽象层，本质上是一组封装了复杂网络协议的接口，简化了开发者对底层通信细节的操作。</p>
<p>从功能上看，Socket
可以看作是网络通信的“电话插座”：两个设备（如客户端与服务器）通过 Socket
建立连接后，即可像电话通话一样进行数据交换，而端口号则类似于插座上的插孔，用于标识具体的通信进程，且不能被其他进程占用。此外，Socket
包含网络通信必需的五种核心信息，例如使用的协议（TCP/UDP）、本地与远程地址、端口等，构成了网络通信的基本操作单元。</p>
<p>总结而言，Socket
既是通信端点的逻辑概念，也是实现网络应用层交互的关键工具，其设计目标是屏蔽底层协议的复杂性，提供统一的编程接口。</p>
</blockquote>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/3.png" alt="3">
<figcaption aria-hidden="true">3</figcaption>
</figure>
<blockquote>
<p>GET ：请求参数通过 URL 的查询字符串（Query
String）传递，数据暴露在地址栏中，例如：https://example.com
?name=value</p>
<p>POST
：请求参数存储在请求体（Body）中传输，相对更安全，且支持传输非字符串数据（如文件、二进制等）</p>
</blockquote>
<blockquote>
<p>一个完整的URL包括：协议、ip、端口、路径、参数</p>
<p>例如：https://www.baidu.com/s?wd=yuan 其中https是协议，www.baidu.com
是IP，端口默认80，/s是路径，参数是wd=yuan</p>
<p>请求方式：get与post请求</p>
<ul>
<li>GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如EditBook?name=test1&amp;id=123456。POST方法是把提交的数据放在HTTP包的请求体中。</li>
<li>GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制</li>
</ul>
<p>响应状态码：状态码的职责是当客户端向服务器端发送请求时，返回的请求结果。借助状态码，用户可以知道服务器端是正常处理了请求，还是出现了问题。状态码如200
OK，以3位数字和原因组成。</p>
</blockquote>
<p>测试http协议格式：请求与响应</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#web应用程序：遵循http协议</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line">sock=socket.socket()</span><br><span class="line">sock.bind((<span class="string">&quot;127.0.0.1&quot;</span>,<span class="number">8080</span>))</span><br><span class="line">sock.listen(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    conn 表示新建立的套接字对象，用于在服务器和客户端之间进行数据传输。</span></span><br><span class="line"><span class="string">    addr 是一个元组，它包含了连接进来的客户端的 IP 地址和端口号。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    conn, addr = sock.accept()<span class="comment">#阻塞等待客户端连接</span></span><br><span class="line">    data=conn.recv(<span class="number">1024</span>)<span class="comment">#请求报文</span></span><br><span class="line">    <span class="comment"># data 是一个字节串，包含了客户端发送的请求信息。</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端发送的请求信息：\n&quot;</span>,data)</span><br><span class="line">    conn.send(<span class="string">b&quot;HTTP/1.1 200 ok\r\nserver:zxj\r\n\r\nhello world&quot;</span>)<span class="comment">#响应首行+响应头+响应体</span></span><br><span class="line">    conn.close()</span><br></pre></td></tr></table></figure>
<p>测试post请求：urlencoded格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 socket 连接</span></span><br><span class="line">client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">client.connect((<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">8080</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造 POST 请求报文</span></span><br><span class="line">path = <span class="string">&quot;/&quot;</span>  <span class="comment"># 目标路径</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;Host&quot;</span>: <span class="string">&quot;127.0.0.1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>,  <span class="comment"># 数据格式</span></span><br><span class="line">    <span class="string">&quot;Content-Length&quot;</span>: <span class="built_in">len</span>(<span class="string">&quot;username=admin&amp;password=123456&quot;</span>)  <span class="comment"># 数据长度</span></span><br><span class="line">&#125;</span><br><span class="line">body = <span class="string">&quot;username=admin&amp;password=123456&quot;</span>  <span class="comment"># 请求体（表单数据）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拼接请求报文</span></span><br><span class="line">request = <span class="string">f&quot;POST <span class="subst">&#123;path&#125;</span> HTTP/1.1\r\n&quot;</span></span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> headers.items():</span><br><span class="line">    request += <span class="string">f&quot;<span class="subst">&#123;k&#125;</span>: <span class="subst">&#123;v&#125;</span>\r\n&quot;</span></span><br><span class="line">request += <span class="string">&quot;\r\n&quot;</span>  <span class="comment"># 空行分隔头部与主体</span></span><br><span class="line">request += body</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送请求</span></span><br><span class="line">client.send(request.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接收响应</span></span><br><span class="line">response = client.recv(<span class="number">4096</span>)</span><br><span class="line"><span class="built_in">print</span>(response.decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">client.close()</span><br></pre></td></tr></table></figure>
<p>测试post请求：json格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义请求地址</span></span><br><span class="line">url = <span class="string">&quot;http://127.0.0.1:8080&quot;</span></span><br><span class="line"><span class="comment"># 定义 JSON 数据（字典格式）</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;username&quot;</span>: <span class="string">&quot;admin&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送 POST 请求</span></span><br><span class="line">response = requests.post(</span><br><span class="line">    url, </span><br><span class="line">    json=data  <span class="comment"># 使用 json 参数自动序列化字典并设置 Content-Type: application/json</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出响应结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;状态码:&quot;</span>, response.status_code)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;响应内容:&quot;</span>, response.text)  <span class="comment"># 使用 text 获取原始响应文本</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">客户端发送的请求信息：</span></span><br><span class="line"><span class="string"> b&#x27;POST / HTTP/1.1\r\nHost: 127.0.0.1:8080\r\nUser-Agent: python-requests/2.32.2\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 43\r\nContent-Type: application/json\r\n\r\n&#123;&quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;123456&quot;&#125;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>通过 <code>json=data</code> 参数，<code>requests</code>
会自动将字典转换为 JSON 字符串，并设置请求头
<code>Content-Type: application/json</code>，无需手动调用
<code>json.dumps()</code> 或配置 headers</p>
</blockquote>
<blockquote>
<p>SSL 验证是指通过 SSL
证书验证网站身份并确保通信安全的过程。其核心目标是确认服务器的真实性、防止身份伪造，并建立加密连接以保护数据传输的安全性</p>
<p>HTTPS（HyperText Transfer Protocol Secure）是以安全为目标的 HTTP
通道，通过在 HTTP
基础上加入加密和身份认证机制，确保数据传输的隐私性、完整性和服务器身份的真实性</p>
<p>https=http+ssl</p>
</blockquote>
<blockquote>
<p>通过 <code>Content-Type</code>，服务器可识别请求体（Body）的格式（如
JSON、表单数据），客户端可解析响应数据的类型（如 HTML、图片）</p>
<p>例如：conn.send(b”HTTP/1.1 200 ok:zxj*content-type:text/html**hello
world&lt;&gt;“)</p>
<p>再例如：’HTTP/1.1 200 ok:zxj*content-type:application/json**’</p>
</blockquote>
<h5 id="api接口">api接口</h5>
<p>在开发web应用中，有两种应用模式：</p>
<p>1.前后端不分离：客户端看到的内容和所有页面效果都是有服务端提供出来的</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/4.png" alt="4">
<figcaption aria-hidden="true">4</figcaption>
</figure>
<p>2.前后端分离：把前端的页面效果（html，css，js分离到另一个服务端，python服务端只需要返回数据即可）</p>
<p>前端形成一个独立的网站，服务端构成一个独立的网站</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<p><strong>应用程序编程接口（Application Programming
Interface，API接口）</strong>，就是应用程序对外提供了一个操作数据的入口，这个入口可以是一个函数或类方法，也可以是一个url地址或者一个网络地址。当客户端调用这个入口，应用程序则会执行对应代码操作，给客户端完成相对应的功能。</p>
<p>当然，api接口在工作中是比较常见的开发内容，有时候，我们会调用其他人编写的api接口，有时候，我们也需要提供api接口给其他人操作。由此就会带来一个问题，api接口往往都是一个函数、类方法、或者url或其他网络地址，不断是哪一种，当api接口编写过程中，我们都要考虑一个问题就是这个接口应该怎么编写？接口怎么写的更加容易维护和清晰，这就需要大家在调用或者编写api接口的时候要有一个明确的编写规范！！！</p>
<p>为了在团队内部形成共识，防止个人习惯差异引起的混乱，我们都需要找到一种大家都觉得很好的接口实现规范，而且这种规范能够让后端写的接口，用途一目了然，减少客户端和服务端双方之间的合作成本。</p>
<p>目前市面上大部分公司开发人员使用的接口实现规范主要有：restful、RPC。</p>
<p>REST全称是Representational State
Transfer，中文意思是表述（编者注：通常译为表征）性状态转移。它首次出现在2000年Roy
Fielding的博士论文中。</p>
<p>RESTful是一种专门为Web开发而定义API接口的设计风格，尤其适用于前后端分离的应用模式中。</p>
<p><strong>关键：面向资源开发</strong></p>
<p>这种风格的理念认为后端开发任务就是提供数据的，对外提供的是数据资源的访问接口，所以在定义接口时，客户端访问的URL路径就表示这种要操作的数据资源。</p>
<p>而<strong>对于数据资源分别使用POST、DELETE、GET、UPDATE等请求动作来表达对数据的增删查改</strong>。</p>
<table>
<thead>
<tr class="header">
<th>请求方法</th>
<th>请求地址</th>
<th>后端操作</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>POST</td>
<td>/student/</td>
<td>增加学生</td>
</tr>
<tr class="even">
<td>GET</td>
<td>/student/</td>
<td>获取所有学生</td>
</tr>
<tr class="odd">
<td>GET</td>
<td>/student/1</td>
<td>获取id为1的学生</td>
</tr>
<tr class="even">
<td>PUT</td>
<td>/student/1</td>
<td>修改id为1的学生</td>
</tr>
<tr class="odd">
<td>DELETE</td>
<td>/student/1</td>
<td>删除id为1的学生</td>
</tr>
</tbody>
</table>
<p>restful规范是一种通用的规范，不限制语言和开发框架的使用。事实上，我们可以使用任何一门语言，任何一个框架都可以实现符合restful规范的API接口。</p>
<h3 id="fastapi快速开始">fastapi快速开始</h3>
<h4 id="简单案例">简单案例</h4>
<p>安装：<code>pip install fastapi</code></p>
<p>还需要一个ASGI服务器，生产环境使用Uvicorn：<code>pip install uvicorn</code></p>
<blockquote>
<p>ASGI（<strong>Asynchronous Server Gateway Interface</strong>
）是一种<strong>异步服务器网关接口</strong> ，为 Python Web
应用提供了标准接口，使其能够处理现代网络协议（如 WebSocket、HTTP/2
等）的异步请求。与传统的 WSGI 不同，ASGI
支持异步编程模型，允许单个请求处理多个事件（如长连接、双向通信），从而提升高并发场景下的性能</p>
<p>Uvicorn 是一个基于 ASGI 的高性能异步 Web 服务器，专为 Python
异步框架设计。</p>
</blockquote>
<blockquote>
<p>web应用程序=web框架+自己写的业务逻辑代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI<span class="comment">#fastapi类</span></span><br><span class="line"></span><br><span class="line">app= FastAPI()<span class="comment">#创建一个fastapi实例</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">home</span>():</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_id&quot;</span>:<span class="number">1001</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/shop&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">shop</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;shop_id&quot;</span>:<span class="number">1002</span>&#125;</span><br></pre></td></tr></table></figure>
<p>启动：<code>uvicorn "04 fastapi_begin:app" --reload</code></p>
<p>也可以：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(app=<span class="string">&quot;04 fastapi_begin:app&quot;</span>,port=<span class="number">8080</span>,reload=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>接口文档</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/6.png" alt="6">
<figcaption aria-hidden="true">6</figcaption>
</figure>
<blockquote>
<p>修饰器（Decorator）是 Python
中一种动态修改函数或类行为的高级功能，本质上是一个函数或类，它<strong>接受目标函数或类作为参数，并返回包装后的新函数或类对象</strong>，从而在<strong>不修改原始代码</strong>
的前提下为对象添加额外功能</p>
</blockquote>
<h3 id="路径操作">路径操作</h3>
<h4 id="路径操作修饰器">路径操作修饰器</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.get()</span></span><br><span class="line"><span class="meta">@app.post()</span></span><br><span class="line"><span class="meta">@app.put()</span></span><br><span class="line"><span class="meta">@app.patch()</span></span><br><span class="line"><span class="meta">@app.delete()</span></span><br><span class="line"><span class="meta">@app.options()</span></span><br><span class="line"><span class="meta">@app.head()</span></span><br><span class="line"><span class="meta">@app.trace()</span></span><br></pre></td></tr></table></figure>
<p>路径操作修饰器参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tags为接口添加标签，用于在自动生成的文档</span></span><br><span class="line"><span class="string">summary为接口添加描述</span></span><br><span class="line"><span class="string">description为接口添加详细描述</span></span><br><span class="line"><span class="string">response_description为接口返回值描述</span></span><br><span class="line"><span class="string">deprecated为过时的接口</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/post&quot;</span>, </span></span></span><br><span class="line"><span class="params"><span class="meta">        tags=[<span class="string">&quot;这是post方法&quot;</span>],</span></span></span><br><span class="line"><span class="params"><span class="meta">        summary=<span class="string">&quot;这是post方法的描述&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">        description=<span class="string">&quot;这是post方法的详细描述&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">        response_description=<span class="string">&quot;这是post方法的返回值描述&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">        deprecated=<span class="literal">True</span>, <span class="comment"># 过时的接口</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        </span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br></pre></td></tr></table></figure>
<h4 id="include_router">include_router</h4>
<p>文件路径如下</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/7.png" alt="7">
<figcaption aria-hidden="true">7</figcaption>
</figure>
<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> apps.app01.shop <span class="keyword">import</span> shop</span><br><span class="line"><span class="keyword">from</span> apps.app02.user <span class="keyword">import</span> user</span><br><span class="line"></span><br><span class="line">app= FastAPI()</span><br><span class="line"></span><br><span class="line">app.include_router(shop,</span><br><span class="line">                 prefix=<span class="string">&quot;/shop&quot;</span>, <span class="comment"># 路由前缀</span></span><br><span class="line">                 tags=[<span class="string">&quot;购物中心接口&quot;</span>], <span class="comment"># 标签</span></span><br><span class="line">                 responses=&#123;<span class="number">200</span>: &#123;<span class="string">&quot;description&quot;</span>: <span class="string">&quot;成功&quot;</span>&#125;&#125; <span class="comment"># 响应描述</span></span><br><span class="line">                 )</span><br><span class="line">app.include_router(user,</span><br><span class="line">                 prefix=<span class="string">&quot;/user&quot;</span>, <span class="comment"># 路由前缀</span></span><br><span class="line">                 tags=[<span class="string">&quot;用户接口&quot;</span>], <span class="comment"># 标签</span></span><br><span class="line">                 responses=&#123;<span class="number">200</span>: &#123;<span class="string">&quot;description&quot;</span>: <span class="string">&quot;成功&quot;</span>&#125;&#125; <span class="comment"># 响应描述</span></span><br><span class="line">                 )</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(<span class="string">&quot;main:app&quot;</span>, port=<span class="number">8080</span>,  reload=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>shop.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"></span><br><span class="line">shop=APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="meta">@shop.get(<span class="params"><span class="string">&quot;/food&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shop_food</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;food&quot;</span>:<span class="string">&quot;shop food&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@shop.get(<span class="params"><span class="string">&quot;/drink&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shop_drink</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;drink&quot;</span>:<span class="string">&quot;shop drink&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>user.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"></span><br><span class="line">user=APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="meta">@user.post(<span class="params"><span class="string">&quot;/login&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">user_login</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user&quot;</span>:<span class="string">&quot;user login&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@user.post(<span class="params"><span class="string">&quot;/register&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">user_register</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user&quot;</span>:<span class="string">&quot;user register&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>include_router</code> 是 FastAPI
框架中用于整合路由的核心方法，其作用是将通过 <code>APIRouter</code>
定义的路由模块添加到主应用程序实例中，使这些路由在应用中生效。</p>
</blockquote>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/8.png" alt="8">
<figcaption aria-hidden="true">8</figcaption>
</figure>
<h3 id="请求与响应">请求与响应</h3>
<h4 id="路径参数">4.1 路径参数</h4>
<h5 id="基本用法">（1）基本用法</h5>
<p>以使用与 Python 格式化字符串相同的语法来声明路径”参数”或”变量”：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/user/&#123;user_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user</span>(<span class="params">user_id</span>):</span><br><span class="line">    <span class="built_in">print</span>(user_id, <span class="built_in">type</span>(user_id))</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_id&quot;</span>: user_id&#125;</span><br></pre></td></tr></table></figure>
<p>路径参数 <code>user_id</code> 的值将作为参数 <code>user_id</code>
传递给你的函数。</p>
<h5 id="有类型的路径参数">（2）有类型的路径参数</h5>
<p>你可以使用标准的 Python 类型标注为函数中的路径参数声明类型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/user/&#123;user_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user</span>(<span class="params">user_id: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(user_id, <span class="built_in">type</span>(user_id))</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_id&quot;</span>: user_id&#125;</span><br></pre></td></tr></table></figure>
<p>在这个例子中，<code>user_id</code> 被声明为 int 类型。</p>
<blockquote>
<p>这将为你的函数提供编辑器支持，包括错误检查、代码补全等等。</p>
</blockquote>
<h5 id="注意顺序">（3）注意顺序</h5>
<p>在创建路径操作时，你会发现有些情况下路径是固定的。</p>
<p>比如
<code>/users/me</code>，我们假设它用来获取关于当前用户的数据。</p>
<p>然后，你还可以使用路径 <code>/user/&#123;username&#125;</code>
来通过用户名获取关于特定用户的数据。</p>
<p>由于路径操作是<strong>按顺序依次运行</strong>的，你需要确保路径
/<code>user/me</code> 声明在路径 <code>/user/&#123;username&#125;</code>
之前。</p>
<p>如下</p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250516193934740.png" alt="image-20250516193934740">
<figcaption aria-hidden="true">image-20250516193934740</figcaption>
</figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250516201128482.png" alt="image-20250516201128482">
<figcaption aria-hidden="true">image-20250516201128482</figcaption>
</figure>
<blockquote>
<p>路由（Routing）是指在网络中<strong>选择数据传输路径</strong>的过程，其核心目标是将数据从源点高效、可靠地传输到目的地</p>
</blockquote>
<blockquote>
<p>cURL 是一个开源的命令行工具和跨平台的库（libcurl），用于基于 URL
语法在网络协议下进行数据传输。它支持多种协议（如 HTTP、HTTPS、FTP、SMTP
等），能够实现文件上传、下载以及与 Web 服务器的交互，常被开发者用于 API
测试、数据传输等场景</p>
</blockquote>
<h4 id="查询参数请求参数">4.2 查询参数（请求参数）</h4>
<p>路径函数中声明<strong>不属于路径参数的其他函数参数</strong>时，它们将被<strong>自动解释为查询字符串参数</strong>，就是
<code>url？</code>之后用 <code>&amp;</code> 分割的
<code>key-value 键值对</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app02.get(<span class="params"><span class="string">&quot;/jobs&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_jobs</span>(<span class="params">kind1: <span class="built_in">str</span>, kind2: <span class="built_in">str</span>, kind3: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="comment">#基于查询参数的值来执行不同的操作</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;kind1&quot;</span>: kind1,</span><br><span class="line">        <span class="string">&quot;kind2&quot;</span>: kind2,</span><br><span class="line">        <span class="string">&quot;kind3&quot;</span>: kind3</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250516201707589.png" alt="image-20250516201707589">
<figcaption aria-hidden="true">image-20250516201707589</figcaption>
</figure>
<p>增加路径参数：kind1为路径参数</p>
<p>增加默认参数值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app02.get(<span class="params"><span class="string">&quot;/jobs/&#123;kind1&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_jobs</span>(<span class="params">kind1: <span class="built_in">str</span>, kind2: <span class="built_in">str</span>=<span class="string">&quot;None&quot;</span>, kind3: <span class="built_in">str</span>=<span class="string">&quot;None&quot;</span></span>):<span class="comment">#增加默认值，可选填</span></span><br><span class="line">    <span class="comment">#基于查询参数的值来执行不同的操作</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;kind1&quot;</span>: kind1,</span><br><span class="line">        <span class="string">&quot;kind2&quot;</span>: kind2,</span><br><span class="line">        <span class="string">&quot;kind3&quot;</span>: kind3</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>Request URL：</p>
<p><code>http://127.0.0.1:8080/app02/jobs/11?kind2=22&amp;kind3=33</code></p>
<p>自python3.5开始，PEP484为python引入了类型注解(type
hints)，typing的主要作用有：</p>
<blockquote>
<p>1.类型检查，防止运行时出现参数、返回值类型不符。</p>
<p>2.作为开发文档附加说明，方便使用者调用时传入和返回参数类型。</p>
<p>3.模块加入不会影响程序的运行不会报正式的错误，pycharm支持typing检查错误时会出现黄色警告。</p>
</blockquote>
<p><code>type hints</code>主要是要指示函数的输入和输出的数据类型，数据类型在typing包中，基本类型有<code>str list dict</code>等等，</p>
<blockquote>
<p>Type Hints 是 Python 3.5
引入的功能，通过类型注解增强代码的可读性和可维护性。它允许开发者为变量、函数参数、返回值等指定预期的数据类型，从而帮助静态类型检查工具（如
<code>mypy</code>）捕获潜在错误，并提升 IDE 的智能提示能力。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">greet</span>(<span class="params">name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;Hello, <span class="subst">&#123;name&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>
<p>此处 <code>name: str</code>
表示参数需为字符串类型，<code>-&gt; str</code> 表示返回值类型为字符串
。</p>
</blockquote>
<p><code>Union</code>是当有多种可能的数据类型时使用，比如函数有可能根据不同情况有时返回str或返回list，那么就可以写成<code>Union[list, str]</code></p>
<blockquote>
<p>从 Python 3.10 起，<code>Union[X, Y]</code> 可简写为
<code>X | Y</code>。例如 <code>int | str</code> 等价于
<code>Union[int, str]</code> 。</p>
<p>再例如：<code>kind2:str|None=None</code></p>
</blockquote>
<p><code>Optional</code>是Union的一个简化，当数据类型中有可能是None时，比如有可能是str也有可能是None，则Optional[str]，相当于Union[str,
None]</p>
<h4 id="请求体数据">4.3 请求体数据</h4>
<p>当你需要将数据从客户端（例如浏览器）发送给 API
时，你将其作为「请求体」发送。请求体是客户端发送给 API 的数据。响应体是
API 发送给客户端的数据。</p>
<p>FastAPI 基于 <code>Pydantic</code> ，<code>Pydantic</code>
主要用来做类型强制检查（校验数据）。不符合类型要求就会抛出异常。</p>
<p>对于 API
服务，支持类型检查非常有用，会让服务更加健壮，也会加快开发速度，因为开发者再也不用自己写一行一行的做类型检查。</p>
<p>安装上手 <code>pip install pydantic</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel,Field,field_validator</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> date</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span>,<span class="type">Optional</span></span><br><span class="line"></span><br><span class="line">app03 = APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Address</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    province: <span class="built_in">str</span></span><br><span class="line">    city: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="comment">#正则表达式</span></span><br><span class="line">    <span class="comment">#username:str=Field(pattern=&quot;^[a-zA-Z0-9]&#123;3,10&#125;$&quot;,title=&quot;用户名&quot;,description=&quot;用户名长度在3-10之间，且只能包含字母和数字&quot;)</span></span><br><span class="line">    <span class="comment">#name: str|None = None</span></span><br><span class="line">    name:<span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span>=Field(default=<span class="number">0</span>,gt=<span class="number">0</span>,lt=<span class="number">100</span>)</span><br><span class="line">    birth:<span class="type">Union</span>[date,<span class="literal">None</span>] = <span class="literal">None</span></span><br><span class="line">    friends:<span class="built_in">list</span>[<span class="built_in">int</span>]=[]</span><br><span class="line">    description:<span class="type">Optional</span>[<span class="built_in">str</span>]=<span class="literal">None</span></span><br><span class="line">    <span class="comment">#嵌套</span></span><br><span class="line">    addr:Address|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    field_validator 的第一个参数必须是 cls，因为它是类方法 （classmethod），用于在验证字段时访问模型类的上下文。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">    @field_validator(<span class="params"><span class="string">&quot;name&quot;</span></span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name_must_alpha</span>(<span class="params">cls,value</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        value.isalpha() 会检查字符串是否只由字母组成，如果是则返回 True，否则返回 False。</span></span><br><span class="line"><span class="string">        如果返回 False，assert 触发，会抛出 AssertionError，并显示错误信息 &quot;name must be alpha&quot;。</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span> value.isalpha(), <span class="string">&quot;name must be alpha&quot;</span></span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="comment">#嵌套</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Data</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    data:<span class="built_in">list</span>[User]</span><br><span class="line"></span><br><span class="line"><span class="meta">@app03.post(<span class="params"><span class="string">&quot;/user&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">user</span>(<span class="params">user:User</span>):</span><br><span class="line">    <span class="built_in">print</span>(user,<span class="built_in">type</span>(user))</span><br><span class="line">    <span class="keyword">return</span> user</span><br><span class="line"></span><br><span class="line"><span class="meta">@app03.post(<span class="params"><span class="string">&quot;/data&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">data</span>(<span class="params">data:Data</span>):</span><br><span class="line">    <span class="built_in">print</span>(data,<span class="built_in">type</span>(data))</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>BaseModel</code>专门用于数据验证、数据转换和序列化。在定义数据结构时继承自
BaseModel，可以：</p>
<ul>
<li><strong>自动校验数据类型</strong>：根据类中字段的类型注解，自动校验输入数据是否符合预期类型。</li>
<li><strong>数据转换</strong>：可以自动将输入数据（例如 JSON
字符串）转换成相应的 Python 数据类型。</li>
<li><strong>序列化输出</strong>：支持将模型实例转换成
JSON、字典等格式，便于响应输出。</li>
</ul>
</blockquote>
<blockquote>
<p>在 Pydantic 中，<code>Field</code>
用于为模型字段提供额外的信息，比如设置默认值、描述信息、约束条件（例如长度、范围等）或别名。这可以帮助自动生成
OpenAPI 文档、增强验证或对字段进行更细粒度的控制。</p>
</blockquote>
<blockquote>
<p><code>field_validator</code> 是 Pydantic v2 中用于替代旧版
<code>@validator</code>
的新装饰器，专门用于为模型字段添加自定义验证逻辑。它通过更清晰的命名和更灵活的模式（如
<code>mode="before"</code> 或
<code>mode="after"</code>）提升代码可读性和验证逻辑的控制能力</p>
<p><code>field_validator</code>和<code>model_validator</code>区别</p>
<p><strong><code>field_validator</code></strong>专门针对<strong>单个字段</strong>
进行验证，适用于需要校验特定字段的规则（如长度、格式、类型约束）。例如验证用户名长度</p>
<p><strong><code>model_validator</code></strong>作用于<strong>整个模型实例</strong>
，适用于需要跨字段验证或全局逻辑的场景。例如检查两次密码是否一致</p>
</blockquote>
<h4 id="form表单数据">4.4 form表单数据</h4>
<p>在 <code>OAuth2</code>
规范的一种使用方式（密码流）中，需要将用户名、密码作为表单字段发送，而不是
JSON。</p>
<p>FastAPI 可以使用 <strong>Form 组件</strong>来接收表单数据，需要先使用
<code>pip install python-multipart</code> 命令进行安装。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app04.post(<span class="params"><span class="string">&quot;/register&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">data</span>(<span class="params">username:<span class="built_in">str</span>=Form(<span class="params"></span>),password:<span class="built_in">str</span>=Form(<span class="params"></span>)</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;username: <span class="subst">&#123;username&#125;</span>, password: <span class="subst">&#123;password&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;username&quot;</span>: username,</span><br><span class="line">        <span class="string">&quot;password&quot;</span>: password</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>发送post请求：form表单数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 目标 URL</span></span><br><span class="line">url = <span class="string">&quot;http://127.0.0.1:8080/app04/register&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 表单数据（键值对）</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;username&quot;</span>: <span class="string">&quot;test_user&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;secure_password_123&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送 POST 请求</span></span><br><span class="line">response = requests.post(</span><br><span class="line">    url, </span><br><span class="line">    data=data</span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>通过 requests.post() 的 data
参数传递表单数据，该参数接受字典或字符串格式的数据。requests
会自动将其编码为 application/x-www-form-urlencoded 格式</p>
</blockquote>
<h4 id="文件上传">4.5 文件上传</h4>
<p>导入必要库</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> File,UploadFile</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">app05 = APIRouter()</span><br></pre></td></tr></table></figure>
<p>通过字节上传</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app05.post(<span class="params"><span class="string">&quot;/file&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">file</span>(<span class="params">file: <span class="built_in">bytes</span> = File(<span class="params">...</span>)</span>):</span><br><span class="line">    <span class="comment">#适合小文件上传</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;filename&quot;</span>: <span class="string">&quot;file&quot;</span>,</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: <span class="built_in">len</span>(file)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>多文件上传</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app05.post(<span class="params"><span class="string">&quot;/files&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">files</span>(<span class="params">files: <span class="built_in">list</span>[<span class="built_in">bytes</span>] = File(<span class="params">...</span>)</span>):</span><br><span class="line">    <span class="comment">#多文件上传</span></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">len</span>(file))</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;filename&quot;</span>: <span class="string">&quot;files&quot;</span>,</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: <span class="built_in">len</span>(files)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>UploadFile上传，绝对路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app05.post(<span class="params"><span class="string">&quot;/uploadfile&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">upload_file</span>(<span class="params">file: UploadFile= File(<span class="params">...</span>)</span>):</span><br><span class="line">    <span class="comment">#适合大文件上传</span></span><br><span class="line">    <span class="comment"># 获取当前文件的绝对路径</span></span><br><span class="line">    base_dir = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line">    <span class="built_in">print</span>(base_dir)</span><br><span class="line">    img_dir = os.path.join(base_dir, <span class="string">&quot;../imgs&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(img_dir)</span><br><span class="line">    <span class="comment"># 创建目录</span></span><br><span class="line">    path = os.path.join(img_dir, file.filename)</span><br><span class="line">    <span class="comment">#path=os.path.join(&quot;../imgs&quot;,file.filename)</span></span><br><span class="line">    <span class="built_in">print</span>(path)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;文件名:&quot;</span>, file.filename)</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> file.file:</span><br><span class="line">            f.write(chunk)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;filename&quot;</span>: file.filename</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>UploadFile是 FastAPI
提供的一个类，用于处理文件上传。与直接将文件内容读取为字节流（例如
bytes相比，UploadFile有以下优点：</p>
<ul>
<li><strong>内存优化</strong>：它采用了文件对象的方式处理上传文件，不必将整个文件内容一次性加载到内存中，适合处理大文件。</li>
<li><strong>异步支持</strong>：支持异步操作，可以用异步方式读取文件内容，提高性能。</li>
<li><strong>文件元数据</strong>：提供文件名、内容类型等元数据信息，通过属性
<code>filename</code>、<code>content_type</code> 获取。</li>
<li><strong>文件接口</strong>：通过 file
属性获取一个类文件对象，可以像操作普通文件一样读取或保存上传的文件。</li>
</ul>
</blockquote>
<h4 id="request对象">4.6 Request对象</h4>
<p>有些情况下我们希望能直接访问 Request
对象。例如我们在路径操作函数中想获取客户端的 IP 地址，需要在函数中声明
Request 类型的参数，FastAPI 就会自动传递 Request
对象给这个参数，我们就可以获取到 Request 对象及其属性信息，例如
header、url、cookie、session 等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app06.post(<span class="params"><span class="string">&quot;/items&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">items</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;url:&quot;</span>, request.url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端ip:&quot;</span>, request.client.host)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求头:&quot;</span>, request.headers)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端宿主&quot;</span>,request.headers.get(<span class="string">&quot;user-agent&quot;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;cookie:&quot;</span>, request.cookies)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;url&quot;</span>: request.url,</span><br><span class="line">        <span class="string">&quot;client_ip&quot;</span>: request.client.host,</span><br><span class="line">        <span class="string">&quot;headers&quot;</span>: request.headers,</span><br><span class="line">        <span class="string">&quot;user_agent&quot;</span>: request.headers.get(<span class="string">&quot;user-agent&quot;</span>),</span><br><span class="line">        <span class="string">&quot;cookies&quot;</span>: request.cookies</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="请求静态文件">4.7请求静态文件</h4>
<p>在 Web 开发中，需要请求很多静态资源文件（不是由服务器生成的文件），如
css/js 和图片文件等。</p>
<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi.staticfiles <span class="keyword">import</span> StaticFiles</span><br><span class="line">app.mount(<span class="string">&quot;/static&quot;</span>, StaticFiles(directory=<span class="string">&quot;statics&quot;</span>))<span class="comment">#静态文件目录</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="./../../../../images/fastapi/image-20250517143857442.png" alt="image-20250517143857442">
<figcaption aria-hidden="true">image-20250517143857442</figcaption>
</figure>
<figure>
<img src="./../../../../images/fastapi/image-20250517143914772.png" alt="image-20250517143914772">
<figcaption aria-hidden="true">image-20250517143914772</figcaption>
</figure>
<blockquote>
<p><strong>静态网站</strong></p>
<p>完全由静态文件（HTML、CSS、JavaScript）组成，内容固定不变，所有页面在开发时已预生成，无需动态计算或数据库支持</p>
<p><strong>动态网站</strong></p>
<p>内容根据用户请求实时生成，通常依赖数据库和服务器端编程（如PHP、Python、Node.js），能提供个性化和交互功能</p>
</blockquote>
<blockquote>
<p><code>StaticFiles</code>是 FastAPI（实际来自
Starlette）提供的一个类，用于挂载和服务静态文件目录。
它的作用是让你可以通过 HTTP
路径直接访问服务器上的静态资源（如图片、CSS、JS 文件等）。</p>
</blockquote>
<blockquote>
<p><code>mount()</code>方法用于将一个完整的应用或静态文件目录挂载到主
FastAPI
应用的某个路径下。这样，访问指定路径时，请求会被转发到挂载的应用或目录。</p>
</blockquote>
<h4 id="响应模型相关参数">4.8 响应模型相关参数</h4>
<h5 id="response_model">response_model</h5>
<p><code>response_model</code>是 FastAPI 路由装饰器（如
<code>@app.post</code>、<code>@app.get</code>
等）中的一个参数，用于指定接口响应的数据模型。它的作用是：</p>
<ul>
<li><strong>自动校验和序列化</strong>：FastAPI 会根据你指定的 Pydantic
模型自动校验、过滤和格式化返回的数据。</li>
<li><strong>自动生成文档</strong>：接口文档会自动显示响应的数据结构。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UserIn</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    username: <span class="built_in">str</span></span><br><span class="line">    password: <span class="built_in">str</span></span><br><span class="line">    email: EmailStr</span><br><span class="line">    full_name: <span class="built_in">str</span>|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UserOut</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    username: <span class="built_in">str</span></span><br><span class="line">    email: EmailStr</span><br><span class="line">    full_name: <span class="built_in">str</span>|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app07.post(<span class="params"><span class="string">&quot;/user02&quot;</span>,response_model=UserOut</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_user</span>(<span class="params">user: UserIn</span>):</span><br><span class="line">    <span class="comment"># 这里可以进行一些处理，比如将用户信息存储到数据库中</span></span><br><span class="line">    <span class="keyword">return</span> user</span><br></pre></td></tr></table></figure>
<p>案例：</p>
<ul>
<li>注册功能</li>
<li>输入账号、密码、昵称、邮箱，注册成功后返回个人信息</li>
</ul>
<h5 id="response_model_exclude_unsettrue">response_model_exclude_unset=True</h5>
<p>通过上面的例子，我们学到了如何用 response_model
控制响应体结构，但是，如果它们实际上没有存储，则可能要从结果中忽略它们。例如，如果
model 在 NoSQL 数据库中具有很多可选属性，但是不想发送很长的 JSON
响应，其中包含默认值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Item</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name:<span class="built_in">str</span></span><br><span class="line">    description: <span class="built_in">str</span>|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line">    price: <span class="built_in">float</span></span><br><span class="line">    tax:<span class="built_in">float</span>=<span class="number">10.5</span></span><br><span class="line">    tags: <span class="built_in">list</span>[<span class="built_in">str</span>]|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#模拟数据库</span></span><br><span class="line">items=&#123;</span><br><span class="line">    <span class="string">&quot;item01&quot;</span>:Item(name=<span class="string">&quot;item01&quot;</span>,price=<span class="number">10.5</span>),</span><br><span class="line">    <span class="string">&quot;item02&quot;</span>:Item(name=<span class="string">&quot;item02&quot;</span>,description=<span class="string">&quot;item02&quot;</span>,price=<span class="number">20.5</span>,tax=<span class="number">20.5</span>,tags=[<span class="string">&quot;tag1&quot;</span>,<span class="string">&quot;tag2&quot;</span>]),</span><br><span class="line">    <span class="string">&quot;item03&quot;</span>:Item(name=<span class="string">&quot;item03&quot;</span>,description=<span class="string">&quot;item03&quot;</span>,price=<span class="number">30.5</span>,tax=<span class="number">30.5</span>,tags=[<span class="string">&quot;tag1&quot;</span>,<span class="string">&quot;tag2&quot;</span>]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app07.get(<span class="params"><span class="string">&quot;/items/&#123;item_id&#125;&quot;</span>,response_model=Item,response_model_exclude_unset=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">read_item</span>(<span class="params">item_id: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">return</span> items[item_id]</span><br></pre></td></tr></table></figure>
<p>设置后返回为：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">item01</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;item01&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">10.5</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>当你设置 <code>response_model_exclude_unset=True</code>
时，返回的响应数据只包含<strong>被显式设置过的字段</strong>，没有被赋值的（即使用默认值且未传递的）字段不会出现在响应中。</p>
</blockquote>
<h5 id="其他参数">其他参数</h5>
<p><strong>response_model_exclude_defaults
</strong>作用：排除所有值为默认值的字段。</p>
<p><strong>response_model_exclude_none</strong> 作用：排除所有值为
<code>None</code> 的字段。</p>
<p><strong>response_model_include</strong> 作用：只返回指定字段</p>
<p><strong>response_model_exclude</strong>
作用：排除指定字段，不在响应中返回。</p>
<h3 id="jinja2模板">jinja2模板</h3>
<p>要了解 jinja2，那么需要先理解模板的概念。模板在 Python 的 web
开发中广泛使用，它能够有效的将业务逻辑和页面逻辑分开，使代码可读性增强、并且更加容易理解和维护。</p>
<p>模板简单来说就是一个其中包涵占位变量表示动态的部分的文件，模板文件在经过动态赋值后，返回给用户。</p>
<p>jinja2 是 Flask 作者开发的一个模板系统，起初是仿 django
模板的一个模板引擎，为 Flask
提供模板支持，由于其灵活，快速和安全等优点被广泛使用。</p>
<p>在 jinja2 中，存在三种语法：</p>
<blockquote>
<ol type="1">
<li>变量取值 <code>&#123;&#123; &#125;&#125;</code></li>
<li>控制结构 <code>&#123;% %&#125;</code></li>
</ol>
</blockquote>
<blockquote>
<p>应用于前后端不分离，模板html+数据库，返回动态网站</p>
</blockquote>
<h4 id="变量">5.1 变量</h4>
<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi.templating <span class="keyword">import</span> Jinja2Templates</span><br><span class="line"></span><br><span class="line">templates=Jinja2Templates(directory=<span class="string">&quot;templates&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/index&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="comment">#数据库</span></span><br><span class="line">    name=<span class="string">&quot;World&quot;</span></span><br><span class="line">    books=[<span class="string">&quot;Python&quot;</span>, <span class="string">&quot;Java&quot;</span>, <span class="string">&quot;C++&quot;</span>]</span><br><span class="line">    user=&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;Tom&quot;</span>, <span class="string">&quot;age&quot;</span>:<span class="number">18</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> templates.TemplateResponse(</span><br><span class="line">        <span class="string">&quot;index.html&quot;</span>,<span class="comment">#模板文件</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;request&quot;</span>: request,<span class="comment"># FastAPI需要一个request对象</span></span><br><span class="line">            <span class="string">&quot;name&quot;</span>: name,</span><br><span class="line">            <span class="string">&quot;books&quot;</span>: books,</span><br><span class="line">            <span class="string">&quot;user&quot;</span>: user</span><br><span class="line">        &#125;<span class="comment">#context上下文对象</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>index.html</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=<span class="string">&quot;en&quot;</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=<span class="string">&quot;UTF-8&quot;</span>&gt;</span><br><span class="line">    &lt;meta name=<span class="string">&quot;viewport&quot;</span> content=<span class="string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span><br><span class="line">    &lt;title&gt;Document&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line"></span><br><span class="line">&lt;body&gt;</span><br><span class="line">    &lt;h1&gt;Hello, &#123;&#123; name &#125;&#125;!&lt;/h1&gt;</span><br><span class="line">    &lt;p&gt;Your favorite books are:&lt;/p&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">        &#123;% <span class="keyword">for</span> book <span class="keyword">in</span> books %&#125;</span><br><span class="line">        &lt;li&gt;&#123;&#123; book &#125;&#125;&lt;/li&gt;</span><br><span class="line">        &#123;% endfor %&#125;</span><br><span class="line">    &lt;/ul&gt;</span><br><span class="line">    &lt;p&gt;姓名：&#123;&#123; user.name &#125;&#125;&lt;/p&gt;</span><br><span class="line">    &lt;p&gt;年龄：&#123;&#123; user.age &#125;&#125;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line"></span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250517200643492.png" alt="image-20250517200643492">
<figcaption aria-hidden="true">image-20250517200643492</figcaption>
</figure>
<h4 id="过滤器">5.2 过滤器</h4>
<p>变量可以通过“过滤器”进行修改，过滤器可以理解为是 jinja2
里面的内置函数和字符串处理函数。常用的过滤器有：</p>
<table>
<thead>
<tr class="header">
<th>过滤器名称</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>capitalize</td>
<td>把值的首字母转换成大写，其他字母转换为小写</td>
</tr>
<tr class="even">
<td>lower</td>
<td>把值转换成小写形式</td>
</tr>
<tr class="odd">
<td>title</td>
<td>把值中每个单词的首字母都转换成大写</td>
</tr>
<tr class="even">
<td>trim</td>
<td>把值的首尾空格去掉</td>
</tr>
<tr class="odd">
<td>striptags</td>
<td>渲染之前把值中所有的 HTML 标签都删掉</td>
</tr>
<tr class="even">
<td>join</td>
<td>拼接多个值为字符串</td>
</tr>
<tr class="odd">
<td>round</td>
<td>默认对数字进行四舍五入，也可以用参数进行控制</td>
</tr>
<tr class="even">
<td>safe</td>
<td>渲染时值不转义</td>
</tr>
</tbody>
</table>
<p>那么如何使用这些过滤器呢？只需要在变量后面使用管道 (|)
分割，多个过滤器可以链式调用，前一个过滤器的输出会作为后一个过滤器的输入。</p>
<p>例如：<code>&lt;h1&gt;Hello, &#123;&#123; name|upper &#125;&#125;!&lt;/h1&gt;</code>
<code>&lt;li&gt;&#123;&#123; book|title &#125;&#125;&lt;/li&gt;</code></p>
<h4 id="控制结构">5.3 控制结构</h4>
<p>jinja2中的if语句类似与Python的if语句，它也具有单分支，多分支等多种结构，不同的是，条件语句不需要使用冒号结尾，而结束控制语句，需要使用endif关键字</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&lt;p&gt;影视区&lt;/p&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% if age &gt;= <span class="number">18</span> %<span class="punctuation">&#125;</span></span><br><span class="line">&lt;ul&gt;</span><br><span class="line">    &lt;li&gt;成人影片&lt;/li&gt;</span><br><span class="line">    &lt;li&gt;成人游戏&lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% else %<span class="punctuation">&#125;</span></span><br><span class="line">&lt;ul&gt;</span><br><span class="line">    &lt;li&gt;儿童影片&lt;/li&gt;</span><br><span class="line">    &lt;li&gt;儿童游戏&lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% endif %<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>jinja2中的for循环用于迭代Python的数据类型，包括列表、元组和字典。在jinja2中不存在while循环。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>% for book in books %<span class="punctuation">&#125;</span></span><br><span class="line">&lt;li&gt;<span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> book|title <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>&lt;/li&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% endfor %<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="orm操作">ORM操作</h3>
<p>在大型的 Web 开发中，我们肯定会用到数据库操作，那么 FastAPI
也支持数据库的开发，你可以用 PostgreSQL、MySQL、SQLite、Oracle
等。本文用 SQLite 为例。我们看下在 FastAPI 是如何操作设计数据库的。</p>
<p>FastAPI 是一个很优秀的框架，但是缺少一个合适的
ORM，官方代码里面使用的是 SQLAlchemy，Tortoise ORM 是受 Django
启发的易于使用的异步 ORM（对象关系映射器）。</p>
<p>Tortoise ORM 目前支持以下数据库：</p>
<ul>
<li>PostgreSQL &gt;= 9.4（使用 asyncpg）</li>
<li>SQLite（使用 aiosqlite）</li>
<li>MySQL/MariaDB（使用 aiomysql 或使用 asyncmy）</li>
</ul>
<p>安装：<code>pip install tortoise-orm</code></p>
<h4 id="创建模型">6.1 创建模型</h4>
<p><strong>1. 一对一关系（One-to-One）</strong></p>
<ul>
<li><strong>定义</strong>
：一张表中的一条记录仅关联另一张表中的一条记录。</li>
<li><strong>示例</strong>
：用户表（User）与身份证信息表（IDCard），一个用户仅对应一张身份证信息。</li>
</ul>
<p><strong>2. 一对多关系（One-to-Many）</strong></p>
<ul>
<li><strong>定义</strong>
：一张表中的一条记录关联另一张表中的多条记录。</li>
<li><strong>示例</strong>
：班级表（Class）与学生表（Student），一个班级包含多个学生，但每个学生只能属于一个班级。</li>
</ul>
<p><strong>3. 多对多关系（Many-to-Many）</strong></p>
<ul>
<li><strong>定义</strong>
：两张表中的记录可以互相关联多条记录，通常通过中间表实现。</li>
<li><strong>示例</strong>
：学生表（Student）与课程表（Course），一个学生可选修多门课程，一门课程也可被多个学生选修。</li>
</ul>
<p><strong>4. 自引用关系（Self-Referencing）</strong></p>
<ul>
<li><strong>定义</strong>
：表内的记录通过字段关联自身，形成层级或树状结构。</li>
<li><strong>示例</strong>
：员工表（Employee），每个员工可能有直属上级（另一个员工）。</li>
</ul>
<p><strong>5. 继承关系（Inheritance）</strong></p>
<ul>
<li><strong>定义</strong>
：基于面向对象的继承概念，子表继承父表的字段和约束。</li>
<li><strong>示例</strong>
：用户表（User）作为基表，管理员表（Admin）和普通用户表（RegularUser）继承其字段（如用户名、密码）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tortoise.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tortoise <span class="keyword">import</span> fields</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Model 是所有数据模型的基类，通过继承 Model 可定义数据库表的结构。每个 Model 子类对应一张数据库表，其类属性定义了表的字段（列）及其约束。</span></span><br><span class="line"><span class="string">fields 提供了多种字段类型，用于定义数据库表的列及其约束。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> = fields.IntField(pk=<span class="literal">True</span>)<span class="comment">#该字段会被指定为模型的主键</span></span><br><span class="line">    name = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;姓名&quot;</span>)</span><br><span class="line">    pwd = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;密码&quot;</span>)</span><br><span class="line">    sno = fields.IntField(description=<span class="string">&quot;学号&quot;</span>)</span><br><span class="line">    <span class="comment">#一对多关系</span></span><br><span class="line">    Class_id = fields.ForeignKeyField(</span><br><span class="line">        <span class="string">&quot;models.Class&quot;</span>,<span class="comment">#关联的模型类</span></span><br><span class="line">        related_name=<span class="string">&quot;students&quot;</span>,<span class="comment">#反向查询时的名称</span></span><br><span class="line">        on_delete=fields.CASCADE,<span class="comment">#级联删除</span></span><br><span class="line">        description=<span class="string">&quot;班级&quot;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#多对多关系</span></span><br><span class="line">    Course_id = fields.ManyToManyField(</span><br><span class="line">        <span class="string">&quot;models.Course&quot;</span>,<span class="comment">#关联的模型类</span></span><br><span class="line">        related_name=<span class="string">&quot;students&quot;</span>,<span class="comment">#反向查询时的名称</span></span><br><span class="line">        description=<span class="string">&quot;课程&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Course</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> = fields.IntField(pk=<span class="literal">True</span>)</span><br><span class="line">    name = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;课程名称&quot;</span>)</span><br><span class="line">    teacher = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;授课老师&quot;</span>)</span><br><span class="line">    <span class="comment">#一对多关系</span></span><br><span class="line">    teacher_id = fields.ForeignKeyField(</span><br><span class="line">        <span class="string">&quot;models.Teacher&quot;</span>,<span class="comment">#关联的模型类</span></span><br><span class="line">        related_name=<span class="string">&quot;courses&quot;</span>,<span class="comment">#反向查询时的名称</span></span><br><span class="line">        on_delete=fields.CASCADE,<span class="comment">#级联删除</span></span><br><span class="line">        description=<span class="string">&quot;老师&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Class</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> = fields.IntField(pk=<span class="literal">True</span>)</span><br><span class="line">    name= fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;班级名称&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Teacher</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> =fields.IntField(pk=<span class="literal">True</span>)</span><br><span class="line">    name = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;老师姓名&quot;</span>)</span><br><span class="line">    pwd = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;密码&quot;</span>)</span><br><span class="line">    sno = fields.IntField(description=<span class="string">&quot;工号&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ORM（Object Relational
Mapping，对象关系映射）是一种程序设计技术，主要用于实现<strong>面向对象编程语言</strong>
与<strong>关系型数据库</strong>
之间的数据转换。其核心思想是通过对象模型与数据库表结构的映射，将数据库操作转化为面向对象的操作，从而简化开发流程并提升代码的可维护性</p>
</blockquote>
<blockquote>
<p>Tortoise ORM 是一款专为 Python
异步环境设计的轻量级对象关系映射（ORM）框架，其设计灵感来源于 Django
ORM，但专注于异步编程场景，适用于 FastAPI、Sanic 等基于
<code>asyncio</code> 的现代 Web 框架。</p>
</blockquote>
<blockquote>
<p>关系型数据库与非关系型数据库</p>
<p><strong>关系型数据库</strong>
以表格形式存储数据，数据按行和列组织，列代表属性（字段），行代表记录。例如，用户表可能包含
<code>id</code>、<code>name</code>、<code>email</code>
等列，每行对应一个用户记录。这种结构化设计支持严格的模式约束（Schema）17。</p>
<p><strong>典型代表</strong> ：MySQL、Oracle、PostgreSQL。</p>
<p><strong>非关系型数据库（NoSQL）</strong>
采用非结构化或半结构化存储，常见的类型包括：</p>
<ul>
<li><p><strong>文档型</strong> （如 MongoDB）：以 JSON 或 BSON
格式存储数据。</p></li>
<li><p><strong>键值型</strong> （如 Redis）：通过键直接访问值。</p></li>
<li><p><strong>列存储</strong> （如
Cassandra）：按列而非行组织数据。</p></li>
<li><p><strong>图数据库</strong></p>
<p>（如 Neo4j）：以节点和边表示数据关系</p></li>
</ul>
</blockquote>
<h4 id="aerich迁移工具">6.2 aerich迁移工具</h4>
<p><strong>docker 安装 mysql</strong>：</p>
<p>拉取 MySQL 镜像：<code>docker pull mysql</code></p>
<p>运行 MySQL 容器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run --name fastapi -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql</span><br></pre></td></tr></table></figure>
<blockquote>
<p>-p表示端口映射 –restart=always表示容器退出时总是重启
–name表示容器命名 –privileged=true表示赋予容器权限修改宿主文件权利 -v
/home/mysql/log:/var/log/mysql表示容器日志挂载到宿主机 -v
/home/mysql/data:/var/lib/mysql表示容器存储文件挂载到宿主机 -v
/home/mysql/conf/my.cnf:/etc/mysql/my.cnf表示容器配置文件挂载到宿主机 -e
MYSQL_ROOT_PASSWORD=a12bCd3_W45pUq6表示设置mysql的root用户密码,建议用强密码
-d表示后台运行</p>
</blockquote>
<p>启动这个 MySQL 容器：<code>docker start fastapi</code></p>
<p>进入 MySQL 容器：<code>docker exec -it fastapi bash</code></p>
<blockquote>
<p>这条命令的作用是：</p>
<ul>
<li><code>docker exec</code>：在已运行的 Docker 容器中执行命令。</li>
<li><code>-it</code>：<code>-i</code> 表示交互式操作，<code>-t</code>
分配一个伪终端（让你像在终端一样操作）。</li>
<li><code>fastapi</code>：这是你要进入的容器名称（你的 MySQL
容器名）。</li>
<li><code>bash</code>：在容器内启动 bash shell。</li>
</ul>
<p>这条命令会让你进入名为 <code>fastapi</code> 的容器，并获得一个 bash
命令行界面，就像登录到一台 Linux
服务器一样，可以在里面执行各种命令（比如登录 MySQL、查看日志等）。</p>
</blockquote>
<p>登录 MySQL：<code>mysql -u root -p</code></p>
<p>从主机直接连接：<code>mysql -h 127.0.0.1 -P 3306 -u root -p</code></p>
<h5 id="配置文件">配置文件</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TORTOISE_ORM = &#123;</span><br><span class="line">    &quot;connections&quot;: &#123;</span><br><span class="line">        &quot;default&quot;: &#123;</span><br><span class="line">            &quot;engine&quot;:&#x27;tortoise.backends.mysql&#x27;,#选择数据库引擎，mysql</span><br><span class="line">            &quot;credentials&quot;: &#123;</span><br><span class="line">                &quot;host&quot;: &quot;localhost&quot;,#数据库地址</span><br><span class="line">                &quot;port&quot;: 3306,#数据库端口</span><br><span class="line">                &quot;user&quot;: &quot;root&quot;,#数据库用户名</span><br><span class="line">                &quot;password&quot;: &quot;root&quot;,#数据库密码</span><br><span class="line">                &quot;database&quot;: &quot;fastapi_db&quot;,#数据库名称</span><br><span class="line">                &#x27;charset&#x27;: &quot;utf8mb4&quot;,#数据库编码</span><br><span class="line">                &#x27;echo&#x27;: True,#是否打印sql语句</span><br><span class="line">                &#x27;minsize&#x27;: 1,#连接池最小连接数</span><br><span class="line">                &#x27;maxsize&#x27;: 5#连接池最大连接数</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;apps&quot;: &#123;</span><br><span class="line">        &quot;models&quot;: &#123;</span><br><span class="line">            #db.models是我们自己定义的模型类,models在db文件夹下</span><br><span class="line">            &quot;models&quot;: [&quot;db.models&quot;,&quot;aerich.models&quot;],</span><br><span class="line">            &quot;default_connection&quot;: &quot;default&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;use_tz&#x27;: False,#是否使用时区</span><br><span class="line">    &#x27;timezone&#x27;: &#x27;Asia/Shanghai&#x27;,#时区</span><br><span class="line">    &quot;generate_schemas&quot;: True,</span><br><span class="line">    &quot;add_exception_handlers&quot;: True</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="初始化配置只需要使用一次">1.初始化配置，只需要使用一次</h5>
<p>aerich 是一种 ORM 迁移工具，需要结合 tortoise 异步 orm 框架使用。安装
aerich</p>
<p><code>pip install aerich</code></p>
<p><code>aerich init -t settings.TORTOISE_ORM  # TORTOISE_ORM 配置的位置</code></p>
<blockquote>
<p>初始化完会在当前目录生成一个文件：pyproject.toml
和一个文件夹：migrations</p>
<ul>
<li>pyproject.toml：保存配置文件路径，低版本可能是 aerich.ini</li>
<li>migrations：存放迁移文件</li>
</ul>
</blockquote>
<h5 id="初始化数据库一般情况下只用一次">2.初始化数据库，一般情况下只用一次</h5>
<p><code>aerich init-db</code></p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250521105044582.png" alt="image-20250521105044582">
<figcaption aria-hidden="true">image-20250521105044582</figcaption>
</figure>
<h5 id="更新模型并进行迁移">3.更新模型并进行迁移</h5>
<p>修改model类，重新生成迁移文件</p>
<p><code>aerich migrate</code></p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250521111024194.png" alt="image-20250521111024194">
<figcaption aria-hidden="true">image-20250521111024194</figcaption>
</figure>
<h5 id="重新执行迁移写入数据库">4.重新执行迁移，写入数据库</h5>
<p><code>aerich upgrade</code></p>
<figure>
<img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250521111131931.png" alt="image-20250521111131931">
<figcaption aria-hidden="true">image-20250521111131931</figcaption>
</figure>
<h5 id="回到上一个版本">5.回到上一个版本</h5>
<p><code>aerich downgrade</code></p>
<h5 id="查看历史迁移记录">6.查看历史迁移记录</h5>
<p><code>aerich history</code></p>
<blockquote>
<p><code>register_tortoise</code> 是 Tortoise ORM
提供的一个工具函数，用于在 <strong>FastAPI</strong>
等异步框架中快速集成和管理 Tortoise ORM
的生命周期（如启动时初始化数据库连接，关闭时释放资源）。其核心作用是简化
Tortoise ORM
的配置和自动化管理，开发者只需一行代码即可完成复杂的初始化流程</p>
</blockquote>
<h4 id="orm查询操作">6.3 ORM查询操作</h4>
<p>api.stud</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"><span class="comment">#导入数据库</span></span><br><span class="line"><span class="keyword">from</span> db.models <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">student_api=APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.get(<span class="params"><span class="string">&quot;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_students</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    #查询所有学生信息</span></span><br><span class="line"><span class="string">    students= await Student.all()#获取所有学生信息</span></span><br><span class="line"><span class="string">    for student in students:</span></span><br><span class="line"><span class="string">        print(student.id,student.name)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #过滤查询filter</span></span><br><span class="line"><span class="string">    students= await Student.filter(name__contains=&quot;张&quot;).all()</span></span><br><span class="line"><span class="string">    for student in students:</span></span><br><span class="line"><span class="string">        print(student.id,student.name)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #get学生信息</span></span><br><span class="line"><span class="string">    stu = await Student.get(id=1)</span></span><br><span class="line"><span class="string">    print(stu.id,stu.name)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #模糊查询</span></span><br><span class="line"><span class="string">    #最大值</span></span><br><span class="line"><span class="string">    stu =await Student.filter(sno__gt=1000).all()</span></span><br><span class="line"><span class="string">    #最小值</span></span><br><span class="line"><span class="string">    #stu = await Student.filter(sno__lt=1000).all()</span></span><br><span class="line"><span class="string">    #范围查询</span></span><br><span class="line"><span class="string">    #stu = await Student.filter(sno__range=(1000,2000)).all()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #values查询</span></span><br><span class="line"><span class="string">    stu = await Student.all().values(&quot;sno&quot;,&quot;name&quot;)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">&quot;获取所有学生信息&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.post(<span class="params"><span class="string">&quot;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_student</span>():</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">&quot;创建学生信息&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.get(<span class="params"><span class="string">&quot;/&#123;student_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_student</span>(<span class="params">student_id:<span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">f&quot;获取学生信息，ID：<span class="subst">&#123;student_id&#125;</span>&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.put(<span class="params"><span class="string">&quot;/&#123;student_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">update_student</span>(<span class="params">student_id:<span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">f&quot;更新学生信息，ID：<span class="subst">&#123;student_id&#125;</span>&quot;</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在 FastAPI 和 Tortoise ORM 中，<code>async</code> 和
<code>await</code> 用于<strong>异步编程</strong>，主要原因如下：</p>
<ol type="1">
<li><strong>异步 I/O 操作</strong> 数据库查询（如
Student.all()）是耗时的 I/O 操作。使用
<code>async</code>/<code>await</code>
可以在等待数据库响应时，不阻塞主线程，提高应用的并发性能。</li>
<li><strong>FastAPI 支持异步路由</strong> FastAPI
支持异步（<code>async def</code>）的路由函数，这样可以充分利用 Python
的异步特性，提升 Web 服务的吞吐量。</li>
<li><strong>Tortoise ORM 的方法是异步的</strong> Tortoise ORM
的数据库操作方法（如 <code>.all()</code>、<code>.create()</code>
等）本身就是异步方法，必须用 <code>await</code> 调用，并且所在函数必须用
<code>async def</code> 声明。</li>
</ol>
</blockquote>
<h3 id="知识点">知识点</h3>
<h4 id="端口查询">端口查询</h4>
<p>查看所有端口占用情况：<code>netstat -ano</code></p>
<p>查询特定端口是否被占用：<code>netstat -ano | findstr 8080</code></p>
<p>使用 <code>taskkill</code>
命令强制结束进程：<code>taskkill /PID 进程ID /F</code></p>
<p>通过 PID 查找进程：<code>tasklist | findstr PID</code></p>
<h4 id="获取绝对路径">获取绝对路径</h4>
<p>获取当前文件的绝对路径：<code>base_dir = os.path.dirname(os.path.abspath(__file__))</code></p>
<p>拼接路径：<code>img_dir = os.path.join(base_dir, "../imgs")</code></p>
<h4 id="mysql部分指令">mysql部分指令</h4>
<p><strong>查看数据库列表</strong>：<code>SHOW DATABASES;</code></p>
<p><strong>选择数据库</strong>：<code>USE 数据库名;</code></p>
<p><strong>删除数据库</strong>：<code>DROP DATABASE 数据库名;</code></p>
<p><strong>创建数据库</strong>：<code>CREATE DATABASE 数据库名;</code></p>
<p><strong>登录 MySQL</strong>：<code>mysql -u root -p</code></p>
<p><strong>退出</strong>：<code>exit</code></p>
<h4 id="docker部分指令">docker部分指令</h4>
<p><strong>linux安装docker</strong>：<code>sudo apt-get update &amp;&amp; sudo apt-get install docker.io</code></p>
<p><strong>查看 Docker
版本信息</strong>：<code>docker version</code></p>
<p><strong>查看镜像</strong>：<code>docker images</code></p>
<p><strong>查看所有的容器</strong>：<code>docker ps -a</code></p>
<blockquote>
<p><code>systemctl</code> 是 <strong>systemd</strong>
系统和服务管理器的核心工具，用于管理系统和服务的状态及配置。</p>
</blockquote>
<p><code>mysql-client</code> 是 MySQL
数据库的命令行客户端工具。它允许你通过命令行连接和操作 MySQL
数据库服务器，比如执行 SQL 查询、管理数据库和用户等。</p>
<p>常用命令格式如下：<code>mysql -h 主机地址 -P 端口号 -u 用户名 -p</code></p>
<p>你可以在终端输入以下命令来检查是否已安装
<code>mysql-client</code>：<code>mysql --version</code></p>
<p>可以使用以下命令安装：<code>sudo apt-get update  sudo apt-get install mysql-client</code></p>
<blockquote>
<p><code>sudo apt-get update</code>
这个命令的作用是<strong>更新本地软件包列表</strong>。</p>
</blockquote>
<p><strong>停止并删除容器</strong>：<code>docker stop fastapi  docker rm fastapi</code></p>
]]></content>
      <categories>
        <category>python-web</category>
        <category>fastapi</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——循环队列</title>
    <url>/2024/10/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[<h1 id="数据结构循环队列">数据结构——循环队列</h1>
<h2 id="思考">思考</h2>
<figure>
<img src="/2024/10/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97/IMG_20241015_235239-1729007863179-13.jpg" alt="IMG_20241015_235239">
<figcaption aria-hidden="true">IMG_20241015_235239</figcaption>
</figure>
<p>头指针<code>front</code>指向的位置为队列头元素的前一个位置</p>
<p>尾指针<code>rear</code>指向的位置为队列尾元素</p>
<p>以上目的：为了区分队列是否为空或已满的判断条件</p>
<ul>
<li><strong>队列为空</strong>：当 <code>front</code> 和
<code>rear</code> 相等时，说明队列中没有元素，此时为空队列。</li>
<li><strong>队列已满</strong>：当
<code>(rear + 1) % MAXSIZE == front</code>
时，说明队列已满，因为<code>rear</code> 紧跟在 <code>front</code>
的前面，队列的最后一个位置不可用，否则会与空队列的情况冲突。</li>
</ul>
<p>注意事项：</p>
<p>由于判断队列满的条件需要 <code>front</code> 位置与
<code>rear + 1</code> 相等，意味着最多只能使用 <code>MAXSIZE - 1</code>
个元素的位置，这种策略用于避免空队列与满队列状态混淆。</p>
<p>若不做此区分，队空和队满的判断条件都是<code>(rear + 1) % MAXSIZE == front</code>，会发生混淆</p>
<h2 id="代码">代码</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//循环队列</span><br><span class="line">const int MAXSIZE = 100;</span><br><span class="line">typedef struct &#123;</span><br><span class="line">	int data[MAXSIZE];</span><br><span class="line">	int front;</span><br><span class="line">	int rear;</span><br><span class="line">&#125;Queue;</span><br><span class="line"></span><br><span class="line">//初始化队列</span><br><span class="line">void InitQueue(Queue&amp; Q) &#123;</span><br><span class="line">	Q.front = 0;</span><br><span class="line">	Q.rear = 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//判断队列是否为空</span><br><span class="line">bool IsEmpty(Queue Q) &#123;</span><br><span class="line">	return Q.front == Q.rear;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//判断队列是否已满</span><br><span class="line">bool IsFull(Queue Q) &#123;</span><br><span class="line">	return (Q.rear + 1) % MAXSIZE == Q.front;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//入队</span><br><span class="line">void push(Queue&amp; Q, int x) &#123;</span><br><span class="line">	if (IsFull(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列已满&quot; &lt;&lt; endl;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	//指针先向后移动，再赋值</span><br><span class="line">	Q.rear = (Q.rear + 1) % MAXSIZE;</span><br><span class="line">	Q.data[Q.rear] = x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//出队</span><br><span class="line">int pop(Queue&amp; Q) &#123;</span><br><span class="line">	if (IsEmpty(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	//指针先向后移动，再返回值</span><br><span class="line">	Q.front = (Q.front + 1) % MAXSIZE;</span><br><span class="line">	return Q.data[Q.front];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//获取队头元素</span><br><span class="line">int getFront(Queue Q) &#123;</span><br><span class="line">	if (IsEmpty(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	//指针向后移动，再返回值，front指针指向的是队头元素的前一个位置</span><br><span class="line">	return Q.data[(Q.front + 1) % MAXSIZE];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//获取队尾元素</span><br><span class="line">int getRear(Queue Q) &#123;</span><br><span class="line">	if (IsEmpty(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	//rear指针指向的是队尾元素</span><br><span class="line">	return Q.data[Q.rear];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//测试函数</span><br><span class="line">int main() &#123;</span><br><span class="line">	Queue Q;</span><br><span class="line">	InitQueue(Q);</span><br><span class="line">	push(Q, 1);</span><br><span class="line">	push(Q, 2);</span><br><span class="line">	push(Q, 3);</span><br><span class="line">	cout &lt;&lt; getFront(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; getRear(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; pop(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; getFront(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; getRear(Q) &lt;&lt; endl;</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意事项：</p>
<p>入队逻辑：rear指针先向后移动一位，再赋值</p>
<p>出队逻辑：front指针先向后移动一位，再返回值，因为front指针指向的是队头元素的前一个位置</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1CC4y1m7Bu/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【队列&amp;循环队列】手动实现循环队列，掌握循环队列的每一处细节_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——查找</title>
    <url>/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/</url>
    <content><![CDATA[<h2 id="查找的概念">查找的概念</h2>
<p><strong>查找(Searching)</strong>
：就是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素(
或记录)。</p>
<p><strong>查找表(Search Table)</strong>
：是由同一类型的数据元素(或记录)构成的集合。</p>
<p><strong>关键字(Key)</strong>
：数据元素中唯一标识该元素的某个数据项的值，使用基于关键字的查找，查找结果应该是唯一的。例如，在由一个学生元素构成的数据集合中，学生元素中“学号”这一数据项的值唯一地标识一名学生。</p>
<p><strong>静态查找表(Static Search Table)</strong>
：只作查找操作的查找表。 <strong>动态查找表(Dynamic Search
Table)</strong> ：
在查找过程中同时插入查找表中不存在的数据元素，或者从查找表中删除已经存在的某个数据元素。</p>
<p><strong>平均查找长度</strong>
：在查找过程中，一次查找的长度是指需要比较的关键字次数，而平均查找长度，则是所有查找过程中进行关键字的比较次数的平均值，其数学定义为<span class="math inline">$\ ASL=\sum_{i=1}^{n}P_iC_i$</span></p>
<p>式中，n是查找表的长度;P是查找第i个数据元素的概率，一般认为每个数据元素的查找概率相等，即P,=
1/n;C;是找到第i个数据元素所需进行的比较次数。平均查找长度是衡量查找算法效率的最主要的指标。</p>
<h2 id="顺序表查找">顺序表查找</h2>
<h3 id="顺序查找">顺序查找</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*有哨兵顺序查找*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Sequential_Search</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> n, <span class="type">int</span> key)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> i;</span><br><span class="line">	a[<span class="number">0</span>] = key;	<span class="comment">//设置a[0]为关键字，称之为“哨兵”</span></span><br><span class="line">	i = n;	<span class="comment">//循环从数组尾部开始</span></span><br><span class="line">	<span class="keyword">while</span>(a[i] != key)&#123;</span><br><span class="line">		i--;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> i;	<span class="comment">//返回0则说明查找失败</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这种在查找方向的尽头放置“哨兵”免去了在查找过程中每一次比较后都要判断查找位置是否越界的小技巧，看似与原先差别不大，但在总数据较多时，效率提高很大，是非常好的编码技巧。
上述顺序表查找时间复杂度是O (n) 。</p>
<h3 id="折半查找">折半查找</h3>
<p>当查找表是有序表时，可采用折半查找的方法。</p>
<p>算法思路：</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215134842077.png" alt="image-20241215134842077">
<figcaption aria-hidden="true">image-20241215134842077</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">Binary_Search</span><span class="params">(SeqList L, ElemType key)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> low = <span class="number">0</span>, high = L.length - <span class="number">1</span>, mid;</span><br><span class="line">	<span class="keyword">while</span>(low &lt;= high)&#123;</span><br><span class="line">		mid = (low + hight)/<span class="number">2</span>;	<span class="comment">//取中间位置</span></span><br><span class="line">		<span class="keyword">if</span>(L.elem[mid] == key)&#123;</span><br><span class="line">			<span class="keyword">return</span> mid;	<span class="comment">//查找成功返回所在位置</span></span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(L.elem[mid] &gt; key)&#123;</span><br><span class="line">			high = mid - <span class="number">1</span>;	<span class="comment">//从前半部分继续查找</span></span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			low = mid + <span class="number">1</span>;	<span class="comment">//从后半部分继续查找</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">-1</span>;	<span class="comment">//查找失败，返回-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215134858075.png" alt="image-20241215134858075">
<figcaption aria-hidden="true">image-20241215134858075</figcaption>
</figure>
<p>折半查找的过程可用二叉树来描述，称为判定树。</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215135512761.png" alt="image-20241215135512761">
<figcaption aria-hidden="true">image-20241215135512761</figcaption>
</figure>
<p>节点的树高代表该节点的查询次数</p>
<p>因此，长度为13的有序表进行折半查找的平均查找长度ASL=(1×1+2×2+3×4+4×6)/13
=41/13。</p>
<p>折半查找的时间复杂度为<span class="math inline"> <em>O</em>(log<sub>2</sub><em>n</em>)</span>，平均情况下比顺序查找的效率高。</p>
<h3 id="分块查找">分块查找</h3>
<p>为了减少索引项的个数，我们可以对数据集进行分块，使其分块有序，然后再对每一块建立一个索引项，从而减少索引项的个数。</p>
<p>分块有序，是把数据集的记录分成了若千块，并且这些块需要满足两个条件：</p>
<ul>
<li><p>块内无序：即每一块内的记录不要求有序。</p></li>
<li><p>块间有序：例如，要求第二块所有记录的关键字均要大于第一块中所有记录的关键字，第三块的所有记录的关键字均要大于第二块的所有记录关键字…因为只有块间有序，才有可能在查找时带来效率。</p></li>
</ul>
<p>对于分块有序的数据集，将每块对应一个索引项，
这种索引方法叫做分块索引。如下图所示，我们定义的分块索引的索引项结构分三个数据项：</p>
<ul>
<li><p>最大关键码：它存储每一块中的最大关键字，这样的好处就是可以使得在它之后的下一块中的最小关键字也能比这一块最大的关键字要大；</p></li>
<li><p>块长：存储了块中的记录个数，以便于循环时使用；</p></li>
<li><p>块首指针：用于指向块首数据元素的指针，便于开始对这一块中记录进行遍历。</p></li>
</ul>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/825a789b2d39804be6b9aede1bbc0ba1.png" alt="825a789b2d39804be6b9aede1bbc0ba1">
<figcaption aria-hidden="true">825a789b2d39804be6b9aede1bbc0ba1</figcaption>
</figure>
<p>在分块索引表中查找，就是分两步进行:
1.在分块索引表中查找要查关键字所在的块。由于分块索引表是块间有序的，因此很容易利用折半、插值等算法得到结果。例如在上图的数据集中查找62，我们可以很快可以从左上角的索引表中由57&lt;62&lt;96得到62在第三个块中。
2.根据块首指针找到相应的块，并在块中顺序查找关键码。</p>
<h2 id="树表的查找">树表的查找</h2>
<h3 id="二叉排序树">二叉排序树</h3>
<p>二叉排序树(也称二叉查找树)或者是一棵空树，或者是具有下列特性的二叉树:</p>
<ol type="1">
<li>若左子树非空，则<strong>左子树上所有结点的值均小于根结点的值</strong>。</li>
<li>若右子树非空，则<strong>右子树上所有结点的值均大于根结点的值</strong>。</li>
<li>左、右子树也分别是一棵二叉排序树。</li>
</ol>
<p>根据二叉排序树的定义，左子树结点值&lt;根结点值&lt;右子树结点值，所以对二叉排序树进行中序遍历，可以得到一个递增的有序序列。例如，下图所示二叉排序树的中序遍历序列为123468。</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/bec1d08d423a4860887667fb980dfbea.png" alt="bec1d08d423a4860887667fb980dfbea">
<figcaption aria-hidden="true">bec1d08d423a4860887667fb980dfbea</figcaption>
</figure>
<h4 id="二叉排序树的插入和建立">二叉排序树的插入和建立</h4>
<p>在一棵二叉排序树中插入值为系的结点的步骤如下：</p>
<p>①若二叉排序树为空，则生成值为k的新结点s，同时将新结点s作为根结点插入。</p>
<p>②若k小于根结点的值,则在根的左子树中插入值为k的结点。</p>
<p>③若k大于根结点的值,则在根的右子树中插入值为k的结点。</p>
<p>④若k等于根结点的值，表明二叉排序树中已有此关键字，则无需插入。</p>
<p>二叉排序树插入算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"> <span class="comment">//构造函数</span></span><br><span class="line"> <span class="built_in">BiNode</span>(<span class="type">int</span> k) : <span class="built_in">key</span>(k), <span class="built_in">lchild</span>(<span class="literal">nullptr</span>), <span class="built_in">rchild</span>(<span class="literal">nullptr</span>) &#123;&#125;;</span><br><span class="line"><span class="comment">// 递归插入函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Insert</span><span class="params">(BiNode*&amp; ptr, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (ptr == <span class="literal">nullptr</span>) &#123; <span class="comment">// 如果当前指针为空，插入新节点</span></span><br><span class="line">            ptr = <span class="keyword">new</span> <span class="built_in">BiNode</span>(k);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (k &lt; ptr-&gt;key) &#123; </span><br><span class="line">            <span class="built_in">Insert</span>(ptr-&gt;lchild, k); <span class="comment">// 递归插入到左子树</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (k &gt; ptr-&gt;key) &#123;</span><br><span class="line">            <span class="built_in">Insert</span>(ptr-&gt;rchild, k); <span class="comment">// 递归插入到右子树</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果k等于当前节点值，则不插入（BST通常不允许重复值）</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 插入值到BST</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Insert</span><span class="params">(<span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">Insert</span>(root, k);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>二叉排序树的建立</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 构造函数：利用数组 a[] 和大小 n 建立二叉排序树</span></span><br><span class="line">    <span class="built_in">BiSortTree</span>(<span class="type">int</span> a[], <span class="type">int</span> n) &#123;</span><br><span class="line">        root = <span class="literal">nullptr</span>; <span class="comment">// 初始化根节点为空</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">            <span class="built_in">Insert</span>(root, a[i]); <span class="comment">// 插入数组中的每个元素</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215144119644.png" alt="image-20241215144119644">
<figcaption aria-hidden="true">image-20241215144119644</figcaption>
</figure>
<h4 id="二叉排序树的查找过程">二叉排序树的查找过程</h4>
<p>根据二叉排序树的定义，在二叉排序树中查找给定值k的过程如下:</p>
<p>①若二叉排序树为空，则表明查找失败，返回空指针;否则，若给定值k等于根结点的值,则表明查找成功,返回根结点。</p>
<p>②若给定值k小于根结点的值,则继续在根的左子树中查找。</p>
<p>③若给定值k大于根结点的值,则继续在根的右子树中查找。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 非递归查找函数</span></span><br><span class="line">   <span class="function">BiNode* <span class="title">Search2</span><span class="params">(BiNode* ptr, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">while</span> (ptr) &#123;</span><br><span class="line">           <span class="keyword">if</span> (k == ptr-&gt;key) <span class="comment">// 找到目标节点</span></span><br><span class="line">               <span class="keyword">return</span> ptr;</span><br><span class="line">           <span class="keyword">else</span> <span class="keyword">if</span> (k &lt; ptr-&gt;key) <span class="comment">// 查找左子树</span></span><br><span class="line">               ptr = ptr-&gt;lchild;</span><br><span class="line">           <span class="keyword">else</span>                  <span class="comment">// 查找右子树</span></span><br><span class="line">               ptr = ptr-&gt;rchild;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="literal">nullptr</span>; <span class="comment">// 未找到</span></span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>若二叉排序树是<strong>平衡的(即形态均匀)</strong>，则进行查找的时间复杂度为<span class="math inline"> <em>O</em>(<em>l</em><em>o</em><em>g</em><sub>2</sub><em>n</em>)</span>;若退化为一棵单支树（最极端和最差的情况)，则其时间复杂度为<span class="math inline"> <em>O</em>(<em>n</em>)</span>。对于一般情况，其时间复杂度可以认为是<span class="math inline"> <em>O</em>(<em>l</em><em>o</em><em>g</em><sub>2</sub><em>n</em>)</span>。</p>
<h4 id="二叉排序树的删除">二叉排序树的删除</h4>
<p>二叉排序树的查找和插入都很简单，但是删除操作就要复杂一些，此时要删除的结点有三种情况：</p>
<ol type="1">
<li>叶子结点；</li>
<li>仅有左或右子树的结点；</li>
<li>左右子树都有的结点；</li>
</ol>
<p>前两种情况都很简单，第一种只需删除该结点不需要做其他操作；第二种删除后需让被删除结点的直接后继接替它的位置；<strong>复杂就复杂在第三种，此时我们需要遍历得到被删除结点的直接前驱或者直接后继来接替它的位置，然后再删除</strong>。</p>
<p>第三种情况如下图所示：</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/1fa9d70c1f0ef1ab673061a9c2e39a08.png" alt="1fa9d70c1f0ef1ab673061a9c2e39a08">
<figcaption aria-hidden="true">1fa9d70c1f0ef1ab673061a9c2e39a08</figcaption>
</figure>
<p>代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">若二叉排序树T中存在关键字等于key的数据元素时，则删除该数据元素结点，</span></span><br><span class="line"><span class="comment">并返回TRUE;否则返回FALSE</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">DeleteBST</span><span class="params">(BiTree *T, <span class="type">int</span> key)</span></span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(!T)&#123;</span><br><span class="line">		<span class="keyword">return</span> FALSE; </span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		<span class="keyword">if</span>(key == T-&gt;data)&#123;</span><br><span class="line">			<span class="comment">//找到关键字等于key的数据元素</span></span><br><span class="line">			<span class="keyword">return</span> <span class="built_in">Delete</span>(T);</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(key &lt; T -&gt; data)&#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="built_in">DeleteBST</span>(T -&gt; lchild, key);</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="built_in">DeleteBST</span>(T -&gt; rchild, key);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面是Delete()方法：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*从二叉排序树中删除结点p，并重接它的左或右子树。*/</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Delete</span><span class="params">(BiTree *p)</span></span>&#123;</span><br><span class="line">	BiTree q, s;</span><br><span class="line">	<span class="keyword">if</span>(p-&gt;rchild == <span class="literal">NULL</span>)&#123;</span><br><span class="line">		<span class="comment">//右子树为空则只需重接它的左子树</span></span><br><span class="line">		q = p;</span><br><span class="line">		p = p-&gt;lchild;</span><br><span class="line">		<span class="built_in">free</span>(q);</span><br><span class="line">	&#125;<span class="keyword">else</span> <span class="keyword">if</span>(p-&gt;lchild == <span class="literal">NULL</span>)&#123;</span><br><span class="line">		<span class="comment">//左子树为空则只需重接它的右子树</span></span><br><span class="line">		q = p;</span><br><span class="line">		p = p-&gt;rchild;</span><br><span class="line">		<span class="built_in">free</span>(q);</span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		<span class="comment">//左右子树均不空</span></span><br><span class="line">		q = p;</span><br><span class="line">		s = p-&gt;lchild;	<span class="comment">//先转左</span></span><br><span class="line">		<span class="keyword">while</span>(s-&gt;rchild)&#123;<span class="comment">//然后向右到尽头，找待删结点的前驱</span></span><br><span class="line">			q = s;</span><br><span class="line">			s = s-&gt;rchild;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//此时s指向被删结点的直接前驱，p指向s的父母节点</span></span><br><span class="line">		p-&gt;data = s-&gt;data;	<span class="comment">//被删除结点的值替换成它的直接前驱的值</span></span><br><span class="line">		<span class="keyword">if</span>(q != p)&#123;</span><br><span class="line">			q-&gt;rchild = s-&gt;lchild;	<span class="comment">//重接q的右子树</span></span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			q-&gt;lchild = s-&gt;lchild;	<span class="comment">//重接q的左子树</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="built_in">pree</span>(s);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> TRUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>二叉排序树的查找性能取决于二叉排序树的形状</strong>。</p>
<p>例如{ 62 , 88 , 58 , 47 , 35 , 73 , 51 , 99 , 37 , 93 }
{62,88,58,47,35,73,51,99,37,93}{62,88,58,47,35,73,51,99,37,93}这样的数组，我们可以构建如下左图的二叉排序树。但如果数组元素的次序是从小到大有序，如{35,37,47,51,58,62,73,88,93,99},则二叉排序树就成了极端的右斜树，如下面右图的二叉排序树：
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/f33a1ebf98e14082fb0df30072964e09.png" alt="f33a1ebf98e14082fb0df30072964e09"></p>
<p>也就是说，我们希望二叉排序树是比较平衡的，即其深度与完全二叉树相同，那么查找的时间复杂也就为<span class="math inline"> <em>O</em>(log<sub>2</sub><em>n</em>)</span>，近似于折半查找。
不平衡的最坏情况就是像上面右图的斜树，查找时间复杂度为O(n)，这等同于顺序查找。
因此，如果我们希望对一个集合按二叉排序树查找，最好是把它构建成一棵<strong>平衡的二叉排序树</strong>。</p>
<h3 id="平衡二叉树">平衡二叉树</h3>
<p><strong>平衡二叉树</strong>：<strong>是一种二叉排序树，其中每一个节点的左子树和右子树的高度差至多等于1。</strong></p>
<p>我们<strong>将二叉树上结点的左子树深度减去右子树深度的值称为平衡因子BF</strong></p>
<p>那么平衡二叉树上所有结点的平衡因子只可能是-1、0和1。只要二叉树上有一个结点的平衡因子的绝对值大于1，则该二叉树就是不平衡的。</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/a1f704e077a99af5d0e5491cfbd18b50.png" alt="a1f704e077a99af5d0e5491cfbd18b50">
<figcaption aria-hidden="true">a1f704e077a99af5d0e5491cfbd18b50</figcaption>
</figure>
<h4 id="平衡二叉树的插入">平衡二叉树的插入</h4>
<p>新结点插入后，若造成查找路径上的某个结点不再平衡，则需要做出相应的调整。可将调整的规律归纳为下列4种情况：</p>
<ol type="1">
<li><strong>LL平衡旋转(右单旋转)</strong>:由于在结点A的左孩子(L)的左子树(L)上插入了新结点</li>
</ol>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/c1f0364ace56db6d49fe314233364370.png" alt="c1f0364ace56db6d49fe314233364370">
<figcaption aria-hidden="true">c1f0364ace56db6d49fe314233364370</figcaption>
</figure>
<ol start="2" type="1">
<li><strong>RR平衡旋转(左单旋转)</strong>:由于在结点A的右孩子(R)的右子树(R)上插入了
新结点</li>
</ol>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/741cd35f51fbb8eab58cd2dbb8988875.png" alt="741cd35f51fbb8eab58cd2dbb8988875">
<figcaption aria-hidden="true">741cd35f51fbb8eab58cd2dbb8988875</figcaption>
</figure>
<ol start="3" type="1">
<li><strong>LR平衡旋转(先左后右双旋转)</strong>:由于在A的左孩子(L)的右子树(R)上插入新结点</li>
</ol>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/53cabfa17150d6a0c98b467098d6379d.png" alt="53cabfa17150d6a0c98b467098d6379d">
<figcaption aria-hidden="true">53cabfa17150d6a0c98b467098d6379d</figcaption>
</figure>
<ol start="4" type="1">
<li><strong>RL平衡旋转(先右后左双旋转)</strong>:由于在A的右孩子(R)的左子树(L)上插入新结点</li>
</ol>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/fcb6dda8bd30d25a55cab887fb332c04.png" alt="fcb6dda8bd30d25a55cab887fb332c04">
<figcaption aria-hidden="true">fcb6dda8bd30d25a55cab887fb332c04</figcaption>
</figure>
<p>举例</p>
<figure>
<img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215152052099.png" alt="image-20241215152052099">
<figcaption aria-hidden="true">image-20241215152052099</figcaption>
</figure>
<h3 id="b树">B树</h3>
<p>B树，又称多路平衡查找树，B树中所有结点的孩子个数的最大值称为B树的阶，通常用m表示。
<strong>B树是所有结点的平衡因子均等于0的多路平衡查找树。</strong></p>
<p>下图所示的B树中所有结点的最大孩子数m = 5，因此它是一棵5阶B树，在m
mm阶B树中结点最多可以有m个孩子。可以借助该实例来分析上述性质： <img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/91938989f25f6c683f053d6b71647591.png" alt="91938989f25f6c683f053d6b71647591"></p>
<p><a href="https://www.bilibili.com/video/BV1JU411d7iY?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">B树(B-树)
- 删除_哔哩哔哩_bilibili</a></p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/Real_Fool_/article/details/114359564">数据结构：查找(Search)【详解】_index.search返回什么结构-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——模式匹配KMP</title>
    <url>/2024/10/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D-KMP/</url>
    <content><![CDATA[<h1 id="数据结构模式匹配kmp">数据结构——模式匹配KMP</h1>
<h2 id="前言">前言</h2>
<p>以前因为惰性，没有记录学习笔记的习惯，但我决定抛弃过去，从现在出发，既要有摒弃过去的决心，又要有继续前进的勇气，悟以往之不谏，知来者之可追。</p>
<h2 id="题目">题目</h2>
<p>对于字符串s，查找是否有子串t，并用字符串m替换</p>
<h2 id="暴力解法bf">暴力解法——BF</h2>
<p>具体操作步骤如下：</p>
<ol type="1">
<li>从文本的第一个字符开始，与模式的第一个字符进行逐一比较。</li>
<li>如果模式的每个字符都与文本中的相应字符匹配，则匹配成功，返回当前匹配的位置。</li>
<li>如果某个字符不匹配，则从文本的下一个字符开始重新进行比较。</li>
<li>重复步骤1-3，直到找到匹配或文本搜索完毕。</li>
</ol>
<p>由于每次比较都要逐一对齐模式串和文本，最坏情况下的时间复杂度是
<strong>O(m * n)</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//编写替换函数</span></span><br><span class="line"><span class="function">string <span class="title">replace</span><span class="params">(string&amp; s, string&amp; t,string&amp; m, <span class="type">int</span> start)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> len1 = s.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len2 = m.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len3 = t.<span class="built_in">length</span>();</span><br><span class="line">	string temp;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; start; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		temp += s[i];</span><br><span class="line">	&#125;</span><br><span class="line">	temp += m;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = start + len3; i &lt; len1; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		temp += s[i];</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFmatching</span><span class="params">(string &amp;s, string &amp;t, string &amp;m)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> i = <span class="number">0</span>;</span><br><span class="line">	<span class="type">int</span> j = <span class="number">0</span>;</span><br><span class="line">	<span class="type">int</span> len1 = s.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span>  len2 = t.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len3 = m.<span class="built_in">length</span>();</span><br><span class="line">	<span class="keyword">while</span> (i &lt; len1)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (s[i] == t[j])</span><br><span class="line">		&#123;</span><br><span class="line">			i++;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			i = i - j + <span class="number">1</span>;</span><br><span class="line">			j = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> (j &gt;= len2)</span><br><span class="line">		&#123;</span><br><span class="line">			s = <span class="built_in">replace</span>(s, t, m, i - j);</span><br><span class="line">			len1 = s.<span class="built_in">length</span>(); <span class="comment">// 更新字符串的长度</span></span><br><span class="line">			i = i - j + len3;</span><br><span class="line">			j = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="kmp算法">KMP算法</h2>
<h3 id="前缀和后缀">前缀和后缀</h3>
<p>前缀：从字符串的 <strong>第一个字符</strong>
开始的连续子串。前缀的长度可以从0到字符串的总长度减1。注意，前缀不包括整个字符串本身。</p>
<p>后缀：从字符串的 <strong>最后一个字符</strong>
开始的连续子串。与前缀类似，后缀的长度也可以从0到字符串的总长度减1。后缀不包括整个字符串本身。</p>
<p>二者意义：简单来说，就是当前匹配的后缀与前缀相同时，便可以跳过前缀的比较，直接开始后面的比较，而next数组则记录的是最长的既是前缀又是后缀的公共子串的长度，同样也是回溯的位置</p>
<h3 id="next数组的生成">next数组的生成</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">getnext</span><span class="params">(string&amp; t)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> len = t.<span class="built_in">length</span>();</span><br><span class="line">	<span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">next</span><span class="params">(len, <span class="number">0</span>)</span></span>;</span><br><span class="line">	<span class="type">int</span> i= <span class="number">0</span>;<span class="comment">//后缀</span></span><br><span class="line">	<span class="type">int</span> j = <span class="number">0</span>;<span class="comment">//前缀末尾的位置，也是前缀的长度</span></span><br><span class="line">	next[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; len; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">while</span> (j &gt; <span class="number">0</span> &amp;&amp; t[i] != t[j])</span><br><span class="line">		&#123;</span><br><span class="line">			j = next[j - <span class="number">1</span>];</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (t[i] == t[j])</span><br><span class="line">		&#123;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		next[i] = j;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用后缀指针i和前缀指针j，在后缀指针不断向后遍历的过程中：</p>
<ul>
<li>如果可以匹配，则前缀指针i向后移动一位</li>
<li>如果不可以匹配，则前缀指针向前回溯</li>
</ul>
<h3 id="kmp算法的匹配">KMP算法的匹配</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">KMPmatching</span><span class="params">(string&amp; s, string&amp; t, string&amp; m)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	vector&lt;<span class="type">int</span>&gt; next = <span class="built_in">getnext</span>(t);</span><br><span class="line">	<span class="type">int</span> len1 = s.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len2 = t.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len3 = m.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> i = <span class="number">0</span>,j = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">while</span> (i &lt; len1) &#123;</span><br><span class="line">		<span class="keyword">if</span> (s[i] == t[j]) &#123;</span><br><span class="line">			i++;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> (j != <span class="number">0</span>) &#123;</span><br><span class="line">				j = next[j - <span class="number">1</span>];<span class="comment">//向前回溯</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> &#123;</span><br><span class="line">				i++;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 完成匹配后进行替换</span></span><br><span class="line">		<span class="keyword">if</span> (j == len2) &#123;</span><br><span class="line">			s = <span class="built_in">replace</span>(s, t, m, i - j);</span><br><span class="line">			len1 = s.<span class="built_in">length</span>(); <span class="comment">// 更新字符串的长度</span></span><br><span class="line">			i = i - j + m.<span class="built_in">length</span>(); <span class="comment">// 从替换后的新位置继续查找</span></span><br><span class="line">			j = <span class="number">0</span>; <span class="comment">// 重置 j 以重新开始匹配</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="反思">反思</h3>
<p>注意更新<code>s</code>字符串的长度，每次替换后，<code>s</code>字符串都会变化，需要进行更新，否则运行是会造成溢出</p>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1PD4y1o7nd?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">帮你把KMP算法学个通透！（理论篇）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1M5411j7Xx?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">帮你把KMP算法学个通透！（求next数组代码篇）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——矩阵压缩</title>
    <url>/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/</url>
    <content><![CDATA[<h1 id="数据结构矩阵压缩">数据结构——矩阵压缩</h1>
<h2 id="特殊矩阵的压缩">特殊矩阵的压缩</h2>
<h3 id="对称矩阵">对称矩阵</h3>
<p>关键点：</p>
<ul>
<li>是选择上三角行主序存储还是下三角列主序存储</li>
<li>组的下标是从1开始还是0开始存储</li>
</ul>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019163345497.png" alt="image-20241019163345497">
<figcaption aria-hidden="true">image-20241019163345497</figcaption>
</figure>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019163357393.png" alt="image-20241019163357393">
<figcaption aria-hidden="true">image-20241019163357393</figcaption>
</figure>
<h3 id="三件矩阵">三件矩阵</h3>
<p>注意点：</p>
<ul>
<li><p>理解下三角列序和下三角行序的差异，后者是计算<code>a[i][j]</code>后面的元素数量和，再用总数减去后面，得到前面元素数量；前者是直接计算<code>a[i][j]</code>前面元素数量</p></li>
<li><p>一位数组空间为<code>n(n+1)/2+1</code>，数组最后一位为0</p></li>
</ul>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019162703259.png" alt="image-20241019162703259">
<figcaption aria-hidden="true">image-20241019162703259</figcaption>
</figure>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019162719970.png" alt="image-20241019162719970">
<figcaption aria-hidden="true">image-20241019162719970</figcaption>
</figure>
<h3 id="对角矩阵">对角矩阵</h3>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019163805806.png" alt="image-20241019163805806">
<figcaption aria-hidden="true">image-20241019163805806</figcaption>
</figure>
<h2 id="稀疏矩阵的压缩存储">稀疏矩阵的压缩存储</h2>
<h3 id="三元组表">三元组表</h3>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_164539.jpg" alt="IMG_20241019_164539">
<figcaption aria-hidden="true">IMG_20241019_164539</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 用于表示稀疏矩阵中非零元素的结构体</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Triplet</span> &#123;</span><br><span class="line">    <span class="type">int</span> row;</span><br><span class="line">    <span class="type">int</span> col;</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于表示稀疏矩阵的类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SparseMatrix</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> rows;</span><br><span class="line">    <span class="type">int</span> cols;</span><br><span class="line">    vector&lt;Triplet&gt; triplets; </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 构造函数，用于初始化矩阵的维度</span></span><br><span class="line">    <span class="built_in">SparseMatrix</span>(<span class="type">int</span> rows, <span class="type">int</span> cols) : <span class="built_in">rows</span>(rows), <span class="built_in">cols</span>(cols) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加非零元素到矩阵的方法</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">add_element</span><span class="params">(<span class="type">int</span> row, <span class="type">int</span> col, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (value != <span class="number">0</span>) &#123;</span><br><span class="line">            triplets.<span class="built_in">push_back</span>(&#123; row, col, value &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 以三元组形式显示稀疏矩阵的方法</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">display</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; triplet : triplets) &#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;行: &quot;</span> &lt;&lt; triplet.row &lt;&lt; <span class="string">&quot;, 列: &quot;</span> &lt;&lt; triplet.col &lt;&lt; <span class="string">&quot;, 值: &quot;</span> &lt;&lt; triplet.value &lt;&lt; endl;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将稀疏矩阵转换为密集矩阵表示的方法</span></span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">to_dense</span>() <span class="type">const</span> &#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dense_matrix</span>(rows, <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(cols, <span class="number">0</span>));</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; triplet : triplets) &#123;</span><br><span class="line">            dense_matrix[triplet.row][triplet.col] = triplet.value;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dense_matrix;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="朴素转置">朴素转置</h4>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_181951.jpg" alt="IMG_20241019_181951">
<figcaption aria-hidden="true">IMG_20241019_181951</figcaption>
</figure>
<p>因为矩阵A的列是矩阵B的行，所以以此遍历A的列，将其存入新的三元组顺序表</p>
<p>不能直接交换i和j的值的原因：因为三元组表是行优先顺序，如果直接交换就是列优先</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;Triplet&gt; <span class="title">transposeTripletMatrix</span><span class="params">(<span class="type">const</span> vector&lt;Triplet&gt;&amp; tripletMatrix)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取原始三元组矩阵的行数、列数和非零元素个数信息</span></span><br><span class="line">    <span class="type">int</span> rows = tripletMatrix[<span class="number">0</span>].row;</span><br><span class="line">    <span class="type">int</span> cols = tripletMatrix[<span class="number">0</span>].col;</span><br><span class="line">    <span class="type">int</span> numNonZero = tripletMatrix[<span class="number">0</span>].value;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建转置矩阵的三元组顺序表</span></span><br><span class="line">    vector&lt;Triplet&gt; transposedMatrix;</span><br><span class="line">    transposedMatrix.<span class="built_in">push_back</span>(&#123;cols, rows, numNonZero&#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过列的顺序插入非零元素到转置矩阵中</span></span><br><span class="line">    <span class="keyword">if</span> (numNonZero &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> col = <span class="number">0</span>; col &lt; cols; ++col) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= numNonZero; ++i) &#123;</span><br><span class="line">                <span class="keyword">if</span> (tripletMatrix[i].col == col) &#123;</span><br><span class="line">                    transposedMatrix.<span class="built_in">push_back</span>(&#123;tripletMatrix[i].col, tripletMatrix[i].row, tripletMatrix[i].value&#125;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transposedMatrix;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="快速转置">快速转置</h4>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_235512.jpg" alt="IMG_20241019_235512">
<figcaption aria-hidden="true">IMG_20241019_235512</figcaption>
</figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;Triplet&gt; <span class="title">fastTransposeTripletMatrix</span><span class="params">(<span class="type">const</span> vector&lt;Triplet&gt;&amp; tripletMatrix)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取原始三元组矩阵的行数、列数和非零元素个数信息</span></span><br><span class="line">    <span class="type">int</span> rows = tripletMatrix[<span class="number">0</span>].row;</span><br><span class="line">    <span class="type">int</span> cols = tripletMatrix[<span class="number">0</span>].col;</span><br><span class="line">    <span class="type">int</span> numNonZero = tripletMatrix[<span class="number">0</span>].value;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建转置矩阵的三元组顺序表</span></span><br><span class="line">    <span class="function">vector&lt;Triplet&gt; <span class="title">transposedMatrix</span><span class="params">(numNonZero + <span class="number">1</span>)</span></span>;</span><br><span class="line">    transposedMatrix[<span class="number">0</span>] = &#123;cols, rows, numNonZero&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (numNonZero &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 初始化每一列中非零元素的个数和位置</span></span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">count</span><span class="params">(cols, <span class="number">0</span>)</span></span>;</span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">index</span><span class="params">(cols + <span class="number">1</span>, <span class="number">2</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 统计每一列中非零元素的个数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= numNonZero; ++i) &#123;</span><br><span class="line">            count[tripletMatrix[i].col]++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算每一列在转置矩阵中的起始位置</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; cols; ++i) &#123;</span><br><span class="line">            index[i + <span class="number">1</span>] = index[i] + count[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 填充转置矩阵的三元组顺序表</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= numNonZero; ++i) &#123;</span><br><span class="line">            <span class="type">int</span> col = tripletMatrix[i].col;</span><br><span class="line">            <span class="type">int</span> pos = index[col];</span><br><span class="line">            transposedMatrix[pos] = &#123;tripletMatrix[i].col, tripletMatrix[i].row, tripletMatrix[i].value&#125;;</span><br><span class="line">            index[col]++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transposedMatrix;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="十字链表">十字链表</h3>
<figure>
<img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_170755.jpg" alt="IMG_20241019_170755">
<figcaption aria-hidden="true">IMG_20241019_170755</figcaption>
</figure>
<h4 id="定义">定义</h4>
<p>类中定义了两个链表数组，用于存储每一行和每一列的头节点指针</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 节点定义</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">OLNode</span> &#123;</span><br><span class="line">    <span class="type">int</span> row;         <span class="comment">// 行号</span></span><br><span class="line">    <span class="type">int</span> col;         <span class="comment">// 列号</span></span><br><span class="line">    <span class="type">int</span> value;       <span class="comment">// 元素值</span></span><br><span class="line">    OLNode* right;   <span class="comment">// 指向右边的节点</span></span><br><span class="line">    OLNode* down;    <span class="comment">// 指向下面的节点</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">OLNode</span>(<span class="type">int</span> r, <span class="type">int</span> c, <span class="type">int</span> val) : <span class="built_in">row</span>(r), <span class="built_in">col</span>(c), <span class="built_in">value</span>(val), <span class="built_in">right</span>(<span class="literal">nullptr</span>), <span class="built_in">down</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 十字链表类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OrthogonalList</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> rows, cols;</span><br><span class="line">    vector&lt;OLNode*&gt; row_heads; <span class="comment">// 行头链表数组</span></span><br><span class="line">    vector&lt;OLNode*&gt; col_heads; <span class="comment">// 列头链表数组</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="构造函数">构造函数</h4>
<p><code>row_heads.resize(rows, nullptr);</code> 是用于调整
<code>row_heads</code> 向量的大小，使其包含 <code>rows</code>
个元素，并将每个元素初始化为 <code>nullptr</code>。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">OrthogonalList</span>(<span class="type">int</span> rows, <span class="type">int</span> cols) : <span class="built_in">rows</span>(rows), <span class="built_in">cols</span>(cols) &#123;</span><br><span class="line">        row_heads.<span class="built_in">resize</span>(rows, <span class="literal">nullptr</span>);</span><br><span class="line">        col_heads.<span class="built_in">resize</span>(cols, <span class="literal">nullptr</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="插入函数">插入函数</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 插入元素</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(<span class="type">int</span> r, <span class="type">int</span> c, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (value == <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查是否已存在节点，若存在则更新值</span></span><br><span class="line">    OLNode* current = row_heads[r];</span><br><span class="line">    <span class="keyword">while</span> (current &amp;&amp; current-&gt;col &lt; c) &#123;</span><br><span class="line">        current = current-&gt;right;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (current &amp;&amp; current-&gt;col == c) &#123;</span><br><span class="line">        current-&gt;value = value; <span class="comment">// 更新已有节点的值</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OLNode* newNode = <span class="keyword">new</span> <span class="built_in">OLNode</span>(r, c, value);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 插入到行链表中</span></span><br><span class="line">    <span class="keyword">if</span> (!row_heads[r]) &#123;</span><br><span class="line">        <span class="comment">//如果该行没有头节点，则成为该行头节点</span></span><br><span class="line">        row_heads[r] = newNode;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        current = row_heads[r];</span><br><span class="line">        OLNode* prev = <span class="literal">nullptr</span>;</span><br><span class="line">        <span class="comment">//current向下遍历，直到遍历到该行链表的最后一个，或者到达插入的列的位置</span></span><br><span class="line">        <span class="comment">//注意，该插入方式如果遇到该位置已有节点存在的情况，会用新节点覆盖旧节点</span></span><br><span class="line">        <span class="keyword">while</span> (current &amp;&amp; current-&gt;col &lt; c) &#123;</span><br><span class="line">            prev = current;</span><br><span class="line">            current = current-&gt;right;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//若prev存在，则说明头节点不为零，若为空则说明插在链表最前面</span></span><br><span class="line">        <span class="keyword">if</span> (prev) &#123;</span><br><span class="line">            prev-&gt;right = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            row_heads[r] = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        newNode-&gt;right = current;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 插入到列链表中</span></span><br><span class="line">    <span class="keyword">if</span> (!col_heads[c]) &#123;</span><br><span class="line">        col_heads[c] = newNode;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        current = col_heads[c];</span><br><span class="line">        OLNode* prev = <span class="literal">nullptr</span>;</span><br><span class="line">        <span class="keyword">while</span> (current &amp;&amp; current-&gt;row &lt; r) &#123;</span><br><span class="line">            prev = current;</span><br><span class="line">            current = current-&gt;down;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (prev) &#123;</span><br><span class="line">            prev-&gt;down = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            col_heads[c] = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        newNode-&gt;down = current;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="打印函数">打印函数</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">   <span class="comment">// 打印矩阵</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; rows; ++i) &#123;</span><br><span class="line">            OLNode* current = row_heads[i];</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; cols; ++j) &#123;</span><br><span class="line">                <span class="keyword">if</span> (current &amp;&amp; current-&gt;col == j) &#123;</span><br><span class="line">                    cout &lt;&lt; current-&gt;value &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">                    current = current-&gt;right;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    cout &lt;&lt; <span class="string">&quot;0 &quot;</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            cout &lt;&lt; endl;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1WM411A7YQ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【数据结构】特殊矩阵的压缩存储/对称矩阵/三角矩阵/对角矩阵（含经典题讲解）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1a8yKYXELM/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【每个人都听得懂的】稀疏矩阵的快速转置算法_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——线性表</title>
    <url>/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%BA%BF%E6%80%A7%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="数据结构线性表">数据结构——线性表</h1>
<h2 id="线性表的定义">线性表的定义</h2>
<p><strong>线性表（List）：零个或多个数据元素的有限序列。</strong></p>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%BA%BF%E6%80%A7%E8%A1%A8/c8b3abeb72098a922a9ac4f6ff62f563.png" alt="c8b3abeb72098a922a9ac4f6ff62f563">
<figcaption aria-hidden="true">c8b3abeb72098a922a9ac4f6ff62f563</figcaption>
</figure>
<h3 id="顺序存储结构">顺序存储结构</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> SEQLIST_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SEQLIST_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 模板类定义，表示顺序表</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="type">int</span> MaxSize&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SeqList</span> &#123;</span><br><span class="line">    T data[MaxSize];  <span class="comment">// 存储顺序表数据的数组</span></span><br><span class="line">    <span class="type">int</span> length;       <span class="comment">// 顺序表的长度</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<h3 id="链式存储结构">链式存储结构</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> LINKLIST_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LINKLIST_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">    T data;</span><br><span class="line">    Node&lt;T&gt;* next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinkList</span> &#123;</span><br><span class="line">    Node&lt;T&gt;* head;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// LINKLIST_H</span></span></span><br></pre></td></tr></table></figure>
<h2 id="归并排序">归并排序</h2>
<p>[归并排序 |
菜鸟教程](https://www.runoob.com/data-structures/merge-sort.html#:~:text=归并排序（Merge
sort）是建立在归并操作上的一种有效、稳定的排序算法，该算法是采用分治法
(Divide,and Conquer）的一个非常典型的应用。
将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。
若将两个有序表合并成一个有序表，称为二路归并。)</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 友元函数：合并两个有序顺序表</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="type">int</span> MaxSize1, <span class="type">int</span> MaxSize2&gt;</span><br><span class="line"><span class="function">SeqList&lt;T, MaxSize1 + MaxSize2&gt; <span class="title">Merge</span><span class="params">(<span class="type">const</span> SeqList&lt;T, MaxSize1&gt;&amp; list1, <span class="type">const</span> SeqList&lt;T, MaxSize2&gt;&amp; list2)</span> </span>&#123;</span><br><span class="line">    SeqList&lt;T, MaxSize1 + MaxSize2&gt; MergedList;  <span class="comment">// 创建一个新的顺序表</span></span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, n = <span class="number">0</span>;                    <span class="comment">// 定义三个指针，分别表示 list1、list2 和合并表的当前索引</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取两个顺序表的长度</span></span><br><span class="line">    <span class="type">int</span> length1 = list<span class="number">1.l</span>ength;</span><br><span class="line">    <span class="type">int</span> length2 = list<span class="number">2.l</span>ength;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 合并两个有序顺序表</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; length1 &amp;&amp; j &lt; length2) &#123;</span><br><span class="line">        <span class="keyword">if</span> (list<span class="number">1.</span>data[i] &lt;= list<span class="number">2.</span>data[j]) &#123;</span><br><span class="line">            MergedList.data[n++] = list<span class="number">1.</span>data[i++];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            MergedList.data[n++] = list<span class="number">2.</span>data[j++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将 list1 中剩余的元素插入到 MergedList 中</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; length1) &#123;</span><br><span class="line">        MergedList.data[n++] = list<span class="number">1.</span>data[i++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将 list2 中剩余的元素插入到 MergedList 中</span></span><br><span class="line">    <span class="keyword">while</span> (j &lt; length2) &#123;</span><br><span class="line">        MergedList.data[n++] = list<span class="number">2.</span>data[j++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    MergedList.length = n;  <span class="comment">// 设置合并后的顺序表长度</span></span><br><span class="line">    <span class="keyword">return</span> MergedList;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——树和二叉树</title>
    <url>/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/</url>
    <content><![CDATA[<h1 id="树">树</h1>
<h2 id="树的基本术语">树的基本术语</h2>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/d72517fa6b39dc28ff37c0942cda4df1.png" alt="d72517fa6b39dc28ff37c0942cda4df1">
<figcaption aria-hidden="true">d72517fa6b39dc28ff37c0942cda4df1</figcaption>
</figure>
<ol type="1">
<li><p>结点的度和树的度</p>
<p>树中结点的最大度数称为<strong>树的度</strong>。如结点B的度为2,结点D的度为3,树的度为3。</p></li>
<li><p>孩子，双亲，兄弟结点</p></li>
<li><p>路径和路径长度</p>
<p>树中两个结点之间的<strong>路径</strong>是由这两个结点之间所经过的结点序列构成的,而<strong>路径长度</strong>是路径上所经过的边的个数。
注意:由于树中的分支是有向的,即从双亲指向孩子,所以树中的路径是从上向下的,同一双亲的两个孩子之间不存在路径。</p></li>
<li><p>子孙结点和祖先结点</p>
<p>根A到结点K的唯一路径上的任意结点,称为结点K的<strong>祖先</strong>。如结点B是结点K的祖先,而结点K是结点B的<strong>子孙</strong>。</p></li>
<li><p>结点的层次和树的高度</p>
<p><strong>结点的层次</strong>从树根开始定义,根结点为第1层,它的子结点为第2层,以此类推。</p></li>
<li><p>有序树和无序树</p>
<p>树中结点的各子树从左到右是有次序的,不能互换,称该树为<strong>有序树</strong>,否则称为<strong>无序树</strong>。</p></li>
<li><p>森林</p>
<p><strong>森林</strong>是m (m≥0)棵互不相交的树的集合。</p></li>
</ol>
<h2 id="树的存储结构">树的存储结构</h2>
<h3 id="多叉链表表示法">多叉链表表示法</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/fasdfa.png" alt="fasdfa">
<figcaption aria-hidden="true">fasdfa</figcaption>
</figure>
<p>采用多叉链表表示法存储树，许多算法设计可以直接参照二叉树的二叉链表结构的算法。其优点是简单易学，缺点是存在许多指针域的浪费。设树中结点数是n，树的度是k，则共使用了n×k个指针域，而这其中只有n
-1个非空指针城。</p>
<h3 id="孩子链表表示法">孩子链表表示法</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/safsafsxcx.png" alt="safsafsxcx">
<figcaption aria-hidden="true">safsafsxcx</figcaption>
</figure>
<p>当树的度较大时，CTree类可以减少多叉链表表示法的空间浪费。但是，当插入、删除结点时，却会涉及多个孩子链表的调整,还有可能造成存储空间的再分配，因此时间复杂度较大。在CTree类中，利用孩子链表可以方便、快捷地查找指定结点的孩子结点。但是，查找双亲结点则需遍历所有的孩子链表,因此效率就低得多了。</p>
<h3 id="双亲表示法">双亲表示法</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/sadfas.png" alt="sadfas">
<figcaption aria-hidden="true">sadfas</figcaption>
</figure>
<p>在PTree类中，不仅利用结点的双亲指针域很容易找到其双亲结点，而且查找其所有祖先结点也非常便利、高效。若需要查找指定结点的孩子或子孙结点，则需遍历整个树的存储空间，效率就低得多了。</p>
<h3 id="孩子兄弟表示法">孩子兄弟表示法</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/dasfgae.png" alt="dasfgae">
<figcaption aria-hidden="true">dasfgae</figcaption>
</figure>
<p>因为孩子兄弟表示法建立起了树和二叉树之间的对应关系，所以常常将其称为树的二叉树表示法。相比树的其他存储结构，孩子兄弟表示法既简化了结构，又可以将许多二叉树的优秀算法移植到树结构的应用中来，因此具有很好的学习、应用价值。</p>
<h2 id="树的操作算法">树的操作算法</h2>
<h3 id="构造算法">构造算法</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 构造函数</span></span><br><span class="line">    <span class="built_in">CSTree</span>(vector&lt;pair&lt;T, T&gt;&gt;&amp; ps) &#123;</span><br><span class="line">        <span class="keyword">if</span> (ps.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            root = <span class="literal">nullptr</span>;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 创建根节点</span></span><br><span class="line">        root = <span class="keyword">new</span> <span class="built_in">CSNode</span>&lt;T&gt;(ps[<span class="number">0</span>].first);</span><br><span class="line">        root-&gt;firstchild = <span class="literal">nullptr</span>;</span><br><span class="line">        root-&gt;nextsibling = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 插入其他节点</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; ps.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="built_in">InsertNode</span>(ps[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 插入节点</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">InsertNode</span><span class="params">(pair&lt;T, T&gt;&amp; p)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 创建新节点</span></span><br><span class="line">        CSNode&lt;T&gt;* child = <span class="keyword">new</span> <span class="built_in">CSNode</span>&lt;T&gt;(p.second);</span><br><span class="line">        child-&gt;firstchild = <span class="literal">nullptr</span>;</span><br><span class="line">        child-&gt;nextsibling = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到父节点</span></span><br><span class="line">        CSNode&lt;T&gt;* parent = <span class="built_in">Search</span>(root, p.first);</span><br><span class="line">        <span class="keyword">if</span> (!parent) &#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;Parent node &quot;</span> &lt;&lt; p.first &lt;&lt; <span class="string">&quot; not found!&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 若父节点无子节点，将新节点作为第一个子节点</span></span><br><span class="line">        <span class="keyword">if</span> (parent-&gt;firstchild == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            parent-&gt;firstchild = child;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 若父节点已有子节点，将新节点作为最后一个子节点</span></span><br><span class="line">            CSNode&lt;T&gt;* temp = parent-&gt;firstchild;</span><br><span class="line">            <span class="keyword">while</span> (temp-&gt;nextsibling != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                temp = temp-&gt;nextsibling;</span><br><span class="line">            &#125;</span><br><span class="line">            temp-&gt;nextsibling = child;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h3 id="计算树的高度">计算树的高度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计算指定节点子树的高度</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> CSTree&lt;T&gt;::<span class="built_in">Height</span>(CSNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">nullptr</span>)  <span class="comment">// 如果节点为空，返回高度 0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> maxheight = <span class="number">0</span>;  <span class="comment">// 初始化子树的最大高度为 0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历所有子节点</span></span><br><span class="line">    <span class="keyword">for</span> (CSNode&lt;T&gt;* child = p-&gt;firstchild; child != <span class="literal">nullptr</span>; child = child-&gt;nextsibling) &#123;</span><br><span class="line">        <span class="type">int</span> height = <span class="built_in">Height</span>(child);  <span class="comment">// 递归计算子节点的高度</span></span><br><span class="line">        <span class="keyword">if</span> (height &gt; maxheight)      <span class="comment">// 更新最大高度</span></span><br><span class="line">            maxheight = height;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> maxheight + <span class="number">1</span>;  <span class="comment">// 当前节点的高度为子树最大高度 + 1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 外部接口：计算整棵树的高度</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> CSTree&lt;T&gt;::<span class="built_in">Height</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Height</span>(root);  <span class="comment">// 从根节点开始计算高度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="计算所有结点的度">计算所有结点的度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计算指定节点的度并递归处理其子树</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> CSTree&lt;T&gt;::<span class="built_in">Degree</span>(CSNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">nullptr</span>)  <span class="comment">// 如果节点为空，直接返回</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    p-&gt;degree = <span class="number">0</span>;  <span class="comment">// 初始化节点的度为 0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历所有子节点，统计度</span></span><br><span class="line">    <span class="keyword">for</span> (CSNode&lt;T&gt;* child = p-&gt;firstchild; child != <span class="literal">nullptr</span>; child = child-&gt;nextsibling) &#123;</span><br><span class="line">        p-&gt;degree++;  <span class="comment">// 子节点存在则度加 1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Degree</span>(p-&gt;firstchild);    <span class="comment">// 递归处理子节点的度</span></span><br><span class="line">    <span class="built_in">Degree</span>(p-&gt;nextsibling);   <span class="comment">// 递归处理兄弟节点的度</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 外部接口：计算整棵树的所有节点的度</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> CSTree&lt;T&gt;::<span class="built_in">Degree</span>() &#123;</span><br><span class="line">    <span class="built_in">Degree</span>(root);  <span class="comment">// 从根节点开始计算度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="二叉树">二叉树</h1>
<h2 id="特殊的二叉树">特殊的二叉树</h2>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/3ca44306b6c5f97c3544f5d091be9ac4.png" alt="3ca44306b6c5f97c3544f5d091be9ac4">
<figcaption aria-hidden="true">3ca44306b6c5f97c3544f5d091be9ac4</figcaption>
</figure>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/a99ebdd407f8c2508597d85c610c44a7.png" alt="a99ebdd407f8c2508597d85c610c44a7">
<figcaption aria-hidden="true">a99ebdd407f8c2508597d85c610c44a7</figcaption>
</figure>
<h2 id="二叉树的性质">二叉树的性质</h2>
<p>非空二叉树上的叶子结点数等于度为2的结点数加1，即<span class="math inline"> <em>n</em><sub>0</sub> = <em>n</em><sub>1</sub> + 1</span></p>
<p>因为二叉树中所有节点的度只能是 0、1、2，所以节点总数 <span class="math inline"> <em>n</em> = <em>n</em><sub>0</sub> + <em>n</em><sub>1</sub> + <em>n</em><sub>2</sub></span></p>
<p>其次考虑二叉树的分支总数。将二叉树的分支总数记作 m。
因为所有的分支是由度为 1 和度为 2 的节点发出的，所以<span class="math inline"><em>m</em> = <em>n</em><sub>1</sub> + 2 × <em>n</em><sub>2</sub></span></p>
<p>最后，由树的性质 1，可得 <span class="math inline"><em>n</em> = <em>m</em> + 1</span>，即<span class="math inline"><em>n</em><sub>0</sub> + <em>n</em><sub>1</sub> + <em>n</em><sub>2</sub> = <em>n</em><sub>1</sub> + 2 × <em>n</em><sub>2</sub> + 1</span></p>
<h2 id="二叉树的存储结构">二叉树的存储结构</h2>
<h3 id="顺序结构">顺序结构</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/afdfa.png" alt="afdfa">
<figcaption aria-hidden="true">afdfa</figcaption>
</figure>
<p>当二叉树单分支节点较多，高度变化较大时，空间浪费现象惊人</p>
<h3 id="链式结构">链式结构</h3>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/adsfgad.png" alt="adsfgad">
<figcaption aria-hidden="true">adsfgad</figcaption>
</figure>
<h2 id="二叉树的遍历">二叉树的遍历</h2>
<p>前序遍历：根左右</p>
<p>中序遍历：左根右</p>
<p>后序遍历：左右根</p>
<p>先序遍历算法如下</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> BiTree&lt;T&gt;::<span class="built_in">PreOrder</span>(BiNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span>;             <span class="comment">// ① 若二叉树为空，则遍历结束</span></span><br><span class="line">    cout &lt;&lt; p-&gt;data;        <span class="comment">// ② 访问当前结点</span></span><br><span class="line">    <span class="built_in">PreOrder</span>(p-&gt;lchild);    <span class="comment">// ③ 先序遍历当前结点的左子树</span></span><br><span class="line">    <span class="built_in">PreOrder</span>(p-&gt;rchild);    <span class="comment">// ④ 先序遍历当前结点的右子树</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> BiTree&lt;T&gt;::<span class="built_in">PreOrder</span>() &#123;</span><br><span class="line">    <span class="built_in">PreOrder</span>(root);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>层序遍历：利用队列</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> BiTree&lt;T&gt;::<span class="built_in">LevelOrder</span>() &#123;</span><br><span class="line">    <span class="keyword">if</span> (root == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span>;             <span class="comment">// ① 若二叉树为空，则遍历结束</span></span><br><span class="line"></span><br><span class="line">    LinkQueue&lt;BiNode&lt;T&gt;*&gt; Q;    <span class="comment">// 定义一个队列存储节点指针</span></span><br><span class="line">    Q.<span class="built_in">EnQueue</span>(root);            <span class="comment">// ② 将根指针加入指针队列</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!Q.<span class="built_in">Empty</span>()) &#123;        <span class="comment">// ③ 若指针队列不空，则循环</span></span><br><span class="line">        BiNode&lt;T&gt;* p = Q.<span class="built_in">DeQueue</span>();   <span class="comment">// ④ 出队列，得到当前指针 p</span></span><br><span class="line">        cout &lt;&lt; p-&gt;data;              <span class="comment">// ④ 访问当前结点</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// ⑤ 若当前结点有左孩子，则左孩子地址进指针队列</span></span><br><span class="line">        <span class="keyword">if</span> (p-&gt;lchild != <span class="literal">NULL</span>)</span><br><span class="line">            Q.<span class="built_in">EnQueue</span>(p-&gt;lchild);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ⑤ 若当前结点有右孩子，则右孩子地址进指针队列</span></span><br><span class="line">        <span class="keyword">if</span> (p-&gt;rchild != <span class="literal">NULL</span>)</span><br><span class="line">            Q.<span class="built_in">EnQueue</span>(p-&gt;rchild);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二叉树的构造算法">二叉树的构造算法</h2>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/sADF.png" alt="sADF">
<figcaption aria-hidden="true">sADF</figcaption>
</figure>
<p>先序序列是<code>abdecf</code>，带空指针标记的先序序列是<code>abd**e**cf ***</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinNode&lt;T&gt;* BinTree&lt;T&gt;::<span class="built_in">CreateByPre</span>(vector&lt;T&gt;&amp; pre, <span class="type">int</span>&amp; i) &#123;</span><br><span class="line">    T e = pre[i]; <span class="comment">// 提取当前数据</span></span><br><span class="line">    i++;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="string">&#x27;*&#x27;</span>) <span class="comment">// 若是特殊数据，返回空指针</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建新结点</span></span><br><span class="line">    BinNode&lt;T&gt;* p = <span class="keyword">new</span> BinNode&lt;T&gt;;</span><br><span class="line">    p-&gt;data = e;</span><br><span class="line">    <span class="comment">// 创建左子树</span></span><br><span class="line">    p-&gt;lchild = <span class="built_in">CreateByPre</span>(pre, i);</span><br><span class="line">    <span class="comment">// 创建右子树</span></span><br><span class="line">    p-&gt;rchild = <span class="built_in">CreateByPre</span>(pre, i);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinTree&lt;T&gt;::<span class="built_in">BinTree</span>(vector&lt;T&gt;&amp; pre) &#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>; <span class="comment">// 向量 pre 的下标变量</span></span><br><span class="line">    root = <span class="built_in">CreateByPre</span>(pre, i); <span class="comment">// 从先序序列构造二叉树</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二叉树的其他操作算法">二叉树的其他操作算法</h2>
<h3 id="计算结点数">计算结点数</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Count</span>(BiNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// 当前节点为空，返回 0</span></span><br><span class="line">    <span class="type">int</span> left = <span class="built_in">Count</span>(p-&gt;lchild);  <span class="comment">// 统计左子树节点数</span></span><br><span class="line">    <span class="type">int</span> right = <span class="built_in">Count</span>(p-&gt;rchild); <span class="comment">// 统计右子树节点数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> + left + right;      <span class="comment">// 当前节点总数 = 左子树 + 右子树 + 当前节点</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Count</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Count</span>(root); <span class="comment">// 从根节点开始统计</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="计算高度">计算高度</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Height</span>(BiNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// 空节点高度为 0</span></span><br><span class="line">    <span class="type">int</span> left = <span class="built_in">Height</span>(p-&gt;lchild);  <span class="comment">// 左子树高度</span></span><br><span class="line">    <span class="type">int</span> right = <span class="built_in">Height</span>(p-&gt;rchild); <span class="comment">// 右子树高度</span></span><br><span class="line">    <span class="keyword">return</span> (left &gt; right ? left : right) + <span class="number">1</span>; <span class="comment">// 树高度为左右子树最大高度 + 1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Height</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Height</span>(root); <span class="comment">// 从根节点开始计算树高度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="查找结点">查找结点</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinNode&lt;T&gt;* BiTree&lt;T&gt;::<span class="built_in">Search</span>(BinNode&lt;T&gt;* p, T e) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;  <span class="comment">// 查找失败</span></span><br><span class="line">    <span class="keyword">if</span> (p-&gt;data == e)</span><br><span class="line">        <span class="keyword">return</span> p;     <span class="comment">// 查找成功，返回节点指针</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在左子树中递归查找</span></span><br><span class="line">    BinNode&lt;T&gt;* q = <span class="built_in">Search</span>(p-&gt;lchild, e);</span><br><span class="line">    <span class="keyword">if</span> (q != <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> q; <span class="comment">// 若在左子树中找到，返回结果</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在右子树中递归查找</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Search</span>(p-&gt;rchild, e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinNode&lt;T&gt;* BiTree&lt;T&gt;::<span class="built_in">Search</span>(T e) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Search</span>(root, e); <span class="comment">// 从根节点开始查找</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="线索二叉树">线索二叉树</h2>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/asfafs.png" alt="asfafs">
<figcaption aria-hidden="true">asfafs</figcaption>
</figure>
<h1 id="哈夫曼树">哈夫曼树</h1>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/wqqwr.png" alt="wqqwr">
<figcaption aria-hidden="true">wqqwr</figcaption>
</figure>
<figure>
<img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/qetqt.png" alt="qetqt">
<figcaption aria-hidden="true">qetqt</figcaption>
</figure>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://blog.csdn.net/Real_Fool_/article/details/113930623">数据结构：树(Tree)【详解】_数据结构
树-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——类模板</title>
    <url>/2024/10/24/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%B1%BB%E6%A8%A1%E6%9D%BF/</url>
    <content><![CDATA[<h1 id="数据结构类模板">数据结构——类模板</h1>
<h2 id="类模板">类模板</h2>
<p>类模板是一种用于创建通用类的机制，它可以让程序员编写一次类，然后让它适用于<strong>多种数据类型</strong>，在实际编程中非常实用。</p>
<p>优点：使用类模板时，可以为同一个类使用不同的数据类型，这使得代码更加灵活。例如，一个通用的栈类模板可以用于<code>int</code>、<code>double</code>、<code>char</code>等不同类型，而不需要为每种类型分别定义栈类。</p>
<h3 id="定义方式">定义方式</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyStack</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 构造函数、析构函数、入栈、出栈等函数</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    T* data;</span><br><span class="line">    <span class="type">int</span> top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>template</code> 关键字用于声明类模板</p>
<h3 id="函数声明与定义">函数声明与定义</h3>
<h4 id="类内定义">类内定义</h4>
<p>如果是在类内进行函数定义，则不需添加<code>template&lt;&gt;</code>，如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 类模板</span><br><span class="line">template &lt;class T1,class T2&gt;</span><br><span class="line">class Data &#123;</span><br><span class="line">private:</span><br><span class="line">	T1 a;</span><br><span class="line">	T2 b;</span><br><span class="line">public:</span><br><span class="line">	Data(T1 a, T2 b)&#123;</span><br><span class="line">		this-&gt;a = a;</span><br><span class="line">		this-&gt;b = b;</span><br><span class="line">		cout &lt;&lt; &quot;Data的有参构造&quot; &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line">	void showData()</span><br><span class="line">	&#123;</span><br><span class="line">		cout &lt;&lt; a &lt;&lt; &quot; &quot; &lt;&lt; b &lt;&lt;endl;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="类外定义">类外定义</h4>
<p>如果成员函数在类外定义</p>
<ul>
<li>在每个成员函数前必须添加<code>template&lt;&gt;</code>。</li>
<li>作用域需要添加<code>&lt;&gt;</code>修饰。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T1</span>,<span class="keyword">class</span> <span class="title class_">T2</span>&gt;</span><br><span class="line"><span class="type">void</span> Data&lt;T1,T2&gt;::<span class="built_in">showData</span>()</span><br><span class="line">&#123;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="友元函数">友元函数</h4>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//类内声明</span></span><br><span class="line"><span class="function"><span class="keyword">friend</span> <span class="type">void</span> <span class="title">MyPrint</span><span class="params">(Data&lt;T3, T4&gt; &amp;ob)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//类外定义</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T3,<span class="keyword">typename</span> T4&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MyPrint</span><span class="params">(Data&lt;T3, T4&gt; &amp;ob)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	cout &lt;&lt; <span class="string">&quot;函数模板友元：&quot;</span> &lt;&lt; ob.a &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; ob.b &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="模板类分文件书写问题">模板类分文件书写问题</h3>
<h4 id="方案一">方案一</h4>
<p>将类的声明和成员函数的定义全部写在一个.h文件中，如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _DATA_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _DATA_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 类模板</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T1</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Data</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	T1 a;</span><br><span class="line">	T2 b;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">showData</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T1</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt;</span><br><span class="line"><span class="type">void</span> Data&lt;T1, T2&gt;::<span class="built_in">showData</span>()</span><br><span class="line">&#123;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// !_DATA_H_</span></span></span><br></pre></td></tr></table></figure>
<h4 id="方案二">方案二</h4>
<p>若将函数的定义写在.cpp文件中，main.cpp中调用时，一定要同时include”.h”和“.cpp”文件，否则编译错误</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//main.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;Data.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;Data.cpp&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">// 类模板实例化对象</span></span><br><span class="line">	</span><br><span class="line">	<span class="function">Data&lt;<span class="type">int</span>, <span class="type">char</span>&gt; <span class="title">ob2</span><span class="params">(<span class="number">100</span>,<span class="string">&#x27;A&#x27;</span>)</span></span>;</span><br><span class="line">	ob<span class="number">2.</span><span class="built_in">showData</span>();</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/Long_xu/article/details/131500484">【035】深入理解C++类模板（最全讲解）：从基础到实战-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——课设</title>
    <url>/2024/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/</url>
    <content><![CDATA[<h1 id="题目">题目</h1>
<ol type="1">
<li>编程实现希尔、快速、堆排序、归并排序算法。要求随机产生10000个数据存入磁盘文件，然后读入数据文件，分别采用不同的排序方法进行排序，并将结果存入文件中。</li>
<li>N（N&gt;10）个居民区之间需要铺设煤气管道。假设任意两个居民区之间都可以铺设煤气管道，但代价不同。要求事先将任意两个居民区之间铺设煤气管道的代价存入磁盘文件中。设计一个最佳方案使得这N个居民区之间铺设煤气管道所需代价最小，并将结果以图形方式在屏幕上输出。</li>
</ol>
<h1 id="题目一">题目一</h1>
<h2 id="算法思想">算法思想</h2>
<p><strong>希尔排序</strong>：希尔排序是一种基于插入排序的排序算法，通过按一定步长将待排序的元素分组，对每组内的元素进行插入排序，不断缩小步长，最终实现整体排序。希尔排序的时间复杂度依赖于步长的选择，最坏情况下时间复杂度为O(n^2)，最好的情况下接近O(nlogn)。</p>
<p><strong>快速排序</strong>：快速排序是一种分治法思想的排序算法，选择一个基准元素，将待排序的数组分为左右两部分，左侧部分的元素都小于基准元素，右侧部分的元素都大于基准元素，然后分别对左右两部分进行递归排序。时间复杂度为O(nlogn)，最坏情况下为O(n^2)。</p>
<p><strong>堆排序</strong>：堆排序是一种选择排序的改进算法，利用堆数据结构（通常是大顶堆或小顶堆）来找到最大值或最小值，并将其移到数组的末尾，然后调整堆。时间复杂度为O(nlogn)，适合大数据量排序。</p>
<p><strong>归并排序</strong>：归并排序是一种分治法的排序算法，它将待排序的数组分为两部分，分别排序后再合并。时间复杂度为O(nlogn)，且具有稳定性。</p>
<h2 id="程序结构">程序结构</h2>
<ol type="1">
<li><p><strong>数据生成</strong>：程序首先生成10000个随机数并将其存储到文件
<code>data.txt</code> 中。</p></li>
<li><p><strong>排序算法实现</strong>：实现了四种排序算法：希尔排序、快速排序、堆排序和归并排序。</p></li>
<li><p><strong>文件操作</strong>：程序从文件中读取数据，然后使用不同的排序算法对数据进行排序，并将排序结果保存到文件中。</p></li>
</ol>
<h2 id="测试结果">测试结果</h2>
<p>程序组成</p>
<figure>
<img src="/2024/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/sadf.png" alt="sadf">
<figcaption aria-hidden="true">sadf</figcaption>
</figure>
<p>生成数据</p>
<figure>
<img src="/2024/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/sadffac.png" alt="sadffac">
<figcaption aria-hidden="true">sadffac</figcaption>
</figure>
<p>排序结果<img src="/2024/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/dasfxc.png" alt="dasfxc"></p>
<h2 id="收获与体会">收获与体会</h2>
<ul>
<li>实践了不同排序算法的实现，加深了对算法效率和适用场景的理解。</li>
<li>学会了如何操作文件进行数据存储和读取，增强了文件输入输出的处理能力。</li>
</ul>
<h1 id="题目二">题目二</h1>
<h2 id="算法思想描述">算法思想描述</h2>
<p>本题使用了<strong>Kruskal算法</strong>来求解最小生成树。Kruskal算法是一种典型的贪心算法，步骤如下：</p>
<ol type="1">
<li>先将所有的边按照权重排序。</li>
<li>从最小的边开始，逐步加入到生成树中，若加入该边不会形成环，就加入生成树，否则跳过该边。</li>
<li>使用并查集（Union-Find）数据结构来判定是否会形成环。</li>
</ol>
<p>该算法通过选择最小权重的边逐步构建最小生成树，保证了铺设煤气管道的总代价最小。</p>
<h2 id="程序结构-1">程序结构</h2>
<ol type="1">
<li><strong>文件读取</strong>：程序读取包含代价矩阵和节点坐标的文件
<code>costs.txt</code>，并根据这些信息构建图。</li>
<li><strong>并查集实现</strong>：实现了一个并查集数据结构来判断是否形成环。</li>
<li><strong>图形显示</strong>：利用图形库绘制了居民区的分布、各居民区之间的煤气管道代价以及最终的最小生成树。</li>
</ol>
<h2 id="测试结果-1">测试结果</h2>
<p>通过程序实现，成功展示了根据最小生成树算法铺设的煤气管道图形，并显示了连接每个居民区的最小代价路径。图形显示了所有居民区和最小生成树路径的直观效果，确保了程序的正确性和可视化。</p>
<figure>
<img src="/2024/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/asdf.png" alt="asdf">
<figcaption aria-hidden="true">asdf</figcaption>
</figure>
<h2 id="收获与体会-1">收获与体会</h2>
<ul>
<li>通过实现Kruskal算法，深入理解了最小生成树问题以及并查集的使用。</li>
<li>掌握了如何通过图形库展示算法结果，增加了对图论问题的兴趣。</li>
<li>通过实践提高了编程技巧，特别是在图形和图论方面的应用。</li>
</ul>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数字逻辑电路——CMOS逻辑门电路</title>
    <url>/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/</url>
    <content><![CDATA[<h1 id="数字逻辑电路cmos逻辑门电路">数字逻辑电路——CMOS逻辑门电路</h1>
<h2 id="mos管">MOS管</h2>
<p>MOSFET全称金属-氧化物-半导体场效应三极管</p>
<p>从载流子极性来看，分为<strong>NMOS（电子型）管</strong>和<strong>PMOS（空穴型）管</strong>两种</p>
<p>按照导电机制的不同，MOS管又可以分为<strong>增强型</strong>和<strong>耗尽型</strong></p>
<p>因此MOSFET共有四种：E型NMOS管、D型NMOS管、E型PMOS管、D型PMOS管</p>
<h3 id="nmos和pmos区别">NMOS和PMOS区别</h3>
<p>MOS管的管脚有三个：<strong>源极S（source）、栅极G（Gate）和漏极（Drain）</strong></p>
<p>MOS管有两种：<strong>一个是PMOS管，一个是NMOS管</strong>；PMOS管就是positive管，是积极的管，而NMOS管是negative管，是消极的管。积极的管就是顺应潮流，顺势而为；消极的管就是违背趋势，逆流而上。
很显然，电流从源极（输入端）到漏极（输出端），那就是顺势而为，因为源极就是源头嘛，因此这种管就是PMOS管；而电流要是从漏极（输入端）到源极（输出端），那就是逆流而上，是NMOS管。</p>
<p>判定是N沟道MOS还是P沟道MOS： <strong>箭头指向G极的是N沟道
箭头背向G极的是P沟道</strong></p>
<p>从导通特性上区分：</p>
<p>NMOS：当电压高于阈值电压<strong>可以导通</strong>；当电压低于阈值电压<strong>不能导通</strong></p>
<p>PMOS：当电压高于阈值电压<strong>不能导通</strong>；当电压低于阈值电压<strong>可以导通</strong></p>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/22e26add55da2a09c803a6ed67ee4777.png" alt="22e26add55da2a09c803a6ed67ee4777">
<figcaption aria-hidden="true">22e26add55da2a09c803a6ed67ee4777</figcaption>
</figure>
<h3 id="增强型和耗尽型的区别">增强型和耗尽型的区别</h3>
<p>以<strong>NMOS管</strong>为例：</p>
<p>当<span class="math inline"> <em>V</em><sub><em>G</em><em>S</em></sub> = 0</span>时没有导电沟道，需要依靠<span class="math inline"> <em>V</em><sub><em>G</em><em>S</em></sub></span>的作用才能产生导电沟道，称为<strong>增强型FET</strong>。</p>
<p>当<span class="math inline"> <em>V</em><sub><em>G</em><em>S</em></sub> = 0</span>时有导电沟道，需要依靠<span class="math inline"> <em>V</em><sub><em>G</em><em>S</em></sub></span>的作用是削弱导电沟道，称为<strong>耗尽型FET</strong>。</p>
<h2 id="cmos逻辑门电路">CMOS逻辑门电路</h2>
<p>由<code>N</code>沟道和<code>P</code>沟道增强型<code>MOS</code>管组成的电路称为互补<code>MOS</code>或<code>CMOS</code>电路。</p>
<h3 id="非门">非门</h3>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/57F%5BQXP6AT6LH8KOVH4CIQ.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="或门和或非门">或门和或非门</h3>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/4.png" alt="4">
<figcaption aria-hidden="true">4</figcaption>
</figure>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/G%WO3%5DUHOQB5%7BDKEJ571A7.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="与门和与非门">与门和与非门</h3>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/5.png" alt="5">
<figcaption aria-hidden="true">5</figcaption>
</figure>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/7.png" alt="7">
<figcaption aria-hidden="true">7</figcaption>
</figure>
<h3 id="异或门和同或门">异或门和同或门</h3>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<figure>
<img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/2.png" alt="2">
<figcaption aria-hidden="true">2</figcaption>
</figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1nL411x7jH?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">【硬核科普】带你认识CPU第00期——什么是MOSFET_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV18M4y137Cr?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">【硬核科普】带你认识CPU第01期——什么是逻辑门_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/weixin_43491077/article/details/109721185">NMOS管与PMOS管的区别与总结_pmos和nmos的区别-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数字逻辑电路</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>数字逻辑电路</tag>
      </tags>
  </entry>
  <entry>
    <title>数字逻辑电路——数电实验1</title>
    <url>/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/</url>
    <content><![CDATA[<h1 id="实验1-门电路逻辑功能测试">实验1 门电路逻辑功能测试</h1>
<h2 id="内容一与非门和异或门逻辑功能的测试">内容一：与非门和异或门逻辑功能的测试</h2>
<h3 id="ls20双4输入与非门逻辑功能测试">74LS20双4输入与非门逻辑功能测试</h3>
<p>74LS20功能：<strong>四输入双与非门</strong>，其内部结构及真值表如图</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/1ac35b0a8f06411f05cc80a49ec9c700.png" alt="1ac35b0a8f06411f05cc80a49ec9c700">
<figcaption aria-hidden="true">1ac35b0a8f06411f05cc80a49ec9c700</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/1.png" alt="1">
<figcaption aria-hidden="true">1</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">C</th>
<th style="text-align: center;">D</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>全1出0，有0出1</p>
<h3 id="ls86四2输入异或门逻辑功能测试">74LS86四2输入异或门逻辑功能测试</h3>
<p>74LS86功能：<strong>二输入端四异或门</strong>，其内部结构及真值表如图</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/a74b68814db1d802db338a7b636a523e.png" alt="a74b68814db1d802db338a7b636a523e">
<figcaption aria-hidden="true">a74b68814db1d802db338a7b636a523e</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/6-1730557274344-12.png" alt="6">
<figcaption aria-hidden="true">6</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<h2 id="内容二根据电路图写出逻辑关系表达式">内容二：根据电路图写出逻辑关系表达式</h2>
<h3 id="用74ls00按图接线将输入输出逻辑关系分别填入表中">用74LS00按图接线，将输入输出逻辑关系分别填入表中。</h3>
<p>74LS00功能：<strong>二输入端四与非门</strong>，其内部结构及真值表如图</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/4.png" alt="4">
<figcaption aria-hidden="true">4</figcaption>
</figure>
<p>题目如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/564.png" alt="564">
<figcaption aria-hidden="true">564</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/44.png" alt="44">
<figcaption aria-hidden="true">44</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/546.png" alt="546">
<figcaption aria-hidden="true">546</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">Y</th>
<th style="text-align: center;">Z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<h3 id="写出两个电路逻辑表达式">写出两个电路逻辑表达式</h3>
<p>电路逻辑表达式为<span class="math inline"> <em>Ā</em><em>B</em> + <em>B̄</em><em>A</em></span></p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/DSFDSG.png" alt="DSFDSG">
<figcaption aria-hidden="true">DSFDSG</figcaption>
</figure>
<p>电路逻辑表达式为<span class="math inline"> <em>Y</em> = <em>Ā</em><em>B</em> + <em>B̄</em><em>A</em></span>
<span class="math inline"> <em>Z</em> = <em>A</em><em>B</em></span></p>
<h2 id="内容三利用与非门控制输出">内容三：利用与非门控制输出</h2>
<h3 id="用一片74ls00按图接线s接任一电平开关用示波器观察s对输出脉冲的控制作用">用一片74LS00按图接线，S接任一电平开关，用示波器观察S对输出脉冲的控制作用</h3>
<h3 id="第一题">第一题</h3>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/4552.png" alt="4552">
<figcaption aria-hidden="true">4552</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/456.png" alt="456">
<figcaption aria-hidden="true">456</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/284.png" alt="284">
<figcaption aria-hidden="true">284</figcaption>
</figure>
<h3 id="第二题">第二题</h3>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/SAD.png" alt="SAD">
<figcaption aria-hidden="true">SAD</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/VX.png" alt="VX">
<figcaption aria-hidden="true">VX</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/GS.png" alt="GS">
<figcaption aria-hidden="true">GS</figcaption>
</figure>
<h2 id="内容四用与非门组成其它门电路并测试验证">内容四：用与非门组成其它门电路并测试验证</h2>
<h3 id="第一题组成或非门">第一题：组成或非门</h3>
<p>用一片2输入端四与非门组成或非门</p>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/dsaf.png" alt="dsaf">
<figcaption aria-hidden="true">dsaf</figcaption>
</figure>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<h3 id="第二题组成异或门">第二题：组成异或门</h3>
<p>同内容二</p>
<h2 id="内容五逻辑门传输延迟时间的测量">内容五：逻辑门传输延迟时间的测量</h2>
<p>用六反相器（非门）按图接线，输入200KHz连续脉冲，用双踪示波器测量输入、输出相位差，计算每个门的平均传输延迟时间的值。</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/asdfa.png" alt="asdfa">
<figcaption aria-hidden="true">asdfa</figcaption>
</figure>
<p>74LS04功能：<strong>六反相器</strong>，其内部结构及真值表如图</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/sad-1730613828885-37.png" alt="sad">
<figcaption aria-hidden="true">sad</figcaption>
</figure>
<p>电路图如下</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/sads.png" alt="sads">
<figcaption aria-hidden="true">sads</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/afdga.png" alt="afdga">
<figcaption aria-hidden="true">afdga</figcaption>
</figure>
<h2 id="内容六用基本门电路组装一个译码电路将bcd8421码转换成格雷码">内容六：用基本门电路组装一个译码电路：将BCD8421码转换成格雷码</h2>
<p>BCD8421码：二进制编码的十进制数，简称BCD码</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/t0131751fc49c1edcb4.png" alt="t0131751fc49c1edcb4">
<figcaption aria-hidden="true">t0131751fc49c1edcb4</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/63d335349be6acd1189581d69870bd56.png" alt="63d335349be6acd1189581d69870bd56">
<figcaption aria-hidden="true">63d335349be6acd1189581d69870bd56</figcaption>
</figure>
<p>一位不产生进位的加法电路用<a href="https://so.csdn.net/so/search?q=异或门&amp;spm=1001.2101.3001.7020">异或门</a>就可以实现，下图左边为一个二进制-格雷码转换器器，右边为一个格雷码-二进制码转换器。</p>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/353484a62261823731307a1969c8278e.png" alt="353484a62261823731307a1969c8278e">
<figcaption aria-hidden="true">353484a62261823731307a1969c8278e</figcaption>
</figure>
<figure>
<img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/sadsfdf.png" alt="sadsfdf">
<figcaption aria-hidden="true">sadsfdf</figcaption>
</figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://blog.csdn.net/qq_41628475/article/details/136149964">数字电路逻辑与设计实验一
门电路逻辑功能及测试_数电实验-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数字逻辑电路</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>数字逻辑电路</tag>
      </tags>
  </entry>
  <entry>
    <title>实习日志——7.8</title>
    <url>/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/</url>
    <content><![CDATA[<h3 id="工作汇总">工作汇总</h3>
<h4 id="vscode连接远程服务器">vscode连接远程服务器</h4>
<ol type="1">
<li>输入 ssh root@10.117.128.50</li>
<li>输入密码 think123@</li>
</ol>
<h5 id="使用旧版remotessh">使用旧版remotessh</h5>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/image-20250708104452761.png" alt="image-20250708104452761">
<figcaption aria-hidden="true">image-20250708104452761</figcaption>
</figure>
<blockquote>
<p>原因：可能因为内网，服务器那边没有进行更新，所以新版的remotessh无法连接</p>
<p>其他问题：可能由于上述原因，trae也无法连接，并且由于trae的远程连接插件无法更改版本，因此无法使用</p>
</blockquote>
<h5 id="虚拟环境创建">虚拟环境创建</h5>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/image-20250708104254347.png" alt="image-20250708104254347">
<figcaption aria-hidden="true">image-20250708104254347</figcaption>
</figure>
<h4 id="git连接远程仓库">git连接远程仓库</h4>
<p>初始化仓库：<code>git init</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 添加所有文件到暂存区</span><br><span class="line">git add .</span><br><span class="line"></span><br><span class="line"># 提交更改</span><br><span class="line">git commit -m &quot;Initial commit&quot;</span><br><span class="line"></span><br><span class="line">#上传远程库</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr class="header">
<th>目标</th>
<th>命令</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>查看远程仓库</td>
<td><code>git remote -v</code></td>
</tr>
<tr class="even">
<td>修改远程仓库地址</td>
<td><code>git remote set-url origin &lt;新地址&gt;</code></td>
</tr>
<tr class="odd">
<td>添加新远程仓库（不同名）</td>
<td><code>git remote add upstream &lt;新地址&gt;</code></td>
</tr>
<tr class="even">
<td>删除远程仓库</td>
<td><code>git remote remove origin</code></td>
</tr>
<tr class="odd">
<td>添加第一个远程仓库</td>
<td><code>git remote add origin</code></td>
</tr>
</tbody>
</table>
<blockquote>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/image-20250708151320868.png" alt="image-20250708151320868">
<figcaption aria-hidden="true">image-20250708151320868</figcaption>
</figure>
<p>当前存在连接超时问题，可能是服务器连接的原因</p>
</blockquote>
<h4 id="mineru部署情况">mineru部署情况</h4>
<figure>
<img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/1a9954d6-31d7-404a-9419-cd9a87c9ee09.png" alt="1a9954d6-31d7-404a-9419-cd9a87c9ee09">
<figcaption aria-hidden="true">1a9954d6-31d7-404a-9419-cd9a87c9ee09</figcaption>
</figure>
<p>通过调整docker镜像源，可以拉取基础镜像了，但是遇到<code>RUN apt-get update &amp;&amp; apt-get install -y libgl1 &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*</code>第二部命令再次出现网络问题</p>
<h3 id="未来工作计划">未来工作计划</h3>
<ul class="task-list">
<li><label><input type="checkbox" checked>部署MinerU</label></li>
<li><label><input type="checkbox">检索方式的调研与学习：BM25等</label></li>
<li><label><input type="checkbox" checked>chunking策略的调研</label></li>
</ul>
<p>vlm slglang</p>
<p>rag评估</p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——决策树</title>
    <url>/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h2 id="正文">正文</h2>
<h2 id="作业">作业</h2>
<h3 id="什么是信息增益根据下图分别计算按照属性a和b划分时的信息增益id3决策树学习算法将会选择哪个属性">什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/hw_h_82p6lenbyhkws867e413c0614d3.png" alt="hw_h_82p6lenbyhkws867e413c0614d3">
<figcaption aria-hidden="true">hw_h_82p6lenbyhkws867e413c0614d3</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153252.jpg" alt="IMG_20250329_153252">
<figcaption aria-hidden="true">IMG_20250329_153252</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153259.jpg" alt="IMG_20250329_153259">
<figcaption aria-hidden="true">IMG_20250329_153259</figcaption>
</figure>
<h3 id="什么是交叉验证法有什么用途">什么是交叉验证法？有什么用途？</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153307.jpg" alt="IMG_20250329_153307">
<figcaption aria-hidden="true">IMG_20250329_153307</figcaption>
</figure>
<h3 id="什么是过拟合overfitting什么情况下可能发生过拟合采取什么措施有助于消除过拟合">什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153310.jpg" alt="IMG_20250329_153310">
<figcaption aria-hidden="true">IMG_20250329_153310</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>最优化方法——期末复习</title>
    <url>/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/</url>
    <content><![CDATA[<p><a href="https://www.bilibili.com/video/BV1uP411K7Hf?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">最优化理论与方法-对偶线性规划（例题分析）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>最优化方法</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>最优化方法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——支持向量机</title>
    <url>/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<h2 id="正文">正文</h2>
<p>下面我将为你详细解释KKT（Karush-Kuhn-Tucker）条件。KKT条件是优化理论中用于求解带约束非线性规划问题的一组必要条件，广泛应用于支持向量机（SVM）等机器学习算法中。我会使用内联数学公式（如
<span class="math display"><em>f</em>(<strong>x</strong>)</span>）来展示相关表达式。</p>
<hr>
<h3 id="优化问题的一般形式">1. 优化问题的一般形式</h3>
<p>我们考虑一个带有约束的优化问题，数学形式如下： - 目标：<span class="math display">min<sub><strong>x</strong></sub><em>f</em>(<strong>x</strong>)</span>
- 不等式约束：<span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) ≤ 0</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>m</em></span> -
等式约束：<span class="math display"><em>h</em><sub><em>j</em></sub>(<strong>x</strong>) = 0</span>，其中
<span class="math display"><em>j</em> = 1, 2, …, <em>p</em></span></p>
<p>这里： - <span class="math display"><em>f</em>(<strong>x</strong>)</span>
是目标函数，通常是我们希望最小化的函数。 - <span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) ≤ 0</span>
表示 <span class="math display"><em>m</em></span> 个不等式约束。 - <span class="math display"><em>h</em><sub><em>j</em></sub>(<strong>x</strong>) = 0</span>
表示 <span class="math display"><em>p</em></span> 个等式约束。</p>
<p>KKT条件的目标是找到满足这些约束的局部最优解 <span class="math display"><strong>x</strong></span>。</p>
<hr>
<h3 id="拉格朗日函数">2. 拉格朗日函数</h3>
<p>为了引入KKT条件，我们首先定义拉格朗日函数： <span class="math display">$$\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda},
\boldsymbol{\mu}) = f(\mathbf{x}) + \sum_{i=1}^{m} \lambda_i
g_i(\mathbf{x}) + \sum_{j=1}^{p} \mu_j h_j(\mathbf{x})$$</span></p>
<p>其中： - <span class="math display"><strong>λ</strong> = (<em>λ</em><sub>1</sub>,<em>λ</em><sub>2</sub>,…,<em>λ</em><sub><em>m</em></sub>)</span>
是与不等式约束 <span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) ≤ 0</span>
对应的拉格朗日乘子。 - <span class="math display"><strong>μ</strong> = (<em>μ</em><sub>1</sub>,<em>μ</em><sub>2</sub>,…,<em>μ</em><sub><em>p</em></sub>)</span>
是与等式约束 <span class="math display"><em>h</em><sub><em>j</em></sub>(<strong>x</strong>) = 0</span>
对应的拉格朗日乘子。</p>
<p>拉格朗日函数将目标函数和约束条件结合在一起，通过引入乘子 <span class="math display"><em>λ</em><sub><em>i</em></sub></span> 和 <span class="math display"><em>μ</em><sub><em>j</em></sub></span>
来平衡约束对优化的影响。</p>
<hr>
<h3 id="kkt条件的组成部分">3. KKT条件的组成部分</h3>
<p>KKT条件由以下四个部分组成，只有当某些正则性条件（如Slater条件）满足时，局部最优解
<span class="math display"><strong>x</strong></span>
才会同时满足这些条件。以下是具体的KKT条件：</p>
<h4 id="梯度条件stationarity">3.1 梯度条件（Stationarity）</h4>
<p>拉格朗日函数对 <span class="math display"><strong>x</strong></span>
的梯度必须为零，即： <span class="math display">$$\nabla_{\mathbf{x}}
\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = \nabla
f(\mathbf{x}) + \sum_{i=1}^{m} \lambda_i \nabla g_i(\mathbf{x}) +
\sum_{j=1}^{p} \mu_j \nabla h_j(\mathbf{x}) = 0$$</span></p>
<p>这意味着在最优解处，目标函数的梯度可以通过约束函数梯度的线性组合来表示。</p>
<h4 id="原始可行性primal-feasibility">3.2 原始可行性（Primal
Feasibility）</h4>
<p>解 <span class="math display"><strong>x</strong></span>
必须满足原始问题的所有约束： - 不等式约束：<span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) ≤ 0</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>m</em></span> -
等式约束：<span class="math display"><em>h</em><sub><em>j</em></sub>(<strong>x</strong>) = 0</span>，其中
<span class="math display"><em>j</em> = 1, 2, …, <em>p</em></span></p>
<p>这确保了解仍在问题的可行域内。</p>
<h4 id="对偶可行性dual-feasibility">3.3 对偶可行性（Dual
Feasibility）</h4>
<p>对于不等式约束对应的拉格朗日乘子，必须满足： <span class="math display"><em>λ</em><sub><em>i</em></sub> ≥ 0</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>m</em></span></p>
<p>这表明不等式约束的乘子非负，反映了约束对优化方向的影响。</p>
<h4 id="互补松弛条件complementary-slackness">3.4
互补松弛条件（Complementary Slackness）</h4>
<p>对于每个不等式约束，乘子与约束函数的乘积必须为零： <span class="math display"><em>λ</em><sub><em>i</em></sub><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) = 0</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>m</em></span></p>
<p>这意味着： - 如果某个约束不“紧”（即 <span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) &lt; 0</span>），则对应的乘子
<span class="math display"><em>λ</em><sub><em>i</em></sub> = 0</span>。
- 如果 <span class="math display"><em>λ</em><sub><em>i</em></sub> &gt; 0</span>，则该约束必须是“紧”的（即
<span class="math display"><em>g</em><sub><em>i</em></sub>(<strong>x</strong>) = 0</span>）。</p>
<hr>
<h3 id="kkt条件的意义">4. KKT条件的意义</h3>
<ul>
<li><strong>梯度条件</strong>：表明最优解处目标函数的改变方向被约束完全平衡。</li>
<li><strong>原始可行性</strong>：确保解满足所有约束条件。</li>
<li><strong>对偶可行性</strong>：限制拉格朗日乘子的符号，保证优化方向的合理性。</li>
<li><strong>互补松弛条件</strong>：揭示哪些约束在最优解处起作用（紧约束），哪些不起作用。</li>
</ul>
<hr>
<h3 id="kkt条件在svm中的应用示例">5. KKT条件在SVM中的应用示例</h3>
<p>KKT条件在支持向量机（SVM）中尤为重要。SVM的原始优化问题为： -
目标：<span class="math display">$$\min_{\mathbf{w}, b} \frac{1}{2}
\|\mathbf{w}\|^2$$</span> - 约束：<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong>⋅<strong>x</strong><sub><em>i</em></sub>+<em>b</em>) ≥ 1</span>，其中
<span class="math display"><em>i</em> = 1, 2, …, <em>n</em></span></p>
<p>将其改写为标准形式的不等式约束：<span class="math display">1 − <em>y</em><sub><em>i</em></sub>(<strong>w</strong>⋅<strong>x</strong><sub><em>i</em></sub>+<em>b</em>) ≤ 0</span>。</p>
<p>拉格朗日函数为： <span class="math display">$$\mathcal{L}(\mathbf{w},
b, \boldsymbol{\alpha}) = \frac{1}{2} \|\mathbf{w}\|^2 + \sum_{i=1}^{n}
\alpha_i \left[ 1 - y_i (\mathbf{w} \cdot \mathbf{x}_i + b)
\right]$$</span></p>
<p>应用KKT条件： 1. <strong>梯度条件</strong>： - 对 <span class="math display"><strong>w</strong></span>：<span class="math display">$$\nabla_{\mathbf{w}} \mathcal{L} = \mathbf{w} -
\sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i = 0$$</span> - 对 <span class="math display"><em>b</em></span>：<span class="math display">$$\frac{\partial \mathcal{L}}{\partial b} =
-\sum_{i=1}^{n} \alpha_i y_i = 0$$</span> 2.
<strong>原始可行性</strong>：<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong>⋅<strong>x</strong><sub><em>i</em></sub>+<em>b</em>) ≥ 1</span>
3. <strong>对偶可行性</strong>：<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span> 4.
<strong>互补松弛条件</strong>：<span class="math display"><em>α</em><sub><em>i</em></sub>[<em>y</em><sub><em>i</em></sub>(<strong>w</strong>⋅<strong>x</strong><sub><em>i</em></sub>+<em>b</em>)−1] = 0</span></p>
<p>这些条件帮助我们识别支持向量（<span class="math display"><em>α</em><sub><em>i</em></sub> &gt; 0</span>
的点）并求解最优的 <span class="math display"><strong>w</strong></span>
和 <span class="math display"><em>b</em></span>。</p>
<hr>
<h3 id="总结">6. 总结</h3>
<p>KKT条件是求解带约束优化问题的核心工具，它通过梯度条件、原始可行性、对偶可行性和互补松弛条件，确保了解既是最优的，又满足所有约束。在机器学习中，KKT条件为SVM等算法提供了理论支持，是理解和实现这些模型的关键。</p>
<h3 id="作业">作业</h3>
<h4 id="关于支持向量机推导目标函数的原始问题转换为对偶问题的过程和条件使用拉格朗日乘子法">关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）</h4>
<figure>
<img src="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/IMG_20250416_164811.jpg" alt="IMG_20250416_164811">
<figcaption aria-hidden="true">IMG_20250416_164811</figcaption>
</figure>
<p>下面我们将推导支持向量机（SVM）中目标函数从原始问题转换为对偶问题的过程和条件，使用拉格朗日乘子法。我们将一步步展开，确保推导清晰且完整。</p>
<hr>
<h3 id="原始问题">1. 原始问题</h3>
<p>支持向量机（SVM）的目标是找到一个超平面，能够最大化到最近数据点的间隔。对于线性可分的情况，原始优化问题可以定义为：</p>
<ul>
<li><p><strong>目标函数</strong>：<br>
<span class="math display">$$\min_{\mathbf{w}, b} \frac{1}{2}
\|\mathbf{w}\|^2$$</span></p></li>
<li><p><strong>约束条件</strong>：<br>
<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong>⋅<strong>x</strong><sub><em>i</em></sub>+<em>b</em>) ≥ 1,  <em>i</em> = 1, 2, …, <em>n</em></span></p></li>
</ul>
<p>其中： - <span class="math display"><strong>w</strong></span>
是超平面的法向量； - <span class="math display"><em>b</em></span>
是超平面的截距； - <span class="math display"><strong>x</strong><sub><em>i</em></sub></span>
是训练样本，<span class="math display"><em>y</em><sub><em>i</em></sub> ∈ { − 1, 1}</span>
是对应的类别标签； - <span class="math display">∥<strong>w</strong>∥<sup>2</sup></span>
表示法向量的平方范数，目标是最小化它以最大化间隔； -
约束条件确保所有样本点被正确分类，并且到超平面的归一化距离至少为 1。</p>
<hr>
<h3 id="引入拉格朗日乘子法">2. 引入拉格朗日乘子法</h3>
<p>由于这是一个带不等式约束的优化问题，我们使用拉格朗日乘子法将其转换为无约束形式。引入拉格朗日乘子
<span class="math display"><strong>α</strong> = (<em>α</em><sub>1</sub>,<em>α</em><sub>2</sub>,…,<em>α</em><sub><em>n</em></sub>)</span>，其中
<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span>，构造拉格朗日函数：</p>
<p><span class="math display">$$\mathcal{L}(\mathbf{w}, b,
\boldsymbol{\alpha}) = \frac{1}{2} \|\mathbf{w}\|^2 - \sum_{i=1}^{n}
\alpha_i \left[ y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1
\right]$$</span></p>
<ul>
<li>第一项 <span class="math display">$$\frac{1}{2}
\|\mathbf{w}\|^2$$</span> 是原始目标函数；</li>
<li>第二项 <span class="math display">$$-\sum_{i=1}^{n} \alpha_i \left[
y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 \right]$$</span>
将约束条件引入，由于是 <span class="math display">≥</span> 不等式，乘子
<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span>。</li>
</ul>
<p>我们的目标是通过拉格朗日函数，将原始问题转换为对偶问题。</p>
<hr>
<h3 id="转换为对偶问题">3. 转换为对偶问题</h3>
<p>对偶问题的核心思想是：先对 <span class="math display"><strong>w</strong></span> 和 <span class="math display"><em>b</em></span> 求拉格朗日函数的极小值，然后对
<span class="math display"><strong>α</strong></span> 求极大值。即：</p>
<p><span class="math display">max<sub><strong>α</strong> ≥ 0</sub>min<sub><strong>w</strong>, <em>b</em></sub>ℒ(<strong>w</strong>,<em>b</em>,<strong>α</strong>)</span></p>
<h4 id="对-mathbfw-和-b-求偏导">3.1 对 <span class="math display"><strong>w</strong></span> 和 <span class="math display"><em>b</em></span> 求偏导</h4>
<p>为了找到 <span class="math display">ℒ</span> 关于 <span class="math display"><strong>w</strong></span> 和 <span class="math display"><em>b</em></span>
的极小值，分别求偏导并令其为零：</p>
<ul>
<li><p>对 <span class="math display"><strong>w</strong></span>
求偏导：<br>
<span class="math display">$$\frac{\partial \mathcal{L}}{\partial
\mathbf{w}} = \mathbf{w} - \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i =
0$$</span><br>
解得：<br>
<span class="math display">$$\mathbf{w} = \sum_{i=1}^{n} \alpha_i y_i
\mathbf{x}_i$$</span></p></li>
<li><p>对 <span class="math display"><em>b</em></span> 求偏导：<br>
<span class="math display">$$\frac{\partial \mathcal{L}}{\partial b} =
-\sum_{i=1}^{n} \alpha_i y_i = 0$$</span><br>
解得：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i =
0$$</span></p></li>
</ul>
<p>这两个结果是后续推导的关键。</p>
<h4 id="代入拉格朗日函数">3.2 代入拉格朗日函数</h4>
<p>将 <span class="math display">$$\mathbf{w} = \sum_{i=1}^{n} \alpha_i
y_i \mathbf{x}_i$$</span> 代入拉格朗日函数，并利用 <span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i = 0$$</span>
简化：</p>
<p><span class="math display">$$\mathcal{L} = \frac{1}{2} \left\|
\sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \right\|^2 - \sum_{i=1}^{n}
\alpha_i \left[ y_i \left( \left( \sum_{j=1}^{n} \alpha_j y_j
\mathbf{x}_j \right) \cdot \mathbf{x}_i + b \right) - 1
\right]$$</span></p>
<ul>
<li><p>计算第一项：<br>
<span class="math display">$$\left\| \sum_{i=1}^{n} \alpha_i y_i
\mathbf{x}_i \right\|^2 = \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i
\alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)$$</span></p></li>
<li><p>计算第二项中的内积部分：<br>
<span class="math display">$$y_i \left( \sum_{j=1}^{n} \alpha_j y_j
\mathbf{x}_j \right) \cdot \mathbf{x}_i = y_i \sum_{j=1}^{n} \alpha_j
y_j (\mathbf{x}_j \cdot \mathbf{x}_i)$$</span><br>
所以：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i \left(
\sum_{j=1}^{n} \alpha_j y_j (\mathbf{x}_j \cdot \mathbf{x}_i) \right) =
\sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i
\cdot \mathbf{x}_j)$$</span></p></li>
<li><p>考虑 <span class="math display"><em>b</em></span> 项：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i b = b
\sum_{i=1}^{n} \alpha_i y_i = 0 \quad (\text{因为} \sum_{i=1}^{n}
\alpha_i y_i = 0)$$</span></p></li>
</ul>
<p>代入后，拉格朗日函数变为：<br>
<span class="math display">$$\mathcal{L} = \frac{1}{2} \sum_{i=1}^{n}
\sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot
\mathbf{x}_j) - \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j
(\mathbf{x}_i \cdot \mathbf{x}_j) + \sum_{i=1}^{n} \alpha_i$$</span></p>
<p>化简：<br>
<span class="math display">$$\mathcal{L} = -\frac{1}{2} \sum_{i=1}^{n}
\sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot
\mathbf{x}_j) + \sum_{i=1}^{n} \alpha_i$$</span></p>
<h4 id="对偶优化问题">3.3 对偶优化问题</h4>
<p>于是，对偶问题是：<br>
<span class="math display">$$\max_{\boldsymbol{\alpha}} \left[
\sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n}
\alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)
\right]$$</span></p>
<ul>
<li><strong>约束条件</strong>：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i =
0$$</span><br>
<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0,  <em>i</em> = 1, 2, …, <em>n</em></span></li>
</ul>
<p>为了与标准优化形式一致，常将其写为最小化问题：<br>
<span class="math display">$$\min_{\boldsymbol{\alpha}} \left[
\frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j
(\mathbf{x}_i \cdot \mathbf{x}_j) - \sum_{i=1}^{n} \alpha_i
\right]$$</span></p>
<ul>
<li><strong>约束条件不变</strong>：<br>
<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i =
0$$</span><br>
<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span></li>
</ul>
<hr>
<h3 id="转换的条件">4. 转换的条件</h3>
<p>原始问题与对偶问题之间的关系由<strong>强对偶性</strong>保证。在SVM中：
- 目标函数 <span class="math display">$$\frac{1}{2}
\|\mathbf{w}\|^2$$</span> 是凸函数（二次函数）； - 约束条件 <span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong>⋅<strong>x</strong><sub><em>i</em></sub>+<em>b</em>) ≥ 1</span>
是线性不等式； -
对于线性可分数据，Slater条件满足（存在可行解使约束严格成立）。</p>
<p>因此，强对偶性成立，原始问题的最优解可以通过对偶问题求解得到。</p>
<p>此外： - 最优的 <span class="math display"><strong>α</strong></span>
通过对偶问题求解； - <span class="math display">$$\mathbf{w} =
\sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i$$</span>； -
对于支持向量（<span class="math display"><em>α</em><sub><em>i</em></sub> &gt; 0</span>
的样本），<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong>⋅<strong>x</strong><sub><em>i</em></sub>+<em>b</em>) = 1</span>，可据此解出
<span class="math display"><em>b</em></span>。</p>
<hr>
<h3 id="总结-1">5. 总结</h3>
<ul>
<li><p><strong>原始问题</strong>：<br>
<span class="math display">$$\min_{\mathbf{w}, b} \frac{1}{2}
\|\mathbf{w}\|^2$$</span><br>
受约束：<span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong>⋅<strong>x</strong><sub><em>i</em></sub>+<em>b</em>) ≥ 1</span></p></li>
<li><p><strong>对偶问题</strong>：<br>
<span class="math display">$$\max_{\boldsymbol{\alpha}} \left[
\sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n}
\alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)
\right]$$</span><br>
受约束：<span class="math display">$$\sum_{i=1}^{n} \alpha_i y_i =
0$$</span>，<span class="math display"><em>α</em><sub><em>i</em></sub> ≥ 0</span></p></li>
<li><p><strong>转换条件</strong>：<br>
通过拉格朗日乘子法，基于凸优化和强对偶性完成转换。对偶形式不仅便于求解，还为引入核函数奠定了基础。</p></li>
</ul>
<p>以上就是SVM目标函数从原始问题到对偶问题的推导过程和条件。</p>
<h4 id="已知训练数据集中正例点x123x233x332负例点x412-x521x631训练线性svm分类器求最大间隔分类超平面和分类决策函数并画出分类超平面间隔边界以及支持向量">2.已知训练数据集中正例点x1=(2,3)，x2=(3,3)，x3=(3,2)，负例点x4=(1,2)，
x5=(2,1)，x6=(3,1)，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。</h4>
<figure>
<img src="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/IMG_20250416_164804-1744793466526-4.jpg" alt="IMG_20250416_164804">
<figcaption aria-hidden="true">IMG_20250416_164804</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——期末复习（上）</title>
    <url>/2025/06/14/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    <content><![CDATA[<h3 id="svm支持向量机">SVM支持向量机</h3>
<h4 id="作业">作业</h4>
<h5 id="section">1</h5>
<p>关于核化软间隔支持向量机，推导目标函数的原始问题转换为对偶问题的过程、KKT条件、预测函数。</p>
<p><strong>原始问题</strong></p>
<p>软间隔SVM的目标函数为： <span class="math display">$$
\min_{\mathbf{w}, b, \xi} \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n
\xi_i
$$</span> 约束条件： <span class="math display"><em>y</em><sub><em>i</em></sub>(<strong>w</strong><sup><em>T</em></sup><em>ϕ</em>(<strong>x</strong><sub><em>i</em></sub>)+<em>b</em>) ≥ 1 − <em>ξ</em><sub><em>i</em></sub>,  <em>ξ</em><sub><em>i</em></sub> ≥ 0,  <em>i</em> = 1, …, <em>n</em></span>
其中 <span class="math inline"><em>C</em> &gt; 0</span>
是惩罚参数，<span class="math inline"><em>ξ</em><sub><em>i</em></sub></span>
是松弛变量，<span class="math inline"><em>ϕ</em>(⋅)</span>
是特征映射。</p>
<p><strong>转化为对偶问题</strong></p>
<ol type="1">
<li><p><strong>构造拉格朗日函数</strong>： <span class="math display">$$
\mathcal{L}(\mathbf{w}, b, \xi, \boldsymbol{\alpha}, \boldsymbol{\beta})
= \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n \xi_i - \sum_{i=1}^n
\alpha_i \left[y_i (\mathbf{w}^T \phi(\mathbf{x}_i) + b) - 1 +
\xi_i\right] - \sum_{i=1}^n \beta_i \xi_i
$$</span> 其中 <span class="math inline"><em>α</em><sub><em>i</em></sub> ≥ 0, <em>β</em><sub><em>i</em></sub> ≥ 0</span>
是拉格朗日乘子。</p></li>
<li><p><strong>对原始变量求偏导并令其为零</strong>：</p></li>
</ol>
<ul>
<li>对 <span class="math inline"><strong>w</strong></span> 求导： <span class="math display">$$
\frac{\partial \mathcal{L}}{\partial \mathbf{w}} = \mathbf{w} -
\sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i) = 0 \quad \Rightarrow
\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i)
$$</span></li>
<li>对 <span class="math inline"><em>b</em></span> 求导： <span class="math display">$$
\frac{\partial \mathcal{L}}{\partial b} = -\sum_{i=1}^n \alpha_i y_i = 0
\quad \Rightarrow \sum_{i=1}^n \alpha_i y_i = 0
$$</span></li>
<li>对 <span class="math inline"><em>ξ</em><sub><em>i</em></sub></span>
求导： <span class="math display">$$
\frac{\partial \mathcal{L}}{\partial \xi_i} = C - \alpha_i - \beta_i = 0
\quad \Rightarrow \beta_i = C - \alpha_i
$$</span></li>
</ul>
<ol start="3" type="1">
<li><p><strong>代入拉格朗日函数消去原始变量</strong>： 将 <span class="math inline"><strong>w</strong></span> 和 <span class="math inline"><em>β</em><sub><em>i</em></sub></span> 代入 <span class="math inline">ℒ</span>，得到对偶目标函数： <span class="math display">$$
\max_{\boldsymbol{\alpha}} \sum_{i=1}^n \alpha_i - \frac{1}{2}
\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j \phi(\mathbf{x}_i)^T
\phi(\mathbf{x}_j)
$$</span> 约束条件： <span class="math display">$$
0 \leq \alpha_i \leq C, \quad \sum_{i=1}^n \alpha_i y_i = 0
$$</span></p></li>
<li><p><strong>引入核函数</strong>： 用核函数 <span class="math inline"><em>K</em>(<strong>x</strong><sub><em>i</em></sub>,<strong>x</strong><sub><em>j</em></sub>) = <em>ϕ</em>(<strong>x</strong><sub><em>i</em></sub>)<sup><em>T</em></sup><em>ϕ</em>(<strong>x</strong><sub><em>j</em></sub>)</span>
替换内积，得到最终对偶问题： <span class="math display">$$
\max_{\boldsymbol{\alpha}} \sum_{i=1}^n \alpha_i - \frac{1}{2}
\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(\mathbf{x}_i,
\mathbf{x}_j)
$$</span> 约束条件不变。</p></li>
</ol>
<p><strong>KKT条件</strong></p>
<ul>
<li><strong>原始可行性</strong>：<span class="math inline"><em>y</em><sub><em>i</em></sub>(<strong>w</strong><sup><em>T</em></sup><em>ϕ</em>(<strong>x</strong><sub><em>i</em></sub>)+<em>b</em>) ≥ 1 − <em>ξ</em><sub><em>i</em></sub>,  <em>ξ</em><sub><em>i</em></sub> ≥ 0</span></li>
<li><strong>对偶可行性</strong>：<span class="math inline"><em>α</em><sub><em>i</em></sub> ≥ 0,  <em>β</em><sub><em>i</em></sub> = <em>C</em> − <em>α</em><sub><em>i</em></sub> ≥ 0</span></li>
<li><strong>互补松弛性</strong>：<span class="math inline"><em>α</em><sub><em>i</em></sub>[<em>y</em><sub><em>i</em></sub>(<strong>w</strong><sup><em>T</em></sup><em>ϕ</em>(<strong>x</strong><sub><em>i</em></sub>)+<em>b</em>)−1+<em>ξ</em><sub><em>i</em></sub>] = 0,  <em>β</em><sub><em>i</em></sub><em>ξ</em><sub><em>i</em></sub> = 0</span></li>
<li><strong>梯度为零条件</strong>：已通过偏导数消去原始变量。</li>
</ul>
<p><strong>预测函数</strong></p>
<p>测试样本 <span class="math inline"><strong>x</strong></span>
的预测函数为： <span class="math display">$$
f(\mathbf{x}) = \text{sign} \left( \sum_{i=1}^n \alpha_i y_i
K(\mathbf{x}_i, \mathbf{x}) + b \right)
$$</span> 其中 <span class="math inline"><em>b</em></span>
可通过任一支持向量（满足 <span class="math inline">0 &lt; <em>α</em><sub><em>i</em></sub> &lt; <em>C</em></span>）计算：
<span class="math display">$$
b = y_i - \sum_{j=1}^n \alpha_j y_j K(\mathbf{x}_j, \mathbf{x}_i)
$$</span></p>
<h5 id="section-1">2</h5>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——知识查漏补缺</title>
    <url>/2025/03/08/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h2 id="pip与conda区别">pip与conda区别</h2>
<p><code>pip</code> 和 <code>conda</code> 都是用来安装和管理 Python
包的工具，但它们的工作方式和适用场景有所不同。以下是它们的主要区别：</p>
<h3 id="包管理的范围">1. <strong>包管理的范围</strong></h3>
<ul>
<li><code>pip</code>：是 Python 官方的包管理工具，只用于安装 Python
包。它从 Python 包索引 (PyPI) 中获取包并安装。这意味着它只能安装 Python
包，不能直接处理其他类型的依赖（如系统库、C 库等）。</li>
<li><code>conda</code>：是一个跨平台的包和环境管理工具，它不仅可以安装
Python 包，还可以安装其他语言（如 R、Java、C++ 等）以及非 Python
依赖（如系统库）。<code>conda</code> 能够管理整个环境（包括 Python
版本和库），并解决与系统库之间的依赖关系。</li>
</ul>
<h3 id="依赖管理">2. <strong>依赖管理</strong></h3>
<ul>
<li><code>pip</code>：在安装包时，<code>pip</code> 仅会安装 Python
包及其 Python 依赖，而不处理系统级依赖。如果一个包依赖于特定的 C
库或其他非 Python 包，<code>pip</code>
不会自动解决这些问题，这可能导致一些复杂的兼容性问题。</li>
<li><code>conda</code>：会同时处理 Python 包和非 Python
包的依赖。它会在安装时自动解决所有依赖，包括操作系统库、C
库等。因此，<code>conda</code> 在依赖关系处理上比 <code>pip</code>
更强大。</li>
</ul>
<h3 id="包来源">3. <strong>包来源</strong></h3>
<ul>
<li><code>pip</code>：通过 PyPI（Python Package
Index）来下载和安装包，PyPI 是一个包含大多数 Python 包的中央库。</li>
<li><code>conda</code>：使用 Anaconda 仓库或其他 conda 仓库。Anaconda
仓库提供了大量的科学计算、数据分析相关的包，而不仅限于 Python 包。conda
还支持安装一些没有在 PyPI 上的包。</li>
</ul>
<h3 id="环境管理">4. <strong>环境管理</strong></h3>
<ul>
<li><code>pip</code>：本身不提供环境管理功能，但可以与
<code>virtualenv</code> 或 <code>venv</code>
等工具结合使用来创建虚拟环境。这些虚拟环境允许你为不同项目隔离依赖。</li>
<li><code>conda</code>：内置环境管理功能，可以通过
<code>conda create</code> 命令直接创建隔离的环境，支持不同版本的 Python
以及其他软件的管理。<code>conda</code> 环境的管理比
<code>pip + virtualenv</code> 更加方便和高效。</li>
</ul>
<h3 id="安装速度">5. <strong>安装速度</strong></h3>
<ul>
<li><code>pip</code>：通常只安装 Python
包。对于某些包，特别是需要从源代码编译的包，安装可能会比较慢，尤其是在没有预编译二进制文件的情况下。</li>
<li><code>conda</code>：由于它使用的是预编译的二进制包，安装速度通常更快，尤其是对于依赖项繁多的包（如
<code>numpy</code>、<code>scipy</code>
等）。它无需从源代码编译，直接安装预编译的版本。</li>
</ul>
<h3 id="跨平台支持">6. <strong>跨平台支持</strong></h3>
<ul>
<li><code>pip</code>：支持所有操作系统，但在一些操作系统（尤其是
Windows）上，安装某些包时可能会遇到编译问题，尤其是 C 扩展包。</li>
<li><code>conda</code>：同样支持多平台，并且在 Windows
系统上安装一些复杂的包（如 <code>numpy</code>、<code>pandas</code>
等）时，比 <code>pip</code>
更加稳定和方便，因为它会自动提供适合平台的预编译二进制文件。</li>
</ul>
<h3 id="包版本冲突">7. <strong>包版本冲突</strong></h3>
<ul>
<li><code>pip</code>：虽然可以安装特定版本的包，但如果项目中的多个包有不同的依赖版本，<code>pip</code>
并不能很好地解决这些版本冲突，需要手动处理依赖版本。</li>
<li><code>conda</code>：在安装时，<code>conda</code>
会自动解析所有的依赖关系，确保包和其依赖的版本兼容，从而减少版本冲突。</li>
</ul>
<h3 id="包更新">8. <strong>包更新</strong></h3>
<ul>
<li><strong><code>pip</code></strong>：更新包的方式通常是直接运行
<code>pip install --upgrade &lt;package&gt;</code>，但是它会仅更新
Python 包本身，不会考虑系统级的依赖。</li>
<li><strong><code>conda</code></strong>：更新包时，<code>conda</code>
会同时考虑包的 Python 依赖和系统库依赖，可以更全面地管理包更新。</li>
</ul>
<h3 id="总结对比表">总结对比表：</h3>
<table>
<colgroup>
<col style="width: 22%">
<col style="width: 33%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>特性</th>
<th><code>pip</code></th>
<th><code>conda</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>包管理范围</strong></td>
<td>只管理 Python 包</td>
<td>管理 Python 包和其他非 Python 包</td>
</tr>
<tr class="even">
<td><strong>依赖关系管理</strong></td>
<td>只处理 Python 依赖</td>
<td>处理 Python 和非 Python 依赖</td>
</tr>
<tr class="odd">
<td><strong>包来源</strong></td>
<td>PyPI</td>
<td>Anaconda 仓库等</td>
</tr>
<tr class="even">
<td><strong>环境管理</strong></td>
<td>需配合 <code>virtualenv</code> 使用</td>
<td>内建环境管理</td>
</tr>
<tr class="odd">
<td><strong>安装速度</strong></td>
<td>慢（尤其是需要编译的包）</td>
<td>快（使用预编译二进制包）</td>
</tr>
<tr class="even">
<td><strong>跨平台支持</strong></td>
<td>跨平台支持良好</td>
<td>更好的 Windows 支持</td>
</tr>
<tr class="odd">
<td><strong>版本冲突处理</strong></td>
<td>手动解决版本冲突</td>
<td>自动解决版本冲突</td>
</tr>
</tbody>
</table>
<h3 id="什么时候使用-pip什么时候使用-conda">什么时候使用
<code>pip</code>，什么时候使用 <code>conda</code>？</h3>
<ul>
<li>如果你已经在使用 Anaconda 或 Miniconda，并且需要安装 Python
包及其相关依赖，<code>conda</code>
是更好的选择，因为它可以自动解决依赖并更好地管理环境。</li>
<li>如果你没有使用 Anaconda 或只需要安装纯粹的 Python
包，<code>pip</code> 更为轻量和直接。</li>
</ul>
<p>在实际使用中，有时你会发现两者可以结合使用：可以用 <code>conda</code>
安装 Python 环境和一些复杂的依赖，再用 <code>pip</code> 安装一些不在
Anaconda 仓库中的包。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——期末复习（查漏补缺）</title>
    <url>/2025/06/10/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA%EF%BC%89/</url>
    <content><![CDATA[<h3 id="高斯核rbf核中-σ²-的作用及其对模型的影响">高斯核（RBF核）中 σ²
的作用及其对模型的影响</h3>
<p>高斯核（RBF核）的形式为： <span class="math display">$$
K(x, x') = \exp\left(-\frac{\|x - x'\|^2}{2\sigma^2}\right)
$$</span> 其中 $ |x - x’| $ 是两个样本点之间的欧氏距离，$ ^2 $
是高斯核的方差参数，控制核函数的“宽度”或“局部性”。</p>
<p><strong>1. σ² 的几何意义：核函数的“影响范围”</strong></p>
<ul>
<li><p><strong>σ² 较小时</strong>：<br>
分母较小，指数项中的 $ $ 会更大，导致指数函数值快速衰减。<br>
<strong>结果</strong>：只有当 $ x $ 和 $ x’ $
非常接近时，核函数值才接近1；稍远一点的距离会导致核函数值迅速趋近于0。<br>
<strong>直观理解</strong>：模型只关注局部区域内的样本点，决策边界会围绕每个样本点“弯曲”，形成复杂的非线性形状。</p></li>
<li><p><strong>σ² 较大时</strong>：<br>
分母较大，指数项中的 $ $ 会更小，指数函数值衰减缓慢。<br>
<strong>结果</strong>：即使 $ x $ 和 $ x’ $
相距较远，核函数值仍可能较大。<br>
<strong>直观理解</strong>：模型会考虑更大范围的样本点，决策边界更平滑，接近线性分隔。</p></li>
</ul>
<p><strong>2. σ² 如何影响模型的复杂度</strong></p>
<ul>
<li><strong>σ² 小 → 局部敏感，高复杂度</strong>：
<ul>
<li>每个样本点的影响范围有限，模型需要“记住”每个局部区域的细节。<br>
</li>
<li>决策边界会围绕每个样本点剧烈弯曲，甚至形成孤立的环形区域（如图1）。<br>
</li>
<li>容易过拟合：模型过度适应训练数据的噪声和细节。</li>
</ul></li>
<li><strong>σ² 大 → 全局平滑，低复杂度</strong>：
<ul>
<li>样本点的影响范围扩大，模型倾向于用简单的全局模式区分数据。<br>
</li>
<li>决策边界接近线性（如图2），可能无法捕捉数据中的非线性结构。<br>
</li>
<li>容易欠拟合：模型无法拟合数据中的局部特征。</li>
</ul></li>
</ul>
<p><strong>3. 数学与直观示例</strong></p>
<p>假设两个样本点 $ x_1 $ 和 $ x_2 $ 距离为 $ d $，核函数值 $ K(x_1,
x_2) $ 随 $ ^2 $ 的变化如下：</p>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 22%">
<col style="width: 31%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>$ ^2 $</th>
<th>$ d = 1 $</th>
<th>$ d = 2 $</th>
<th>$ d = 3 $</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>$ ^2 = 0.1 $</td>
<td>$ (-5) $</td>
<td>$ (-20) ^{-9} $</td>
<td>$ (-45) ^{-20} $</td>
</tr>
<tr class="even">
<td>$ ^2 = 1 $</td>
<td>$ (-0.5) $</td>
<td>$ (-2) $</td>
<td>$ (-4.5) $</td>
</tr>
<tr class="odd">
<td>$ ^2 = 10 $</td>
<td>$ (-0.05) $</td>
<td>$ (-0.2) $</td>
<td>$ (-0.45) $</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>σ² 小（如
0.1）</strong>：距离稍大的样本点之间几乎无关联，模型仅依赖极邻近的点做决策。<br>
</li>
<li><strong>σ² 大（如
10）</strong>：即使距离较远的样本点仍有显著关联，模型决策边界更平滑。</li>
</ul>
<h3 id="为什么使用高斯核之前要归一化">为什么使用高斯核之前要归一化</h3>
<p>在使用高斯核（RBF核）之前对数据进行归一化，是机器学习中至关重要的预处理步骤。其核心原因是<strong>高斯核对特征的尺度（scale）极度敏感</strong>，而归一化能消除特征间尺度差异带来的负面影响。以下是详细解释：</p>
<ol type="1">
<li><strong>高斯核的本质依赖距离计算</strong></li>
</ol>
<p>高斯核的公式为： <span class="math display">$$
K(x, x') = \exp\left(-\frac{\|x - x'\|^2}{2\sigma^2}\right)
$$</span> 其中 <span class="math inline">∥<em>x</em> − <em>x</em>′∥</span>
是两个样本点之间的欧氏距离。<br>
<strong>问题</strong>：欧氏距离的计算受特征尺度影响极大。例如： -
假设特征A的取值范围是 [0,1]，特征B的取值范围是 [0,1000]。 -
此时特征B的差异会主导距离计算（如 $ (0.5)^2 + (500)^2
$），特征A的贡献几乎被忽略。</p>
<p><strong>结果</strong>：模型决策边界会过度依赖尺度大的特征，导致性能下降。</p>
<ol start="2" type="1">
<li><strong>归一化消除特征尺度差异</strong></li>
</ol>
<p>归一化（如标准化或最小-最大缩放）将所有特征调整到相似的数值范围（如
[0,1] 或均值为0、方差为1）。<br>
<strong>效果</strong>： -
<strong>公平比较特征</strong>：每个特征对距离的贡献权重均衡。 -
<strong>防止“大尺度特征主导”</strong>：避免模型因某些特征数值过大而忽略其他重要特征。</p>
<p><strong>示例</strong>：<br>
假设两个样本：<br>
- 未归一化：$ x_1 = [1, 100], x_2 = [2, 200] $，距离为 $ <span class="math inline">。 − <em>归</em><em>一</em><em>化</em><em>后</em>（<em>假</em><em>设</em><em>缩</em><em>放</em><em>到</em>[0,1]）：</span>
x_1 = [0.1, 0.1], x_2 = [0.2, 0.2] $，距离为 $ $。<br>
此时两个特征的贡献比例从 1:100 变为 1:1。</p>
<ol start="3" type="1">
<li><strong>高斯核参数 σ² 的有效性依赖归一化</strong></li>
</ol>
<p>高斯核的参数 σ²（或 γ =
1/σ²）决定了核函数的“局部性”（即模型关注局部还是全局模式）。<br>
- <strong>未归一化时</strong>：σ²
的选择必须同时适应不同尺度的特征，导致参数调优困难。 -
例如：若某特征尺度极大，需要极小的 σ²
才能捕捉其局部变化，但这可能使其他小尺度特征的核函数失效。 -
<strong>归一化后</strong>：所有特征尺度一致，σ²
的调参只需关注数据整体分布，而非单个特征的尺度。</p>
<h3 id="svm的hinge损失函数">SVM的Hinge损失函数</h3>
<p>Hinge损失函数是支持向量机（SVM）中用于分类任务的核心损失函数，其核心思想是<strong>最大化分类间隔</strong>，同时惩罚分类错误或置信度不足的样本。以下是详细解析：</p>
<p><strong>1. 数学定义</strong></p>
<p>对于二分类问题，假设真实标签 $ y {+1, -1} $，模型输出 $ f(x) = w^T x
+ b $，则 <strong>Hinge损失</strong> 的定义为： <span class="math display">ℒ(<em>y</em>,<em>f</em>(<em>x</em>)) = max (0,1−<em>y</em>⋅<em>f</em>(<em>x</em>))</span>
- <strong>关键含义</strong>： - 当 $ y f(x)
$：样本被正确分类且置信度足够（位于间隔边界外），损失为0。 - 当 $ y f(x)
&lt; 1 $：样本位于间隔内或被错误分类，损失随 $ y f(x) $ 线性增长。</p>
<p><strong>2. 几何意义：最大化间隔</strong></p>
<p>Hinge损失的设计与SVM的<strong>硬间隔（Hard
Margin）</strong>和<strong>软间隔（Soft Margin）</strong>目标直接相关：
- <strong>硬间隔</strong>：要求所有样本严格满足 $ y_i (w^T x_i + b)
$，即完全线性可分。 -
<strong>软间隔</strong>：允许部分样本违反间隔约束，通过Hinge损失将约束转化为优化目标：
<span class="math display">$$
  \min_{w,b} \left( \frac{1}{2} \|w\|^2 + C \sum_{i=1}^n \max(0, 1 - y_i
(w^T x_i + b)) \right)
  $$</span> - <strong>第一项</strong> $ |w|^2 $：最大化间隔（间隔宽度与
$ |w| $ 成反比）。 - <strong>第二项</strong>
Hinge损失：惩罚违反间隔约束的样本，$ C $ 控制惩罚强度。</p>
<h3 id="为什么树的数量增加不会导致过拟合">为什么树的数量增加不会导致过拟合？</h3>
<p><strong>核心原因</strong>：随机森林通过<strong>集成学习</strong>和<strong>多样性机制</strong>抑制了单棵决策树的过拟合风险。具体来说：</p>
<ol type="1">
<li><p><strong>Bagging（自助聚合）机制</strong>：<br>
每棵树的训练数据是通过有放回采样（Bootstrap）得到的子集，这意味着每棵树看到的数据略有不同，减少了对训练数据的“记忆”依赖。</p></li>
<li><p><strong>特征随机选择</strong>：<br>
每次分裂节点时，仅从随机选择的特征子集中挑选最优特征，进一步降低了各树之间的相关性。</p></li>
<li><p><strong>投票/平均机制</strong>：<br>
多棵树的预测结果通过投票（分类）或平均（回归）结合，高方差的个体树被平滑，整体模型的泛化能力增强。</p></li>
<li><p><strong>收敛性保证</strong>：<br>
随着树的数量增加，模型性能逐渐收敛到一个稳定值。即使继续增加树的数量，也不会显著提升训练集性能，更不会过拟合。</p></li>
</ol>
<h3 id="欧式距离的特性分析">欧式距离的特性分析</h3>
<p><strong>欧式距离</strong>（Euclidean
Distance）是衡量欧几里得空间中两点之间直线距离的常用方法，其公式为：
<span class="math display">$$
d(x, y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}
$$</span> 以下是对其特性的详细分析：</p>
<p><strong>A. 旋转不变性</strong></p>
<p><strong>正确</strong><br>
- <strong>定义</strong>：若坐标系旋转，两点间的欧式距离保持不变。<br>
- <strong>原因</strong>：旋转是刚性变换（rigid
transformation），仅改变点的坐标表示，但不改变几何距离。<br>
- <strong>示例</strong>：在二维平面中，将坐标系旋转θ角度，两点 <span class="math inline">(<em>x</em><sub>1</sub>,<em>y</em><sub>1</sub>)</span>
和 <span class="math inline">(<em>x</em><sub>2</sub>,<em>y</em><sub>2</sub>)</span>
的旋转后坐标分别为： <span class="math display">(<em>x</em><sub>1</sub>′,<em>y</em><sub>1</sub>′) = (<em>x</em><sub>1</sub>cos<em>θ</em>−<em>y</em><sub>1</sub>sin<em>θ</em>,<em>x</em><sub>1</sub>sin<em>θ</em>+<em>y</em><sub>1</sub>cos<em>θ</em>)</span>
<span class="math display">(<em>x</em><sub>2</sub>′,<em>y</em><sub>2</sub>′) = (<em>x</em><sub>2</sub>cos<em>θ</em>−<em>y</em><sub>2</sub>sin<em>θ</em>,<em>x</em><sub>2</sub>sin<em>θ</em>+<em>y</em><sub>2</sub>cos<em>θ</em>)</span>
计算旋转后的距离仍等于原始距离。</p>
<p><strong>B. 尺度缩放不变性</strong></p>
<p><strong>错误</strong><br>
-
<strong>定义</strong>：若对坐标轴进行非均匀或均匀缩放，欧式距离会发生变化。<br>
- <strong>反例</strong>：假设对某维特征缩放 <span class="math inline"><em>k</em></span> 倍（如将 <span class="math inline"><em>x</em><sub><em>i</em></sub></span> 变为 <span class="math inline"><em>k</em><em>x</em><sub><em>i</em></sub></span>），则距离变为原来的
<span class="math inline"><em>k</em></span> 倍。<br>
-
<strong>结论</strong>：欧式距离<strong>依赖于特征的绝对尺度</strong>，不具备缩放不变性。</p>
<p><strong>C. 不受量纲影响的特性</strong></p>
<p><strong>错误</strong><br>
-
<strong>定义</strong>：若不同特征的量纲不同（如身高[m]与体重[kg]），欧式距离的计算会因量纲差异而失真。<br>
- <strong>反例</strong>：<br>
- 点A：(1.8m, 70kg)，点B：(1.7m, 65kg)<br>
-
若不标准化，身高差（0.1m）与体重差（5kg）的贡献会被直接相加，但两者量纲不同，结果无实际意义。<br>
-
<strong>解决方法</strong>：需通过标准化（如Z-score归一化）消除量纲影响。</p>
<h3 id="下列哪个不属于特征提取">下列哪个不属于特征提取</h3>
<p><strong>答案：D. 主成分分析</strong></p>
<p><strong>解析：</strong></p>
<p>在文本分类的特征选择中，常用的方法包括：</p>
<ul>
<li><strong>A.
卡方检验值</strong>：通过统计检验评估特征与类别的相关性，属于过滤式特征选择方法。</li>
<li><strong>B.
互信息</strong>：基于信息论，衡量特征与类别的依赖关系，属于无监督或半监督的特征选择方法。</li>
<li><strong>C.
信息增益</strong>：基于熵的指标，评估特征对分类的贡献，常用于决策树等算法中的特征选择。</li>
</ul>
<p>而 <strong>D. 主成分分析（PCA）</strong> 是一种
<strong>降维技术</strong>，通过线性变换将高维数据映射到低维空间，其核心目标是保留数据的主要方差，而非直接选择原始特征。它属于
<strong>特征提取</strong>（Feature Extraction）而非传统意义上的
<strong>特征选择</strong>（Feature
Selection）。因此，主成分分析不属于常用的文本分类特征选择算法。</p>
<p>### ridge回归和lasso回归</p>
<p>Ridge回归（岭回归）和Lasso回归（套索回归）是两种常用的<strong>正则化线性回归方法</strong>，主要用于解决线性回归中的<strong>过拟合问题</strong>和<strong>特征选择问题</strong>。它们的核心思想是在损失函数中添加正则化项（惩罚项），从而限制模型参数的大小，提升模型的泛化能力。</p>
<p><strong>1. Ridge回归（岭回归）</strong></p>
<p><strong>目标函数</strong> <span class="math display">$$
\min_{\mathbf{w}} \left\{ \sum_{i=1}^n (y_i - \mathbf{w}^T
\mathbf{x}_i)^2 + \lambda \|\mathbf{w}\|_2^2 \right\}
$$</span> - 第一项是普通线性回归的均方误差（MSE）。 -
第二项是L2正则化项（权重平方的和），<span class="math inline"><em>λ</em> ≥ 0</span>
是正则化系数，控制惩罚强度。</p>
<p><strong>特点</strong></p>
<ul>
<li><strong>L2正则化</strong>：通过缩小权重系数（但不会完全置零）来减少模型复杂度。</li>
<li><strong>解决多重共线性</strong>：当特征之间存在高度相关性时，Ridge回归能稳定回归系数。</li>
<li><strong>唯一解</strong>：目标函数是凸函数，且严格凸，因此有唯一最优解。</li>
<li><strong>计算效率高</strong>：可以通过解析解（闭式解）求解： <span class="math display"><strong>w</strong><sub>Ridge</sub> = (<strong>X</strong><sup><em>T</em></sup><strong>X</strong>+<em>λ</em><strong>I</strong>)<sup>−1</sup><strong>X</strong><sup><em>T</em></sup><strong>y</strong></span></li>
</ul>
<p><strong>应用场景</strong></p>
<ul>
<li>特征维度较低，但存在多重共线性。</li>
<li>需要保留所有特征，但希望抑制其影响（如基因数据分析）。</li>
</ul>
<p><strong>2. Lasso回归（套索回归）</strong></p>
<p><strong>目标函数</strong> <span class="math display">$$
\min_{\mathbf{w}} \left\{ \sum_{i=1}^n (y_i - \mathbf{w}^T
\mathbf{x}_i)^2 + \lambda \|\mathbf{w}\|_1 \right\}
$$</span> - 第一项是均方误差。 -
第二项是L1正则化项（权重绝对值的和），<span class="math inline"><em>λ</em> ≥ 0</span> 是正则化系数。</p>
<p><strong>特点</strong></p>
<ul>
<li><strong>L1正则化</strong>：强制部分权重系数为零，实现特征选择。</li>
<li><strong>稀疏模型</strong>：适用于高维数据（如文本分类、基因数据），自动筛选关键特征。</li>
<li><strong>非唯一解</strong>：目标函数是凸函数，但可能有多个解（当特征高度相关时）。</li>
<li><strong>计算复杂度较高</strong>：通常需要迭代优化算法（如坐标下降法、近端梯度下降）。</li>
</ul>
<p><strong>应用场景</strong></p>
<ul>
<li>特征维度极高（如万维以上），需降维。</li>
<li>需要可解释性强的模型（如金融风控中的关键特征筛选）。</li>
</ul>
<p><strong>3. 总结</strong></p>
<ul>
<li><strong>Ridge回归</strong>：适合特征较少且需要稳定系数的场景。</li>
<li><strong>Lasso回归</strong>：适合高维数据和特征选择场景。</li>
<li><strong>实际选择</strong>：
<ul>
<li>如果特征数量远大于样本数量（<span class="math inline"><em>p</em> ≫ <em>n</em></span>），优先使用Lasso。</li>
<li>如果特征间存在强相关性，优先使用Ridge或弹性网络。</li>
</ul></li>
</ul>
<p>通过调整正则化系数 <span class="math inline"><em>λ</em></span>，可以控制模型的复杂度与泛化能力。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——Python常用库</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Python%E5%B8%B8%E7%94%A8%E5%BA%93/</url>
    <content><![CDATA[<h2 id="python常用库">Python常用库</h2>
<h3 id="numpy">1. Numpy</h3>
<p>numpy（Numerical
Python的简称）是高性能科学计算和数据分析的基础包。其部分功能如下：</p>
<p>ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。
用于对整组数据进行快速运算的标准数学函数（无需编写循环）。
用于读写磁盘数据的工具以及用于操作内存映射文件的工具。
线性代数、随机数生成以及傅里叶变换功能。
用于集成由C、C++、Fortran等语言编写的代码的工具。</p>
<h3 id="pandas">2. Pandas</h3>
<p>pandas是python第三方库，提供高性能易用数据类型和分析工具
pandas基于numpy实现，常与numpy和matplotlib一同使用
pandas中有两大核心数据结构：Series（一维数据） 和
DataFrame（多特征数据,既有行索引,又有列索引）</p>
<h3 id="pil">3. PIL</h3>
<p>PIL库是一个具有强大图像处理能力的第三方库 在命令行下的安装方法：pip
install pillow 在使用过程中的引入方法：from PIL import Image Image 是
PIL 库中代表一个图像的类（对象）
图像是一个由像素组成的二维矩阵，每个元素是一个RGB值</p>
<h3 id="matplotlib">4. Matplotlib</h3>
<p>Matplotlib库由各种可视化类构成，内部结构复杂。
受Matlab启发，matplotlib.pylot是绘制各类可视化图形的命令字库，相当于快捷方式。</p>
<h3 id="scikit-learn">5. scikit-learn</h3>
<p><code>scikit-learn</code>（简称 <code>sklearn</code>）是一个开源的
Python
库，广泛应用于机器学习任务，提供了丰富的工具和算法，能够帮助数据科学家和机器学习工程师高效地进行数据预处理、模型训练、评估和优化。它基于
<code>NumPy</code>、<code>SciPy</code> 和
<code>matplotlib</code>，具有以下主要特点和功能：</p>
<h4 id="主要功能"><strong>主要功能</strong>：</h4>
<ul>
<li><strong>分类 (Classification)</strong>
：用于预测数据点所属的类别（如垃圾邮件分类、疾病预测等）。</li>
<li><strong>回归 (Regression)</strong>
：用于预测连续的数值（如房价预测、股票价格预测等）。</li>
<li><strong>聚类 (Clustering)</strong>
：将数据点分为不同的簇或组（如客户细分、图像分割等）。</li>
<li><strong>降维 (Dimensionality Reduction)</strong>
：减少数据的维度，常用于数据压缩和可视化。</li>
<li><strong>模型评估 (Model Evaluation)</strong>
：提供评估工具，如交叉验证、准确率、F1 分数等。</li>
<li><strong>数据预处理 (Data Preprocessing)</strong>
：包括标准化、归一化、缺失值处理、编码等。</li>
<li><strong>超参数调优 (Hyperparameter Tuning)</strong>
：通过网格搜索（GridSearchCV）和随机搜索（RandomizedSearchCV）来优化模型超参数。</li>
</ul>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——绪论</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[<h3 id="正文">正文</h3>
<figure>
<img src="/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%AA%E8%AE%BA/QQ20250320-191604.png" alt="QQ20250320-191604">
<figcaption aria-hidden="true">QQ20250320-191604</figcaption>
</figure>
<h3 id="参考文章">参考文章</h3>
<p><a href="https://blog.csdn.net/lhxez6868/article/details/108150777">准确度(accuracy)、精确率（precision)、召回率（recall）、F1值
谈谈我的看法_recall f1-CSDN博客</a></p>
<p>南瓜书在线阅读：https://datawhalechina.github.io/pumpkin-book/#/</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——神经网络</title>
    <url>/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h2 id="正文">正文</h2>
<h3 id="作业">作业</h3>
<h4 id="类别不均衡指的是什么有哪些解决方案">类别不均衡指的是什么？有哪些解决方案。</h4>
<p><strong>类别不均衡（Class Imbalance）</strong>
是指分类任务中不同类别样本的数量差异显著，例如：<br>
- <strong>多数类（Majority
Class）</strong>：样本数量多（如正常交易占99%）。<br>
- <strong>少数类（Minority
Class）</strong>：样本数量极少（如欺诈交易仅占1%）。</p>
<p>这种问题会导致模型倾向于预测多数类，严重降低少数类的预测性能（如漏检欺诈行为）。以下是详细解释和解决方案：</p>
<p><strong>1. 类别不均衡的影响</strong></p>
<ul>
<li><strong>模型偏差</strong>：模型过度关注多数类，忽略少数类（如将所有样本预测为多数类，准确率虚高）。<br>
</li>
<li><strong>评估指标失效</strong>：准确率（Accuracy）失去意义（例如：99%
的样本是多数类，模型只需预测多数类即可达到 99% 准确率）。</li>
</ul>
<p><strong>2. 解决方案</strong></p>
<p><strong>2.1 数据层面调整</strong></p>
<ul>
<li><strong>过采样（Oversampling）</strong>
<ul>
<li><strong>复制少数类样本</strong>：直接复制少数类数据（可能导致过拟合）。<br>
</li>
<li><strong>生成合成样本</strong>：使用
<strong>SMOTE</strong>（Synthetic Minority Over-sampling
Technique）生成新样本（通过插值法）。<br>
</li>
<li><strong>改进版算法</strong>：如
<strong>ADASYN</strong>（自适应合成采样），根据样本分布动态生成数据。</li>
</ul></li>
<li><strong>欠采样（Undersampling）</strong>
<ul>
<li><strong>随机删除多数类样本</strong>：减少多数类数量，但可能丢失重要信息。<br>
</li>
<li><strong>选择性欠采样</strong>：保留多数类中更具代表性的样本（如
<strong>Tomek Links</strong> 或 <strong>Cluster
Centroids</strong>）。</li>
</ul></li>
<li><strong>混合采样</strong><br>
结合过采样和欠采样（如先过采样少数类，再欠采样多数类）。</li>
</ul>
<p><strong>2.2 算法层面调整</strong></p>
<ul>
<li><strong>调整类别权重（Class Weight）</strong>
<ul>
<li>为少数类分配更高的权重（如
<code>class_weight='balanced'</code>），让模型更关注少数类。<br>
</li>
<li>公式：<br>
[ = ]</li>
</ul></li>
<li><strong>集成学习（Ensemble Methods）</strong>
<ul>
<li><strong>EasyEnsemble</strong>：从多数类中随机采样多个子集，分别与少数类结合训练多个模型，集成结果。<br>
</li>
<li><strong>BalanceCascade</strong>：逐步筛选多数类样本，避免冗余信息。<br>
</li>
<li><strong>RUSBoost</strong>：结合欠采样和提升算法（Boosting）。</li>
</ul></li>
<li><strong>改进损失函数</strong>
<ul>
<li><strong>Focal
Loss</strong>：降低易分类样本的权重，聚焦于难分类的少数类样本。<br>
</li>
<li><strong>Cost-sensitive
Learning</strong>：为不同类别分配不同的误分类代价。</li>
</ul></li>
</ul>
<p><strong>2.3 评估指标调整</strong></p>
<ul>
<li><strong>避免使用准确率（Accuracy）</strong>，改用以下指标：
<ul>
<li><strong>F1-Score</strong>：精确率（Precision）和召回率（Recall）的调和平均。<br>
</li>
<li><strong>AUC-ROC
曲线</strong>：衡量分类器在不同阈值下的整体性能。<br>
</li>
<li><strong>精确率-召回率曲线（PR
Curve）</strong>：关注少数类的识别能力。<br>
</li>
<li><strong>平衡准确率（Balanced
Accuracy）</strong>：计算每个类别的召回率的平均值。</li>
</ul></li>
</ul>
<p><strong>2.4 高级技术</strong></p>
<ul>
<li><p><strong>异常检测（Anomaly Detection）</strong><br>
将少数类视为异常，使用 One-Class SVM 或孤立森林（Isolation
Forest）检测。</p></li>
<li><p><strong>生成对抗网络（GAN）</strong><br>
使用 GAN 生成高质量的少数类样本（如医疗数据中的罕见病样本）。</p></li>
<li><p><strong>阈值调整</strong><br>
根据业务需求调整分类阈值（如将欺诈检测的阈值从 0.5 降低到
0.3）。</p></li>
</ul>
<p><strong>3. 实际应用建议</strong></p>
<ul>
<li><strong>场景举例</strong>：
<ul>
<li><strong>欺诈检测</strong>：少数类（欺诈）样本极少，需使用 SMOTE +
集成学习。<br>
</li>
<li><strong>医疗诊断</strong>：罕见病识别可尝试 GAN
生成数据或异常检测。<br>
</li>
</ul></li>
<li><strong>工具库</strong>：
<ul>
<li>Python 的 <code>imbalanced-learn</code>（提供 SMOTE、EasyEnsemble
等）。<br>
</li>
<li>TensorFlow/PyTorch 中的 <code>class_weight</code> 参数。</li>
</ul></li>
</ul>
<p><strong>总结</strong></p>
<p>类别不均衡的核心是让模型“看到”足够的少数类信息，同时选择合适的评估指标。根据数据特点和业务需求，灵活组合数据采样、算法改进和评估方法，才能有效提升模型对少数类的识别能力。</p>
<h4 id="关于误差逆传播bp算法详细推导e_k对w_hj的导数和对v_ih的导数">关于误差逆传播BP算法，详细推导E_k对w_hj的导数和对v_ih的导数。</h4>
<p>以下是误差逆传播（Backpropagation, BP）算法中误差 ( E_k ) 对权重 (
w_{hj} )（输出层权重）和 ( v_{ih}
)（隐藏层权重）的详细导数推导过程：</p>
<p><strong>符号定义</strong></p>
<ul>
<li><strong>输入层节点</strong>：( <span class="math inline"><em>x</em><sub><em>i</em></sub></span> )（( i = 1,
2, $, n $)）<br>
</li>
<li><strong>隐藏层节点</strong>：( <span class="math inline"><em>b</em><sub><em>h</em></sub></span> )（( h = 1,
2, $, q $)）<br>
</li>
<li><strong>输出层节点</strong>：( <span class="math inline"><em>y</em><sub><em>j</em></sub></span> )（( j = 1,
2,$ , l $)）<br>
</li>
<li><strong>隐藏层到输出层的权重</strong>：( <span class="math inline"><em>w</em><sub><em>h</em><em>j</em></sub></span>
)（从隐藏层节点 ( h ) 到输出层节点 ( j )）<br>
</li>
<li><strong>输入层到隐藏层的权重</strong>：( <span class="math inline"><em>v</em><sub><em>i</em><em>h</em></sub></span>
)（从输入层节点 ( i ) 到隐藏层节点 ( h )）<br>
</li>
<li><strong>激活函数</strong>：假设为 Sigmoid 函数 ($ f(x) = <span class="math inline">$\)，其导数为 \($</span> f’(x) = f(x)(1 - f(x))
$)<br>
</li>
<li><strong>损失函数</strong>：均方误差 ($ E_k = _{j=1}^l (y_j - _j)^2
$)，其中 ( $_j $) 是真实标签。</li>
</ul>
<p><strong>1. 计算 ( $ $)（输出层权重的梯度）</strong></p>
<p><strong>步骤分解</strong>：</p>
<ol type="1">
<li><p><strong>输出层输入</strong>：<br>
[ <span class="math inline">$net_j = \sum_{h=1}^q w_{hj} b_h$</span> ]
输出层节点的激活值为 ( <span class="math inline"><em>y</em><sub><em>j</em></sub> = <em>f</em>(<em>n</em><em>e</em><em>t</em><sub><em>j</em></sub>)</span>
)。</p></li>
<li><p><strong>损失函数对 ( net_j ) 的导数</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial net_j} =
\frac{\partial E_k}{\partial y_j} \cdot \frac{\partial y_j}{\partial
net_j}$</span> ]</p>
<ul>
<li>( <span class="math inline">$\frac{\partial E_k}{\partial y_j} =
(y_j - \hat{y}_j)$</span> )（均方误差导数）<br>
</li>
<li>( $ = f’(net_j) = y_j (1 - y_j) $)（Sigmoid 导数）<br>
因此：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial net_j} = (y_j
- \hat{y}_j) \cdot y_j (1 - y_j)$</span> ]</li>
</ul></li>
<li><p><strong>损失函数对 ( w_{hj} ) 的导数</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial w_{hj}} =
\frac{\partial E_k}{\partial net_j} \cdot \frac{\partial net_j}{\partial
w_{hj}}$</span> ]</p>
<ul>
<li>( <span class="math inline">$\frac{\partial net_j}{\partial w_{hj}}
= b_h$</span> )（因为 ( $net_j = w_{hj} b_h $)）<br>
因此：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial w_{hj}} = (y_j
- \hat{y}_j) \cdot y_j (1 - y_j) \cdot b_h$</span> ]</li>
</ul></li>
</ol>
<p><strong>2. 计算 ( $ $)（隐藏层权重的梯度）</strong></p>
<p><strong>步骤分解</strong>：<br>
1. <strong>隐藏层输入</strong>：<br>
[ <span class="math inline">$net_h = \sum_{i=1}^n v_{ih} x_i$</span> ]
隐藏层节点的激活值为 ($ b_h = f(net_h) $)。</p>
<ol start="2" type="1">
<li><strong>损失函数对 ( net_h ) 的导数</strong>：<br>
需要将误差从输出层反向传播到隐藏层：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial net_h} =
\sum_{j=1}^l \left( \frac{\partial E_k}{\partial net_j} \cdot
\frac{\partial net_j}{\partial b_h} \right) \cdot \frac{\partial
b_h}{\partial net_h}$</span> ]
<ul>
<li>($ = w_{hj} $)（输出层输入依赖于隐藏层输出 ( b_h )）<br>
</li>
<li>($ = f’(net_h) = b_h (1 - b_h) $)<br>
因此：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial net_h} =
\left( \sum_{j=1}^l \frac{\partial E_k}{\partial net_j} \cdot w_{hj}
\right) \cdot b_h (1 - b_h)$</span> ]</li>
</ul></li>
<li><strong>损失函数对 ( v_{ih} ) 的导数</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial v_{ih}} =
\frac{\partial E_k}{\partial net_h} \cdot \frac{\partial net_h}{\partial
v_{ih}}$</span> ]
<ul>
<li>($ = x_i <span class="math inline">$\)（因为 \($</span> net_h =
v_{ih} x_i $）<br>
因此：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial v_{ih}} =
\left( \sum_{j=1}^l \frac{\partial E_k}{\partial net_j} \cdot w_{hj}
\right) \cdot b_h (1 - b_h) \cdot x_i$</span> ]</li>
</ul></li>
</ol>
<p><strong>3. 最终梯度公式</strong></p>
<ul>
<li><p><strong>输出层权重梯度</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial w_{hj}} =
\delta_j \cdot b_h, \quad \text{其中 } \delta_j = (y_j - \hat{y}_j)
\cdot y_j (1 - y_j)$</span> ]</p></li>
<li><p><strong>隐藏层权重梯度</strong>：<br>
[ <span class="math inline">$\frac{\partial E_k}{\partial v_{ih}} =
\delta_h \cdot x_i, \quad \text{其中 } \delta_h = \left( \sum_{j=1}^l
\delta_j \cdot w_{hj} \right) \cdot b_h (1 - b_h)$</span> ]</p></li>
</ul>
<p><strong>4. 参数更新规则</strong></p>
<p>使用梯度下降法更新权重：<br>
1. <strong>输出层权重更新</strong>：<br>
[ <span class="math inline">$w_{hj} \leftarrow w_{hj} - \eta \cdot
\frac{\partial E_k}{\partial w_{hj}}$</span> ]</p>
<ol start="2" type="1">
<li><strong>隐藏层权重更新</strong>：<br>
[ <span class="math inline">$v_{ih} \leftarrow v_{ih} - \eta \cdot
\frac{\partial E_k}{\partial v_{ih}}$</span> ] 其中，( $$)
是学习率。</li>
</ol>
<p><strong>关键点总结</strong></p>
<ol type="1">
<li><strong>链式法则</strong>：通过逐层反向传播误差，将全局误差分解为对每个权重的局部梯度。<br>
</li>
<li><strong>敏感度（Delta）</strong>：
<ul>
<li>输出层：($ _j = (y_j - _j) f’(net_j)$ )<br>
</li>
<li>隐藏层：($ _h = ( <em>j w</em>{hj} ) f’(net_h)$ )<br>
</li>
</ul></li>
<li><strong>高效性</strong>：通过存储中间结果（如 ( _j
)），避免重复计算，降低时间复杂度。</li>
</ol>
<p>如果需要进一步解释具体步骤或示例，请随时告诉我！ 😊</p>
<h2 id="参考资料">参考资料</h2>
<p>[<a href="https://www.bilibili.com/video/BV1oY411N7Xz/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">5分钟深度学习]
#01 梯度下降算法_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1zV4y1R7B4/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">反向传播算法可视化展示_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——线性模型</title>
    <url>/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="正文">正文</h2>
<h3 id="极大似然估计">极大似然估计</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200047048.png" alt="image-20250320200047048">
<figcaption aria-hidden="true">image-20250320200047048</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200109835.png" alt="image-20250320200109835">
<figcaption aria-hidden="true">image-20250320200109835</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200139754.png" alt="image-20250320200139754">
<figcaption aria-hidden="true">image-20250320200139754</figcaption>
</figure>
<h2 id="作业">作业</h2>
<h3 id="何为正则化其功能是什么如何理解l1和l2正则化">1、何为正则化？其功能是什么？如何理解L1和L2正则化？</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250320_170100.jpg" alt="IMG_20250320_170100">
<figcaption aria-hidden="true">IMG_20250320_170100</figcaption>
</figure>
<h3 id="什么是偏差与方差简要说明偏差方差与过拟合欠拟合的关系">2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。</h3>
<table>
<colgroup>
<col style="width: 6%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 44%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>现象</th>
<th>偏差</th>
<th>方差</th>
<th>典型原因</th>
<th>解决方法</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>欠拟合</td>
<td>高</td>
<td>低</td>
<td>模型过于简单（如线性模型拟合非线性数据）</td>
<td>增加特征、使用更复杂模型、减少正则化</td>
</tr>
<tr class="even">
<td>过拟合</td>
<td>低</td>
<td>高</td>
<td>模型过于复杂（如深度树模型拟合噪声）</td>
<td>增加数据、正则化、简化模型、早停法</td>
</tr>
</tbody>
</table>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250320_181442.jpg" alt="IMG_20250320_181442">
<figcaption aria-hidden="true">IMG_20250320_181442</figcaption>
</figure>
<h3 id="公式推导最小二乘法多元线性回归与岭回归逻辑回归极大似然法">3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）</h3>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163937.jpg" alt="IMG_20250321_163937">
<figcaption aria-hidden="true">IMG_20250321_163937</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163941.jpg" alt="IMG_20250321_163941">
<figcaption aria-hidden="true">IMG_20250321_163941</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163944.jpg" alt="IMG_20250321_163944">
<figcaption aria-hidden="true">IMG_20250321_163944</figcaption>
</figure>
<figure>
<img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163948.jpg" alt="IMG_20250321_163948">
<figcaption aria-hidden="true">IMG_20250321_163948</figcaption>
</figure>
<h2 id="参考文献">参考文献</h2>
<p><a href="https://www.bilibili.com/video/BV1Z44y147xA/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">“L1和L2正则化”直观理解(之一)，从拉格朗日乘数法角度进行理解_哔哩哔哩_bilibili</a></p>
<p>超级棒的公式证明，对我帮助很大</p>
<p>https://www.bilibili.com/video/BV1Mh411e7VU?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=3&amp;spm_id_from=333.788.videopod.episodes</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——上机作业1</title>
    <url>/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A1/</url>
    <content><![CDATA[<h2 id="环境搭建">环境搭建</h2>
<p>安装vmware虚拟机</p>
<p>安装ubuntu</p>
<h2 id="在ubuntu终端里编写c语言程序">在Ubuntu终端里编写C语言程序</h2>
<p>打开终端：ctrl+alt+t</p>
<p>新建文件：<strong>vim hello.c</strong></p>
<p>输入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#define DISPLAY &quot;hello c!&quot;</span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">  printf(&quot;%s\n&quot;, DISPLAY);</span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br><span class="line">ZZ（*说明：ZZ当前文件进行快速保存操作*）</span><br></pre></td></tr></table></figure>
<p>退出编译模式：shift+：</p>
<p>输入：w保存q退出</p>
<p><strong>预编译(Preprocessing)</strong></p>
<p><em>对各种预处理指令（#include #define #ifdef
等#开始的代码行）进行处理，删除注释和多余的空白字符，生成一份新的代码</em></p>
<p>输入：<strong>gcc -E hello.c -o hello.i</strong></p>
<ol type="1">
<li><strong>命令分解</strong></li>
</ol>
<ul>
<li><strong><code>gcc</code></strong> ：GNU Compiler
Collection（GCC）的编译器命令。</li>
<li><strong><code>-E</code></strong> ：选项表示
<strong>仅执行预处理阶段</strong> ，不进行编译、汇编和链接。</li>
<li><strong><code>hello.c</code></strong> ：输入的C语言源文件。</li>
<li><strong><code>-o hello.i</code></strong>
：指定预处理后的输出文件名为 <code>hello.i</code>（<code>.i</code>
是预处理文件的默认后缀）。</li>
</ul>
<p><strong>2. 预处理阶段的作用</strong></p>
<p>预处理是编译过程的第一个阶段，主要处理以下内容：</p>
<ol type="1">
<li>头文件展开
<ul>
<li>将 <code>#include &lt;stdio.h&gt;</code>
等指令替换为对应头文件的实际内容。</li>
</ul></li>
<li>宏展开
<ul>
<li>替换 <code>#define PI 3.14</code> 等宏定义。</li>
</ul></li>
<li>条件编译
<ul>
<li>处理 <code>#ifdef</code>, <code>#ifndef</code>, <code>#endif</code>
等条件编译指令。</li>
</ul></li>
<li>删除注释
<ul>
<li>移除代码中的注释（<code>//</code> 或 <code>/* */</code>）。</li>
</ul></li>
</ol>
<p><strong>编译(Compilation)</strong></p>
<p><em>对代码进行语法、语义分析和错误判断，生成汇编代码文件</em></p>
<p><strong>gcc -S hello.i -o hello.s</strong></p>
<p><strong>编译阶段的作用</strong></p>
<p>在编译流程中，<code>-S</code> 选项对应 <strong>编译阶段</strong>
，主要完成以下任务：</p>
<ol type="1">
<li><strong>语法分析</strong> ：检查代码是否符合C语言语法规则。</li>
<li><strong>中间代码生成</strong>
：将预处理后的代码转换为中间表示（如抽象语法树）。</li>
<li><strong>优化</strong> ：根据优化选项（如
<code>-O2</code>）对代码进行优化。</li>
<li><strong>生成汇编代码</strong>
：将优化后的中间代码转换为目标平台的汇编指令（如x86-64汇编）。</li>
</ol>
<p><strong>汇编(Assembly)</strong></p>
<p><strong>gcc -c hello.s -o hello.o</strong></p>
<p><strong>汇编阶段的作用</strong></p>
<p>该命令执行 <strong>汇编阶段</strong> ，将人类可读的汇编代码（如
<code>mov</code>, <code>call</code> 等指令）转换为
<strong>二进制机器码</strong> ，生成目标文件（<code>.o</code>）。
目标文件包含：</p>
<ul>
<li>机器指令（二进制代码）。</li>
<li>符号表（函数名、变量名等）。</li>
<li>未解析的引用（如外部函数 <code>printf</code> 的地址）。</li>
</ul>
<p><strong>链接(Linking/Build)</strong></p>
<p><strong>gcc hello.o -o hello</strong></p>
<p><strong>链接阶段的作用</strong></p>
<p>链接器（<code>ld</code>）完成以下任务：</p>
<ol type="1">
<li>合并代码和数据
<ul>
<li>将 <code>hello.o</code> 中的机器码与标准库（如 <code>stdio.h</code>
中的 <code>printf</code>）的二进制代码合并。</li>
</ul></li>
<li>解析符号引用
<ul>
<li>解决外部符号（如
<code>printf</code>）的地址，确保所有函数和全局变量正确关联。</li>
</ul></li>
<li>生成可执行文件格式
<ul>
<li>创建符合操作系统要求的可执行文件（如Linux的ELF格式）。</li>
</ul></li>
</ol>
<p><strong>程序运行</strong></p>
<p><strong>./hello</strong></p>
<h2 id="手动安装vmware-tools">手动安装VMware tools</h2>
<p><a href="https://www.bilibili.com/video/BV1F6DzY2Ep9/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">手动安装VMware
Tools（提示VMware Tools 不再随旧版客户机操作系统的 VMware Workstation
一起提供的解决办法）_哔哩哔哩_bilibili</a></p>
<p><strong>在线安装</strong></p>
<p>如果方法一不行，可以试试方法二，我是通过方法二进行安装的。</p>
<p>首先更新系统已安装的软件源，以确保是最新的，在终端输入命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br></pre></td></tr></table></figure>
<p>然后再输入命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install open-vm-tools-desktop</span><br></pre></td></tr></table></figure>
<p>完成后运行upgrade命令，来升级系统中已安装的软件包(命令后面的
-y可以跳过确认询问)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt upgrade -y</span><br></pre></td></tr></table></figure>
<p>完成后进行重启，重启过后，点击菜单栏查看，变成重新安装就是成功了。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——上机作业2</title>
    <url>/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A2/</url>
    <content><![CDATA[<h3 id="实验1变量输出与机器数分析"><strong>实验1：变量输出与机器数分析</strong></h3>
<h4 id="运行代码并分析输出"><strong>1.1 运行代码并分析输出</strong></h4>
<p><strong>源代码</strong>： <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> x = <span class="number">-1</span>;</span><br><span class="line">    <span class="type">unsigned</span> u = <span class="number">2147483648</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x = %u = %d.\n&quot;</span>, x, x);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;u = %u = %d.\n&quot;</span>, u, u);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>编译与运行</strong>： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -o test1 test1.c</span><br><span class="line">./test1</span><br></pre></td></tr></table></figure></p>
<p><strong>输出结果</strong>（假设32位系统）： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x = 4294967295 = -1.</span><br><span class="line">u = 2147483648 = -2147483648.</span><br></pre></td></tr></table></figure></p>
<p><strong>结果分析</strong>： -
<strong><code>x = %u</code></strong>：<br>
<code>x</code> 是 <code>int</code> 类型的 <code>-1</code>，二进制补码为
<code>0xFFFFFFFF</code>。用
<code>%u</code>（无符号）解释时，<code>0xFFFFFFFF</code> 对应
<code>4294967295</code>。 - <strong><code>x = %d</code></strong>：<br>
正常输出 <code>-1</code>。 -
<strong><code>u = %u</code></strong>：<br>
<code>u</code> 是 <code>unsigned</code> 类型的
<code>2147483648</code>（即 <code>0x80000000</code>），直接输出为
<code>2147483648</code>。 - <strong><code>u = %d</code></strong>：<br>
用 <code>%d</code>（有符号）解释
<code>0x80000000</code>，最高位为1，表示负数，结果为
<code>-2147483648</code>。</p>
<hr>
<h4 id="反汇编分析机器数"><strong>1.2 反汇编分析机器数</strong></h4>
<p><strong>步骤</strong>： 1. 生成目标文件： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -c test1.c -o test1.o</span><br></pre></td></tr></table></figure> 2.
反汇编查看变量赋值： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">objdump -d -M intel test1.o</span><br></pre></td></tr></table></figure></p>
<p><strong>关键汇编代码</strong>（简化）： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov DWORD PTR [rbp-4], 0xffffffff   ; x = -1 (机器数 0xFFFFFFFF)</span><br><span class="line">mov DWORD PTR [rbp-8], 0x80000000   ; u = 2147483648 (机器数 0x80000000)</span><br></pre></td></tr></table></figure></p>
<p><strong>变量机器数总结</strong>： | 变量 | 机器数（十六进制） | | —-
| —————— | | x | 0xFFFFFFFF | | u | 0x80000000 |</p>
<hr>
<h3 id="实验2表达式结果与反汇编分析"><strong>实验2：表达式结果与反汇编分析</strong></h3>
<h4 id="验证表达式结果"><strong>2.1 验证表达式结果</strong></h4>
<p><strong>源代码</strong>： <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;-1 &lt; 0\t\t -&gt; %d\n&quot;</span>, (<span class="number">-1</span> &lt; <span class="number">0</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;-1 &lt; 0U\t -&gt; %d\n&quot;</span>, (<span class="number">-1</span> &lt; <span class="number">0U</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;2147483647 &gt; -2147483647 - 1\t -&gt; %d\n&quot;</span>, (<span class="number">2147483647</span> &gt; <span class="number">-2147483647</span> - <span class="number">1</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;2147483647U &gt; -2147483647 - 1\t -&gt; %d\n&quot;</span>, (<span class="number">2147483647U</span> &gt; <span class="number">-2147483647</span> - <span class="number">1</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>编译与运行</strong>： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -o test2 test2.c</span><br><span class="line">./test2</span><br></pre></td></tr></table></figure></p>
<p><strong>输出结果</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-1 &lt; 0           -&gt; 1</span><br><span class="line">-1 &lt; 0U          -&gt; 0</span><br><span class="line">2147483647 &gt; -2147483647 - 1  -&gt; 1</span><br><span class="line">2147483647U &gt; -2147483647 - 1 -&gt; 0</span><br></pre></td></tr></table></figure></p>
<p><strong>结果分析</strong>： 1.
<strong><code>-1 &lt; 0</code></strong>：<br>
有符号比较，<code>-1</code> 小于
<code>0</code>，结果为真（<code>1</code>）。 2.
<strong><code>-1 &lt; 0U</code></strong>：<br>
<code>0U</code> 是无符号，<code>-1</code> 被转换为无符号数
<code>0xFFFFFFFF</code>（4294967295），远大于
<code>0U</code>，结果为假（<code>0</code>）。 3.
<strong><code>2147483647 &gt; -2147483647 - 1</code></strong>：<br>
右侧表达式 <code>-2147483647 - 1</code> 等于
<code>-2147483648</code>（<code>INT_MIN</code>），有符号比较，<code>2147483647</code>（<code>INT_MAX</code>）大于
<code>INT_MIN</code>，结果为真（<code>1</code>）。 4.
<strong><code>2147483647U &gt; -2147483647 - 1</code></strong>：<br>
左侧是无符号，右侧 <code>INT_MIN</code> 被转换为无符号数
<code>0x80000000</code>（2147483648），比较 <code>2147483647</code> 和
<code>2147483648</code>，结果为假（<code>0</code>）。</p>
<hr>
<h4 id="反汇编分析表达式"><strong>2.2 反汇编分析表达式</strong></h4>
<p><strong>步骤</strong>： 1. 生成目标文件： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -c test2.c -o test2.o</span><br></pre></td></tr></table></figure> 2.
反汇编查看比较指令： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">objdump -d -M intel test2.o</span><br></pre></td></tr></table></figure></p>
<p><strong>关键汇编代码</strong>（以 <code>-1 &lt; 0U</code> 为例）：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov DWORD PTR [rbp-4], 0xffffffff   ; -1 的机器数</span><br><span class="line">cmp DWORD PTR [rbp-4], 0            ; 比较时，-1 被视为无符号数 4294967295</span><br><span class="line">setb al                             ; 设置结果（0 表示假）</span><br></pre></td></tr></table></figure></p>
<p><strong>总结</strong>： - 类型转换规则决定了比较结果。 -
反汇编显示编译器如何处理有符号与无符号的隐式转换。</p>
<hr>
<h3 id="实验报告建议"><strong>实验报告建议</strong></h3>
<ol type="1">
<li><strong>源代码与输出结果</strong>：附上代码及运行结果。</li>
<li><strong>反汇编截图</strong>：展示变量赋值和表达式比较的汇编代码。</li>
<li><strong>分析</strong>：
<ul>
<li>解释类型转换对输出的影响。</li>
<li>说明反汇编中机器数与表达式比较的底层实现。</li>
</ul></li>
</ol>
<p>如果需要更详细的反汇编代码或具体步骤解释，请随时告知！</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——上机作业3</title>
    <url>/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A3/</url>
    <content><![CDATA[<p>以下是针对表1和表2中所有函数的实现和验证分析，严格按照约束条件和操作符数量限制设计：</p>
<hr>
<h3 id="表1-位操作函数实现"><strong>表1 位操作函数实现</strong></h3>
<h4 id="lsbzero-将x的最低有效位清零"><strong>1. lsbZero
(将x的最低有效位清零)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">lsbZero</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> x &amp; (~<span class="number">1</span>);  <span class="comment">// 操作符: &amp; ~ 1 (共3个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x = 0x05 (0b101)</code> → <code>0x04 (0b100)</code></p>
<hr>
<h4 id="bytenot-将x的第n个字节取反"><strong>2. byteNot
(将x的第n个字节取反)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">byteNot</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = <span class="number">0xFF</span> &lt;&lt; (n &lt;&lt; <span class="number">3</span>);  <span class="comment">// 构造字节掩码</span></span><br><span class="line">    <span class="keyword">return</span> x ^ mask;               <span class="comment">// 操作符: &lt;&lt; &lt;&lt; 3 &lt;&lt; 8 (共6个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x = 0x12345678, n=1</code> → <code>0x1234A978</code>（第1字节
<code>0x56</code> 取反为 <code>0xA9</code>）</p>
<hr>
<h4 id="bytexor-比较x和y的第n个字节"><strong>3. byteXor
(比较x和y的第n个字节)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">byteXor</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> shift = n &lt;&lt; <span class="number">3</span>;</span><br><span class="line">    <span class="type">int</span> x_byte = (x &gt;&gt; shift) &amp; <span class="number">0xFF</span>;</span><br><span class="line">    <span class="type">int</span> y_byte = (y &gt;&gt; shift) &amp; <span class="number">0xFF</span>;</span><br><span class="line">    <span class="keyword">return</span> !!(x_byte ^ y_byte);  <span class="comment">// 操作符: &lt;&lt; &gt;&gt; &amp; ^ !! (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0x12345678, y=0x12745678, n=2</code> → <code>1</code>（第2字节
<code>0x34</code> vs <code>0x74</code>）</p>
<hr>
<h4 id="logicaland-模拟x-y"><strong>4. logicalAnd (模拟x &amp;&amp;
y)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">logicalAnd</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (!!x) &amp; (!!y);  <span class="comment">// 操作符: !! &amp; (共2个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0, y=5</code> → <code>0</code>；<code>x=1, y=2</code> →
<code>1</code></p>
<hr>
<h4 id="logicalor-模拟x-y"><strong>5. logicalOr (模拟x ||
y)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">logicalOr</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (!!x) | (!!y);  <span class="comment">// 操作符: !! | (共2个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0, y=0</code> → <code>0</code>；<code>x=0, y=1</code> →
<code>1</code></p>
<hr>
<h4 id="rotateleft-循环左移n位"><strong>6. rotateLeft
(循环左移n位)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">rotateLeft</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = (<span class="number">0xFF</span> &lt;&lt; <span class="number">24</span>) &gt;&gt; (<span class="number">32</span> - n);  <span class="comment">// 构造高位掩码</span></span><br><span class="line">    <span class="keyword">return</span> (x &lt;&lt; n) | ((x &gt;&gt; (<span class="number">32</span> - n)) &amp; mask);  <span class="comment">// 操作符: &lt;&lt; &gt;&gt; | &amp; (共25个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0x12345678, n=4</code> →
<code>0x23456781</code>（左移4位，高位循环到低位）</p>
<hr>
<h4 id="paritycheck-奇偶校验"><strong>7. parityCheck
(奇偶校验)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">parityCheck</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">16</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">8</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">4</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">2</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> x &amp; <span class="number">1</span>;  <span class="comment">// 操作符: ^ &gt;&gt; &amp; (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0b1010</code> →
<code>0</code>（2个1，偶数）；<code>x=0b101</code> →
<code>1</code>（奇数）</p>
<hr>
<h3 id="表2-补码运算函数实现"><strong>表2 补码运算函数实现</strong></h3>
<h4 id="mul2ok-判断2x是否溢出">**8. mul2OK (判断2*x是否溢出)**</h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mul2OK</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> sign = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> result = x &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> !(((result &gt;&gt; <span class="number">31</span>) ^ sign) &amp; (!!(x ^ (x &lt;&lt; <span class="number">1</span>))));  <span class="comment">// 操作符: &gt;&gt; &lt;&lt; ^ &amp; !! (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0x40000000</code> →
<code>0</code>（溢出）；<code>x=0x3FFFFFFF</code> → <code>1</code></p>
<hr>
<h4 id="mult3div2-计算x32">**9. mult3div2 (计算(x*3)/2)**</h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mult3div2</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> temp = x + x + x;</span><br><span class="line">    <span class="type">int</span> sign = temp &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> (temp + (temp &gt;&gt; <span class="number">31</span> &amp; <span class="number">1</span>)) &gt;&gt; <span class="number">1</span>;  <span class="comment">// 操作符: + &gt;&gt; &amp; (共12个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=-3</code> → <code>(-9)/2 = -4</code>（向零取整）</p>
<hr>
<h4 id="subok-判断x---y是否溢出"><strong>10. subOK (判断x -
y是否溢出)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">subOK</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="type">int</span> sub = x + (~y + <span class="number">1</span>);</span><br><span class="line">    <span class="type">int</span> x_sign = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> y_sign = (~y + <span class="number">1</span>) &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> sub_sign = sub &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> !((~(x_sign ^ y_sign)) &amp; (x_sign ^ sub_sign));  <span class="comment">// 操作符: ~ ^ + &gt;&gt; &amp; (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=0x80000000, y=1</code> → <code>0</code>（溢出）</p>
<hr>
<h4 id="absval-求绝对值"><strong>11. absVal (求绝对值)</strong></h4>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">absVal</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> (x + mask) ^ mask;  <span class="comment">// 操作符: &gt;&gt; + ^ (共10个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br>
<code>x=-5</code> → <code>5</code>；<code>x=3</code> →
<code>3</code></p>
<hr>
<h3 id="验证方法"><strong>验证方法</strong></h3>
<ol type="1">
<li><strong>编写测试代码</strong>：为每个函数设计边界值（如0、最大值、最小值）。</li>
<li><strong>反汇编分析</strong>：使用 <code>objdump -d</code>
检查生成的机器码是否符合操作符限制。</li>
<li><strong>覆盖率测试</strong>：确保所有分支条件被触发（如正负数、溢出情况）。</li>
</ol>
<hr>
<h3 id="关键技巧"><strong>关键技巧</strong></h3>
<ul>
<li><strong>位掩码</strong>：使用
<code>0xFF</code>、<code>0x80000000</code> 等构造特定模式。</li>
<li><strong>符号位操作</strong>：通过 <code>x &gt;&gt; 31</code>
提取符号位。</li>
<li><strong>逻辑运算替代</strong>：用 <code>!!x</code>
将非零值转换为1，用 <code>x ^ (x &gt;&gt; 31)</code> 处理绝对值。</li>
</ul>
<p>如果需要具体函数的详细推导或测试用例，可进一步说明！</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——期末复习（下）</title>
    <url>/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
    <content><![CDATA[<h2 id="期末复习">期末复习</h2>
<h3 id="方差与偏差">方差与偏差</h3>
<p>方差（Variance）和偏差（Bias）是机器学习中衡量模型性能的两个核心概念，它们共同构成了<strong>偏差-方差权衡</strong>（Bias-Variance
Tradeoff）的基础框架。以下是两者的定义与区别：</p>
<p><strong>1. 偏差（Bias）</strong></p>
<ul>
<li><strong>定义</strong>：偏差是指模型预测的期望值与真实值之间的差异。它反映了模型本身的拟合能力，即是否能够准确捕捉数据中的规律。</li>
</ul>
<p><strong>2. 方差（Variance）</strong></p>
<ul>
<li><strong>定义</strong>：方差是指模型在不同训练数据集下预测结果的波动程度。它衡量了模型对训练数据中噪声或微小变化的敏感性。</li>
</ul>
<p><strong>3. 如何降低偏差与方差</strong></p>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 56%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th><strong>目标</strong></th>
<th><strong>方法</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>降低偏差</strong></td>
<td>增加模型复杂度（如更多特征、更深的神经网络）、减少正则化强度</td>
<td>使用多项式回归替代线性回归</td>
</tr>
<tr class="even">
<td><strong>降低方差</strong></td>
<td>增加训练数据、引入正则化（L1/L2）、使用集成方法（如
Bagging、Boosting）</td>
<td>随机森林（Bagging）降低决策树的方差</td>
</tr>
</tbody>
</table>
<p><strong>4. 总结</strong></p>
<ul>
<li><strong>偏差</strong>关注模型是否能准确拟合数据（<strong>学习能力</strong>），而<strong>方差</strong>关注模型对数据波动的稳定性（<strong>泛化能力</strong>）。</li>
<li>实际应用中需通过交叉验证、正则化或集成学习等技术平衡两者的关系。</li>
</ul>
<h3 id="监督学习与无监督学习">监督学习与无监督学习</h3>
<p>以下是关于监督学习与无监督学习的核心区别总结：</p>
<p><strong>1. 监督学习（Supervised Learning）</strong></p>
<p><strong>任务类型</strong>：<br>
-
<strong>分类（Classification）</strong>：预测离散类别标签（如垃圾邮件/非垃圾邮件）。<br>
-
<strong>回归（Regression）</strong>：预测连续数值标签（如房价预测）。</p>
<p><strong>特点</strong>：<br>
- 需要<strong>带标签的样本</strong>（Labeled
Data），即每个训练样本都有明确的输入 $ x $ 和输出 $ y $。<br>
- 模型通过学习输入与标签之间的映射关系进行预测。</p>
<p><strong>2. 无监督学习（Unsupervised Learning）</strong></p>
<p><strong>任务类型</strong>：</p>
<ul>
<li><strong>聚类（Clustering）</strong>：将样本划分为具有相似特征的群体（如客户分群）。<br>
</li>
<li><strong>降维（Dimensionality
Reduction）</strong>：压缩数据维度同时保留关键信息（如PCA）。</li>
</ul>
<p><strong>特点</strong>：<br>
- 仅需<strong>无标签的样本</strong>（Unlabeled
Data），无需预先定义输出目标。<br>
- 模型自主挖掘数据内在结构或分布规律。</p>
<h3 id="贝叶斯分类">贝叶斯分类</h3>
<h4 id="贝叶斯分类器">贝叶斯分类器</h4>
<h5 id="贝叶斯决策论">贝叶斯决策论</h5>
<p>本质思想：寻找合适的参数使得「当前的样本情况发生的概率」最大。</p>
<p>又由于假设每一个样本相互独立（概率条件理想的情况下），因此可以用连乘的形式表示上述概率，当然由于概率较小导致连乘容易出现浮点数精度损失，因此尝尝采用取对数的方式来避免「下溢」问题。也就是所谓的「对数似然估计」方法。</p>
<p>在已知样本特征 $ $ 的条件下，选择分类结果 $ c_i
$，使得分类的期望损失（Risk）最小<strong>。</strong></p>
<p>**(1) 损失函数 $ _{ij} $**</p>
<ul>
<li><strong>定义</strong>：$ _{ij} $ 是将真实类别为 $ c_j $
的样本误分类为 $ c_i $ 所产生的损失。
<ul>
<li>例如：
<ul>
<li>在医学诊断中，若 $ c_1 $ 表示“患病”，$ c_2 $ 表示“未患病”：
<ul>
<li>$ _{21} <span class="math inline">：<em>将</em><em>实</em><em>际</em><em>患</em><em>病</em>（</span>
c_1 <span class="math inline">）<em>误</em><em>判</em><em>为</em><em>未</em><em>患</em><em>病</em>（</span>
c_2 $）的损失（可能更高）。</li>
<li>$ _{12} <span class="math inline">：<em>将</em><em>实</em><em>际</em><em>未</em><em>患</em><em>病</em>（</span>
c_2 <span class="math inline">）<em>误</em><em>判</em><em>为</em><em>患</em><em>病</em>（</span>
c_1 $）的损失（可能较低）。</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p><strong>(2) 条件风险（单个样本的期望损失）</strong></p>
<p>对于给定样本 $ $，若将其分类为 $ c_i
$，则其<strong>条件风险</strong>为： <span class="math display">$$
R(c_i | \mathbf{x}) = \sum_{j=1}^N \lambda_{ij} P(c_j | \mathbf{x})
$$</span> - <strong>含义</strong>：在已知 $ $ 的情况下，分类为 $ c_i $
的平均损失。 - <strong>推导</strong>： - $ P(c_j | ) $：样本 $ $
真实属于 $ c_j $ 的后验概率。 - $ <em>{ij} $：若真实类别是 $ c_j
$，但被分到 $ c_i $，则产生损失 $ </em>{ij} $。 -
因此，总期望损失是所有可能真实类别的加权和（权重为后验概率）。</p>
<p><strong>(3) 总体风险</strong></p>
<p>对于整个数据集，分类器 $ h() $ 的<strong>总体风险</strong>为： <span class="math display"><em>R</em>(<em>h</em>) = 𝔼<sub><strong>x</strong></sub>[<em>R</em>(<em>h</em>(<strong>x</strong>)|<strong>x</strong>)] = ∫<em>R</em>(<em>h</em>(<strong>x</strong>)|<strong>x</strong>)<em>p</em>(<strong>x</strong>)<em>d</em><strong>x</strong></span>
- <strong>含义</strong>：所有样本的平均条件风险。h为分类器（模型） -
<strong>目标</strong>：找到使 $ R(h) $ 最小的分类器 $ h() $。</p>
<h5 id="贝叶斯决策规则"><strong>贝叶斯决策规则</strong></h5>
<p>根据上述定义，贝叶斯决策论的分类规则是： &gt; <strong>对于样本 $
$，选择使其条件风险 $ R(c_i | ) $ 最小的类别 $ c_i $
作为预测结果。</strong></p>
<p>即： <span class="math display">$$
h^*(\mathbf{x}) = \arg\min_{c_i} R(c_i | \mathbf{x}) = \arg\min_{c_i}
\sum_{j=1}^N \lambda_{ij} P(c_j | \mathbf{x})
$$</span></p>
<h5 id="特殊情况0-1-损失函数"><strong>特殊情况：0-1
损失函数</strong></h5>
<p>当所有误分类的损失相同（即 $ <em>{ij} = 1 $ 对于 $ i j <span class="math inline">，</span> </em>{ii} = 0 $）<strong>0-1
损失函数</strong>： <span class="math display">$$
\lambda_{ij} =
\begin{cases}
0, &amp; \text{if } i = j \\
1, &amp; \text{otherwise}
\end{cases}
$$</span> 此时条件风险简化为： <span class="math display"><em>R</em>(<em>c</em><sub><em>i</em></sub>|<strong>x</strong>) = ∑<sub><em>j</em> ≠ <em>i</em></sub><em>P</em>(<em>c</em><sub><em>j</em></sub>|<strong>x</strong>) = 1 − <em>P</em>(<em>c</em><sub><em>i</em></sub>|<strong>x</strong>)</span>
原因：概率之和为 1：$ <em>{j=1}^N P(c_j | ) = 1 $，因此 $ </em>{j i}
P(c_j | ) = 1 - P(c_i | ) $。</p>
<p>此时，最小化风险等价于<strong>最大化后验概率</strong>，即： <span class="math display"><em>h</em><sup>*</sup>(<strong>x</strong>) = arg max<sub><em>c</em><sub><em>i</em></sub></sub><em>P</em>(<em>c</em><sub><em>i</em></sub>|<strong>x</strong>)</span>
这正是传统贝叶斯分类器的决策规则。</p>
<blockquote>
<p>即在x样本的情况下，分类正确的概率最大</p>
</blockquote>
<h4 id="后验概率与先验概率">后验概率与先验概率</h4>
<h5 id="后验概率">后验概率</h5>
<p>后验概率（Posterior
Probability）是贝叶斯理论中的核心概念，指的是<strong>在观察到新证据（数据）后，对事件发生概率的修正</strong>
。 其本质是：</p>
<blockquote>
<p><strong>“已知结果（数据），反推原因（类别或参数）的概率”</strong>
。</p>
</blockquote>
<p>已知结果（数据）B，反推最可能的原因A（后验概率
<em>P</em>(<em>A</em>∣<em>B</em>) ）</p>
<h5 id="先验概率prior-probability"><strong>先验概率（Prior
Probability）</strong></h5>
<p>先验概率是贝叶斯统计中的核心概念，指的是在<strong>观察到新数据之前</strong>，对某一事件或假设的概率估计。它是基于<strong>已有知识、经验或假设</strong>得出的初始概率，后续会通过新数据更新为更准确的<strong>后验概率</strong>。</p>
<p><strong>1. 核心定义</strong></p>
<ul>
<li><strong>数学表达</strong>：<br>
<span class="math display"><em>P</em>(<em>A</em>)</span>
<ul>
<li>$ P(A) $：事件 $ A $ 的先验概率。</li>
<li>例如：$ A $ 表示“某人患有某种疾病”，则 $ P(A) $
是该疾病的已知发病率（在未进行检测前的概率）。</li>
</ul></li>
<li><strong>与后验概率的区别</strong>：
<ul>
<li><strong>先验概率</strong>：$ P(A) $，在无新数据时的概率。<br>
</li>
<li><strong>后验概率</strong>：$ P(A|B) $，在观察到数据 $ B $
后更新的概率（通过贝叶斯定理计算）。</li>
</ul></li>
</ul>
<p><strong>2. 直观理解</strong></p>
<p><strong>(1) 类比：医学诊断</strong></p>
<ul>
<li><strong>先验概率</strong>：某种疾病的已知发病率（如 1%）。<br>
</li>
<li><strong>新数据</strong>：患者接受检测，结果为阳性。<br>
</li>
<li><strong>后验概率</strong>：结合发病率和检测结果，计算实际患病的概率（如
8.7%，参考贝叶斯定理的经典医学测试案例）。</li>
</ul>
<h4 id="生成式模型和判别式模型">生成式模型和判别式模型</h4>
<h5 id="核心区别"><strong>核心区别</strong></h5>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 44%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th><strong>模型类型</strong></th>
<th><strong>建模目标</strong></th>
<th><strong>数学表达</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>判别式模型</strong></td>
<td>直接建模 $ P(c</td>
<td>) $</td>
</tr>
<tr class="even">
<td><strong>生成式模型</strong></td>
<td>先建模联合概率 $ P(, c) $，再推导 $ P(c</td>
<td>) $</td>
</tr>
</tbody>
</table>
<h5 id="详细解释"><strong>详细解释</strong></h5>
<p><strong>1. 判别式模型（Discriminative Model）</strong></p>
<ul>
<li><strong>目标</strong>：直接学习从输入 $ $ 到标签 $ c $
的映射关系。</li>
<li><strong>数学本质</strong>：建模条件概率 $ P(c|) $，即“已知特征 $
$，预测类别 $ c $”。</li>
<li><strong>特点</strong>：
<ul>
<li>不关心数据本身的分布，只关注分类边界。</li>
<li>例如：逻辑回归、支持向量机（SVM）、神经网络等。</li>
</ul></li>
</ul>
<p><strong>2. 生成式模型（Generative Model）</strong></p>
<ul>
<li><p><strong>目标</strong>：先学习数据的生成过程，即联合概率 $ P(, c)
$，再通过贝叶斯定理推导条件概率 $ P(c|) $。</p></li>
<li><p><strong>数学步骤</strong>：</p>
<ol type="1">
<li>建模 $ P(|c) $（特征在类别 $ c $ 下的分布）和 $ P(c)
$（类别先验）。</li>
<li>根据贝叶斯定理计算后验概率： <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(\mathbf{x}|c)P(c)}{P(\mathbf{x})}
$$</span></li>
<li>选择使 $ P(c|) $ 最大的类别作为预测结果。</li>
</ol></li>
</ul>
<h5 id="示例二分类问题"><strong>示例：二分类问题</strong></h5>
<p>假设我们要判断一封邮件是否为垃圾邮件（$ c=spam $ 或 $ ham $）。</p>
<p><strong>判别式模型（逻辑回归）</strong></p>
<p>直接建模： <span class="math display">$$
P(spam|\mathbf{x}) = \frac{1}{1 + e^{-(w^T \mathbf{x} + b)}}
$$</span> 若 $ P(spam|) &gt; 0.5 $，则判定为垃圾邮件。</p>
<p><strong>生成式模型（朴素贝叶斯）</strong></p>
<ol type="1">
<li>建模联合概率： <span class="math display"><em>P</em>(<strong>x</strong>,<em>s</em><em>p</em><em>a</em><em>m</em>) = <em>P</em>(<em>s</em><em>p</em><em>a</em><em>m</em>)∏<sub><em>i</em></sub><em>P</em>(<em>w</em><em>o</em><em>r</em><em>d</em><sub><em>i</em></sub>|<em>s</em><em>p</em><em>a</em><em>m</em>)</span>
<span class="math display"><em>P</em>(<strong>x</strong>,<em>h</em><em>a</em><em>m</em>) = <em>P</em>(<em>h</em><em>a</em><em>m</em>)∏<sub><em>i</em></sub><em>P</em>(<em>w</em><em>o</em><em>r</em><em>d</em><sub><em>i</em></sub>|<em>h</em><em>a</em><em>m</em>)</span></li>
<li>计算后验概率： <span class="math display">$$
P(spam|\mathbf{x}) = \frac{P(\mathbf{x}|spam)P(spam)}{P(\mathbf{x})}
$$</span> <span class="math display">$$
P(ham|\mathbf{x}) = \frac{P(\mathbf{x}|ham)P(ham)}{P(\mathbf{x})}
$$</span></li>
<li>选择概率更大的类别。</li>
</ol>
<h4 id="生成式模型的建模思路">生成式模型的建模思路</h4>
<p>根据概率论的基本定义： <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(\mathbf{x}, c)}{P(\mathbf{x})}
$$</span> - <strong>含义</strong>： - $ P(, c) $：联合概率，表示特征 $ $
和类别 $ c $ 同时发生的概率。 - $ P() $：边缘概率（证据），表示特征 $ $
出现的概率，用于归一化。</p>
<p>根据贝叶斯定理，联合概率 $ P(, c) $ 可以分解为： <span class="math display"><em>P</em>(<strong>x</strong>,<em>c</em>) = <em>P</em>(<em>c</em>) ⋅ <em>P</em>(<strong>x</strong>|<em>c</em>)</span>
其中： - $ P(c) $：类先验概率（Prior Probability），表示类别 $ c $
在数据中的整体占比。 - $ P(|c) $：似然度（Likelihood），表示在类别 $ c $
下，特征 $ $ 出现的概率。</p>
<p>将上述分解代入条件概率公式，得到： <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(c) \cdot P(\mathbf{x}|c)}{P(\mathbf{x})}
$$</span> 产生问题：</p>
<p>在贝叶斯分类中，需要计算联合概率
<em>P</em>(<strong>x</strong>∣<em>c</em>) ，即在类别 <em>c</em>
下，特征向量 <strong>x</strong>=(<em>x</em>1,<em>x</em>2,…,*x**d<em>)
的条件概率。 若直接建模联合概率，需估计 </em>d*
个特征的所有可能组合的概率。例如：</p>
<ul>
<li>若每个特征有 <em>k</em> 个取值，类别数为 <em>K</em> ，则需要估计
<em>K</em>⋅*k**d* 个参数。</li>
<li>当特征维度 <em>d</em>
很大时（如文本分类中成千上万的词汇），参数数量呈指数级增长，导致计算不可行（<strong>维度灾难</strong>
）。</li>
</ul>
<p>举例：</p>
<ul>
<li><strong>低维空间</strong> ：假设只有 2
个特征（如“免费”和“中奖”），每个特征取值为 0 或 1，则特征空间共有 22=4
个可能的组合（即四个格子）。
<ul>
<li>如果有 100 封邮件，每个格子平均有 25 封邮件（数据较密集）。</li>
</ul></li>
<li><strong>高维空间</strong> ： 当特征维度增加到 <em>d</em>=10,000
时，特征空间的组合数是 210,000 ，远大于宇宙中原子的数量（约 1080 ）。
<ul>
<li>即使有 100 万封邮件，每个组合几乎都是空的（数据极度稀疏）。</li>
</ul></li>
</ul>
<p><strong>结果</strong> ：
在高维空间中，训练数据无法覆盖所有可能的特征组合，导致模型无法可靠估计联合概率
<em>P</em>(x∣c) 。</p>
<p>因此产生<strong>属性条件独立性假设</strong></p>
<h4 id="朴素贝叶斯分类器">朴素贝叶斯分类器</h4>
<p>朴素贝叶斯分类器的核心思想是通过<strong>贝叶斯定理</strong>和<strong>属性条件独立性假设</strong>来简化计算，从而高效地进行分类。</p>
<h5 id="属性条件独立性假设">属性条件独立性假设</h5>
<p>朴素贝叶斯的核心假设是：<strong>在已知类别 $ c $
的条件下，所有属性（特征）之间相互独立</strong>。<br>
因此，联合概率 $ P(|c) $ 可以分解为各属性独立概率的乘积： <span class="math display">$$
P(\mathbf{x}|c) = \prod_{i=1}^d P(x_i|c)
$$</span> 其中 $ d $ 是特征的数量，$ x_i $ 是第 $ i $ 个特征的取值。</p>
<p>将此代入贝叶斯公式： <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(c) \cdot \prod_{i=1}^d
P(x_i|c)}{P(\mathbf{x})}
$$</span></p>
<h5 id="为何可以忽略-p"><strong>为何可以忽略 $ P() $?</strong></h5>
<p>在分类任务中，我们的目标是比较不同类别 $ c $ 的后验概率 $ P(c|)
$，并选择最大值。由于 $ P() $
对所有类别来说是相同的常量（与类别无关），因此在最大化过程中可以忽略：
<span class="math display">$$
\arg\max_{c} P(c|\mathbf{x}) = \arg\max_{c} \left[ \frac{P(c) \cdot
\prod_{i=1}^d P(x_i|c)}{P(\mathbf{x})} \right] = \arg\max_{c} \left[
P(c) \cdot \prod_{i=1}^d P(x_i|c) \right]
$$</span> 这就是公式中 $ P() $ 被省略的原因。</p>
<blockquote>
<p>在比较的过程中，分母相同，可以忽略</p>
</blockquote>
<h5 id="朴素贝叶斯的最终决策规则"><strong>朴素贝叶斯的最终决策规则</strong></h5>
<p>简化后的决策规则为： <span class="math display">$$
h_{nb}(\mathbf{x}) = \arg\max_{c} \left[ P(c) \cdot \prod_{i=1}^d
P(x_i|c) \right]
$$</span> 即： - 计算每个类别的先验概率 $ P(c) $。 -
计算每个特征在该类别下的条件概率 $ P(x_i|c) $。 -
将这些概率相乘，选择乘积最大的类别作为预测结果。</p>
<h5 id="类先验概率-pc-的估计方法"><strong>类先验概率 $ P(c) $
的估计方法</strong></h5>
<p>基于<strong>大数定律</strong> <span class="math display">$$
P(c) = \frac{|D_c|}{|D|}
$$</span> - <strong>符号含义</strong>： - $ D $：训练集，包含所有样本。
- $ D_c $：训练集中类别为 $ c $ 的样本子集。 - $ |D_c| $：类别 $ c $
的样本数量。 - $ |D| $：训练集总样本数量。</p>
<ul>
<li><strong>直观解释</strong>：
类先验概率等于该类别样本数占总样本数的比例。</li>
</ul>
<h5 id="条件概率-px_i-c-的估计方法"><strong>条件概率 $ P(x_i | c) $
的估计方法</strong></h5>
<p>在生成式模型（如朴素贝叶斯分类器）中，<strong>条件概率 $ P(x_i | c)
$</strong> 表示在类别 $ c $ 下，第 $ i $ 个属性取值为 $ x_i $
的概率。根据属性类型（离散或连续），其估计方法不同：</p>
<p><strong>1. 离散属性的条件概率估计</strong></p>
<p><strong>公式</strong>： <span class="math display">$$
P(x_i | c) = \frac{|D_{c,x_i}|}{|D_c|}
$$</span> - <strong>符号含义</strong>： - $ D_c $：训练集中类别为 $ c $
的样本集合。 - $ D_{c,x_i} <span class="math inline">：</span> D_c $
中第 $ i $ 个属性取值为 $ x_i $ 的样本子集。 - $ |D_{c,x_i}| <span class="math inline">：</span> D_{c,x_i} $ 的样本数量。 - $ |D_c| $：类别
$ c $ 的总样本数量。</p>
<p><strong>直观解释</strong>：</p>
<ul>
<li>在类别 $ c $ 的样本中，统计第 $ i $ 个属性取值为 $ x_i $
的频率，作为 $ P(x_i | c) $ 的估计。</li>
<li><strong>示例</strong>：<br>
若类别 $ c=spam $（垃圾邮件）有 200 封，其中 150 封包含“免费”一词，则：
<span class="math display">$$
P(\text{“免费”} | spam) = \frac{150}{200} = 0.75
$$</span></li>
</ul>
<p><strong>注意事项</strong>：</p>
<ul>
<li><strong>零概率问题</strong>：若某属性值在类别 $ c $ 中未出现，则 $
P(x_i | c) = 0 $，可能导致后续计算失效。<br>
<strong>解决方案</strong>：使用<strong>拉普拉斯平滑（Laplace
Smoothing）</strong>，将公式改为： <span class="math display">$$
P(x_i | c) = \frac{|D_{c,x_i}| + 1}{|D_c| + K}
$$</span> 其中 $ K $ 是该属性的取值总数。</li>
</ul>
<p><strong>2. 连续属性的条件概率估计</strong></p>
<p><strong>假设</strong>：属性服从正态分布（高斯分布） <span class="math display">$$
p(x_i | c) = \frac{1}{\sqrt{2\pi}\sigma_{c,i}} \exp\left( -\frac{(x_i -
\mu_{c,i})^2}{2\sigma_{c,i}^2} \right)
$$</span> - <strong>符号含义</strong>： - $ <em>{c,i} $：类别 $ c $ 在第
$ i $ 个属性上的均值。 - $ </em>{c,i}^2 $：类别 $ c $ 在第 $ i $
个属性上的方差。</p>
<p><strong>直观解释</strong>：</p>
<ul>
<li>假设在类别 $ c $ 下，属性 $ x_i $ 服从均值为 $ <em>{c,i} $、方差为 $
</em>{c,i}^2 $ 的正态分布。</li>
<li><strong>示例</strong>：<br>
若类别 $ c=spam $ 的“字数”属性均值 $ <em>{spam, } = 500 $，方差 $
</em>{spam, }^2 = 100 $，则： <span class="math display">$$
p(600 | spam) = \frac{1}{\sqrt{2\pi \cdot 100}} \exp\left( -\frac{(600 -
500)^2}{2 \cdot 100} \right) \approx 0.004
$$</span></li>
</ul>
<p><strong>注意事项</strong>：</p>
<ul>
<li><strong>分布假设</strong>：若实际数据不符合正态分布，需调整假设（如使用核密度估计、对数变换等）。</li>
<li><strong>参数估计</strong>：均值和方差通过训练数据计算： <span class="math display">$$
\mu_{c,i} = \frac{1}{|D_c|} \sum_{x \in D_c} x_i, \quad \sigma_{c,i}^2 =
\frac{1}{|D_c|} \sum_{x \in D_c} (x_i - \mu_{c,i})^2
$$</span></li>
</ul>
<h4 id="半朴素贝叶斯分类器">半朴素贝叶斯分类器</h4>
<p>半朴素贝叶斯分类器是对传统<strong>朴素贝叶斯</strong>的改进，它在保留计算效率的同时，<strong>适当引入部分属性间的依赖关系</strong>，从而在分类性能和计算复杂度之间取得平衡。</p>
<h5 id="独依赖估计ode方法"><strong>独依赖估计（ODE）方法</strong></h5>
<p><strong>(1) 定义</strong></p>
<p>独依赖估计（One-Dependent Estimator,
ODE）是半朴素贝叶斯的一种实现方式，其核心假设是： &gt; <strong>每个属性
$ x_i $ 在类别 $ c $ 之外最多依赖于一个其他属性（称为父属性 $ pa_i
$）</strong>。</p>
<p>数学表达式为： <span class="math display">$$
P(c|\mathbf{x}) \propto P(c) \prod_{i=1}^d P(x_i | c, pa_i)
$$</span> 其中： - $ pa_i $：属性 $ x_i $ 的父属性（依赖的单一属性）。 -
$ P(x_i | c, pa_i) $：在类别 $ c $ 和父属性 $ pa_i $ 下，属性 $ x_i $
的条件概率。</p>
<p><strong>(2) 直观理解</strong></p>
<ul>
<li>每个属性 $ x_i $ 的分布不仅受类别 $ c $ 影响，还受其父属性 $ pa_i $
的影响。</li>
<li>例如，在文本分类中，若属性 $ x_1 $ 是“免费”，$ x_2 $
是“中奖”，可设定 $ pa_2 = x_1
$，表示“中奖”在类别和“免费”的共同作用下出现。</li>
</ul>
<h5 id="超父独依赖估计spode"><strong>超父独依赖估计（SPODE）</strong></h5>
<p>超父独依赖估计（Super Parent One-Dependent Estimator,
SPODE）是<strong>半朴素贝叶斯分类器</strong>的一种扩展，其核心思想是：
&gt; <strong>所有属性都依赖于同一个“超父”属性 $ x_i
$</strong>，从而在保留部分依赖关系的同时避免完全联合概率的计算。</p>
<p><strong>(1) 贝叶斯定理展开</strong> <span class="math display">$$
P(c|\mathbf{x}) = \frac{P(\mathbf{x}, c)}{P(\mathbf{x})}
$$</span> 其中： - $ P(, c) $：联合概率，表示特征 $ $ 和类别 $ c $
同时发生的概率。 - $ P() $：证据（归一化因子）。</p>
<p><strong>(2) 引入“超父”属性 $ x_i $</strong></p>
<p>假设所有属性 $ x_j (j i) $ 在类别 $ c $ 下仅依赖于 $ x_i $，则：
<span class="math display"><em>P</em>(<strong>x</strong>,<em>c</em>) = <em>P</em>(<em>c</em>,<em>x</em><sub><em>i</em></sub>) ⋅ <em>P</em>(<em>x</em><sub>1</sub>,…,<em>x</em><sub><em>i</em> − 1</sub>,<em>x</em><sub><em>i</em> + 1</sub>,…,<em>x</em><sub><em>d</em></sub>|<em>c</em>,<em>x</em><sub><em>i</em></sub>)</span>
进一步分解为： <span class="math display"><em>P</em>(<strong>x</strong>,<em>c</em>) = <em>P</em>(<em>c</em>,<em>x</em><sub><em>i</em></sub>) ⋅ ∏<sub><em>j</em> ≠ <em>i</em></sub><em>P</em>(<em>x</em><sub><em>j</em></sub>|<em>c</em>,<em>x</em><sub><em>i</em></sub>)</span></p>
<p><strong>(3) 最终形式</strong></p>
<p>由于 $ P() $ 对所有类别相同，可忽略，最终决策规则为： <span class="math display">$$
P(c|\mathbf{x}) \propto P(c, x_i) \cdot \prod_{j=1}^d P(x_j | c, x_i)
$$</span> 其中： - $ P(c, x_i) $：类别 $ c $ 和属性 $ x_i $ 的联合概率。
- $ P(x_j | c, x_i) $：在类别 $ c $ 和 $ x_i $ 的条件下，属性 $ x_j $
的概率。</p>
<h5 id="树增强朴素贝叶斯tan-tree-augmented-naive-bayes"><strong>树增强朴素贝叶斯（TAN:
Tree-Augmented Naive Bayes）</strong></h5>
<p><strong>TAN</strong>（Tree-Augmented Naive
Bayes）是<strong>半朴素贝叶斯分类器</strong>的一种扩展，旨在通过引入属性间的<strong>树状依赖关系</strong>，在保留计算效率的同时，显著提升分类性能。它结合了<strong>贝叶斯网络</strong>的建模能力和<strong>生成式模型</strong>的概率推理优势。</p>
<p><strong>1. 核心思想</strong></p>
<p>TAN 的核心假设是： &gt; <strong>所有属性（特征）在类别 $ c $
的基础上，形成一个以属性为节点的树状依赖结构</strong>，即每个属性最多依赖一个其他属性（父属性），且整个依赖图是一棵无环的树。</p>
<p><strong>数学表达</strong>： <span class="math display">$$
P(c|\mathbf{x}) \propto P(c) \cdot \prod_{i=1}^d P(x_i | c, pa_i)
$$</span> 其中： - $ pa_i $：属性 $ x_i $ 的父属性（依赖的单一属性）。 -
$ P(x_i | c, pa_i) $：在类别 $ c $ 和父属性 $ pa_i $ 的条件下，属性 $
x_i $ 的条件概率。</p>
<p><strong>2. TAN 的构建步骤</strong></p>
<p>TAN 通过以下步骤构建属性间的依赖结构：</p>
<p><strong>(1) 计算互信息（Mutual Information）</strong></p>
<p>互信息衡量两个属性之间的相关性： <span class="math display">$$
I(x_i, x_j) = \sum_{x_i, x_j} P(x_i, x_j) \log \frac{P(x_i,
x_j)}{P(x_i)P(x_j)}
$$</span> -
<strong>含义</strong>：互信息越大，两个属性之间的依赖关系越强。</p>
<p><strong>(2) 构建带权图</strong></p>
<ul>
<li>将所有属性视为图中的节点。</li>
<li>每对属性间的边权重设为互信息 $ I(x_i, x_j) $。</li>
</ul>
<p><strong>(3) 最大带权生成树（Maximum Weight Spanning Tree,
MWST）</strong></p>
<p>使用克鲁斯卡尔（Kruskal）算法或普里姆（Prim）算法，选择一棵连接所有属性节点的树，使得：
- 树的边权重（互信息）总和最大。 - 树中无环。</p>
<p><strong>(4) 确定依赖方向</strong></p>
<ul>
<li>随机选择一个根节点（或根据领域知识指定）。</li>
<li>从根节点出发，确定每条边的方向（父属性 → 子属性）。</li>
</ul>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250605223036362.png" alt="image-20250605223036362">
<figcaption aria-hidden="true">image-20250605223036362</figcaption>
</figure>
<h4 id="贝叶斯网">贝叶斯网</h4>
<p>待学习</p>
<h4 id="em算法">EM算法</h4>
<p>EM算法（Expectation-Maximization
Algorithm）是一种<strong>迭代优化算法</strong>，用于处理<strong>含有隐变量</strong>（Hidden
Variables）或<strong>缺失数据</strong>的概率模型参数估计问题。它的核心思想是通过交替执行<strong>期望（E）步</strong>和<strong>最大化（M）步</strong>，逐步逼近模型参数的最大似然估计。</p>
<h5 id="核心思想解决隐变量问题"><strong>1.
核心思想：解决隐变量问题</strong></h5>
<p><strong>(1) 什么是隐变量？</strong></p>
<p>隐变量（Latent
Variables）是模型中<strong>不可观测但影响观测数据</strong>的变量。例如：
-
<strong>混合高斯模型（GMM）</strong>：每个样本属于哪个高斯分布是隐变量。
- <strong>聚类任务</strong>：样本所属的聚类标签是隐变量。</p>
<p><strong>(2) 问题挑战</strong></p>
<p>当存在隐变量时，直接最大化似然函数变得困难。例如： <span class="math display">log <em>P</em>(<strong>x</strong>|<em>θ</em>) = log ∑<sub><em>z</em></sub><em>P</em>(<strong>x</strong>,<em>z</em>|<em>θ</em>)</span>
其中 $ z $ 是隐变量，$ $
是模型参数。由于对数中包含求和，直接求导无法分离参数。</p>
<p><strong>(3) EM算法的解决方案</strong></p>
<p>EM算法通过以下步骤迭代求解： 1.
<strong>E步（期望）</strong>：用当前参数估计隐变量的后验分布（即“责任”分配）。
2.
<strong>M步（最大化）</strong>：基于隐变量的后验分布，最大化期望似然函数以更新参数。</p>
<h5 id="算法流程"><strong>2. 算法流程</strong></h5>
<p><strong>(1) 初始化参数</strong></p>
<p>选择初始参数 $ ^{(0)} $，例如随机初始化或通过启发式方法设定。</p>
<p><strong>(2) E步：计算隐变量后验分布</strong></p>
<p>给定当前参数 $ ^{(t)} $，计算隐变量 $ z $ 的后验概率： <span class="math display"><em>Q</em><sup>(<em>t</em>)</sup>(<em>z</em>) = <em>P</em>(<em>z</em>|<strong>x</strong>,<em>θ</em><sup>(<em>t</em>)</sup>)</span>
这一步为每个样本分配隐变量的概率分布（如样本属于某个聚类的概率）。</p>
<p><strong>(3) M步：最大化期望似然</strong></p>
<p>基于 $ Q^{(t)}(z) $，构造期望似然函数并最大化： <span class="math display"><em>θ</em><sup>(<em>t</em>+1)</sup> = arg max<sub><em>θ</em></sub>∑<sub><em>z</em></sub><em>Q</em><sup>(<em>t</em>)</sup>(<em>z</em>)log <em>P</em>(<strong>x</strong>,<em>z</em>|<em>θ</em>)</span>
这一步更新参数 $ $，使得期望似然最大。</p>
<p><strong>(4) 收敛判断</strong></p>
<p>重复E步和M步直到参数收敛（如 $ |^{(t+1)} - ^{(t)}| &lt;
$）或达到最大迭代次数。</p>
<h5 id="示例混合高斯模型gmm"><strong>3.
示例：混合高斯模型（GMM）</strong></h5>
<p>假设数据由多个高斯分布生成，但不知道每个样本属于哪个分布。</p>
<p><strong>(1) 模型定义</strong></p>
<ul>
<li>观测变量 $ x_i ^d $：第 $ i $ 个样本。</li>
<li>隐变量 $ z_i {1, …, K} $：样本 $ x_i $ 所属的高斯分布。</li>
<li>参数 $ = {_k, _k, <em>k}</em>{k=1}^K $：
<ul>
<li>$ _k $：第 $ k $ 个高斯分布的均值。</li>
<li>$ _k $：第 $ k $ 个高斯分布的协方差矩阵。</li>
<li>$ _k $：第 $ k $ 个高斯分布的权重（先验概率）。</li>
</ul></li>
</ul>
<p><strong>(2) E步：计算责任分配</strong></p>
<p>对于每个样本 $ x_i $ 和类别 $ k $，计算责任（responsibility）： <span class="math display">$$
\gamma_{ik}^{(t)} = P(z_i=k|x_i, \theta^{(t)}) = \frac{\pi_k^{(t)}
\mathcal{N}(x_i|\mu_k^{(t)}, \Sigma_k^{(t)})}{\sum_{j=1}^K \pi_j^{(t)}
\mathcal{N}(x_i|\mu_j^{(t)}, \Sigma_j^{(t)})}
$$</span> 含义：在当前参数下，样本 $ x_i $ 属于类别 $ k $ 的概率。</p>
<p><strong>(3) M步：更新参数</strong></p>
<p>根据责任 $ _{ik} $ 更新参数： - <strong>均值更新</strong>： <span class="math display">$$
  \mu_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)} x_i}{\sum_{i=1}^N
\gamma_{ik}^{(t)}}
  $$</span> - <strong>协方差更新</strong>： <span class="math display">$$
  \Sigma_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)} (x_i -
\mu_k^{(t+1)})(x_i - \mu_k^{(t+1)})^T}{\sum_{i=1}^N \gamma_{ik}^{(t)}}
  $$</span> - <strong>权重更新</strong>： <span class="math display">$$
  \pi_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)}}{N}
  $$</span></p>
<p><strong>(4) 迭代终止</strong></p>
<p>当参数变化小于阈值或达到最大迭代次数时停止。</p>
<h4 id="作业">作业</h4>
<h5 id="section">1</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143758565.png" alt="image-20250606143758565">
<figcaption aria-hidden="true">image-20250606143758565</figcaption>
</figure>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143819352.png" alt="image-20250606143819352">
<figcaption aria-hidden="true">image-20250606143819352</figcaption>
</figure>
<h5 id="section-1">2</h5>
<p>已知观测数据-67，-48，6，8，14，16，23，24，28，29，41，49，56，60，75，试估计两个分量的高斯混合模型的5个参数。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150830535.png" alt="image-20250606150830535">
<figcaption aria-hidden="true">image-20250606150830535</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化观测数据</span></span><br><span class="line">data = np.array([-<span class="number">67</span>, -<span class="number">48</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">41</span>, <span class="number">49</span>, <span class="number">56</span>, <span class="number">60</span>,</span><br><span class="line">                 <span class="number">75</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类</span></span><br><span class="line">gmmModel = GaussianMixture(n_components=<span class="number">2</span>)</span><br><span class="line">gmmModel.fit(data)</span><br><span class="line">labels = gmmModel.predict(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels =&quot;</span>, labels)</span><br><span class="line">labels = [<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(labels)):</span><br><span class="line">    <span class="keyword">if</span> labels[i] == <span class="number">0</span>:</span><br><span class="line">        plt.scatter(i, data.take(i), s=<span class="number">15</span>, c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> labels[i] == <span class="number">1</span>:</span><br><span class="line">        plt.scatter(i, data.take(i), s=<span class="number">15</span>, c=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Gaussian Mixture Model&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;means =&quot;</span>, gmmModel.means_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;covariances =&quot;</span>, gmmModel.covariances_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights = &quot;</span>, gmmModel.weights_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150906475.png" alt="image-20250606150906475">
<figcaption aria-hidden="true">image-20250606150906475</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># means = [[ 32.98489643 -57.51107027]]</span></span><br><span class="line"><span class="comment"># covariances = [[429.45764867  90.24987882]]</span></span><br><span class="line"><span class="comment"># weights =  [[0.86682762 0.13317238]]</span></span><br></pre></td></tr></table></figure>
<h5 id="section-2">3</h5>
<p>简要阐述下EM算法的原理，并给出EM算法对高斯混合模型GMM进行求解的具体过程。</p>
<h6 id="em算法的原理">EM算法的原理</h6>
<p>EM算法（期望最大化算法）是一种用于含有隐变量的概率模型参数估计的迭代优化方法。其核心思想是通过交替执行两个步骤来最大化观测数据的似然函数：</p>
<ol type="1">
<li><strong>E步（期望步）</strong>：计算隐变量的后验期望（即责任），给定当前参数估计。</li>
<li><strong>M步（最大化步）</strong>：基于责任，最大化完全数据的期望似然函数以更新参数。</li>
</ol>
<p>EM算法通过不断优化似然函数的下界，最终收敛到局部最优解。以下具体阐述EM算法对高斯混合模型（GMM）的求解过程。</p>
<h6 id="em算法对gmm的具体求解过程"><strong>EM算法对GMM的具体求解过程</strong></h6>
<p><strong>1. GMM模型定义</strong></p>
<p>GMM假设数据由 $ K $ 个高斯分布线性组合生成，其概率密度函数为： <span class="math display">$$
p(\mathbf{x}|\theta) = \sum_{k=1}^K \alpha_k \cdot
\mathcal{N}(\mathbf{x}|\mu_k, \Sigma_k)
$$</span> 其中： - $ <em>k $：第 $ k $ 个高斯分布的权重（$ </em>{k=1}^K
_k = 1 $）。 - $ _k $：第 $ k $ 个高斯分布的均值向量。 - $ _k $：第 $ k
$ 个高斯分布的协方差矩阵。 - $ = {_k, _k, <em>k}</em>{k=1}^K
$：模型参数。</p>
<p>隐变量 $ z_i {1,,K} $ 表示样本 $ _i $ 的类别标签（未知）。</p>
<p><strong>2. EM算法步骤</strong></p>
<p><strong>(1) 初始化参数</strong></p>
<p>随机或通过K-means初始化： - 每个高斯分布的均值 $ _k^{(0)} $、协方差 $
_k^{(0)} $、权重 $ _k^{(0)} $。</p>
<p><strong>(2) 迭代优化（E步与M步）</strong></p>
<p><strong>E步：计算责任（后验概率）</strong> 对每个样本 <span class="math inline"><strong>x</strong><sub><em>i</em></sub></span>
和每个簇 $ k $，计算其属于第 $ k $ 个高斯分布的后验概率 <span class="math display">$$
\gamma(z_{ik}) = \frac{\alpha_k \cdot \mathcal{N}(\mathbf{x}_i | \mu_k,
\Sigma_k)}{\sum_{j=1}^K \alpha_j \cdot \mathcal{N}(\mathbf{x}_i | \mu_j,
\Sigma_j)}
$$</span> 此概率表示在当前参数下，样本 $ _i $ 属于第 $ k $
个高斯分布的“责任”。</p>
<p><strong>M步：更新参数</strong><br>
基于责任 $ (z_{ik}) $，最大化完全数据似然函数的期望，更新参数：</p>
<ul>
<li><strong>权重更新</strong>： <span class="math display">$$
\alpha_k^{(new)} = \frac{1}{N} \sum_{i=1}^N \gamma(z_{ik})
$$</span></li>
<li><strong>均值更新</strong>： <span class="math display">$$
\mu_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik})
\mathbf{x}_i}{\sum_{i=1}^N \gamma(z_{ik})}
$$</span></li>
<li><strong>协方差更新</strong>： <span class="math display">$$
\Sigma_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) (\mathbf{x}_i -
\mu_k^{(new)})(\mathbf{x}_i - \mu_k^{(new)})^\top}{\sum_{i=1}^N
\gamma(z_{ik})}
$$</span> 若为单变量高斯分布，则更新方差： <span class="math display">$$
\sigma_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) (x_i -
\mu_k^{(new)})^2}{\sum_{i=1}^N \gamma(z_{ik})}
$$</span></li>
</ul>
<p><strong>(3) 收敛判断</strong></p>
<p>计算对数似然函数： <span class="math display">$$
\log p(\mathbf{X}|\theta) = \sum_{i=1}^N \log \left( \sum_{k=1}^K
\alpha_k \cdot \mathcal{N}(\mathbf{x}_i|\mu_k, \Sigma_k) \right)
$$</span>
若对数似然的变化量小于阈值或达到最大迭代次数，则停止；否则重复E步和M步。。</p>
<h4 id="参考资料">参考资料</h4>
<p>[<a href="https://www.bilibili.com/video/BV1RT411G7jJ/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">5分钟学算法]
#06 EM算法 你到底是哪个班级的_哔哩哔哩_bilibili</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/396007256">《统计学习方法_第二版》学习笔记第九章
- 知乎</a></p>
<h3 id="集成学习">集成学习</h3>
<h4 id="个体与集成">个体与集成</h4>
<h5 id="集成学习的基本概念"><strong>集成学习的基本概念</strong></h5>
<p>集成学习（Ensemble
Learning）通过构建并结合<strong>多个学习器（基模型）</strong>来完成学习任务，其核心思想是“<strong>优而不同</strong>”，即<strong>通过多个弱学习器的协作提升整体性能</strong>，通常能获得比单一学习器更优的泛化能力
。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606154731476.png" alt="image-20250606154731476">
<figcaption aria-hidden="true">image-20250606154731476</figcaption>
</figure>
<p>在上图的集成模型中，若个体学习器都属于同一类别，例如都是决策树或都是神经网络，则称该集成为同质的（homogeneous）;若个体学习器包含多种类型的学习算法，例如既有决策树又有神经网络，则称该集成为异质的（heterogenous）。</p>
<blockquote>
<p><strong>同质集成</strong>：个体学习器称为“基学习器”（base
learner），对应的学习算法为“基学习算法”（base learning algorithm）。</p>
<p><strong>异质集成</strong>：个体学习器称为“组件学习器”（component
learner）或直称为“个体学习器”。</p>
</blockquote>
<p>集成学习的两个重要概念：<strong>准确性</strong>和<strong>多样性</strong>（diversity）。准确性指的是个体学习器不能太差，要有一定的准确度；多样性则是个体学习器之间的输出要具有差异性。</p>
<p>通过下面的这三个例子可以很容易看出这一点，准确度较高，差异度也较高，可以较好地提升集成性能。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606155939884.png" alt="image-20250606155939884">
<figcaption aria-hidden="true">image-20250606155939884</figcaption>
</figure>
<p><strong>集成策略</strong>：如何结合多个基模型的预测结果，例如：</p>
<ul>
<li><strong>投票法</strong>（Voting）：多数投票（硬投票）或概率加权（软投票）。<br>
</li>
<li><strong>加权平均法</strong>：对基模型的输出赋予不同权重 。<br>
</li>
<li><strong>Stacking</strong>：用元模型（Meta-Model）学习基模型的输出作为新特征
。</li>
</ul>
<h5 id="基于投票法的集成个体学习器的收敛性保证"><strong>基于投票法的集成个体学习器的收敛性保证</strong>：</h5>
<p><strong>公式解析</strong> <span class="math display">$$
P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) = \sum_{k=0}^{\lfloor T/2
\rfloor} \binom{T}{k} (1-\epsilon)^k \epsilon^{T-k} \leq
\exp\left(-\frac{1}{2} T (1 - 2\epsilon)^2\right)
$$</span></p>
<p><strong>1. 公式含义</strong></p>
<ul>
<li><strong><span class="math inline"><em>H</em>(<strong>x</strong>)</span></strong>：集成学习器的最终预测结果（如多数投票结果）。</li>
<li><strong><span class="math inline"><em>f</em>(<strong>x</strong>)</span></strong>：真实标记。</li>
<li><strong><span class="math inline"><em>ϵ</em></span></strong>：单个弱学习器的错误率（即
<span class="math inline"><em>P</em>(<em>h</em><sub><em>t</em></sub>(<strong>x</strong>)≠<em>f</em>(<strong>x</strong>))</span>），默认小于0.5。</li>
<li><strong><span class="math inline"><em>T</em></span></strong>：基学习器的数量。</li>
<li><strong>左边</strong>：集成学习器预测错误的概率（即至少有超过 <span class="math inline"><em>T</em>/2</span>
个基学习器预测错误的概率）。</li>
<li><strong>右边</strong>：对左边概率的指数级上限估计。</li>
</ul>
<p><strong>2. 推导思路</strong></p>
<ul>
<li>假设每个基学习器独立且错误率为 <span class="math inline"><em>ϵ</em></span>，则错误次数服从<strong>二项分布</strong>
<span class="math inline"><em>B</em>(<em>T</em>,<em>ϵ</em>)</span>。</li>
<li>集成错误的条件是“超过半数基学习器错误”，即错误次数 <span class="math inline"><em>k</em> ≤ ⌊<em>T</em>/2⌋</span>。</li>
</ul>
<p><strong>两个基本结论</strong></p>
<p><strong>1. 收敛速率随个体学习器数量 <span class="math inline"><em>T</em></span> 指数下降</strong></p>
<ul>
<li><strong>数学体现</strong>：错误概率的上界是 <span class="math inline">exp (−<em>c</em><em>T</em>)</span> 形式，其中 <span class="math inline">$c = \frac{1}{2}(1 - 2\epsilon)^2$</span>。</li>
</ul>
<p><strong>2. <span class="math inline"><em>ϵ</em> = 0.5</span>
的个体学习器对收敛没有作用</strong></p>
<ul>
<li><strong>数学原因</strong>：当 <span class="math inline"><em>ϵ</em> = 0.5</span> 时，<span class="math inline">(1−2<em>ϵ</em>)<sup>2</sup> = 0</span>，指数项变为
0，错误概率上界为 <span class="math inline">exp (0) = 1</span>，即错误概率无法降低。</li>
</ul>
<p>根据个体学习器的<strong>生成方式</strong>，目前集成学习可分为两类，代表作如下：</p>
<ol type="1">
<li>个体学习器直接存在强依赖关系，必须串行生成的序列化方法：<strong>Boosting</strong>；</li>
<li>个体学习器间不存在强依赖关系，可以同时生成的并行化方法：<strong>Bagging</strong>
和 <strong>随机森林 (Random Forest)</strong>。</li>
</ol>
<h4 id="boosting"><strong>Boosting</strong></h4>
<p>Boosting是一种<strong>串行</strong>的工作机制，即<strong>个体学习器的训练存在依赖关系</strong>，必须一步一步序列化进行。</p>
<p>其<strong>基本思想</strong>是：<strong>增加前一个基学习器在训练过程中预测错误样本的权重，使得后续基学习器更加关注这些打标错误的训练样本，尽可能纠正这些错误，然后基于调整后的样本分布训练下一个基学习器</strong>，如此重复，一直向下串行直至产生需要的T个基学习器，Boosting最终对这T个学习器进行加权结合，产生学习器委员会。</p>
<p>Boosting族算法最著名、使用最为广泛的就是<strong>AdaBoost</strong>，因此下面主要是对AdaBoost算法进行介绍。</p>
<p>AdaBoost使用的是<strong>指数损失函数</strong>，因此AdaBoost的权值与样本分布的更新都是围绕着最小化指数损失函数进行的。</p>
<blockquote>
<p>看到这里回想一下之前的机器学习算法，<strong>不难发现机器学习的大部分带参模型只是改变了最优化目标中的损失函数</strong>：如果是Square
loss，那就是最小二乘了；如果是Hinge
Loss，那就是著名的SVM了；如果是log-Loss，那就是Logistic
Regression了。</p>
</blockquote>
<h5 id="adaboost">AdaBoost</h5>
<h5 id="公式解析"><strong>公式解析</strong></h5>
<p><span class="math display">$$
H(\boldsymbol{x}) = \sum_{t=1}^T \alpha_t h_t(\boldsymbol{x})
$$</span> <span class="math display">ℓ<sub>exp</sub>(<em>H</em>|𝒟) = 𝔼<sub><strong>x</strong> ∼ 𝒟</sub>[<em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup>]</span></p>
<p><strong>1. 符号含义</strong></p>
<ul>
<li><strong><span class="math inline"><em>H</em>(<strong>x</strong>)</span></strong>：最终集成模型的预测结果，是
<span class="math inline"><em>T</em></span> 个基学习器 <span class="math inline"><em>h</em><sub><em>t</em></sub>(<strong>x</strong>)</span>
的加权和。</li>
<li><strong><span class="math inline"><em>α</em><sub><em>t</em></sub></span></strong>：第
<span class="math inline"><em>t</em></span>
个基学习器的权重，表示其在集成中的重要性。</li>
<li><strong><span class="math inline"><em>h</em><sub><em>t</em></sub>(<strong>x</strong>)</span></strong>：第
<span class="math inline"><em>t</em></span>
个基学习器（如决策树、感知机等）。</li>
<li><strong><span class="math inline"><em>f</em>(<strong>x</strong>)</span></strong>：真实标签，通常取值为
<span class="math inline">{ − 1,  + 1}</span>（二分类问题）。</li>
<li><strong><span class="math inline">𝒟</span></strong>：训练数据分布。</li>
<li><strong><span class="math inline">ℓ<sub>exp</sub></span></strong>：指数损失函数（Exponential
Loss）。</li>
</ul>
<p><strong>2. 指数损失函数的意义</strong></p>
<p>指数损失函数的形式为： <span class="math display">ℓ<sub>exp</sub>(<em>H</em>|𝒟) = 𝔼<sub><strong>x</strong> ∼ 𝒟</sub>[<em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup>]</span>
- <strong>直观解释</strong>： - 当 <span class="math inline"><em>H</em>(<strong>x</strong>)</span> 与 <span class="math inline"><em>f</em>(<strong>x</strong>)</span>
同号时（预测正确），指数项 <span class="math inline"><em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup></span>
接近 0，损失小。 - 当 <span class="math inline"><em>H</em>(<strong>x</strong>)</span> 与 <span class="math inline"><em>f</em>(<strong>x</strong>)</span>
异号时（预测错误），指数项趋近于正无穷，损失极大。 -
因此，该损失函数对错误样本的惩罚非常严格，迫使模型优先修正错误。</p>
<h5 id="adaboost的优化目标"><strong>AdaBoost的优化目标</strong></h5>
<p>AdaBoost的目标是选择基学习器 <span class="math inline"><em>h</em><sub><em>t</em></sub></span> 和权重 <span class="math inline"><em>α</em><sub><em>t</em></sub></span>，使得集成模型
<span class="math inline"><em>H</em>(<strong>x</strong>)</span>
能够<strong>最小化指数损失函数</strong>： <span class="math display">$$
\min_{\alpha_1, h_1, \dots, \alpha_T, h_T} \mathbb{E}_{\boldsymbol{x}
\sim \mathcal{D}} \left[ e^{-f(\boldsymbol{x}) \sum_{t=1}^T \alpha_t
h_t(\boldsymbol{x})} \right]
$$</span></p>
<p><strong>优化策略</strong></p>
<p>AdaBoost采用<strong>前向分步算法（Forward Stagewise
Algorithm）</strong>，逐轮迭代优化： 1.
<strong>初始化样本权重</strong>：初始时所有样本权重相等。 2.
<strong>训练基学习器 <span class="math inline"><em>h</em><sub><em>t</em></sub></span></strong>：在当前样本权重分布下，训练一个弱学习器
<span class="math inline"><em>h</em><sub><em>t</em></sub></span>。 3.
<strong>计算权重 <span class="math inline"><em>α</em><sub><em>t</em></sub></span></strong>：根据
<span class="math inline"><em>h</em><sub><em>t</em></sub></span>
的错误率 <span class="math inline"><em>ϵ</em><sub><em>t</em></sub></span> 计算其权重：
<span class="math display">$$
   \alpha_t = \frac{1}{2} \ln \left( \frac{1 - \epsilon_t}{\epsilon_t}
\right)
   $$</span> 4. <strong>更新样本权重</strong>：提高被 <span class="math inline"><em>h</em><sub><em>t</em></sub></span>
错分类样本的权重，降低正确分类样本的权重。 5. <strong>重复步骤
2-4</strong>，直到训练完成 <span class="math inline"><em>T</em></span>
轮。</p>
<h5 id="示例二分类问题-1"><strong>示例：二分类问题</strong></h5>
<p>假设一个二分类任务，真实标签 <span class="math inline"><em>f</em>(<strong>x</strong>) ∈ { − 1,  + 1}</span>，集成模型预测值
<span class="math inline">$H(\boldsymbol{x}) = \sum_{t=1}^T \alpha_t
h_t(\boldsymbol{x})$</span>： - 若 <span class="math inline"><em>H</em>(<strong>x</strong>) &gt; 0</span>，预测为
<span class="math inline"> + 1</span>； - 若 <span class="math inline"><em>H</em>(<strong>x</strong>) &lt; 0</span>，预测为
<span class="math inline"> − 1</span>。</p>
<p>此时，指数损失函数的值反映了模型对错误样本的惩罚程度： -
正确预测时，<span class="math inline"><em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup> ≈ 0</span>；
- 错误预测时，<span class="math inline"><em>e</em><sup>−<em>f</em>(<strong>x</strong>)<em>H</em>(<strong>x</strong>)</sup> ≫ 1</span>。</p>
<h5 id="adaboost的算法流程">AdaBoost的算法流程</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606172851748.png" alt="image-20250606172851748">
<figcaption aria-hidden="true">image-20250606172851748</figcaption>
</figure>
<h5 id="重赋权法与重采样法">重赋权法与重采样法</h5>
<p>在集成学习中，<strong>Boosting
算法的核心在于动态调整样本权重</strong> ，以逐步聚焦难分类样本。Boosting
主要通过两种方法实现样本权重的更新：<strong>重赋权法（re-weighting）</strong>
和 <strong>重采样法（re-sampling）</strong> 。</p>
<blockquote>
<p><strong>重赋权法</strong> :
对每个样本附加一个权重，这时涉及到样本属性与标签的计算，都需要乘上一个权值。
<strong>重采样法</strong> :
对于一些无法接受带权样本的及学习算法，适合用“重采样法”进行处理。方法大致过程是，根据各个样本的权重，对训练数据进行重采样，初始时样本权重一样，每个样本被采样到的概率一致，每次从N个原始的训练样本中按照权重有放回采样N个样本作为训练集，然后计算训练集错误率，然后调整权重，重复采样，集成多个基学习器。</p>
</blockquote>
<p>从偏差-方差分解来看：Boosting算法主要关注于降低偏差，每轮的迭代都关注于训练过程中预测错误的样本，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成学习器。</p>
<h5 id="拓展gradient-boosting">拓展：Gradient Boosting</h5>
<p>任务分为分类，回归，聚类，降维等，而分类中还分为二分类和多分类</p>
<p>从AdaBoost的算法流程来看，标准的AdaBoost只适用于二分类问题。</p>
<p>通过改造AdaBoost对样本分类的限制和损失函数，可以实现多分类或回归问题，这样改造出来的算法框架成为<strong>Gradient
Boosting</strong></p>
<h6 id="gbdtgradient-boosting-decision-tree与xgboost"><strong>GBDT（Gradient
Boosting Decision Tree）与XGBoost</strong></h6>
<p><strong>1. GBDT 的核心思想</strong></p>
<p>GBDT 是基于<strong>梯度提升（Gradient
Boosting）</strong>框架的集成学习方法，其特点包括： -
<strong>基学习器</strong>：使用<strong>CART（分类与回归树）</strong>作为个体学习器。
- <strong>损失函数</strong>： -
<strong>回归问题</strong>：平方损失（Squared Loss）： <span class="math display">err(<em>H</em><sub><em>t</em></sub>(<strong>x</strong>),<em>f</em>(<strong>x</strong>)) = (<em>H</em><sub><em>t</em></sub>(<strong>x</strong>)−<em>f</em>(<strong>x</strong>))<sup>2</sup></span>
- <strong>二分类问题</strong>：对数似然损失（Log-Likelihood
Loss，类似逻辑回归）： <span class="math display">err(<em>H</em><sub><em>t</em></sub>(<strong>x</strong>),<em>f</em>(<strong>x</strong>)) = log (1+exp(−<em>f</em>(<strong>x</strong>)<em>H</em><sub><em>t</em></sub>(<strong>x</strong>)))</span>
- <strong>多分类问题</strong>：扩展为多分类对数损失。</p>
<p><strong>2. XGBoost 的定位</strong></p>
<p>XGBoost（eXtreme Gradient Boosting）是 GBDT
的一种<strong>高效实现和改进</strong>，类似于 LIBSVM 对 SVM
的优化关系。其核心目标是： -
<strong>提升训练速度</strong>：通过<strong>并行计算</strong>、<strong>内存优化</strong>等工程技巧。
-
<strong>增强模型性能</strong>：引入<strong>正则化项</strong>、<strong>缺失值处理</strong>、<strong>自适应学习率</strong>等改进。</p>
<blockquote>
<p>XGBoost即eXtremeGradient
Boosting的缩写，XGBoost与GBDT的关系可以类比为
LIBSVM和SVM的关系，即XGBoOst是GBDT的一种高效实现和改进。</p>
<p>它并非一个全新的算法框架，而是对标准 GBDT
进行了<strong>大量的工程优化和算法增强</strong>。</p>
</blockquote>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606175536310.png" alt="image-20250606175536310">
<figcaption aria-hidden="true">image-20250606175536310</figcaption>
</figure>
<h4 id="bagging">Bagging</h4>
<p>Bagging是一种<strong>并行式</strong>的集成学习方法，即<strong>基学习器的训练之间没有前后顺序可以同时进行</strong></p>
<p>Bagging使用<strong>“有放回”采样的方式选取训练集</strong>，对于包含m个样本的训练集，进行m次有放回的随机采样操作，从而得到m个样本的采样集，这样训练集中有<strong>接近36.8%</strong>的样本没有被采到，可用作验证集来对泛化性能进行“包外估计”(out-of-bag
estimate)。</p>
<p>按照相同的方式重复进行，我们就可以采集到T个包含m个样本的数据集，从而训练出<strong>T个基学习器</strong>，最终对<strong>这T个基学习器的输出进行结合</strong>。</p>
<h5 id="bagging与boosting的差异">Bagging与Boosting的差异</h5>
<p>Boosting算法一大特点是串行，这样诚然可以降低模型的偏差，增强拟合能力，但是当数据过大时，一大缺点就是会降低学习效率</p>
<p>Bagging作为并行式的集成学习方法，通过综合多个基学习器的结果，可以增加学习效率</p>
<p>二者差异性：</p>
<p>1.对目标的拟合程度：Boosting对目标有更好的拟合能力（偏差小）；Bagging则偏差相对大一些</p>
<p>2.运行效率：由于并行的特点，Bagging的运行效率是大于Boosting的</p>
<p>3.泛化能力：由于Bagging每个学习器不会受其他学习器的影响，泛化能力（方差大）相对于Boosting</p>
<p>更好</p>
<h5 id="bagging的算法流程">Bagging的算法流程</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606182733022.png" alt="image-20250606182733022">
<figcaption aria-hidden="true">image-20250606182733022</figcaption>
</figure>
<p>可以看出Bagging主要通过<strong>样本的扰动</strong>来增加基学习器之间的多样性，因此Bagging的基学习器应为那些对训练集十分敏感的不稳定学习算法，例如：神经网络与决策树等。</p>
<p>从偏差-方差分解来看，Bagging算法主要关注于降低方差，即通过多次重复训练提高稳定性。</p>
<p>不同于AdaBoost的是，Bagging可以十分简单地移植到多分类、回归等问题。总的说起来则是：<strong>AdaBoost关注于降低偏差，而Bagging关注于降低方差。</strong></p>
<h5 id="自助采样法bootstrap-sampling">自助采样法（Bootstrap
Sampling）</h5>
<p>在机器学习中，<strong>自助采样法（Bootstrap Sampling）</strong> 是
Bagging
算法的核心技术之一。其核心思想是从原始数据集中有放回地随机抽取样本，形成新的训练子集。这一过程的一个重要数学性质是：当样本量
<span class="math inline"><em>n</em></span> 趋近于无穷大时，每个样本在
Bootstrap 样本集中<strong>未被抽中</strong>的概率趋近于 <span class="math inline">$\frac{1}{e} \approx
36.6\%$</span>。以下是详细解析：</p>
<p><strong>1. 公式推导</strong></p>
<p>假设我们从 <span class="math inline"><em>n</em></span>
个样本中<strong>有放回地</strong>抽取 <span class="math inline"><em>n</em></span> 次，形成一个 Bootstrap
样本集。对于任意一个特定样本（如第 <span class="math inline"><em>i</em></span>
个样本），它在某次抽样中<strong>未被选中</strong>的概率为： <span class="math display">$$
1 - \frac{1}{n}
$$</span> 因此，它在整个 <span class="math inline"><em>n</em></span>
次抽样中<strong>从未被选中</strong>的概率为： <span class="math display">$$
\left(1 - \frac{1}{n}\right)^n
$$</span> 当 <span class="math inline"><em>n</em> → ∞</span>
时，该概率的极限为： <span class="math display">$$
\lim_{n \to \infty} \left(1 - \frac{1}{n}\right)^n = \frac{1}{e} \approx
0.3679 \quad (\text{即 } 36.6\%)
$$</span> 在每次 Bootstrap 采样中，约有 <strong>36.6%
的样本未被选中</strong> ，这些样本称为
<strong>Out-of-Bag（OOB，包外估计）样本</strong> 。</p>
<p><strong>2. OOB 样本的应用</strong></p>
<p>在 Bagging 算法中，OOB 样本具有以下重要作用： 1.
<strong>无偏验证</strong>：<br>
每个基学习器的训练数据不包含其对应的 OOB
样本，因此可以用这些样本直接评估模型性能（即 OOB
误差），无需额外的交叉验证。 2. <strong>特征重要性评估</strong>：<br>
在随机森林中，通过比较 OOB
样本在打乱某个特征后的预测误差变化，可以衡量该特征的重要性。</p>
<p><strong>3. 与其他采样方法的对比</strong></p>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 17%">
<col style="width: 32%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th><strong>采样方法</strong></th>
<th><strong>是否放回</strong></th>
<th><strong>样本覆盖范围</strong></th>
<th><strong>典型应用场景</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Bootstrap 采样</strong></td>
<td>是</td>
<td>约 63.4% 样本被重复使用</td>
<td>Bagging、随机森林</td>
</tr>
<tr class="even">
<td><strong>简单随机采样</strong></td>
<td>否</td>
<td>所有样本唯一出现</td>
<td>传统交叉验证</td>
</tr>
</tbody>
</table>
<h5 id="随机森林">随机森林</h5>
<p>随机森林（Random
Forest）是Bagging的一个拓展体，它的基学习器固定为<strong>决策树</strong>，多棵树也就组成了森林，而<strong>“随机”则在于选择划分属性的随机</strong>，随机森林在训练基学习器时，也采用有放回采样的方式添加样本扰动，同时它还引入了一种<strong>属性扰动</strong>，即在基决策树的训练过程中，在选择划分属性时，RF先从候选属性集中随机挑选出一个包含K个属性的子集，再从这个子集中选择最优划分属性
。</p>
<p>这样随机森林中基学习器的<strong>多样性不仅来自样本扰动，还来自属性扰动</strong>，从而进一步提升了基学习器之间的差异度。相比决策树的Bagging集成，随机森林的起始性能较差（由于属性扰动，基决策树的准确度有所下降），但随着基学习器数目的增多，随机森林往往会收敛到更低的泛化误差。同时不同于Bagging中决策树从所有属性集中选择最优划分属性，<strong>随机森林只在属性集的一个子集中选择划分属性，因此训练效率更高</strong>。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606184958951.png" alt="image-20250606184958951">
<figcaption aria-hidden="true">image-20250606184958951</figcaption>
</figure>
<h4 id="结合策略">结合策略</h4>
<p>在集成学习中，结合策略是将多个基学习器的输出整合为最终预测结果的关键步骤。以下是针对回归和分类问题的不同结合策略及其核心要点：</p>
<p><strong>定义</strong>：在训练好多个基学习器后，如何将其输出组合成集成模型的最终输出。</p>
<h5 id="平均法回归问题"><strong>1.平均法（回归问题）</strong></h5>
<ol type="1">
<li><p><strong>简单平均法（Simple Averaging）</strong></p>
<ul>
<li><strong>公式</strong>：<br>
<span class="math display">$$
H(x) = \frac{1}{T} \sum_{i=1}^{T} h_i(x)
$$</span></li>
<li><strong>特点</strong>：
<ul>
<li>直接对所有基学习器的预测结果取算术平均。<br>
</li>
<li>计算简单，适合基学习器性能相近的场景。<br>
</li>
<li>若部分基学习器表现较差，可能拖累整体性能。</li>
</ul></li>
</ul></li>
<li><p><strong>加权平均法（Weighted Averaging）</strong></p>
<ul>
<li><strong>公式</strong>：<br>
<span class="math display">$$
H(x) = \sum_{i=1}^{T} w_i h_i(x)
$$</span> 其中，$ w_i $ 且 $ _{i=1}^{T} w_i = 1 $。<br>
</li>
<li><strong>特点</strong>：
<ul>
<li>通过权重 $ w_i $ 调节各基学习器的贡献，灵活性更高。<br>
</li>
<li>适用于基学习器性能差异较大的情况，可提升鲁棒性。<br>
</li>
<li>权重可通过验证集性能（如RMSE、MAE）或优化算法（如梯度下降）确定。</li>
</ul></li>
</ul></li>
</ol>
<h5 id="投票法分类问题"><strong>2.投票法（分类问题）</strong></h5>
<ol type="1">
<li><strong>简单投票法（Majority Voting）</strong>
<ul>
<li><strong>原理</strong>：<br>
每个基学习器对样本进行分类投票，最终结果由得票最多的类别决定。<br>
</li>
<li><strong>公式</strong>（二分类示例）：<br>
<span class="math display">$$
H(x) =
\begin{cases}
1 &amp; \text{若} \sum_{i=1}^{T} I(h_i(x) = 1) &gt; T/2 \\
0 &amp; \text{否则}
\end{cases}
$$</span> 其中，$ I() $ 为指示函数。<br>
</li>
<li><strong>特点</strong>：
<ul>
<li>简单高效，适合基学习器性能相近的场景。<br>
</li>
<li>对异常分类器的鲁棒性较弱。</li>
</ul></li>
</ul></li>
<li><strong>加权投票法（Weighted Voting）</strong>
<ul>
<li><strong>原理</strong>：<br>
给不同基学习器分配权重，最终结果由加权票数最高的类别决定。<br>
</li>
<li><strong>公式</strong>（二分类示例）：<br>
<span class="math display">$$
H(x) =
\begin{cases}
1 &amp; \text{若} \sum_{i=1}^{T} w_i I(h_i(x) = 1) &gt; 0.5
\sum_{i=1}^{T} w_i \\
0 &amp; \text{否则}
\end{cases}
$$</span></li>
<li><strong>特点</strong>：
<ul>
<li>权重可根据基学习器的验证集准确率或领域知识设定。<br>
</li>
<li>更适合处理性能差异较大的基学习器。</li>
</ul></li>
</ul></li>
</ol>
<p>绝对多数投票法（majority
voting）提供了拒绝选项，这在可靠性要求很高的学习任务中是一个很好的机制。同时，对于分类任务，各个基学习器的输出值有两种类型，分别为类标记和类概率。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606195241433.png" alt="image-20250606195241433">
<figcaption aria-hidden="true">image-20250606195241433</figcaption>
</figure>
<p>一些在产生类别标记的同时也生成置信度的学习器，置信度可转化为类概率使用，<strong>一般基于类概率进行结合往往比基于类标记进行结合的效果更好</strong>，需要注意的是对于异质集成，其类概率不能直接进行比较，此时需要将类概率转化为类标记输出，然后再投票。</p>
<h5 id="学习法stacking"><strong>3.学习法（Stacking）</strong></h5>
<p><strong>学习法</strong>是一种更高级的结合策略，其核心思想是通过训练一个<strong>次级学习器（Meta-Learner）</strong>
来动态融合多个基学习器的输出。其中，<strong>Stacking（堆叠泛化）</strong>
是学习法的典型代表，它通过将基学习器的预测结果作为新特征，进一步训练一个次级模型，最终实现更优的泛化性能。</p>
<p><strong>Stacking 的基本原理</strong></p>
<p><strong>步骤概述</strong>：</p>
<ul>
<li><strong>训练基学习器</strong>：使用原始数据训练 $ T $
个基学习器（如决策树、SVM、神经网络等）。<br>
</li>
<li><strong>生成新特征</strong>：对于每个样本，将 $ T $
个基学习器的输出（预测结果）作为该样本的新特征，形成一个 $ m T $
的数据集（$ m $ 为样本数量）。<br>
</li>
<li><strong>训练次级学习器</strong>：使用新数据集（基学习器输出 +
真实标签）训练一个次级学习器（如逻辑回归、梯度提升树等），该学习器负责融合基学习器的预测结果。</li>
</ul>
<p><strong>Stacking 的优势</strong></p>
<ol type="1">
<li><strong>动态权重分配</strong>：<br>
次级学习器可以自动学习基学习器的权重，无需人工设定。例如，若某个基学习器表现优异，次级学习器会赋予其更高的权重。<br>
</li>
<li><strong>异质模型融合</strong>：<br>
可以混合不同类型的基学习器（如线性模型与树模型），充分利用各自的特性。<br>
</li>
<li><strong>提升泛化能力</strong>：<br>
次级学习器通过学习基学习器的输出模式，能够捕捉更复杂的决策边界。</li>
</ol>
<p><strong>Stacking 的实现细节</strong></p>
<ol type="1">
<li><strong>数据划分</strong>：
<ul>
<li>通常需将原始数据分为两部分：
<ul>
<li><strong>训练集</strong>：用于训练基学习器。<br>
</li>
<li><strong>验证集</strong>：用于生成基学习器的输出（避免过拟合）。<br>
</li>
</ul></li>
<li>或采用交叉验证（如 $ k
$-折）生成基学习器的预测结果，确保次级学习器的训练数据不被污染。</li>
</ul></li>
<li><strong>基学习器输出类型</strong>：
<ul>
<li><strong>分类任务</strong>：基学习器输出类概率（Soft
Voting），而非类别标签（Hard Voting）。例如，逻辑回归输出 $ P(c_j | x)
$，随机森林输出节点样本的类别分布。<br>
</li>
<li><strong>回归任务</strong>：基学习器直接输出预测值（如线性回归的
<span class="math inline"><em>ŷ</em></span>）。</li>
</ul></li>
<li><strong>次级学习器选择</strong>：
<ul>
<li><strong>多响应线性回归（MLR）</strong>：适用于基学习器输出可加权平均的情况，计算简单且鲁棒。<br>
<span class="math display">$$
H(x) = \sum_{i=1}^{T} w_i h_i(x)
$$</span></li>
<li><strong>复杂模型</strong>：如梯度提升树、神经网络，可捕捉基学习器输出之间的非线性关系。</li>
</ul></li>
</ol>
<h4 id="多样性">多样性</h4>
<p>在集成学习中，<strong>多样性增强（Diversity Enhancement）</strong>
是提升模型性能的关键策略。通过引入多样性，可以降低基学习器之间的相关性，从而减少误差传递和过拟合风险。以下是四种常见的多样性增强方法及其核心要点：</p>
<p><strong>1. 数据样本扰动（Data Perturbation）</strong></p>
<p><strong>原理</strong>：通过修改训练数据的分布或采样方式，使每个基学习器看到不同的数据子集。</p>
<p><strong>实现方式</strong>：<br>
- <strong>Bagging（如随机森林）</strong>：<br>
- 随机有放回地采样（Bootstrap），生成多个不同的训练集。<br>
- 对输入扰动敏感的基学习器（如决策树、神经网络）效果显著。<br>
- <strong>示例</strong>：<br>
- 决策树对数据扰动敏感，Bagging 可有效提升其泛化能力。<br>
- 线性模型（如线性回归、SVM）对数据扰动不敏感，Bagging 效果有限。</p>
<p><strong>2. 输入属性扰动（Input Attribute Perturbation）</strong></p>
<p><strong>原理</strong>：通过改变输入特征的表示或选择，增加基学习器间的差异。</p>
<p><strong>实现方式</strong>：<br>
-
<strong>特征子集采样</strong>：每次随机选择部分特征进行训练（如随机森林中的列扰动）。<br>
- <strong>特征变换</strong>：对特征进行缩放、旋转或加噪声等操作。<br>
- <strong>适用场景</strong>：<br>
- 数据包含大量冗余属性时，可大幅加速训练并提升多样性。<br>
- 对高维数据（如图像、文本）尤其有效。</p>
<p><strong>3. 输出属性扰动（Output Attribute Perturbation）</strong></p>
<p><strong>原理</strong>：通过修改训练样本的标签，间接影响基学习器的学习过程。</p>
<p><strong>实现方式</strong>：<br>
-
<strong>随机翻转标签</strong>：对部分样本的标记进行随机更改（需谨慎使用，避免干扰模型）。<br>
- <strong>Dropout（神经网络）</strong>：<br>
- 在训练过程中随机“关闭”部分神经元，强制网络学习更鲁棒的特征。<br>
- 类似于对输出属性的随机扰动，可提升模型泛化能力。</p>
<p><strong>4. 算法参数扰动（Algorithm Parameter
Perturbation）</strong></p>
<p><strong>原理</strong>：通过调整基学习器的超参数，生成不同的模型行为。</p>
<p><strong>实现方式</strong>：</p>
<ul>
<li><strong>正则化方法</strong>：L1/L2 正则化（如
Ridge、Lasso）限制模型复杂度，降低过拟合风险。</li>
<li><strong>随机初始化</strong>：
神经网络的随机权重初始化可能导致收敛到不同局部最优解。</li>
</ul>
<h4 id="作业-1">作业</h4>
<h5 id="section-3">1</h5>
<p>集成学习中常见的两种方法是什么？请分别介绍它们的原理和特点。集成学习相比于单个模型有什么优势和应用场景？</p>
<p><strong>集成学习常见方法、原理、特点及优势</strong></p>
<p><strong>常见方法</strong>：Bagging 和 Boosting<br>
<strong>原理与特点</strong>：</p>
<table>
<colgroup>
<col style="width: 9%">
<col style="width: 45%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th><strong>方法</strong></th>
<th><strong>原理</strong></th>
<th><strong>特点</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Bagging</strong></td>
<td>1. <strong>自助采样</strong>：从训练集有放回抽取多个子集<br>2.
<strong>并行训练</strong>基模型<br>3.
<strong>聚合预测</strong>（投票/平均）</td>
<td>- 降低方差<br>- 适合高方差模型（如未剪枝决策树）<br>-
并行化，训练快<br>- 代表：随机森林</td>
</tr>
<tr class="even">
<td><strong>Boosting</strong></td>
<td>1. <strong>顺序训练</strong>：后一个模型修正前一个模型的错误<br>2.
<strong>加权困难样本</strong><br>3. <strong>加权组合</strong>模型</td>
<td>- 降低偏差<br>- 需弱学习器（如树桩）<br>- 易过拟合（需正则化）<br>-
代表：AdaBoost, GBDT, XGBoost</td>
</tr>
</tbody>
</table>
<p><strong>集成学习的优势</strong>：<br>
-
<strong>提升泛化能力</strong>：降低过拟合（Bagging）或欠拟合（Boosting）风险<br>
- <strong>增强鲁棒性</strong>：减少异常值/噪声影响（如投票机制）<br>
- <strong>突破性能上限</strong>：组合多个弱模型达到强模型效果</p>
<p><strong>应用场景</strong>：<br>
- <strong>分类任务</strong>：医疗诊断（整合多模型减少误诊）<br>
- <strong>回归任务</strong>：房价预测（融合不同树模型提升精度）<br>
- <strong>不平衡数据</strong>：Boosting 加权少数类样本<br>
- <strong>高维数据</strong>：随机森林自动特征选择</p>
<h5 id="section-4">2</h5>
<p>如果在完全相同的训练集上训练了五个不同的模型，并且它们都达到了95%的准确率，是否还有机会通过结合这些模型来获得更好的结果？如果可以，该怎么做？如果不行，为什么？</p>
<p><strong>模型结合提升性能的可能性与方法</strong></p>
<p><strong>是否可能提升</strong>：<strong>是</strong>，但需满足条件：<strong>模型错误不相关</strong>（即犯错样本不同）。</p>
<p><strong>如何实现</strong>：</p>
<ol type="1">
<li><strong>投票法（分类）</strong>：
<ul>
<li>多数投票：5个模型对样本 (x) 的预测为 ([A, A, B, A, C]) → 最终输出
(A)<br>
</li>
<li><strong>关键要求</strong>：模型存在<strong>多样性</strong>（如使用SVM、决策树等不同算法）<br>
</li>
</ul></li>
<li><strong>加权平均（回归）</strong>：
<ul>
<li>若模型精度不同，分配权重：$ y_{} = w_1 y_1 + w_2 y_2 + + w_5
y_5$</li>
<li>权重可通过验证集性能确定</li>
</ul></li>
</ol>
<p><strong>若无法提升的情况</strong>：<br>
-
<strong>原因</strong>：模型高度相关（如相同算法、相同特征、相同超参）<br>
- <strong>数学解释</strong>：误差相关性 <span class="math inline"><em>r</em><em>h</em><em>o</em> ≈ 1</span>
时，集成误差 <span class="math inline">≈</span>单一模型误差</p>
<h5 id="section-5">3</h5>
<p>是否可以通过在多个服务器上并行来加速随机森林的训练？AdaBoost集成呢？为什么？</p>
<table>
<colgroup>
<col style="width: 13%">
<col style="width: 18%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="header">
<th><strong>算法</strong></th>
<th><strong>是否支持并行</strong></th>
<th><strong>原因</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>随机森林</strong></td>
<td>✅ <strong>是</strong></td>
<td>1. 树之间独立训练<br>2. 可分布式分配Bootstrap样本到不同服务器<br>3.
特征分裂也可并行（如选特征子集）</td>
</tr>
<tr class="even">
<td><strong>AdaBoost</strong></td>
<td>❌ <strong>否</strong></td>
<td>1.
模型必须<strong>顺序训练</strong>：后一个模型依赖前一个模型的样本权重更新<br>2.
无法解耦迭代过程</td>
</tr>
</tbody>
</table>
<h3 id="聚类">聚类</h3>
<h4 id="聚类任务"><strong>聚类任务</strong></h4>
<blockquote>
<p>我们之前学习的分类/回归任务都属于 有监督学习
需要我们提供样本与标签</p>
<p>而马上要学习的聚类任务和后续学习的降维则属于 无监督学习
仅需提供样本</p>
</blockquote>
<p>聚类是一种经典的<strong>无监督学习</strong>(unsupervised
learning)方法，<strong>无监督学习的目标是通过对无标记训练样本的学习，发掘和揭示数据集本身潜在的结构与规律</strong>，即不依赖于训练数据集的类标记信息。</p>
<p>聚类试图将数据集中的样本划分为若干个通常是不相交的子集,<strong>每个子集称为一个“簇”(
cluster)</strong>。通过这样的划分,每簇可能对应于一些潜在的概念(类别),如“浅色瓜”“深色瓜”,“有籽瓜”“无籽瓜”,甚至“本地瓜”“外地瓜”等;需说明的是,这些概念对聚类算法而言事先是未知的,聚类过程仅能自动形成簇结构,
<strong>簇所对应的概念语义需由使用者来把握和命名</strong>。</p>
<p>直观上来说，聚类是将相似的样本聚在一起，从而形成一个<strong>类簇（cluster）</strong>。涉及两个问题</p>
<ul>
<li>如何<strong>度量相似性</strong>（similarity
measure），这便是<strong>距离度量</strong>(distance
measure)，在生活中我们说差别小则相似，对应到多维样本，每个样本可以对应于高维空间中的一个数据点，若它们的距离相近，我们便可以称它们相似。</li>
<li>如何<strong>评价聚类结果</strong>，这便是<strong>性能度量</strong>(validity
index)</li>
</ul>
<h4 id="距离度量">距离度量</h4>
<h5 id="连续离散有序">连续/离散有序</h5>
<p><strong>明可夫斯基距离（Minkowski Distance）</strong></p>
<p>明可夫斯基距离是一组常用的<strong>连续型距离度量</strong>，通过调整参数
$ p $ 可以统一表示多种距离形式，是欧氏距离和曼哈顿距离的推广。</p>
<p><strong>1. 公式定义</strong></p>
<p>对于两个 $ n $ 维向量 $ <em>i = (x</em>{i1}, x_{i2}, , x_{in}) $ 和 $
<em>j = (x</em>{j1}, x_{j2}, , x_{jn}) $，明可夫斯基距离的计算公式为：
<span class="math display">$$
\text{dist}_{\text{mk}}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \left(
\sum_{u=1}^{n} |x_{iu} - x_{ju}|^p \right)^{\frac{1}{p}}
$$</span> 其中，$ p $ 是一个可调节的参数。</p>
<p><strong>2. 特殊情况</strong></p>
<ul>
<li><strong>当 $ p = 2 $</strong>：退化为<strong>欧氏距离（Euclidean
Distance）</strong><br>
<span class="math display">$$
\text{dist}_{\text{ed}}(\boldsymbol{x}_i, \boldsymbol{x}_j) =
\sqrt{\sum_{u=1}^{n} |x_{iu} - x_{ju}|^2}
$$</span>
<ul>
<li><strong>几何意义</strong>：两点之间的直线距离。<br>
</li>
<li><strong>适用场景</strong>：大多数机器学习算法（如KNN、PCA）默认使用欧氏距离。</li>
</ul></li>
<li><strong>当 $ p = 1 $</strong>：退化为<strong>曼哈顿距离（Manhattan
Distance）</strong><br>
<span class="math display">$$
\text{dist}_{\text{man}}(\boldsymbol{x}_i, \boldsymbol{x}_j) =
\sum_{u=1}^{n} |x_{iu} - x_{ju}|
$$</span>
<ul>
<li><strong>几何意义</strong>：沿坐标轴移动的总距离（如棋盘格路径）。<br>
</li>
<li><strong>适用场景</strong>：高维稀疏数据（如文本特征）、计算资源受限的场景。</li>
</ul></li>
<li><strong>当 $ p $</strong>：退化为<strong>切比雪夫距离（Chebyshev
Distance）</strong><br>
<span class="math display">dist<sub>che</sub>(<strong>x</strong><sub><em>i</em></sub>,<strong>x</strong><sub><em>j</em></sub>) = max<sub><em>u</em></sub>|<em>x</em><sub><em>i</em><em>u</em></sub>−<em>x</em><sub><em>j</em><em>u</em></sub>|</span>
<ul>
<li><strong>几何意义</strong>：各维度差值的最大值。<br>
</li>
<li><strong>适用场景</strong>：关注最坏情况下的误差（如游戏AI路径规划）。</li>
</ul></li>
</ul>
<p><strong>3. 参数 $ p $ 的影响</strong></p>
<ul>
<li><strong>$ p $
越小</strong>：距离计算越关注较小的维度差异（如曼哈顿距离对单个维度的扰动更敏感）。<br>
</li>
<li><strong>$ p $
越大</strong>：距离计算越关注较大的维度差异（如切比雪夫距离仅关注最大差值）。<br>
</li>
<li><strong>选择依据</strong>：
<ul>
<li>数据分布是否均匀：若某些维度差异显著，可增大 $ p $。<br>
</li>
<li>算法需求：如KNN中，高维数据可能更适合曼哈顿距离（缓解“维度灾难”）。</li>
</ul></li>
</ul>
<h5 id="离散无序">离散无序</h5>
<p>我们知道属性分为两种：<strong>连续属性</strong>(continuous
attribute)和<strong>离散属性</strong>（catergorical
attribute有限个取值）。对于连续值的属性，一般都可以被学习器所用，有时会根据具体的情形作相应的预处理，例如：归一化等；而对于离散值的属性，需要作下面进一步的处理：</p>
<blockquote>
<p>若属性值之间<strong>存在序关系</strong>(ordinal
attribute)，则可以将其转化为连续值，例如：身高属性“高”“中等”“矮”，可转化为{1,
0.5, 0}。</p>
<p>若属性值之间<strong>不存在序关系</strong>(non-ordinal
attribute)，则通常将其转化为向量的形式，例如：性别属性“男”“女”，可转化为{（1,0）,（0,1）}。</p>
</blockquote>
<p><strong>连续属性和存在序关系的离散属性都可以直接参与计算</strong>，而不存在序关系的<strong>无序属性，我们一般采用VDM（Value
Difference Metric）进行距离的计算</strong></p>
<p>VDM
是一种专门用于<strong>离散无序属性</strong>的距离度量方法，通过统计信息量化不同类别间的差异。其核心思想是：<strong>若两个类别的样本在目标变量上的分布差异越大，则它们的距离越大</strong>。</p>
<p><strong>1. 公式解析</strong> <span class="math display">$$
\text{VDM}_p(a, b) = \sum_{i=1}^{k} \left| \frac{m_{u,a,i}}{m_{u,a}} -
\frac{m_{u,b,i}}{m_{u,b}} \right|^p
$$</span> - <strong>符号含义</strong>：<br>
- $ a, b $：两个不同的类别值（如性别“男”和“女”）。<br>
- $ m_{u,a,i} $：在属性 $ u $ 的第 $ i $ 个取值下，类别 $ a $
的样本数量。<br>
- $ m_{u,a} $：类别 $ a $ 的总样本数量。<br>
- $ k $：属性 $ u $ 的不同取值数目（如颜色属性有红、蓝、绿三种取值，则 $
k=3 $）。<br>
- $ p $：距离幂指数（通常取 $ p=1 $ 或 $ p=2 $）。</p>
<p><strong>2. 核心思想</strong></p>
<ul>
<li><strong>统计分布差异</strong>：<br>
对于每个属性取值 $ i $，计算类别 $ a $ 和 $ b $ 的样本比例差异：<br>
<span class="math display">$$
\left| \frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}} \right|
$$</span> 该值越大，说明两个类别在该取值上的分布差异越大。<br>
</li>
<li><strong>加权求和</strong>：<br>
将所有属性取值的差异按 $ p $ 次方加权求和，得到最终的距离。</li>
</ul>
<p><strong>3. 示例说明</strong></p>
<p>假设我们有一个“颜色”属性（红、蓝、绿），目标变量是“是否购买商品”（0/1）。统计结果如下：</p>
<table>
<thead>
<tr class="header">
<th>颜色</th>
<th>购买（1）</th>
<th>不购买（0）</th>
<th>总计</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>红</td>
<td>10</td>
<td>5</td>
<td>15</td>
</tr>
<tr class="even">
<td>蓝</td>
<td>8</td>
<td>12</td>
<td>20</td>
</tr>
<tr class="odd">
<td>绿</td>
<td>3</td>
<td>7</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>计算“红”与“蓝”之间的 VDM 距离（$ p=1 <span class="math inline">）：1.<em>计</em><em>算</em><em>每</em><em>个</em><em>颜</em><em>色</em><em>在</em><em>购</em><em>买</em>/<em>不</em><em>购</em><em>买</em><em>的</em><em>比</em><em>例</em>： − <em>红</em>：</span>
P(1) = 10/15 <span class="math inline">，</span> P(0) = 5/15 $<br>
- 蓝：$ P(1) = 8/20 = 0.4 <span class="math inline">，</span> P(0) =
12/20 = 0.6 $<br>
2. 计算差异并求和：<br>
<span class="math display">VDM<sub>1</sub>(红,蓝) = |0.67−0.4| + |0.33−0.6| = 0.27 + 0.27 = 0.54</span></p>
<h4 id="性能度量">性能度量</h4>
<p>于聚类算法不依赖于样本的真实类标，就不能像监督学习的分类那般，通过计算分对分错（即精确度或错误率）来评价学习器的好坏或作为学习过程中的优化目标。</p>
<p>直观上看,我们希望<strong>“物以类聚”</strong>,即同一簇的样本尽可能彼此相似,不同簇的样本尽可能不同换言之,聚类结果的<strong>“簇内相似度”(
intra-cluster similarity)高且“簇间相似度” inter-cluster
similarity)低</strong></p>
<p><strong>聚类性能度量有两类</strong></p>
<ul>
<li>“外部指标”(external
index)：所谓外部指标就是已经有一个“参考模型”存在了，将当前模型与参考模型的比对结果作为指标。</li>
<li>“内部指标”( internal
index)：所谓内部指标就是仅仅考虑当前模型的聚类结果。</li>
</ul>
<h5 id="外部指标">外部指标</h5>
<p><strong>1.基本概念</strong></p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607110103570.png" alt="image-20250607110103570">
<figcaption aria-hidden="true">image-20250607110103570</figcaption>
</figure>
<p>显然，$ a + b + c + d = $ 。</p>
<p><strong>2. 常用外部指标</strong></p>
<p><strong>（1）Jaccard系数（JC）</strong> <span class="math display">$$
\text{JC} = \frac{a}{a + b + c}
$$</span> -
<strong>含义</strong>：衡量两个划分的重叠程度，仅考虑正确匹配（$ a <span class="math inline">）<em>与</em><em>矛</em><em>盾</em><em>情</em><em>况</em>（</span>
b + c <span class="math inline">）。 −  *  * <em>范</em><em>围</em> *  * ：</span>
[0, 1] $，值越大越好。<br>
- <strong>特点</strong>：对称性差，对噪声敏感 。</p>
<p><strong>（2）Fowlkes-Mallows指数（FMI）</strong> <span class="math display">$$
\text{FMI} = \sqrt{\frac{a}{a + b} \cdot \frac{a}{a + c}}
$$</span> - <strong>含义</strong>：结合查准率（$ <span class="math inline">）<em>和</em><em>查</em><em>全</em><em>率</em>（</span>
<span class="math inline">），<em>反</em><em>映</em><em>正</em><em>确</em><em>匹</em><em>配</em><em>的</em><em>综</em><em>合</em><em>能</em><em>力</em>。 −  *  * <em>范</em><em>围</em> *  * ：</span>
[0, 1] $，值越大越好。<br>
- <strong>特点</strong>：平衡性较好，适合小样本 。</p>
<p><strong>（3）Rand指数（RI）</strong> <span class="math display">$$
\text{RI} = \frac{2(a + d)}{m(m - 1)}
$$</span> - <strong>含义</strong>：同时考虑正确匹配（$ a + d <span class="math inline">）<em>与</em><em>总</em><em>样</em><em>本</em><em>对</em><em>数</em>，<em>适</em><em>用</em><em>于</em><em>大</em><em>规</em><em>模</em><em>数</em><em>据</em>。 −  *  * <em>范</em><em>围</em> *  * ：</span>
[0, 1] $，值越大越好。<br>
- <strong>特点</strong>：计算简单，但对噪声较鲁棒 。</p>
<p><strong>常用指标</strong></p>
<ul>
<li><strong>调整兰德指数（Adjusted Rand Index, ARI）</strong>
<ul>
<li><strong>定义</strong>：衡量聚类结果与真实标签的匹配程度，调整随机聚类的影响，取值范围
[-1, 1]，值越大越好。<br>
</li>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{ARI} = \frac{\text{RI} - \mathbb{E}[\text{RI}]}{\max(\text{RI}) -
\mathbb{E}[\text{RI}]}
$$</span> 其中 RI 是兰德指数（匹配样本对的比例）。</li>
</ul></li>
<li><strong>归一化互信息（Normalized Mutual Information, NMI）</strong>
<ul>
<li><strong>定义</strong>：衡量聚类结果与真实标签的信息共享程度，值越大越好。<br>
</li>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{NMI} = \frac{I(C; K)}{\sqrt{H(C) H(K)}}
$$</span> 其中 $ I(C; K) $ 是互信息，$ H(C) $ 和 $ H(K) $ 是熵。</li>
</ul></li>
<li><strong>Fowlkes-Mallows 指数（FMI）</strong>
<ul>
<li><strong>定义</strong>：基于聚类结果与真实标签的 TP、FP、TN、FN
计算，值越大越好。<br>
</li>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{FMI} = \sqrt{\frac{\text{TP}}{\text{TP} + \text{FP}} \cdot
\frac{\text{TP}}{\text{TP} + \text{FN}}}
$$</span></li>
</ul></li>
</ul>
<p><strong>优点</strong></p>
<ul>
<li>在有真实标签时，能更客观地评估聚类效果。</li>
<li>适用于验证聚类结果的业务意义（如客户分群是否符合预期）。</li>
</ul>
<p><strong>局限性</strong></p>
<ul>
<li>需要真实标签，不适用于纯无监督任务。</li>
<li>对标签噪声敏感（如标签错误会误导 $ K $ 的选择）。</li>
</ul>
<p><strong>3. 应用示例</strong></p>
<p>假设一个包含4个样本的数据集，参考标签为 <span class="math inline">{<em>A</em>, <em>A</em>, <em>B</em>, <em>B</em>}</span>，聚类结果为
<span class="math inline">{<em>C</em>, <em>C</em>, <em>D</em>, <em>D</em>}</span>：
- <strong>计算样本对</strong>：<br>
- $ a = 2 $（样本1-2同簇，参考与聚类均同类）。<br>
- $ b = 0 $（参考同类但聚类不同类）。<br>
- $ c = 0 $（参考不同类但聚类同类）。<br>
- $ d = 2 $（参考不同类且聚类不同类）。<br>
- <strong>指标结果</strong>：<br>
- JC = $ = 1 $（完美匹配）。<br>
- FMI = $ = 1 $。<br>
- RI = $ = $。</p>
<h5 id="内部指标">内部指标</h5>
<p>内部指标不依赖任何外部参考模型，直接通过<strong>簇内紧凑性</strong>和<strong>簇间分离性</strong>评估聚类结果。其核心思想是：
- <strong>簇内高内聚</strong>：同一簇的样本尽可能相似（距离小）。<br>
- <strong>簇间低耦合</strong>：不同簇的样本尽可能不同（距离大）。</p>
<p><strong>1. 基本定义</strong></p>
<p>设聚类结果为 $ C = {C_1, C_2, , C_k} $，定义以下四个关键距离：</p>
<p><strong>（1）簇内平均距离（avg(C)）</strong> <span class="math display">$$
\text{avg}(C) = \frac{2}{|C|(|C| - 1)} \sum_{1 \leq i &lt; j \leq |C|}
\text{dist}(\boldsymbol{x}_i, \boldsymbol{x}_j)
$$</span> - <strong>含义</strong>：簇内所有样本对的平均距离。<br>
- <strong>目标</strong>：越小越好，表示簇内样本更紧密。</p>
<p><strong>（2）簇内最大距离（diam(C)）</strong> <span class="math display">diam(<em>C</em>) = max<sub>1 ≤ <em>i</em> &lt; <em>j</em> ≤ |<em>C</em>|</sub>dist(<strong>x</strong><sub><em>i</em></sub>,<strong>x</strong><sub><em>j</em></sub>)</span>
- <strong>含义</strong>：簇内最远的两个样本之间的距离。<br>
- <strong>目标</strong>：越小越好，避免簇内存在离群点。</p>
<p><strong>（3）簇间最小距离（$ d_{}(C_i, C_j) $）</strong> <span class="math display"><em>d</em><sub>min</sub>(<em>C</em><sub><em>i</em></sub>,<em>C</em><sub><em>j</em></sub>) = min<sub><strong>x</strong><sub><em>i</em></sub> ∈ <em>C</em><sub><em>i</em></sub>, <strong>x</strong><sub><em>j</em></sub> ∈ <em>C</em><sub><em>j</em></sub></sub>dist(<strong>x</strong><sub><em>i</em></sub>,<strong>x</strong><sub><em>j</em></sub>)</span>
- <strong>含义</strong>：簇 $ C_i $ 和 $ C_j $
之间最近的两个样本的距离。<br>
- <strong>目标</strong>：越大越好，表示簇间分离度高。</p>
<p><strong>（4）簇中心距离（$ d_{}(C_i, C_j) $）</strong> <span class="math display"><em>d</em><sub>cen</sub>(<em>C</em><sub><em>i</em></sub>,<em>C</em><sub><em>j</em></sub>) = dist(<strong>μ</strong><sub><em>i</em></sub>,<strong>μ</strong><sub><em>j</em></sub>)</span>
- <strong>含义</strong>：簇 $ C_i $ 和 $ C_j $
的中心点（均值向量）之间的距离。<br>
- <strong>目标</strong>：越大越好，表示簇中心相隔较远。</p>
<p><strong>2. 常用内部指标</strong></p>
<p><strong>1. DB指数（Davies-Bouldin Index, DBI）</strong></p>
<ul>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{DBI} = \frac{1}{k} \sum_{i=1}^{k} \max_{j \neq i} \left(
\frac{\text{avg}(C_i) + \text{avg}(C_j)}{d_{\text{cen}}(\mu_i, \mu_j)}
\right)
$$</span>
<ul>
<li><strong>符号含义</strong>：
<ul>
<li>$ k $：簇的数量。<br>
</li>
<li>$ (C_i) $：簇 $ C_i $ 内部样本的平均距离。<br>
</li>
<li>$ d_{}(_i, _j) $：簇 $ C_i $ 和 $ C_j $
的中心点（均值向量）之间的距离。<br>
</li>
</ul></li>
<li><strong>目标</strong>：越小越好。<br>
</li>
<li><strong>核心思想</strong>：对于每个簇 $ C_i $，找到与其“最竞争”的簇
$ C_j $（即 $ $ 最大的簇），并取所有簇的平均值。</li>
</ul></li>
<li><strong>示例</strong>：<br>
若簇 $ C_1 $ 和 $ C_2 $ 的平均距离分别为 2 和 3，中心距离为
5，则它们的比值为 $ = 1 $。若这是 $ C_1 $ 的最大比值，则 $ C_1 $ 对 DBI
的贡献为 1。最终 DBI 是所有簇贡献的平均值。</li>
</ul>
<p><strong>2. Dunn指数（Dunn Index, DI）</strong></p>
<ul>
<li><strong>公式</strong>：<br>
<span class="math display">$$
\text{DI} = \min_{1 \leq i \leq k} \left\{ \frac{\min_{j \neq i}
d_{\min}(C_i, C_j)}{\max_{1 \leq l \leq k} \text{diam}(C_l)} \right\}
$$</span>
<ul>
<li><strong>符号含义</strong>：
<ul>
<li>$ d_{}(C_i, C_j) $：簇 $ C_i $ 和 $ C_j $
之间的最小距离（最近样本对的距离）。<br>
</li>
<li>$ (C_l) $：簇 $ C_l $ 内的最大距离（最远样本对的距离）。<br>
</li>
</ul></li>
<li><strong>目标</strong>：越大越好。<br>
</li>
<li><strong>核心思想</strong>：
<ul>
<li>分子：所有簇对之间的最小距离中的最小值（即最“脆弱”的簇间分离度）。<br>
</li>
<li>分母：所有簇中的最大直径（最“松散”的簇内紧凑度）。<br>
</li>
<li>指数越大，表示簇间分离度高且簇内紧凑。</li>
</ul></li>
</ul></li>
<li><strong>示例</strong>：<br>
假设簇对 $ (C_1, C_2) $ 的最小距离为 5，簇 $ C_3 $ 的最大直径为 10，则
DI 为 $ = 0.5 $。</li>
</ul>
<p><strong>3. 轮廓系数（Silhouette Coefficient）</strong></p>
<ul>
<li><p><strong>单一样本的轮廓系数</strong>：<br>
<span class="math display">$$
s = \frac{b - a}{\max(a, b)}
$$</span></p>
<ul>
<li><strong>符号含义</strong>：
<ul>
<li>$ a $：样本到同簇其他样本的平均距离（簇内凝聚度）。<br>
</li>
<li>$ b $：样本到最近簇中样本的平均距离（簇间分离度）。<br>
</li>
</ul></li>
<li><strong>取值范围</strong>：$ [-1, 1] $，越接近 1
表示聚类效果越好。<br>
</li>
<li><strong>核心思想</strong>：
<ul>
<li>若 $ a &lt; b $（同簇紧密，异簇疏远），则 $ s &gt; 0
$，样本分类合理。<br>
</li>
<li>若 $ a &gt; b $（同簇松散，异簇更近），则 $ s &lt; 0
$，样本可能被错误分类。</li>
</ul></li>
</ul></li>
<li><p><strong>整体轮廓系数</strong>：所有样本轮廓系数的平均值。</p></li>
<li><p><strong>示例</strong>：<br>
若某样本 $ a = 2 <span class="math inline">，</span> b = 5 $，则 $ s = =
0.6 $，表明该样本分类合理。</p></li>
</ul>
<p><strong>4.肘部法则（Elbow Method）</strong></p>
<p>肘部法则是一种<strong>经验性方法</strong>，常用于确定K-means等聚类算法的最优簇数（$
K $）。其核心思想是通过观察误差平方和（SSE, Sum of Squared Errors）随 $
K $ 值变化的趋势，寻找“肘部点”（即 SSE
下降速度明显减缓的拐点），从而选择最优的 $ K $ 值</p>
<ul>
<li><p><strong>SSE（误差平方和）</strong>：衡量每个样本到其所属簇中心的距离平方和，公式为：
<span class="math display">$$
\text{SSE} = \sum_{i=1}^n \|x_i - \mu_{c_i}\|^2
$$</span> 其中 $ x_i $ 是样本点，$ _{c_i} $ 是其所属簇中心。</p></li>
<li><p><strong>趋势分析</strong>：</p>
<ul>
<li>当 $ K $ 增大时，SSE
会不断减小（因为簇越多，每个簇的样本越密集）。</li>
<li>但当 $ K $ 增加到某个值后，SSE
的下降速度会显著放缓，形成“肘部”形状。</li>
</ul></li>
<li><p><strong>肘部点的意义</strong>：<br>
肘部点对应的 $ K $
值是<strong>模型复杂度</strong>（簇数）与<strong>聚类效果</strong>（SSE）之间的平衡点。</p></li>
</ul>
<p><strong>指标对比与选择</strong></p>
<table style="width:100%;">
<colgroup>
<col style="width: 8%">
<col style="width: 32%">
<col style="width: 13%">
<col style="width: 22%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th><strong>指标</strong></th>
<th><strong>计算方式</strong></th>
<th><strong>目标</strong></th>
<th><strong>适用场景</strong></th>
<th><strong>局限性</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DBI</td>
<td>簇内平均距离与簇中心距离的比值</td>
<td>越小越好</td>
<td>球形簇，需指定 $ k $</td>
<td>对离群点敏感</td>
</tr>
<tr class="even">
<td>Dunn指数</td>
<td>簇间最小距离与簇内最大直径的比值</td>
<td>越大越好</td>
<td>强调簇间分离与簇内紧凑</td>
<td>计算复杂，受离群点影响</td>
</tr>
<tr class="odd">
<td>轮廓系数</td>
<td>样本到同簇/异簇的平均距离差</td>
<td>越接近 1 越好</td>
<td>快速评估，适合 K-Means</td>
<td>对非球形簇不敏感</td>
</tr>
</tbody>
</table>
<h4 id="原型聚类与kmeans">原型聚类与kmeans</h4>
<h5 id="原型聚类">原型聚类</h5>
<p>原型聚类即“<strong>基于原型的聚类</strong>”（prototype-based
clustering），原型表示模板的意思，就是通过参考一个模板向量或模板分布的方式来完成聚类的过程，通常情形下算法先对原型进行初始化,然后对原型进行迭代更新求解。采用不同的原型表、不同的求解方式,将产生不同的算法。</p>
<p>常见的K-Means便是基于簇中心（原型向量）来实现聚类，混合高斯聚类则是基于簇分布（概率模型）来实现聚类。</p>
<h5 id="k-means-聚类算法详解"><strong>K-Means 聚类算法详解</strong></h5>
<p><strong>目标函数</strong>：最小化所有样本到其所属簇中心的平方距离之和：<br>
<span class="math display">$$
E = \sum_{i=1}^{k} \sum_{\boldsymbol{x} \in C_i} \|\boldsymbol{x} -
\boldsymbol{\mu}_i\|_2^2
$$</span> 其中，$ <em>i = </em>{ C_i} $ 是簇 $ C_i $ 的均值向量。</p>
<p><strong>算法步骤</strong></p>
<ol type="1">
<li><strong>初始化簇中心</strong>：随机选择 $ k $ 个样本作为初始簇中心。
<ul>
<li><strong>改进方法</strong>：K-Means++
算法可提升初始中心的质量。<br>
</li>
</ul></li>
<li><strong>分配样本到最近簇</strong>：对每个样本 $
$，计算其到所有簇中心的距离，将其分配到距离最近的簇 $ C_i $。<br>
</li>
<li><strong>更新簇中心</strong>：重新计算每个簇的均值向量 $ _i $。<br>
</li>
<li><strong>迭代终止条件</strong>：
<ul>
<li>达到预设的最大迭代次数；<br>
</li>
<li>簇中心不再显著变化（如变化幅度小于阈值 $ $）；<br>
</li>
<li>样本分配不再改变。</li>
</ul></li>
</ol>
<p><strong>如何选择 $ k $ 值？</strong></p>
<ul>
<li><strong>肘部法则（Elbow Method）</strong>：绘制 $ k $ 与误差 $ E $
的关系曲线，选择误差下降显著变缓的 $ k $ 值。<br>
</li>
<li><strong>轮廓系数（Silhouette
Coefficient）</strong>：计算每个样本的轮廓系数，选择平均轮廓系数最大的 $
k $。</li>
</ul>
<h5 id="k-means的算法流程">K-Means的算法流程</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607114743211.png" alt="image-20250607114743211">
<figcaption aria-hidden="true">image-20250607114743211</figcaption>
</figure>
<h5 id="k-means">K-means++</h5>
<p>此法相对于 K-means 做出了一个小的改进。在一开始选择 k
个聚类中心时，并不是随机初始化 k 个，而是首先随机出 1 个，然后循环
k−1<em>k</em>−1 次选择剩下的 k-1
个聚类中心。选择的规则是：每次选择最不可能成为新的聚类中心的样本，或者是到所有聚类中心的最小距离最大的样本。</p>
<h5 id="优势"><strong>优势</strong></h5>
<p><strong>避免不良初始化</strong>
：传统K-means随机初始化可能导致中心过于集中，而K-means++通过“最大化最小距离”策略，使初始中心分布更均匀。</p>
<h5 id="bisecting-k-means">Bisecting K-means</h5>
<p>此法叫做二分 K-means
算法。具体的，在一开始将所有的样本划分为一个簇，然后每次选择一个误差最大的簇进行二分裂，不断分裂直到收敛。这种方法不能使得
Loss 最小，但是可以作为 K-means
算法的一个预热，比如可以通过这种方法得到一个相对合理的簇中心，然后再利用
K-means 算法进行聚类。</p>
<h5 id="优势-1"><strong>优势</strong></h5>
<p><strong>降低计算复杂度</strong>
：每次仅对一个簇进行二分，时间复杂度为
<em>O</em>(<em>k</em>⋅<em>m</em>⋅<em>n</em>) ，适合大规模数据。</p>
<p><strong>提供合理初始中心</strong>
：可作为传统K-means的预处理，减少随机初始化的影响。</p>
<h5 id="lvq学习向量量化"><strong>LVQ（学习向量量化）</strong></h5>
<p><strong>核心思想</strong>：<br>
LVQ
是一种<strong>有监督的原型聚类算法</strong>，结合了神经网络与向量量化技术。它通过维护一组<strong>原型向量</strong>（Prototype
Vectors）来代表不同类别，并利用这些原型对数据进行分类或聚类。与 K-Means
类似，LVQ
会为每个簇分配一个原型向量，但其更新规则受类别标签的指导，因此更适用于分类任务
。</p>
<p><strong>算法特点</strong>：</p>
<ul>
<li><strong>有监督学习</strong>：需要已知类别标签来调整原型向量，使同类样本更接近对应原型，异类样本远离原型。<br>
</li>
<li><strong>拓扑结构建模</strong>：通过原型向量捕捉数据的局部特征，类似于自组织映射（SOM），但更具针对性。<br>
</li>
<li><strong>硬聚类</strong>：每个样本最终被分配到最近的原型对应的类别，不提供概率输出
。</li>
</ul>
<h5 id="高斯混合聚类gaussian-mixture-model-gmm"><strong>高斯混合聚类（Gaussian
Mixture Model, GMM）</strong></h5>
<p>一句话概述算法：高斯混合聚类算法是一种概率模型，假设数据由多个高斯分布混合而成，通过迭代优化参数以拟合数据分布，常用于无监督学习中的聚类任务。</p>
<p>算法过程：</p>
<p>初始化参数： 随机初始化每个分量的均值、协方差矩阵和混合系数。</p>
<p>E 步（Expectation）：
对每个数据点，计算它属于每个分量的后验概率，即计算每个分量的权重。</p>
<p>M 步（Maximization）：
使用E步计算得到的后验概率，更新每个分量的均值、协方差矩阵和混合系数。</p>
<p>迭代： 重复执行E步和M步，直到模型参数收敛或达到预定的迭代次数。</p>
<p>GMM的优点包括对各种形状和方向的聚类簇建模能力，以及对数据分布的灵活性。它在许多领域，如模式识别、图像处理和自然语言处理等，都有广泛的应用。
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250611180451162.png" alt="image-20250611180451162"></p>
<p>以下是高斯混合聚类（GMM）算法的详细步骤及EM算法中E步与M步的解释：</p>
<p><strong>算法流程解析</strong></p>
<p><strong>输入</strong>：样本集 $ D = {x_1, x_2, , x_m} $，混合成分个数
$ k $。<br>
<strong>输出</strong>：簇划分 $ C = {C_1, C_2, , C_k} $。</p>
<p><strong>步骤详解</strong></p>
<ol type="1">
<li><p><strong>初始化模型参数</strong><br>
随机初始化或通过K-means初步估计以下参数：</p>
<ul>
<li><strong>混合系数</strong> $ <em>i $（满足 $ </em>{i=1}^k _i = 1
$）。</li>
<li><strong>均值向量</strong> $ _i $。</li>
<li><strong>协方差矩阵</strong> $ _i $。</li>
</ul></li>
<li><p><strong>迭代优化参数（EM循环）</strong><br>
重复以下步骤直到收敛（如对数似然变化小于阈值）：</p>
<ul>
<li><p><strong>E步（期望步）</strong>：<br>
对每个样本 $ x_j $，计算其由第 $ i $
个高斯分布生成的<strong>后验概率</strong>（责任度 $ _{ji} $）： <span class="math display">$$
\gamma_{ji} = p(z_j = i | x_j) = \frac{\alpha_i \mathcal{N}(x_j | \mu_i,
\Sigma_i)}{\sum_{l=1}^k \alpha_l \mathcal{N}(x_j | \mu_l, \Sigma_l)}
$$</span> 其中 $ (x | , ) $ 是高斯分布的概率密度函数。</p></li>
<li><p><strong>M步（最大化步）</strong>：<br>
根据当前的责任度 $ _{ji} $，更新模型参数：</p>
<ol type="1">
<li><strong>新均值向量</strong>： <span class="math display">$$
\mu_i' = \frac{\sum_{j=1}^m \gamma_{ji} x_j}{\sum_{j=1}^m \gamma_{ji}}
$$</span></li>
<li><strong>新协方差矩阵</strong>： <span class="math display">$$
\Sigma_i' = \frac{\sum_{j=1}^m \gamma_{ji} (x_j - \mu_i')(x_j -
\mu_i')^\top}{\sum_{j=1}^m \gamma_{ji}}
$$</span></li>
<li><strong>新混合系数</strong>： <span class="math display">$$
\alpha_i' = \frac{\sum_{j=1}^m \gamma_{ji}}{m}
$$</span></li>
</ol></li>
</ul></li>
<li><p><strong>簇划分</strong></p>
<ul>
<li>初始化空簇 $ C_i = $。</li>
<li>对每个样本 $ x_j $，计算其属于各簇的后验概率 $ _j = <em>i </em>{ji}
$。</li>
<li>将 $ x_j $ 分配到簇 $ C_{_j} $ 中。</li>
</ul></li>
</ol>
<p><strong>E步与M步的核心作用</strong></p>
<p><strong>E步（期望步）</strong></p>
<ul>
<li><strong>目标</strong>：基于当前参数 $ (_i, _i, <em>i)
$，计算每个样本 $ x_j $ 属于各高斯分布的<strong>责任度</strong> $
</em>{ji} $。</li>
<li><strong>意义</strong>：
<ul>
<li>责任度反映了在当前模型下，样本 $ x_j $ 由第 $ i $
个高斯分布生成的概率。</li>
<li><strong>软分配</strong>：允许样本部分属于多个簇，而非硬划分。</li>
</ul></li>
</ul>
<p><strong>M步（最大化步）</strong></p>
<ul>
<li><strong>目标</strong>：根据责任度 $ _{ji} $，重新估计模型参数 $
(_i’, _i’, _i’) $，以最大化数据的对数似然。</li>
<li><strong>关键公式</strong>：
<ul>
<li><strong>均值更新</strong>：加权平均样本点，权重为责任度。</li>
<li><strong>协方差更新</strong>：加权样本点的方差，反映簇内数据分布。</li>
<li><strong>混合系数更新</strong>：各簇样本的“有效数量”占总样本的比例。</li>
</ul></li>
</ul>
<h4 id="参考资料-1">参考资料</h4>
<p><a href="https://blog.csdn.net/smileyan9/article/details/135398479">西瓜书读书笔记整理（九）
—— 第九章 聚类_西瓜书笔记第9章-CSDN博客</a></p>
<h4 id="密度聚类与dbscan">密度聚类与DBSCAN</h4>
<blockquote>
<p>若样本分布为同心的两个环，kmeans则无法做到良好的聚类效果，因此引出密度聚类</p>
</blockquote>
<p>密度聚类是一种基于<strong>样本分布密集程度</strong>的无监督学习方法，其核心思想是：<strong>将高密度区域划分为同一簇，低密度区域视为噪声或边界</strong>。</p>
<p>DBSCAN（Density-Based Spatial Clustering of Applications with
Noise）是密度聚类的典型代表，通过两个关键参数 $ $ 和 $ MinPts $
描述样本分布的紧密性。</p>
<h5 id="核心概念"><strong>1. 核心概念</strong></h5>
<ol type="1">
<li><strong>$ $-邻域</strong>
<ul>
<li>定义：与样本 $ x $ 距离不超过 $ $ 的所有样本集合。<br>
</li>
<li>作用：衡量样本周围的局部密度。<br>
</li>
</ul></li>
<li><strong>核心对象（Core Object）</strong>
<ul>
<li>定义：若样本 $ x $ 的 $ $-邻域内包含至少 $ MinPts $ 个样本，则 $ x $
是核心对象。<br>
</li>
<li>作用：作为簇的生长起点，确保簇的最小密度要求。<br>
</li>
</ul></li>
<li><strong>密度直达（Directly Density-Reachable）</strong>
<ul>
<li>定义：若样本 $ x_j $ 位于核心对象 $ x_i $ 的 $ $-邻域内，则称 $ x_i
$ 可密度直达 $ x_j $。<br>
</li>
<li>作用：建立核心对象与邻近样本的直接连接。<br>
</li>
</ul></li>
<li><strong>密度可达（Density-Reachable）</strong>
<ul>
<li>定义：若存在样本序列 $ x_i, p_1, p_2, , p_n, x_j $，其中 $ p_i $
密度直达 $ p_{i+1} $，则称 $ x_i $ 可密度可达 $ x_j $。<br>
</li>
<li>作用：通过链式传递扩展簇的范围。<br>
</li>
</ul></li>
<li><strong>密度相连（Density-Connected）</strong>
<ul>
<li>定义：若样本 $ x_i $ 和 $ x_j $ 均可密度可达某个公共样本 $ x_k
$，则称 $ x_i $ 和 $ x_j $ 密度相连。<br>
</li>
<li>作用：确保簇的连通性，避免碎片化。</li>
</ul></li>
</ol>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124326529.png" alt="image-20250607124326529">
<figcaption aria-hidden="true">image-20250607124326529</figcaption>
</figure>
<p><strong>DBSCN定义的簇</strong></p>
<ul>
<li>定义：最大密度相连的样本集合为一个簇</li>
<li>有两个性质：1.连接性：同一个簇内任意两样本，必然密度相连2.最大性：密度可达的两个样本必
定属于同一个簇</li>
</ul>
<h5 id="dbscan-算法流程"><strong>2. DBSCAN 算法流程</strong></h5>
<p>简单来理解DBSCAN：<strong>找出一个核心对象所有密度可达的样本集合形成簇</strong>。首先从数据集中任选一个核心对象A，找出所有A密度可达的样本集合，将这些样本形成一个密度相连的类簇，直到所有的核心对象都遍历完。DBSCAN算法的流程如下图所示：</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124446432.png" alt="image-20250607124446432">
<figcaption aria-hidden="true">image-20250607124446432</figcaption>
</figure>
<h5 id="参数选择与影响"><strong>3. 参数选择与影响</strong></h5>
<ul>
<li><strong>$ $（邻域半径）</strong>：
<ul>
<li>过小：可能导致多数样本被标记为噪声，簇数量增加。<br>
</li>
<li>过大：可能导致不同簇合并，簇数量减少。<br>
</li>
<li><strong>选择方法</strong>：通过<strong>K-Distance图</strong>（排序后的第
$ k $ 近邻距离）观察“拐点”。</li>
</ul></li>
<li><strong>$ MinPts $（最小样本数）</strong>：
<ul>
<li>控制簇的最小密度阈值。<br>
</li>
<li>通常取 $ d+1 <span class="math inline">（</span> d $
为特征维度），避免在高维空间中误判噪声。</li>
</ul></li>
</ul>
<h4 id="层次聚类与agnes">层次聚类与AGNES</h4>
<p>层次聚类是一种通过构建<strong>树状结构（Dendrogram）</strong>将数据划分为不同层次的聚类方法。其核心思想是：<br>
-
<strong>凝聚型（Agglomerative）</strong>：从每个样本作为一个独立簇开始，逐步合并最相似的簇，直到达到预设的簇数或形成一个唯一簇。<br>
-
<strong>分裂型（Divisive）</strong>：与凝聚型相反，从整个数据集作为一个簇开始，逐步分裂为更小的簇。</p>
<p>本节重点介绍<strong>AGNES（Agglomerative
Nesting）</strong>，一种经典的自底向上的层次聚类算法。</p>
<h5 id="agnes-算法流程"><strong>1. AGNES 算法流程</strong></h5>
<ol type="1">
<li><strong>初始化</strong>：每个样本作为一个独立簇。<br>
</li>
<li><strong>迭代合并</strong>：
<ul>
<li>计算所有簇对之间的距离。<br>
</li>
<li>合并距离最近的两个簇。<br>
</li>
</ul></li>
<li><strong>终止条件</strong>：
<ul>
<li>达到预设的簇数 $ k $；<br>
</li>
<li>所有簇之间的距离大于阈值。</li>
</ul></li>
</ol>
<h5 id="簇间距离的定义"><strong>2. 簇间距离的定义</strong></h5>
<p>AGNES
的关键在于如何定义<strong>簇间距离</strong>，常见的三种方法如下：</p>
<p><strong>（1）最小距离（Single Linkage）</strong> <span class="math display"><em>d</em><sub>min</sub>(<em>C</em><sub><em>i</em></sub>,<em>C</em><sub><em>j</em></sub>) = min<sub><strong>x</strong> ∈ <em>C</em><sub><em>i</em></sub>, <strong>z</strong> ∈ <em>C</em><sub><em>j</em></sub></sub>dist(<strong>x</strong>,<strong>z</strong>)</span>
- <strong>含义</strong>：两个簇之间最近的两个样本的距离。</p>
<p><strong>（2）最大距离（Complete Linkage）</strong> <span class="math display"><em>d</em><sub>max</sub>(<em>C</em><sub><em>i</em></sub>,<em>C</em><sub><em>j</em></sub>) = max<sub><strong>x</strong> ∈ <em>C</em><sub><em>i</em></sub>, <strong>z</strong> ∈ <em>C</em><sub><em>j</em></sub></sub>dist(<strong>x</strong>,<strong>z</strong>)</span>
- <strong>含义</strong>：两个簇之间最远的两个样本的距离。</p>
<p><strong>（3）平均距离（Average Linkage）</strong> <span class="math display">$$
d_{\text{avg}}(C_i, C_j) = \frac{1}{|C_i| |C_j|} \sum_{\boldsymbol{x}
\in C_i} \sum_{\boldsymbol{z} \in C_j} \text{dist}(\boldsymbol{x},
\boldsymbol{z})
$$</span> - <strong>含义</strong>：两个簇所有样本对距离的平均值。</p>
<h5 id="层次聚类法的算法流程如下所示">层次聚类法的算法流程如下所示：</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125338029.png" alt="image-20250607125338029">
<figcaption aria-hidden="true">image-20250607125338029</figcaption>
</figure>
<h4 id="作业-2">作业</h4>
<h5 id="section-6">1</h5>
<p>假设任务是将下面8个点聚类成3个簇：A1(2,10), A2(2,5), A3(8,4),
B1(5,8), B2(7,5), B3(6,4), C1(1,2),
C3(4,9)，距离函数是欧式距离。假设初始选择A1，B1，C1分别作为每个聚类的中心，用Kmeans算法给出计算过程。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125506436.png" alt="image-20250607125506436">
<figcaption aria-hidden="true">image-20250607125506436</figcaption>
</figure>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125606040.png" alt="image-20250607125606040">
<figcaption aria-hidden="true">image-20250607125606040</figcaption>
</figure>
<h5 id="section-7">2</h5>
<p>Kmeans初始类簇中心如何选取？K值如何确定？请简要阐述。</p>
<p><strong>一、初始类簇中心的选取 (如何选好的起始点？)</strong></p>
<p>传统K-means随机选择初始中心点，容易导致结果不稳定（多次运行结果不同）或陷入局部最优（效果差）。改进方法主要有：</p>
<ol type="1">
<li><strong>K-means++ (最常用且推荐)：</strong>
<ul>
<li><strong>核心思想：</strong> 让初始中心点彼此尽量远离。</li>
<li><strong>步骤：</strong>
<ol type="1">
<li>随机选择<strong>第一个</strong>中心点。</li>
<li>计算每个数据点到<strong>当前已选中心点</strong>的最短距离（即离最近中心的距离）。</li>
<li>以<strong>与这个最短距离平方成正比</strong>的概率，随机选择下一个中心点（距离越大的点，被选中的概率越大）。</li>
<li>重复步骤2和3，直到选出K个中心点。</li>
</ol></li>
<li><strong>优点：</strong>
显著提高聚类质量和稳定性，计算开销增加不大。</li>
</ul></li>
<li><strong>多次运行+选取最优：</strong>
<ul>
<li>独立运行K-means算法多次（每次随机初始化）。</li>
<li>每次运行完成后，计算所有数据点与其所属簇中心的距离平方和（SSE, Sum
of Squared Errors）。</li>
<li>选择SSE最小的那次运行结果作为最终结果。</li>
<li><strong>优点：</strong> 简单，增加找到更好解的机会。</li>
<li><strong>缺点：</strong> 计算开销随运行次数增加。</li>
</ul></li>
<li><strong>基于样本密度/距离：</strong>
<ul>
<li>选择数据空间中样本密度高的区域点作为中心。</li>
<li>或选择相互之间距离较远的点作为中心（类似K-means++的思想，但实现方式可能不同）。</li>
</ul></li>
</ol>
<p><strong>二、K值（簇数量）的确定 (如何知道分几类？)</strong></p>
<p>K值通常需要预先指定，但没有绝对正确的答案。常用方法基于评估不同K值下聚类结果的“质量”，寻找拐点或最优值：</p>
<ol type="1">
<li><strong>肘部法则：</strong>
<ul>
<li><strong>核心思想：</strong>
随着K增大，簇内样本聚合更紧密，簇内平方和误差（SSE）会下降，但下降幅度会逐渐变缓。找到SSE下降速率发生显著变化的“肘点”。</li>
<li><strong>做法：</strong> 计算不同K值（如K=1, 2, 3, …,
max）对应的SSE。绘制<code>K值 - SSE</code>曲线图。观察曲线，寻找SSE下降幅度突然变得平缓的那个K值（形如手臂的“肘关节”）。</li>
<li><strong>优点：</strong> 直观。</li>
<li><strong>缺点：</strong>
“肘点”有时不明显或不存在，需要主观判断。</li>
</ul></li>
<li><strong>轮廓系数：</strong>
<ul>
<li><strong>核心思想：</strong>
综合衡量一个样本与其自身簇的紧密度(<code>a</code>)和与其他簇的分离度(<code>b</code>)。</li>
<li><strong>计算：</strong> 对于每个样本i：
<ul>
<li><code>a(i)</code> = i
到同簇内所有其他点的平均距离（簇内不相似度）。</li>
<li><code>b(i)</code> = i
到所有<strong>其他簇</strong>中点的平均距离的最小值（最近邻簇的不相似度）。</li>
<li>样本i的轮廓系数：<code>s(i) = (b(i) - a(i)) / max(a(i), b(i))</code>。值在[-1,
1]之间。</li>
</ul></li>
<li><strong>整体评估：</strong>
计算所有样本轮廓系数的平均值，作为该K值下聚类的整体轮廓系数。</li>
<li><strong>选择K：</strong>
尝试不同K值，选择<strong>平均轮廓系数最大</strong>对应的K值。轮廓系数越接近1，表示聚类效果越好（簇内紧凑，簇间分离）。</li>
<li><strong>优点：</strong> 量化评估，结果在[-1, 1]之间有界。</li>
<li><strong>缺点：</strong> 计算量较大，尤其对于大数据集。</li>
</ul></li>
</ol>
<h4 id="参考资料-2">参考资料</h4>
<p><a href="https://cloud.tencent.com.cn/developer/article/1802143">《机器学习》–
第九章 聚类-腾讯云开发者社区-腾讯云</a></p>
<h3 id="降维与度量学习">降维与度量学习</h3>
<h4 id="knn">KNN</h4>
<p>k近邻算法简称<strong>kNN（k-Nearest
Neighbor）</strong>，是一种经典的监督学习方法，是数据挖掘十大算法之一。其工作机制十分简单：给定某个测试样本，kNN基于某种<strong>距离度量</strong>在训练集中找出与其距离最近的k个带有真实标记的训练样本，然后基于这k个邻居的真实标记来进行预测，类似于集成学习中的基学习器结合策略：分类任务采用投票法，回归任务则采用平均法。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607150256290.png" alt="image-20250607150256290">
<figcaption aria-hidden="true">image-20250607150256290</figcaption>
</figure>
<p><strong>核心思想</strong></p>
<p>1NN 分类器通过将测试样本 $ $ 分配到其最近邻样本 $ $
的类别来完成预测。其错误概率取决于两个关键因素： - <strong>$ $
的真实类别</strong>：$ P(c | ) $，即给定 $ $ 属于类别 $ c $
的概率。<br>
- <strong>$ $ 的类别</strong>：$ P(c | ) $，即 $ $ 属于类别 $ c $
的概率。</p>
<p><strong>错误概率公式</strong></p>
<p>若测试样本 $ $ 的最近邻为 $ $，则 1NN 分类器出错的概率为： <span class="math display"><em>P</em>(err) = 1 − <em>P</em>(correct) = 1 − ∑<sub><em>c</em> ∈ 𝒞</sub><em>P</em>(<em>c</em>|<strong>x</strong>)<em>P</em>(<em>c</em>|<strong>z</strong>)</span>
其中： - $ $ 是所有可能的类别集合。<br>
- $ P(c | ) <span class="math inline">：</span> $ 属于类别 $ c $
的条件概率。<br>
- $ P(c | ) <span class="math inline">：</span> $ 属于类别 $ c $
的条件概率。</p>
<p>通过证明可以发现一个令人震惊的结论：<strong>最近邻分类器的错误率不超过贝叶斯最优分类器错误率的两倍</strong>。</p>
<p>对于距离度量，<strong>不同的度量方法得到的k个近邻不尽相同，从而对最终的投票结果产生了影响</strong>，因此选择一个合适的距离度量方法也十分重要。</p>
<p>在上一篇聚类算法中，在度量样本相似性时介绍了常用的几种距离计算方法，包括<strong>闵可夫斯基距离，曼哈顿距离，VDM</strong>等。在实际应用中，<strong>kNN的距离度量函数一般根据样本的特性来选择合适的距离度量，同时应对数据进行去量纲/归一化处理来消除大量纲属性的强权政治影响</strong>。</p>
<h4 id="低维嵌入">低维嵌入</h4>
<p><strong>使用knn的前提是样本空间的密度要一定大，但是这个条件在现实中很难满足，因此引出降维操作</strong></p>
<blockquote>
<p>kNN的重要假设: 任意测试样本 附近任意小的
距离范围内总能找到一个训练样本，即训练样本的采样密度足够大，或称为
<strong>“密采样”( dense sample)</strong>
。然而，这个假设在现实任务中通常很难满足</p>
</blockquote>
<p>样本的<strong>特征数</strong>也称为<strong>维数</strong>（dimensionality），当维数非常大时，也就是通常所说的“<strong>维数灾难</strong>”(curse
of
dimensionality)，具体表现在：在高维情形下，<strong>数据样本变得十分稀疏</strong>，因为此时要满足训练样本为“<strong>密采样</strong>”的总体样本数目是一个触不可及的天文数字。<strong>训练样本的稀疏使得其代表总体分布的能力大大减弱，从而消减了学习器的泛化能力</strong>；同时当维数很高时，<strong>计算距离也变得十分复杂</strong>，甚至连计算内积都不再容易</p>
<p>缓解维数灾难的一个重要途径就是<strong>降维（dimension
reduction），即通过某种数学变换将原始高维空间转变到一个低维的子空间</strong>。在这个子空间中，样本的密度将大幅提高，同时距离计算也变得容易。这</p>
<p>时也许会有疑问，降维之后不是会丢失原始数据的一部分信息吗？</p>
<p>实际上，在很多实际问题中，虽然训练数据是高维的，但是与学习任务相关也许仅仅是其中的一个低维子空间，也称为一个<strong>低维嵌入</strong>，例如：数据属性中存在噪声属性、相似属性或冗余属性等，<strong>对高维数据进行降维能在一定程度上达到提炼低维优质属性或降噪的效果</strong>。</p>
<h4 id="mds算法"><strong>MDS算法</strong></h4>
<p>MDS（Multidimensional
Scaling，多维尺度分析）是一种经典的<strong>降维技术</strong>，其核心目标是将高维数据映射到低维空间（如二维或三维），同时<strong>尽可能保留原始数据中样本点之间的距离关系</strong>。以下是其核心原理与应用要点：</p>
<p><strong>1. 核心思想</strong></p>
<ul>
<li><strong>输入</strong>：一个样本点之间的距离矩阵 $ D
$（如欧氏距离、余弦距离等）。<br>
</li>
<li><strong>输出</strong>：低维空间中样本点的坐标矩阵 $ Z
$，使得低维空间中的距离与原始距离尽可能一致 。<br>
</li>
<li><strong>关键假设</strong>：高维数据的内在结构可通过样本间的距离关系描述，降维后需最小化这种关系的失真。</li>
</ul>
<p><strong>2. 算法步骤</strong></p>
<p>MDS 的核心是通过<strong>矩阵分解</strong>从距离矩阵推导低维坐标： 1.
<strong>构建距离矩阵 $ D $</strong>：<br>
对于 $ r $ 个样本，计算两两之间的距离，形成 $ r r $ 的矩阵 $ D $，其中 $
D_{ij} $ 表示样本 $ i $ 和 $ j $ 的距离 。</p>
<ol start="2" type="1">
<li><p><strong>双中心化（Double Centering）</strong>：<br>
构造矩阵 $ B = - H D^{(2)} H $，其中 $ D^{(2)} $ 是距离的平方矩阵，$ H =
I - ^$ 是中心化矩阵 。</p></li>
<li><p><strong>特征值分解</strong>：<br>
对 $ B $ 进行特征值分解，得到 $ B = V V^$，其中 $ $
是按降序排列的特征值对角矩阵，$ V $ 是对应的特征向量矩阵 。</p></li>
<li><p><strong>构造低维坐标</strong>：<br>
选择前 $ d’ $ 个最大特征值（$ d’ $
为目标维度）和对应的特征向量，计算低维坐标矩阵：<br>
<span class="math display"><em>Z</em> = <em>Λ</em><sup>1/2</sup><em>V</em><sup>⊤</sup></span>
其中 $ ^{1/2} $ 是特征值矩阵的平方根 。</p></li>
</ol>
<p><strong>3. 关键特性</strong></p>
<ul>
<li><strong>保留距离关系</strong>：MDS
直接优化低维空间中的距离与原始距离的一致性，适用于需精确保留样本相似性的场景（如生物信息学中的基因关系分析）。<br>
</li>
<li><strong>非线性适应性</strong>：与 PCA 不同，MDS
不要求数据线性分布，更适合处理非线性结构（如环形、流形数据）。<br>
</li>
<li><strong>灵活性</strong>：支持任意距离度量（如自定义的相似性指标），而
PCA 仅适用于欧氏距离 。</li>
</ul>
<h4 id="线性降维方法"><strong>线性降维方法</strong></h4>
<p>线性降维通过<strong>线性变换</strong>将高维数据 $ ^{d m} $
投影到低维空间 $ ^{d’ m} <span class="math inline">（</span> d’ d
$），保留数据的主要信息。其数学表达为： <span class="math display"><strong>Z</strong> = <strong>W</strong><sup>⊤</sup><strong>X</strong></span></p>
<ul>
<li><p><strong>变换矩阵 $ ^{d d’} $</strong>：<br>
每一列是正交的基向量，构成低维子空间的坐标系。<br>
</p></li>
<li><p><strong>目标</strong>：选择 $ $ 使得低维表示 $ $
最大化保留原始数据的信息（如方差、距离等）。</p></li>
<li><p><strong>MDS</strong>：<br>
直接以<strong>保留高维空间中样本点之间的距离关系</strong>为目标。降维后的低维空间需尽可能保持原始样本两两之间的距离（如欧氏距离、自定义相似性距离）。</p>
<ul>
<li><strong>示例</strong>：在基因数据分析中，MDS可确保基因表达相似的样本在低维空间中仍紧密分布。</li>
</ul></li>
<li><p><strong>其他线性方法（如PCA、LDA）</strong>：</p>
<ul>
<li><strong>PCA</strong>：最大化数据在低维空间的方差，强调保留全局结构而非具体距离。<br>
</li>
<li><strong>LDA</strong>：在监督学习中最大化类间分离度，忽略类内距离。</li>
</ul></li>
</ul>
<h4 id="主成分分析">主成分分析</h4>
<p>不同于MDS采用距离保持的方法，主成分分析（Principal Component Analysis
,PCA）是一种经典的<strong>无监督降维算法</strong>
，其核心目标是通过线性变换将高维数据映射到低维空间，同时保留数据的<strong>最大方差信息</strong>
（即信息损失最小）</p>
<p>直接通过一个<strong>线性变换</strong>，将原始空间中的样本<strong>投影</strong>到新的低维空间中。</p>
<p>简单来理解这一过程便是：<strong>PCA采用一组新的基（向量）来表示样本点，其中每一个基向量都是原始空间基向量的线性组合，通过使用尽可能少的新基向量来表出样本，从而达到降维的目的。</strong></p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607155733314.png" alt="image-20250607155733314">
<figcaption aria-hidden="true">image-20250607155733314</figcaption>
</figure>
<p>假设使用d’个新基向量来表示原来样本，实质上是将样本投影到一个由d’个基向量确定的一个<strong>超平面</strong>上（<strong>即舍弃了一些维度</strong>），要用一个超平面对空间中所有高维样本进行恰当的表达，最理想的情形是：<strong>若这些样本点都能在超平面上表出且这些表出在超平面上都能够很好地分散开来</strong>。但是一般使用较原空间低一些维度的超平面来做到这两点十分不容易，因此我们退一步海阔天空，要求这个超平面应具有如下两个性质：</p>
<blockquote>
<p><strong>最近重构性</strong>：样本点到超平面的距离足够近，即尽可能在超平面附近；</p>
<p><strong>最大可分性</strong>：样本点在超平面上的投影尽可能地分散开来，即投影后的坐标具有区分性。</p>
</blockquote>
<p>这里十分神奇的是：<strong>最近重构性与最大可分性虽然从不同的出发点来定义优化问题中的目标函数，但最终这两种特性得到了完全相同的优化问题</strong>：</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607165159235.png" alt="image-20250607165159235">
<figcaption aria-hidden="true">image-20250607165159235</figcaption>
</figure>
<h5 id="协方差矩阵与优化求解"><strong>协方差矩阵与优化求解</strong></h5>
<p>若数据已<strong>中心化</strong>（均值为零），则 $ ^$
是<strong>样本协方差矩阵</strong>的 $ m $
倍。此时，PCA的优化问题转化为： <span class="math display">$$
\begin{aligned}
&amp; \underset{\mathbf{W}}{\text{maximize}}
&amp; &amp; \text{tr}\left( \mathbf{W}^\top \mathbf{X} \mathbf{X}^\top
\mathbf{W} \right) \\
&amp; \text{subject to}
&amp; &amp; \mathbf{W}^\top \mathbf{W} = \mathbf{I}
\end{aligned}
$$</span> 通过拉格朗日乘数法，该问题的解为 $ ^$ 的前 $ d’ $
个最大特征值对应的特征向量</p>
<h5 id="pca的数学推导"><strong>PCA的数学推导</strong></h5>
<ul>
<li><p><strong>优化目标</strong>：<br>
<span class="math display">max<sub><strong>W</strong></sub>  tr(<strong>W</strong><sup>⊤</sup><strong>X</strong><strong>X</strong><sup>⊤</sup><strong>W</strong>)  s.t.  <strong>W</strong><sup>⊤</sup><strong>W</strong> = <strong>I</strong></span>
其中，$ ^{d m} $ 是中心化后的数据矩阵（均值为零）。</p></li>
<li><p><strong>拉格朗日乘数法</strong>：<br>
引入拉格朗日乘子 $ $，构造拉格朗日函数： <span class="math display">ℒ(<strong>W</strong>,<em>Λ</em>) = tr(<strong>W</strong><sup>⊤</sup><strong>X</strong><strong>X</strong><sup>⊤</sup><strong>W</strong>) − tr(<em>Λ</em>(<strong>W</strong><sup>⊤</sup><strong>W</strong>−<strong>I</strong>))</span>
对 $ $ 求导并令导数为零，得到： <span class="math display"><strong>X</strong><strong>X</strong><sup>⊤</sup><strong>W</strong> = <em>Λ</em><strong>W</strong></span>
即 $ ^$ 的特征向量 $ _i $ 满足： <span class="math display"><strong>X</strong><strong>X</strong><sup>⊤</sup><strong>w</strong><sub><em>i</em></sub> = <em>λ</em><sub><em>i</em></sub><strong>w</strong><sub><em>i</em></sub></span></p></li>
</ul>
<h5 id="pca特征向量选择">PCA特征向量选择</h5>
<p><strong>1. 核心问题</strong></p>
<p>在PCA中，我们希望找到一个 $ d’ d $ 的变换矩阵 $
$，其列向量是协方差矩阵 $ ^$ 的特征向量，且满足正交约束 $ ^ =
$。关键问题是：<strong>如何从 $ d $ 个特征向量中选择 $ d’ $
个最优的？</strong></p>
<p><strong>2. 数学推导</strong></p>
<ol type="1">
<li><p><strong>特征值分解</strong>：<br>
协方差矩阵 $ <sup></sup>{d d} $ 可分解为： <span class="math display"><strong>X</strong><strong>X</strong><sup>⊤</sup><strong>W</strong> = <strong>W</strong><strong>Λ</strong></span>
其中，$ = (_1, _2, , _d) $ 是特征值对角矩阵，$ $
是特征向量矩阵。</p></li>
<li><p><strong>优化目标转化</strong>：<br>
PCA的目标是最大化 $ (^ ^) $。利用特征值分解，可得： <span class="math display"><strong>W</strong><sup>⊤</sup><strong>X</strong><strong>X</strong><sup>⊤</sup><strong>W</strong> = <strong>W</strong><sup>⊤</sup>(<strong>W</strong><strong>Λ</strong>) = <strong>Λ</strong></span>
因此，优化目标变为： <span class="math display">$$
\max_{\mathbf{W}} \quad \text{tr}(\boldsymbol{\Lambda}) =
\sum_{i=1}^{d'} \lambda_i
$$</span> 即选择 $ d’ $ 个最大的特征值 $ _i $ 对应的特征向量组成 $
$。</p></li>
</ol>
<p><strong>3. 特征向量选择策略</strong></p>
<ul>
<li><strong>按特征值排序</strong>：<br>
特征值 $ _i $ 表示数据沿特征向量 $ _i $ 方向的方差。选择前 $ d’ $
个最大特征值对应的特征向量，可保留最多信息。<br>
</li>
<li><strong>正交性保证</strong>：<br>
特征向量矩阵 $ $ 的列自动满足 $ ^ = $，无需额外正交化。</li>
</ul>
<h5 id="pca算法的整个流程如下图所示">PCA算法的整个流程如下图所示：</h5>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607170020467.png" alt="image-20250607170020467">
<figcaption aria-hidden="true">image-20250607170020467</figcaption>
</figure>
<h4 id="核化线性降维"><strong>核化线性降维</strong></h4>
<p>待学习</p>
<h4 id="流形学习">流形学习</h4>
<p><strong>流形学习（manifold
learning）</strong>是一种借助拓扑流形概念的降维方法，流形是指在<strong>局部与欧式空间同胚的空间</strong>，即在局部与欧式空间具有相同的性质，能用欧氏距离计算样本之间的距离。这样即使高维空间的分布十分复杂，但是在局部上依然满足欧式空间的性质，基于流形学习的降维正是这种
<strong>“邻域保持”</strong> 的思想。其中
<strong>等度量映射（Isomap）试图在降维前后保持邻域内样本之间的距离，而局部线性嵌入（LLE）则是保持邻域内样本之间的线性关系</strong>
。</p>
<h5 id="等度量映射isomap">等度量映射Isomap</h5>
<p>等度量映射的基本出发点是：高维空间中的直线距离具有误导性，因为有时高维空间中的直线距离在低维空间中是不可达的。<strong>因此利用流形在局部上与欧式空间同胚的性质，可以使用近邻距离来逼近测地线距离</strong>，即对于一个样本点，它与近邻内的样本点之间是可达的，且距离使用欧式距离计算，这样整个样本空间就形成了一张近邻图，高维空间中两个样本之间的距离就转为最短路径问题。可采用著名的<strong>Dijkstra算法</strong>或<strong>Floyd算法</strong>计算最短距离，得到高维空间中任意两点之间的距离后便可以使用
MDS 算法来其计算低维空间中的坐标。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171119645.png" alt="image-20250607171119645">
<figcaption aria-hidden="true">image-20250607171119645</figcaption>
</figure>
<p>Isomap算法流程如下图：</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171258284.png" alt="image-20250607171258284">
<figcaption aria-hidden="true">image-20250607171258284</figcaption>
</figure>
<p>对于近邻图的构建，常用的有两种方法：<strong>一种是指定近邻点个数</strong>，像kNN一样选取k个最近的邻居；<strong>另一种是指定邻域半径</strong>，距离小于该阈值的被认为是它的近邻点。但两种方法均会出现下面的问题：</p>
<blockquote>
<p>若<strong>邻域范围指定过大，则会造成“短路问题”</strong>，即本身距离很远却成了近邻，将距离近的那些样本扼杀在摇篮。</p>
<p>若<strong>邻域范围指定过小，则会造成“断路问题”</strong>，即有些样本点无法可达了，整个世界村被划分为互不可达的小部落。</p>
</blockquote>
<h5 id="局部线性嵌入">局部线性嵌入</h5>
<p>待学习</p>
<h4 id="度量学习">度量学习</h4>
<p><strong>1. 核心思想</strong></p>
<p>度量学习（Metric
Learning）的核心目标是<strong>学习一个合理的距离度量</strong>，使得相似样本距离更近，不相似样本距离更远。传统欧式距离（Euclidean
Distance）虽然简单，但其固定权重无法反映不同特征的实际重要性。因此，我们引入<strong>加权欧式距离</strong>，通过可调节的参数（权重）优化距离计算。</p>
<p><strong>2. 欧式距离与加权欧式距离</strong></p>
<ul>
<li><p><strong>标准欧式距离</strong>：<br>
<span class="math display">$$
\text{dist}_{\text{ed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) =
\|\boldsymbol{x}_i - \boldsymbol{x}_j\|_2^2 = \sum_{k=1}^d
(\boldsymbol{x}_{i,k} - \boldsymbol{x}_{j,k})^2
$$</span>
每个特征维度对距离的贡献相同，未考虑特征的重要性差异。</p></li>
<li><p><strong>加权欧式距离</strong>：<br>
<span class="math display">dist<sub>wed</sub><sup>2</sup>(<strong>x</strong><sub><em>i</em></sub>,<strong>x</strong><sub><em>j</em></sub>) = (<strong>x</strong><sub><em>i</em></sub>−<strong>x</strong><sub><em>j</em></sub>)<sup>⊤</sup><strong>W</strong>(<strong>x</strong><sub><em>i</em></sub>−<strong>x</strong><sub><em>j</em></sub>)</span>
其中，$ = () $ 是对角权重矩阵，$ w_k $ 表示第 $ k $ 个特征的权重。<br>
展开后为： <span class="math display">$$
\text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) =
\sum_{k=1}^d w_k (\boldsymbol{x}_{i,k} - \boldsymbol{x}_{j,k})^2
$$</span></p></li>
</ul>
<p><strong>3. 权重的作用</strong></p>
<ul>
<li><strong>特征重要性调节</strong>：
<ul>
<li>高权重 $ w_k $：强调第 $ k $
维特征对距离的影响（如图像的颜色通道比位置更重要）。<br>
</li>
<li>低权重 $ w_k $：弱化噪声或冗余特征的影响。<br>
</li>
</ul></li>
<li><strong>几何意义</strong>：<br>
加权欧式距离相当于在各特征维度上进行缩放，将数据映射到一个新的空间，使得关键特征的差异更显著。</li>
</ul>
<p><strong>4. 度量学习的目标</strong></p>
<p>通过学习最优权重 $ <span class="math inline">，<em>使</em><em>以</em><em>下</em><em>目</em><em>标</em><em>成</em><em>立</em>： −  *  * <em>相</em><em>似</em><em>样</em><em>本</em> *  * ：<em>加</em><em>权</em><em>距</em><em>离</em><em>小</em>（</span>
_{}^2(_i, <em>j) <span class="math inline">）。 −  *  * <em>不</em><em>相</em><em>似</em><em>样</em><em>本</em> *  * ：<em>加</em><em>权</em><em>距</em><em>离</em><em>大</em>（</span>
</em>{}^2(_i, _j) $）。</p>
<p>典型优化问题形式： <span class="math display">min<sub><strong>w</strong></sub>  ∑<sub>(<strong>x</strong><sub><em>i</em></sub>,<strong>x</strong><sub><em>j</em></sub>) ∈ <em>S</em></sub>dist<sub>wed</sub><sup>2</sup>(<strong>x</strong><sub><em>i</em></sub>,<strong>x</strong><sub><em>j</em></sub>) + <em>λ</em>∥<strong>w</strong>∥<sub>2</sub><sup>2</sup></span>
其中，$ S $ 是相似样本对集合，$ $ 是正则化项防止过拟合。</p>
<blockquote>
<p>总结来说，</p>
<ul>
<li><strong>降维是将原高维空间嵌入到一个合适的低维子空间中，接着在低维空间中进行学习任务</strong></li>
<li><strong>度量学习则是试图去学习出一个 *距离度量*
来等效降维的效果</strong></li>
</ul>
</blockquote>
<h5 id="lmnnlarge-margin-nearest-neighbors详解"><strong>LMNN（Large
Margin Nearest Neighbors）详解</strong></h5>
<p><strong>1. 核心思想</strong></p>
<p>LMNN
是一种<strong>监督度量学习方法</strong>，其目标是通过学习一个线性变换矩阵
$
$，使<strong>同类样本在变换后的空间中更紧密</strong>，<strong>不同类样本被推开</strong>，从而提升KNN等基于距离的算法性能。其核心是引入<strong>最大边距（Large
Margin）</strong>的概念，类似于SVM的分类边界。</p>
<p><strong>2. 损失函数</strong></p>
<p>LMNN 的优化目标由两部分组成： - <strong>Pull
Loss（拉力损失）</strong>：<br>
使同类样本对的距离尽可能小，公式为： <span class="math display">$$
  \varepsilon_{\text{pull}}(\mathbf{L}) = \sum_{j \sim i}
\|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2
  $$</span> 其中，$ j i $ 表示与样本 $ i $ 同类的最近邻样本。</p>
<ul>
<li><p><strong>Push Loss（推力损失）</strong>：<br>
使不同类样本对的距离至少保持一个固定边距 $ <em>{ijl} $，公式为： <span class="math display">$$
\varepsilon_{\text{push}}(\mathbf{L}) = \sum_{i,j,l} (1 - y_{il})
\left[1 + \|\mathbf{L}(\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_j)\|^2 - \|\mathbf{L}(\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_l)\|^2\right]_+
$$</span> 其中，$ y</em>{il} = 1 $ 表示样本 $ i $ 和 $ l $
属于同一类，否则为0；$ []_+ $ 表示取正值部分。</p></li>
<li><p><strong>总损失函数</strong>：<br>
<span class="math display"><em>ε</em>(<strong>L</strong>) = (1−<em>μ</em>)<em>ε</em><sub>pull</sub>(<strong>L</strong>) + <em>μ</em><em>ε</em><sub>push</sub>(<strong>L</strong>)</span>
参数 $ $ 控制两类损失的权重。</p></li>
</ul>
<p><strong>3. 优化问题</strong></p>
<p>LMNN 的目标是最小化总损失函数，同时满足以下约束： <span class="math display">$$
\begin{aligned}
&amp; \min_{\mathbf{M}, \boldsymbol{\xi}} \quad (1 - \mu) \sum_{i,j \sim
i} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)^\top \mathbf{M}
(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j) + \mu \sum_{i,j \sim
i,l} (1 - y_{il}) \xi_{ijl} \\
&amp; \text{s.t.} \quad (\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_l)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_l) - (\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_j)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_j) \geq 1 - \xi_{ijl}, \\
&amp; \quad \quad \quad \xi_{ijl} \geq 0, \quad \mathbf{M} \succeq 0.
\end{aligned}
$$</span> -
<strong>约束（1）</strong>：确保不同类样本对的距离比同类样本对大至少 $ 1
- <em>{ijl} $。<br>
- <strong>约束（2）</strong>：松弛变量 $ </em>{ijl} $
允许部分样本对违反约束。<br>
- <strong>约束（3）</strong>：$ $
必须是半正定矩阵，保证距离的非负性和三角不等式。</p>
<h4 id="作业-3">作业</h4>
<h5 id="section-8">1</h5>
<p>数据降维有哪些常用的方法？阐述主成分分析（PCA）算法的计算流程，并讨论PCA
降维之后的维度如何确定？</p>
<p><strong>（1）常用数据降维方法</strong></p>
<ol type="1">
<li><strong>主成分分析（PCA）</strong>：通过线性变换保留最大方差方向，适用于去噪和压缩数据
。<br>
</li>
<li><strong>线性判别分析（LDA）</strong>：在监督学习中最大化类间分离度，适用于分类任务
。</li>
</ol>
<p><strong>（2）主成分分析（PCA）的计算流程</strong></p>
<ol type="1">
<li><strong>数据标准化</strong>：对原始数据去均值、方差归一化，消除量纲影响
。<br>
</li>
<li><strong>计算协方差矩阵</strong>：<br>
<span class="math display">$$
\mathbf{\Sigma} = \frac{1}{m} \mathbf{X} \mathbf{X}^\top
$$</span> 其中 $ $ 是中心化后的数据矩阵 。<br>
</li>
<li><strong>特征值分解</strong>：对协方差矩阵进行特征值分解，得到特征值
$ _i $ 和单位正交特征向量 $ _i $ 。<br>
</li>
<li><strong>选择主成分</strong>：按特征值大小排序，选择前 $ d’ $
个最大特征值对应的特征向量构成变换矩阵 $ = [_1, <em>2, , </em>{d’}]
$。<br>
</li>
<li><strong>降维投影</strong>：计算低维表示 $ = ^ $，其中 $ ^{d’ m} $
。</li>
</ol>
<p><strong>（3）PCA降维后维度的确定</strong></p>
<ul>
<li><strong>累积方差贡献率</strong>：选择前 $ d’ $
个主成分，使累计方差占比达到阈值（如95%）。<br>
</li>
<li><strong>肘部法则（Elbow
Method）</strong>：绘制特征值随维度变化的曲线，选择“拐点”作为 $ d’
$。</li>
</ul>
<h5 id="section-9">2</h5>
<p>度量学习的目标是什么？LMNN算法中三元组损失是什么？如何计算？</p>
<p><strong>（1）度量学习的目标</strong></p>
<p>度量学习旨在学习一个合理的距离度量，使得： -
<strong>相似样本</strong>：距离尽可能小（如同类样本）。<br>
- <strong>不相似样本</strong>：距离尽可能大（如异类样本）。<br>
典型应用包括推荐系统（优化用户-商品相似性）、图像检索（提升匹配精度）和生物识别（增强类间可分性）。</p>
<p><strong>（2）LMNN中的三元组损失</strong></p>
<p>LMNN（Large Margin Nearest
Neighbor）是一种监督度量学习方法，其核心思想是通过优化距离度量来提升KNN的分类性能。虽然LMNN本身主要使用对比损失（Contrastive
Loss），但三元组损失（Triplet
Loss）是深度度量学习中常见的损失函数，其计算方式如下：<strong>三元组损失的定义</strong></p>
<p>三元组损失基于锚点（Anchor）、正例（Positive）和负例（Negative）三个样本，目标是使锚点与正例的距离小于锚点与负例的距离，公式为：
<span class="math display">ℒ = ∑<sub><em>i</em>, <em>j</em>, <em>l</em></sub>max (0,∥<strong>z</strong><sub><em>i</em></sub>−<strong>z</strong><sub><em>j</em></sub>∥<sup>2</sup>−∥<strong>z</strong><sub><em>i</em></sub>−<strong>z</strong><sub><em>l</em></sub>∥<sup>2</sup>+<em>m</em>)</span>
- $ _i $：锚点样本的嵌入表示。<br>
- $ _j $：与锚点同类的正例样本。<br>
- $ _l $：与锚点不同类的负例样本。<br>
- $ m $：预设的边界值（Margin），控制正负样本距离的最小差距 。</p>
<p><strong>LMNN的损失函数</strong></p>
<p>LMNN 的损失函数包含两部分： 1. <strong>拉力损失（Pull
Loss）</strong>：最小化同类样本对的距离：<br>
<span class="math display">$$
   \varepsilon_{\text{pull}} = \sum_{i,j \sim i}
\|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2
   $$</span> 2. <strong>推力损失（Push
Loss）</strong>：最大化异类样本对的距离：<br>
<span class="math display">$$
   \varepsilon_{\text{push}} = \sum_{i,j \sim i,l} (1 - y_{il}) \left[1
+ \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2 -
\|\mathbf{L}(\bar{\boldsymbol{x}}_i -
\bar{\boldsymbol{x}}_l)\|^2\right]_+
   $$</span> 其中 $ $ 是线性变换矩阵，$ y_{il} $ 表示样本对是否同类，$
[]_+ $ 表示取正值部分 。</p>
<p><strong>优化目标</strong></p>
<p>LMNN 的总损失为拉力和推力损失的加权和： <span class="math display"><em>ε</em>(<strong>L</strong>) = (1−<em>μ</em>)<em>ε</em><sub>pull</sub> + <em>μ</em><em>ε</em><sub>push</sub></span>
参数 $ $ 平衡两类损失的权重，最终通过优化 $ $ 得到最优距离度量 。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607175825520.png" alt="image-20250607175825520">
<figcaption aria-hidden="true">image-20250607175825520</figcaption>
</figure>
<h3 id="半监督学习">半监督学习</h3>
<p>监督学习解决现实问题有哪些难点?
1.标记数据获取成本高：在许多领域如医疗，获取标记数据是昂贵且耗时的。
2.未标记数据大量存在且易得：相对而言，未标记数据大量存在且容易获取。
3.提升模型的泛化能力：通过利用未标记数据，可以增强模型的泛化能力。
举例：在医疗领域，获取医生标记的诊断数据非常昂贵，但有大量未标记的病人记录。
半监督学习可以帮助利用这些未标记数据，提高疾病预测模型的准确性。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607181345721.png" alt="image-20250607181345721">半监督学习结合了有监督学习和无监督学习，半监督学习使用<strong>少量的标记数据</strong>和<strong>大量的未标记数据</strong>来训练模型，主要目标是提升模型在未标记数据上的表现。</p>
<h5 id="基于生成模型的方法">基于生成模型的方法</h5>
<p>假设所有数据（无论是否有标记）都是由一个<strong>潜在的模型</strong>“生成”的。那么无标记的数据可以帮助更准确的估计潜在模型的参数。
比如右图中可以看到数据可以由两个高斯分布近似，则无监督的数据可以被用来更好得做高斯分布的参数估计</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183201926.png" alt="image-20250607183201926">
<figcaption aria-hidden="true">image-20250607183201926</figcaption>
</figure>
<h5 id="半监督svm"><strong>半监督SVM</strong></h5>
<p>监督学习中的SVM试图找到一个划分超平面，使得两侧支持向量之间的间隔最大，即
<strong>最大划分间隔</strong> 思想。对于半监督SVM (Semi-Supervised
Support Vector Machine, S3VM)
则考虑超平面在能将两类标记样本分隔的同时，<strong>穿过数据低密度的区域</strong>。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183349866.png" alt="image-20250607183349866">
<figcaption aria-hidden="true">image-20250607183349866</figcaption>
</figure>
<h6 id="tsvmtransductive-support-vector-machine">TSVM(Transductive
Support Vector Machine)</h6>
<p><strong>1. 核心思想</strong></p>
<p>TSVM 是一种<strong>半监督学习方法</strong>，通过结合有标记数据 $ D_l
$ 和未标记数据 $ D_u
$，利用伪标签（Pseudo-labels）和迭代优化策略，最大化分类超平面的间隔。其损失函数需同时考虑：
- <strong>有标记样本</strong>：最小化分类错误（Hinge Loss）。<br>
- <strong>未标记样本</strong>：通过伪标签引入约束，逐步调整超平面。</p>
<p><strong>2. 损失函数推导</strong></p>
<p>TSVM 的目标是找到一个超平面 $ ^ + b = 0 $，使得： 1.
<strong>有标记样本</strong>的分类误差最小。<br>
2. <strong>未标记样本</strong>的伪标签与超平面预测结果一致。</p>
<p><strong>标准SVM的损失函数</strong>为： <span class="math display">$$
\min_{\boldsymbol{w}, b, \xi} \quad \frac{1}{2} \|\boldsymbol{w}\|^2 + C
\sum_{i=1}^l \xi_i
$$</span> 其中，$ _i $ 是松弛变量，表示样本 $ (_i, y_i) $
的分类误差。</p>
<p><strong>TSVM的扩展</strong>：<br>
引入未标记样本 $ D_u $ 的伪标签 $ _j <span class="math inline">（</span>
j = l+1, , l+u $），并赋予其较小的惩罚系数 $ C_u $（初始阶段 $ C_u C_l
$）： <span class="math display">$$
\min_{\boldsymbol{w}, b, \xi} \quad \frac{1}{2} \|\boldsymbol{w}\|^2 +
C_l \sum_{i=1}^l \xi_i + C_u \sum_{j=l+1}^{l+u} \xi_j
$$</span> 其中： - $ C_l $：有标记样本的惩罚系数。<br>
- $ C_u
$：未标记样本的惩罚系数，初始值很小，逐步增大以增强伪标签的影响。</p>
<p><strong>3. 迭代优化流程</strong></p>
<ol type="1">
<li><strong>初始化</strong>：
<ul>
<li>用有标记数据 $ D_l $ 训练初始 SVM，得到 $ _0, b_0 $。<br>
</li>
<li>对未标记数据 $ D_u $ 预测伪标签 $ _j = (_0^_j + b_0) $。</li>
</ul></li>
<li><strong>伪标签调整</strong>：
<ul>
<li>若存在冲突（如 $ _i _j &lt; 0 $ 且 $ _i + _j &gt; 2
$），翻转其中一个伪标签（如 $ _i -_i $）。<br>
</li>
<li>重新求解优化问题，更新 $ , b $。</li>
</ul></li>
<li><strong>参数调整</strong>：
<ul>
<li>逐步增大 $ C_u $（如 $ C_u {2C_u, C_l}
$），增强未标记样本的影响。</li>
</ul></li>
</ol>
<p><strong>4. 关键数学细节</strong></p>
<ul>
<li><p><strong>Hinge Loss</strong>：<br>
对每个样本 $ (_i, y_i) $，损失为： <span class="math display"><em>ξ</em><sub><em>i</em></sub> = max (0,1−<em>y</em><sub><em>i</em></sub>(<strong>w</strong><sup>⊤</sup><strong>x</strong><sub><em>i</em></sub>+<em>b</em>))</span>
未标记样本的伪标签 $ _j $ 同样代入此公式，但惩罚系数为 $ C_u
$。</p></li>
<li><p><strong>正则化项</strong>：<br>
$ ||^2 $ 确保超平面的泛化能力，防止过拟合。</p></li>
<li><p><strong>伪标签翻转条件</strong>：<br>
当两个未标记样本 $ i, j $ 满足： <span class="math display"><em>ŷ</em><sub><em>i</em></sub><em>ŷ</em><sub><em>j</em></sub> &lt; 0  且  <em>ξ</em><sub><em>i</em></sub> &gt; 0, <em>ξ</em><sub><em>j</em></sub> &gt; 0,  <em>ξ</em><sub><em>i</em></sub> + <em>ξ</em><sub><em>j</em></sub> &gt; 2</span>
表示它们被错误分类且距离超平面较近，需翻转其中一个标签以减少冲突。</p></li>
</ul>
<h5 id="图半监督学习"><strong>图半监督学习</strong></h5>
<p>给定一个数据集，我们可将其映射为一个图，数据集中每个样本对应于图结点，若两个样本之间的相似度很高(或相关性很强)，则对应的结点之间存在一条边，边的“强度”(strength)
正比于样本之间的相似度(或相关性)。</p>
<p>可将有标记样本所对应的结点想象为染过色，标记样本所对应的结点尚未染色。半监督学习就对应于“颜色”在图上扩散或传播的过程。由于个图对应了一个矩阵，我们就能基于矩阵运算来进行半监督学习算法的推导与分析。</p>
<figure>
<img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607184534217.png" alt="image-20250607184534217">
<figcaption aria-hidden="true">image-20250607184534217</figcaption>
</figure>
<p><strong>图半监督学习中的能量函数推导详解</strong></p>
<p><strong>1. 图结构与亲和矩阵</strong></p>
<p>给定有标记数据集 $ D_l = {(<em>1, y_1), (<em>2, y_2), , (<em>l, y_l)}
$ 和未标记数据集 $ D_u = {</em>{l+1}, </em>{l+2}, , </em>{l+u}}
$，构建图 $ G = (V, E) <span class="math inline">： −  *  * <em>结</em><em>点</em><em>集</em> *  * ：</span>
V = {<em>1, , <em>l, </em>{l+1}, , </em>{l+u}} $，包含所有样本。<br>
- <strong>边集</strong>：通过亲和矩阵 $ $ 表示，元素定义为： <span class="math display">$$
  (\mathbf{W})_{ij} =
  \begin{cases}
  \exp\left(-\frac{\|\boldsymbol{x}_i -
\boldsymbol{x}_j\|^2}{2\sigma^2}\right), &amp; i \neq j \\
  0, &amp; \text{otherwise}
  \end{cases}
  $$</span> 其中，$ $ 是高斯核的带宽参数，控制邻接关系的敏感性。</p>
<p><strong>2. 能量函数的定义与推导</strong></p>
<p>假设分类模型的输出标记为 $ f(_i) $（取值为类别标签，如 $
$），定义能量函数 $ E(f) $ 为： <span class="math display">$$
E(f) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij}
(f(\boldsymbol{x}_i) - f(\boldsymbol{x}_j))^2
$$</span> 其中 $ m = l + u $ 是总样本数。</p>
<p><strong>3. 能量函数的展开与简化</strong></p>
<ol type="1">
<li><strong>展开平方项</strong> <span class="math display">$$
E(f) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} \left[
f^2(\boldsymbol{x}_i) - 2 f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) +
f^2(\boldsymbol{x}_j) \right]
$$</span></li>
<li><strong>利用对称性简化</strong> 由于 $ $ 是对称矩阵（<span class="math inline">(<strong>W</strong>)<sub><em>i</em><em>j</em></sub> = (<strong>W</strong>)<sub><em>j</em><em>i</em></sub></span>），可交换求和顺序：
<span class="math display">$$
\sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_j) =
\sum_{j=1}^m \sum_{i=1}^m (\mathbf{W})_{ji} f^2(\boldsymbol{x}_j) =
\sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_i)
$$</span> 因此，能量函数变为 <span class="math display">$$
E(f) = \frac{1}{2} \left( 2 \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij}
f^2(\boldsymbol{x}_i) - 2 \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij}
f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) \right)
$$</span></li>
<li><strong>引入度矩阵</strong> 定义度矩阵 $ $
为对角矩阵，其对角线元素为： <span class="math display">$$
d_i = \sum_{j=1}^m (\mathbf{W})_{ij}
$$</span> 最终能量函数可表示为： <span class="math display">$$
E(f) = \sum_{i=1}^m d_i f^2(\boldsymbol{x}_i) - \sum_{i=1}^m
\sum_{j=1}^m (\mathbf{W})_{ij} f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) =
\boldsymbol{f}^\top (\mathbf{D} - \mathbf{W}) \boldsymbol{f}
$$</span> 其中，$ = [f(_1), f(_2), , f(_m)]^$。</li>
</ol>
<p><strong>图半监督学习方法推导详解</strong></p>
<p><strong>1. 分块矩阵表示</strong></p>
<p>将亲和矩阵 $ $ 和度矩阵 $ $ 按有标记数据（前 $ l $
行列）和未标记数据（后 $ u $ 行列）分块： <span class="math display">$$
\mathbf{W} =
\begin{bmatrix}
\mathbf{W}_{ll} &amp; \mathbf{W}_{lu} \\
\mathbf{W}_{ul} &amp; \mathbf{W}_{uu}
\end{bmatrix}, \quad
\mathbf{D} =
\begin{bmatrix}
\mathbf{D}_{ll} &amp; \mathbf{0}_{lu} \\
\mathbf{0}_{ul} &amp; \mathbf{D}_{uu}
\end{bmatrix}
$$</span> 其中： - $ <em>{ll} $：有标记数据间的亲和度。<br>
- $ </em>{lu} $：有标记与未标记数据间的亲和度。<br>
- $ <em>{uu} $：未标记数据间的亲和度。<br>
- $ </em>{ll}, _{uu} $：对应子图的度矩阵。</p>
<p><strong>2. 能量函数的分块展开</strong></p>
<p>能量函数 $ E(f) = ^( - ) $ 可展开为</p>
<p>展开后得到： <span class="math display"><em>E</em>(<em>f</em>) = <strong>f</strong><sub><em>l</em></sub><sup>⊤</sup>(<strong>D</strong><sub><em>l</em><em>l</em></sub>−<strong>W</strong><sub><em>l</em><em>l</em></sub>)<strong>f</strong><sub><em>l</em></sub> − 2<strong>f</strong><sub><em>u</em></sub><sup>⊤</sup><strong>W</strong><sub><em>u</em><em>l</em></sub><strong>f</strong><sub><em>l</em></sub> + <strong>f</strong><sub><em>u</em></sub><sup>⊤</sup>(<strong>D</strong><sub><em>u</em><em>u</em></sub>−<strong>W</strong><sub><em>u</em><em>u</em></sub>)<strong>f</strong><sub><em>u</em></sub></span></p>
<p>**3. 对未标记数据 $ _u $ 求偏微分**</p>
<p>目标是最小化 $ E(f) $，对 $ _u $ 求偏导并令其为零： <span class="math display">$$
\frac{\partial E(f)}{\partial \boldsymbol{f}_u} = -2 \mathbf{W}_{ul}
\boldsymbol{f}_l + 2 (\mathbf{D}_{uu} - \mathbf{W}_{uu})
\boldsymbol{f}_u = 0
$$</span> 解得： <span class="math display"><strong>f</strong><sub><em>u</em></sub> = (<strong>D</strong><sub><em>u</em><em>u</em></sub>−<strong>W</strong><sub><em>u</em><em>u</em></sub>)<sup>−1</sup><strong>W</strong><sub><em>u</em><em>l</em></sub><strong>f</strong><sub><em>l</em></sub></span></p>
<h4 id="协同训练">协同训练</h4>
<p>协同训练（Co-training）是一种经典的<strong>半监督学习方法</strong>，由Blum和Mitchell于1998年首次提出，主要用于处理<strong>多视图数据</strong>（Multi-view
Data）。其核心思想是通过多个分类器的协作，利用少量标记数据和大量未标记数据提升模型性能。以下是详细解析：</p>
<p><strong>1. 核心思想与假设</strong></p>
<p><strong>（1）多视图数据</strong></p>
<ul>
<li><strong>定义</strong>：每个样本可被划分为多个<strong>充分冗余且条件独立</strong>的视图（View）。
<ul>
<li><strong>充分冗余</strong>：每个视图本身包含足够信息，可独立完成学习任务。<br>
</li>
<li><strong>条件独立性</strong>：在给定类别标签的条件下，不同视图的特征相互独立。<br>
例如，网页数据可划分为“文本内容”和“超链接结构”两个视图，它们共同描述网页内容。</li>
</ul></li>
</ul>
<p><strong>（2）协作机制</strong></p>
<ul>
<li><strong>双分类器设计</strong>：使用两个分类器 $ h_1 $ 和 $ h_2
$，分别基于视图 $ V_1 $ 和 $ V_2 $ 进行训练。<br>
</li>
<li><strong>伪标签生成</strong>：分类器 $ h_1 $
对未标记数据的高置信度预测结果会被 $ h_2 $
使用，反之亦然，形成迭代优化。<br>
</li>
<li><strong>目标</strong>：通过分类器间的互补性，逐步扩展标记数据集，提升模型泛化能力。</li>
</ul>
<p><strong>2. 算法流程</strong></p>
<ol type="1">
<li><strong>初始化阶段</strong>：
<ul>
<li>使用少量标记数据 $ D_l $，分别训练分类器 $ h_1 $（基于视图 $ V_1
$）和 $ h_2 $（基于视图 $ V_2 $）。<br>
</li>
</ul></li>
<li><strong>伪标签生成</strong>：
<ul>
<li>对未标记数据 $ D_u <span class="math inline">，</span> h_1 $
预测视图 $ V_1 $ 的伪标签，$ h_2 $ 预测视图 $ V_2 $ 的伪标签。<br>
</li>
<li>选择置信度高于阈值的样本加入训练集（如 $ h_1 $ 的预测结果用于更新 $
h_2 $ 的训练数据，反之亦然）。<br>
</li>
</ul></li>
<li><strong>迭代优化</strong>：
<ul>
<li>重复伪标签生成和模型训练，直到未标记数据耗尽或模型收敛。</li>
</ul></li>
</ol>
<p><strong>3. 核心优势</strong></p>
<ul>
<li><strong>减少对标注数据的依赖</strong>：仅需少量标记数据即可训练高性能模型，尤其适合标注成本高的场景（如医疗影像分析）。<br>
</li>
<li><strong>提升模型鲁棒性</strong>：分类器间的协作可纠正彼此的错误，降低单一模型过拟合风险。<br>
</li>
<li><strong>多视图互补性</strong>：不同视图的信息融合能捕捉更全面的特征（如图像的RGB通道与纹理特征）。</li>
</ul>
<h4 id="作业-4">作业</h4>
<h5 id="section-10">1</h5>
<p>什么是半监督学习？请简要描述其基本思想。半监督学习相比于监督学习和无监督学习有什么优势和应用场景？</p>
<p><strong>（1）定义与基本思想</strong></p>
<p>半监督学习（Semi-Supervised
Learning）是结合<strong>监督学习</strong>（利用标记数据）和<strong>无监督学习</strong>（利用未标记数据）的机器学习方法，其核心思想是通过少量标记数据与大量未标记数据的联合训练，提升模型的泛化能力和鲁棒性。<br>
-
<strong>监督学习</strong>：依赖大量人工标注数据（如分类、回归）。<br>
-
<strong>无监督学习</strong>：仅利用数据分布规律（如聚类、降维）。<br>
-
<strong>半监督学习</strong>：在标记数据稀缺时，通过未标记数据挖掘潜在结构，降低标注成本
。</p>
<p><strong>（2）优势</strong></p>
<ul>
<li><strong>减少标注依赖</strong>：仅需少量标记数据即可训练高性能模型，适用于标注成本高的场景（如医疗影像分析）。<br>
</li>
<li><strong>提升模型性能</strong>：利用未标记数据增强数据多样性，缓解过拟合风险。<br>
</li>
<li><strong>平衡效率与精度</strong>：在资源有限时，兼顾监督学习的准确性与无监督学习的高效性
。</li>
</ul>
<p><strong>（3）应用场景</strong></p>
<ul>
<li><strong>医学诊断</strong>：利用少量标注的病理图像和大量未标注数据训练疾病预测模型。<br>
</li>
<li><strong>推荐系统</strong>：结合用户行为（有标记）与商品属性（未标记）优化排序模型。<br>
</li>
<li><strong>自然语言处理</strong>：通过预训练模型（如GPT）的“预训练+微调”框架，减少人工标注需求
。</li>
</ul>
<h5 id="section-11">2</h5>
<p>协同训练算法的作用是什么？请简述算法主要流程和所需条件。</p>
<p><strong>（1）作用与核心思想</strong></p>
<p>协同训练是一种典型的半监督学习方法，适用于<strong>多视图数据</strong>（Multi-view
Data）。其核心思想是通过多个分类器的协作，利用未标记数据扩展训练集，最终提升模型性能。</p>
<ul>
<li><strong>多视图条件</strong>：
<ul>
<li><strong>充分冗余</strong>：每个视图本身包含足够信息，可独立完成任务。<br>
</li>
<li><strong>条件独立性</strong>：在给定类别标签的条件下，不同视图的特征相互独立
。</li>
</ul></li>
</ul>
<p><strong>（2）算法流程</strong></p>
<ol type="1">
<li><strong>初始化阶段</strong>：
<ul>
<li>使用少量标记数据 $ D_l $，分别训练两个分类器 $ h_1 $（基于视图 $ V_1
$）和 $ h_2 $（基于视图 $ V_2 $）。<br>
</li>
</ul></li>
<li><strong>伪标签生成</strong>：
<ul>
<li>对未标记数据 $ D_u <span class="math inline">，</span> h_1 $ 预测 $
V_2 $ 的伪标签，$ h_2 $ 预测 $ V_1 $ 的伪标签。<br>
</li>
<li>选择置信度高于阈值的样本加入训练集（如 $ h_1 $ 的预测结果用于更新 $
h_2 $ 的训练数据，反之亦然）。<br>
</li>
</ul></li>
<li><strong>迭代优化</strong>：
<ul>
<li>重复伪标签生成和模型训练，直到未标记数据耗尽或模型收敛 。</li>
</ul></li>
</ol>
<p><strong>（3）所需条件</strong></p>
<ul>
<li><strong>多视图划分</strong>：数据需满足“充分冗余”和“条件独立性”（如图像的RGB通道与纹理特征）。<br>
</li>
<li><strong>分类器多样性</strong>：选择差异较大的分类器（如SVM +
决策树），增强互补性。<br>
</li>
<li><strong>伪标签可靠性</strong>：初始模型需有一定性能，避免错误伪标签污染训练集
。</li>
</ul>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>初识Linux与Ubuntu</title>
    <url>/2025/03/17/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E5%88%9D%E8%AF%86Linux/</url>
    <content><![CDATA[<h3 id="正文">正文</h3>
<p>Linux</p>
<p>ubuntu</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——知识点</title>
    <url>/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h2 id="位运算">位运算</h2>
<p>在这张图片中，表格列出了 <code>x</code> 和 <code>y</code>
的十六进制值，并且要求用 C
语言中的位运算符对它们进行操作。接下来，我将对每个表达式进行详细的计算和解释。</p>
<p>在表格中，要求使用 C 语言中的不同位运算符来计算 <code>x</code> 和
<code>y</code> 之间的结果。位运算符包括：</p>
<ol type="1">
<li><code>&amp;</code>（位与）</li>
<li><code>|</code>（位或）</li>
<li><code>^</code>（位异或）</li>
<li><code>~</code>（位取反）</li>
<li><code>&lt;&lt;</code>（左移）</li>
<li><code>&gt;&gt;</code>（右移）</li>
<li><code>!</code>（逻辑非）</li>
</ol>
<h3 id="计算步骤">计算步骤：</h3>
<ol type="1">
<li><strong>位与运算 <code>x &amp; y</code></strong>： 位与运算会比较
<code>x</code> 和 <code>y</code> 的每一位，只有当对应位都为 1
时，结果才为 1，否则为 0。</li>
<li><strong>位或运算 <code>x | y</code></strong>： 位或运算会比较
<code>x</code> 和 <code>y</code> 的每一位，只要对应位有一个为
1，结果就为 1。</li>
<li><strong>位异或运算 <code>x ^ y</code></strong>： 位异或运算会比较
<code>x</code> 和 <code>y</code> 的每一位，当两者相同时，结果为
0；当两者不同时，结果为 1。</li>
<li><strong>位取反运算 <code>~x</code> 和 <code>~y</code></strong>：
位取反运算会将 <code>x</code> 或 <code>y</code> 的每一位都反转，0 变
1，1 变 0。</li>
<li><strong>左移运算 <code>x &lt;&lt; y</code></strong>： 左移运算会将
<code>x</code> 的二进制位向左移动 <code>y</code> 位，并在右边补 0。</li>
<li><strong>右移运算 <code>x &gt;&gt; y</code></strong>： 右移运算会将
<code>x</code> 的二进制位向右移动 <code>y</code>
位，符号位（对于负数来说是 1）保持不变。</li>
<li><strong>逻辑非运算 <code>!x</code></strong>： 逻辑非运算对
<code>x</code> 进行布尔值判断，如果 <code>x</code> 为 0，则结果为
1，否则为 0。</li>
</ol>
<h2 id="十六进制hexadecimal-h和二进制binary-b之间的直接关系">十六进制（Hexadecimal,
H）和二进制（Binary, b）之间的直接关系</h2>
<p><strong>核心原理:</strong> 每一个十六进制数字正好对应 4
个二进制位。这是因为 16=24。</p>
<p>我们可以将十六进制数 <code>8080 108B</code> H
中的每一位数字，分别转换为它对应的4位二进制数：</p>
<ol type="1">
<li><strong><code>8</code></strong> H =
<strong><code>1000</code></strong> b</li>
<li><strong><code>0</code></strong> H =
<strong><code>0000</code></strong> b</li>
<li><strong><code>8</code></strong> H =
<strong><code>1000</code></strong> b</li>
<li><strong><code>0</code></strong> H =
<strong><code>0000</code></strong> b</li>
<li><strong><code>1</code></strong> H =
<strong><code>0001</code></strong> b</li>
<li><strong><code>0</code></strong> H =
<strong><code>0000</code></strong> b</li>
<li><strong><code>8</code></strong> H =
<strong><code>1000</code></strong> b</li>
<li><strong><code>B</code></strong> H (B 代表十进制的 11) =
<strong><code>1011</code></strong> b</li>
</ol>
<p><strong>组合:</strong>
现在，按照原始十六进制数的顺序，把这些4位的二进制数组合起来：</p>
<p><code>1000</code> (来自<code>8</code>) + <code>0000</code>
(来自<code>0</code>) + <code>1000</code> (来自<code>8</code>) +
<code>0000</code> (来自<code>0</code>) + <code>0001</code>
(来自<code>1</code>) + <code>0000</code> (来自<code>0</code>) +
<code>1000</code> (来自<code>8</code>) + <code>1011</code>
(来自<code>B</code>)</p>
<p>结果: 将它们连接在一起就得到：</p>
<p>1000 0000 1000 0000 0001 0000 1000 1011 b</p>
<p><strong>所以，<code>8080 108B</code> H 等于
<code>1000 0000 1000 0000 0001 0000 1000 1011</code> b
是因为每个十六进制位都可以独立地、直接地转换为一个4位的二进制表示，然后按顺序拼接起来。</strong></p>
<h2 id="指令决定了如何解释寄存器中的二进制位串">指令决定了如何解释寄存器中的二进制位串</h2>
<p>好的，我们来详细解释一下为什么在不同的指令下，寄存器 R1 和 R2 的内容
<code>0000 108B</code> H 和 <code>8080 108B</code> H
会对应不同的真值。核心原因在于，<strong>指令决定了如何解释寄存器中的二进制位串</strong>。</p>
<p><strong>（1）无符号数加法指令 (Unsigned Addition)</strong></p>
<ul>
<li><strong>解释规则:</strong>
当执行无符号数指令时，计算机会将寄存器中的 <strong>所有32位</strong>
都视为表示数值大小（magnitude）的部分，没有单独的符号位。数值就是这个32位二进制数直接转换成的十进制（或十六进制）值。</li>
</ul>
<p><strong>（2）带符号整数乘法指令 (Signed Integer
Multiplication)</strong></p>
<ul>
<li><p>解释规则:</p>
<p>当执行带符号整数指令时，计算机会使用</p>
<p>补码 (Two’s Complement)</p>
<p>来表示整数。</p>
<ul>
<li><strong>最高位 (MSB, Most Significant Bit)</strong>
是符号位：<code>0</code> 代表正数或零，<code>1</code> 代表负数。</li>
<li><strong>正数:</strong>
其补码、原码、反码相同，数值就是除去符号位后的二进制值。</li>
<li><strong>负数:</strong>
其真值需要通过补码转换回原码来确定其绝对值。转换方法是：<strong>对补码再次求补（符号位不变，数值位按位取反，末位加1；或者全部位按位取反，末位加1）得到原码的绝对值</strong>。</li>
</ul></li>
</ul>
<p><strong>（3）单精度浮点数减法指令 (Single-Precision Floating-Point
Subtraction)</strong></p>
<ul>
<li><p>解释规则:</p>
<p>当执行浮点数指令时，计算机会按照</p>
<p>IEEE 754 单精度 (32位)</p>
<p>标准来解释寄存器中的位。格式如下：</p>
<ul>
<li><strong>符号位 (Sign, S):</strong> 1位 (第31位)。<code>0</code>
为正，<code>1</code> 为负。</li>
<li><strong>阶码 (Exponent, E):</strong> 8位 (第30-23位)。存储的是
<code>e + bias</code>，其中 <code>e</code> 是实际指数，<code>bias</code>
(偏移量) 对于单精度是 <strong>127</strong>。</li>
<li><strong>尾数 (Mantissa/Fraction, F):</strong> 23位
(第22-0位)。表示小数部分。对于规格化数，实际尾数是
<code>1.F</code>（有一个隐藏的1）。</li>
<li><strong>数值公式 (规格化):</strong> Value=(−1)S×(1.F)2×2(E−127)</li>
<li><strong>特殊情况:</strong> 需要注意 E=0 (表示0或非规格化数) 和 E=255
(表示无穷大或NaN)。</li>
</ul></li>
</ul>
<h2 id="补码的基本规则">补码的基本规则</h2>
<p>在开始计算之前，我们先了解补码的基本规则：</p>
<ol type="1">
<li><strong>符号位</strong>：
<ul>
<li>补码的最高位（最左边的位）是符号位。</li>
<li>符号位为 <strong>0</strong> 表示正数或零，符号位为
<strong>1</strong> 表示负数。</li>
</ul></li>
<li><strong>正数的补码</strong>：
<ul>
<li>如果符号位是 0，补码与原码相同，直接按照二进制数值解释即可。</li>
</ul></li>
<li><strong>负数的补码</strong>：
<ul>
<li>如果符号位是
1，表示负数。要得到原码（即实际的数值），需要对数值部分取反（0 变 1，1
变 0），然后加 1。</li>
<li>最后在结果前加上负号。</li>
</ul></li>
<li><strong>小数部分的处理</strong>：
<ul>
<li>如果补码表示包含小数点，符号位在小数点左边，数值部分在小数点右边，按照二进制小数计算。</li>
</ul></li>
</ol>
<h2 id="是的在-c-语言中0u-后面的-u-确实表示无符号的意思具体来说">是的，在 C
语言中，<code>0U</code> 后面的 <code>U</code>
确实表示无符号的意思。具体来说：</h2>
<ul>
<li><strong><code>0</code>
本身</strong>：这是一个整数常量，默认情况下是有符号整数类型（<code>signed int</code>）。</li>
<li><strong><code>0U</code> 的含义</strong>：当在 <code>0</code>
后面加上 <code>U</code>
后缀时，它就变成了一个无符号整数常量（<code>unsigned int</code>）。<code>U</code>
后缀明确指定了这个数字是无符号类型。</li>
</ul>
<h3 id="c-语言中整数常量的后缀规则">C 语言中整数常量的后缀规则</h3>
<p>在 C 语言中，可以通过后缀来指定整数常量的类型： -
<strong>无后缀</strong>：表示默认的有符号整数（<code>int</code>）。 -
<strong><code>U</code> 或
<code>u</code></strong>：表示无符号整数（<code>unsigned int</code>）。 -
<strong><code>L</code> 或
<code>l</code></strong>：表示长整型（<code>long int</code>）。 -
<strong><code>UL</code> 或
<code>ul</code></strong>：表示无符号长整型（<code>unsigned long int</code>）。</p>
<h3 id="举例说明">举例说明</h3>
<ul>
<li><code>0</code>：有符号整数，值是 0。</li>
<li><code>0U</code>：无符号整数，值仍然是 0，但它的类型是
<code>unsigned int</code>。</li>
</ul>
<h3 id="为什么这很重要">为什么这很重要？</h3>
<p>无符号类型和有符号类型的区别在某些情况下会影响程序的行为，比如比较运算：
- 如果比较两个无符号整数，或者两个有符号整数，直接按数值比较即可。 -
如果一个是有符号整数，另一个是无符号整数，C
语言会将有符号整数转换为无符号整数后再比较。这可能导致意外结果，例如负数在转换为无符号整数时变成一个很大的正数。</p>
<p>总之，<code>U</code>
后缀的作用就是告诉编译器，这个整数常量是无符号的。所以你的理解是对的，后面带
<code>U</code> 就是无符号的意思！</p>
<h2 id="让我们来分析这个问题为什么在表达式-unsigned--1--2-中-1-被转换为无符号整数而--2-也被按无符号数处理">让我们来分析这个问题：为什么在表达式
<code>(unsigned) -1 &gt; -2</code> 中，<code>-1</code>
被转换为无符号整数，而 <code>-2</code> 也被按无符号数处理。</h2>
<h3 id="表达式-unsigned--1-的含义">1. 表达式 <code>(unsigned) -1</code>
的含义</h3>
<ul>
<li><strong>(unsigned)</strong> 是一个强制类型转换，表示将后面的值
<code>-1</code>
从有符号整数（<code>int</code>）转换为无符号整数（<code>unsigned int</code>）。</li>
<li>在计算机中，整数通常以补码形式存储。以 32 位为例：
<ul>
<li>有符号整数 <code>-1</code> 的补码是 <code>1111...1111</code>（32
位全 1）。</li>
<li>当将其强制转换为无符号整数时，这串二进制位被重新解释为一个正数。</li>
<li><code>1111...1111</code> 作为无符号整数的值是 (2^{32} - 1 =
4294967295)。</li>
</ul></li>
<li>所以，<code>(unsigned) -1</code> 的结果是
<code>4294967295</code>。</li>
</ul>
<h3 id="比较中的--2-为什么按无符号数处理">2. 比较中的 <code>-2</code>
为什么按无符号数处理</h3>
<ul>
<li>在表达式 <code>(unsigned) -1 &gt; -2</code> 中，<code>-2</code>
默认是一个有符号整数（<code>int</code>），其补码表示为
<code>1111...1110</code>（32 位中最后一位是 0）。</li>
<li>当一个无符号整数（<code>(unsigned) -1</code>）与一个有符号整数（<code>-2</code>）进行比较时，C
语言会执行<strong>隐式类型转换</strong>，以确保两个操作数的类型一致。</li>
<li>根据 C 语言的规则：
<ul>
<li>如果一个操作数是无符号整数，另一个是有符号整数，有符号整数会被转换为无符号整数。</li>
</ul></li>
<li>因此，<code>-2</code> 会被隐式转换为无符号整数：
<ul>
<li><code>1111...1110</code> 作为无符号整数的值是 (2^{32} - 2 =
4294967294)。</li>
</ul></li>
</ul>
<h3 id="比较的过程">3. 比较的过程</h3>
<ul>
<li>现在，表达式 <code>(unsigned) -1 &gt; -2</code> 变成了：
<ul>
<li><code>(unsigned) -1 = 4294967295</code>（无符号整数）。</li>
<li><code>-2</code> 被转换为
<code>4294967294</code>（无符号整数）。</li>
</ul></li>
<li>比较
<code>4294967295 &gt; 4294967294</code>，显然成立，结果为真（<code>1</code>）。</li>
</ul>
<h3 id="为什么--2-被按无符号数处理">4. 为什么 <code>-2</code>
被按无符号数处理</h3>
<ul>
<li><code>-2</code> 被按无符号数处理的原因在于 C
语言的<strong>类型转换规则</strong>：
<ul>
<li>当有符号整数与无符号整数进行运算或比较时，有符号整数会被自动转换为无符号整数。</li>
<li>这种转换基于补码的二进制表示，直接将补码重新解释为无符号值，而不改变位模式。</li>
</ul></li>
<li>在这个例子中：
<ul>
<li><code>(unsigned) -1</code> 强制指定了无符号类型。</li>
<li><code>-2</code> 由于与无符号数比较，被隐式转换成了无符号数。</li>
</ul></li>
</ul>
<h3 id="总结">5. 总结</h3>
<ul>
<li><strong>(unsigned) -1</strong> 将 <code>-1</code>
显式转换为无符号整数，结果是 <code>4294967295</code>。</li>
<li><strong>-2</strong> 在比较中被隐式转换为无符号整数，结果是
<code>4294967294</code>。</li>
<li>这种行为是 C
语言类型转换规则的结果：为了保证比较时类型一致，<code>-2</code>
被按无符号数处理。</li>
</ul>
<p>这种机制虽然确保了类型一致性，但在处理负数时可能导致意外结果，因此在使用无符号类型时需要特别注意。希望这个解释清晰地回答了你的问题！</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——期末复习</title>
    <url>/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="第一章">第一章</h3>
<p><strong>时钟频率（f）</strong>
：单位时间内完成的时钟周期数，单位为赫兹（Hz）。 例如：800MHz
表示每秒完成 800×106 个周期。</p>
<p><strong>时钟周期（T）</strong>
：完成一个时钟周期所需的时间，单位为秒（s）。 例如：800MHz 的时钟周期为
<em>T</em>=800×1061​s=1.25ns （纳秒）。</p>
<p><strong>CPI</strong>（<strong>Cycles Per
Instruction</strong>，每条指令所需的时钟周期数）是衡量计算机体系结构性能的关键指标之一，用于描述<strong>CPU执行一条指令平均需要多少个时钟周期</strong>。它直接影响程序的执行速度和系统性能。</p>
<ul>
<li><strong>CPI</strong>
表示每条指令执行所需的平均时钟周期数，计算公式为： <span class="math display">$$
\text{CPI} = \frac{\text{总时钟周期数}}{\text{总指令数}}
$$</span></li>
<li><strong>执行时间</strong> 与 CPI 的关系： <span class="math display">执行时间 = 指令数 × CPI × 时钟周期时间</span>
其中，时钟周期时间 = 1 / 时钟频率。</li>
</ul>
<p><strong>MIPS（Million Instructions Per Second）</strong>
是衡量计算机处理器性能的一个经典指标，表示
<strong>每秒执行的百万条指令数</strong>，用于量化 CPU
的指令处理能力。其核心思想是：<strong>数值越大，性能越强</strong>，但需注意其局限性。</p>
<ul>
<li><strong>MIPS</strong> = 指令数 / (执行时间 × 10⁶)<br>
</li>
<li>或通过 <strong>时钟频率</strong> 和 <strong>CPI（Cycles Per
Instruction）</strong> 计算：<br>
<span class="math display">$$
\text{MIPS} = \frac{\text{时钟频率（Hz）}}{\text{CPI} \times 10^6}
$$</span></li>
</ul>
<p><strong>举例</strong>：<br>
- 若 CPU 主频为 <strong>2 GHz</strong>（2×10⁹ Hz），平均
CPI=4，则：<br>
<span class="math display">$$
  \text{MIPS} = \frac{2 \times 10^9}{4 \times 10^6} = 500 \text{ MIPS}
  $$</span></p>
<p>数量级：</p>
<p>G，吉，十的九次方</p>
<p>n，纳，十的负九次方</p>
<p><strong>m（milli，毫）的数量级是 10−3 （千分之一）</strong> 。</p>
<h3 id="第二章">第二章</h3>
<h4 id="补码">补码</h4>
<p><strong>1. 补码的定义</strong></p>
<p>补码（Two’s
Complement）是计算机中表示有符号整数的标准方法，其核心作用是将减法运算转化为加法运算，从而简化硬件设计。</p>
<p><strong>2. 如何求一个数的补码？</strong></p>
<p>以 <strong>8位二进制</strong> 为例： - <strong>正数</strong>：补码 =
原码（符号位为0，其余位直接表示数值）。<br>
例如：<code>+5</code> 的补码是 <code>00000101</code>。</p>
<ul>
<li><strong>负数</strong>：补码 =
原码的符号位不变，其余位取反（反码），然后末位加1。<br>
例如：求 <code>-5</code> 的补码：
<ol type="1">
<li>原码：<code>10000101</code>（符号位为1，其余位为5的二进制）。</li>
<li>取反（符号位保留）：<code>11111010</code>（反码）。</li>
<li>加1：<code>11111010 + 1 = 11111011</code>（补码）。</li>
</ol></li>
</ul>
<p><strong>3. 数学原理：模运算</strong></p>
<p>补码的本质是基于 <strong>模（Modulo）运算</strong>。<br>
- 对于 <strong>n位二进制数</strong>，其模为 <span class="math inline">2<sup><em>n</em></sup></span>。<br>
- 负数的补码表示为：<br>
<span class="math display"> − <em>x</em> ≡ 2<sup><em>n</em></sup> − <em>x</em> (mod 2<sup><em>n</em></sup>)</span>
例如，8位二进制数的模是 <span class="math inline">2<sup>8</sup> = 256</span>，因此：<br>
<span class="math inline"> − 5</span> 的补码 = <span class="math inline">256 − 5 = 251</span>，二进制表示为
<code>11111011</code>。</p>
<p><strong>4. 为什么“取反 + 1”有效？</strong></p>
<ul>
<li><strong>取反</strong>：相当于将数值部分取反（即 <span class="math inline"><em>x</em> → (2<sup><em>n</em> − 1</sup>−1−<em>x</em>)</span>）。</li>
<li><strong>加1</strong>：最终得到 <span class="math inline">2<sup><em>n</em></sup> − <em>x</em></span>，即补码的数学定义。</li>
</ul>
<p>以 <code>-5</code> 为例（8位）： 1.
原码：<code>10000101</code>（符号位为1，数值部分为5）。 2.
取反：<code>11111010</code>（数值部分取反，符号位保留）。 3.
加1：<code>11111010 + 1 = 11111011</code>，即 <span class="math inline">251 = 256 − 5</span>。</p>
<p><strong>5. 补码的优势</strong></p>
<ul>
<li><strong>唯一零表示</strong>：补码中只有
<strong>一个零</strong>（<code>00000000</code>），而原码和反码存在
<code>+0</code> 和 <code>-0</code> 的问题。</li>
<li><strong>加减统一</strong>：所有加减运算均通过加法器完成，无需单独的减法器。<br>
例如：<code>5 - 3 = 5 + (-3)</code>，直接通过补码相加即可。</li>
<li><strong>溢出自动处理</strong>：超过范围的高位会自然丢弃（模运算特性）。</li>
</ul>
<p><strong>6. 特殊情况：最小负数</strong></p>
<p>对于 <strong>n位补码</strong>，能表示的范围是：<br>
<span class="math display">[−2<sup><em>n</em> − 1</sup>, 2<sup><em>n</em> − 1</sup>−1]</span>
- 例如，8位补码范围是：<code>-128</code>（<code>10000000</code>）到
<code>+127</code>（<code>01111111</code>）。 -
<strong>最小负数（-128）</strong> 没有对应的正数（因为 <span class="math inline"> + 128</span> 超出范围），其补码直接定义为
<code>10000000</code>，无法通过“取反 + 1”从原码推导（因为原码中不存在
<code>+128</code>）。</p>
<h4 id="移码offset-binary详解"><strong>移码（Offset
Binary）详解</strong></h4>
<p><strong>1. 移码的定义</strong></p>
<p>移码是一种<strong>带偏移量的编码方式</strong>，主要用于表示<strong>浮点数的阶码</strong>（Exponent）。其核心思想是将真值（实际数值）加上一个固定的偏移量（Bias），使得所有数值映射到<strong>非负数范围</strong>，从而简化比较和运算。</p>
<p><strong>公式</strong>：<br>
<span class="math display">移码 = 真值 + 偏移量</span></p>
<p><strong>2. 移码的核心作用</strong></p>
<ul>
<li><strong>简化比较</strong>：<br>
移码将负数范围映射到正数范围，使得可以直接通过<strong>无符号整数比较</strong>来判断阶码的大小。
<ul>
<li>例如：<br>
在浮点数中，阶码 <span class="math inline"> − 3</span> 和 <span class="math inline"> + 2</span> 的移码分别为 <span class="math inline">125</span> 和 <span class="math inline">130</span>（偏移量为127），直接比较 <span class="math inline">125 &lt; 130</span> 即可得出 <span class="math inline"> − 3 &lt;  + 2</span>。</li>
</ul></li>
<li><strong>消除负数表示</strong>：<br>
移码将负数转换为正数表示，避免了补码中负数符号位的影响。</li>
</ul>
<p><strong>3. 偏移量的选择</strong></p>
<p>偏移量通常为 <span class="math inline">2<sup><em>n</em> − 1</sup></span> 或 <span class="math inline">2<sup><em>n</em> − 1</sup> − 1</span>（<span class="math inline"><em>n</em></span> 为位数）： -
<strong>单精度浮点数（32位）</strong>：偏移量为 <span class="math inline">127</span>（即 <span class="math inline">2<sup>7</sup> − 1</span>）。<br>
- <strong>双精度浮点数（64位）</strong>：偏移量为 <span class="math inline">1023</span>（即 <span class="math inline">2<sup>10</sup> − 1</span>）。</p>
<p><strong>4. 移码与补码的关系</strong></p>
<ul>
<li><strong>符号位取反</strong>：<br>
移码可以看作是<strong>补码的符号位取反</strong>。例如：
<ul>
<li>补码 <code>10000000</code>（<span class="math inline"> − 128</span>）的移码为 <code>00000000</code>（<span class="math inline"> − 128 + 128 = 0</span>）。<br>
</li>
<li>补码 <code>00000000</code>（<span class="math inline">0</span>）的移码为 <code>10000000</code>（<span class="math inline">0 + 128 = 128</span>）。</li>
</ul></li>
<li><strong>本质区别</strong>：
<ul>
<li><strong>补码</strong>：用于定点数的加减运算，支持负数和正数的统一处理。<br>
</li>
<li><strong>移码</strong>：用于浮点数阶码的表示，便于直接比较大小。</li>
</ul></li>
</ul>
<p><strong>5. 移码的应用场景</strong></p>
<ul>
<li><strong>IEEE 754浮点数标准</strong>：<br>
移码用于表示浮点数的阶码（Exponent），使得阶码可以直接按无符号整数比较。
<ul>
<li><strong>单精度（32位）</strong>：<br>
阶码占8位，偏移量为127。<br>
真值 <span class="math inline"><em>E</em></span> 的移码为 <span class="math inline"><em>E</em> + 127</span>。<br>
</li>
<li><strong>双精度（64位）</strong>：<br>
阶码占11位，偏移量为1023。<br>
真值 <span class="math inline"><em>E</em></span> 的移码为 <span class="math inline"><em>E</em> + 1023</span>。</li>
</ul></li>
</ul>
<h4 id="浮点数表示">浮点数表示</h4>
<p><a href="https://www.bilibili.com/video/BV1VK4y1f7o6?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】2-4.浮点数(上)_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1Le4y137gU/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【计算机知识】定点数与浮点数（2）浮点数法表示方法！_哔哩哔哩_bilibili</a></p>
<h4 id="进制转换">进制转换</h4>
<p><a href="https://www.bilibili.com/video/BV1ke411T7Qr?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【计算机基础】进制转换(3)
小数部分如何进行转换？_哔哩哔哩_bilibili</a></p>
<h4 id="整数加减">整数加减</h4>
<h4 id="浮点数加减">浮点数加减</h4>
<p><a href="https://www.bilibili.com/video/BV1894y1C7br/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">浮点数加减法运算
白中英计算机组成原理期末速成_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1ue4y1s71Z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">(自用)计算机组成原理
题型三 浮点数加减法运算题_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1ej411J71a/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">浮点运算（浮点数加减运算）计算机组成原理（看了包会）_哔哩哔哩_bilibili</a></p>
<p>ieee</p>
<p><a href="https://www.bilibili.com/video/BV1nwTXz7EVi/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">计算机组成原理期末复习（5分钟）：IEEE754浮点数加减计算！_哔哩哔哩_bilibili</a></p>
<h4 id="位数">位数</h4>
<p>short 16位</p>
<h3 id="第三章-程序的转换与机器级表示"><strong>第三章
程序的转换与机器级表示</strong></h3>
<h4 id="结构体与联合体">结构体与联合体</h4>
<p><a href="https://www.bilibili.com/video/BV1754y1Y7Ut?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-9.结构体与联合体_哔哩哔哩_bilibili</a></p>
<h4 id="数组的分配和访问">数组的分配和访问</h4>
<p><a href="https://www.bilibili.com/video/BV1ho4y1d7J6?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-8.数组的分配和访问_哔哩哔哩_bilibili</a></p>
<h4 id="过程调用">过程调用</h4>
<p><a href="https://www.bilibili.com/video/BV1By4y1x7Yh/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">C程序在内存中的栈_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV19X4y1P7Pn?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-7.
过程（函数调用）_哔哩哔哩_bilibili</a></p>
<h4 id="att格式">AT&amp;T格式</h4>
<p>AT&amp;T格式是汇编语言中的一种语法风格，主要用于x86/x64架构的汇编代码编写。它与Intel格式并列为最常见的两种汇编语法，两者在语法细节上有显著差异。以下是AT&amp;T格式的核心特点、示例及常见用途：</p>
<p><strong>主要特点</strong></p>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 47%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>特性</th>
<th>AT&amp;T格式语法</th>
<th>对比Intel格式语法</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>寄存器</strong></td>
<td>前缀 <code>%</code>（如 <code>%eax</code>）</td>
<td>无前缀（如 <code>eax</code>）</td>
</tr>
<tr class="even">
<td><strong>立即数</strong></td>
<td>前缀 <code>$</code>（如 <code>$0x10</code>）</td>
<td>直接使用数值（如 <code>10</code>）</td>
</tr>
<tr class="odd">
<td><strong>操作数顺序</strong></td>
<td>源操作数在前，目标在后</td>
<td>目标在前，源在后</td>
</tr>
<tr class="even">
<td><strong>内存寻址</strong></td>
<td><code>offset(base, index, scale)</code></td>
<td><code>[base + index*scale + offset]</code></td>
</tr>
<tr class="odd">
<td><strong>指令后缀</strong></td>
<td>通过后缀标明操作数大小（如 <code>l</code> 表示32位）</td>
<td>无后缀，由操作数推断</td>
</tr>
</tbody>
</table>
<h4 id="寄存器种类">寄存器种类</h4>
<ul>
<li>8 个通用寄存器，其中
<ul>
<li><code>EAX, EBX, ECX, EDX</code> 均为 32 位寄存器</li>
<li><code>AX, BX, CX, DX</code> 均为 16 位寄存器</li>
<li><code>AH, BH, CH, DH</code> 均为高 8 位寄存器</li>
<li><code>AL, BL, CL, DL</code> 均为低 8 位寄存器</li>
</ul></li>
<li>2 个专用寄存器</li>
<li>6 个段寄存器</li>
</ul>
<h4 id="操作数寻址方式">操作数寻址方式</h4>
<p><strong>1. 基础内存寻址模式</strong></p>
<p><strong>(1) 直接寻址（Direct Addressing）</strong>
cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc</p>
<ul>
<li><strong>语法</strong>：<code>offset</code>（AT&amp;T格式）或
<code>[offset]</code>（Intel格式）。</li>
<li><strong>用途</strong>：直接访问全局变量或静态数据。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl var(%rip), %eax  # AT&amp;T格式（RIP相对寻址，64位模式推荐）</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov eax, [var]        # Intel格式（32位模式）</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>(2) 寄存器间接寻址（Register Indirect
Addressing）</strong></p>
<ul>
<li><strong>语法</strong>：<code>(base_register)</code> 或
<code>[base_register]</code></li>
<li><strong>用途</strong>：指针解引用。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl (%eax), %ebx     # 将EAX指向的内存值传入EBX</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov ebx, [eax]</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>(3) 基址寻址（Base Addressing）</strong></p>
<ul>
<li><strong>语法</strong>：<code>offset(base_register)</code> 或
<code>[base_register + offset]</code></li>
<li><strong>用途</strong>：访问栈帧中的局部变量或结构体成员。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl 8(%ebp), %ecx    # 从栈帧偏移8处读取数据到ECX</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov ecx, [ebp + 8]</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>(4) 变址寻址（Indexed Addressing）比例寻址</strong></p>
<ul>
<li><p><strong>语法</strong>：<code>array(, index_register, scale)</code>
或 <code>[array + index_register*scale]</code></p></li>
<li><p><strong>用途</strong>：数组元素访问。</p></li>
<li><p><strong>示例</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl array(,%eax,4), %edx  # 数组array + EAX*4位置的值传入EDX（数组索引）</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edx, [array + eax*4]</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>2. 组合寻址模式</strong></p>
<p><strong>(1) 基址 + 变址（Base + Index）</strong></p>
<ul>
<li><p><strong>语法</strong>：<code>(base_register, index_register)</code>
或 <code>[base_register + index_register]</code></p></li>
<li><p><strong>用途</strong>：访问二维数组或动态分配的数组。</p></li>
<li><p><strong>示例</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl (%ebx, %esi), %edi  # 将EBX + ESI指向的内存值传入EDI</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edi, [ebx + esi]</span><br></pre></td></tr></table></figure></li>
</ul>
<p>**(2) 基址 + 比例变址（Base + Index*Scale）**</p>
<ul>
<li><strong>语法</strong>：<code>(base_register, index_register, scale)</code>
或 <code>[base_register + index_register*scale]</code></li>
<li><strong>用途</strong>：按元素大小（scale）访问数组。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl (%ebx, %esi, 4), %edi  # 将EBX + ESI*4指向的内存值传入EDI（4字节元素）</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edi, [ebx + esi*4]</span><br></pre></td></tr></table></figure></li>
</ul>
<p>**(3) 基址 + 比例变址 + 偏移（Base + Index*Scale + Offset）**</p>
<ul>
<li><strong>语法</strong>：<code>offset(base_register, index_register, scale)</code>
或 <code>[base_register + index_register*scale + offset]</code></li>
<li><strong>用途</strong>：访问结构体数组或复杂数据结构。</li>
<li><strong>示例</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl 12(%ebx, %esi, 8), %edi  # 结构体数组中第ESI个元素的偏移12处数据传入EDI</span><br></pre></td></tr></table></figure> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edi, [ebx + esi*8 + 12]</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>3.总结</strong></p>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 28%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>寻址模式</th>
<th>AT&amp;T格式语法</th>
<th>Intel格式语法</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>直接寻址</td>
<td><code>var(%rip)</code></td>
<td><code>[rip + var]</code>（64位）或 <code>var</code></td>
</tr>
<tr class="even">
<td>寄存器间接寻址</td>
<td><code>(%eax)</code></td>
<td><code>[eax]</code></td>
</tr>
<tr class="odd">
<td>基址寻址</td>
<td><code>8(%ebp)</code></td>
<td><code>[ebp + 8]</code></td>
</tr>
<tr class="even">
<td>变址寻址</td>
<td><code>array(,%eax,4)</code></td>
<td><code>[array + eax*4]</code></td>
</tr>
<tr class="odd">
<td>基址+比例变址</td>
<td><code>(%ebx, %esi, 4)</code></td>
<td><code>[ebx + esi*4]</code></td>
</tr>
<tr class="even">
<td>基址+比例变址+偏移</td>
<td><code>12(%ebx, %esi, 8)</code></td>
<td><code>[ebx + esi*8 + 12]</code></td>
</tr>
</tbody>
</table>
<h4 id="指令后缀">指令后缀</h4>
<p>在 AT&amp;T 汇编格式中，<strong>指令后缀</strong>（如
<code>b</code>、<code>w</code>、<code>l</code>、<code>q</code>）用于明确操作数的大小，确保汇编器正确生成机器码。判断后缀的核心规则是：<strong>根据操作数的大小选择对应的后缀</strong>，尤其是寄存器的位数或内存操作数的显式指定。以下是详细说明：</p>
<p><strong>后缀与操作数大小的对应关系</strong></p>
<table>
<thead>
<tr class="header">
<th>后缀</th>
<th>操作数大小</th>
<th>示例寄存器/操作数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>b</code></td>
<td>byte（8位）</td>
<td><code>%al</code>, <code>$0x10</code>,
<code>12(%ebp)</code>（需显式指定）</td>
</tr>
<tr class="even">
<td><code>w</code></td>
<td>word（16位）</td>
<td><code>%ax</code>, <code>%bx</code>,
<code>12(%ebp)</code>（需显式指定）</td>
</tr>
<tr class="odd">
<td><code>l</code></td>
<td>long（32位）</td>
<td><code>%eax</code>, <code>%ebx</code>,
<code>12(%ebp)</code>（需显式指定）</td>
</tr>
<tr class="even">
<td><code>q</code></td>
<td>quad（64位）</td>
<td><code>%rax</code>, <code>%rbx</code>,
<code>12(%ebp)</code>（需显式指定）</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>立即数默认为32位</strong></p>
</blockquote>
<h4 id="判断指针与临时变量">判断“指针”与“临时变量</h4>
<p><strong>（1）<code>%edx</code>：临时变量</strong></p>
<ul>
<li><strong>特征</strong>：直接从寄存器 <code>%edx</code>
读取数据，不涉及内存地址的间接访问。</li>
<li><strong>对应C语言</strong>：<br>
如果 <code>%edx</code> 存储的是某个局部变量或计算结果（如
<code>temp = a + b</code>），则对应<strong>临时变量</strong>。</li>
</ul>
<p><strong>（2）<code>(%ecx)</code>：指针</strong></p>
<ul>
<li><strong>特征</strong>：<code>%ecx</code>
中存储的是内存地址，<code>(%ecx)</code> 表示解引用该地址（类似C语言的
<code>*ptr</code>）。<br>
</li>
<li><strong>对应C语言</strong>：<br>
如果 <code>%ecx</code> 存储的是一个指针变量（如
<code>int *ptr</code>），则 <code>(%ecx)</code>
对应<strong>指针解引用</strong>。</li>
</ul>
<p><strong>关键结论</strong></p>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 10%">
<col style="width: 78%">
</colgroup>
<thead>
<tr class="header">
<th>操作数</th>
<th>类型</th>
<th>判断依据</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>%edx</code></td>
<td>临时变量</td>
<td>直接从寄存器读取数据，无间接内存访问（无括号）。</td>
</tr>
<tr class="even">
<td><code>(%ecx)</code></td>
<td>指针</td>
<td>使用括号 <code>(%ecx)</code> 表示解引用内存地址（类似C语言的
<code>*ptr</code>）。</td>
</tr>
</tbody>
</table>
<p><strong>常见模式对比</strong></p>
<table>
<colgroup>
<col style="width: 24%">
<col style="width: 17%">
<col style="width: 58%">
</colgroup>
<thead>
<tr class="header">
<th>汇编指令</th>
<th>C语言对应操作</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>movl %eax, (%ebx)</code></td>
<td><code>*ptr = temp;</code></td>
<td><code>%ebx</code> 是指针（存储地址），<code>%eax</code>
是临时变量。</td>
</tr>
<tr class="even">
<td><code>movl (%ebx), %eax</code></td>
<td><code>temp = *ptr;</code></td>
<td>从指针 <code>ptr</code> 读取值到临时变量 <code>temp</code>。</td>
</tr>
<tr class="odd">
<td><code>movl $0x1, %eax</code></td>
<td><code>temp = 1;</code></td>
<td><code>%eax</code> 是临时变量，直接赋值。</td>
</tr>
</tbody>
</table>
<h4 id="汇编语言中m的作用">汇编语言中M的作用</h4>
<p>在汇编语言中，<strong>M</strong> 通常表示
<strong>内存（Memory）</strong>，用于指示操作数来自内存地址。在你的问题中，<code>M[R[eax]]</code>
的含义是：</p>
<p><strong><code>M</code> 的作用</strong></p>
<ul>
<li><strong><code>M[地址]</code></strong> 表示从 <strong>内存地址为
<code>地址</code> 的位置读取数据</strong>。</li>
<li><strong><code>R[eax]</code></strong> 表示寄存器 <code>EAX</code>
的值（即 <code>EAX</code> 中存储的内容）。</li>
<li>因此，<code>M[R[eax]]</code> 的含义是： &gt; <strong>以
<code>EAX</code>
寄存器的值作为内存地址，从该地址读取数据</strong>。</li>
</ul>
<p>** AT&amp;T 汇编中的等价写法**</p>
<p>在 AT&amp;T 汇编语法中，<code>M[R[eax]]</code> 对应的写法是：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">addl (%eax), %edx</span><br></pre></td></tr></table></figure> - <strong>含义</strong>： - <code>(%eax)</code>：以
<code>EAX</code> 的值为内存地址，读取该地址的内容（默认是 4 字节，即 32
位）。 - <code>addl</code>：执行 32 位加法。 -
<code>%edx</code>：目标寄存器，存储结果。</p>
<p><strong>关键点总结</strong></p>
<table>
<thead>
<tr class="header">
<th>符号</th>
<th>含义</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>R</code></td>
<td>寄存器（Register）</td>
<td><code>R[eax]</code> → <code>EAX</code> 的值</td>
</tr>
<tr class="even">
<td><code>M</code></td>
<td>内存（Memory）</td>
<td><code>M[地址]</code> → 从地址读取数据</td>
</tr>
<tr class="odd">
<td><code>()</code></td>
<td>AT&amp;T 汇编中表示内存寻址</td>
<td><code>(%eax)</code> → 等价于 <code>M[R[eax]]</code></td>
</tr>
</tbody>
</table>
<h4 id="常见att格式汇编指令">常见AT&amp;T格式汇编指令</h4>
<table>
<colgroup>
<col style="width: 12%">
<col style="width: 15%">
<col style="width: 28%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>指令类型</th>
<th>操作目的</th>
<th>影响标志位</th>
<th>典型用途</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>addl</code></td>
<td>加法</td>
<td>OF, SF, ZF, CF</td>
<td>数值运算、地址偏移</td>
</tr>
<tr class="even">
<td><code>subl</code></td>
<td>减法</td>
<td>OF, SF, ZF, CF</td>
<td>数值运算、条件判断</td>
</tr>
<tr class="odd">
<td><code>orl</code></td>
<td>按位或</td>
<td>OF=0, SF, ZF, CF=0</td>
<td>位掩码操作</td>
</tr>
<tr class="even">
<td><code>testl</code></td>
<td>按位与测试</td>
<td>OF=0, SF, ZF, CF=0</td>
<td>条件判断（如检查位是否设置）</td>
</tr>
<tr class="odd">
<td><code>imull</code></td>
<td>有符号乘法</td>
<td>OF, CF</td>
<td>数值运算</td>
</tr>
<tr class="even">
<td><code>leal</code></td>
<td>地址计算</td>
<td>无影响</td>
<td>高效数组索引计算</td>
</tr>
<tr class="odd">
<td><code>decl</code></td>
<td>递减</td>
<td>OF, SF, ZF, CF</td>
<td>循环计数、边界检查</td>
</tr>
</tbody>
</table>
<p><strong><code>sall</code>（Shift Arithmetic Left）——
左移指令</strong></p>
<p><strong>功能</strong></p>
<ul>
<li><strong>作用</strong> ：将操作数的二进制位 <strong>向左移动</strong>
指定的位数，低位补0。</li>
<li><strong>效果</strong> ：相当于将操作数乘以 2<em>n</em> （n
为移动的位数）。</li>
</ul>
<p><strong><code>and</code>（Logical AND）—— 逻辑与指令</strong></p>
<p><strong>功能</strong></p>
<ul>
<li><strong>作用</strong> ：对两个操作数进行 <strong>按位与运算</strong>
，结果写入目标操作数。</li>
<li><strong>效果</strong> ：只有对应位都为1时，结果位才为1。</li>
</ul>
<p><code>shrl</code> 是 <strong>逻辑右移指令</strong> （Shift Right
Logical），用于对操作数进行 <strong>无符号右移</strong> ，即高位补
0，低位移出。</p>
<p><code>leal</code> 是 <strong>加载有效地址（Load Effective
Address）</strong> 的指令，其功能是
<strong>计算内存地址并存储到目标寄存器</strong> ，但
<strong>不会访问内存</strong> 。它常用于 <strong>地址计算</strong> 和
<strong>高效算术运算</strong></p>
<h4 id="标志位">标志位</h4>
<p>以下是 <strong>x86/x64
架构中常见的四个状态标志位</strong>（OF、SF、ZF、CF）的详细说明及其判断方法：</p>
<p><strong>1. 标志位概述</strong></p>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 16%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="header">
<th>标志</th>
<th>全称</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>CF</strong></td>
<td>Carry Flag</td>
<td><strong>无符号溢出标志</strong>：表示无符号数运算是否产生进位或借位。</td>
</tr>
<tr class="even">
<td><strong>ZF</strong></td>
<td>Zero Flag</td>
<td><strong>零标志</strong>：表示运算结果是否为零。</td>
</tr>
<tr class="odd">
<td><strong>SF</strong></td>
<td>Sign Flag</td>
<td><strong>符号标志</strong>：表示运算结果的最高位（符号位）是否为1（负数）。</td>
</tr>
<tr class="even">
<td><strong>OF</strong></td>
<td>Overflow Flag</td>
<td><strong>溢出标志</strong>：表示有符号数运算是否溢出（结果超出数据类型表示范围）。</td>
</tr>
</tbody>
</table>
<p><strong>2. 判断方法详解</strong></p>
<p><strong>(1) 进位标志（CF）</strong></p>
<ul>
<li><strong>用途</strong>：判断 <strong>无符号数运算</strong>
是否溢出。</li>
<li><strong>判断规则</strong>：
<ul>
<li><strong>加法</strong>：若结果最高位（最高有效位）发生进位（超过数据类型的最大值），CF=1。</li>
<li><strong>减法</strong>：若结果需要借位（被减数 &lt;
减数），CF=1。</li>
</ul></li>
</ul>
<p><strong>(2) 零标志（ZF）</strong></p>
<ul>
<li><strong>用途</strong>：判断运算结果是否为零。</li>
<li><strong>判断规则</strong>：
<ul>
<li><strong>结果为0</strong> → ZF=1</li>
<li><strong>结果非0</strong> → ZF=0</li>
</ul></li>
</ul>
<p><strong>(3) 符号标志（SF）</strong></p>
<ul>
<li><strong>用途</strong>：表示运算结果的符号（正/负）。</li>
<li><strong>判断规则</strong>：
<ul>
<li><strong>结果最高位为1</strong>（负数）→ SF=1</li>
<li><strong>结果最高位为0</strong>（正数）→ SF=0</li>
</ul></li>
</ul>
<p><strong>(4) 溢出标志（OF）</strong></p>
<ul>
<li><strong>用途</strong>：判断 <strong>有符号数运算</strong>
是否溢出。</li>
<li><strong>判断规则</strong>：
<ul>
<li><strong>溢出条件</strong>：两个正数相加结果为负，或两个负数相加结果为正
→ OF=1。</li>
<li><strong>无溢出</strong>：其他情况 → OF=0。</li>
</ul></li>
</ul>
<h4 id="栈帧布局和参数偏移计算规则">栈帧布局和参数偏移计算规则</h4>
<p><a href="https://www.bilibili.com/video/BV1sV411b7c1/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-3.栈与数据传送指令_哔哩哔哩_bilibili</a></p>
<p><strong>1. 参数压栈顺序</strong></p>
<p>C语言默认使用 <strong><code>cdecl</code>
调用约定</strong>，参数<strong>从右到左</strong>压入栈中。例如，函数调用
<code>operate(x, y, z, k)</code> 的压栈顺序为： <figure class="highlight c"><table><tr><td class="code"><pre><span class="line">push k;     <span class="comment">// 第四个参数（最右边）</span></span><br><span class="line">push z;     <span class="comment">// 第三个参数</span></span><br><span class="line">push y;     <span class="comment">// 第二个参数</span></span><br><span class="line">push x;     <span class="comment">// 第一个参数（最左边）</span></span><br><span class="line">call operate;</span><br></pre></td></tr></table></figure>
栈中参数布局（高地址 → 低地址）： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">高地址</span><br><span class="line">| k  (参数4) | ← 栈顶（ESP）</span><br><span class="line">| z  (参数3) |</span><br><span class="line">| y  (参数2) |</span><br><span class="line">| x  (参数1) |</span><br><span class="line">| 返回地址   |</span><br><span class="line">低地址</span><br></pre></td></tr></table></figure></p>
<p><strong>2. 栈帧建立过程</strong></p>
<p>进入函数 <code>operate</code> 后，通过以下指令建立栈帧：
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pushl %ebp        ; 保存旧的EBP（栈帧基址）</span><br><span class="line">movl %esp, %ebp   ; 将当前栈顶（ESP）赋值给EBP，作为新栈帧的基址</span><br></pre></td></tr></table></figure> 此时栈帧布局如下： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">高地址</span><br><span class="line">| k  (参数4) | ← EBP + 20</span><br><span class="line">| z  (参数3) | ← EBP + 16</span><br><span class="line">| y  (参数2) | ← EBP + 12</span><br><span class="line">| x  (参数1) | ← EBP + 8</span><br><span class="line">| 返回地址   | ← EBP + 4</span><br><span class="line">| 旧 EBP     | ← EBP</span><br><span class="line">低地址</span><br></pre></td></tr></table></figure></p>
<p><strong>3. 参数地址的计算逻辑</strong></p>
<ul>
<li><strong><code>EBP + 4</code></strong>：返回地址（由
<code>call</code> 指令自动压栈）。<br>
</li>
<li><strong><code>EBP + 8</code></strong>：第一个参数（<code>x</code>）。<br>
</li>
<li><strong><code>EBP + 12</code></strong>：第二个参数（<code>y</code>）。<br>
</li>
<li><strong><code>EBP + 16</code></strong>：第三个参数（<code>z</code>）。<br>
</li>
<li><strong><code>EBP + 20</code></strong>：第四个参数（<code>k</code>）。</li>
</ul>
<p><strong>原因</strong>：<br>
1.
<strong>参数顺序</strong>：参数从右到左压栈，导致第一个参数（<code>x</code>）位于栈的最低地址（<code>EBP + 8</code>），而第四个参数（<code>k</code>）位于最高地址（<code>EBP + 20</code>）。<br>
2. <strong>偏移计算</strong>：每个参数占用4字节（32位系统中
<code>int</code> 和指针大小），因此偏移量依次递增4。<br>
3. <strong>栈帧基址</strong>：<code>EBP</code> 指向旧的 <code>EBP</code>
值，其上方是返回地址（<code>EBP + 4</code>），再上方是参数。</p>
<h4 id="汇编语言表示程序函数的过程调用">汇编语言表示程序函数的过程调用</h4>
<p><a href="https://www.bilibili.com/video/BV1Nt4y1G728/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">超硬核！408考研重点！汇编语言表示程序函数的过程调用！23王道计算机组成原理指令系统_哔哩哔哩_bilibili</a></p>
<h4 id="反汇编">反汇编</h4>
<p>反汇编代码是将二进制机器码（如可执行文件、内存转储）转换为
<strong>人类可读的汇编指令</strong>
的结果。它是逆向工程、漏洞分析、调试等领域的核心工具。以下是详细说明：</p>
<p><strong>1. 反汇编代码的定义</strong></p>
<ul>
<li><strong>本质</strong>：将机器码（二进制/十六进制）转换为对应的汇编指令。</li>
<li><strong>作用</strong>：帮助开发者理解程序逻辑、分析恶意软件、调试崩溃原因或研究编译器优化。</li>
</ul>
<p><strong>2. 反汇编代码的典型格式</strong></p>
<p>反汇编代码通常包含以下部分： | <strong>字段</strong> |
<strong>说明</strong> | <strong>示例</strong> | | ————————- |
————————————————– | —————————- | | <strong>地址（Address）</strong> |
指令在内存中的地址（十六进制）。 | <code>0x804838c</code> | |
<strong>机器码（Opcode）</strong> |
对应的原始十六进制机器码（机器指令的二进制表示）。 | <code>74 08</code>
| | <strong>汇编指令（Mnemonic）</strong> | 汇编助记符（如
<code>mov</code>, <code>jmp</code>, <code>call</code>）及操作数。 |
<code>je 0x8048396</code> | | <strong>注释（Comment, 可选）</strong> |
开发者添加的注释（某些工具会自动生成符号信息）。 |
<code>; if (eax == 0) goto label</code> |</p>
<p><strong>示例反汇编代码（AT&amp;T格式）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0804838c &lt;main&gt;:</span><br><span class="line">804838c:    74 08                   je     8048396 &lt;main+0xa&gt;</span><br><span class="line">804838e:    b8 00 00 00 00          mov    $0x0, %eax</span><br><span class="line">8048393:    e9 0e 00 00 00          jmp    80483a6 &lt;main+0x1a&gt;</span><br></pre></td></tr></table></figure>
<h4 id="大端小端">大端小端</h4>
<p><strong>小端方式（Little-Endian）</strong> 是一种
<strong>数据在内存中的存储顺序</strong>，其核心特点是： &gt;
<strong>数据的低位字节（LSB, Least Significant
Byte）存储在内存的低地址处，高位字节（MSB, Most Significant
Byte）存储在高地址处</strong>。</p>
<p><strong>1. 小端 vs 大端</strong></p>
<table>
<colgroup>
<col style="width: 14%">
<col style="width: 42%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th><strong>特性</strong></th>
<th><strong>小端（Little-Endian）</strong></th>
<th><strong>大端（Big-Endian）</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>存储顺序</strong></td>
<td>低位字节在前（低地址），高位在后</td>
<td>高位字节在前（低地址），低位在后</td>
</tr>
<tr class="even">
<td><strong>示例</strong></td>
<td><code>0x12345678</code> → 存储为 <code>78 56 34 12</code></td>
<td><code>0x12345678</code> → 存储为 <code>12 34 56 78</code></td>
</tr>
<tr class="odd">
<td><strong>常见平台</strong></td>
<td>x86/x64 架构（Intel/AMD 处理器）</td>
<td>ARM（部分模式）、网络协议（TCP/IP）</td>
</tr>
</tbody>
</table>
<p><strong>2. 小端方式的直观理解</strong></p>
<p><strong>示例：32位整数 <code>0x12345678</code></strong></p>
<ul>
<li><strong>内存地址分配</strong>： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">地址 →    0x1000    0x1001    0x1002    0x1003</span><br><span class="line">         +---------+---------+---------+---------+</span><br><span class="line">         |  0x78   |  0x56   |  0x34   |  0x12   |</span><br><span class="line">         +---------+---------+---------+---------+</span><br></pre></td></tr></table></figure></li>
<li><strong>解释</strong>：
<ul>
<li>数据的最低位字节 <code>0x78</code> 存储在最低地址
<code>0x1000</code>。</li>
<li>高位字节 <code>0x12</code> 存储在最高地址 <code>0x1003</code>。</li>
</ul></li>
</ul>
<h4 id="转移目标地址的计算">转移目标地址的计算</h4>
<p>在 IA-32（x86）架构中，<strong>转移目标地址的计算</strong>依赖于
<strong>指令的长度</strong> 和
<strong>相对偏移量（Displacement）</strong>。以下是详细分析：</p>
<p><strong>1. 转移指令的基本原理</strong></p>
<ul>
<li><strong>相对跳转（Relative Jump）</strong>：转移目标地址 =
<strong>下一条指令地址</strong> + <strong>偏移量</strong>。</li>
<li><strong>偏移量</strong>：有符号的 8 位、16 位或 32 位整数，表示从
<strong>下一条指令地址</strong> 开始的偏移（正向或负向）。</li>
<li><strong>小端方式（Little-Endian）</strong>：多字节偏移量需按小端方式存储（低位字节在前）。</li>
</ul>
<p><strong>2. 示例：<code>call</code> 指令的地址计算</strong></p>
<p><strong>(1) 已知条件</strong></p>
<ul>
<li><strong>指令地址</strong>：<code>0x804838e</code>（<code>call</code>
指令的起始地址）。</li>
<li><strong>机器码</strong>：<code>E8 1E 00 00 00</code>。
<ul>
<li><code>E8</code> 是 <code>call</code> 的操作码。</li>
<li><code>1E 00 00 00</code> 是偏移量（小端方式存储）。</li>
</ul></li>
</ul>
<p><strong>(2) 计算步骤</strong></p>
<ol type="1">
<li><strong>确定指令长度</strong>：
<ul>
<li><code>call</code> 指令占 <strong>5 字节</strong>（1 字节操作码 + 4
字节偏移量）。</li>
</ul></li>
<li><strong>计算下一条指令地址</strong>：
<ul>
<li>下一条指令地址 = 当前指令地址 + 指令长度<br>
= <code>0x804838e + 5 = 0x8048393</code>。</li>
</ul></li>
<li><strong>解析偏移量</strong>：
<ul>
<li>偏移量字段为 <code>1E 00 00 00</code>（小端方式）→ 转换为大端顺序为
<code>0x0000001E</code>（十进制 30）。</li>
</ul></li>
<li><strong>计算转移目标地址</strong>：
<ul>
<li>转移目标地址 = 下一条指令地址 + 偏移量<br>
= <code>0x8048393 + 0x1E = 0x80483B1</code>。</li>
</ul></li>
</ol>
<p><strong>3. 核心公式</strong> <span class="math display">目标地址 = (当前指令地址+指令长度) + 偏移量</span>
- <strong>当前指令地址</strong>：指令的起始地址（如
<code>0x804838e</code>）。 -
<strong>指令长度</strong>：由操作码和操作数决定（如 <code>call</code> 占
5 字节）。 -
<strong>偏移量</strong>：从指令的操作数中提取并转换为有符号整数。</p>
<p><strong>9. 其他指令示例</strong></p>
<p><strong>(1) <code>je</code> 指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">804838c:    74 08                   je     0x8048396</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>当前地址</strong>：<code>0x804838c</code>。</li>
<li><strong>指令长度</strong>：2 字节。</li>
<li><strong>偏移量</strong>：<code>0x08</code>（单字节，无需反转）。</li>
<li><strong>目标地址</strong>：<code>0x804838c + 2 + 0x08 = 0x8048396</code>。</li>
</ul>
<p><strong>(2) <code>jmp</code> 指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">80483a4:    E9 F6 FF FF FF          jmp    0x804839f</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>当前地址</strong>：<code>0x80483a4</code>。</li>
<li><strong>指令长度</strong>：5 字节。</li>
<li><strong>偏移量</strong>：<code>F6 FF FF FF</code>（小端）→ 补码为
<code>-10</code>（十进制）。</li>
<li><strong>目标地址</strong>：<code>0x80483a4 + 5 + (-10) = 0x804839f</code>。</li>
</ul>
<h4 id="计算下一条指令地址"><strong>计算下一条指令地址</strong></h4>
<p>下一条指令地址=当前指令地址+当前指令长度</p>
<h3 id="第四章-程序的链接">第四章 程序的链接</h3>
<h4 id="重定位">重定位</h4>
<p><a href="https://www.bilibili.com/video/BV1JL411L7ku?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】7-6.
重定位_哔哩哔哩_bilibili</a></p>
<h4 id="其他">其他</h4>
<p><a href="https://www.bilibili.com/video/BV1oe411n72U/?spm_id_from=333.337.search-card.all.click">3分钟彻底理解链接器_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/gzxb1995/article/details/105088502">计算机系统基础摘记——程序的链接_引入链接的好处是什么-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1oS4y1T7Uf?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】7-5.
静态库的解析过程_哔哩哔哩_bilibili</a></p>
<h3 id="其他-1">其他</h3>
<p>gdb调试</p>
<p><a href="https://www.bilibili.com/video/BV1Sg41167B1/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">一分钟学会GDB程序调试_哔哩哔哩_bilibili</a></p>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.bilibili.com/video/BV17K4y1N7Q2?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">深入理解计算机系统合集（周更中）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——课后答案</title>
    <url>/2025/03/12/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88/</url>
    <content><![CDATA[<h1 id="目录">目录</h1>
<h2 id="说明"><a href="#说明">说明</a></h2>
<h1 id="说明-1">说明</h1>
<h2 id="版本信息">版本信息</h2>
<p>书名：《计算机系统基础（第二版）》 袁春风</p>
<p>整理日期：2019-10-27</p>
<p>整理人：李加其（幽弥狂）</p>
<p>内容：课后习题参考答案</p>
<p>联系方式：13812991101</p>
<p>邮箱：1768478912@qq.com</p>
<p>QQ:1768478912</p>
<p>版本：v1.0</p>
<h2 id="声明">声明</h2>
<p>1、如果有侵权或者其他问题欢迎联系我。</p>
<p>2、参考书目为https://github.com/JackeyLea/NJUCS中README.md文件中列出的参考书目。</p>
<p>3、红色字体为重要内容，比如曾作为课后习题、考试考过等等。</p>
<p>4、括号里的P**表示在书本的第几页。</p>
<h1 id="第一部分-系统概述和可执行目标文件的生成">第一部分
系统概述和可执行目标文件的生成</h1>
<h2 id="第一章计算机系统概述">第一章计算机系统概述</h2>
<p>1、见《计算机系统基础习题解答与教学指导》</p>
<p>2、简单回答下列问题。</p>
<p>（1）冯·诺依曼计算机由哪几部分组成？各部分的功能是什么？</p>
<pre><code>控制器：用于控制主动执行指令；

运算器：用于执行指令；

存储器：存放数据和指令；

输入输出设备：通过输入输出设备使用计算机；</code></pre>
<p>（2）什么是“存储程序”工作方式？</p>
<pre><code>必须将事先编好的程序和原始数据送人主存后才开能执行程序，一旦程序被启动执行，计算机能在必须操作人员干预的情况下自动完成逐条指令取出和执行任务。（P3）</code></pre>
<p>（3）一条指令的执行过程包含哪几个阶段？</p>
<pre><code>程序的执行就是指令的执行过程。

阶段：
取指令、取数、传数、ALU运算阶段。（P6）</code></pre>
<p>（4）计算机系统的层次结构如何划分？</p>
<pre><code>电路设计、数字设计、ISA、汇编程序、编译程序、应用程序、操作系统（P18 图1.11）</code></pre>
<p>（5）计算机系统的用户可分哪几类？每类用户工作在哪个层次？</p>
<pre><code>用户有四种：

最终用户：应用程序级

系统管理员：操作系统

应用程序员：编译程序

系统程序员：汇编程序和ISA之间</code></pre>
<p>（6）程序的 CPI 与哪些因素有关？</p>
<pre><code>总时钟周期数、指令条数（P20）</code></pre>
<p>（7）为什么说性能指标 MIPS 不能很好地反映计算机的性能？</p>
<pre><code>MIPS反映了机器执行定点指令的速度。首先，不同机器的指令集是不同的，而且指令的功能也是不同的，也许在机器1上一条指令完成的功能机器2需要多条指令。其次，不同机器的CPI和时钟周期也是不同的，因此同一条指令在不同的机器上所用的时间也不同。（P20 最后一段）</code></pre>
<p>3、略</p>
<p>4、略</p>
<p>5、题目略</p>
<p>仿照图1.3</p>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>主存地址</th>
<th>主存单元地址</th>
<th>内容说明（Ii表示第i条指令）</th>
<th>指令的符号表示</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1110 0111</td>
<td>I1：R[0]←M[7]；op=1110；取数操作</td>
<td>load r0,7#</td>
</tr>
<tr class="even">
<td>1</td>
<td>0000 0100</td>
<td>I2：R[1]←R[0]；op=0000；传送操作</td>
<td>mov r1,r0</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1110 0101</td>
<td>I3：R[0]←M[6]；op=1110；取数操作</td>
<td>load r0,6#</td>
</tr>
<tr class="even">
<td>3</td>
<td>0010 0001</td>
<td>I4：R[0]←R[0]-R[1]；op=0010；减操作</td>
<td>sub r0,r1</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0011 0001</td>
<td>I5：R[0]←R[0]*R[1]；op=0011；乘操作</td>
<td>mul r0,r1</td>
</tr>
<tr class="even">
<td>5</td>
<td>1111 1000</td>
<td>I6：M[8]←R[0]；op=1111；存数操作</td>
<td>store 8#,r0</td>
</tr>
<tr class="odd">
<td>6</td>
<td>0001 0000</td>
<td>操作数x，值为16</td>
<td></td>
</tr>
<tr class="even">
<td>7</td>
<td>0010 0001</td>
<td>操作数y，值为33</td>
<td></td>
</tr>
<tr class="odd">
<td>8</td>
<td>0000 0000</td>
<td>结果z，初始值为0</td>
<td></td>
</tr>
</tbody>
</table>
<p>仿照图1.5</p>
<table style="width:100%;">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>操作</th>
<th>I1:1110 0111</th>
<th>I2：0000 0100</th>
<th>I3：1110 0101</th>
<th>I4：0010 0001</th>
<th>I5：0011 0001</th>
<th>I6：1111 1000</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>取指令</td>
<td>IR←M[0000]</td>
<td>IR←M[0001]</td>
<td>IR←M[0010]</td>
<td>IR←M[0011]</td>
<td>IR←M[0100]</td>
<td>IR←M[0101]</td>
</tr>
<tr class="even">
<td>指令译码</td>
<td>op=1110，取数</td>
<td>op=0000，传送</td>
<td>op=1110，取数</td>
<td>op=0010，减</td>
<td>op=0011，乘</td>
<td>op=1111，存数</td>
</tr>
<tr class="odd">
<td>PC增量</td>
<td>PC←0000+1</td>
<td>PC←0001+1</td>
<td>PC←0010+1</td>
<td>PC←0011+1</td>
<td>PC←0100+1</td>
<td>PC←0101+1</td>
</tr>
<tr class="even">
<td>取数并执行</td>
<td>MDR←M[0110]</td>
<td>A←R[0]、mov</td>
<td>MDR←M[0101]</td>
<td>A←R[0]、B←R[1]、sub</td>
<td>A←R[0]、B←R[1]、mul</td>
<td>MDR←R[0]</td>
</tr>
<tr class="odd">
<td>送结果</td>
<td>R[0]←MDR</td>
<td>R[1]←F</td>
<td>R[0]←MDR</td>
<td>R[0]←F</td>
<td>R[0]←F</td>
<td>M[1000]←MDR</td>
</tr>
<tr class="even">
<td>执行结果</td>
<td>R[0]=33</td>
<td>R[1]=33</td>
<td>R[0]=16</td>
<td>R[0]=16-33=-17</td>
<td>R[0]=-17×33</td>
<td>M[8]=-561</td>
</tr>
</tbody>
</table>
<p>6、若有两个基准测试程序P1和P2在机器M1和M2上运行，假定M1和M2的价格分别是5000元和8000元，下表给出了P1和P2在M1和M2上所花的时间和指令条数。</p>
<table>
<tr>
<th rowspan="2">
程序
</th>
<th colspan="2">
M1
</th>
<th colspan="2">
M2
</th>
</tr>
<tr>
<td>
指令条数
</td>
<td>
执行时间(ms)
</td>
<td>
指令条数
</td>
<td>
执行时间(ms)
</td>
</tr>
<tr>
<td>
P1
</td>
<td>
200×10^6
</td>
<td>
10000
</td>
<td>
150×10^6
</td>
<td>
5000
</td>
</tr>
<tr>
<td>
P2
</td>
<td>
300×10^3
</td>
<td>
3
</td>
<td>
420×10^3
</td>
<td>
6
</td>
</tr>
</table>
<p>请回答下列问题：</p>
<p>（1）对于P1，哪台机器的速度快？快多少？对于P2呢？</p>
<pre><code>对于P1，M2比M1快一倍；对于P2，M1比M2快一倍。</code></pre>
<p>（2）在M1上执行P1和P2的速度分别是多少MIPS？在M2上的执行速度又各是多少？从执行速度来看，对于P2，哪台机器的速度快？快多少？</p>
<pre><code>对于M1，P1的速度为：200M/10=20MIPS；P2为300k/0.003=100MIPS。

对于M2，P1的速度为：150M/5=30MIPS；P2为420k/0.006=70MIPS。

从执行速度来看，对于P2，因为100/70=1.43倍，所以M1比M2快0.43倍。</code></pre>
<p>（3）假定M1和M2的时钟频率各是800MHz和1.2GHz，则在M1和M2上执行P1时的平均时钟周期数CPI各是多少？</p>
<pre><code>在M1上执行P1时的平均时钟周期数CPI为：10×800M/(200×106)=40。

在M2上执行P1时的平均时钟周期数CPI为：5×1.2G/(150×106)=40。</code></pre>
<p>（4）如果某个用户需要大量使用程序P1，并且该用户主要关心系统的响应时间而不是吞吐率，那么，该用户需要大批购进机器时，应该选择M1还是M2？为什么？（提示：从性价比上考虑）</p>
<pre><code>考虑运行P1时M1和M2的性价比，因为该用户主要关心系统的响应时间，所以性价比中的性能应考虑执行时间，其性能为执行时间的倒数。故性价比R为：

R=1/(执行时间×价格)

R越大说明性价比越高，也即，“执行时间×价格”的值越小，则性价比越高。

因为10×5000 &gt; 5×8000，所以，M2的性价比高。应选择M2。</code></pre>
<p>（5）如果另一个用户也需要购进大批机器，但该用户使用P1和P2一样多，主要关心的也是响应时间，那么，应该选择M1还是M2？为什么？</p>
<pre><code>P1和P2需要同等考虑，性能有多种方式：执行时间总和、算术平均、几何平均。

若用算术平均方式，则：因为 (10+0.003)/2×5000 &gt; (5+0.006)/2×8000，所以M2的性价比高，应选择M2。

若用几何平均方式，则：因为sqrt(10×0.003) ×5000 &lt; sqrt(5×0.006) ×8000，所以M1的性价比高，应选择M1。</code></pre>
<p>7．若机器M1和M2具有相同的指令集，其时钟频率分别为1GHz和1.5GHz。在指令集中有五种不同类型的指令A~E。下表给出了在M1和M2上每类指令的平均时钟周期数CPI。</p>
<table>
<thead>
<tr class="header">
<th>机器</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>M1</td>
<td>1</td>
<td>2</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr class="even">
<td>M2</td>
<td>2</td>
<td>2</td>
<td>4</td>
<td>5</td>
<td>6</td>
</tr>
</tbody>
</table>
<p>请回答下列问题： （1）M1和M2的峰值MIPS各是多少？</p>
<pre><code>M1上可以选择一段都是A类指令组成的程序，其峰值MIPS为1000MIPS。
M2上可以选择一段A和B类指令组成的程序，其峰值MIPS为1500/2=750MIPS。</code></pre>
<p>（2）假定某程序P的指令序列中，五类指令具有完全相同的指令条数，则程序P在M1和M2上运行时，哪台机器更快？快多少？在M1和M2上执行程序P时的平均时钟周期数CPI各是多少？</p>
<pre><code>5类指令具有完全相同的指令条数，所以各占20%。
在M1和M2上执行程序P时的平均时钟周期数CPI分别为：
    M1：20%×(1+2+2+3+4)= 0.2×12 = 2.4
    M2：20%×(2+2+4+5+6)= 0.2×19 = 3.8
假设程序P的指令条数为N，则在M1和M2上的执行时间分别为：
    M1：2.4× N×1/1G = 2.4N (ns)
    M2：3.8×N×1/1.5G = 2.53 N (ns)
M1执行P的速度更快，每条指令平均快0.13ns，也即M1比M2快0.13/2.53×100%≈5%。</code></pre>
<p>8．假设同一套指令集用不同的方法设计了两种机器M1和M2。机器M1的时钟周期为0.8ns，机器M2的时钟周期为1.2ns。某个程序P在机器M1上运行时的CPI为4，在M2上的CPI为2。对于程序P来说，哪台机器的执行速度更快？快多少？</p>
<pre><code>假设程序P的指令条数为N，则在M1和M2上的执行时间分别为：
    M1：4 N×0.8 = 3.2N (ns)
    M2：2 N×1.2 = 2.4 N (ns)  
所以，M2执行P的速度更快，每条指令平均快0.8ns，比M1快0.8/3.2×100%=25%。</code></pre>
<p>9．假设某机器M的时钟频率为4GHz，用户程序P在M上的指令条数为8×109，其CPI为1.25，则P在M上的执行时间是多少？若在机器M上从程序P开始启动到执行结束所需的时间是4秒，则P占用的CPU时间的百分比是多少？</p>
<pre><code>程序P在M上的执行时间为：1.25×8××1/4G = 2.5 s，
从启动P执行开始到执行结束的总时间为4秒，
其中2.5秒是P在CPU上真正的执行时间，
其他时间可能执行操作系统程序或其他用户程序。
程序P占用的CPU时间的百分比为：2.5/4 = 62.5%。</code></pre>
<p>10．假定某编译器对某段高级语言程序编译生成两种不同的指令序列S1和S2，在时钟频率为500MHz的机器M上运行，目标指令序列中用到的指令类型有A、B、C和D四类。四类指令在M上的CPI和两个指令序列所用的各类指令条数如下表所示。
| | A | B | C | D | |–| —|—|—|—| 各指令的CPI 1 2 3 4 S1的指令条数 5 2 2
1 S2的指令条数 1 1 1 5</p>
<p>请问：S1和S2各有多少条指令？CPI各为多少？所含的时钟周期数各为多少？执行时间各为多少？</p>
<pre><code>S1有10条指令，CPI为 (5×1+2×2+2×3+1×4)/10=1.9, 所含的时钟周期数为10×1.9=19，执行时间为19/500M = 38ns。
S2有8条指令，CPI为 (1×1+1×2+1×3+5×4)/8 =3.25, 所含的时钟周期数为8×3.25=26，执行时间为26/500M = 52ns。 </code></pre>
<p>10．假定机器M的时钟频率为1.2GHz，某程序P在机器M上的执行时间为12秒钟。对P优化时，将其所有的乘4指令都换成了一条左移2位的指令，得到优化后的程序P’。已知在M上乘法指令的CPI为5，左移指令的CPI为2，P的执行时间是P’执行时间的1.2倍，则P中有多少条乘法指令被替换成了左移指令被执行？
参考答案：
显然，P’的执行时间为10秒，因此，P比P’多花了2秒钟，因此，执行时被换成左移指令的乘法指令的条数为1.2G×2/(5–2)
= 800M。</p>
<h2 id="第二章计算机系统基本功能和基本组成">第二章计算机系统基本功能和基本组成</h2>
<p>1、见习题解答。</p>
<p>2、简单回答下列问题。</p>
<p>（1）为什么计算机内部采用二进制表示信息？既然计算机内部所有信息都用二进制表示，为什么还要用到十六进制或八进制数？</p>
<p>制造两个稳定状态的元器件比多个稳定状态的元器件要容易，两个稳定状态对应高低电平，正好可以用0/1表示；二进制编码规则简单，可用开关电路实现；方便通过逻辑电路实现算术运算。
二进制硬件容易理解，但是不方便书写和阅读。</p>
<p>（2）常用的定点数编码方式有哪几种？ 通常它们各自用来表示什么？</p>
<p>原码：用定点原码表示浮点数的尾数部分；</p>
<p>补码：带符号整数；</p>
<p>反码：</p>
<p>移码：</p>
<p>（3）为什么计算机中大多用补码表示带符号整数？</p>
<p>（4）在浮点数的基和位数一定的情况下，浮点数的表数范围和表数精度分别由什么决定？两者如何相互制约？</p>
<p>（5）为什么要对浮点数进行规格化？有哪两种规格化操作？</p>
<p>（6）为什么有些计算机中除了用二进制外还用 BCD 码来表示数值数据？</p>
<p>（7）为什么计算机处理汉字时会涉及到不同的编码（如，输入码、内码、字模码）？说明这些编码中哪些是用二进制编码，哪些不是用二进制编码，为什么？</p>
<p>3．实现下列各数的转换。 （1）(25.8125)10= (?)2= (?) 8= (?) 16</p>
<p>（2）(101101.011)2 = (?)10= (?) 8= (?) 16= (?) 8421</p>
<p>（3）(0101 1001 0110.0011)8421 = (?)10= (?) 2= (?) 16</p>
<p>（4）(4E.C)16 = (?)10= (?) 2</p>
<p>参考答案：</p>
<p>（1） (25.8125)10 = (1 1001.1101)2 = (31.64) 8 = (19.D) 16</p>
<p>（2）(101101.011)2 = (45.375)10 = (55.3) 8 = (2D.6) 16 = (0100
0101.0011 0111 0101) 8421</p>
<p>（3）(0101 1001 0110.0011)8421 = (596.3)10 =
(1001010100.01001100110011…) 2 = (254.4CCC…) 16</p>
<p>（4）(4E.C)16 = (78.75)10 = (0100 1110.11) 2</p>
<p>4．
假定机器数为8位（1位符号，7位数值），写出下列各二进制数的原码和补码表示。
+0.1001，–0.1001，+1.0，–1.0，+0.010100，–0.010100，+0，–0</p>
<p>参考答案： | 原码 | 补码 | |—– |—–| |+0.1001： 0.1001000 0.1001000
–0.1001： 1.1001000 1.0111000 +1.0： 溢出 溢出 –1.0： 溢出 1.0000000
+0.010100： 0.0101000 0.0101000 –0.010100： 1.0101000 1.1011000 +0：
0.0000000 0.0000000 –0： 1.0000000 0.0000000</p>
<p>5．
假定机器数为8位（1位符号，7位数值），写出下列各二进制数的补码和移码表示。
+1001，–1001，+1，–1，+10100，–10100，+0，–0 参考答案：<br>
移码 补码 +1001： 10001001 00001001 –1001： 01110111 11110111 +1：
10000001 00000001 –1： 011111111 11111111 +10100： 10010100 00010100
–10100： 01101100 11101100 +0： 10000000 00000000 –0： 10000000
00000000</p>
<p>6． 已知 [x]补，求x （1）[x]补=1.1100111 （2）[x]补=10000000
（3）[x]补=0.1010010 （4）[x]补=11010011 参考答案： （1）[x]补=1.1100111
x = –0.0011001B （2）[x]补=10000000 x = –10000000B = –128
（3）[x]补=0.1010010 x = +0.101001B （4）[x]补=11010011 x = – 101101B =
– 45</p>
<p>7．假定一台32位字长的机器中带符号整数用补码表示，浮点数用IEEE
754标准表示，寄存器R1和R2的内容分别为R1：0000108BH，R2：8080108BH。不同指令对寄存器进行不同的操作，因而，不同指令执行时寄存器内容对应的真值不同。假定执行下列运算指令时，操作数为寄存器R1和R2的内容，则R1和R2中操作数的真值分别为多少？
（1）无符号数加法指令 （2）带符号整数乘法指令 （3）单精度浮点数减法指令
参考答案： R1 = 0000108BH = 0000 0000 0000 0000 0001 0000 1000 1011b R2
= 8080108BH = 1000 0000 1000 0000 0001 0000 1000 1011b
（1）对于无符号数加法指令，R1和R2中是操作数的无符号数表示，因此，其真值分别为R1：108BH,
R2：8080108BH。
（2）对于带符号整数乘法指令，R1和R2中是操作数的带符号整数补码表示，由最高位可知，
R1为正数， R2为负数。R1的真值为+108BH, R2的真值为–(0111 1111 0111 1111
1110 1111 0111 0100b + 1b) = –7F7FEF75H。
（3）对于单精度浮点数减法指令，R1和R2中是操作数的IEEE754单精度浮点数表示。在IEEE
754
标准中，单精度浮点数的位数为32位，其中包含1位符号位，8位阶码，23位尾数。
由R1中的内容可知，其符号位为0，表示其为正数，阶码为0000
0000，尾数部分为000 0000 0001 0000 1000
1011，故其为非规格化浮点数，指数为–126，尾数中没有隐藏的1，用十六进制表示尾数为+0.002116H，故R1表示的真值为+0.002116H
× 10-126。 由R2中的内容可知，其符号位为1，表示其为负数，阶码为0000
0001， 尾数部分为000 0000 0001 0000 1000
1011，故其为规格化浮点数，指数为1–127 =
–126，尾数中有隐藏的1，用十六进制表示尾数为–1.002116H，故R2表示的真值为–1.002116H
× 10-126</p>
<p>8．假定机器M的字长为32位，用补码表示带符号整数。下表第一列给出了在机器M上执行的C语言程序中的关系表达式，请参照已有的表栏内容完成表中后三栏内容的填写。
关系表达式 运算类型 结果 说明 0 == 0U –1 &lt; 0 –1 &lt; 0U 2147483647
&gt; –2147483647 – 1 2147483647U &gt; –2147483647 – 1 2147483647 &gt;
(int) 2147483648U –1 &gt; –2 (unsigned) –1 &gt; –2 无符号整数 有符号整数
无符号整数 有符号整数 无符号整数 有符号整数 有符号整数 无符号整数 1 1 0
1 0 1 1 1 00…0B = 00…0B 11…1B (–1) &lt; 00…0B (0) 11…1B (232–1) &gt;
00…0B(0) 011…1B (231–1) &gt; 100…0B (–231) 011…1B (231–1) &lt;
100…0B(231) 011…1B (231–1) &gt; 100…0B (–231) 11…1B (–1) &gt; 11…10B
(–2) 11…1B (232–1) &gt; 11…10B (232–2)</p>
<p>9．以下是一个C语言程序，用来计算一个数组a中每个元素的和。当参数len为0时，返回值应该是0，但是在机器上执行时，却发生了存储器访问异常。请问这是什么原因造成的，并说明程序应该如何修改。
1 float sum_elements(float a[], unsigned len) 2 { 3 int i; 4 float
result = 0; 5 6 for (i = 0; i &lt;= len–1; i++) 7 result += a[i]; 8
return result; 9 }</p>
<p>参考答案：
参数len的类型是unsigned，所以，当len=0时，执行len-1的结果为11…1，是最大可表示的无符号数，因而，任何无符号数都比它小，使得循环体被不断执行，引起数组元素的访问越界，发生存储器访问异常。
只要将len声明为int型，或循环的测试条件改为i&lt;len。</p>
<ol type="1">
<li>设某浮点数格式为：</li>
</ol>
<p>其中，移码的偏置常数为16，补码采用一位符号位，基数为4。
（1）用这种格式表示下列十进制数：+1.7，–0.12，+19，–1/8。
（2）写出该格式浮点数的表示范围，并与12位定点补码整数表示范围比较。
参考答案：（假定采用0舍1入法进行舍入） （1） +1.7 = +1.1011001B =
0.011011B× 41, 故阶码为1 +16 = 17 = 10001B, 尾数为+0.011011的补码，
即0.011011，所以+1.7表示为0 10001 011011。</p>
<pre><code>–0.12 = – 0.000111101B = – 0.011111B × 4–1, 故阶码为 –1 + 16 =15 = 01111B, 尾数为– 0.011111的补码，即1.100001, 所以–0.12表示为1 01111 100001。

+19 = +10011B = 0.010011B× 43，故阶码为3 + 16 = 19 = 10011B, 尾数为0.010011，所以+19表示为0 10011 010011。

–1/8 = – 0.125 = – 0.001B = – 0.100000 × 4–1，阶码为 –1 + 16 = 15 = 01111B，尾数为– 0.100000的补码，即1.100000，所以–1/8表示为1 01111 100000。</code></pre>
<p>（2）该格式浮点数表示的范围如下。 正数最大值：0.111111B ×
411111，即：0.333× 415 （≈230 ≈109） 正数最小值：0.000001B ×
400000，即：0.001× 4–16 （≈2–34≈10–10） 负数最大值：–0.000001B ×
400000，即：–0.001× 4–16 负数最小值：–1.000000B × 411111，即：–1.000×
415 因此，该格式浮点数的数量级在10–10～109之间。
12位定点补码整数的表示范围为：–211～+(211–1)，即：–2048～2047
由此可见，定点数和浮点数的表示范围相差非常大。</p>
<ol start="11" type="1">
<li><p>下列几种情况所能表示的数的范围是什么？ （1）16位无符号整数
（2）16位原码定点小数 （3）16位补码定点小数 （4）16位补码定点整数
（5）下述格式的浮点数（基数为2，移码的偏置常数为128）</p>
<p>参考答案： （1）无符号整数：0～216–1。 （2）原码定点小数：–(1–2–15)
～ + (1–2–15)。 （3）补码定点小数：–1 ～ + (1–2–15)。
（4）补码定点整数：–32768 ～ +32767。 （5）浮点数：负数：– (1–2–7)×2+127
～ –2–7×2–128。 正数：+2–135 ～ (1–2–7) ×2+127。</p></li>
<li><p>以IEEE 754单精度浮点数格式表示下列十进制数。
+1.75，+19，–1/8，258 参考答案： +1.75 = +1.11B = 1.11B × 20,
故阶码为0+127=01111111B,
数符为0，尾数为1.110…0，小数点前为隐藏位，所以+1.7表示为0 01111111 110
0000 0000 0000 0000 0000，用十六进制表示为3FE00000H。</p>
<p>+19 = +10011B = +1.0011B × 24，故阶码为4+127 = 10000011B,
数符为0，尾数为1.00110…0，所以+19表示为0 10000011 001 1000 0000 0000
0000 0000，用十六进制表示为41980000H。</p>
<p>–1/8 = – 0.125 = – 0.001B = – 1.0 × 2–3，阶码为–3+127 =
01111100B，数符为1，尾数为1.0…0，所以–1/8表示为1 01111100 000 0000 0000
0000 0000 0000，用十六进制表示为BE000000H。</p></li>
</ol>
<p>258=100000010B=1.0000001B × 28, 故阶码为8+127=10000111B,
数符为0，尾数为1.0000001，所以258表示为0 10000111 000 0001 0000 0000
0000 0000，用十六进制表示为43810000H。</p>
<p>13．设一个变量的值为4098，要求分别用32位补码整数和IEEE
754单精度浮点格式表示该变量（结果用十六进制表示），并说明哪段二进制序列在两种表示中完全相同，为什么会相同？
参考答案： 4098 = +1 0000 0000 0010B = +1. 0000 0000 001 × 212
32位2-补码形式为：0000 0000 0000 0000 0001 0000 0000 0010 （00001002H）
IEEE754单精度格式为：0 10001011 0000 0000 0010 0000 0000 000
（45801000H）
粗体部分为除隐藏位外的有效数字，因此，在两种表示中是相同的序列。</p>
<p>14．设一个变量的值为–2147483647，要求分别用32位补码整数和IEEE754单精度浮点格式表示该变量（结果用十六进制表示），并说明哪种表示其值完全精确，哪种表示的是近似值。
参考答案： –2147483647 = –111 1111 1111 1111 1111 1111 1111 1111B =
–1.11 1111 1111 1111 1111 1111 1111 1111 × 230 32位2-补码形式为：1000
0000 0000 0000 0000 0000 0000 0001 （80000001H） IEEE 754单精度格式为：1
10011101 1111 1111 1111 1111 1111 111 （CEFFFFFFH）
32位2-补码形式能表示精确的值，而浮点数表示的是近似值，低位被截断</p>
<p>15．下表给出了有关IEEE
754浮点格式表示中一些重要数据的取值，表中已经有最大规格化数的相应内容，要求填入其他浮点数的相应内容。（注：表中a代表一个在1到10之间的正纯小数）
项目 阶码 尾数 单精度 双精度 以2的幂次表示的值 以10的幂次表示的值
以2的幂次表示的值 以10的幂次表示的值 0 1 最大规格化数 最小规格化数
最大非规格化数 最小非规格化数 +∞ NaN 00000000 01111111 11111110 00000001
00000000 00000000 11111111 11111111 0….00 0….00 1…11 0….00 1…11 0…01
0….00 非全0 0 1 (2–2–23)×2127 1.0×2–126 (1–2–23)×2–126 2–23×2–126=2–149
– – 0 1 a×1038 a×10–38 a×10–38 a×10–44 – – 0 1 (2–2–52)×21023 1.0×2–1022
(1–2–52)×2–1022 2–52×2–1022 – – 0 1 a×10308 a×10–308 a×10–308 a×10–? –
–</p>
<p>16．已知下列字符编码：A=100 0001，a=110 0001，0=011
0000，求E、e、f、7、G、Z、5的7位ACSII码和第一位前加入奇校验位后的8位编码。
参考答案： E的ASCII码为 ‘A’ + (‘E’ – ‘A’) = 100 0001 + 100 = 100 0101,
奇校验位P = 0，第一位前加入奇校验位后的8位编码是0 100 0101。
e的ASCII码为‘a’+ (‘e’ – ‘a’) = 110 0001 + 100 = 110 0101， 奇校验位P =
1, 第一位前加入奇校验位后的8位编码是1 110 0101。 f的ASCII码为‘a’+ (‘f’ –
‘a’) = 110 0001 + 101 = 110 0110, 奇校验位P = 1, 第一位前
加入奇校验位后的8位编码是 1 110 0110。 7的ASCII码为‘0’+ (7 - 0) = 011
0000 + 111 = 011 0111,奇校验位P = 0, 第一位前加入奇校验位后的8位编码是0
011 0111。 G的ASCII码为‘A’+ (‘G’ – ‘A’) = 100 0001 + 0110 = 100 0111,
奇校验位P = 1, 第一位前加入奇校验位后的8位编码是1 100 0111。
Z的ASCII码为‘A’+(‘Z’ – ‘A’) = 100 0001 + 11001 = 101 1010, 奇校验位P =
1, 第一位前加入奇校验位后的8位编码是 1 101 1010。 5的ASCII码为‘0’+(5 –
0) = 011 0000 + 101 = 011 0101， 奇校验位P = 1,
第一位前加入奇校验位后的8位编码是 1 011 0101。</p>
<p>17．假定在一个程序中定义了变量x、y和i，其中，x和y是float型变量（用IEEE754单精度浮点数表示），i是16位short型变量（用补码表示）。程序执行到某一时刻，x
=
–0.125、y=7.5、i=100，它们都被写到了主存（按字节编址），其地址分别是100，108和112。请分别画出在大端机器和小端机器上变量x、y和i在内存的存放位置。
参考答案： –0.125 = –0.001B = –1.0 × 2-3 x在机器内部的机器数为：1
01111100 00…0 (BE00 0000H) 7.5= +111.1B= +1.111 × 22
y在机器内部的机器数为：0 10000001 11100…0 (40F0 0000H)
100=64+32+4=1100100B i在机器内部表示的机器数为：0000 0000 0110
0100（0064H） 大端机 小端机 地址 内容 内容<br>
100 BEH 00H 101 00H 00H 102 00H 00H 103 00H BEH 108 40H 00H 109 F0H 00H
110 00H F0H 111 00H 40H 112 00H 64H 113 64H 00H</p>
<p>18．假定某计算机的总线采用奇校验，每8位数据有一位校验位，若在32位数据线上传输的信息是8F
3C AB
96H，则对应的4个校验位应为什么？若接受方收到的数据信息和校验位分别为87
3C AB 96H和0101B，则说明发生了什么情况，并给出验证过程。 参考答案：
传输信息8F 3C AB 96H展开为1000 1111 0011 1100 1010 1011 1001
0110，每8位有一个奇校验位，因此，总线上发送方送出的4个校验位应该分别为0、1、0、1。
接受方的数据信息为87 3C AB 96H，展开后为1000 0111 0011 1100 1010 1011
1001 0110；接收到的校验位分别为0、1、0、1。在接受方进行校验判断如下：
根据接收到的数据信息计算出4个奇校验位分别为1、1、0、1，将该4位校验位分别和接收到的4位校验位进行异或，得到1、0、0、0，说明数据信息的第一个字节发生传输错误。对照传输前、后的数据信息，第一字节8FH变成了87H，说明确实发生了传输错误，验证正确。</p>
<p>19．写出16位数据的SEC码。假定数据为0101 0001 0100
0110，说明SEC码如何正确检测数据位5的错误。 参考答案： 对于16位数据，
可以如下插入校验位： M16 M15 M14 M13 M12 P5 M11 M10 M9 M8 M7 M6 M5 P4 M4
M3 M2 P3 M1 P2 P1 其中Mi是原信息数据， Pi是加入的校验位，
对于各个校验位的值可以如下计算 P1 = M1⊕M2⊕M3⊕M4⊕M5⊕M7⊕M9⊕M11⊕M12⊕M14⊕M16
= 1 P2 = M1⊕M3⊕M4⊕M6⊕M7⊕M10⊕M11⊕M13⊕M14 = 1 P3 =
M2⊕M3⊕M4⊕M8⊕M9⊕M10⊕M11⊕M15⊕M16 = 0 P4 = M5⊕M6⊕M7⊕M8⊕M9⊕M10⊕M11 = 0 P5 =
M12⊕M13⊕M14⊕M15⊕M16 = 0 所以此时P5 P4 P3 P2 P1 =
00011，第五位数据出错时，数据字变为：0101 0001 0101
0110，P5’P4’P3’P2’P1’= 01010，故障字 = 00011⊕01010 =
01001，说明码字第9位出错，即M5出错。</p>
<p>20．假设要传送的数据信息为：100011，若约定的生成多项式为：G(x)=
x3+1，则校验码为多少？假定在接收端接收到的数据信息为100010，说明如何正确检测其错误，写出检测过程。</p>
<p>参考答案： 原数据信息为100011，对应的报文多项式为M(x) = x5 + x + 1,
生成多项式的位数为4位， 所以在原数据信息后面添加3个0，变为M’(x) = x3M(x)
= x8 + x4 + x3, 用M(x)去模2除G(x)，得到的余数为111，
所以得到CRC码为100011 111。</p>
<pre><code>检测时， 用接收到的CRC码去模2除生成多项式1001，若得到的余数为0，则表明正确，否则说明传输时发生了错误。此题中接收到的CRC码为100010 111（即数据100010加检验位111），显然，用100010 111 模2除 1001，得到余数为001，不为0，说明传输时发生错误。</code></pre>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——第二次上机——数据预处理基础</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="机器学习数据预处理基础">机器学习数据预处理基础</h1>
<h1 id="one-hot编码">1. One-Hot编码</h1>
<h2 id="任务介绍">任务介绍</h2>
<ul>
<li>使用Pandas中的value_counts()函数，查看data中的特征User
continent的取值类型， 并打印输出的内容；</li>
<li>使用pandas中的get_dummies()函数对data中的特征User
continent进行One-Hot编码，参数prefix为User continent_；</li>
<li>将编码后的结果保存在encode_uc中，并输出变量的前5行内容。</li>
</ul>
<h2 id="预期实验结果">预期实验结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/bac5b83fc21a435fabddd64a5ab463600c7d80dc00e44fd6ae1715ae25355db6">
<img src="https://ai-studio-static-online.cdn.bcebos.com/2f183364e29348079537f8ad38d9489004d4498e9b5d483fa9432f2bae06654e"></p>
<blockquote>
<p>补全代码;</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># value_counts() 函数统计并输出 &quot;User continent&quot; 列中各大陆出现的次数</span></span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;User continent&#x27;</span>].value_counts())</span><br><span class="line"><span class="comment"># 使用 get_dummies() 对 &quot;User continent&quot; 列进行 One-Hot 编码</span></span><br><span class="line"><span class="comment"># One-hot编码是一种将类别变量转换为多个二进制特征列的技术，</span></span><br><span class="line"><span class="comment"># 每个类别对应一列，如果该行数据属于该类别则取值为1，否则为0</span></span><br><span class="line">encode_uc = pd.get_dummies(data[<span class="string">&#x27;User continent&#x27;</span>], prefix=<span class="string">&#x27;User continent_&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(encode_uc)</span><br></pre></td></tr></table></figure>
<p>​ User continent ​ North America 296 ​ Europe 118 ​ Oceania 41 ​ Asia 36 ​
Africa 7 ​ South America 6 ​ Name: count, dtype: int64 ​ User
continent__Africa User continent__Asia User continent__Europe<br>
​0 False False False<br>
​1 False False False<br>
​2 False False False<br>
​3 False False True<br>
​4 False False False<br>
​.. … … …<br>
​499 False False True<br>
​500 False False False<br>
​501 False False False<br>
​502 False False False<br>
​503 False False False<br>
​<br>
​User continent__North America User continent__Oceania<br>
​0 True False<br>
​1 True False<br>
​2 True False<br>
​3 False False<br>
​4 True False<br>
​.. … …<br>
​499 False False<br>
​500 True False<br>
​501 True False<br>
​502 True False<br>
​503 True False<br>
​<br>
​User continent__South America<br>
​0 False<br>
​1 False<br>
​2 False<br>
​3 False<br>
​4 False<br>
​.. …<br>
​499 False<br>
​500 False<br>
​501 False<br>
​502 False<br>
​503 False<br>
​<br>
​[504 rows x 6 columns] ​</p>
<h1 id="缺失值填补">2. 缺失值填补</h1>
<h2 id="任务介绍-1">任务介绍</h2>
<ul>
<li>使用pandas中的value_counts()函数打印输出data中的特征Traveler
type的取值统计信息， 并查看其是否含有缺失值；</li>
<li>如果存在缺失值，将特征Traveler
type在其他样本中取值频数最多的值保存在变量freq_v中，并使用freq_v进行缺失值填充；</li>
<li>再次打印输出特征Traveler type的取值统计信息。</li>
</ul>
<h2 id="预期实验结果-1">预期实验结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/573d921570d34dc08c44f863ee8732f8d5816c88af7b467aa8cae7a2ce188129"></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># value_counts(dropna=False) 会包括缺失值（NaN）在内</span></span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;Traveler type&#x27;</span>].value_counts(dropna=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># idxmax()会获取频数最多的取值</span></span><br><span class="line">freq_v = data[<span class="string">&#x27;Traveler type&#x27;</span>].value_counts().idxmax()</span><br><span class="line"></span><br><span class="line"><span class="comment"># freq_v会替代缺失值</span></span><br><span class="line">data[<span class="string">&#x27;Traveler type&#x27;</span>] = data[<span class="string">&#x27;Traveler type&#x27;</span>].fillna(freq_v)</span><br><span class="line"></span><br><span class="line"><span class="comment">### 打印</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&#x27;缺失值填充完之后：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;Traveler type&#x27;</span>].value_counts(dropna=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure>
<h1 id="特征标准化">3. 特征标准化</h1>
<h2 id="任务1">任务1:</h2>
<ul>
<li>使用sklearn中preprocessing模块下的StandardScaler()函数对data的特征Score进行Z-score标准化；</li>
<li>将特征取值的均值保存在变量score_mean中，并打印；</li>
<li>将特征取值的方差保存在变量score_var中，并打印。</li>
</ul>
<h2 id="预期实验结果-2">预期实验结果</h2>
<figure>
<img src="/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/fa64d89b-3dc9-4b07-b27f-210b56e583ed-1741258230441-1.png" alt="fa64d89b-3dc9-4b07-b27f-210b56e583ed">
<figcaption aria-hidden="true">fa64d89b-3dc9-4b07-b27f-210b56e583ed</figcaption>
</figure>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="comment"># sklearn是一个用于机器学习的Python库，提供了各种分类、回归、聚类算法，</span></span><br><span class="line"><span class="comment"># 包括支持向量机、随机森林、梯度提升等。它还包含了用于数据预处理、特征提取和模型选择的工具。</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment">## 创建Z-score对象</span></span><br><span class="line"><span class="comment">## Z-score标准化是一种将数据转换为均值为0，标准差为1的标准正态分布的方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 初始化StandardScaler对象，用于执行Z-score标准化</span></span><br><span class="line">std_scaler = StandardScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment">## Score特征标准化，使用fit_transform()方法</span></span><br><span class="line"><span class="comment"># fit_transform() 会先计算出该特征的均值和标准差，然后进行标准化</span></span><br><span class="line">normal_df = std_scaler.fit_transform(data[[<span class="string">&#x27;Score&#x27;</span>]])  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 均值</span></span><br><span class="line"><span class="comment"># StandardScaler 会自动计算并存储 &#x27;Score&#x27; 列的均值，这个值在标准化过程中用来进行数据转换</span></span><br><span class="line">score_mean = std_scaler.mean_</span><br><span class="line"></span><br><span class="line"><span class="comment">## 方差</span></span><br><span class="line"><span class="comment"># 方差也是 StandardScaler 会计算的一个参数，表示数据的离散程度</span></span><br><span class="line">score_var = std_scaler.var_</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印</span></span><br><span class="line"><span class="built_in">print</span> (score_mean)</span><br><span class="line"><span class="built_in">print</span> (score_var)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印前五行内容</span></span><br><span class="line">normal_df[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p>​ [4.12301587] ​ [1.01264487] ​</p>
<p>​ array([[ 0.87149149], ​ [-1.11598231], ​ [ 0.87149149], ​
[-0.12224541], ​ [-0.12224541]])</p>
<h2 id="任务2">任务2：</h2>
<ul>
<li>自定义函数min_max()实现MinMax标准化，输入参数data为要进行标准化的数据，输出为标准化后的数据。</li>
<li>使自定义的min_max()函数对data的特征Score进行MinMax标准化，输出结果保存在score_transformed中，并打印变量的前5行内容</li>
</ul>
<h2 id="预期结果">预期结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/98a830f8c5594920883029b03ae2882f516aef4a6af244ff93061ef21aa09836"></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">min_max</span>(<span class="params">data</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 最小值</span></span><br><span class="line">    data_min = data.<span class="built_in">min</span>()</span><br><span class="line">    <span class="comment">## 最大值</span></span><br><span class="line">    data_max = data.<span class="built_in">max</span>()</span><br><span class="line">    <span class="comment">## 最大值与最小值之间的差值</span></span><br><span class="line">    data_range=data_max-data_min</span><br><span class="line">    <span class="comment">## 根据MinMax标准化的定义实现</span></span><br><span class="line">    <span class="comment">#MinMax 标准化（最小-最大标准化）是一种数据预处理方法，</span></span><br><span class="line">    <span class="comment"># 旨在将数据的所有特征（列）缩放到一个指定的范围，通常是 [0, 1]。</span></span><br><span class="line">    <span class="comment"># 这种标准化方法将原始数据通过线性变换映射到新的范围。</span></span><br><span class="line">    new_data = (data-data_min)/data_range<span class="comment"># MinMax标准化公式： (x - min) / (max - min)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 返回结果</span></span><br><span class="line">    <span class="keyword">return</span> new_data</span><br><span class="line"></span><br><span class="line"><span class="comment">## 调用min_max()函数</span></span><br><span class="line">score_transformed = min_max(data[<span class="string">&#x27;Score&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印变量的前5行内容</span></span><br><span class="line">score_transformed.head()</span><br></pre></td></tr></table></figure>
<p>​ 0 1.00 ​ 1 0.50 ​ 2 1.00 ​ 3 0.75 ​ 4 0.75 ​ Name: Score, dtype:
float64</p>
<h2 id="任务3">任务3：</h2>
<ul>
<li>自定义logistic()函数，输入参数为要进行标准化的数据，输出结果为经过标准化后的数据；</li>
<li>使用自定义函数对data的特征Member
years进行Logsitic标准化，结果保存在member_transformed中，并输出变量的前5行内容。</li>
</ul>
<h2 id="预期结果-1">预期结果：</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/22fd81b1a5614b418f88cbe90bf7f99ba6c553820c2542be80f1a90421779026"></p>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ogistic 标准化（Logistic Normalization）是一个将数据转换为 (0, 1) 范围的过程，</span></span><br><span class="line"><span class="comment"># 通常使用 Logistic 函数（也称为 Sigmoid 函数）。</span></span><br><span class="line"><span class="comment"># 它是一种非线性转换方法，常用于神经网络和其他需要将数据映射到概率范围的场景。</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">logistic</span>(<span class="params">data</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    <span class="keyword">import</span> warnings</span><br><span class="line">    warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 计算 1 + e^(-x)</span></span><br><span class="line">    denominator = <span class="number">1</span>+ np.exp(-data)<span class="comment"># 使用 np.exp() 计算 e^(-x)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 实现logistic标准化</span></span><br><span class="line">    new_data = <span class="number">1</span>/denominator</span><br><span class="line">    <span class="comment">## 返回结果</span></span><br><span class="line">    <span class="keyword">return</span> new_data</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对特征Member years进行logsitic标准化</span></span><br><span class="line">member_transformed = logistic(data[<span class="string">&#x27;Member years&#x27;</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印内容</span></span><br><span class="line">member_transformed.head()</span><br></pre></td></tr></table></figure>
<p>​ 0 0.999877 ​ 1 0.952574 ​ 2 0.880797 ​ 3 0.997527 ​ 4 0.999089 ​ Name:
Member years, dtype: float64</p>
<h1 id="特征离散化">4. 特征离散化</h1>
<h2 id="任务介绍-2">任务介绍</h2>
<ul>
<li>使用Pandas的qcut()函数对data中的特征Member
years进行等频离散化，结果保存在bins中；</li>
<li>使用pd.value_counts()函数统计categorical对象bins的取值信息。</li>
</ul>
<h2 id="预期结果-2">预期结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/a4729a315ee6483687f3a819d01d905b025fa5f90da04f3e893a7a80ce5e5107"></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 返回bins</span></span><br><span class="line"><span class="comment"># q=4 表示将数据分成 4 个区间</span></span><br><span class="line">bins = pd.qcut(data[<span class="string">&#x27;Member years&#x27;</span>], q=<span class="number">4</span>, labels=[<span class="string">&quot;(-1806.001, 2.0]&quot;</span>, <span class="string">&quot;(2.0, 4.0]&quot;</span>, <span class="string">&quot;(4.0, 6.0]&quot;</span>, <span class="string">&quot;(6.0, 13.0]&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 统计取值信息</span></span><br><span class="line"><span class="comment"># 使用value_counts()函数统计bins中每个类别的数量，得到离散化后的各个类别的分布情况</span></span><br><span class="line">value_counts = pd.value_counts(bins)  </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(value_counts)</span><br></pre></td></tr></table></figure>
<p>​ Member years ​ (-1806.001, 2.0] 156 ​ (6.0, 13.0] 124 ​ (2.0, 4.0] 123 ​
(4.0, 6.0] 101 ​ Name: count, dtype: int64 ​</p>
<h1 id="离群值检测">5. 离群值检测</h1>
<h2 id="任务介绍-3">任务介绍</h2>
<ul>
<li>使用拉依达准则对data的特征Member years进行离群值检测；</li>
<li>如果存在离群值，输出离群值的个数outlier_num，并将包含离群值的数据记录保存在变量outeliers中，并打印变量内容。</li>
</ul>
<h2 id="预期结果-3">预期结果</h2>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/40e316267fc542339a74291e8438e340109ece96fc2a439591b75414e12085d2"></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取csv文件到DataFrame</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取&#x27;Member years&#x27;这一列</span></span><br><span class="line">member_data = data[[<span class="string">&#x27;Member years&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">拉伊达准则</span></span><br><span class="line"><span class="string">计算四分位数（Q1 和 Q3）：计算Member years特征的第25百分位数（Q1）和第75百分位数（Q3）。</span></span><br><span class="line"><span class="string">计算IQR（Interquartile Range）：IQR = Q3 - Q1。</span></span><br><span class="line"><span class="string">判断离群值：低于 Q1 - 1.5 * IQR 或高于 Q3 + 1.5 * IQR 的数据点视为离群值。</span></span><br><span class="line"><span class="string">统计离群值的个数，并提取包含离群值的记录。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算四分位数</span></span><br><span class="line">Q1 = member_data[<span class="string">&#x27;Member years&#x27;</span>].quantile(<span class="number">0.25</span>)  <span class="comment"># 第25百分位数</span></span><br><span class="line">Q3 = member_data[<span class="string">&#x27;Member years&#x27;</span>].quantile(<span class="number">0.75</span>)  <span class="comment"># 第75百分位数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算IQR（四分位间距）</span></span><br><span class="line">IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写出过滤条件：低于 Q1 - 1.5 * IQR 或 高于 Q3 + 1.5 * IQR 的值为离群值</span></span><br><span class="line">outlier_judge = (member_data[<span class="string">&#x27;Member years&#x27;</span>] &lt; (Q1 - <span class="number">1.5</span> * IQR)) | (member_data[<span class="string">&#x27;Member years&#x27;</span>] &gt; (Q3 + <span class="number">1.5</span> * IQR))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计离群值的个数</span></span><br><span class="line">outlier_num = outlier_judge.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取包含离群值的样本记录</span></span><br><span class="line">outliers = data[outlier_judge]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印离群值记录</span></span><br><span class="line"><span class="built_in">print</span>(outliers)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​ User country User continent Member years Traveler type<br>
​75 USA North America -1806 Solo<br>
​143 USA North America 13 Couples<br>
​<br>
​Hotel name Hotel stars Nr. rooms Score<br>
​75 Treasure Island- TI Hotel &amp; Casino 4.0 2884 5<br>
​143 Caesars Palace 5.0 3348 4<br>
​</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机3——线性回归（医疗保险费预测）</title>
    <url>/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="线性回归">线性回归</h1>
<h2 id="任务1.-一元线性回归">任务1. 一元线性回归</h2>
<h3 id="任务介绍">任务介绍：</h3>
<ul>
<li>自定义一元回归函数MyLinearRegression()，输入参数为x和y的数组xArr和yArr，输出为参数w1和w0，利用最小二乘法求得参数;</li>
<li>使用美国医疗保险费数据insurance.csv中的输入特征age和目标特征charges，输入MyLinearRegression()函数，得到回归参数值w1和w0，并保留到小数点后两位;</li>
<li>调用sklearn的LinearRegression()函数，比较其运行结果与上述自定义函数MyLinearRegression()的输出结果是否一致。</li>
<li>利用age与charges绘制真实样本点，利用w1与w0计算预测值，再绘制age与预测值的点图，观察真实样本点与预测点之间的拟合程度。</li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line">age = insurance[<span class="string">&#x27;age&#x27;</span>].values</span><br><span class="line">charges = insurance[<span class="string">&#x27;charges&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 定义一元线性回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># x均值, y均值计算</span></span><br><span class="line">    mean_x = xArr.mean()</span><br><span class="line">    mean_y = yArr.mean()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># w0, w1计算，公式</span></span><br><span class="line">    numerator = np.<span class="built_in">sum</span>((xArr - mean_x) * (yArr - mean_y))</span><br><span class="line">    denominator = np.<span class="built_in">sum</span>((xArr - mean_x)**<span class="number">2</span>)</span><br><span class="line">    w1 = numerator / denominator</span><br><span class="line">    w0 = mean_y - w1 * mean_x</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(w0,<span class="number">2</span>), <span class="built_in">round</span>(w1,<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型训练，得到参数值&quot;</span>)</span><br><span class="line">w0, w1 = MyLinearRegression(age, charges)</span><br><span class="line"><span class="built_in">print</span>(w1,<span class="string">&#x27;\n&#x27;</span>, w0)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sklearn的训练结果&quot;</span>)</span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment">#线性回归模型训练</span></span><br><span class="line">lr.fit(age.reshape(-<span class="number">1</span>, <span class="number">1</span>), charges)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.coef_[<span class="number">0</span>],<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.intercept_,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 观察真实样本点与预测点之间的拟合程度</span></span><br><span class="line">plt.scatter(age, charges, marker=<span class="string">&#x27;.&#x27;</span>)  <span class="comment"># 画样本点，随机散点</span></span><br><span class="line"><span class="comment"># 利用w1与w0计算预测值，绘制预测点</span></span><br><span class="line">plt.scatter(age, w1 * age + w0, marker=<span class="string">&#x27;+&#x27;</span>)  <span class="comment"># 画预测点，形成直线</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>模型训练，得到参数值
257.72 
 3165.89
sklearn的训练结果
257.72
3165.89</code></pre>
<figure>
<img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/main_2_1.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<h3 id="最小二乘法求解公式"><strong>最小二乘法求解公式</strong></h3>
<p><strong>目标</strong>：最小化预测值与真实值的平方误差之和： <span class="math display">$$ \min_{w_0, w_1} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$</span></p>
<p><strong>闭式解（Normal Equation）</strong>：<br>
1. <strong>斜率 ( w_1 )</strong>：<br>
<span class="math display">$$ w_1 = \frac{\sum_{i=1}^n (x_i -
\bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} $$</span><br>
其中 ({x}) 和 ({y}) 分别是 (x) 和 (y) 的均值。</p>
<ol start="2" type="1">
<li><strong>截距 ( w_0 )</strong>：<br>
<span class="math display"><em>w</em><sub>0</sub> = <em>ȳ</em> − <em>w</em><sub>1</sub><em>x̄</em></span></li>
</ol>
<p>round(w0, 2) 和 round(w1, 2)
的作用是对线性回归模型的参数进行四舍五入处理，保留两位小数。</p>
<p>这段代码使用 <code>scikit-learn</code> 的
<code>LinearRegression</code>
类实现线性回归，并输出模型参数。以下是逐行解释： ### 1.
<strong>创建线性回归模型实例</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr = LinearRegression()</span><br></pre></td></tr></table></figure> -
<code>LinearRegression()</code> 是 <code>scikit-learn</code>
中用于线性回归的类。 - <code>lr</code>
是该类的一个实例，后续通过它调用模型训练、预测等方法。 ### 2.
<strong>模型训练</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr.fit(age.reshape(-<span class="number">1</span>, <span class="number">1</span>), charges)</span><br></pre></td></tr></table></figure> -
<strong>作用</strong>：用输入数据 <code>age</code>（特征）和
<code>charges</code>（目标值）训练线性回归模型。 -
<strong>关键细节</strong>： - <code>age</code> 是一维数组（形状如
<code>(n,)</code>），但 <code>scikit-learn</code>
要求输入特征为二维数组（形状如 <code>(n, 1)</code>）。 -
<code>age.reshape(-1, 1)</code>
将一维数组转换为二维列向量（<code>n</code> 行 1 列），确保输入格式正确。
- <code>charges</code> 是目标值的一维数组，无需调整形状。 ### 3.
<strong>输出模型参数</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.coef_[<span class="number">0</span>], <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.intercept_, <span class="number">2</span>))</span><br></pre></td></tr></table></figure> -
<strong><code>lr.coef_</code></strong>： - 存储模型的回归系数（即
<code>w1</code>，特征权重）。 - 对于一元线性回归，<code>coef_</code>
是一个包含单个元素的数组（如 <code>[w1]</code>），因此用
<code>coef_[0]</code> 提取数值。 -
<strong><code>lr.intercept_</code></strong>： - 存储模型的截距项（即
<code>w0</code>）。 - 直接通过 <code>intercept_</code> 访问，无需索引。
-
<strong><code>round(..., 2)</code></strong>：将参数四舍五入保留两位小数，便于与自定义函数结果对比。</p>
<h2 id="任务2.-多元线性回归">任务2. 多元线性回归</h2>
<h3 id="任务介绍-1">任务介绍：</h3>
<ul>
<li>自定义多元线性回归函数MyLinearRegression2()，输入参数为X和y的数组xArr和yArr，输出为参数ws，利用最小二乘法求得参数;</li>
<li>使用美国医疗保险费数据insurance.csv中的输入特征age、bmi和children，目标特征charges，根据MyLinearRegression2()函数，得到回归参数值ws；注意判断（X^T
X）^{-1}是否为满秩，如果满秩，则引入正则项，参数为alpha，目标函数变为岭回归问题。</li>
<li>为了得到模型的截距，需要在矩阵X最后增加一列，并且该列所有行的值均为1。</li>
<li>调用sklearn的LinearRegression()函数，比较其运行结果与上述自定义函数MyLinearRegression2()的输出结果是否一致。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg, column_stack, ones, array</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># 定义多元线性回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression2</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用mat将Array转换为矩阵</span></span><br><span class="line">    xMat = np.asmatrix(xArr)</span><br><span class="line">    yMat = np.asmatrix(yArr).T  <span class="comment"># 转换为列向量</span></span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    <span class="comment"># 通过调用linalg计算行列式来判定协方差矩阵是否可逆</span></span><br><span class="line">    <span class="keyword">if</span> linalg.det(xTx) &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>( <span class="string">&quot;singular matrix, can&#x27;t do inverse&quot;</span>)</span><br><span class="line">        <span class="comment"># 引入正则项，即 岭回归</span></span><br><span class="line">        alpha = <span class="number">0.1</span></span><br><span class="line">        <span class="comment"># 添加岭回归正则项（单位矩阵大小为特征数+1）</span></span><br><span class="line">        xTx  += alpha * np.eye(xMat.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算参数向量</span></span><br><span class="line">    <span class="comment"># 计算参数并转为一维数组</span></span><br><span class="line">    ws = xTx.I * (xMat.T * yMat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练，得到参数值</span></span><br><span class="line">X = insurance[[<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;bmi&#x27;</span>, <span class="string">&#x27;children&#x27;</span>]].values</span><br><span class="line"><span class="comment"># 调用column_stack函数在矩阵X后增加一列，并且该列所有行的值均为1</span></span><br><span class="line"><span class="comment"># 添加截距列（全1）</span></span><br><span class="line">X = column_stack((X, ones(X.shape[<span class="number">0</span>])))</span><br><span class="line">y = insurance[<span class="string">&#x27;charges&#x27;</span>]</span><br><span class="line">ws = MyLinearRegression2(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自定义的训练结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ws)</span><br><span class="line"><span class="comment"># sklearn的训练结果</span></span><br><span class="line">lr = LinearRegression(fit_intercept=<span class="literal">False</span>)  <span class="comment"># 关键：禁用自动截距</span></span><br><span class="line"><span class="comment">#线性回归模型训练</span></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sklearn的训练结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(lr.coef_)</span><br><span class="line"><span class="built_in">print</span>(lr.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>自定义的训练结果
[[  239.99447429]
 [  332.0833645 ]
 [  542.86465225]
 [-6916.24334779]]
sklearn的训练结果
[  239.99447429   332.0833645    542.86465225 -6916.24334779]
0.0</code></pre>
<h2 id="任务3.-线性回归应用预测医疗费用">任务3.
线性回归应用：预测医疗费用</h2>
<h3 id="任务介绍-2">任务介绍</h3>
<ul>
<li>对insurance.csv中的名义型特征进行One-Hot编码，得到了数据变量insurance</li>
<li>请使用自定义的多元回归函数MyLinearRegression2()得到回归模型参数ws和预测值y_pred，并计算R2分数</li>
<li>比较使用sklearn进行模型训练和模型评价R2分数的结果</li>
</ul>
<p>复用上一节实验中实现的代码，可以复制粘贴代替下面的代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model, metrics</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array, mean, ones</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用get_dummies函数对非数值型特征进行 one-hot 编码处理，以便于运算</span></span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line">insurance = pd.get_dummies(insurance, drop_first=<span class="literal">True</span>)  <span class="comment"># One-Hot编码</span></span><br><span class="line"><span class="built_in">print</span>(insurance.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从insurance中获取X与y</span></span><br><span class="line">X = insurance.drop([<span class="string">&#x27;charges&#x27;</span>], axis=<span class="number">1</span>).values.astype(np.float64)</span><br><span class="line">y = insurance[<span class="string">&#x27;charges&#x27;</span>].values.astype(np.float64)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个特征与y的关系进行可视化，观察与y的相关性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">1</span>]):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">6</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.scatter(array(X)[:,i],y,s=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression2</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用mat将Array转换为矩阵</span></span><br><span class="line">    xMat = np.asmatrix(xArr)</span><br><span class="line">    yMat = np.asmatrix(yArr).T  <span class="comment"># 转换为列向量</span></span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    <span class="comment"># 通过调用linalg计算行列式来判定协方差矩阵是否可逆</span></span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(xTx) &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>( <span class="string">&quot;singular matrix, can&#x27;t do inverse&quot;</span>)</span><br><span class="line">        <span class="comment"># 引入正则项，即 岭回归</span></span><br><span class="line">        alpha = <span class="number">0.1</span></span><br><span class="line">        <span class="comment"># 添加岭回归正则项（单位矩阵大小为特征数+1）</span></span><br><span class="line">        xTx  += alpha * np.eye(xMat.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算参数向量</span></span><br><span class="line">    <span class="comment"># 计算参数并转为一维数组</span></span><br><span class="line">    ws = xTx.I * (xMat.T * yMat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据X、y和自定义函数MyLinearRegression2()训练模型参数ws，并计算X的预测值y_pred</span></span><br><span class="line">ws = MyLinearRegression2(X, y)</span><br><span class="line">y_pred = X.dot(ws)</span><br><span class="line">y_pred = array(y_pred).reshape(y_pred.shape[<span class="number">0</span>],) <span class="comment"># 将矩阵转换为一行多列的array格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用metrics中的r2_score函数根据y和y_pred计算决定系数score</span></span><br><span class="line">score = metrics.r2_score(y, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sklearn模型训练与预测</span></span><br><span class="line">lr = linear_model.LinearRegression(fit_intercept=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="comment"># 计算X的预测值y_pred_sk与R2分数score_sk</span></span><br><span class="line">y_pred_sk = lr.predict(X)              <span class="comment"># 使用训练好的sklearn模型进行预测</span></span><br><span class="line">score_sk = metrics.r2_score(y, y_pred_sk)  <span class="comment"># 计算决定系数R²</span></span><br><span class="line"><span class="built_in">print</span>(score_sk)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>(1338, 9)</code></pre>
<figure>
<img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/main_9_1.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<pre><code>0.7235368166092777</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机3——逻辑回归（广告点击率预测）</title>
    <url>/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="广告点击率预测">广告点击率预测</h1>
<p>广告点击率(CTR)预测是广告行业的典型应用，是评估广告效果的一个非常重要的指标。通过历史数据训练预测模型，对于每天的增量数据进行预测，找出广告的CTR符合标准的样本进行投放。
## 数据集介绍
数据集来自于kaggle，数据包含了10天的Avazu的广告点击数据，训练集10000个，测试集1000个。每一条广告包含：广告id、时间、广告位置等属性。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/1682d3186a5d4fedab10c4ad3a7f3656e3db56852e5c4fdbb4fb26005c0ba811"></p>
<h2 id="任务1导入库和数据集与数据预处理">任务1：导入库和数据集与数据预处理</h2>
<ul>
<li>读入训练数据和测试数据，划分data和label</li>
<li>将string类型的特征转化为int型：1）进行 one-hot
编码处理，会得到高维稀疏的特征，增大内存开销；2）使用python内置的hash函数将那些类型为object的特征变量映射为一定范围内的整数(原来的string被映射成了integer)，可以大大降低内存的消耗。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">types_train = &#123;</span><br><span class="line">    <span class="string">&#x27;id&#x27;</span>: np.dtype(<span class="built_in">int</span>),</span><br><span class="line">    <span class="string">&#x27;click&#x27;</span>: np.dtype(<span class="built_in">int</span>),         <span class="comment">#是否点击,1表示被点击,0表示没被点击</span></span><br><span class="line">    <span class="string">&#x27;hour&#x27;</span>: np.dtype(<span class="built_in">int</span>),          <span class="comment">#广告被展现的日期+时间</span></span><br><span class="line">    <span class="string">&#x27;C1&#x27;</span>: np.dtype(<span class="built_in">int</span>),            <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;banner_pos&#x27;</span>: np.dtype(<span class="built_in">int</span>),    <span class="comment">#广告位置</span></span><br><span class="line">    <span class="string">&#x27;site_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),       <span class="comment">#站点Id</span></span><br><span class="line">    <span class="string">&#x27;site_domain&#x27;</span>: np.dtype(<span class="built_in">str</span>),   <span class="comment">#站点域名</span></span><br><span class="line">    <span class="string">&#x27;site_category&#x27;</span>: np.dtype(<span class="built_in">str</span>), <span class="comment">#站点分类</span></span><br><span class="line">    <span class="string">&#x27;app_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),        <span class="comment"># appId</span></span><br><span class="line">    <span class="string">&#x27;app_domain&#x27;</span>: np.dtype(<span class="built_in">str</span>),    <span class="comment"># app域名</span></span><br><span class="line">    <span class="string">&#x27;app_category&#x27;</span>: np.dtype(<span class="built_in">str</span>),  <span class="comment"># app分类</span></span><br><span class="line">    <span class="string">&#x27;device_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),     <span class="comment">#设备Id</span></span><br><span class="line">    <span class="string">&#x27;device_ip&#x27;</span>: np.dtype(<span class="built_in">str</span>),     <span class="comment">#设备Ip</span></span><br><span class="line">    <span class="string">&#x27;device_model&#x27;</span>: np.dtype(<span class="built_in">str</span>),  <span class="comment">#设备型号</span></span><br><span class="line">    <span class="string">&#x27;device_type&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#设备型号</span></span><br><span class="line">    <span class="string">&#x27;device_conn_type&#x27;</span>: np.dtype(<span class="built_in">int</span>),</span><br><span class="line">    <span class="string">&#x27;C14&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C15&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C16&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C17&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C18&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C19&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C20&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C21&#x27;</span>:np.dtype(<span class="built_in">int</span>)     <span class="comment">#匿名分类变量</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加列名</span></span><br><span class="line">header_row = [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;click&#x27;</span>, <span class="string">&#x27;hour&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;banner_pos&#x27;</span>, <span class="string">&#x27;site_id&#x27;</span>, <span class="string">&#x27;site_domain&#x27;</span>, <span class="string">&#x27;site_category&#x27;</span>, \</span><br><span class="line">              <span class="string">&#x27;app_id&#x27;</span>, <span class="string">&#x27;app_domain&#x27;</span>, <span class="string">&#x27;app_category&#x27;</span>, <span class="string">&#x27;device_id&#x27;</span>, <span class="string">&#x27;device_ip&#x27;</span>, <span class="string">&#x27;device_model&#x27;</span>,\</span><br><span class="line">              <span class="string">&#x27;device_type&#x27;</span>, <span class="string">&#x27;device_conn_type&#x27;</span>, <span class="string">&#x27;C14&#x27;</span>, <span class="string">&#x27;C15&#x27;</span>, <span class="string">&#x27;C16&#x27;</span>, <span class="string">&#x27;C17&#x27;</span>, <span class="string">&#x27;C18&#x27;</span>, <span class="string">&#x27;C19&#x27;</span>,\</span><br><span class="line">              <span class="string">&#x27;C20&#x27;</span>, <span class="string">&#x27;C21&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入训练数据和测试数据</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train_data.csv&#x27;</span>, names=header_row, dtype=types_train)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;test_data.csv&#x27;</span>, names=header_row, dtype=types_train)</span><br><span class="line"><span class="comment"># 去除第0行（表示列的编号，不是样本）</span></span><br><span class="line">train = train.drop(labels=train.index.values[<span class="number">0</span>])</span><br><span class="line">test = test.drop(labels=test.index.values[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(test.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分data和label</span></span><br><span class="line">train_data = train.drop(<span class="string">&#x27;click&#x27;</span>, axis=<span class="number">1</span>) <span class="comment">#去除click 这一列</span></span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br><span class="line">train_label = train[<span class="string">&#x27;click&#x27;</span>] <span class="comment">#提取click 这一列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="comment"># 使用pd.get_dummies对非数值型特征进行 one-hot 编码处理，得到高维稀疏的特征</span></span><br><span class="line">train_data1 = pd.get_dummies(train_data)</span><br><span class="line"><span class="built_in">print</span>(train_data1.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编写convert_obj_to_int()函数将string类型的特征转换为int型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_obj_to_int</span>(<span class="params">self</span>):</span><br><span class="line">    object_list_columns = <span class="variable language_">self</span>.columns</span><br><span class="line">    object_list_dtypes = <span class="variable language_">self</span>.dtypes</span><br><span class="line">    new_col_suffix = <span class="string">&#x27;_int&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(object_list_columns)):</span><br><span class="line">        <span class="keyword">if</span> object_list_dtypes[index] == <span class="built_in">object</span>:</span><br><span class="line">            <span class="comment"># 使用hash和map将string特征变量映射为一定范围内的整数</span></span><br><span class="line">            <span class="variable language_">self</span>[object_list_columns[index] + new_col_suffix] = <span class="variable language_">self</span>[object_list_columns[index]].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">hash</span>(x) % (<span class="number">1</span> &lt;&lt; <span class="number">32</span>))</span><br><span class="line">            <span class="variable language_">self</span>.drop([object_list_columns[index]], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用convert_obj_to_int()函数，将string类型转换为int型    </span></span><br><span class="line">train_data = convert_obj_to_int(train_data)</span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1000, 24)
(10000, 23)
(10000, 10531)
(10000, 23)


C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:</code></pre>
<h2 id="任务2特征分析">任务2：特征分析</h2>
<p>以广告在网页中的位置(banner_pos)为例，查看banner_pos和最终类标(click)之间的关系。
- 查看banner_pos在数据集中的取值分布； -
查看不同banner_pos对点击率click的贡献。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看banner_pos在数据集中的取值分布</span></span><br><span class="line"><span class="built_in">print</span>(train.banner_pos.value_counts()/<span class="built_in">len</span>(train))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看不同banner_pos对点击率click的贡献</span></span><br><span class="line">banner_pos_val = train.banner_pos.unique()</span><br><span class="line">banner_pos_val.sort()</span><br><span class="line">ctr_avg_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> banner_pos_val:</span><br><span class="line">    selected_data = train.loc[train.banner_pos == i]</span><br><span class="line">    ctr_avg = selected_data.click.mean()</span><br><span class="line">    ctr_avg_list.append(ctr_avg)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; banner 位置: &#123;&#125;,  点击率: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, ctr_avg))</span><br></pre></td></tr></table></figure>
<pre><code>banner_pos
0    0.8041
1    0.1951
2    0.0007
4    0.0001
Name: count, dtype: float64
 banner 位置: 0,  点击率: 0.16975500559631887
 banner 位置: 1,  点击率: 0.19067145053818554
 banner 位置: 2,  点击率: 0.14285714285714285
 banner 位置: 4,  点击率: 0.0</code></pre>
<h2 id="任务3模型训练与评估">任务3：模型训练与评估</h2>
<ul>
<li>调用sklearn的逻辑回归函数LogisticRegression()，进行模型训练</li>
<li>对测试集test_data进行预测，计算预测结果的各项指标acc, pre, recall,
auc</li>
<li>绘制ROC曲线（使用预测的概率值而不是预测的类标）</li>
<li><strong>选做</strong>：自定义逻辑回归函数MyLogisticRegression()，进行模型训练与预测，与上述结果比较。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_data = test.drop(<span class="string">&#x27;click&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">test_data = convert_obj_to_int(test_data)</span><br><span class="line">test_label = test[<span class="string">&#x27;click&#x27;</span>]</span><br><span class="line"><span class="comment"># 调用sklearn的逻辑回归函数LogisticRegression()</span></span><br><span class="line">clf = linear_model.LogisticRegression(max_iter=<span class="number">1000</span>)  <span class="comment"># 增加最大迭代次数防止不收敛</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">clf.fit(train_data, train_label)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Finish Training!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">pred = clf.predict(test_data)</span><br><span class="line">pred_proba = clf.predict_proba(test_data)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算模型的acc, pre, recall, auc，并输出</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line">acc = accuracy_score(test_label, pred)</span><br><span class="line">pre = precision_score(test_label, pred)</span><br><span class="line">recall = recall_score(test_label, pred)</span><br><span class="line">auc = roc_auc_score(test_label, pred_proba)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>, Precision: <span class="subst">&#123;pre:<span class="number">.4</span>f&#125;</span>, Recall: <span class="subst">&#123;recall:<span class="number">.4</span>f&#125;</span>, AUC: <span class="subst">&#123;auc:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># 绘制roc曲线</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line">fpr, tpr, _ = roc_curve(test_label, pred_proba)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(fpr, tpr, label=<span class="string">f&#x27;AUC = <span class="subst">&#123;auc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>], [<span class="number">0</span>,<span class="number">1</span>], <span class="string">&#x27;k--&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;ROC Curve (sklearn)&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 自定义实现逻辑回归函数MyLogisticRegression()</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Finish Training!
Accuracy: 0.8120, Precision: 0.0000, Recall: 0.0000, AUC: 0.4983


C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
f:\Anconda\Anconda\envs\general\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;&#123;metric.capitalize()&#125; is&quot;, len(result))</code></pre>
<figure>
<img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/main_5_2.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
<p>​<br>
Custom Model - Accuracy: 0.8240, Precision: 0.6875, Recall: 0.1170, AUC:
0.6580</p>
<figure>
<img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/main_5_4.png" alt="png">
<figcaption aria-hidden="true">png</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机实验10--支持向量机</title>
    <url>/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C10--%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<h1 id="上机实验10支持向量机">上机实验10–支持向量机</h1>
<h2 id="任务1sklearn中的svc与惩罚系数c">任务1：sklearn中的SVC与惩罚系数C</h2>
<ul>
<li>提供一份糖尿病患者数据集diabetes.csv，该数据集有768个数据样本，9个特征(最后一列为目标特征数据)，并且已经存入变量data。特征的具体信息如下：</li>
</ul>
<table>
<thead>
<tr class="header">
<th>特征名称</th>
<th>特征含义</th>
<th>取值举例</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>feature1</td>
<td>怀孕次数</td>
<td>6</td>
</tr>
<tr class="even">
<td>feature2</td>
<td>2小时口服葡萄糖耐受实验中的血浆葡萄浓度</td>
<td>148</td>
</tr>
<tr class="odd">
<td>feature3</td>
<td>舒张压 (mm Hg)</td>
<td>72</td>
</tr>
<tr class="even">
<td>feature4</td>
<td>三头肌皮褶厚度(mm)</td>
<td>35</td>
</tr>
<tr class="odd">
<td>feature5</td>
<td>2小时血清胰岛素浓度 (mu U/ml)</td>
<td>0</td>
</tr>
<tr class="even">
<td>feature6</td>
<td>体重指数(weight in kg/(height in m)^2)</td>
<td>33.6</td>
</tr>
<tr class="odd">
<td>feature7</td>
<td>糖尿病谱系功能(Diabetes pedigree function)</td>
<td>0.627</td>
</tr>
<tr class="even">
<td>feature8</td>
<td>年龄</td>
<td>50</td>
</tr>
<tr class="odd">
<td>class</td>
<td>是否患有糖尿病</td>
<td>1：阳性；0：阴性</td>
</tr>
</tbody>
</table>
<p>主要任务如下： - 请先将数据使用sklearn中的StandardScaler进行标准化；
-
然后使用sklearn中的svm.SVC支持向量分类器，构建支持向量机模型（所有参数使用默认参数），对测试集进行预测，将预测结果存为pred_y，并对模型进行评价；
-
最后新建一个svm.SVC实例clf_new，并设置惩罚系数C=0.3，并利用该支持向量分类器对测试集进行预测，将预测结果存为pred_y_new，并比较两个模型的预测效果。</p>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># 将目标特征与其他特征分离</span></span><br><span class="line">X = data.drop(<span class="string">&#x27;class&#x27;</span>, axis=<span class="number">1</span>)  </span><br><span class="line">y = data[<span class="string">&#x27;class&#x27;</span>]  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集train_X, train_y和测试集train_X, train_y</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = <span class="number">.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集标准化，返回结果为scaled_train_X</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaled_train_X = scaler.fit_transform(train_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建支持向量机模型</span></span><br><span class="line">clf = SVC()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">clf.fit(scaled_train_X, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集标准化</span></span><br><span class="line">scaled_test_X = scaler.transform(test_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型返回预测值</span></span><br><span class="line">pred_y = clf.predict(scaled_test_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印支持向量的个数，返回结果为列表，[-1标签的支持向量，+1标签的支持向量]</span></span><br><span class="line"><span class="built_in">print</span>(clf.n_support_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用classification_report函数进行模型评价</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建惩罚系数C为0.3的模型，并与之前的模型做比较</span></span><br><span class="line">clf_new = SVC(C=<span class="number">0.3</span>)</span><br><span class="line">clf_new.fit(scaled_train_X, train_y)</span><br><span class="line">pred_y_new = clf_new.predict(scaled_test_X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(clf_new.n_support_)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y_new))</span><br><span class="line"></span><br><span class="line"><span class="comment">#调整惩罚系数C寻优</span></span><br></pre></td></tr></table></figure>
<pre><code>[187 180]

              precision    recall  f1-score   support</code></pre>
<p>​</p>
<pre><code>           0       0.82      0.90      0.86       107

           1       0.70      0.55      0.62        47</code></pre>
<p>​</p>
<pre><code>    accuracy                           0.79       154

   macro avg       0.76      0.73      0.74       154

weighted avg       0.78      0.79      0.78       154</code></pre>
<p>​</p>
<pre><code>[197 196]

              precision    recall  f1-score   support</code></pre>
<p>​</p>
<pre><code>           0       0.83      0.92      0.87       107

           1       0.75      0.57      0.65        47</code></pre>
<p>​</p>
<pre><code>    accuracy                           0.81       154

   macro avg       0.79      0.75      0.76       154

weighted avg       0.81      0.81      0.80       154</code></pre>
<p>​</p>
<blockquote>
<p>预期结果</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/0768604ae0644fcdb3edd584090f6af7fae81344e0b14da789ec1324ee81bcf0"></p>
<h2 id="任务2svc选定rbf核函数并寻优核带宽参数gamma">任务2：SVC选定RBF核函数，并寻优核带宽参数gamma</h2>
<blockquote>
<p>在支持向量分类器中，核函数对其性能有直接的影响。已知径向基函数 RBF
及核矩阵元素为： <span class="math display"><em>K</em>(<strong>x</strong><sub><em>i</em></sub>,<strong>x</strong><sub><em>j</em></sub>) = exp (−<em>γ</em>∥<strong>x</strong><sub><em>i</em></sub>−<strong>x</strong><sub><em>j</em></sub>∥<sup>2</sup>)</span>
且对于核矩阵K，有<span class="math inline"><em>K</em><sub><em>i</em><em>j</em></sub> = <em>K</em>(<strong>x</strong><sub><em>i</em></sub>,<strong>x</strong><sub><em>j</em></sub>).</span></p>
</blockquote>
<p>主要任务如下： - 自定义函数实现径向基函数
rbf_kernel，要求输入参数为两个矩阵 X、Y，以及 gamma； -
利用rbf_kernel核函数，计算标准化后的训练集scaled_train_X的核矩阵，并存为
rbf_matrix； - 利用rbf_kernel核函数，训练支持向量分类器
clf，并预测标准化后的测试数据 scaled_test_X 的标签，最后评价模型效果。
&gt; 提示：先计算各自的 Gram 矩阵，然后再使用 np.diag
提取对角线元素，使用 np.tile 将列表扩展成一个矩阵。</p>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rbf_kernel</span>(<span class="params">X, Y, gamma=<span class="number">0.5</span></span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取X和Y的大小</span></span><br><span class="line">    num1 = X.shape[<span class="number">0</span>]</span><br><span class="line">    num2 = Y.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算X和X^T的矩阵乘积</span></span><br><span class="line">    gram_1 = X.dot(X.T)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取gram_1对角线位置的元素，组成大小(num1, 1)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component1</span></span><br><span class="line">    component1 = np.tile(np.diag(gram_1).reshape(-<span class="number">1</span>, <span class="number">1</span>), (<span class="number">1</span>, num2))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算Y和Y^T的乘积</span></span><br><span class="line">    gram_2 = Y.dot(Y.T)</span><br><span class="line">     </span><br><span class="line">    <span class="comment"># 获取gram_2对角线位置的元素，组成(1, num2)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component2</span></span><br><span class="line">    component2 = np.tile(np.diag(gram_2).reshape(<span class="number">1</span>, -<span class="number">1</span>), (num1, <span class="number">1</span>))</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># 计算2X和Y^T的内积 </span></span><br><span class="line">    component3 = <span class="number">2</span> * X.dot(Y.T)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 返回结果</span></span><br><span class="line">    result = np.exp(gamma*(component3 - component1 - component2))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算糖尿病患者训练数据集的核矩阵</span></span><br><span class="line">rbf_matrix = rbf_kernel(scaled_train_X, scaled_train_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练一个支持向量分类器</span></span><br><span class="line">clf = SVC(kernel=rbf_kernel)</span><br><span class="line">clf.fit(scaled_train_X, train_y)</span><br><span class="line">pred_y = clf.predict(scaled_test_X)</span><br><span class="line"><span class="built_in">print</span> (clf.n_support_)</span><br><span class="line"><span class="built_in">print</span> (classification_report(test_y, pred_y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整gamma值寻找最优</span></span><br></pre></td></tr></table></figure>
<pre><code>[250 208]

              precision    recall  f1-score   support

           0       0.84      0.89      0.86       107

           1       0.71      0.62      0.66        47

    accuracy                           0.81       154

   macro avg       0.77      0.75      0.76       154

weighted avg       0.80      0.81      0.80       154</code></pre>
<blockquote>
<p>预期结果</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/09cbd0f9a36e4802941289e87082169b6640e370714642d38606e76575bc5632"></p>
<h2 id="任务3自定义函数实现svm选做">任务3：自定义函数实现SVM（选做）</h2>
<p>主要任务如下： -
读取sklearn中的iris数据集，提取特征与标记，并进行数据划分为训练与测试集；
- 自定义函数实现SVM； -
调用SVM函数进行支持向量机训练，并对测试集进行测试。</p>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_data</span>():</span><br><span class="line">    iris = load_iris()</span><br><span class="line">    df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">    df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line">    df.columns = [<span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">    data = np.array(df.iloc[:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">        <span class="keyword">if</span> data[i,-<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">            data[i,-<span class="number">1</span>] = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># print(data)</span></span><br><span class="line">    <span class="keyword">return</span> data[:,:<span class="number">2</span>], data[:,-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据，拆分数据，训练测试集划分</span></span><br><span class="line">X, y = create_data()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.25</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SVM</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_iter=<span class="number">100</span>, kernel=<span class="string">&#x27;linear&#x27;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.max_iter = max_iter</span><br><span class="line">        <span class="variable language_">self</span>._kernel = kernel</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_args</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.m, <span class="variable language_">self</span>.n = features.shape</span><br><span class="line">        <span class="variable language_">self</span>.X = features</span><br><span class="line">        <span class="variable language_">self</span>.Y = labels</span><br><span class="line">        <span class="variable language_">self</span>.b = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将Ei保存在一个列表里</span></span><br><span class="line">        <span class="variable language_">self</span>.alpha = np.ones(<span class="variable language_">self</span>.m)</span><br><span class="line">        <span class="variable language_">self</span>.E = [<span class="variable language_">self</span>._E(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m)]</span><br><span class="line">        <span class="comment"># 松弛变量</span></span><br><span class="line">        <span class="variable language_">self</span>.C = <span class="number">1.0</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_KKT</span>(<span class="params">self, i</span>):</span><br><span class="line">        y_g = <span class="variable language_">self</span>._g(i)*<span class="variable language_">self</span>.Y[i]</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.alpha[i] == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> y_g &gt;= <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.alpha[i] &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">            <span class="keyword">return</span> y_g == <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> y_g &lt;= <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># g(x)预测值，输入xi（X[i]）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_g</span>(<span class="params">self, i</span>):</span><br><span class="line">        r = <span class="variable language_">self</span>.b</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m):</span><br><span class="line">            r += <span class="variable language_">self</span>.alpha[j] * <span class="variable language_">self</span>.Y[j] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[j], <span class="variable language_">self</span>.X[i])</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 核函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kernel</span>(<span class="params">self, x1, x2</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._kernel == <span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> np.dot(x1, x2)</span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>._kernel == <span class="string">&#x27;poly&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="built_in">sum</span>([x1[k]*x2[k] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.n)]) + <span class="number">1</span>)**<span class="number">2</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># E（x）为g(x)对输入x的预测值和y的差</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_E</span>(<span class="params">self, i</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._g(i) - <span class="variable language_">self</span>.Y[i]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_alpha</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 外层循环首先遍历所有满足0&lt;a&lt;C的样本点，检验是否满足KKT</span></span><br><span class="line">        index_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m) <span class="keyword">if</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.alpha[i] &lt; <span class="variable language_">self</span>.C]</span><br><span class="line">        <span class="comment"># 否则遍历整个训练集</span></span><br><span class="line">        non_satisfy_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m) <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> index_list]</span><br><span class="line">        index_list.extend(non_satisfy_list)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> index_list:</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>._KKT(i):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            E1 = <span class="variable language_">self</span>.E[i]</span><br><span class="line">            <span class="comment"># 如果E2是+，选择最小的；如果E2是负的，选择最大的</span></span><br><span class="line">            <span class="keyword">if</span> E1 &gt;= <span class="number">0</span>:</span><br><span class="line">                j = <span class="built_in">min</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.m), key=<span class="keyword">lambda</span> x: <span class="variable language_">self</span>.E[x])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                j = <span class="built_in">max</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.m), key=<span class="keyword">lambda</span> x: <span class="variable language_">self</span>.E[x])</span><br><span class="line">            <span class="keyword">return</span> i, j</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compare</span>(<span class="params">self, _alpha, L, H</span>):</span><br><span class="line">        <span class="keyword">if</span> _alpha &gt; H:</span><br><span class="line">            <span class="keyword">return</span> H</span><br><span class="line">        <span class="keyword">elif</span> _alpha &lt; L:</span><br><span class="line">            <span class="keyword">return</span> L</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> _alpha      </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.init_args(features, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.max_iter):</span><br><span class="line">            <span class="comment"># train</span></span><br><span class="line">            i1, i2 =<span class="variable language_">self</span>._init_alpha()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 边界</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.Y[i1] == <span class="variable language_">self</span>.Y[i2]:</span><br><span class="line">                L = <span class="built_in">max</span>(<span class="number">0</span>, <span class="variable language_">self</span>.alpha[i1]+<span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.C)</span><br><span class="line">                H = <span class="built_in">min</span>(<span class="variable language_">self</span>.C, <span class="variable language_">self</span>.alpha[i1]+<span class="variable language_">self</span>.alpha[i2])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                L = <span class="built_in">max</span>(<span class="number">0</span>, <span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.alpha[i1])</span><br><span class="line">                H = <span class="built_in">min</span>(<span class="variable language_">self</span>.C, <span class="variable language_">self</span>.C+<span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.alpha[i1])</span><br><span class="line">                </span><br><span class="line">            E1 = <span class="variable language_">self</span>.E[i1]</span><br><span class="line">            E2 = <span class="variable language_">self</span>.E[i2]</span><br><span class="line">            <span class="comment"># eta=K11+K22-2K12</span></span><br><span class="line">            eta = <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i1]) + \</span><br><span class="line">                  <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i2]) - \</span><br><span class="line">                  <span class="number">2</span> * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i2])</span><br><span class="line">            <span class="keyword">if</span> eta &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># print(&#x27;eta &lt;= 0&#x27;)</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            alpha2_new_unc = <span class="variable language_">self</span>.alpha[i2] + <span class="variable language_">self</span>.Y[i2] * (E2 - E1) / eta</span><br><span class="line">            alpha2_new = <span class="variable language_">self</span>._compare(alpha2_new_unc, L, H)</span><br><span class="line">            </span><br><span class="line">            alpha1_new = <span class="variable language_">self</span>.alpha[i1] + <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.Y[i2] * (<span class="variable language_">self</span>.alpha[i2] - alpha2_new)</span><br><span class="line">            </span><br><span class="line">            b1_new = -E1 - <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i1]) * (alpha1_new-<span class="variable language_">self</span>.alpha[i1]) - <span class="variable language_">self</span>.Y[i2] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i1]) * (alpha2_new-<span class="variable language_">self</span>.alpha[i2])+ <span class="variable language_">self</span>.b </span><br><span class="line">            b2_new = -E2 - <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i2]) * (alpha1_new-<span class="variable language_">self</span>.alpha[i1]) - <span class="variable language_">self</span>.Y[i2] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i2]) * (alpha2_new-<span class="variable language_">self</span>.alpha[i2])+ <span class="variable language_">self</span>.b </span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt; alpha1_new &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">                b_new = b1_new</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">0</span> &lt; alpha2_new &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">                b_new = b2_new</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 选择中点</span></span><br><span class="line">                b_new = (b1_new + b2_new) / <span class="number">2</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 更新参数</span></span><br><span class="line">            <span class="variable language_">self</span>.alpha[i1] = alpha1_new</span><br><span class="line">            <span class="variable language_">self</span>.alpha[i2] = alpha2_new</span><br><span class="line">            <span class="variable language_">self</span>.b = b_new</span><br><span class="line">            </span><br><span class="line">            <span class="variable language_">self</span>.E[i1] = <span class="variable language_">self</span>._E(i1)</span><br><span class="line">            <span class="variable language_">self</span>.E[i2] = <span class="variable language_">self</span>._E(i2)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;train done!&#x27;</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, data</span>):</span><br><span class="line">        r = <span class="variable language_">self</span>.b</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m):</span><br><span class="line">            r += <span class="variable language_">self</span>.alpha[i] * <span class="variable language_">self</span>.Y[i] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i], data)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> r &gt; <span class="number">0</span> <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self, X_test, y_test</span>):</span><br><span class="line">        right_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_test)):</span><br><span class="line">            result = <span class="variable language_">self</span>.predict(X_test[i])</span><br><span class="line">            <span class="keyword">if</span> result == y_test[i]:</span><br><span class="line">                right_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> right_count / <span class="built_in">len</span>(X_test)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_weight</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># linear model</span></span><br><span class="line">        yx = <span class="variable language_">self</span>.Y.reshape(-<span class="number">1</span>, <span class="number">1</span>)*<span class="variable language_">self</span>.X</span><br><span class="line">        <span class="variable language_">self</span>.w = np.dot(<span class="variable language_">self</span>.alpha, yx)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.w</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 调用SVM进行模型训练与测试评估</span></span><br><span class="line">svm = SVM(max_iter=<span class="number">100</span>)</span><br><span class="line">svm.fit(X_train, y_train)</span><br><span class="line">svm.score(X_test, y_test)</span><br></pre></td></tr></table></figure>
<pre><code>0.92</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——第二次上机——波士顿房价预测任务（线性回归、岭回归实现）</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%EF%BC%88%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0%EF%BC%89/</url>
    <content><![CDATA[<h1 id="波士顿房价预测任务线性回归岭回归实现">波士顿房价预测任务（线性回归、岭回归实现）</h1>
<p>包括数据准备、模型训练、模型评估与选择、性能度量、参数选择</p>
<h2 id="问题背景与数据集介绍">问题背景与数据集介绍</h2>
<p>波士顿房价预测是一个经典的机器学习任务，类似于程序员世界的“Hello
World”。和大家对房价的普遍认知相同，波士顿地区的房价受诸多因素影响。美国某经济杂志登出波士顿房价数据集，该数据集包含506条观测信息，统计了13种可能影响房价的因素（输入变量）和该类型房屋的均价（输出变量），其中每条观测信息包含城镇犯罪率、一氧化氮浓度、住宅平均房间数、到中心区域的加权距离以及自住房平均房价等关于波士顿周边或者城镇房价的描述，期望通过分析影响波士顿房价的因素来构建房价预测模型。相关属性描述如下图所示，其中最后一项就是想要预测的房屋均价。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/be005522b4c441ba89ee7a2ad8277f7c8706457a7a8e4b5f84f92591a32b701d"></p>
<p>观测数据的示例如下图所示。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/46fb2e80de2047ff8af2c16819a9e3f5114533f01e3c44c697cfdd66be7bf22f"></p>
<p>对于预测问题，可以根据预测输出的类型是连续的实数值，还是离散的标签，区分为回归任务和分类任务。因为房价是一个连续值，所以房价预测显然是一个回归任务。本次实验要求大家调用sklearn
的线性回归、岭回归模型来实现。</p>
<h3 id="实现过程">实现过程：</h3>
<ol type="1">
<li>数据准备：导入数据、特征可视化</li>
<li>数据预处理：数据集划分、数据标准化处理</li>
<li>模型训练：线性回归、岭回归</li>
<li>模型评估与选择、参数选择</li>
</ol>
<h2 id="数据准备">数据准备</h2>
<h3 id="导入数据">导入数据</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line"><span class="built_in">print</span>(boston.DESCR)</span><br></pre></td></tr></table></figure>
<h3 id="数据可视化">数据可视化</h3>
<p>通过观察不同属性与房价之间的关系，分析影响房价的主要因素。</p>
<p>boston.data 存储的是所有样本的属性值，boston.target
存储的是所有样本的房价。下段程序所展示的13幅图中，横坐标是该属性的取值，纵坐标是房价值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入matplotlib库中的pyplot模块，用于绘制图表</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表的大小，figsize指定了图表的宽度和高度，单位是英寸</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历波士顿数据集的13个特征</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>):</span><br><span class="line">    <span class="comment"># 创建一个2行7列的子图，并在当前子图中绘制散点图</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">7</span>, i + <span class="number">1</span>)  <span class="comment"># 2行7列的第i+1个子图</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 绘制散点图：x轴是第i个特征，y轴是目标值（房价中位数），s指定点的大小</span></span><br><span class="line">    plt.scatter(boston.data[:, i], boston.target, s=<span class="number">20</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置当前子图的标题，显示当前特征的名称</span></span><br><span class="line">    plt.title(boston.feature_names[i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存当前图表为PNG格式的图片，文件名为img.png</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;img.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示绘制的所有子图</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%EF%BC%88%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0%EF%BC%89/img.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="数据预处理">数据预处理</h2>
<h3 id="任务1数据集划分">任务1：数据集划分</h3>
<p>调用sklearn.model_selection中的train_test_split()函数，把boston数据集分为训练集和测试集，划分比例是4:1。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 加载波士顿房价数据集</span></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据集划分为训练集和测试集，test_size=0.2 表示测试集占20%，即训练集占80%</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<h3 id="结果">结果：</h3>
<ul>
<li><strong><code>X_train</code></strong>：训练集的特征数据，形状为
<code>(404, 13)</code>，即 80% 的数据（506 * 0.8 = 404
个样本），每个样本有 13 个特征。</li>
<li><strong><code>X_test</code></strong>：测试集的特征数据，形状为
<code>(102, 13)</code>，即 20% 的数据（506 * 0.2 = 102 个样本）。</li>
<li><strong><code>y_train</code></strong>：训练集的目标值，形状为
<code>(404,)</code>，即对应训练集的 404 个房价中位数。</li>
<li><strong><code>y_test</code></strong>：测试集的目标值，形状为
<code>(102,)</code>，即对应测试集的 102 个房价中位数。</li>
</ul>
<h3 id="总结">总结：</h3>
<ul>
<li><code>train_test_split()</code>
将数据集（包括特征和目标值）按照指定的比例随机划分为训练集和测试集。划分后的数据将用于模型的训练和评估，确保模型评估时使用的数据不会在训练过程中被“看见”。</li>
<li><code>test_size=0.2</code> 表示将 20% 的数据作为测试集，80%
的数据作为训练集。</li>
<li><code>random_state=42</code>
确保每次划分数据集时能得到一致的结果，保证实验的可复现性。</li>
</ul>
<h3 id="任务2数据标准化处理">任务2：数据标准化处理：</h3>
<h4 id="z-score标准化">1. Z-score标准化</h4>
<p>首先使用StandardScaler()函数初始化对属性值的标准化器，然后调用fit_transform()方法对训练数据进行Z-score标准化，再将这个标准化器调用transform()方法用于测试数据的标准化。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment"># 初始化对属性值的标准化器</span></span><br><span class="line">ss_X = StandardScaler()</span><br><span class="line"><span class="comment"># ss_X调用fit_transform()和transform()方法对训练数据和测试数据进行标准化</span></span><br><span class="line"><span class="comment"># 对训练数据进行标准化，fit_transform() 方法会计算训练数据的均值和标准差，并应用到训练数据</span></span><br><span class="line"><span class="comment"># 训练数据X_train会被标准化为均值0，标准差1</span></span><br><span class="line">X_train = ss_X.fit_transform(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对测试数据进行标准化，使用transform()方法来使用训练数据的均值和标准差来标准化测试数据</span></span><br><span class="line"><span class="comment"># 注意：测试数据不能再用fit_transform()，否则会使用测试数据的统计量，导致数据泄露</span></span><br><span class="line">X_test = ss_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p><strong>Z-score
标准化</strong>的过程是将数据转换为均值为0，标准差为1的分布。<code>StandardScaler()</code>
是 <code>scikit-learn</code>
提供的标准化工具，它通过去掉均值并除以标准差来实现这一标准化。</p>
<h4 id="代码解释">代码解释：</h4>
<p><strong>对训练数据进行标准化</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train = ss_X.fit_transform(X_train)</span><br></pre></td></tr></table></figure> -
<code>fit()</code>：计算训练数据的均值和标准差。 -
<code>transform()</code>：使用训练数据的均值和标准差将数据标准化。 -
<code>fit_transform()</code>：这两个操作结合在一起，计算并转换训练数据，使其均值为0，标准差为1。</p>
<p><strong>对测试数据进行标准化</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_test = ss_X.transform(X_test)</span><br></pre></td></tr></table></figure> -
对测试数据应用 <code>transform()</code>
方法时，不会重新计算均值和标准差，而是使用在训练数据上计算得到的均值和标准差对测试数据进行转换。
-
这确保了测试数据的标准化是基于训练数据的统计信息，而不是测试数据本身的统计信息。</p>
<h4 id="minmax标准化">2. MinMax标准化</h4>
<p>首先使用StandardScaler()函数初始化对属性值的标准化器，然后调用fit_transform()方法对训练数据进行Z-score标准化，再将这个标准化器调用transform()方法用于测试数据的标准化。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="comment"># 初始化对属性值的标准化器</span></span><br><span class="line">mm_X = MinMaxScaler()</span><br><span class="line"><span class="comment"># mm_X调用fit_transform()和transform()方法对训练数据和测试数据进行MinMax标准化</span></span><br><span class="line">X_train1 = mm_X.fit_transform(X_train)</span><br><span class="line">X_test1 = mm_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p>在 <strong>MinMax 标准化</strong>（也称为
<strong>归一化</strong>）中，数据将被缩放到指定的最小值和最大值之间，通常是将数据缩放到
<code>[0, 1]</code>
范围内。这对于那些对特征的绝对范围敏感的算法非常有效。</p>
<p><code>MinMaxScaler</code> 是 <code>scikit-learn</code>
提供的一个标准化工具，它会将每个特征缩放到一个指定的范围内，默认情况下是
<code>[0, 1]</code>。</p>
<h3 id="代码解释-1">代码解释：</h3>
<p><strong>对训练数据进行 MinMax 标准化</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train1 = mm_X.fit_transform(X_train)</span><br></pre></td></tr></table></figure> -
<code>fit_transform()</code>
方法会计算训练数据的最小值和最大值，并将数据缩放到 <code>[0, 1]</code>
范围内。 -
<strong><code>fit()</code></strong>：计算训练数据的最小值和最大值。 -
<strong><code>transform()</code></strong>：根据计算出的最小值和最大值，进行数据的转换。
- <code>fit_transform()</code>
是这两个操作的组合，直接返回标准化后的训练数据。</p>
<p><strong>对测试数据进行 MinMax 标准化</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_test1 = mm_X.transform(X_test)</span><br></pre></td></tr></table></figure> -
<code>transform()</code>
方法会使用训练数据上的最小值和最大值来转换测试数据。 -
<strong>注意</strong>：<code>transform()</code>
仅仅使用训练数据的统计量（即最小值和最大值）来对测试数据进行标准化，避免了数据泄露问题。如果对测试数据使用
<code>fit_transform()</code>，就会导致模型从测试数据中学习统计量，破坏了训练和测试数据的独立性。</p>
<p><strong>MinMax
标准化</strong>是一种常用的数据预处理方法，尤其适用于特征的取值范围差异较大时。它将每个特征的最小值映射到
0，最大值映射到
1，其他值则在该区间内按比例进行缩放。这样做的好处是避免了某些特征因数值范围较大而在训练模型时占据主导地位，尤其是对于需要计算距离或内积的模型，如
KNN、SVM 等，使用 MinMax 标准化后的数据会使模型训练更加稳定。</p>
<h2 id="模型训练与评估">模型训练与评估</h2>
<h3 id="任务3.1线性回归模型训练">任务3.1：线性回归模型训练</h3>
<p>调用sklearn.linear_model中的LinearRegression()函数，对训练集(X_train,y_train)进行模型训练，并预测测试集X_test的房价lr_y_predict。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="comment"># 初始化线性回归模型</span></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment"># 线性回归模型训练</span></span><br><span class="line">lr.fit(X_train, y_train)  <span class="comment"># 使用训练集数据训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">lr_y_predict = lr.predict(X_test)  <span class="comment"># 使用训练好的模型对测试集数据进行预测</span></span><br></pre></td></tr></table></figure>
<h3 id="代码解释-2">代码解释：</h3>
<p><strong>训练模型</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr.fit(X_train, y_train)</span><br></pre></td></tr></table></figure> - <code>fit()</code>
方法会使用训练集数据 <code>(X_train, y_train)</code>
来训练线性回归模型。训练过程就是计算线性回归模型的系数（权重）和截距，以使预测值最接近真实目标值。</p>
<p><strong>预测房价</strong>： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr_y_predict = lr.predict(X_test)</span><br></pre></td></tr></table></figure> - <code>predict()</code>
方法会使用已经训练好的模型来对测试集 <code>X_test</code>
进行预测，返回预测的房价（即预测值
<code>lr_y_predict</code>）。模型根据训练时学到的关系来预测测试集中的每个样本的房价。</p>
<h3 id="任务3.2线性回归模型评估">任务3.2：线性回归模型评估</h3>
<p>回归模型常用的三种评价指标：（1）R方分数（决定系数）、（2）MSE均方误差、以及（3）MAE平均绝对误差。</p>
<p>方法一：调用sklearn.metrics中的相关函数，计算测试结果lr_y_predict与真实结果y_test之间的误差或精度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score,mean_squared_error,mean_absolute_error</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;the value of R-squared of LR is&#x27;</span>,r2_score(y_test,lr_y_predict))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;the MSE of LR is&#x27;</span>,mean_squared_error(y_test,lr_y_predict))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;the MAE of LR is&#x27;</span>,mean_absolute_error(y_test,lr_y_predict))</span><br></pre></td></tr></table></figure>
<pre><code>the value of R-squared of LR is 0.7250808093832966
the MSE of LR is 23.56944609104811
the MAE of LR is 3.302381007591344</code></pre>
<p>方法二：自己编写函数，计算上述指标。本实验要求学生至少完成MSE均方误差的计算，并打印输出结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 计算R²（决定系数）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_r2</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># R² = 1 - (SS_res / SS_tot)</span></span><br><span class="line">    ss_res = ((y_true - y_pred) ** <span class="number">2</span>).<span class="built_in">sum</span>()  <span class="comment"># 残差平方和</span></span><br><span class="line">    ss_tot = ((y_true - y_true.mean()) ** <span class="number">2</span>).<span class="built_in">sum</span>()  <span class="comment"># 总平方和</span></span><br><span class="line">    r2_score = <span class="number">1</span> - (ss_res / ss_tot)  <span class="comment"># 决定系数</span></span><br><span class="line">    <span class="keyword">return</span> r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算MSE（均方误差）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_mse</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    mse = mean_squared_error(y_true, y_pred)</span><br><span class="line">    <span class="keyword">return</span> mse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算MAE（平均绝对误差）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_mae</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    mae = mean_absolute_error(y_true, y_pred)</span><br><span class="line">    <span class="keyword">return</span> mae</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">r2 = calculate_r2(y_test, lr_y_predict)  <span class="comment"># R²</span></span><br><span class="line">mse = calculate_mse(y_test, lr_y_predict)  <span class="comment"># MSE</span></span><br><span class="line">mae = calculate_mae(y_test, lr_y_predict)  <span class="comment"># MAE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;R² (决定系数): <span class="subst">&#123;r2&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;MSE (均方误差): <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;MAE (平均绝对误差): <span class="subst">&#123;mae&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>R² (决定系数): 0.7250808093832966
MSE (均方误差): 23.56944609104811
MAE (平均绝对误差): 3.302381007591344</code></pre>
<p>下面是
<strong>R²（决定系数）</strong>、<strong>MSE（均方误差）</strong> 和
<strong>MAE（平均绝对误差）</strong> 的计算公式：</p>
<h3 id="r²决定系数-计算公式">1. <strong>R²（决定系数）</strong>
计算公式：</h3>
<p>R² 衡量模型对目标变量变化的解释程度。它的取值范围为 0 到 1，越接近
1，表示模型越能解释数据的变异性。</p>
<p>公式: <span class="math display">$$
R^2=1-\frac{\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2}
$$</span></p>
<ul>
<li>( $y_i $)：实际值（真实的目标值）。</li>
<li>( <span class="math inline"><em>ŷ</em><sub><em>i</em></sub></span>
)：预测值（模型预测的目标值）。</li>
<li>( <span class="math inline"><em>ȳ</em></span> )：实际值的均值（
<span class="math inline">$\bar{y} = \frac{1}{n} \sum_{i=1}^{n}
y_i$</span> ）。</li>
<li>( <span class="math inline"><em>n</em></span> )：样本数。</li>
</ul>
<h4 id="解释">解释：</h4>
<ul>
<li>分子部分是
<strong>残差平方和（RSS）</strong>，衡量预测值与真实值之间的差异。</li>
<li>分母部分是
<strong>总平方和（TSS）</strong>，衡量真实值与均值之间的差异。</li>
<li>R² 越接近 1，表示模型的拟合度越好。</li>
</ul>
<h3 id="mse均方误差-计算公式">2. <strong>MSE（均方误差）</strong>
计算公式：</h3>
<p>MSE
衡量预测值与真实值之间差异的平方和的平均值，是一种常用的回归模型评估指标。</p>
<p>公式： <span class="math display">$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$</span></p>
<ul>
<li>( <span class="math inline"><em>y</em><sub><em>i</em></sub></span>
)：实际值。</li>
<li>( <span class="math inline"><em>ŷ</em><sub><em>i</em></sub></span>)：预测值。</li>
<li>( <span class="math inline"><em>n</em></span> )：样本数。</li>
</ul>
<h4 id="解释-1">解释：</h4>
<ul>
<li>MSE
是实际值与预测值之间差异的平方和的平均值，越小表示模型的预测误差越小。</li>
</ul>
<h3 id="mae平均绝对误差-计算公式">3.
<strong>MAE（平均绝对误差）</strong> 计算公式：</h3>
<p>MAE
衡量预测值与真实值之间差异的绝对值的平均值，也是一种常用的回归模型评估指标。</p>
<p>公式： <span class="math display">$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$</span></p>
<ul>
<li>( <span class="math inline"><em>y</em><sub><em>i</em></sub></span>
)：实际值。</li>
<li>( <span class="math inline"><em>ŷ</em><sub><em>i</em></sub></span>
)：预测值。</li>
<li>( <span class="math inline"><em>n</em></span> )：样本数。</li>
</ul>
<h4 id="解释-2">解释：</h4>
<ul>
<li>MAE
是实际值与预测值之间差异的绝对值的平均值，越小表示模型的预测性能越好。</li>
</ul>
<h3 id="总结-1">总结：</h3>
<ul>
<li><strong>R²（决定系数）</strong>：度量模型拟合优度，越接近 1
表示模型越好。</li>
<li><strong>MSE（均方误差）</strong>：越小，表示模型的预测误差越小。</li>
<li><strong>MAE（平均绝对误差）</strong>：越小，表示模型在预测时的绝对误差越小。</li>
</ul>
<h3 id="任务3.3岭回归模型训练">任务3.3：岭回归模型训练</h3>
<p>调用sklearn.linear_model中的Ridge()函数(参数设置为5)，对训练集(X_train,y_train)进行模型训练，并预测测试集X_test的房价rd_y_predict。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">rd = Ridge(alpha=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#岭回归模型训练</span></span><br><span class="line">rd.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 输出训练后的模型系数（回归系数）</span></span><br><span class="line"><span class="built_in">print</span>(rd.coef_)</span><br><span class="line"><span class="comment">#模型测试</span></span><br><span class="line">rd_y_predict = rd.predict(X_test)</span><br></pre></td></tr></table></figure>
<pre><code>[-0.89921997  1.17687007  0.06847273  0.58380163 -2.09273127  2.39227753
  0.15081088 -3.06269707  2.53630955 -1.8549535  -2.24256957  0.89722135
 -3.79040179]</code></pre>
<h3 id="岭回归ridge-regression">岭回归（Ridge Regression）</h3>
<p><strong>岭回归</strong>（Ridge Regression），又称 <strong>L2
正则化回归</strong>，是一种扩展了普通最小二乘回归（OLS）的回归模型。其核心思想是在最小化
<strong>残差平方和</strong>（即普通最小二乘回归的目标函数）的同时，加入一个
<strong>正则化项</strong>，用于惩罚模型的复杂性，避免过拟合。</p>
<h3 id="岭回归的公式">岭回归的公式</h3>
<p>岭回归的目标函数为： <span class="math display">$$
\text{minimize} \quad \left( \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 + \alpha
\sum_{j=1}^{p} \beta_j^2 \right)
$$</span> 其中：</p>
<ul>
<li>( <span class="math inline"><em>y</em><sub><em>i</em></sub></span>
)：实际观测值。</li>
<li>( <span class="math inline"><em>ŷ</em><sub><em>i</em></sub></span>
)：模型预测值。</li>
<li>( <span class="math inline"><em>β</em><sub><em>j</em></sub></span>
)：模型的回归系数。</li>
<li>( <span class="math inline"><em>α</em></span>
)：正则化强度（超参数），控制正则化项的权重。</li>
</ul>
<h3 id="关键点">关键点：</h3>
<ol type="1">
<li><strong>残差平方和</strong>：普通最小二乘回归的目标函数是最小化预测值和真实值之间的差异平方和：<span class="math inline">$\sum_{i=1}^{n} (y_i - \hat{y}_i)^2$</span></li>
<li><strong>L2
正则化</strong>：岭回归在最小化残差平方和的同时，加上一个正则化项$ _{j=1}^{p}
_j^2
$，用来限制回归系数的大小。这个正则化项惩罚过大的系数，使得系数趋向于
0，但不会完全为 0（与 Lasso 回归不同，Lasso 是 L1
正则化，会使部分系数变为 0）。
<ul>
<li>$$：是岭回归的正则化参数，控制惩罚项的强度。较大的 ( )
值会增加正则化的惩罚，使模型的系数变得较小，从而减少过拟合。</li>
</ul></li>
</ol>
<h3 id="岭回归的作用">岭回归的作用</h3>
<ul>
<li><strong>防止过拟合</strong>：在普通的最小二乘回归中，若特征非常多，模型可能会在训练数据上表现得非常好，但却在测试数据上表现得较差（过拟合）。通过在回归系数上施加惩罚，岭回归减少了模型的复杂度，从而帮助防止过拟合。</li>
<li><strong>适应多重共线性</strong>：当特征之间存在强烈的相关性时（即多重共线性），普通的最小二乘回归可能无法得出稳定的回归系数。岭回归通过正则化项使得模型更稳定，避免共线性问题带来的不稳定性。</li>
</ul>
<h3 id="岭回归与普通最小二乘回归的区别">岭回归与普通最小二乘回归的区别</h3>
<ul>
<li><strong>普通最小二乘回归</strong>：最小化残差平方和，没有对回归系数施加任何惩罚。因此，模型会根据训练数据的噪声来拟合训练数据，可能导致过拟合。</li>
<li><strong>岭回归</strong>：最小化残差平方和，并加上正则化项，控制回归系数的大小，防止模型复杂度过高，减少过拟合。</li>
</ul>
<h3 id="岭回归的超参数-alpha">岭回归的超参数 ( <span class="math inline"><em>α</em></span> )</h3>
<ul>
<li><strong>( <span class="math inline"><em>α</em></span>
)</strong>：是岭回归中的超参数，控制正则化项的强度。
<ul>
<li>当 ( = 0 ) 时，岭回归退化为普通的最小二乘回归。</li>
<li>当 ( )
较大时，模型的回归系数被更多地惩罚，减少了过拟合的风险，但也可能导致欠拟合（即模型对数据的拟合能力不足）。</li>
</ul></li>
</ul>
<h3 id="任务3.4岭回归模型评估">任务3.4：岭回归模型评估</h3>
<p>与线性回归一样，岭回归模型有两种方法计算评价指标，这里调用sklearn.metrics来实现。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score,mean_squared_error,mean_absolute_error</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;the value of R-squared of Ridge is&#x27;</span>,r2_score(y_test,rd_y_predict ))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;the MSE of Ridge is&#x27;</span>,mean_squared_error(y_test,rd_y_predict))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;the MAE of Ridge is&#x27;</span>,mean_absolute_error(y_test,rd_y_predict))</span><br></pre></td></tr></table></figure>
<pre><code>the value of R-squared of Ridge is 0.7279447933421523
the MSE of Ridge is 23.323910246960786
the MAE of Ridge is 3.2535718613670053</code></pre>
<h2 id="参数选择">参数选择</h2>
<h3 id="任务4运用交叉验证选择模型参数">任务4：运用交叉验证选择模型参数</h3>
<p>岭回归模型参数是正则化参数alpha，前面把它设置为5。为了选择最优参数，对训练集进行10次10折交叉验证。具体地，参数选择在[0,10]范围内，以1为步长，进行选择。
1.
总共进行11次实验（不同alpha值），每次实验将训练数据随机分成10份，重复10次；
2. 每一次划分，任意9份做训练，剩余1份测试，共执行10次，测试结果取平均；
3. 再将所有划分的结果再取平均，作为这一次alpha取值的分数； 4.
比较不同alpha取值的交叉验证模型分数，来选择其中表现最好的（分数最高的）模型的alpha值；
5. 用上述选择的alpha值对训练数据重新训练模型，再测试评估。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv_score_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>):</span><br><span class="line">    <span class="comment"># alpha 取不同值</span></span><br><span class="line">    rd = Ridge(alpha=i)</span><br><span class="line">    avg_score_cross = []</span><br><span class="line">    <span class="comment"># 进行10次随机划分</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        <span class="comment">#调用KFold()实现10折划分</span></span><br><span class="line">        kf = KFold(n_splits=<span class="number">10</span>, shuffle=<span class="literal">True</span>, random_state=j)</span><br><span class="line">        <span class="comment">#调用cross_val_score()计算训练集本次10折划分的分数</span></span><br><span class="line">        score_cross = cross_val_score(rd, X_train, y_train, cv=kf, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>)</span><br><span class="line">        avg_score_cross.append(np.mean(score_cross))</span><br><span class="line">    cv_score_list.append(np.mean(avg_score_cross))</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">11</span>), cv_score_list)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># cv_score_list中找到分数最大的模型所对应的alpha取值</span></span><br><span class="line">index = np.argmax(cv_score_list)</span><br><span class="line">rd = Ridge(alpha=index)</span><br><span class="line"><span class="comment">#岭回归模型训练</span></span><br><span class="line">rd.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#模型测试</span></span><br><span class="line">rd_y_predict = rd.predict(X_test)</span><br><span class="line"><span class="comment"># 打印模型评估结果</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, mean_absolute_error</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Best Alpha: <span class="subst">&#123;index&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Squared Error: <span class="subst">&#123;mean_squared_error(y_test, rd_y_predict)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Absolute Error: <span class="subst">&#123;mean_absolute_error(y_test, rd_y_predict)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Best Alpha: 4
Mean Squared Error: 23.35986469628359
Mean Absolute Error: 3.260923268350155</code></pre>
<h2 id="二分类问题">二分类问题</h2>
<h3 id="任务5波士顿房价二分类问题">任务5：波士顿房价二分类问题</h3>
<p>为了了解分类问题的建模与评估，本任务将连续值的波士顿房价数值使用阈值进行二值化（0,1，例如：廉价房、品质房），可以将房价预测的回归问题，改为简单的二分类问题。</p>
<p>同样是包括四个步骤：数据准备、数据预处理、模型训练、模型评估与选择。</p>
<p>下面的程序使用方法一调用sklearn.metrics中的相应函数计算预测结果的准确率accuracy、f1
score、auc值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, f1_score, roc_auc_score</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"><span class="comment"># 房价数值二值化</span></span><br><span class="line">threshold = np.mean(boston.target)</span><br><span class="line">labels = (boston.target&gt;threshold).astype(np.int_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集划分</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(boston.data, labels, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment"># 省略数据预处理步骤</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment"># 模型训练：我们使用 LogisticRegression（线性回归常用于回归问题，但 Logistic Regression 更适合于二分类问题）</span></span><br><span class="line">lr = LogisticRegression(max_iter=<span class="number">10000</span>)  <span class="comment"># 设置最大迭代次数为10000以确保收敛</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测：对测试集进行预测</span></span><br><span class="line">lr_y_predict = lr.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The accuracy score of LR is&#x27;</span>, accuracy_score(y_test, lr_y_predict))  <span class="comment"># 准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The f1 score of LR is&#x27;</span>, f1_score(y_test, lr_y_predict))  <span class="comment"># F1 分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The auc of LR is&#x27;</span>, roc_auc_score(y_test, lr_y_predict))  <span class="comment"># AUC（曲线下面积）</span></span><br></pre></td></tr></table></figure>
<pre><code>The accuracy score of LR is 0.9117647058823529
The f1 score of LR is 0.8695652173913043
The auc of LR is 0.89002079002079


f:\project python\.conda\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.

    The Boston housing prices dataset has an ethical problem. You can refer to
    the documentation of this function for further details.

    The scikit-learn maintainers therefore strongly discourage the use of this
    dataset unless the purpose of the code is to study and educate about
    ethical issues in data science and machine learning.

    In this special case, you can fetch the dataset from the original
    source::

        import pandas as pd
        import numpy as np

        data_url = &quot;http://lib.stat.cmu.edu/datasets/boston&quot;
        raw_df = pd.read_csv(data_url, sep=&quot;\s+&quot;, skiprows=22, header=None)
        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
        target = raw_df.values[1::2, 2]

    Alternative datasets include the California housing dataset (i.e.
    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing
    dataset. You can load the datasets as follows::

        from sklearn.datasets import fetch_california_housing
        housing = fetch_california_housing()

    for the California housing dataset and::

        from sklearn.datasets import fetch_openml
        housing = fetch_openml(name=&quot;house_prices&quot;, as_frame=True)

    for the Ames housing dataset.
  warnings.warn(msg, category=FutureWarning)</code></pre>
<p>方法二：自己编写函数，计算上述指标。</p>
<p>本实验要求学生至少完成accuracy与f1 score的计算，并打印输出结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="comment"># 计算准确率（Accuracy）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_accuracy</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    correct = np.<span class="built_in">sum</span>(y_true == y_pred)  <span class="comment"># 计算正确预测的数量</span></span><br><span class="line">    total = <span class="built_in">len</span>(y_true)  <span class="comment"># 总样本数</span></span><br><span class="line">    accuracy = correct / total  <span class="comment"># 准确率</span></span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算F1分数（F1 Score）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_f1_score</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    cm = confusion_matrix(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 提取混淆矩阵中的 TP, FP, FN</span></span><br><span class="line">    tp = cm[<span class="number">1</span>, <span class="number">1</span>]  <span class="comment"># True Positives</span></span><br><span class="line">    fp = cm[<span class="number">0</span>, <span class="number">1</span>]  <span class="comment"># False Positives</span></span><br><span class="line">    fn = cm[<span class="number">1</span>, <span class="number">0</span>]  <span class="comment"># False Negatives</span></span><br><span class="line">    precision = tp / (tp + fp) <span class="keyword">if</span> (tp + fp) != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    recall = tp / (tp + fn) <span class="keyword">if</span> (tp + fn) != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="comment"># 计算 F1 分数</span></span><br><span class="line">    f1 = <span class="number">2</span> * (precision * recall) / (precision + recall) <span class="keyword">if</span> (precision + recall) != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> f1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">accuracy = calculate_accuracy(y_test, lr_y_predict)</span><br><span class="line">f1_score = calculate_f1_score(y_test, lr_y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;F1 Score: <span class="subst">&#123;f1_score&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy: 0.9117647058823529
F1 Score: 0.8695652173913043</code></pre>
<h3 id="准确率-accuracy">1. <strong>准确率 (Accuracy)</strong>：</h3>
<p>准确率是正确分类的样本数与总样本数之比。</p>
<p>公式： <span class="math display">$$
\text{Accuracy} = \frac{\text{正确预测的数量}}{\text{总样本数}}
$$</span></p>
<h3 id="f1-分数-f1-score">2. <strong>F1 分数 (F1 Score)</strong>：</h3>
<p>F1 分数是准确率 (Precision) 和召回率 (Recall) 的调和平均数。</p>
<p>公式： <span class="math display">$$
F1 = 2 \times \frac{\text{Precision} \times
\text{Recall}}{\text{Precision} + \text{Recall}}
$$</span> 其中： <span class="math display">$$
\text{Precision} = \frac{\text{True Positive}}{\text{True Positive} +
\text{False Positive}}
$$</span></p>
<p><span class="math display">$$
\text{Recall} = \frac{\text{True Positive}}{\text{True Positive} +
\text{False Negative}}
$$</span></p>
<h3 id="auc-area-under-the-curve">3. <strong>AUC (Area Under the
Curve)</strong>：</h3>
<p>AUC 是 ROC 曲线下面积，用于衡量分类模型的性能，范围在 0 到 1
之间，越接近 1，模型表现越好。AUC
是一个广泛使用的评估二分类问题模型的性能的指标。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机4——决策树</title>
    <url>/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h1 id="上机实验决策树">上机实验：决策树</h1>
<h2 id="任务1分支节点的选择方法">任务1：分支节点的选择方法</h2>
<p>现有一个数据集
weekend.txt，目标是根据一个人的特征来预测其周末是否出行。</p>
<p>所有特征均为二元特征，取值为 0 或
1，其中“status”（目标特征也是类别）表示用户的周末是否出行，1 表示出行，0
表示不出行，“marriageStatus”表示申请人是否已婚、“hasChild”表示申请人是否有小孩、“hasAppointment”表示申请人是否有约、“weather”表示天气是否晴朗。</p>
<p>已知信息熵和信息增益的公式为：</p>
<p><span class="math display">$$\text{Entropy}(D)=-\sum_{k=1}^{C}p_k
\cdot log_2(p_k)$$</span></p>
<p><span class="math display">$$\text{InfoGain}(D,
a)=\text{Entropy}(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|}
\cdot\text{Entropy}(D^v)$$</span></p>
<p>请完成以下三个内容：</p>
<ul>
<li><p>请自定义函数 cal_entropy(data,
feature_name)计算数据集data关于feature_name的信息熵。输入参数 data 为
DataFrame，feature_name 为目标特征(或类别)的名称；</p></li>
<li><p>请调用 cal_entropy() 函数计算决策树分支之前的信息熵，保存为
data_entropy；</p></li>
<li><p>请自定义函数 cal_infoGain(data, base_entropy) 计算 weekend.txt
中各个特征的信息增益，保存为列表 infogains，并选择信息增益最大的分支节点
best_feature。</p></li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入必要库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据（假设文件为tab分隔，包含特征和目标变量&#x27;status&#x27;）</span></span><br><span class="line">weekend_data = pd.read_table(<span class="string">&#x27;weekend.txt&#x27;</span>, sep=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义熵计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数（如：status特征中&quot;出门&quot;和&quot;不出门&quot;的数量）</span></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（注意：熵公式为负数求和）</span></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算初始信息熵（假设目标特征列为&#x27;status&#x27;）</span></span><br><span class="line">data_entropy = cal_entropy(weekend_data, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义信息增益计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 获取所有特征名称</span></span><br><span class="line">    feature_list.remove(<span class="string">&#x27;status&#x27;</span>)  <span class="comment"># 移除目标特征（避免计算自身）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布（如：天气特征的&quot;晴朗/下雨/阴天&quot;）</span></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历特征的每个取值</span></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line">            <span class="comment"># 获取特征取当前值的子集</span></span><br><span class="line">            subset = data[data[feature] == value]</span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算子集的熵并累加加权熵</span></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算信息增益（信息增益 = 基础熵 - 条件熵）</span></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到信息增益最大的特征</span></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大增益值</span></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 对应的最优特征名称</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"><span class="comment">## 执行信息增益计算</span></span><br><span class="line">infogains, best_feature = cal_infoGain(weekend_data, data_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 结果输出</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;各特征的信息增益：&#x27;</span>, infogains)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n信息增益最大的特征：&#x27;</span>, best_feature)</span><br></pre></td></tr></table></figure>
<pre><code>各特征的信息增益： [0.0076, 0.0076, 0.0322, 0.0868]</code></pre>
<p>​</p>
<pre><code>信息增益最大的特征： weather</code></pre>
<blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc"></p>
<h2 id="任务2常见的决策树算法">任务2：常见的决策树算法</h2>
<p>现在有一份有关商品销量的数据集product.csv，数据集的离散型特征信息如下：</p>
<table>
<thead>
<tr class="header">
<th>特征名称</th>
<th>取值说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>天气</td>
<td>1：天气好；0：天气坏</td>
</tr>
<tr class="even">
<td>是否周末</td>
<td>1：是；0：不是</td>
</tr>
<tr class="odd">
<td>是否有促销</td>
<td>1：有促销；0：没有促销</td>
</tr>
<tr class="even">
<td>销量</td>
<td>1：销量高；0：销量低</td>
</tr>
</tbody>
</table>
<p>请完成以下三个内容： - 请根据提供的商品销量数据集 data，使用 sklearn
中的
DecisionTreeClassifier()函数构建决策树模型，模型选择分支结点的特征以Gini指数为判定准则；
- 训练模型，并对测试集test_X进行预测，将预测结果存为
pred_y，进行模型评估； - 将构建的决策树模型进行可视化。</p>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz  <span class="comment"># 补全export_graphviz导入</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;product.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取除目标特征以外的其他特征的数据记录X</span></span><br><span class="line">X = data[[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>]]  <span class="comment"># 使用双括号选择多列</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取目标特征`销量`的数据记录y</span></span><br><span class="line">y = data[<span class="string">&quot;销量&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用train_test_split函数划分训练集train_X, train_y和测试集test_X, test_y</span></span><br><span class="line"><span class="comment">## 测试集所占比例为0.1,random_state为0</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 构建分支节点选择方法为基尼指数的决策树模型tree_model，进行模型训练、测试与性能评估</span></span><br><span class="line">tree_model = DecisionTreeClassifier(criterion=<span class="string">&#x27;gini&#x27;</span>)  <span class="comment"># 设置基尼指数准则</span></span><br><span class="line">tree_model.fit(train_X, train_y)  <span class="comment"># 模型训练</span></span><br><span class="line"></span><br><span class="line">pred_y = tree_model.predict(test_X)  <span class="comment"># 测试集预测</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型分类报告：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y))  <span class="comment"># 输出评估报告</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 决策树可视化（修正特征名称与数据列一致）</span></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line">dot_data = export_graphviz(</span><br><span class="line">    tree_model,</span><br><span class="line">    out_file=<span class="literal">None</span>,</span><br><span class="line">    feature_names=[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>],  <span class="comment"># 修正为完整特征名称</span></span><br><span class="line">    class_names=[<span class="string">&quot;销量低&quot;</span>, <span class="string">&quot;销量高&quot;</span>],</span><br><span class="line">    filled=<span class="literal">True</span>,</span><br><span class="line">    rounded=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph</span><br></pre></td></tr></table></figure>
<pre><code>模型分类报告：

              precision    recall  f1-score   support</code></pre>
<p>​</p>
<pre><code>           0       1.00      0.50      0.67         2

           1       0.67      1.00      0.80         2</code></pre>
<p>​</p>
<pre><code>    accuracy                           0.75         4

   macro avg       0.83      0.75      0.73         4

weighted avg       0.83      0.75      0.73         4</code></pre>
<p>​</p>
<p>​<br>
<img src="/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/main_7_1.svg" alt="svg"> ​</p>
<blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/f7c9f4d97660416b9ac354a1bcd6c87efcb7a0958cfa4579bf70a83d01ee64f7">
<img src="https://ai-studio-static-online.cdn.bcebos.com/eb46fe19bf43414290f904042a511f25140e1908a2eb4c2e81c52450f1de68bd"></p>
<h2 id="任务3利用任务1的cal_infogain函数自行实现id3决策树算法">任务3：利用任务1的cal_infoGain函数自行实现ID3决策树算法</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的熵计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line"></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数分布</span></span><br><span class="line"></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line"></span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（Σ -p_i log2(p_i)）</span></span><br><span class="line"></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的信息增益计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line"></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line"></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 所有特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自动识别目标特征（假设目标特征不在特征列表中）</span></span><br><span class="line"></span><br><span class="line">    target_feature = [col <span class="keyword">for</span> col <span class="keyword">in</span> feature_list <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> data.columns][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    feature_list = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]  <span class="comment"># 移除目标特征</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line"></span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布</span></span><br><span class="line"></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line"></span><br><span class="line">            subset = data[data[feature] == value]  <span class="comment"># 特征取当前值的子集</span></span><br><span class="line"></span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line"></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 累加加权熵</span></span><br><span class="line"></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, target_feature)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算信息增益</span></span><br><span class="line"></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line"></span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 选择最优特征</span></span><br><span class="line"></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大信息增益值</span></span><br><span class="line"></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line"></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 最优特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## ID3决策树实现</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ID3DecisionTree</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="literal">None</span>  <span class="comment"># 存储决策树结构</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = <span class="literal">None</span>  <span class="comment"># 目标特征名称</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, data, target_feature</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        训练决策树模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 包含特征和目标列的DataFrame</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param target_feature: 目标特征名称（如&#x27;销量&#x27;）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = target_feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取特征列表（排除目标特征）</span></span><br><span class="line"></span><br><span class="line">        features = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建决策树</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="variable language_">self</span>._build_tree(data, features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_tree</span>(<span class="params">self, data, features</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 当前节点的数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param features: 当前可用的特征列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 字典形式的树节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件1：所有样本属于同一类别</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(data[<span class="variable language_">self</span>.target].unique()) == <span class="number">1</span>:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: data[<span class="variable language_">self</span>.target].values[<span class="number">0</span>],  <span class="comment"># 叶节点类别</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件2：无剩余特征可用时选择多数类</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> features:</span><br><span class="line"></span><br><span class="line">            class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),  <span class="comment"># 多数类</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算当前数据集的熵</span></span><br><span class="line"></span><br><span class="line">        base_entropy = cal_entropy(data, <span class="variable language_">self</span>.target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取最优特征和信息增益列表</span></span><br><span class="line"></span><br><span class="line">        info_gains, best_feature = cal_infoGain(data, base_entropy)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建当前树节点</span></span><br><span class="line"></span><br><span class="line">        node = &#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;feature&#x27;</span>: best_feature,  <span class="comment"># 分裂特征</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;info_gain&#x27;</span>: info_gains[features.index(best_feature)],  <span class="comment"># 信息增益值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data),  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;children&#x27;</span>: &#123;&#125;  <span class="comment"># 子节点</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建子树（排除当前最优特征）</span></span><br><span class="line"></span><br><span class="line">        remaining_features = [f <span class="keyword">for</span> f <span class="keyword">in</span> features <span class="keyword">if</span> f != best_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历最优特征的所有取值</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> data[best_feature].unique():</span><br><span class="line"></span><br><span class="line">            subset = data[data[best_feature] == value]  <span class="comment"># 获取子集</span></span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 处理空子集（采用父节点多数类）</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> subset.empty:</span><br><span class="line"></span><br><span class="line">                class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;samples&#x27;</span>: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 递归构建子树</span></span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = <span class="variable language_">self</span>._build_tree(subset, remaining_features)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        对新样本进行预测</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param X: 特征数据（DataFrame格式）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 预测结果列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        predictions = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历每个样本</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _, sample <span class="keyword">in</span> X.iterrows():</span><br><span class="line"></span><br><span class="line">            current_node = <span class="variable language_">self</span>.tree</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 遍历树直到叶节点</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                feature = current_node[<span class="string">&#x27;feature&#x27;</span>]  <span class="comment"># 当前分裂特征</span></span><br><span class="line"></span><br><span class="line">                value = sample[feature]  <span class="comment"># 样本在该特征的取值</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 处理未见过的特征值（采用当前节点多数类）</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> value <span class="keyword">not</span> <span class="keyword">in</span> current_node[<span class="string">&#x27;children&#x27;</span>]:</span><br><span class="line"></span><br><span class="line">                    class_counts = <span class="variable language_">self</span>._get_class_counts(current_node)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 选择样本数最多的类别</span></span><br><span class="line"></span><br><span class="line">                    predictions.append(<span class="built_in">max</span>(class_counts, key=class_counts.get))</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">break</span>  <span class="comment"># 跳出循环</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 移动到子节点</span></span><br><span class="line"></span><br><span class="line">                current_node = current_node[<span class="string">&#x27;children&#x27;</span>][value]</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 记录叶节点类别</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                predictions.append(current_node[<span class="string">&#x27;class&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_class_counts</span>(<span class="params">self, node</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归统计节点中的类别分布</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 类别计数字典</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        counts = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果是叶节点直接返回</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;node[<span class="string">&#x27;class&#x27;</span>]: node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归统计子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].values():</span><br><span class="line"></span><br><span class="line">            child_counts = <span class="variable language_">self</span>._get_class_counts(child)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> cls, cnt <span class="keyword">in</span> child_counts.items():</span><br><span class="line"></span><br><span class="line">                counts[cls] = counts.get(cls, <span class="number">0</span>) + cnt</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> counts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">visualize</span>(<span class="params">self, feature_names, class_names</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        可视化决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: graphviz对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        dot = graphviz.Digraph()  <span class="comment"># 创建有向图</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建图形</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._build_graph(dot, <span class="variable language_">self</span>.tree, feature_names, class_names)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_graph</span>(<span class="params">self, dot, node, feature_names, class_names, parent=<span class="literal">None</span>, edge_label=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建graphviz图形</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param dot: graphviz.Digraph对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param parent: 父节点（用于连接边）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param edge_label: 边标签（特征取值）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 叶节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;class_names[<span class="built_in">int</span>(node[<span class="string">&#x27;class&#x27;</span>])]&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),  <span class="comment"># 唯一节点ID</span></span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;box&quot;</span>,  <span class="comment"># 矩形框</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,  <span class="comment"># 填充颜色</span></span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightblue&quot;</span>  <span class="comment"># 浅蓝色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 内部节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;node[<span class="string">&#x27;feature&#x27;</span>]&#125;</span>\\nIG=<span class="subst">&#123;node[<span class="string">&#x27;info_gain&#x27;</span>]:<span class="number">.3</span>f&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;ellipse&quot;</span>,  <span class="comment"># 椭圆</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,</span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightgreen&quot;</span>  <span class="comment"># 浅绿色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建父节点到当前节点的边</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> parent:</span><br><span class="line"></span><br><span class="line">            dot.edge(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(parent)),</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label=edge_label  <span class="comment"># 显示特征取值</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归处理子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> value, child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].items():</span><br><span class="line"></span><br><span class="line">                <span class="variable language_">self</span>._build_graph(</span><br><span class="line"></span><br><span class="line">                    dot,</span><br><span class="line"></span><br><span class="line">                    child,</span><br><span class="line"></span><br><span class="line">                    feature_names,</span><br><span class="line"></span><br><span class="line">                    class_names,</span><br><span class="line"></span><br><span class="line">                    node,  <span class="comment"># 当前节点作为父节点</span></span><br><span class="line"></span><br><span class="line">                    <span class="built_in">str</span>(value)  <span class="comment"># 边标签为特征取值</span></span><br><span class="line"></span><br><span class="line">                )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机实验11--核化分类器判定西瓜好坏</title>
    <url>/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/</url>
    <content><![CDATA[<h1 id="上机实验11核化分类器判定西瓜好坏">上机实验11：核化分类器判定西瓜好坏</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&quot;work/西瓜数据集3.0α.txt&quot;</span>)</span><br><span class="line">data</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">yes = data[data[<span class="string">&#x27;Good melon&#x27;</span>].isin([<span class="string">&#x27;是&#x27;</span>])]</span><br><span class="line">no = data[data[<span class="string">&#x27;Good melon&#x27;</span>].isin([<span class="string">&#x27;否&#x27;</span>])]</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax.scatter(yes[<span class="string">&#x27;Density&#x27;</span>], yes[<span class="string">&#x27;Sugar content&#x27;</span>], marker=<span class="string">&#x27;o&#x27;</span>, c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Yes&#x27;</span>)</span><br><span class="line">ax.scatter(no[<span class="string">&#x27;Density&#x27;</span>], no[<span class="string">&#x27;Sugar content&#x27;</span>], marker=<span class="string">&#x27;x&#x27;</span>, c=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;No&#x27;</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Sugar content&#x27;</span>)</span><br><span class="line">plt.show() <span class="comment"># 可以发现线性不可分</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_3_0.png" alt="output_3_0">
<figcaption aria-hidden="true">output_3_0</figcaption>
</figure>
<h2 id="任务1svm分类器判定西瓜好坏">任务1：SVM分类器判定西瓜好坏</h2>
<p>在SVM分类器中，使用线性核与高斯核进行比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用线性核与高斯核进行比较</span></span><br><span class="line">linear_svc = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>)  <span class="comment"># 线性核</span></span><br><span class="line">rbf_svc = svm.SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>)        <span class="comment"># 高斯核（RBF）</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp = &#123;<span class="string">&#x27;是&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;否&#x27;</span>: -<span class="number">1</span>&#125;</span><br><span class="line">X = np.array(data.iloc[:, :<span class="number">2</span>])</span><br><span class="line">y = np.array(data.iloc[:, <span class="number">2</span>].replace(temp))[<span class="literal">None</span>].T</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">linear_svc.fit(X, y)</span><br><span class="line">linear_svc.score(X,y)</span><br><span class="line"><span class="comment"># 查看支持向量</span></span><br><span class="line">linear_svc.support_vectors_</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)





array([[0.666, 0.091],
       [0.243, 0.267],
       [0.343, 0.099],
       [0.639, 0.161],
       [0.657, 0.198],
       [0.36 , 0.37 ],
       [0.593, 0.042],
       [0.719, 0.103],
       [0.697, 0.46 ],
       [0.774, 0.376],
       [0.634, 0.264],
       [0.608, 0.318],
       [0.556, 0.215],
       [0.403, 0.237],
       [0.481, 0.149],
       [0.437, 0.211]])</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rbf_svc.fit(X, y)</span><br><span class="line">rbf_svc.score(X,y)</span><br><span class="line"><span class="comment"># 查看支持向量</span></span><br><span class="line">rbf_svc.support_vectors_</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

array([[0.666, 0.091],
       [0.243, 0.267],
       [0.245, 0.057],
       [0.343, 0.099],
       [0.639, 0.161],
       [0.657, 0.198],
       [0.36 , 0.37 ],
       [0.593, 0.042],
       [0.719, 0.103],
       [0.697, 0.46 ],
       [0.774, 0.376],
       [0.634, 0.264],
       [0.608, 0.318],
       [0.556, 0.215],
       [0.403, 0.237],
       [0.481, 0.149],
       [0.437, 0.211]])</code></pre>
<h2 id="任务2kernel-logistic-regression-判定西瓜好坏">任务2：Kernel
Logistic Regression 判定西瓜好坏</h2>
<p>将原始的Logistic Regression 进行核化，使用不同的核函数进行比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.colors <span class="keyword">as</span> colors</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>:</span><br><span class="line">    kern_param = <span class="number">0</span></span><br><span class="line">    X = np.array([])</span><br><span class="line">    a = np.array([])</span><br><span class="line">    kernel = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel=<span class="string">&#x27;poly&#x27;</span>, kern_param=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> kernel == <span class="string">&#x27;poly&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__linear__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> kernel == <span class="string">&#x27;gaussian&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__gaussian__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">0.1</span></span><br><span class="line">        <span class="keyword">elif</span> kernel == <span class="string">&#x27;laplace&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__laplace__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y, max_rate=<span class="number">100</span>, min_rate=<span class="number">0.001</span>, gd_step=<span class="number">10</span>, epsilon=<span class="number">0.0001</span></span>):</span><br><span class="line">        m = <span class="built_in">len</span>(X)</span><br><span class="line">        <span class="variable language_">self</span>.X = np.vstack([X.T, np.ones(m)]).T</span><br><span class="line">        <span class="comment"># Construct kernel matrix</span></span><br><span class="line">        K =<span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X, <span class="variable language_">self</span>.X, <span class="variable language_">self</span>.kern_param)  <span class="comment"># 填空1：计算核矩阵</span></span><br><span class="line">        <span class="comment"># Gradient descent</span></span><br><span class="line">        <span class="variable language_">self</span>.a = np.zeros([m])</span><br><span class="line">        prev_cost = <span class="number">0</span></span><br><span class="line">        next_cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">        <span class="keyword">while</span> np.fabs(prev_cost-next_cost) &gt; epsilon:</span><br><span class="line">            neg_grad = -<span class="variable language_">self</span>.__gradient__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">            best_rate = rate = max_rate</span><br><span class="line">            min_cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">            <span class="keyword">while</span> rate &gt;= min_rate:</span><br><span class="line">                cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a+neg_grad*rate)</span><br><span class="line">                <span class="keyword">if</span> cost &lt; min_cost:</span><br><span class="line">                    min_cost = cost</span><br><span class="line">                    best_rate = rate</span><br><span class="line">                rate /= gd_step</span><br><span class="line">            <span class="variable language_">self</span>.a += neg_grad * best_rate</span><br><span class="line">            prev_cost = next_cost</span><br><span class="line">            next_cost = min_cost</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 1. 添加偏置项（与训练数据处理一致）</span></span><br><span class="line">        X = np.vstack([X.T, np.ones(<span class="built_in">len</span>(X))]).T  <span class="comment"># 形状变为 (n_samples, n_features + 1)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 计算核矩阵（训练数据与测试数据之间的核函数值）</span></span><br><span class="line">        K = <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X, X, <span class="variable language_">self</span>.kern_param)  <span class="comment"># 形状：(训练样本数, 测试样本数)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 计算预测得分（关键修正：移除 self.Y 的乘法）</span></span><br><span class="line">        pred = np.dot(<span class="variable language_">self</span>.a, K) </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. Sigmoid转换为概率并二值化</span></span><br><span class="line">        prob = <span class="variable language_">self</span>.__sigmoid__(pred)</span><br><span class="line">        <span class="keyword">return</span> (prob &gt;= <span class="number">0.5</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Kernels</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__linear__</span>(<span class="params">a, b, parameter</span>):</span><br><span class="line">        <span class="keyword">return</span> np.dot(a, np.transpose(b))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__gaussian__</span>(<span class="params">a, b, kern_param</span>):</span><br><span class="line">        mat = np.zeros([<span class="built_in">len</span>(a), <span class="built_in">len</span>(b)])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(b)):</span><br><span class="line">                mat[i][j] = np.exp(-np.<span class="built_in">sum</span>(np.square(np.subtract(a[i], b[j]))) / (<span class="number">2</span> * kern_param * kern_param))</span><br><span class="line">        <span class="keyword">return</span> mat</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__laplace__</span>(<span class="params">a, b, kern_param</span>):</span><br><span class="line">        mat = np.zeros([<span class="built_in">len</span>(a), <span class="built_in">len</span>(b)])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(b)):</span><br><span class="line">                mat[i][j] = np.exp(-np.linalg.norm(np.subtract(a[i], b[j])) / kern_param)</span><br><span class="line">        <span class="keyword">return</span> mat</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__sigmoid__</span>(<span class="params">X</span>):</span><br><span class="line">        <span class="keyword">return</span> np.exp(X) / (<span class="number">1</span> + np.exp(X))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__cost__</span>(<span class="params">K, y, a</span>):</span><br><span class="line">        <span class="keyword">return</span> -np.dot(y, np.dot(a, K)) + np.<span class="built_in">sum</span>(np.log(<span class="number">1</span> + np.exp(np.dot(a, K))))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__gradient__</span>(<span class="params">cls, K, y, a</span>):</span><br><span class="line">        <span class="keyword">return</span> -np.dot(K, y - cls.__sigmoid__(np.dot(a, K)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read data</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;work/西瓜数据集3.0α.txt&quot;</span>)</span><br><span class="line">X = np.array(data[[<span class="string">&#x27;Density&#x27;</span>, <span class="string">&#x27;Sugar content&#x27;</span>]])</span><br><span class="line">y = np.array(data[<span class="string">&#x27;Good melon&#x27;</span>]) == <span class="string">&#x27;是&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Kernels</span></span><br><span class="line">kernels = [<span class="string">&#x27;poly&#x27;</span>, <span class="string">&#x27;gaussian&#x27;</span>, <span class="string">&#x27;laplace&#x27;</span>]</span><br><span class="line">titles = [<span class="string">&#x27;linear kernel&#x27;</span>, <span class="string">&#x27;gaussian kernel, σ=0.1&#x27;</span>, <span class="string">&#x27;laplace kernel, σ=0.1&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(kernels)):</span><br><span class="line">    <span class="comment"># Training</span></span><br><span class="line">    <span class="comment"># 填空3：实例化并训练模型</span></span><br><span class="line">    model = LogisticRegression(kernel=kernels[i])</span><br><span class="line">    model.fit(X, y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Plot</span></span><br><span class="line">    cmap = colors.LinearSegmentedColormap.from_list(<span class="string">&#x27;watermelon&#x27;</span>, [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>])</span><br><span class="line">    xx, yy = np.meshgrid(np.arange(<span class="number">0.2</span>, <span class="number">0.8</span>, <span class="number">0.01</span>), np.arange(<span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">0.01</span>))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    plt.contourf(xx, yy, Z, cmap=cmap, alpha=<span class="number">0.3</span>, antialiased=<span class="literal">True</span>)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sugar content&#x27;</span>)</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:97: RuntimeWarning: overflow encountered in exp</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_1.png" alt="output_10_1">
<figcaption aria-hidden="true">output_10_1</figcaption>
</figure>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_2.png" alt="output_10_2">
<figcaption aria-hidden="true">output_10_2</figcaption>
</figure>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_3.png" alt="output_10_3">
<figcaption aria-hidden="true">output_10_3</figcaption>
</figure>
<h3 id="线性核linear-kernel"><strong>1. 线性核（Linear
Kernel）</strong></h3>
<ul>
<li><strong>数学形式</strong>：<br>
[ K(x_i, x_j) = x_i^T x_j + c (c ) ]</li>
<li><strong>特点</strong>：
<ul>
<li>直接计算特征向量的内积，不进行非线性映射。<br>
</li>
<li>决策边界为线性超平面，计算效率高。<br>
</li>
</ul></li>
<li><strong>适用场景</strong>：
<ul>
<li>数据线性可分（如两类可通过一条直线/平面分开）。<br>
</li>
<li>特征维度较高时（避免核方法的计算开销）。<br>
</li>
</ul></li>
<li><strong>西瓜数据集表现</strong>：
<ul>
<li>生成直线决策边界，可能误分类非线性分布的样本。</li>
</ul></li>
</ul>
<hr>
<h3 id="高斯核gaussianrbf-kernel"><strong>2. 高斯核（Gaussian/RBF
Kernel）</strong></h3>
<ul>
<li><strong>数学形式</strong>：<br>
[ K(x_i, x_j) = (-|x_i - x_j|^2) (&gt; 0) ]</li>
<li><strong>特点</strong>：
<ul>
<li>基于样本间的欧氏距离（L2距离），隐式映射到无限维空间。<br>
</li>
<li>参数 <code>γ</code> 控制影响范围：<code>γ</code>
越大，局部性越强（对邻近点更敏感）。<br>
</li>
</ul></li>
<li><strong>适用场景</strong>：
<ul>
<li>数据非线性可分（如环形分布、复杂流形）。<br>
</li>
<li>特征维度较低或中等时效果最佳。<br>
</li>
</ul></li>
<li><strong>西瓜数据集表现</strong>：
<ul>
<li>生成平滑的非线性边界，能捕捉密度与含糖量的复杂交互关系。</li>
</ul></li>
</ul>
<hr>
<h3 id="拉普拉斯核laplace-kernel"><strong>3. 拉普拉斯核（Laplace
Kernel）</strong></h3>
<ul>
<li><strong>数学形式</strong>：<br>
[ K(x_i, x_j) = (-|x_i - x_j|_1) (&gt; 0) ]</li>
<li><strong>特点</strong>：
<ul>
<li>基于曼哈顿距离（L1距离），对异常值鲁棒性更强。<br>
</li>
<li>隐式映射到无限维空间，但形状更尖锐（适合非光滑边界）。<br>
</li>
</ul></li>
<li><strong>适用场景</strong>：
<ul>
<li>数据分布不规则或存在离群点。<br>
</li>
<li>特征具有稀疏性（如文本分类）。<br>
</li>
</ul></li>
<li><strong>西瓜数据集表现</strong>：
<ul>
<li>生成尖锐的非线性边界，可能更好地处理边缘样本。</li>
</ul></li>
</ul>
<p>以下是欧氏距离（Euclidean Distance）与曼哈顿距离（Manhattan
Distance）的详细对比：</p>
<hr>
<h3 id="数学定义"><strong>1. 数学定义</strong></h3>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 62%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th>距离类型</th>
<th>公式</th>
<th>几何意义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>欧氏距离</strong></td>
<td>( |x - y|_2 = )</td>
<td>两点之间的<strong>直线距离</strong></td>
</tr>
<tr class="even">
<td><strong>曼哈顿距离</strong></td>
<td>( |x - y|<em>1 = </em>{i=1}^n</td>
<td>x_i - y_i</td>
</tr>
</tbody>
</table>
<h3 id="选择建议"><strong>5. 选择建议</strong></h3>
<ul>
<li><strong>优先欧氏距离</strong>：<br>
数据分布连续、特征维度较低、需要捕捉局部相似性时（如图像分类）。</li>
<li><strong>优先曼哈顿距离</strong>：<br>
数据稀疏（如文本）、存在噪声或异常值、特征维度较高时（如推荐系统）。</li>
</ul>
<hr>
<h3 id="示例对比"><strong>示例对比</strong></h3>
<p>假设两点 ( A(1, 1) ) 和 ( B(4, 5) )：</p>
<ul>
<li><strong>欧氏距离</strong>：<br>
[ = 5 ]</li>
<li><strong>曼哈顿距离</strong>：<br>
[ |4-1| + |5-1| = 3 + 4 = 7 ]</li>
</ul>
<hr>
<h3 id="总结"><strong>总结</strong></h3>
<ul>
<li><strong>欧氏距离</strong>：强调“直线最短”，适合低维连续数据。<br>
</li>
<li><strong>曼哈顿距离</strong>：强调“网格路径”，适合高维稀疏数据。<br>
</li>
<li><strong>在核函数中的体现</strong>：
<ul>
<li>高斯核通过欧氏距离捕捉平滑边界，拉普拉斯核通过曼哈顿距离增强鲁棒性。</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机实验9--神经网络</title>
    <url>/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1 id="上机实验9神经网络">上机实验9：神经网络</h1>
<h2 id="任务1神经元模型">任务1：神经元模型</h2>
<ul>
<li>给定数据集X和y</li>
<li>请补全以下代码以实现一个简单的神经元模型（即不包含隐层），并计算模型的参数向量w_vec</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 输入X和y</span></span><br><span class="line">X = np.array([ [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">y = np.array([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]]).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># Sigmoid激活函数以及其导数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x, derivative = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># 计算sigmoid的输出</span></span><br><span class="line">    sigmoid_value =<span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">    <span class="keyword">if</span> derivative == <span class="literal">False</span>:     </span><br><span class="line">        <span class="keyword">return</span> sigmoid_value</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> derivative == <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 计算sigmoid的导数</span></span><br><span class="line">        <span class="keyword">return</span> sigmoid_value * (<span class="number">1</span> - sigmoid_value)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代次数</span></span><br><span class="line">iter_num  = <span class="number">1000</span></span><br><span class="line">eta = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化权重向量w</span></span><br><span class="line">num, dim = X.shape</span><br><span class="line">w_vec = np.ones((dim, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(iter_num):</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## X通过权重向量w_vec，实现线性加和，结果为z1</span></span><br><span class="line">    z_1 =  X.dot(w_vec)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 经过激活函数Sigmoid，获得输出a_1</span></span><br><span class="line">    a_1 = sigmoid(z_1)</span><br><span class="line">      </span><br><span class="line">    <span class="comment"># 模型输出a_1与真实值的误差</span></span><br><span class="line">    error = a_1 - y</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 权重更新</span></span><br><span class="line">    w_vec_delta = X.T.dot(error * sigmoid(z_1, derivative=<span class="literal">True</span>))</span><br><span class="line">    w_vec = w_vec + eta*w_vec_delta  </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (w_vec)</span><br></pre></td></tr></table></figure>
<pre><code>[[0.94321144]
 [1.83125284]
 [4.71149329]]</code></pre>
<h2 id="任务2-感知机">任务2： 感知机</h2>
<p>1．感知机是根据输入实例的特征向量<span class="math inline"><em>x</em></span>对其进行二类分类的线性分类模型：</p>
<p><span class="math display"><em>f</em>(<em>x</em>) = sign (<em>w</em>⋅<em>x</em>+<em>b</em>)</span></p>
<p>感知机模型对应于输入空间（特征空间）中的分离超平面<span class="math inline"><em>w</em> ⋅ <em>x</em> + <em>b</em> = 0</span>。</p>
<p>2．感知机学习的策略是极小化损失函数：</p>
<p><span class="math display">min<sub><em>w</em>, <em>b</em></sub><em>L</em>(<em>w</em>,<em>b</em>) =  − ∑<sub><em>x</em><sub><em>i</em></sub> ∈ <em>M</em></sub><em>y</em><sub><em>i</em></sub>(<em>w</em>⋅<em>x</em><sub><em>i</em></sub>+<em>b</em>)</span></p>
<p>损失函数对应于误分类点到分离超平面的总距离。</p>
<p>3．感知机学习算法是基于随机梯度下降法的对损失函数的最优化算法，有原始形式和对偶形式。算法简单且易于实现。原始形式中，首先任意选取一个超平面，然后用梯度下降法不断极小化目标函数。在这个过程中一次随机选取一个误分类点使其梯度下降。</p>
<p>4．当训练数据集线性可分时，感知机学习算法是收敛的。感知机算法在训练数据集上的误分类次数<span class="math inline"><em>k</em></span>满足不等式：</p>
<p><span class="math display">$$
k \leqslant\left(\frac{R}{\gamma}\right)^{2}
$$</span></p>
<p>当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同。</p>
<ol start="5" type="1">
<li>随机梯度下降算法 Stochastic Gradient Descent：</li>
</ol>
<p>随机抽取一个误分类点使其梯度下降。</p>
<p><span class="math inline"><em>w</em> = <em>w</em> + <em>η</em><em>y</em><sub><em>i</em></sub><em>x</em><sub><em>i</em></sub></span></p>
<p><span class="math inline"><em>b</em> = <em>b</em> + <em>η</em><em>y</em><sub><em>i</em></sub></span></p>
<p>当实例点被误分类，即位于分离超平面的错误侧，则调整<span class="math inline"><em>w</em></span>, <span class="math inline"><em>b</em></span>的值，使分离超平面向该无分类点的一侧移动，直至误分类点被正确分类。</p>
<p><strong>使用iris数据集中两个类别的数据和[sepal length，sepal
width]作为特征，进行感知机分类。</strong></p>
<ol type="1">
<li>自定义感知机模型，实现iris数据分类；</li>
<li>调用sklearn中Perceptron函数来分类；</li>
<li>验证感知机为什么不能表示异或（选做）。</li>
</ol>
<h3 id="自定义感知机模型实现iris数据分类">1.
自定义感知机模型，实现iris数据分类</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line"></span><br><span class="line">df.columns = [</span><br><span class="line">    <span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>, <span class="string">&#x27;label&#x27;</span></span><br><span class="line">]</span><br><span class="line">df.label.value_counts()</span><br><span class="line"></span><br><span class="line">data = np.array(df.iloc[:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">X, y = data[:,:-<span class="number">1</span>], data[:,-<span class="number">1</span>]</span><br><span class="line">y = np.array([<span class="number">1</span> <span class="keyword">if</span> i == <span class="number">1</span> <span class="keyword">else</span> -<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> y])</span><br><span class="line"></span><br><span class="line">plt.scatter(df[:<span class="number">50</span>][<span class="string">&#x27;sepal length&#x27;</span>], df[:<span class="number">50</span>][<span class="string">&#x27;sepal width&#x27;</span>], label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.scatter(df[<span class="number">50</span>:<span class="number">100</span>][<span class="string">&#x27;sepal length&#x27;</span>], df[<span class="number">50</span>:<span class="number">100</span>][<span class="string">&#x27;sepal width&#x27;</span>], label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f177628f110&gt;



/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_6_2.png" alt="output_6_2">
<figcaption aria-hidden="true">output_6_2</figcaption>
</figure>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据线性可分，二分类数据</span></span><br><span class="line"><span class="comment"># 此处为一元一次线性方程</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.w = np.ones(<span class="built_in">len</span>(data[<span class="number">0</span>]) - <span class="number">1</span>, dtype=np.float32)</span><br><span class="line">        <span class="variable language_">self</span>.b = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.l_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">self, x, w, b</span>):</span><br><span class="line">        y = np.sign(np.dot(x, w) + b)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机梯度下降法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X_train, y_train</span>):</span><br><span class="line">        is_wrong = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> is_wrong:</span><br><span class="line">            wrong_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train)):</span><br><span class="line">                X = X_train[d]</span><br><span class="line">                y = y_train[d]</span><br><span class="line">                <span class="keyword">if</span> y * (np.dot(X, <span class="variable language_">self</span>.w) + <span class="variable language_">self</span>.b) &lt;= <span class="number">0</span>: <span class="comment">#判断样本被误分类</span></span><br><span class="line">                    <span class="comment"># 更新权重和偏置</span></span><br><span class="line">                    <span class="variable language_">self</span>.w = <span class="variable language_">self</span>.w + <span class="variable language_">self</span>.l_rate * y * X</span><br><span class="line">                    <span class="variable language_">self</span>.b = <span class="variable language_">self</span>.b + <span class="variable language_">self</span>.l_rate * y</span><br><span class="line">                    wrong_count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> wrong_count == <span class="number">0</span>:</span><br><span class="line">                is_wrong = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Perceptron Model!&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进行模型训练</span></span><br><span class="line">perceptron = Model()</span><br><span class="line">perceptron.fit(X, y)</span><br><span class="line"></span><br><span class="line">x_points = np.linspace(<span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">y_ = -(perceptron.w[<span class="number">0</span>] * x_points + perceptron.b) / perceptron.w[<span class="number">1</span>]</span><br><span class="line">plt.plot(x_points, y_)</span><br><span class="line"></span><br><span class="line">plt.plot(data[:<span class="number">50</span>, <span class="number">0</span>], data[:<span class="number">50</span>, <span class="number">1</span>], <span class="string">&#x27;bo&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.plot(data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], <span class="string">&#x27;bo&#x27;</span>, color=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f1773a0c950&gt;</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_9_1.png" alt="output_9_1">
<figcaption aria-hidden="true">output_9_1</figcaption>
</figure>
<h3 id="调用sklearn中perceptron函数来分类">2.
调用sklearn中Perceptron函数来分类</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="comment"># 调用sklearn中Perceptron函数进行分类</span></span><br><span class="line">clf = Perceptron(</span><br><span class="line">    max_iter=<span class="number">5000</span>,      <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">    eta0=<span class="number">0.05</span>,           <span class="comment"># 调整学习率（原0.01可能过小）</span></span><br><span class="line">    shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 训练模型</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"><span class="comment"># Weights assigned to the features.</span></span><br><span class="line"><span class="built_in">print</span>(clf.coef_)</span><br><span class="line"><span class="comment"># 截距 Constants in decision function.</span></span><br><span class="line"><span class="built_in">print</span>(clf.intercept_)</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.16  -1.935]]
[-0.25]</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画布大小</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文标题</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.title(<span class="string">&#x27;鸢尾花线性数据示例&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(data[:<span class="number">50</span>, <span class="number">0</span>], data[:<span class="number">50</span>, <span class="number">1</span>], c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Iris-setosa&#x27;</span>,)</span><br><span class="line">plt.scatter(data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], c=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;Iris-versicolor&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画感知机的线</span></span><br><span class="line">x_ponits = np.arange(<span class="number">4</span>, <span class="number">8</span>)</span><br><span class="line">y_ = -(clf.coef_[<span class="number">0</span>][<span class="number">0</span>]*x_ponits + clf.intercept_)/clf.coef_[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">plt.plot(x_ponits, y_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他部分</span></span><br><span class="line">plt.legend()  <span class="comment"># 显示图例</span></span><br><span class="line">plt.grid(<span class="literal">False</span>)  <span class="comment"># 不显示网格</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f1769a4eb50&gt;



/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_12_2.png" alt="output_12_2">
<figcaption aria-hidden="true">output_12_2</figcaption>
</figure>
<h3 id="验证感知机为什么不能表示异或选做">3.
验证感知机为什么不能表示异或（选做）</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">x=np.array([[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line">y=np.array([<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">plt.plot(x[:<span class="number">2</span>,<span class="number">0</span>],x[:<span class="number">2</span>,<span class="number">1</span>],<span class="string">&#x27;bo&#x27;</span>,color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.plot(x[<span class="number">2</span>:<span class="number">4</span>,<span class="number">0</span>],x[<span class="number">2</span>:<span class="number">4</span>,<span class="number">1</span>],<span class="string">&#x27;bo&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>,label=<span class="string">&#x27;-1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 初始化感知机模型</span></span><br><span class="line">clf = Perceptron(</span><br><span class="line">    max_iter=<span class="number">1000</span>,      <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">    eta0=<span class="number">0.1</span>,           <span class="comment"># 学习率</span></span><br><span class="line">    random_state=<span class="number">42</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>        <span class="comment"># 每次迭代打乱数据</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出模型参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征权重 (w):&quot;</span>, clf.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;截距 (b):&quot;</span>, clf.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">predictions = clf.predict(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测结果:&quot;</span>, predictions)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;真实标签:&quot;</span>, y)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>特征权重 (w): [[0. 0.]]
截距 (b): [0.]
预测结果: [-1 -1 -1 -1]
真实标签: [ 1  1 -1 -1]


/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))</code></pre>
<figure>
<img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_14_2.png" alt="output_14_2">
<figcaption aria-hidden="true">output_14_2</figcaption>
</figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
</search>
