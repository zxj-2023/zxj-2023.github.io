<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>不要过分苛责自己</title>
    <url>/2024/11/25/diary/%E4%B8%8D%E8%A6%81%E8%BF%87%E5%88%86%E8%8B%9B%E8%B4%A3%E8%87%AA%E5%B7%B1/</url>
    <content><![CDATA[<h3 id="不要过分苛责自己"><a href="#不要过分苛责自己" class="headerlink" title="不要过分苛责自己"></a>不要过分苛责自己</h3><p>​        数竞的成绩出来，没有看到自己名字，不知道为什么还是有些难受，理性告诉我这是理所应当，因为我根本没有为这个比赛花任何时间，只有前一天晚上临时抱佛脚的两个小时，对于报名，却没有复习的原因，如果别人让我做出解释，我可能会说，那段时间太累了，这不是借口，我记忆中那段时间确实是挺累的，但现在我已经不记得我那段时间忙些了什么，或者为自己留下了什么实际性的收获，似乎什么都没有。</p>
<p>​        结果上看，我对待这个比赛的态度是放弃的，那既然已经决定放弃的事情，为什么还会有些难受呢，我想，一方面，我还对不劳而获存在不切实际的幻想，幻想着不复习，幻想着靠自己脑子那一点点知识，就想在竞赛中占有一席之地，幻想着运气一次又一次眷顾自己，事实会告诉我这是不可能的；另一方面，每个人的精力确实是有限的，但我总是比较贪心，这也想要，那也想要，结果就是应接不暇，这是好强导致的吗，感觉还是比较幼稚，没有舍弃与选择的魄力，没有舍弃的勇气的人，什么也改变不了，hhh突然想起巨人的台词，有些中二嗷，扯远了扯远了。</p>
<p>​        其实，就算做不到也没关系，现实已经一次又一次地证明了，人无完人，这件事你做不好不代表其他事你做不好啊，我并不喜欢钻研数学啊物理啊做题做试卷这种，但我决定参加一些项目，学习新的知识很有意思，我也确实在其他一些科研比赛中获得不错的成绩，为什么要为一个小小的数竟，过分地苛责自己呢，况且你一开始就没有好好准备他，失败是理所应当的，你并没有损失什么，看得开一些，向前看，不要为一些小失败而驻足不前，不要为一些小失败过分地苛责自己。</p>
<p>​       突然发现把一些心里话写下来，心情真的舒畅了很多，继续加油，不要停止奔跑。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>简历备份</title>
    <url>/2024/10/14/diary/zxj/</url>
    <content><![CDATA[<ul>
<li><h1 id="🧑‍💻-张熙浚"><a href="#🧑‍💻-张熙浚" class="headerlink" title="🧑‍💻 张熙浚"></a>🧑‍💻 张熙浚</h1><p>电话：18114477496｜ 个人网站：<a href="https://zxj-2023.github.io/">https://zxj-2023.github.io/</a></p>
<h2 id="教育背景"><a href="#教育背景" class="headerlink" title="教育背景"></a>教育背景</h2><p><strong>南京师范大学 - 本科 - 人工智能专业（2023.09-2027.07）</strong> <code>211</code> <code>双一流</code></p>
<ul>
<li><p><strong>语言：</strong>英语（CET4，589）</p>
</li>
<li><p><strong>校内任职：</strong>现任院学生会主任、班级学习委员；</p>
</li>
<li><p><strong>绩点综测：</strong>绩点综测排名均列专业前二；</p>
</li>
<li><p><strong>校园经历：</strong>在三次获得校优秀学生奖学金一等奖，校优秀学习奖，校三好学生；</p>
</li>
</ul>
<h2 id="个人荣誉"><a href="#个人荣誉" class="headerlink" title="个人荣誉"></a>个人荣誉</h2><ul>
<li><p><strong>全国大学生计算机设计大赛 - 全国级三等奖</strong> (2024)</p>
</li>
<li><p><strong>全国大学生数学建模大赛 - 江苏省一等奖</strong> (2024)</p>
</li>
<li><p><strong>全国大学生蓝桥杯程序算法设计 - 江苏省三等奖</strong></p>
</li>
<li><p><strong>大学生创新创业项目 - 省重点项目</strong> (2024)</p>
</li>
<li><p><strong><em>蓝桥杯</em>AIGC 数字内容创意设计大赛 - 国家级三等奖</strong>（2024）</p>
</li>
</ul>
<h2 id="项目经验"><a href="#项目经验" class="headerlink" title="项目经验"></a>项目经验</h2><p><strong>计算机设计大赛 - 基于 unity 的 2.5D 国风游戏设计 -（2024.03 - 2024.06）</strong></p>
<ul>
<li><p>围绕《九章算术》设计并开发了四大游戏场景，多个小游戏，动画，对话系统和ui界面。</p>
</li>
<li><p>在unity平台实现2.5D场景构建，利用playmaker插件实现可视化编程。</p>
</li>
<li><p>使用C#脚本完成游戏逻辑构建。</p>
</li>
</ul>
<p><strong>计算机设计大赛 - 基于 LightRAG 的本地安全大模型 -（2024.10 - 至今）</strong></p>
<ul>
<li><p>完成LightRAG与GraphRAG的对比，利用LightRAG实现知识检索增强功能,并利用neo4j实现知识图谱可视化。</p>
</li>
<li><p>采用pycharm+anaconda集成开发环境，使用ollama框架完成本地大模型部署。</p>
</li>
<li><p>后续会进行大模型的微调，数据集的清洗，网站搭建等工作。</p>
</li>
</ul>
<p><strong>25 年大学生创新创业项目 - 基于多模态特征融合的视频暴力行为识别方法研究 -（2024.09 - 至今）</strong></p>
<ul>
<li><p>完成了一种基于多模态特征融合的视频暴力行为识别算法，通过融合RGB模态、帧差模态以及Depth模态，使其能够准确、鲁棒地在复杂的真实环境下进行暴力行为识别。</p>
</li>
<li><p>完成了一种自适应的注意力算法用于多模态融合。让模型自适应地学习不同模态特征之间的权重关系。</p>
</li>
<li><p>完成了系统的设计，后续会继续进行开发。</p>
</li>
</ul>
<h2 id="竞赛经验"><a href="#竞赛经验" class="headerlink" title="竞赛经验"></a>竞赛经验</h2><p><strong>全国大学生数学建模大赛 - 江苏省一等奖 - （2024.09）</strong><br><strong>认证杯数学建模大赛（小美赛）- s奖 -（2024.12）</strong></p>
<ul>
<li>担任编程手一职，协同建模手完成了部分公式的推导等</li>
</ul>
<p><strong>蓝桥杯AIGC中数杯 - 国家级三等奖 -（2024.10）</strong></p>
<ul>
<li>利用市面上现有AIGC技术完成视频制作，实现docker部署stable Diffusion</li>
</ul>
<h2 id="自我评价"><a href="#自我评价" class="headerlink" title="自我评价"></a>自我评价</h2><ul>
<li><p>交际能力强，具备良好的口头表达和书面沟通能力，长于社交，具备丰富的活动组织经验</p>
</li>
<li><p>学习能力强，陌生的知识与技术会积极学习，会积极请教问题并听取建议</p>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>人生匆匆啊</title>
    <url>/2025/03/05/diary/%E5%8C%86%E5%8C%86%E5%95%8A/</url>
    <content><![CDATA[<h3 id="人生匆匆啊"><a href="#人生匆匆啊" class="headerlink" title="人生匆匆啊"></a>人生匆匆啊</h3><p>今天是2025年3月5日，是我的20岁生日，现在是9点45分，刚上完算法课，逃了上机课来到了机房，在开始一天的学习之前，我还是决定写一篇随笔记录一下自己的心情，或许多年之后，我已经忘记当时的心情，但这些文字会保留下来，会见证我的成长。</p>
<p>小时候，或许人人都希望生日到来的那一天，因为生日的到来意味着成长，代表着长大成人，当时的自己得知自己又成长了一岁，心中确实是喜悦的；但今日的我，却没有了这份喜悦，换来的是感慨与思考。自从上大学之后，觉得时间真的好快，转眼我已经是大二下的学生，四年的大学生活已经过半，我到底做了什么，有没有成长与进步，有没有荒度这些时光，这些天我无时无刻不反问自己。我觉得我还有很多事情，很多方面需要成长，但是时间却仿佛没有这么多了，大学本科毕业那年我22岁，如果在国内读研究生，那就是3年，毕业之后我就是25岁，在我的认知里，25岁就算是开始步入中年了，而那时的我才研究生毕业初入社会，可以说是稚嫩一无所有，这是我不能接受的。所以，这也是很大一部分原因让我选择出国留学，我希望更早地步入社会，去闯去打拼，而且就我自身而言，我觉得我的性格，在社会中会更能展现出优势，而不是科研的料。希望我可以在25岁这个结点，能做到小有成就，能做到让自己满意。</p>
<p> 再简单记录一下自己这个学期的情况，学校的课程基本要从早八上到下午三点，下课之后在图书馆学习到七点20左右，然后去吃饭，八点在健身房锻炼到9点半左右，十点多洗完澡跟好朋友玩一玩游戏到十二点左右。我秉承着德智体美劳全面发展与劳逸结合，学习不能光学书本上的知识，网上很多各种类型的视频也常常可以给我启发，学习劳累之后去运动运动把身体搞好，学就是学玩就是玩，我分的很开，所以我每天晚上多少会玩一会游戏让自己放松一下。</p>
<p>差不多就说到这吧，写一写随笔真的挺好的，我经常心中有很多话，仿佛构思鸿篇巨制，却常因懒惰没有记录下来，希望以后勤写勤记，加油！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>笨鸟的共鸣</title>
    <url>/2024/11/25/diary/%E7%AC%A8%E9%B8%9F%E5%85%88%E9%A3%9E/</url>
    <content><![CDATA[<h2 id="笨鸟的共鸣"><a href="#笨鸟的共鸣" class="headerlink" title="笨鸟的共鸣"></a>笨鸟的共鸣</h2><p>​    今天刷谈笑间，看的一位同学很沮丧，说自己在南师大感受到了前所未有的压力，自己是高考发挥超常才来到南师大的，而身边很多同学却是高考发挥失常，在大学的学习中感受同辈人巨大的压力，不禁让我引起共鸣。别人的失常发挥上的学校，却是高中三年竭尽全力的结晶，甚至是高考的超常发挥才带来的。想到这里，我不禁再次感慨人与人之间差距的巨大。</p>
<p>​    但是，大一一年已经过去，回望这一年，笨鸟变了吗，变了，这只原来的笨鸟也获得很多成就，也在成长，也遇到很多同行路上的好友，甚至也成了别人口中的优秀者。但他真的变了吗，其实没变，他还是那只笨鸟，天赋比他好的大有人在，比他努力者也数不胜数，他始终要以一种谦逊的态度，然后不断学习，不断奔跑。高中，大学，都只是一个跳板，这种笨鸟天生不会飞，通过这一个个跳板，爬至高处，才能看见世间美景。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>未来的选择</title>
    <url>/2025/03/01/diary/%E6%9C%AA%E6%9D%A5%E7%9A%84%E9%80%89%E6%8B%A9/</url>
    <content><![CDATA[<h3 id="未来的选择"><a href="#未来的选择" class="headerlink" title="未来的选择"></a>未来的选择</h3><p>前一阵子与很久不见的学长交谈了一阵，两个小时感觉转瞬即逝，从未来选择到现在学业，和学长的交谈总能让我醍醐灌顶。我很喜欢和优秀的人谈话，他们的想法和建议总能让我豁然开朗。我最近一直对未来的选择十分迷惘，想学的东西太多，但时间精力有限，这时候就不得不做出选择。我需要好好想想我未来到底想从事什么方向的工作，并以此为目标钻研下去，而不是像无头苍蝇一样这学一点那学一点，泛而不精的人企业是不会要的。</p>
<p>摆在我眼前的有三个选择，第一个，我最近一直在看前端的知识，并跟着网上的教程编点小项目实操一下，我考虑的是一方面大创需要前端，我近期就可以用得上，另一方面我学的并不是前端很深入的知识，做一个知识上的普及还是有必要的；第二个，近期又来到计算机设计大赛的时间点，我要不要重拾unity的学习，后面走unity游戏开发方向的工作呢。但其实现在这个我不考虑了；第三个，我个人对金融，投资很感兴趣，我自己又是人工智能专业，后续去香港留学也想走ai+金融的方向，我是不是应该把更多的时间用在学习ai相关呢。</p>
<p>学长建议我还是要把更多的时间花在ai相关的学习，现在ai正是主流方向，沿着这个方向努力肯定是不会有问题的，平时要把人工智能相关的专业课，比如机器学习等，学扎实，而且我既然打算香港读研也是这个方向，就更要把时间花在这个地方。后续我打算把手头的项目写完后，有时间就开始在网上学习相关知识。</p>
<p>感觉废话有点多了，特别是上大学之后，选择与方向真的太多，但不管是哪个选择，都要大步走下去，而不是犹犹豫豫原地踏步，任重而道远啊！</p>
<p>最后说点题外话，把能认识到像学长这样优秀的人，我着实感到十分幸运。这两天又看了看学长的博客，每次看都能让我受益良多，我能开始写博客很大部分也受他的影响，但相比之下，确实感到自惭形愧，向学长学习！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>梦开始的地方</title>
    <url>/2024/10/13/diary/Blog/</url>
    <content><![CDATA[<p>这是梦开始的地方</p>
<p>我一直觉得写文章是一件很酷的事情，但奈何自己文采实在有限，又没有练习写作读书的勤奋劲，所以一直搁置，还记得刚上大学那一阵，看了两位学长自己搭的博客，写了很多自己的文章，记录着自己的成长，不仅是对自己成长的记录，也是对后辈的鼓励和启示，真的让我十分崇拜与鼓舞，于是就在心中埋下搭建自己心中埋下搭建自己博客的种子，但因学业和惰性一直搁置下来，还有个重要原因就是，我不知道我的博客应该写些什么，这使我没有动力继续前进。</p>
<p>直到前阵子，我与我的父亲在车上谈话，他与我聊起了他年轻时做贸易的故事，他说他对市场的判断总能先于他人，甚至08年金融危机，他也做出了正确的判断，他与我分享说，他一个很重要的习惯就是，把他读书看新闻遇到的信息整合，实实在在地写下来，记录下来到一个本子上。可能这对别人觉得很正常，但我却很震撼，我没想到不光是我的同龄人们这样做，我的父母辈也是如此，这样一个宝贵的经验我实在应该学习。</p>
<p>现在我已经步入大二，接触的事物也比大一扩展了很多，我绝对不能再等待，即使现在写不好，只要开始就是进步，后面我希望能把我的所思所想，进步痕迹通通记录下来，我的博客不光是我的名片，让大家更好地了解我，也是我自己宝贵的回忆！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>天下英雄如过江之鲫</title>
    <url>/2025/06/24/diary/%E5%A4%A9%E4%B8%8B%E8%8B%B1%E9%9B%84%E5%A6%82%E8%BF%87%E6%B1%9F%E4%B9%8B%E9%B2%AB/</url>
    <content><![CDATA[<p>当你来到双非，你会艳羡211的牌子，当你拼死考上211，你会发现985的头衔会处处卡死你。当你侥幸考上末流 985，你就会发现华五c9的光芒压的你喘不过气。若你真问鼎华五，抬头看，京城中双日凌空。或许你是真正的天才，清北中的佼佼者，他们告诉你，世界不止中国。当你最终成为这一世最不折不扣的天才，你会发现欧拉，黎曼，还有7岁因为想快点放学而创造求和公式的高斯， 早已在山顶等候多时。</p>
<p>有时候想想，这学上到多高才算高啊，大专上面有本科，本科上面有硕博，好不容易毕业了吧，副高，正高，青基，博导，在上面还有杰青，院士。唉，天下英雄，如过江之鲫，无穷尽也。之前没有感觉，自从上了大学，这种感受就像一团乌云一直萦绕在我心头，不禁反思人这一生究竟在追求什么。</p>
<p>大多数人追求的东西，无非三者：权钱学。</p>
<p>有的人梦想升官，但官外有官，权外有权，科级处级厅级，省部级已经算是人中龙凤，但上面还有副国级正国级，大多数人忙忙碌碌一生也就当个副处级，他们真的甘心吗，那种拼劲全力也无法跨过的鸿沟，最后只剩下无奈，遗憾和释然。</p>
<p>有人的渴望财富，赚到了十万就想赚百万，赚到了百万又开始想办法，想赚千万，亿，觉得自己有能力了，开始创业投资，拿着钱去炒股炒币最后赔了个精光，更有甚者权钱勾结，做些不法勾当，不都是为了满足自己的贪婪，但欲望无穷无尽，何时才能填满这个无底洞，更可怕的是，多少人的欲望和他的能力并不符合，自身没有那么大的能力却渴望一切，最后只会反噬，自食其果。</p>
<p>有的人钻研学识，中国的大多数人都是通过高考这一途径踏进学识的殿堂，那些在高中自命不凡的天才们，进入了高校才发现，自己只是芸芸众生的普通一员，以前的光辉也变的暗淡无光，即便是清北级别，已经是很多人可望而不可即的存在，在面对越来越难的知识，在面对更聪明的身边人，在发现自己再努力也无法达成目标时，也会学习释然这一门课。</p>
<p>我想起来看过的一个清华物理系同学的采访，有一句话我印象很深刻，古人会说少壮不努力，老大徒伤悲，但不会说少壮不成功，老大徒伤悲，或许我上面说的这些，都太注重结果了，以结果的好坏判定了过程的意义，这是不对的，在追求这些目标的过程中，我们努力了，拼搏了，奋斗了，其实那就足够了，不应该把结果失利的压力强加在自己身上。</p>
<p>唉，这些说起来容易，真正能做到不为结果所动哪里容易呢，只跟自己比较，不与他人攀比，处之泰然地面对任何困难与挑战。这就是我所追求的心境吧，我什么时候能做到这种地步，可能才是真正的长大了吧。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>脚踏实地</title>
    <url>/2025/05/21/diary/%E8%84%9A%E8%B8%8F%E5%AE%9E%E5%9C%B0/</url>
    <content><![CDATA[<h3 id="脚踏实地"><a href="#脚踏实地" class="headerlink" title="脚踏实地"></a>脚踏实地</h3><p>没有一夜暴富的美梦，天下掉馅饼的事情只有可能是诱惑，在得到某些好处前先想一想你配不配。</p>
<p>杜绝心浮气躁，用双手制造财富。.</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>总结与反思-11.20</title>
    <url>/2024/11/20/diary/%E9%9A%8F%E7%AC%94-11.20/</url>
    <content><![CDATA[<h3 id="总结与反思-11-20"><a href="#总结与反思-11-20" class="headerlink" title="总结与反思-11.20"></a>总结与反思-11.20</h3><p>距离我正式开始写博客不知不觉已经过去一个多月，决定写一篇随笔，总结反思一下</p>
<p>期中已经考完了，回过头看，其实我对我这个学期的上半学期并不满意，大物的期中和线代的第一次阶段性考核实在是不理想，这跟我自己的学习状态有关，开学一开始给自己定的这学期的主基调是不要太累，导致一直对去图书馆学习十分反感，每天就是在宿舍玩一玩浪费时间，现在回想起来还是挺后悔的，除了期中考试的不如意，主要还因为一个事情让我启发很大，就是我同学的动态，他分享每天自己的收获，可能是学习可能是看书，我看了之后第一感觉是非常的佩服的，觉得他很有毅力很自律，但是他在动态下面评论的一句话让我深有感触，他说他并不觉得他很自律，他没有强迫自己学习，他是以一个享受地态度做这些事，当时我看了可以说大受震撼，因为在过去的一年大学生活中，我一直是以强迫的态度让自己去图书馆的，有时就算到图书馆也坐立不安，最后干脆去都不去了。相比之下，我发现我对自律的理解真是太浅薄了。自律不是强迫自己做某件事情，而是想做成什么事一定会做成的决心。于是，我以一种全新的态度重新审视学习。不想学线代了？那就别强迫自己，看看科研项目相关的事，这样坚持几天下来，我发现这几天过的十分充实，一种精神上的满足。这对我来说，确确实实是一大收获，希望这种享受学习的态度能伴我一直走下去。</p>
<blockquote>
<p>这里引用一下他的话，作为记录</p>
<p>有人爱一行干一行，有人干一行不爱一行，有人爱不干的那一行…感觉我是那种“干一行爱一行”的人，越做越觉得有趣，做一点就想知道更多（可能是我运气好刚好碰上的都是能爱上的..)如果单纯为了绩点不需要这样，刷题就好，但是我会把“学习”当做是我的一种生活或者说是娱乐方式</p>
<p>我很少痛苦地去学习，我要是觉得不舒服就会去学别的，去看书（或者刷刷手机)我也经常写很慢写很久停不下来，如果只是为了做题完全不需要。嗯希望给大家一个思路都能发现生活中的美好～导</p>
</blockquote>
<p>但令我感到开心的是，我在健身这件事上做到了坚持，以前我一直觉得自己总是三分钟热度，什么事情都做不长久，如今回想起来，我自高中以来，已经做成了很多很多我以前不敢想的事情，包括对英语的学习，包括高考的超常发挥，包括大学以来获得的很多成就，希望能对自己更有自信一些，向更好的自己前进！</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>AIGC——中数杯</title>
    <url>/2024/12/05/%E6%AF%94%E8%B5%9B/%E4%B8%AD%E6%95%B0%E6%9D%AF/</url>
    <content><![CDATA[<h1 id="《老匠新传》"><a href="#《老匠新传》" class="headerlink" title="《老匠新传》"></a>《老匠新传》</h1><p><strong>背景剧情：</strong></p>
<p>在安徽省一个偏远小山村里，住着一位年迈的老匠人程老。他是村里最后一位木雕匠，祖传的技艺如今面临失传的窘境。一天，城市的女孩小林，来到了这个小山村。她被精致的雕刻作品和老人的精湛技艺所吸引，留下来悉心学习这传统技艺。</p>
<p>多年后，女孩学成回到城市。她呼吸着浮躁的空气，下定决心在城市的一隅开设了一家雕刻工作室。门口摆放着一只木雕鸟，和曾经吸引她踏入木雕门扉的那只一般，精致而美丽。但是简约的线条又让它显得轻盈而现代。</p>
<p>“那是一块文化的拼图，串起了过去岁月的技艺，和当代创新的潮流。”</p>
<p><strong>创作理念：</strong></p>
<p>我们的故事从安徽省一个偏远小山村的年迈木雕匠人程老为起点，通过他与来自城市的女孩小林之间的师徒传承，展现传统技艺在现代社会中的困境与重生。</p>
<p>文化传承：我们希望强调了传统技艺的文化价值，如木雕这一几代人相传的技艺，不仅是技艺本身，更是一种文化的延续。程老作为村里最后一位木雕匠，他的技艺和作品承载着丰富的历史和文化信息。</p>
<p>师徒传承：通过小林对程老技艺的学习和传承，我们希望展现师徒之间深厚的情感纽带和技艺的传递。这种传承不仅是对技艺的保存，更是对文化精神的延续。</p>
<p>创新融合：小林学成后，在城市开设雕刻工作室，将传统技艺与现代审美相结合，创作出既具有传统韵味又符合现代审美的作品。其中表达着对传统文化的创新和发展，以及传统技艺在现代社会中焕发出新的生命力。</p>
<p>文化自信：故事中的小林在回到城市后，能够自信地展示和推销自己的作品，体现了对传统文化的自信和自豪感。</p>
<p><strong>艺术表达：</strong></p>
<p>我们采用现代的技术载体讲述传统技艺的传承和新生，希望增添作品的现实意义。</p>
<p>细节描写：故事中对木雕作品的细节描写，如“精致的雕刻作品”和“一只木雕鸟”，不仅展现了程老技艺的精湛，也通过小林对这些作品的喜爱和学习，传递了她对传统文化的热爱和尊重。</p>
<p>情感渲染：通过小林与程老之间的互动，以及小林学成后回到城市的心理变化，渲染师徒之间的深厚情感和传统文化的厚重感。</p>
<p>象征手法：木雕鸟作为故事中的象征物，既代表了程老的技艺传承，也象征着传统技艺在现代社会中的重生和创新。它的“精致而美丽”和“简约的线条”既体现了传统技艺的精髓，又融入了现代审美元素。</p>
<p>语言风格：故事中的语言风格简洁明了，富有诗意。</p>
<p><strong>使用技术：</strong></p>
<p>图像生成：首先训练GPT-4成为Midjourney提示词生成器。然后通过文字描述剧本中的场景，获取提示词。最后使用Midjourney生成场景图片，进行筛选。</p>
<p>视频生成：我们利用可灵AI进行视频的制作，我们使用生成的图片生成初版视频，然后通过提示词进行多次约束，修改，最后剪辑合并。</p>
]]></content>
      <categories>
        <category>竞赛</category>
      </categories>
      <tags>
        <tag>竞赛</tag>
      </tags>
  </entry>
  <entry>
    <title>1912</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/1912/</url>
    <content><![CDATA[<h3 id="1912"><a href="#1912" class="headerlink" title="1912"></a>1912</h3><p>2025年的生日，与李哥在百家湖1912聚餐，李哥请我吃的铁板烧，超级美味</p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784805-1745080945538-24.jpg" alt="1745080784805"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784820-1745080945538-25.jpg" alt="1745080784820"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784834-1745080945538-26.jpg" alt="1745080784834"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784848-1745080945538-27.jpg" alt="1745080784848"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784862-1745080945538-28.jpg" alt="1745080784862"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/1912/1745080784789-1745080968451-38.jpg" alt="1745080784789"></p>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>前言</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E5%89%8D%E8%A8%80/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>我是一个很珍惜回忆的人，但是任何回忆都有忘却的那一天，所以我能做的就是尽可能把他ji’lu</p>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>我想听他扫弦的声音</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/</url>
    <content><![CDATA[<h3 id="我想听他扫弦的声音"><a href="#我想听他扫弦的声音" class="headerlink" title="我想听他扫弦的声音"></a>我想听他扫弦的声音</h3><p>南京1701livehouse</p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840515.jpg" alt="1745077840515"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840490.jpg" alt="1745077840490"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840469.jpg" alt="1745077840469"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%88%91%E6%83%B3%E5%90%AC%E4%BB%96%E6%89%AB%E5%BC%A6%E7%9A%84%E5%A3%B0%E9%9F%B3/1745077840480.jpg" alt="1745077840480"></p>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>梦龙</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/</url>
    <content><![CDATA[<h3 id="梦龙演唱会"><a href="#梦龙演唱会" class="headerlink" title="梦龙演唱会"></a>梦龙演唱会</h3><p>4.6 Imagine Dragons 杭州<br>真的太嗨太嗨了，内场氛围巨好无比，所有人都在合唱，超值啊！<br>再记录一下这次比较特别的体验，在小红书找到了一个自驾去看演唱会的，五个人一辆车边走边聊边听歌，也是很不错啊</p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837710.jpg" alt="1745078837710"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837725.jpg" alt="1745078837725"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837752.jpg" alt="1745078837752"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837739.jpg" alt="1745078837739"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A2%A6%E9%BE%99/1745078837778.jpg" alt="1745078837778"></p>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>2024小美赛</title>
    <url>/2024/11/30/%E6%AF%94%E8%B5%9B/2024%E5%B0%8F%E7%BE%8E%E8%B5%9B/</url>
    <content><![CDATA[<h1 id="论文阅读：Jupiter-friend-or-foe-An-answer"><a href="#论文阅读：Jupiter-friend-or-foe-An-answer" class="headerlink" title="论文阅读：Jupiter: friend or foe? An answer"></a>论文阅读：Jupiter: friend or foe? An answer</h1><p>奥尔特云：</p>
<p><a href="https://zh.wikipedia.org/zh-cn/奥尔特云#潮汐力效應">奥尔特云 - 维基百科，自由的百科全书</a></p>
<p>长周期彗星：这些天体来自奥尔特云，周期超过200年，具有完整的轨道倾角范围，由 1012-1013 个冰体组成，其中绝大多数的直径小于 10 公里，并占据一个距离太阳约 103-105 天文单位的厚球形壳</p>
<p>短周期彗星：一般认为来自于柯伊伯带或离散盘。周期在200年以下</p>
<p>短周期彗星有两大类：木星族彗星（<a href="https://zh.wikipedia.org/wiki/半長軸">半长轴</a>小于5天文单位）及哈雷类彗星</p>
<p><a href="https://zh.wikipedia.org/wiki/短周期彗星">短周期彗星 - 维基百科，自由的百科全书</a></p>
<p>木星族:<a href="https://baike.baidu.com/item/木星/0?fromModule=lemma_inlink">木星</a>有时会缩短一颗彗星的运动周期，有时会延长一颗彗星的运动周期，有时会改变彗星轨道，从而使得周期彗星变成<a href="https://baike.baidu.com/item/非周期彗星/407319?fromModule=lemma_inlink">非周期彗星</a>，反过来也一样。周期3-10年，远日点在木星轨道附近的彗 星称为木星族彗星。</p>
<p>改变木星轨道上巨星的质量Y来 自小行星带的轰击</p>
<p>我们研究了改变“木星”质量对地球从小行星带向内抛出的物体所经历的撞击率的影响。我们在模拟冲击通量时遇到了一些问题。小行星被认为构成了最大的威胁。然而，在创建一群可能进化到撞击地球轨道的测试小行星时，我们面临着巨大的不确定性，特别是<strong>与整合开始时小行星的分布有关的不确定性</strong>。</p>
<p>因为自木星形成以来，它一直在扰乱目前在小行星带中观察到的物体的轨道。因此，尝试为这颗小行星构建一个受干扰程度要小得多的初始种群是很重要的</p>
<p>我们 2008 年的论文详细介绍了我们如何确定小行星分布，$\ N<em>{0}(a)=k(a-a</em>{min})^\frac{1}{2}$，其中 N（a） 是距离太阳 a 的小行星数量，k 是常数，$\ a<em>{min}$ 是小行星分布的内部边界。$\ a</em>{min}$的值为1.558AU，相当于火星的轨道半长轴，1.52 AU，加上三个 希尔半径</p>
<p>归一化常数 k 的确定<br>为了使总的小行星数量 $\ N_{total}$, 为一个固定值，我们需要对 N(a)进行归一化。通过对 N(a)在范<br>围[amin,amax]内积分，可以得到归一化常数 k</p>
<p>$\ k=\frac{3N<em>{total}}{2(a</em>{max}-a_{min})^\frac{2}{3}}$</p>
<p>希尔半径$\ R<em>{H}=a_p(\frac{M</em>{planet}}{3M_{Sun}})^\frac{1}{3}$，ap 是行星轨道的半长轴，M 表示质量。希尔球半径是一个天体对其周围物体产生重力影响的范围</p>
<p>以这种方式创建的物体代表一个碎片圆盘，在行星形成过程中受到了适度但不过度的搅拌（例如 Ward 2002）。</p>
<p>然后，在地球、火星、木星、土星、天星和海王星的影响下，使用 MERCURY 包中包含的混合积分器对测试粒子进行了 1000 万年的跟踪。进行了简单的测试积分，以检查地球横截面积对所经历的冲击通量的影响。<strong>正如预期的那样，发现撞击率与地球的横截面积成正比，引力聚焦的影响可以忽略不计</strong>。为了<strong>提高撞击率以获得合理的撞击统计数据</strong>，因此我们将地球膨胀到 $\ 10^6$ 公里的半径。在我们的整合中，小行星与行星和太阳发生引力相互作用，但<strong>彼此之间没有相互作用</strong></p>
<p>我们运行中使用的 “Jupiter” 经过修改，因此我们运行了 12 个单独的质量。在木星质量 MJ 的倍数中，这些是：0.01、0.05、0.10、0.15、0.20、0.25、0.33、0.50、0.75、1.00、1.50 和 2.00。每个“木星”的轨道元素与今天的木星相同。同样，模拟中其他行星的元素与今天相同：一次运行和下一次运行之间行星<strong>设置的唯一区别是木星质量的变化——所有其他变量都是恒定的</strong>。</p>
<p>显示了我们的模拟中 通量与质量关系的形式，其中小行星是 源群体。这些结果令人惊讶。在 1.00 M J 时，对地球的撞击次数约为 0.01 M J 时的撞击次数的 3.5 倍Y几乎没 有屏蔽！在这两个”木星”质量之间， 在 0.2 M J 左右存在一个峰值，其中撞 击次数几乎是 1.00 M J 时的两倍。</p>
<p><img src="/2024/11/30/%E6%AF%94%E8%B5%9B/2024%E5%B0%8F%E7%BE%8E%E8%B5%9B/asdasd.png" alt="asdasd"></p>
<p>我们随机生成了 100 000 个测试群体粒子，近日点位于 0.1– 10 AU 范围内，远日点位于 10 000 和100 000 个AU。人口的结构是为 了模仿观察到的长周期彗星的远日点 分布。近日点距离 q 确定如下$\ q=0.1+[(q<em>{max}-q</em>{min})^\frac{2}{3}*random]^\frac{2}{3}$其中 $\ q<em>{max}$ 和$\ q</em>{min}$分别是 0.1 和 10 AU 的最大和最小可能近日点 距离，而 random 是在克隆程序中 生成的 0 到 1 之间的随机数。这导 致大约 3% 的初始样本具有与地球 轨道交叉的轨道（地球交叉轨 道），大约 38% 位于最初与木星 交叉的轨道（q 小于或等于 5.203 AU 的轨道）。这个分布是一个简 单但有效的尝试，试图拟合新奥尔 特云彗星的已知分布</p>
<p>我们计算了奥尔特云 彗星在（膨胀的）地球上的碰撞次 数。需要采取不同的方法。奥尔特 云彗星的轨道周期是如此之大，以 至于即使在 100 Myr 的模拟中，即 使地球严重膨胀，也很少会与地球 近距离接触。因此，为了直接确定 对地球的撞击率，我们必须模拟大 量的测试粒子，其数量级比所使用 的粒子高出许多数量级</p>
<p>我们模拟中使用的”木 星”的质量被修改了从一个场景到 下一个场景。总共考虑了五种不同 的场景。研究了质量为木星质量 0.25、0.50、1.00 和 2.00 倍 的”木星”系统，以及不存在木星 的系统。和以前一样，场景之间的 唯一区别是木星的质量Y所有其 他参数都是恒定的。</p>
<p>大质量情况下彗星的消失速度 明显快于低质量木星的情况。即使 仅在 1 Myr 后，木星质量较高的喷 射率就很明显，并且一直持续到我 们模拟的最后，到那时，在所有情 况下，仅保留了初始彗星种群的一 小部分。</p>
<p>值得注意的是，即使没有 木星存在，到运行结束时，长周期 彗星的数量仍然会显着减少。由于 木星不存在（”木星”质量为 零）</p>
<p>。当考虑基于喷射率的初始代理 的结果时，重要的是要确保该措施 是实际上是冲击通量的合适代理。 例如，地球上的碰撞率似乎可能并 不简单地与幸存的奥尔特云彗星的 数量成正比。特别是，另外两种可 能性似乎值得进一步研究，以确保 我们最初的假设是正确的：考虑到 所研究的彗星轨道的扩展，重要的 是要检查是否存在穿过地球轨道的 奥尔特云彗星的优先生存（ q &lt; 1 AU)，或那些不存在的 (q &gt; 1 AU)。</p>
<p>换句话说，当考虑到长周期彗星通量（与我们之前 的发现相反），一颗质量更大的木星 肯定会在不存在这样的行星的情况下 为地球提供一些可测量的屏蔽。</p>
<p>事实上，只有在来自奥尔特 云的彗星的情况下，我们的结果表 明木星确实是长期以来所假设的地 球的朋友！</p>
<p>然而，应该指出的 是，在长周期轨道上运动的物体平 均而言通常比在短周期或星状轨道 上运动的物体具有更大的碰撞速度 （这是由于它们较高的倾角[包括逆 行轨道]和更大的轨道）速度为 1 天 文单位），这增加了奥尔特云彗星 作为轰炸机群体的相对重要性。</p>
<p>作 为一个整体，我们的工作表明，而 不是充当作为地球的盾牌，木星反 而增加了我们星球所经历的冲击通 量，超过了如果这颗行星以某种方 式神奇地从我们的太阳系中移走时 所受到的冲击通量。然而，如果木 星的质量减少到土星的质量，地球 的情况会更糟</p>
<p>事实上，只有在来自奥尔特 云的彗星的情况下，我们的结果表 明木星确实是长期以来所假设的地 球的朋友！</p>
<p><img src="/2024/11/30/%E6%AF%94%E8%B5%9B/2024%E5%B0%8F%E7%BE%8E%E8%B5%9B/4dd5a3dac2ad91f343c275db992ed5a.png" alt="4dd5a3dac2ad91f343c275db992ed5a"></p>
<p>我们的结果令人震惊。对于当前时代威胁地球的两个主要种群（近地小行星 和短周期彗星），我们发现木星质量与撞击率之间的关系相当复杂。在”木星”质量 较低的情况下，两颗行星的撞击率都非常低，因为这些小行星很难在地球交叉轨道上 放置物体。同样，在高”木星”质量（类似于或大于我们的木星）时，两个种群的撞 击率都相对较低，尽管略高于质量最小的”木星”。然而，在这两个极端之间，我们 在模拟中发现地球上的撞击通量出现了显着的峰值。对于近地小行星(Horner &amp; Jones, ̚ ̘ ̘ ̠ b)和短周期彗星(Horner &amp; Jones, 2009)，我们发现当模拟中的”木 星”在0.2到0.3倍之间时，撞击通量最大。和我们的木星一样大。换句话说，与质量 小得多的情况相比（例如，当它的质量与海王星相当时），我们的木星仅提供适度的 屏蔽，但如果它围绕土星的质量，那么地球上的撞击通量将是远远大于我们观察到 的。</p>
<p>当我们研究木星质量对第三种潜在危险天体M长周期彗星M的撞击率的影响时 （例如 Wiegert &amp; Tremaine, 1999, Levison, Dones &amp;Duncan, 2001, Horner &amp; Evans, 2002），我们发现”木星”质量越大，对地球的撞击率就越低（Horner，Jones &amp;钱伯斯， 2010）。那么，对于长周期彗星来说，木星似乎确实起到了盾牌的作用。然而，长周期彗星 被认为只对小行星和彗星对地球的影响贡献了一小部分（</p>
<p>这是否也在确定其宿主系统中潜在宜居行星的撞击通量中 发挥作用？在这项工作中，我们通过检查木星轨道偏心率和倾角的影响，建立在早期结果 的基础上。在这项工作中，我们只考虑两个主要的撞击星群M近地小行星和短周期彗星。 由于长周期彗星在轨道倾角基本上各向同性分布的轨道上运行，并且几乎不受太阳系引力 约束，因此可以合理地假设木星轨道的微小变化对彗星通量几乎没有影响或没有影响。</p>
<p>总体而言，很明显，巨行星轨道偏心率的增加会导致近地小行星和短周期彗星对地球的 撞击通量增加。</p>
]]></content>
      <categories>
        <category>竞赛</category>
        <category>数学建模</category>
      </categories>
      <tags>
        <tag>竞赛</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>为何需要专一</title>
    <url>/2024/10/29/%E6%96%87%E6%A1%88/%E4%B8%BA%E4%BD%95%E4%B8%93%E4%B8%80/</url>
    <content><![CDATA[<h2 id="为何需要专一"><a href="#为何需要专一" class="headerlink" title="为何需要专一"></a>为何需要专一</h2><p>以下源自网络</p>
<p>精神层次越高的人对感情越专一，因为善于处理自己内心欲望，因而不会把类似找备胎、和谁玩、玩过谁，这种肤浅的价值观当作得意的谈资。他们更愿意跟某个人担起生活的风雨，因为时间都用来做正经的事情，所以左顾右盼不代表你赢了，花哨是因为你层次太低。欲望是人性，克制是教养，新欢旧爱迎来送往，你以为的魅力难挡实则廉价百搭，得陇望蜀、骑驴找马、悲凉的让人生厌且鄙弃。道德不能杀掉带给我痛苦的人，所以我只能杀死理智和感性的自己。忠诚和专一是最基本的原则和底线，但它也只是三观正且有教养的人对感情中的自我约束</p>
]]></content>
      <categories>
        <category>文案</category>
      </categories>
      <tags>
        <tag>文案</tag>
      </tags>
  </entry>
  <entry>
    <title>大风起兮云飞扬</title>
    <url>/2024/10/15/%E6%96%87%E6%A1%88/%E5%88%98%E9%82%A6/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>史书上轻轻翻过的一页，便是他们波澜壮阔的一生。鉴史可以明志，知古方能鉴今，以史为镜，可以知兴替。我虽然是一位理科生，但我心里一直深知历史的重要，历史不是冰冷的文字，而是充满温度的生命轨迹。那些沉浮于历史长河中的伟大人物，用他们的智慧与勇气改写了时代的篇章，也为后人留下了宝贵的思想财富。迷茫时读史，退缩时读史，困惑时读史，或许都会有不一样的收获。</p>
<hr>
<p>刘邦，</p>
<p>38岁，一事无成，骗吃骗喝，娶了老婆。<br>48岁，被逼无奈，起兵反秦。<br>50岁，被项羽吓得跪地求饶。<br>51岁，被项羽打得丢盔弃甲，老婆、父亲都被抓。<br>54岁，建立汉朝，君临天下。<br>55岁，干翻曾经对他豪横的人。</p>
<p>七年时间，纵横四海，天下归一。<br>60岁，出征匈奴。<br>62岁，衣锦还乡时，写下大气磅礴的《大风歌》：</p>
<blockquote>
<p>大风起兮云飞扬，<br>威加海内兮归故乡，<br>安得猛士兮守四方。</p>
</blockquote>
<p>有人少年得志，有人大器晚成。人生从来没有太晚的开始，尽自己最大的努力，你也只是在等待一个时机。</p>
<hr>
]]></content>
      <categories>
        <category>文案</category>
      </categories>
      <tags>
        <tag>文案</tag>
      </tags>
  </entry>
  <entry>
    <title>名言警句</title>
    <url>/2024/10/15/%E6%96%87%E6%A1%88/%E5%90%8D%E8%A8%80/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我语文不好，始终羡慕那些说话出口成章，底蕴深厚，时不时冒出几句金句的人，所以，为了让我这么一个没有什么文化底蕴的人，说话不至于太俗气，既然我不会说，那我便学名人说，便有了记录名言警句的习惯，此外，这些名言警句背后的哲理，也经常能让我醍醐灌顶。之前在网上看到一些名言警句，就会顺手记录在手机的备忘录上，现在整理下来，希望再看到时能有所收获。我说的名人警句，不光是真正意义上的名人说的，其中也有部分是我看到网友写的，我觉得，学习一切可以学习的，任何人都可以是我的老师，他们很多的文字也能给我很大感触。</p>
<hr>
<h3 id="1-励志与挑战"><a href="#1-励志与挑战" class="headerlink" title="1. 励志与挑战"></a>1. <strong>励志与挑战</strong></h3><ul>
<li><strong>十年运到龙困井，一朝得势入青云</strong></li>
<li><strong>命定的局限尽可永在，不屈的挑战却不可须臾或缺</strong> ——《霍乱时期的爱情》</li>
<li><strong>受任于败军之际,奉命于危难之间</strong> ——诸葛亮《出师表》</li>
<li><strong>他时若遂凌云志，敢笑黄巢不丈夫</strong> ——唐代罗隐</li>
<li><strong>燕雀安知鸿鹄之志</strong> ——《史记·陈涉世家》</li>
<li><strong>攻心为上,攻城为下</strong> ——《孙子兵法》</li>
<li><strong>技不外漏，海不露底，千两黄金不卖道，十字街头送故交</strong></li>
<li><strong>将军不下马，各自奔前程</strong></li>
<li><strong>胜败兵家事不期，包羞忍耻是男儿</strong> ——宋代陆游《秋夜将晓出篱门迎凉有感二首》</li>
<li><strong>大丈夫生于天地之间，岂能郁郁久居人下</strong> ——《三国志·蜀书》</li>
<li><strong>江东子弟多才俊，卷土重来未可知</strong> ——唐代杜牧《题乌江亭》</li>
<li><strong>一位大师曾经说过要像水一样，那我应该就是海啸吧！</strong></li>
<li><strong>命数如织，当为磐石</strong></li>
</ul>
<h3 id="2-爱情与亲密关系"><a href="#2-爱情与亲密关系" class="headerlink" title="2. 爱情与亲密关系"></a>2. <strong>爱情与亲密关系</strong></h3><ul>
<li><strong>我想要爱、激情、真诚和亲密的关系、性，这些使我鲜活，然唯有灵魂的交流使我平静</strong></li>
<li><strong>一顾倾人城， 再顾倾人国。宁不知倾城与倾国？佳人难再得</strong> ——《汉书·李延年传》</li>
<li><strong>不见鹿，不见鲸，亦不见你</strong></li>
</ul>
<h3 id="3-人生与哲理"><a href="#3-人生与哲理" class="headerlink" title="3. 人生与哲理"></a>3. <strong>人生与哲理</strong></h3><ul>
<li><strong>你不妨大胆去冒险，只因生命终将逝去</strong> ——尼采</li>
<li><strong>人生不需要意义，意义需要人生</strong></li>
<li><strong>我曾踏足山巅，也曾进入谷底，二者都让我受益良多</strong> </li>
<li><strong>旧游无处不堪寻。无寻处、惟有少年心</strong> ——宋代辛弃疾《南乡子·登京口北固亭有怀》</li>
<li><strong>天下万般兵刃 唯有过往伤人最深</strong></li>
<li><strong>我见青山多妩媚,料青山见我应如是</strong> ——宋代辛弃疾《贺新郎·别茂嘉十二弟》</li>
<li><strong>如果真相带来痛苦，谎言只会雪上加霜</strong></li>
<li><strong>花团锦簇的节日用来铭记逝者，而我，宁愿被人遗忘</strong></li>
<li><strong>坟墓里寂静无比,埋葬你的是所有你没说出口的话</strong></li>
<li><strong>世界既不黑也不白，而是一道极致的灰</strong></li>
<li><strong>梦醒时夜续，惊慌失措</strong></li>
</ul>
<h3 id="4-自由与个性"><a href="#4-自由与个性" class="headerlink" title="4. 自由与个性"></a>4. <strong>自由与个性</strong></h3><ul>
<li><strong>因为生活过于教条，所以格外欣赏自由野性的东西</strong></li>
<li><strong>是俗是雅，我已经分不清了，我只知道月亮正圆，我若不看一眼，倒显得我不解风情了</strong></li>
<li><strong>国王们以世袭的权柄和虚名逼你下跪，诺克萨斯要你站起来，要你在荣耀中重获新生</strong></li>
</ul>
<h3 id="5-孤独与感伤"><a href="#5-孤独与感伤" class="headerlink" title="5. 孤独与感伤"></a>5. <strong>孤独与感伤</strong></h3><ul>
<li><strong>忽有清风化剑气,直斩少年二十意</strong></li>
<li><strong>生活的底片从来都不是遥远的白日梦，而是热爱生活的自己</strong></li>
<li><strong>黄昏见证虔诚的信徒，巅峰诞生虚伪的拥护</strong></li>
<li><strong>假作真时真亦假，无为有处有还无</strong> ——《红楼梦》</li>
<li><strong>林深时雾起，不见归处</strong></li>
<li><strong>海蓝时浪涌，望而却步</strong></li>
</ul>
<h3 id="6-经典与历史"><a href="#6-经典与历史" class="headerlink" title="6. 经典与历史"></a>6. <strong>经典与历史</strong></h3><ul>
<li><strong>朕非亡国之君，臣乃亡国之臣</strong> ——明代崇祯帝与大臣对话</li>
<li><strong>满腹经纶书香气,腹有诗书气自华</strong></li>
<li><strong>天下熙熙，皆为利往</strong> ——《史记·货殖列传》</li>
<li><strong>竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生</strong> ——宋代苏轼《定风波》</li>
<li><strong>回首向来萧瑟处，归去，也无风雨也无晴</strong> ——宋代苏轼《定风波》</li>
<li><strong>既生瑜何生亮</strong> ——《三国演义》</li>
<li><strong>欲买桂花同载酒，终不似，少年游</strong> ——宋代刘过《唐多令》</li>
<li><strong>愿以深心奉尘刹，不予自身求利益</strong> ——明代张居正</li>
</ul>
<h3 id="7-长文"><a href="#7-长文" class="headerlink" title="7.长文"></a>7.长文</h3><p>最绝望的人有三种，第一种是始出初之人，他没有同类，而身边全是未知，他无时无刻都在害怕着，你无法想象他是如何作为第一个人活下去的，因为他活着这件事本身，就已经违背了他被创造出来的本能。第二种是终焉之人，他也曾拥有同类，而现在，他便是最后之人，在迎接终焉时，他并不会感到孤单，因为同类早已用别的方式存在于他身上。他只能在可以活动的范围内活动，这使他对环境非常了解，了解到令自己感到绝望。第三种是活着之人，活着本身就是一种折磨，当你足够冷静时，你会发现，你做的一切都对自己没有任何意义，你本是一粒尘埃，最后也终回归尘埃，你认为的有意义只是你本能对你的奴役</p>
<hr>
<p>我不喜欢读书，但却无比向往哲思的海洋，所以游戏常常成为引导我思考的老师，与其是娱乐消遣的工具，我更愿意把他当做一部艺术品，其背后可以是一次次引人深思的哲理，其背后也可以是作者对某种人，对某件事，对某个价值观的思考，其背后还可以是一部引人入胜的恢宏世界观与史诗，无论是哪一种都令我着迷，引领我思考</p>
<hr>
]]></content>
      <categories>
        <category>文案</category>
      </categories>
      <tags>
        <tag>文案</tag>
      </tags>
  </entry>
  <entry>
    <title>决战蓝桥杯</title>
    <url>/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>好久不编算法了，为了不让300r打水漂，废话不多说，决战蓝桥杯！！！</p>
<p>我是算法彩笔，而且python也不是很会用，所有刷题刷的很慢，后续会把文件整理上传GitHub</p>
<p>思考了一下，因为时间紧迫，没有时间复盘每一道题了，这一篇文章简单记录一下进度</p>
<h2 id="进度记录"><a href="#进度记录" class="headerlink" title="进度记录"></a>进度记录</h2><p>3.13</p>
<p>贪心：1.力扣406. 根据身高重建队列2.P10387 [蓝桥杯 2024 省 A] 训练士兵3.蓝桥杯真题 谈判</p>
<p>3.14</p>
<p>贪心：1.蓝桥杯真题 翻硬币</p>
<p>bfs：1.蓝桥杯真题 扫雷2.蓝桥杯真题 长草3.力扣695.岛屿的最大面积</p>
<p>3.16</p>
<p>哈希：1.力扣 两数之和</p>
<p>前缀和：1.洛谷 求区间和</p>
<p>二分问题：1.洛谷 查找</p>
<p>dfs：1.蓝桥杯真题 小朋友崇拜圈2.蓝桥杯真题 最大数字</p>
<p>3.17</p>
<p>二分问题：1.力扣 统计公平数对的数目2.力扣 2226.每个小孩最多能分到多少糖果</p>
<p>3.18</p>
<p>二分答案：1.蓝桥杯真题 冶炼金属</p>
<p>并查集：1.洛谷P1551 亲戚2.洛谷P1536 村村通</p>
<p>3.19</p>
<p>哈希：1.力扣 3080.执行操作标记数组中的元素</p>
<p>堆：1.力扣 2530.执行k次操作后的最大分数</p>
<p>动态规划：1.力扣 70.爬楼梯2.力扣 198.打家劫舍3.P1048 [NOIP 2005 普及组] 采药4.力扣 494. 目标和5.力扣 322.零钱兑换</p>
<p>3.21</p>
<p>动态规划：1.力扣 2915.和为目标值的最长子序列的长度2.蓝桥杯真题 蓝桥课程抢购3.力扣518. 零钱兑换 II</p>
<p>图论：1.力扣1971.寻找图中是否存在路径</p>
<p>3.25</p>
<p>图论：1.力扣743.网络延迟时间</p>
<p>数论：1.蓝桥杯真题 数字诗意</p>
<p>3.26</p>
<p>贪心：1.蓝桥杯真题 回文数组</p>
<p>图论：1.力扣 1584.连接所有点的最小费用2.蓝桥杯真题 城市规划大师</p>
<p>3.27</p>
<p>动态规划：1.力扣1143.最长公共子序列2.蓝桥杯真题 查找最长公共子序列3.力扣583.两个字符串的删除操作</p>
<p>3.28</p>
<p>动态规划：1.蓝桥杯真题 砍柴</p>
<p>3.30</p>
<p>贪心：1.蓝桥杯真题 三国游戏2.蓝桥杯真题 平均</p>
<p>暴力：1.蓝桥杯真题 翻转</p>
<p>单调队列，单调栈：1.力扣239.滑动窗口最大值2.力扣739.每日温度3.力扣42.接雨水</p>
<p>双指针：1.力扣209.长度最小的子数组2.力扣3.无重复字符的最长字串3.力扣713.乘积小于k的子数组</p>
<p>3.31</p>
<p>二维单调队列：1.蓝桥杯真题 子矩阵（拼劲全力无法战胜，放弃）</p>
<p>4.1</p>
<p>数论：1.蓝桥杯真题 阶乘的和2.蓝桥杯真题 质因数个数</p>
<p>树：1.蓝桥杯真题 子树的大小</p>
<p>4.4</p>
<p>模拟：1.蓝桥杯真题 消除游戏</p>
<p>4.5</p>
<p>差分：1.蓝桥杯真题 重新排序2.力扣1094.拼车</p>
<p>动态规划：1.蓝桥杯真题 全排列的价值2.力扣300.最长递增子序列</p>
<p>贪心：1.蓝桥杯真题 优清零方案</p>
<p>4.9-11</p>
<p>刷填空题</p>
<p>4.12后记：也是考完蓝桥杯了，后面应该很长时间不碰算法了嘿嘿</p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="算法基础"><a href="#算法基础" class="headerlink" title="算法基础"></a>算法基础</h3><h4 id="快读模板"><a href="#快读模板" class="headerlink" title="快读模板"></a>快读模板</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入系统模块</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment"># 重定义input函数，用于快速读取输入</span></span><br><span class="line"><span class="comment"># sys.stdin.readline() 比 python 自带的 input() 快</span></span><br><span class="line"><span class="comment"># strip() 用于去除行末的换行符</span></span><br><span class="line"><span class="built_in">input</span> = <span class="keyword">lambda</span>:sys.stdin.readline().strip()</span><br></pre></td></tr></table></figure>
<p><img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312124949702.png" alt="image-20250312124949702"></p>
<h4 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h4><p><img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312130008507.png" alt="image-20250312130008507"></p>
<h4 id="列表推导器"><a href="#列表推导器" class="headerlink" title="列表推导器"></a>列表推导器</h4><p><img src="/2025/03/12/%E7%AE%97%E6%B3%95/%E5%86%B3%E6%88%98%E8%93%9D%E6%A1%A5%E6%9D%AF/image-20250312131643035.png" alt="image-20250312131643035"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>竟然在b站刷到学长做的视频，太惊喜了，真是雪中送炭</p>
<p><a href="https://www.bilibili.com/video/BV1wcR3Y5EMg/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【蓝桥杯】Python速成 刷题指南_哔哩哔哩_bilibili</a></p>
<p><a href="https://wiki.dwj601.cn/ds-and-algo/templates-py/">代码模板 (Python) - Open Wiki Community</a></p>
<p><a href="https://github.com/TsingPig/LanQiao_Python">TsingPig/LanQiao_Python: 视频合集 https://space.bilibili.com/398421867/lists?sid=4898042&amp;spm_id_from=333.788.0.0</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>补充资料</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://wiki.dwj601.cn/ds-and-algo/templates-py/">https://wiki.dwj601.cn/ds-and-algo/templates-py/</a></td>
<td>【★★★★★】Python代码模板</td>
</tr>
<tr>
<td><a href="https://www.lanqiao.cn/problems/?first_category_id=1">https://www.lanqiao.cn/problems/?first_category_id=1</a></td>
<td>蓝桥题库</td>
</tr>
<tr>
<td><a href="https://ac.nowcoder.com/acm/problem/collection/6999">https://ac.nowcoder.com/acm/problem/collection/6999</a></td>
<td>牛客蓝桥寒假题单</td>
</tr>
<tr>
<td><a href="https://www.luogu.com.cn/training/list">https://www.luogu.com.cn/training/list</a></td>
<td>洛谷题单</td>
</tr>
<tr>
<td><a href="https://leetcode.cn/u/endlesscheng/">https://leetcode.cn/u/endlesscheng/</a></td>
<td>力扣分类题单（进入点击“讨论发布”）</td>
</tr>
<tr>
<td><a href="https://www.lanqiao.cn/paper/">https://www.lanqiao.cn/paper/</a></td>
<td>【★★★★★】蓝桥杯真题卷模拟系统</td>
</tr>
<tr>
<td><a href="https://leetcode.cn/problemset/">https://leetcode.cn/problemset/</a></td>
<td>力扣题库</td>
</tr>
</tbody>
</table>
</div>
<p>讲的很好的视频</p>
<p><a href="https://leetcode.cn/discuss/post/3141566/ru-he-ke-xue-shua-ti-by-endlesscheng-q3yd/">分享｜如何科学刷题？- 讨论 - 力扣（LeetCode）</a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>蓝桥杯</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>蓝桥杯</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>橘子海</title>
    <url>/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/</url>
    <content><![CDATA[<h3 id="橘子海"><a href="#橘子海" class="headerlink" title="橘子海"></a>橘子海</h3><p>橘子海，现场超超超超级赞，嗨到爆，完全超出预期</p>
<p>Give me the faith that we broke</p>
<p>请重拾我们背叛过的誓言</p>
<p>Reminds me the verse that we spoke</p>
<p>不要让我遗忘共同诵读过的诗篇</p>
<p>There is no chance for start it over</p>
<p>一切已经永远无法重来</p>
<p>Back to the check point be my lover</p>
<p>回不去那个你我还是“我们”的存盘点</p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894738.jpg" alt="1745079894738"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894693.jpg" alt="1745079894693"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894721.jpg" alt="1745079894721"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894676.jpg" alt="1745079894676"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894659.jpg" alt="1745079894659"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894631.jpg" alt="1745079894631"></p>
<p><img src="/2025/04/19/%E5%9B%9E%E5%BF%86/%E6%A9%98%E5%AD%90%E6%B5%B7/1745079894645.jpg" alt="1745079894645"></p>
]]></content>
      <categories>
        <category>回忆</category>
      </categories>
      <tags>
        <tag>回忆</tag>
      </tags>
  </entry>
  <entry>
    <title>读书笔记——前言</title>
    <url>/2024/10/15/reading/%E5%89%8D%E8%A8%80/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我从小就不是一个喜欢读书的人，不管是小说还是文学作品，感觉文字始终无法对我产生兴趣，回忆起来，我自从初中开始，书读的可能最多的就是课本，课外甚至没有完整地看下来一本书。但我一直深知读书的重要性，而且把读书的感悟写下是很有意义的一件事，希望自己以后可以多读书，自勉。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>LangGraphChatBot</title>
    <url>/2025/07/14/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/LangGraphChatBot/</url>
    <content><![CDATA[<h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>python虚拟环境构建</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m venv .venv</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install langgraph==0.2.74                  </span><br><span class="line">pip install langchain-openai==0.3.6            </span><br><span class="line">pip install fastapi==0.115.8                         </span><br><span class="line">pip install uvicorn==0.34.0                          </span><br><span class="line">pip install gradio==5.18.0</span><br></pre></td></tr></table></figure>
<p>查看包<code>pip list</code></p>
<h3 id="构建一个基本的fastapi-langgraph应用"><a href="#构建一个基本的fastapi-langgraph应用" class="headerlink" title="构建一个基本的fastapi+langgraph应用"></a>构建一个基本的fastapi+langgraph应用</h3><h4 id="llm示例的构建（利用ChatOpenAI）"><a href="#llm示例的构建（利用ChatOpenAI）" class="headerlink" title="llm示例的构建（利用ChatOpenAI）"></a>llm示例的构建（利用ChatOpenAI）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建LLM实例</span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    base_url=config[&quot;base_url&quot;],</span><br><span class="line">    api_key=config[&quot;api_key&quot;],</span><br><span class="line">    model=config[&quot;model&quot;],</span><br><span class="line">    temperature=DEFAULT_TEMPERATURE,</span><br><span class="line">    timeout=30,  # 添加超时配置（秒）</span><br><span class="line">    max_retries=2  # 添加重试次数</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="数据类型的构建"><a href="#数据类型的构建" class="headerlink" title="数据类型的构建"></a>数据类型的构建</h4><p>继承于pydantic</p>
<p>规范化 API 请求和响应的数据结构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义消息类，用于封装API接口返回数据</span></span><br><span class="line"><span class="comment">#基于 Pydantic 的数据模型</span></span><br><span class="line"><span class="comment"># 定义Message类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    role (角色): 这是一个字符串，表示消息的发送者。常见的角色包括：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">- user (用户): 表示用户输入的消息。</span></span><br><span class="line"><span class="string">- assistant (助手): 表示聊天机器人或模型生成的消息。</span></span><br><span class="line"><span class="string">- system (系统): 表示为模型提供上下文或指令的系统消息。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    role: <span class="built_in">str</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义ChatCompletionRequest类</span></span><br><span class="line"><span class="comment">#聊天 API 请求</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatCompletionRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    stream: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span><span class="comment">#是否流式方式响应</span></span><br><span class="line">    userId: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span><span class="comment">#用于标识发起请求的用户</span></span><br><span class="line">    conversationId: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span><span class="comment">#用于标识特定的对话会话，这对于管理对话上下文或历史记录非常有用</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义ChatCompletionResponseChoice类</span></span><br><span class="line"><span class="comment">#聊天完成响应中的一个“选择”或一个生成的回复</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatCompletionResponseChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义ChatCompletionResponse类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatCompletionResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span> = Field(default_factory=<span class="keyword">lambda</span>: <span class="string">f&quot;chatcmpl-<span class="subst">&#123;uuid.uuid4().<span class="built_in">hex</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">object</span>: <span class="built_in">str</span> = <span class="string">&quot;chat.completion&quot;</span></span><br><span class="line">    created: <span class="built_in">int</span> = Field(default_factory=<span class="keyword">lambda</span>: <span class="built_in">int</span>(time.time()))</span><br><span class="line">    choices: <span class="type">List</span>[ChatCompletionResponseChoice]<span class="comment">#模型生成的所有可能的回复选项</span></span><br><span class="line">    system_fingerprint: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<h4 id="定义fastapi应用并管理应用的生命周期"><a href="#定义fastapi应用并管理应用的生命周期" class="headerlink" title="定义fastapi应用并管理应用的生命周期"></a>定义fastapi应用并管理应用的生命周期</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义了一个异步函数lifespan，它接收一个FastAPI应用实例app作为参数。这个函数将管理应用的生命周期，包括启动和关闭时的操作</span></span><br><span class="line"><span class="comment"># 函数在应用启动时执行一些初始化操作，如加载上下文数据、以及初始化问题生成器</span></span><br><span class="line"><span class="comment"># 函数在应用关闭时执行一些清理操作</span></span><br><span class="line"><span class="comment"># @asynccontextmanager 装饰器用于创建一个异步上下文管理器，它允许你在 yield 之前和之后执行特定的代码块，分别表示启动和关闭时的操作</span></span><br><span class="line"><span class="meta">@asynccontextmanager</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">lifespan</span>(<span class="params">app: FastAPI</span>):</span><br><span class="line">    <span class="comment"># 启动时执行</span></span><br><span class="line">    <span class="comment"># 申明引用全局变量，在函数中被初始化，并在整个应用中使用</span></span><br><span class="line">    <span class="keyword">global</span> graph</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        logger.info(<span class="string">&quot;正在初始化模型、定义Graph...&quot;</span>)</span><br><span class="line">        <span class="comment">#（1）初始化LLM</span></span><br><span class="line">        llm = get_llm(llm_type)</span><br><span class="line">        <span class="comment">#（2）定义Graph</span></span><br><span class="line">        graph = create_graph(llm)</span><br><span class="line">        <span class="comment">#（3）将Graph可视化图保存</span></span><br><span class="line">        save_graph_visualization(graph)</span><br><span class="line">        logger.info(<span class="string">&quot;初始化完成&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        logger.error(<span class="string">f&quot;初始化过程中出错: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># raise 关键字重新抛出异常，以确保程序不会在错误状态下继续运行</span></span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># yield 关键字将控制权交还给FastAPI框架，使应用开始运行</span></span><br><span class="line">    <span class="comment"># 分隔了启动和关闭的逻辑。在yield 之前的代码在应用启动时运行，yield 之后的代码在应用关闭时运行</span></span><br><span class="line">    <span class="keyword">yield</span></span><br><span class="line">    <span class="comment"># 关闭时执行</span></span><br><span class="line">    logger.info(<span class="string">&quot;正在关闭...&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># lifespan参数用于在应用程序生命周期的开始和结束时执行一些初始化或清理工作</span></span><br><span class="line">app = FastAPI(lifespan=lifespan)</span><br></pre></td></tr></table></figure>
<h4 id="langgraph核心逻辑"><a href="#langgraph核心逻辑" class="headerlink" title="langgraph核心逻辑"></a>langgraph核心逻辑</h4><p>创建langgraph</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义chatbot的状态</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建和配置chatbot的状态图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_graph</span>(<span class="params">llm</span>) -&gt; StateGraph:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 构建graph</span></span><br><span class="line">        <span class="comment">#创建一个 StateGraph 的实例，并将其配置为使用 State 类作为其状态管理的数据模型</span></span><br><span class="line">        graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义chatbot的node</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">            <span class="comment"># 处理当前状态并返回 LLM 响应</span></span><br><span class="line">            <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 配置graph</span></span><br><span class="line">        <span class="comment">#第二个参数 chatbot ：这是一个可调用对象（通常是一个函数或方法），它定义了当执行流程到达这个名为 &quot;chatbot&quot; 的节点时，应该执行什么操作。</span></span><br><span class="line">        graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line">        graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">        graph_builder.add_edge(<span class="string">&quot;chatbot&quot;</span>, END)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这里使用内存存储 也可以持久化到数据库</span></span><br><span class="line">        memory = MemorySaver()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 编译生成graph并返回</span></span><br><span class="line">        <span class="comment">#checkpointer 参数将 memory 实例传递给编译过程，使得图能够管理其状态的保存和加载。编译后的图对象被返回，这个对象可以被调用来运行聊天机器人。</span></span><br><span class="line">        <span class="keyword">return</span> graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">f&quot;Failed to create graph: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>可视化langgraph节点</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将构建的graph可视化保存为 PNG 文件</span><br><span class="line">def save_graph_visualization(graph: StateGraph, filename: str = &quot;graph.png&quot;) -&gt; None:</span><br><span class="line">    try:</span><br><span class="line">        with open(filename, &quot;wb&quot;) as f:</span><br><span class="line">            f.write(graph.get_graph().draw_mermaid_png())</span><br><span class="line">        logger.info(f&quot;Graph visualization saved as &#123;filename&#125;&quot;)</span><br><span class="line">    except IOError as e:</span><br><span class="line">        logger.info(f&quot;Warning: Failed to save graph visualization: &#123;str(e)&#125;&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="封装接口"><a href="#封装接口" class="headerlink" title="封装接口"></a>封装接口</h4><p>包含流式输出与非流式输出的处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 封装POST请求接口，与大模型进行问答</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">chat_completions</span>(<span class="params">request: ChatCompletionRequest</span>):</span><br><span class="line">    <span class="comment"># 判断初始化是否完成</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> graph:</span><br><span class="line">        logger.error(<span class="string">&quot;服务未初始化&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">500</span>, detail=<span class="string">&quot;服务未初始化&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        logger.info(<span class="string">f&quot;收到聊天完成请求: <span class="subst">&#123;request&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        query_prompt = request.messages[-<span class="number">1</span>].content</span><br><span class="line">        logger.info(<span class="string">f&quot;用户问题是: <span class="subst">&#123;query_prompt&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: request.userId+<span class="string">&quot;@@&quot;</span>+request.conversationId&#125;&#125;</span><br><span class="line">        logger.info(<span class="string">f&quot;用户当前会话信息: <span class="subst">&#123;config&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        prompt_template_system = PromptTemplate.from_file(PROMPT_TEMPLATE_TXT_SYS)</span><br><span class="line">        prompt_template_user = PromptTemplate.from_file(PROMPT_TEMPLATE_TXT_USER)</span><br><span class="line">        prompt = [</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt_template_system.template&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt_template_user.template.<span class="built_in">format</span>(query=query_prompt)&#125;</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理流式响应</span></span><br><span class="line">        <span class="keyword">if</span> request.stream:</span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">generate_stream</span>():</span><br><span class="line">                chunk_id = <span class="string">f&quot;chatcmpl-<span class="subst">&#123;uuid.uuid4().<span class="built_in">hex</span>&#125;</span>&quot;</span></span><br><span class="line">                <span class="keyword">async</span> <span class="keyword">for</span> message_chunk, metadata <span class="keyword">in</span> graph.astream(&#123;<span class="string">&quot;messages&quot;</span>: prompt&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">                    chunk = message_chunk.content</span><br><span class="line">                    logger.info(<span class="string">f&quot;chunk: <span class="subst">&#123;chunk&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="comment"># 在处理过程中产生每个块</span></span><br><span class="line">                    <span class="keyword">yield</span> <span class="string">f&quot;data: <span class="subst">&#123;json.dumps(&#123;<span class="string">&#x27;id&#x27;</span>: chunk_id,<span class="string">&#x27;object&#x27;</span>: <span class="string">&#x27;chat.completion.chunk&#x27;</span>,<span class="string">&#x27;created&#x27;</span>: <span class="built_in">int</span>(time.time()),<span class="string">&#x27;choices&#x27;</span>: [&#123;<span class="string">&#x27;index&#x27;</span>: <span class="number">0</span>,<span class="string">&#x27;delta&#x27;</span>: &#123;<span class="string">&#x27;content&#x27;</span>: chunk&#125;</span>,&#x27;finish_reason&#x27;: None&#125;]&#125;)&#125;\n\n&quot;</span></span><br><span class="line">                <span class="comment"># 流结束的最后一块</span></span><br><span class="line">                <span class="keyword">yield</span> <span class="string">f&quot;data: <span class="subst">&#123;json.dumps(&#123;<span class="string">&#x27;id&#x27;</span>: chunk_id,<span class="string">&#x27;object&#x27;</span>: <span class="string">&#x27;chat.completion.chunk&#x27;</span>,<span class="string">&#x27;created&#x27;</span>: <span class="built_in">int</span>(time.time()),<span class="string">&#x27;choices&#x27;</span>: [&#123;<span class="string">&#x27;index&#x27;</span>: <span class="number">0</span>,<span class="string">&#x27;delta&#x27;</span>: &#123;&#125;</span>,&#x27;finish_reason&#x27;: &#x27;stop&#x27;&#125;]&#125;)&#125;\n\n&quot;</span></span><br><span class="line">            <span class="comment"># 返回fastapi.responses中StreamingResponse对象</span></span><br><span class="line">            <span class="keyword">return</span> StreamingResponse(generate_stream(), media_type=<span class="string">&quot;text/event-stream&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理非流式响应处理</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                events = graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: prompt&#125;, config)</span><br><span class="line">                <span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">                    <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">                        result = value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                logger.info(<span class="string">f&quot;Error processing response: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            formatted_response = <span class="built_in">str</span>(format_response(result))</span><br><span class="line">            logger.info(<span class="string">f&quot;格式化的搜索结果: <span class="subst">&#123;formatted_response&#125;</span>&quot;</span>)</span><br><span class="line">			<span class="comment">#封装响应</span></span><br><span class="line">            response = ChatCompletionResponse(</span><br><span class="line">                choices=[</span><br><span class="line">                    ChatCompletionResponseChoice(</span><br><span class="line">                        index=<span class="number">0</span>,</span><br><span class="line">                        message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=formatted_response),</span><br><span class="line">                        finish_reason=<span class="string">&quot;stop&quot;</span></span><br><span class="line">                    )</span><br><span class="line">                ]</span><br><span class="line">            )</span><br><span class="line">            logger.info(<span class="string">f&quot;发送响应内容: \n<span class="subst">&#123;response&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="comment"># 返回fastapi.responses中JSONResponse对象</span></span><br><span class="line">            <span class="comment"># model_dump()方法通常用于将Pydantic模型实例的内容转换为一个标准的Python字典，以便进行序列化</span></span><br><span class="line">            <span class="keyword">return</span> JSONResponse(content=response.model_dump())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        logger.error(<span class="string">f&quot;处理聊天完成时出错:\n\n <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">500</span>, detail=<span class="built_in">str</span>(e))</span><br></pre></td></tr></table></figure>
<h3 id="langgraph的短期记忆与长期记忆"><a href="#langgraph的短期记忆与长期记忆" class="headerlink" title="langgraph的短期记忆与长期记忆"></a>langgraph的短期记忆与长期记忆</h3><p>LangGraph支持两种对于构建对话代理至关重要的内存类型：</p>
<ul>
<li><strong><a href="https://github.langchain.ac.cn/langgraph/agents/memory/#short-term-memory">短期内存</a></strong>：通过在会话中维护消息历史来跟踪正在进行的对话。</li>
<li><strong><a href="https://github.langchain.ac.cn/langgraph/agents/memory/#long-term-memory">长期内存</a></strong>：在不同会话之间存储用户特定或应用程序级别的数据。</li>
</ul>
<p><img src="/2025/07/14/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/LangGraphChatBot/image-20250715094855646.png" alt="image-20250715094855646"></p>
<p>在LangGraph中</p>
<ul>
<li><em>短期内存</em>也称为<strong>线程级内存</strong>。</li>
<li><em>长期内存</em>也称为<strong>跨线程内存</strong>。</li>
</ul>
<h3 id="教程地址"><a href="#教程地址" class="headerlink" title="教程地址"></a>教程地址</h3><p><a href="https://github.com/NanGePlus/LangGraphChatBot">NanGePlus/LangGraphChatBot: 使用LangGraph+DeepSeek-R1+FastAPI+Gradio实现一个带有记忆功能的流量包推荐智能客服web端用例,同时也支持gpt大模型、国产大模型(OneApi方式)、Ollama本地开源大模型、阿里通义千问大模型</a></p>
<p><a href="https://www.bilibili.com/video/BV1m89NYKE2J/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">LangGraph+deepseek-r1+FastAPI+Gradio实现拥有记忆的流量包推荐智能客服web端用例,同时也支持gpt、国产大模型、Ollama_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>指数基金投资指南</title>
    <url>/2025/02/26/reading/%E6%8C%87%E6%95%B0%E5%9F%BA%E9%87%91%E6%8A%95%E8%B5%84%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<h2 id="为什么要读这本书"><a href="#为什么要读这本书" class="headerlink" title="为什么要读这本书"></a>为什么要读这本书</h2><p>我觉得学会投资，学会钱生钱，是一件很重要的事情，一开始这是我父亲告诉我的，后来我自身也是深刻地感受到了。投资，可以避免通货膨胀带了的损失，如果做到了一定的境界，更可以真正实现财富自由。但是想要学好投资并不是一件容易的事。投资的成功，不仅需要敏锐的洞察力与眼光，社会经验的积累，还要有一种成熟的投资心态，进而探索出适合自身的投资理念。我觉得，这是需要一件长期实践的事情，所以我决定早些开始，虽然我现在并没有什么资产，但在投资的过程中，包括看新闻看热点，去搜索去了解一家公司，这都是在锻炼我的视野，为以后做铺垫吧</p>
<h2 id="习惯的力量"><a href="#习惯的力量" class="headerlink" title="习惯的力量"></a>习惯的力量</h2><blockquote>
<p>因为“习惯”的力量，仍然有许多人把所有的收入存放在收益率较低的“储蓄”里，让通货膨胀</p>
</blockquote>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>读书笔记</tag>
        <tag>金融投资</tag>
      </tags>
  </entry>
  <entry>
    <title>LangChain学习</title>
    <url>/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langchain%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="实战demo"><a href="#实战demo" class="headerlink" title="实战demo"></a>实战demo</h3><h4 id="agent实战"><a href="#agent实战" class="headerlink" title="agent实战"></a>agent实战</h4><p>langchain的agent与langgraph的agent主要差异点在create_openai_functions_agent, AgentExecutor这两个函数</p>
<p>前者的作用类似<strong>构建 Runnable 链</strong>，返回一个<code>RunnablePassthrough.assign(...)|prompt|llm_with_tools|ToolsAgentOutputParser()</code>，但其invoke仅能完成单步的调用，而<code>AgentExecutor</code> 会自动完成3 步循环（调用工具→拼回结果→再次调用 LLM），直到任务结束。</p>
<blockquote>
<p>以下为ai的解释</p>
<p><strong>直接使用 <code>agent</code> (Runnable) 的局限性:</strong></p>
<ol>
<li><strong>单步执行</strong>: 你直接调用 <code>agent.invoke()</code> 或 <code>agent.ainvoke()</code> 时，它通常只执行<strong>一步</strong>。对于像 <code>create_tool_calling_agent</code> 生成的 <code>agent</code> 来说，这一步就是：<ul>
<li>接收输入（包括历史消息和 <code>agent_scratchpad</code>）。</li>
<li>让 LLM 决定是给出最终答案 (<code>AgentFinish</code>) 还是调用工具 (<code>AgentAction</code>)。</li>
<li>返回这个决定。</li>
</ul>
</li>
<li><strong>工具调用需要手动处理</strong>: 如果 LLM 决定调用工具（返回 <code>AgentAction</code>），<strong>你</strong>需要负责：<ul>
<li>从返回的 <code>AgentAction</code> 中找出工具名称和输入参数。</li>
<li>在你的工具列表中找到对应的工具。</li>
<li>执行这个工具。</li>
<li>获取工具的输出（Observation）。</li>
<li><strong>再次手动调用 <code>agent.invoke(...)</code></strong>，把工具的输出（通常需要格式化成 <code>ToolMessage</code>）放回 <code>agent_scratchpad</code> 或 <code>intermediate_steps</code> 中。</li>
<li>重复这个过程，直到 <code>agent</code> 最终返回 <code>AgentFinish</code>。</li>
</ul>
</li>
</ol>
<p><strong>使用 <code>AgentExecutor</code> 的优势:</strong></p>
<p><code>AgentExecutor</code> 就是为了解决上述问题而设计的。它本质上是一个<strong>自动化的执行引擎</strong>，为你管理整个 Agent 的思考-行动-观察循环。</p>
<ol>
<li><strong>自动化循环</strong>: <code>AgentExecutor</code> 内部会自动运行那个循环：<ul>
<li>调用 <code>agent</code> (Runnable)。</li>
<li>检查返回的是 <code>AgentAction</code> 还是 <code>AgentFinish</code>。</li>
<li>如果是 <code>AgentAction</code>，它会自动根据你提供的 <code>tools</code> 列表找到并执行对应的工具。</li>
<li>它会自动将工具的输出（Observation）记录下来，并作为下一步的输入（放入 <code>agent_scratchpad</code>）再次调用 <code>agent</code>。</li>
<li>这个过程会一直重复。</li>
</ul>
</li>
</ol>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.agents import create_openai_functions_agent, AgentExecutor</span><br><span class="line">from langchain.tools import tool</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line"># 1. 定义工具</span><br><span class="line">class WeatherInput(BaseModel):</span><br><span class="line">    location: str = Field(description=&quot;城市名称&quot;)</span><br><span class="line"></span><br><span class="line">@tool(&quot;get_weather&quot;, args_schema=WeatherInput)</span><br><span class="line">def get_weather(location: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;查询城市天气&quot;&quot;&quot;</span><br><span class="line">    return f&quot;&#123;location&#125; 今天是晴天，25°C&quot;</span><br><span class="line"></span><br><span class="line"># 2. 创建Agent</span><br><span class="line">llm = ChatOpenAI(model=&quot;gpt-4&quot;)</span><br><span class="line">tools = [get_weather]</span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (&quot;system&quot;, &quot;你是一个助手，可以调用工具&quot;),</span><br><span class="line">    (&quot;human&quot;, &quot;&#123;input&#125;&quot;)</span><br><span class="line">])</span><br><span class="line">agent = create_openai_functions_agent(llm, tools, prompt)</span><br><span class="line">agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)</span><br><span class="line"></span><br><span class="line"># 3. 执行</span><br><span class="line">result = agent_executor.invoke(&#123;&quot;input&quot;: &quot;北京天气如何？&quot;&#125;)</span><br><span class="line">print(result[&quot;output&quot;])</span><br></pre></td></tr></table></figure>
<h4 id="工具调用"><a href="#工具调用" class="headerlink" title="工具调用"></a>工具调用</h4><p>利用bind_tools绑定工具，当大模型需要调用工具的时候，会返回工具信息，tool_calls，如下</p>
<p>[{‘name’: ‘add_numbers’, ‘args’: {‘a’: 15, ‘b’: 27}, ‘id’: ‘4e7b261cce6d4e3da09134086c704c3c’, ‘type’: ‘tool_call’}]</p>
<blockquote>
<p><code>llm_with_tools.invoke(...)</code> 只是一个<strong>单步调用</strong>，LLM 返回的是<strong>“我想调用哪个工具、传什么参数”</strong>（即 <code>tool_calls</code>）。<br><strong>但 LLM 并不会自动执行工具</strong>，所以你必须：</p>
<ol>
<li><strong>手动执行工具</strong>（或让 AgentExecutor 帮你执行）。</li>
<li><strong>把执行结果拼回对话</strong>（作为 <code>ToolMessage</code>）。</li>
<li><strong>再次调用 LLM</strong>，让它基于工具返回的结果生成最终答案。</li>
</ol>
</blockquote>
<p>这里展示的是手动拼接，并传给大模型，如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将工具的输出发送回LLM，让LLM基于结果生成最终回答</span><br><span class="line">            # 这是一个关键步骤，通常在Agent中自动处理。这里手动演示。</span><br><span class="line">            final_response = llm_with_tools.invoke([</span><br><span class="line">                HumanMessage(content=&quot;What is 15 + 27?&quot;),</span><br><span class="line">                AIMessage(content=&quot;&quot;, tool_calls=[tool_call]), # 告知LLM它之前建议的工具调用</span><br><span class="line">                ToolMessage(content=str(result), tool_call_id=tool_call[&#x27;id&#x27;]) # 告知LLM工具的执行结果</span><br><span class="line">            ])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.tools import tool</span><br><span class="line">from typing import Literal</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">from langchain_core.messages import HumanMessage, AIMessage, ToolMessage</span><br><span class="line"></span><br><span class="line"># 定义一个加法工具</span><br><span class="line">@tool</span><br><span class="line">def add_numbers(a: float, b: float) -&gt; float:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Adds two numbers together.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: The first number.</span><br><span class="line">        b: The second number.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a + b</span><br><span class="line"></span><br><span class="line"># 我们可以定义更多的工具，例如一个乘法工具</span><br><span class="line">@tool</span><br><span class="line">def multiply_numbers(a: float, b: float) -&gt; float:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Multiplies two numbers together.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: The first number.</span><br><span class="line">        b: The second number.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line"></span><br><span class="line"># 将我们定义的工具放在一个列表中</span><br><span class="line">tools = [add_numbers, multiply_numbers]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 初始化LLM</span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    temperature=0.5,</span><br><span class="line">    model_name=&quot;deepseek-v3-0324&quot;, # 聊天模型通常使用&quot;gpt-3.5-turbo&quot;或&quot;gpt-4&quot;</span><br><span class="line">    openai_api_base=&quot;https://api.qnaigc.com/v1&quot;, # 例如，您可以指定base_url</span><br><span class="line">    openai_api_key=&quot;sk-&quot; # 直接在此处设置API密钥，或者通过环境变量设置</span><br><span class="line">)</span><br><span class="line"># 将工具绑定到LLM</span><br><span class="line"># LLM现在知道了add_numbers和multiply_numbers这两个工具及其功能</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 场景一：LLM直接回答，不需要工具</span><br><span class="line">print(&quot;--- 场景一：LLM直接回答 ---&quot;)</span><br><span class="line">response1 = llm_with_tools.invoke([HumanMessage(content=&quot;Hello, what&#x27;s your name?&quot;)])</span><br><span class="line">print(response1.content) # LLM直接生成文本回复</span><br><span class="line"></span><br><span class="line">print(&quot;\n--- 场景二：LLM决定调用工具 ---&quot;)</span><br><span class="line"># 场景二：LLM决定调用工具</span><br><span class="line"># 当LLM的响应中包含tool_calls时，意味着它想要调用一个或多个工具</span><br><span class="line">response2 = llm_with_tools.invoke([HumanMessage(content=&quot;What is 15 + 27?&quot;)])</span><br><span class="line">print(response2.tool_calls) # 打印LLM决定调用的工具信息</span><br><span class="line"></span><br><span class="line"># 检查并执行LLM建议的工具调用</span><br><span class="line">if response2.tool_calls:</span><br><span class="line">    for tool_call in response2.tool_calls:</span><br><span class="line">        if tool_call[&#x27;name&#x27;] == &quot;add_numbers&quot;:</span><br><span class="line">            # 提取LLM为工具调用生成的参数</span><br><span class="line">            args = tool_call[&#x27;args&#x27;]</span><br><span class="line">            result = add_numbers.invoke(args) # 执行工具</span><br><span class="line">            print(f&quot;Tool call: add_numbers(&#123;args[&#x27;a&#x27;]&#125;, &#123;args[&#x27;b&#x27;]&#125;) = &#123;result&#125;&quot;)</span><br><span class="line"></span><br><span class="line">            # 将工具的输出发送回LLM，让LLM基于结果生成最终回答</span><br><span class="line">            # 这是一个关键步骤，通常在Agent中自动处理。这里手动演示。</span><br><span class="line">            final_response = llm_with_tools.invoke([</span><br><span class="line">                HumanMessage(content=&quot;What is 15 + 27?&quot;),</span><br><span class="line">                AIMessage(content=&quot;&quot;, tool_calls=[tool_call]), # 告知LLM它之前建议的工具调用</span><br><span class="line">                ToolMessage(content=str(result), tool_call_id=tool_call[&#x27;id&#x27;]) # 告知LLM工具的执行结果</span><br><span class="line">            ])</span><br><span class="line">            print(&quot;Final LLM response based on tool output:&quot;)</span><br><span class="line">            print(final_response.content)</span><br></pre></td></tr></table></figure>
<h3 id="概念扫盲"><a href="#概念扫盲" class="headerlink" title="概念扫盲"></a>概念扫盲</h3><h4 id="Document-对象"><a href="#Document-对象" class="headerlink" title="Document 对象"></a>Document 对象</h4><p>Document 对象是 LangChain 用来封装和处理文本数据的基本单位。无论您是从 PDF、Markdown 文件、网站还是数据库加载数据，LangChain 都会将这些数据转换成一个或多个 Document 对象，以便在后续的流程中使用。</p>
<p>一个 Document 对象主要包含两个部分：</p>
<ol>
<li><p>page_content (字符串)</p>
<ul>
<li>这是文档对象的核心，存储了原始的文本内容。例如，如果加载一个 Markdown 文件， page_content 就会包含该文件的所有文本。</li>
</ul>
</li>
<li><p>metadata (字典)</p>
<ul>
<li>这是一个字典，用于存储关于文档的“元数据”或附加信息。这些信息对于过滤、追踪或增强文档处理流程非常有用。常见的元数据包括：<ul>
<li>source ：文档的来源，比如文件名、URL等。</li>
<li>page ：如果文档来自多页文件（如PDF），这里可以存储页码。</li>
<li>其他自定义信息：您可以添加任何有助于您应用的信息，如作者、创建日期等。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>除了通过文档加载器（Loaders）自动创建，您也可以手动创建一个 Document 对象。这在测试或处理简单文本时非常方便。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建一个简单的 Document 对象</span><br><span class="line">doc = Document(</span><br><span class="line">    page_content=&quot;这是文档的主要内容。LangChain 真酷！&quot;,</span><br><span class="line">    metadata=&#123;</span><br><span class="line">        &#x27;source&#x27;: &#x27;my_notebook.ipynb&#x27;,</span><br><span class="line">        &#x27;author&#x27;: &#x27;AI Assistant&#x27;,</span><br><span class="line">        &#x27;chapter&#x27;: 2</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="Runnable协议"><a href="#Runnable协议" class="headerlink" title="Runnable协议"></a>Runnable协议</h4><p><a href="https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable">“Runnable”</a>协议</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.bilibili.com/video/BV12TLAzuEni/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">2025最新版！langchain入门到精通实战教程！结合实战案例，干货拉满！99%的人不知道的暴利玩法，学完敢谷歌工程师叫板！_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.langchain.com.cn/docs/introduction/">introduction | LangChain中文网</a></p>
<p><a href="https://www.bilibili.com/video/BV1XudVYzEcW?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">跟着官网学langchain2025(version 0.3)_哔哩哔哩_bilibili</a></p>
<p><a href="https://docs.langchain.com/langgraph-platform">LangGraph Platform - Docs by LangChain</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langchain</category>
      </categories>
      <tags>
        <tag>langchain</tag>
      </tags>
  </entry>
  <entry>
    <title>LangGraph学习——快速入门</title>
    <url>/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="构建langgraph聊天机器人的基本流程"><a href="#构建langgraph聊天机器人的基本流程" class="headerlink" title="构建langgraph聊天机器人的基本流程"></a>构建langgraph聊天机器人的基本流程</h3><h4 id="创建一个-StateGraph"><a href="#创建一个-StateGraph" class="headerlink" title="创建一个 StateGraph"></a>创建一个 <code>StateGraph</code></h4><p>首先创建一个 <code>StateGraph</code>。一个 <code>StateGraph</code> 对象将我们的聊天机器人结构定义为“状态机”。我们将添加 <code>节点</code> 来表示 LLM 和聊天机器人可以调用的函数，并添加 <code>边</code> 来指定机器人应如何在这些函数之间进行转换。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义状态</span></span><br><span class="line">graph_builder = StateGraph(State)</span><br></pre></td></tr></table></figure>
<p>在 langgraph 中，状态会在图的各个节点之间传递。当一个节点产生新的消息时，它会更新 State 中的 messages 字段。</p>
<p>我们的图现在可以处理两个关键任务</p>
<ol>
<li>每个 <code>节点</code> 都可以接收当前 <code>状态</code> 作为输入，并输出状态的更新。</li>
<li>对 <code>消息</code> 的更新将追加到现有列表而不是覆盖它，这得益于与 <code>Annotated</code> 语法一起使用的预构建 <a href="https://github.langchain.ac.cn/langgraph/reference/graphs/?h=add+messages#add_messages"><code>add_messages</code></a> 函数。</li>
</ol>
<blockquote>
<p>langgraph中每个消息对象通常包含以下关键属性：</p>
<ul>
<li>role : 一个字符串，标识消息的发送者（例如 ‘human’ , ‘ai’ , ‘system’ ）。</li>
<li>content : 消息的具体内容，通常是字符串，但也可以是更复杂的结构（例如，用于多模态输入）。</li>
<li>id : 一个可选的唯一标识符。</li>
</ul>
<p>Annotated 的作用 : 通过使用 Annotated[list, add_messages] ，你改变了这个默认行为。 add_messages 函数（由 langgraph 提供或由你自定义）的逻辑是 追加 而不是覆盖。所以，当一个新节点返回消息时， langgraph 会调用 add_messages 函数，将新消息 追加 到现有 messages 列表的末尾。</p>
</blockquote>
<h4 id="定义一个聊天模型"><a href="#定义一个聊天模型" class="headerlink" title="定义一个聊天模型"></a>定义一个聊天模型</h4><p>两种方法：</p>
<p>1.使用 <code>init_chat_model</code>(通用高层封装)<br>这是一个通用的辅助函数，旨在提供一个统一的接口来初始化来自 不同提供商 的聊天模型。</p>
<p><a href="https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html">init_chat_model — 🦜🔗 LangChain 文档 —- init_chat_model — 🦜🔗 LangChain documentation</a></p>
<p>2.使用如ChatOpenAI (特定于提供商的类)<br>这是一个专门为 OpenAI API 设计的类，提供了对 OpenAI 模型所有功能的完全访问。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.chat_models import init_chat_model</span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;sk-&quot;</span><br><span class="line">#使用‘&#123;model_provider&#125;:&#123;model&#125;’格式在单个参数中指定模型和模型提供者，例如“openai:o1”</span><br><span class="line">llm = init_chat_model(&quot;openai:qwen-plus-2025-04-28&quot;,</span><br><span class="line">                      base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">                      )</span><br></pre></td></tr></table></figure>
<h4 id="添加一个节点"><a href="#添加一个节点" class="headerlink" title="添加一个节点"></a>添加一个节点</h4><p>现在我们可以将聊天模型集成到一个简单的节点中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#定义节点chatbot</span><br><span class="line">def chatbot(state: State):</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line">graph_builder.add_node(&quot;chatbot&quot;, chatbot)</span><br></pre></td></tr></table></figure>
<p> <code>chatbot</code> 节点函数如何将当前 <code>状态</code> 作为输入，并返回一个包含更新的 <code>消息</code> 列表的字典，键为“messages”。这是所有 LangGraph 节点函数的基本模式。</p>
<p>我们 <code>状态</code> 中的 <code>add_messages</code> 函数会将 LLM 的响应消息追加到状态中已有的消息之后。</p>
<h4 id="添加一个-入口-点"><a href="#添加一个-入口-点" class="headerlink" title="添加一个 入口 点"></a>添加一个 <code>入口</code> 点</h4><p>添加一个 <code>入口</code> 点，以告诉图每次运行时<strong>从何处开始工作</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph_builder.add_edge(START, &quot;chatbot&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="编译图"><a href="#编译图" class="headerlink" title="编译图"></a>编译图</h4><p>在运行图之前，我们需要对其进行编译。我们可以通过在图构建器上调用 <code>compile()</code> 来完成。这将创建一个 <code>CompiledGraph</code>，我们可以在我们的状态上调用它。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph = graph_builder.compile()</span><br></pre></td></tr></table></figure>
<h4 id="可视化图"><a href="#可视化图" class="headerlink" title="可视化图"></a>可视化图</h4><p>您可以使用 <code>get_graph</code> 方法和其中一个“绘图”方法（例如 <code>draw_ascii</code> 或 <code>draw_png</code>）来可视化图。这些 <code>draw</code> 方法都需要额外的依赖项。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    display(Image(graph.get_graph().draw_mermaid_png()))</span><br><span class="line">except Exception:</span><br><span class="line">    # This requires some extra dependencies and is optional</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure>
<h4 id="运行聊天机器人"><a href="#运行聊天机器人" class="headerlink" title="运行聊天机器人"></a>运行聊天机器人</h4><p>运行聊天机器人</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;]&#125;):</span><br><span class="line">        <span class="built_in">print</span>(event)</span><br><span class="line">        <span class="comment">#stream 返回的每个 event 通常是一个字典，键是图中节点的名称，值是该节点完成后的状态更新。</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">            <span class="comment">#消息列表中的最后一条消息的文本内容</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="comment">#退出</span></span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment">#调用</span></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>graph.stream() 是 LangGraph 的核心功能之一。它会执行整个图（Graph），但不是一次性返回最终结果，而是像视频流一样，一步一步地返回中间过程的更新。这使得您可以实时看到模型生成内容的每一个部分。</p>
</blockquote>
<h3 id="添加网页搜索工具"><a href="#添加网页搜索工具" class="headerlink" title="添加网页搜索工具"></a>添加网页搜索工具</h3><h4 id="获取Tavily-api"><a href="#获取Tavily-api" class="headerlink" title="获取Tavily api"></a>获取Tavily api</h4><p><a href="https://tavily.com/">Tavily 的搜索 API</a> 是一款专为 AI 代理 (LLM) 构建的搜索引擎，能够快速提供实时、准确和基于事实的结果。</p>
<p>每月 1,000 次免费搜索</p>
<p><a href="https://python.langchain.ac.cn/docs/integrations/tools/tavily_search/">Tavily Search | 🦜️🔗 LangChain 框架</a></p>
<p>获取api<a href="https://app.tavily.com/home">Tavily AI —- Tavily AI</a></p>
<h4 id="添加工具"><a href="#添加工具" class="headerlink" title="添加工具"></a>添加工具</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line"></span><br><span class="line">tool = TavilySearch(</span><br><span class="line">    tavily_api_key=&quot;tvly-dev-&quot;,</span><br><span class="line">    max_results=2)</span><br><span class="line">tools = [tool]</span><br><span class="line">tool.invoke(&quot;李超是谁?&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="定义图"><a href="#定义图" class="headerlink" title="定义图"></a>定义图</h4><p>在LLM上添加<code>bind_tools</code>。这让LLM知道如果它想使用搜索引擎，应使用正确的JSON格式。</p>
<p>定义聊天模型llm（代码同上）</p>
<p>将tools整合到<code>StateGraph</code>中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将一个或多个**工具（tools） 绑定到一个 大型语言模型（LLM）**上，从而创建一个新的、具备工具调用能力的 LLM 实例</span></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br></pre></td></tr></table></figure>
<h4 id="创建一个运行工具的函数"><a href="#创建一个运行工具的函数" class="headerlink" title="创建一个运行工具的函数"></a>创建一个运行工具的函数</h4><p>现在，创建一个函数来运行被调用的工具。通过将工具添加到一个名为<code>BasicToolNode</code>的新节点来完成，该节点检查状态中的最新消息，如果消息包含<code>tool_calls</code>，则调用工具。它依赖于LLM的<code>tool_calling</code>支持，该支持在Anthropic、OpenAI、Google Gemini以及许多其他LLM提供商中可用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义 __call__ 方法，让这个类的实例可以像函数一样被调用</span></span><br><span class="line"><span class="comment"># inputs 是 langgraph 传进来的当前状态，是一个字典</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, inputs: <span class="built_in">dict</span></span>):</span><br><span class="line">    <span class="comment"># 1. 从状态中获取最新的消息</span></span><br><span class="line">    <span class="comment"># 使用了“海象操作符” :=，先从 inputs 中获取 &#x27;messages&#x27; 列表，如果不存在则返回空列表 []</span></span><br><span class="line">    <span class="comment"># 然后检查列表是否为空。如果不为空，则取出最后一条消息。</span></span><br><span class="line">    <span class="keyword">if</span> messages := inputs.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">        message = messages[-<span class="number">1</span>]  <span class="comment"># 通常，最后一条消息是 AI 发出的，其中包含工具调用请求</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果没有消息，就报错，因为这个节点不知道该做什么</span></span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;No message found in input&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 准备一个列表，用来存放所有工具的执行结果</span></span><br><span class="line">    outputs = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 遍历 AI 消息中请求的所有工具调用</span></span><br><span class="line">    <span class="keyword">for</span> tool_call <span class="keyword">in</span> message.tool_calls:</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 执行工具</span></span><br><span class="line">        <span class="comment"># a. tool_call[&quot;name&quot;] 获取工具名称 (例如 &#x27;tavily_search_results_json&#x27;)</span></span><br><span class="line">        <span class="comment"># b. self.tools_by_name[...] 从预存的工具字典中找到对应的工具对象</span></span><br><span class="line">        <span class="comment"># c. .invoke(tool_call[&quot;args&quot;]) 使用 LLM 提供的参数来调用该工具</span></span><br><span class="line">        tool_result = <span class="variable language_">self</span>.tools_by_name[tool_call[<span class="string">&quot;name&quot;</span>]].invoke(</span><br><span class="line">            tool_call[<span class="string">&quot;args&quot;</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 5. 将工具执行结果打包成 ToolMessage</span></span><br><span class="line">        <span class="comment"># 这是 langgraph/langchain 的标准格式，用于告诉 LLM 工具执行的结果是什么</span></span><br><span class="line">        outputs.append(</span><br><span class="line">            ToolMessage(</span><br><span class="line">                content=json.dumps(tool_result),  <span class="comment"># 工具结果必须是字符串，所以用 json.dumps 序列化</span></span><br><span class="line">                name=tool_call[<span class="string">&quot;name&quot;</span>],  <span class="comment"># 告诉 LLM 这是哪个工具的结果</span></span><br><span class="line">                tool_call_id=tool_call[<span class="string">&quot;id&quot;</span>],  <span class="comment"># 必须提供原始请求的 ID，以便 LLM 知道这个结果对应哪个请求</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 6. 返回结果，更新图的状态</span></span><br><span class="line">    <span class="comment"># 返回一个字典，其中 &#x27;messages&#x27; 键对应着包含所有 ToolMessage 的列表</span></span><br><span class="line">    <span class="comment"># langgraph 会将这个列表中的消息追加到主状态的 &#x27;messages&#x27; 列表中</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: outputs&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>call</strong> 是 Python 中一个非常特殊的“魔术方法”（magic method）。它的作用是 让一个类的实例（对象）能够像函数一样被调用 。</p>
<p>这在 langgraph 中是一种常见且核心的设计模式。它的含义是：</p>
<ol>
<li>节点即函数 ： BasicToolNode 的实例（比如 tool_node ）本身就代表了图中的一个可执行节点。</li>
<li>执行逻辑 ：当 langgraph 的状态机运行到这个 tool_node 节点时，它会直接“调用”这个节点对象，并把当前的状态（ inputs 字典）传递给它</li>
</ol>
</blockquote>
<p>可以使用LangGraph预构建的<a href="https://github.langchain.ac.cn/langgraph/reference/agents/#langgraph.prebuilt.tool_node.ToolNode">ToolNode</a>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br></pre></td></tr></table></figure>
<h4 id="定义conditional-edges"><a href="#定义conditional-edges" class="headerlink" title="定义conditional_edges"></a>定义<code>conditional_edges</code></h4><p>添加了工具节点后，现在您可以定义<code>conditional_edges</code>。</p>
<p><strong>边（Edges）</strong>将控制流从一个节点路由到下一个节点。<strong>条件边（Conditional edges）</strong>从单个节点开始，通常包含“if”语句，根据当前图状态路由到不同的节点。这些函数接收当前的图<code>state</code>并返回一个字符串或字符串列表，指示接下来要调用哪个（或哪些）节点。</p>
<p>接下来，定义一个名为<code>route_tools</code>的路由函数，它检查聊天机器人输出中的<code>tool_calls</code>。通过调用<code>add_conditional_edges</code>将此函数提供给图，这会告诉图，无论何时<code>chatbot</code>节点完成，都要检查此函数以确定下一步去哪里。</p>
<p>如果存在工具调用，条件将路由到<code>tools</code>；如果不存在，则路由到<code>END</code>。由于条件可以返回<code>END</code>，因此这次您不需要明确设置<code>finish_point</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">route_tools</span>(<span class="params"></span></span><br><span class="line"><span class="params">     state: State,</span></span><br><span class="line"><span class="params"> </span>):</span><br><span class="line">     <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">     用于 conditional_edge 的路由函数：</span></span><br><span class="line"><span class="string">     - 如果最后一条消息包含工具调用，则路由到 ToolNode</span></span><br><span class="line"><span class="string">     - 否则路由到结束节点</span></span><br><span class="line"><span class="string">     &quot;&quot;&quot;</span></span><br><span class="line">     <span class="comment"># 处理 state 为列表的情况（可能是消息列表）</span></span><br><span class="line">     <span class="keyword">if</span> <span class="built_in">isinstance</span>(state, <span class="built_in">list</span>):</span><br><span class="line">         ai_message = state[-<span class="number">1</span>]  <span class="comment"># 获取最后一条消息</span></span><br><span class="line">     <span class="comment"># 处理 state 为字典的情况（包含 messages 字段）</span></span><br><span class="line">     <span class="keyword">elif</span> messages := state.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">         ai_message = messages[-<span class="number">1</span>]  <span class="comment"># 获取最后一条消息</span></span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">         <span class="keyword">raise</span> ValueError(<span class="string">f&quot;输入状态中没有找到消息: <span class="subst">&#123;state&#125;</span>&quot;</span>)</span><br><span class="line">     </span><br><span class="line">     <span class="comment"># 检查消息是否有工具调用</span></span><br><span class="line">     <span class="keyword">if</span> <span class="built_in">hasattr</span>(ai_message, <span class="string">&quot;tool_calls&quot;</span>) <span class="keyword">and</span> <span class="built_in">len</span>(ai_message.tool_calls) &gt; <span class="number">0</span>:</span><br><span class="line">         <span class="keyword">return</span> <span class="string">&quot;tools&quot;</span>  <span class="comment"># 有工具调用，返回 &quot;tools&quot; 路由到工具节点</span></span><br><span class="line">     <span class="keyword">return</span> END  <span class="comment"># 没有工具调用，返回 END 结束流程</span></span><br></pre></td></tr></table></figure>
<p>可以使用预构建的<a href="https://github.langchain.ac.cn/langgraph/reference/prebuilt/#tools_condition">tools_condition</a>代替route_tools以使其更简洁。</p>
<blockquote>
<p><code>tools_condition</code> 函数在聊天机器人需要使用工具时返回 “tools”，如果可以不使用响应则返回 “END”。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> tools_condition</span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">    &#123;<span class="string">&quot;tools&quot;</span>: <span class="string">&quot;tools&quot;</span>, END: END&#125;,</span><br><span class="line">)</span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br></pre></td></tr></table></figure>
<h4 id="可视化图-1"><a href="#可视化图-1" class="headerlink" title="可视化图"></a>可视化图</h4><p>如上</p>
<h4 id="向机器人提问"><a href="#向机器人提问" class="headerlink" title="向机器人提问"></a>向机器人提问</h4><p>现在您可以向聊天机器人提出超出其训练数据范围的问题。</p>
<p>如上</p>
<h3 id="添加记忆功能"><a href="#添加记忆功能" class="headerlink" title="添加记忆功能"></a>添加记忆功能</h3><p>LangGraph 通过<strong>持久性检查点</strong>解决了这个问题。如果您在编译图时提供一个<code>checkpointer</code>，并在调用图时提供一个<code>thread_id</code>，LangGraph 会在每一步之后自动保存状态。当您使用相同的<code>thread_id</code>再次调用图时，图会加载其保存的状态，允许聊天机器人从上次中断的地方继续。</p>
<p>我们稍后会看到，<strong>检查点</strong>比简单的聊天记忆功能<em>强大得多</em>——它允许您随时保存和恢复复杂状态，用于错误恢复、人工干预工作流、时间旅行交互等。但首先，让我们添加检查点以实现多轮对话。</p>
<h4 id="创建-MemorySaver-检查点"><a href="#创建-MemorySaver-检查点" class="headerlink" title="创建 MemorySaver 检查点"></a>创建 <code>MemorySaver</code> 检查点</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br></pre></td></tr></table></figure>
<p>这是一个内存中的检查点，方便本教程使用。然而，在生产应用程序中，您可能会将其更改为使用 <code>SqliteSaver</code> 或 <code>PostgresSaver</code> 并连接数据库。</p>
<h4 id="编译图-1"><a href="#编译图-1" class="headerlink" title="编译图"></a>编译图</h4><p>使用提供的检查点编译图，图在遍历每个节点时将对 <code>State</code> 进行检查点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph = graph_builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<h4 id="与您的聊天机器人互动"><a href="#与您的聊天机器人互动" class="headerlink" title="与您的聊天机器人互动"></a>与您的聊天机器人互动</h4><ol>
<li><p>选择一个线程作为此对话的键。</p>
<p>thread_id决定对话窗口</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>调用您的聊天机器人</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">user_input = &quot;我是谁&quot;</span><br><span class="line"></span><br><span class="line"># The config is the **second positional argument** to stream() or invoke()!</span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">)</span><br><span class="line">for event in events:</span><br><span class="line">    event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="添加人工干预"><a href="#添加人工干预" class="headerlink" title="添加人工干预"></a>添加人工干预</h3><p>代理可能不可靠，并且可能需要人工输入才能成功完成任务。同样，对于某些操作，您可能需要在运行前要求人工批准，以确保一切按预期运行。</p>
<p>LangGraph 的<a href="https://github.langchain.ac.cn/langgraph/concepts/persistence/">持久化</a>层支持<strong>人工干预</strong>工作流，允许根据用户反馈暂停和恢复执行。此功能的主要接口是<a href="https://github.langchain.ac.cn/langgraph/how-tos/human_in_the_loop/add-human-in-the-loop/"><code>interrupt</code></a>函数。在节点内调用<code>interrupt</code>将暂停执行。通过传入<a href="https://github.langchain.ac.cn/langgraph/concepts/low_level/#command">Command</a>，可以恢复执行并接收来自人工的新输入。<code>interrupt</code>在功能上类似于 Python 的内置<code>input()</code>，<a href="https://github.langchain.ac.cn/langgraph/how-tos/human_in_the_loop/add-human-in-the-loop/">但有一些注意事项</a>。</p>
<h4 id="添加human-assistance工具"><a href="#添加human-assistance工具" class="headerlink" title="添加human_assistance工具"></a>添加<code>human_assistance</code>工具</h4><p>将<code>human_assistance</code>工具添加到聊天机器人。此工具使用<code>interrupt</code>从人工接收信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 添加人工干预功能</span><br><span class="line"># 导入LangGraph的中断机制和命令类型</span><br><span class="line">from langgraph.types import Command, interrupt</span><br><span class="line"># 导入LangChain的工具装饰器</span><br><span class="line">from langchain_core.tools import tool</span><br><span class="line"></span><br><span class="line"># 使用@tool装饰器将函数标记为可被LLM调用的工具</span><br><span class="line">@tool</span><br><span class="line">def human_assistance(query: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;请求人工协助的工具函数。</span><br><span class="line">    当LLM遇到需要人工判断或帮助的情况时，会调用此工具。</span><br><span class="line">    该函数会暂停图的执行，等待人工操作员提供响应。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # interrupt()函数会暂停图的执行，等待人工输入</span><br><span class="line">    # 传入的字典包含查询信息，人工操作员会看到这个查询</span><br><span class="line">    human_response = interrupt(&#123;&quot;query&quot;: query&#125;)</span><br><span class="line">    </span><br><span class="line">    # 从人工响应中提取数据并返回给LLM</span><br><span class="line">    # human_response是一个字典，&quot;data&quot;字段包含人工提供的实际响应</span><br><span class="line">    return human_response[&quot;data&quot;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>简单来说， <strong>调用哪个工具，以及何时调用，完全是由大语言模型（LLM）根据你给它的指令（Prompt）来决定的。</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tool = TavilySearch(max_results=2)</span><br><span class="line">tools = [tool, human_assistance]</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br></pre></td></tr></table></figure>
<h4 id="定义chatbot"><a href="#定义chatbot" class="headerlink" title="定义chatbot"></a>定义chatbot</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def chatbot(state: State):</span><br><span class="line">    # 调用绑定了工具的LLM（llm_with_tools），传入当前的消息历史</span><br><span class="line">    # LLM会根据最新的消息决定是生成文本回复，还是调用一个或多个工具</span><br><span class="line">    message = llm_with_tools.invoke(state[&quot;messages&quot;])</span><br><span class="line">    </span><br><span class="line">    # --- 关键断言逻辑 ---</span><br><span class="line">    assert len(message.tool_calls) &lt;= 1</span><br><span class="line">    </span><br><span class="line">    # 将LLM生成的新消息（可能是文本回复，也可能是工具调用请求）返回</span><br><span class="line">    # 这个返回值会以字典的形式更新到状态（State）对象中</span><br><span class="line">    return &#123;&quot;messages&quot;: [message]&#125;</span><br><span class="line"></span><br><span class="line"># 将 chatbot 函数作为名为 &quot;chatbot&quot; 的节点添加到图构建器中</span><br><span class="line">graph_builder.add_node(&quot;chatbot&quot;, chatbot)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>中断安全性的断言 ( assert ) : assert len(message.tool_calls) &lt;= 1 是在实现人工干预时一个非常重要的 安全措施 。</p>
<ul>
<li>问题 : 现代 LLM 支持并行工具调用（一次请求执行多个工具）。但如果其中一个工具是 human_assistance 并触发了中断，整个图会暂停。当人工操作完成后，图会从中断点恢复。此时，如果不对工具调用数量做限制，LangGraph 可能会重新尝试执行所有在中断前请求的工具，导致已经执行过的工具被再次调用。</li>
<li>解决方案 : 这个断言强制要求 LLM 在每一步最多只能请求调用一个工具。这样就保证了当中断发生并恢复后，不会有重复执行工具的风险，确保了流程的稳定性和可预测性。</li>
</ul>
</blockquote>
<h4 id="编译图-2"><a href="#编译图-2" class="headerlink" title="编译图"></a>编译图</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line">graph = graph_builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<h4 id="调用聊天机器人并中断"><a href="#调用聊天机器人并中断" class="headerlink" title="调用聊天机器人并中断"></a>调用聊天机器人并中断</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">user_input = &quot;我需要一些关于构建 AI 代理的专家指导。你能帮我请求协助吗？&quot;</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    #它的作用是指定在进行流式处理时，你希望接收到的数据是以 完整的、累积的值 的形式返回，而不是以增量的、片段的形式返回。</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>聊天机器人生成了一个工具调用，但随后执行被中断。如果您检查图状态，您会看到它停止在工具节点</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">snapshot = graph.get_state(config)</span><br><span class="line">snapshot.next</span><br></pre></td></tr></table></figure>
<h4 id="恢复执行"><a href="#恢复执行" class="headerlink" title="恢复执行"></a>恢复执行</h4><p>要恢复执行，请传入一个包含工具所需数据的<a href="https://github.langchain.ac.cn/langgraph/concepts/low_level/#command"><code>Command</code></a>对象。此数据的格式可以根据需要进行自定义。对于本示例，请使用一个带有键<code>&quot;data&quot;</code>的字典（由human_assistance决定）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">human_response = (</span><br><span class="line">&quot;我们专家在此为您提供帮助！我们建议您查看 LangGraph 来构建您的代理。它比简单的自主代理更可靠、更具可扩展性。&quot;</span><br><span class="line">)   </span><br><span class="line">#从暂停状态恢复执行</span><br><span class="line">human_command = Command(resume=&#123;&quot;data&quot;: human_response&#125;)</span><br><span class="line"></span><br><span class="line">events = graph.stream(human_command, config, stream_mode=&quot;values&quot;)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<blockquote>
<p>1.工具的定义 ( human_assistance function):</p>
<ul>
<li>当 LLM 调用 human_assistance 工具时，这个函数被执行。</li>
<li>函数内部， interrupt() 被调用，导致图暂停，并等待人工输入。</li>
<li>在图恢复后， interrupt() 函数会返回一个值，这个值就是您通过 Command(resume=…) 注入的内容，也就是 {“data”: human_response} 。</li>
<li>因此， human_assistance 函数中的 human_response 变量实际上就等于 {“data”: human_response} 。</li>
<li>最后， return human_response[“data”] 从这个字典中提取出 “data” 键对应的值 ，并将其作为 human_assistance 工具的最终返回结果。</li>
</ul>
<p>2.恢复指令 ( Command(resume=…) ):</p>
<ul>
<li>当您构建 Command(resume={“data”: human_response}) 时，您正在创建一个符合 human_assistance 函数期望的结构。</li>
<li>您将人工回复包装在一个字典里，并使用 “data” 作为键。</li>
<li>这个结构被传递回 interrupt() ，然后被 human_assistance 函数接收和解析。</li>
</ul>
<p>因为 human_assistance 函数的 return 语句期望从返回的字典中访问 “data” 键，所以我们在恢复执行时必须提供一个具有相同结构的字典。这是为了确保数据能够正确地在中断和恢复的过程中传递。</p>
</blockquote>
<p>在 LangGraph 中，<code>Command</code> 是一个用于<strong>控制图执行流程、更新状态、实现人机交互</strong>的核心类。它支持以下四个参数：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">参数名</th>
<th style="text-align:left">类型</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>update</code></td>
<td style="text-align:left"><code>dict</code></td>
<td style="text-align:left">用于更新图的状态（state）。例如：<code>Command(update=&#123;&quot;foo&quot;: &quot;bar&quot;&#125;)</code>。</td>
</tr>
<tr>
<td style="text-align:left"><code>resume</code></td>
<td style="text-align:left"><code>Any</code></td>
<td style="text-align:left">与 <code>interrupt()</code> 配合使用，用于恢复被中断的图执行，并传递用户输入。</td>
</tr>
<tr>
<td style="text-align:left"><code>goto</code></td>
<td style="text-align:left"><code>str</code> 或 <code>Send</code> 或 `List[str</td>
<td style="text-align:left">Send]`</td>
<td>控制下一步要执行的节点，支持跳转到指定节点、多个节点序列，或使用 <code>Send</code> 对象。</td>
</tr>
<tr>
<td style="text-align:left"><code>graph</code></td>
<td style="text-align:left"><code>str</code></td>
<td style="text-align:left">可选，指定命令作用的图。默认是当前图，也可以设为 <code>Command.PARENT</code> 表示父图。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="自定义状态"><a href="#自定义状态" class="headerlink" title="自定义状态"></a>自定义状态</h3><p>在本教程中，您将向状态添加额外字段，以定义复杂行为，而无需依赖消息列表。聊天机器人将使用其搜索工具查找特定信息，并将其转发给人工进行审查。</p>
<h4 id="向状态添加键"><a href="#向状态添加键" class="headerlink" title="向状态添加键"></a>向状态添加键</h4><p>通过向状态添加 <code>name</code> 和 <code>birthday</code> 键，更新聊天机器人以研究实体的生日</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class State(TypedDict):</span><br><span class="line">    messages: Annotated[list, add_messages]</span><br><span class="line">    name: str</span><br><span class="line">    birthday: str</span><br></pre></td></tr></table></figure>
<p>将此信息添加到状态中，可以使其轻松被其他图节点（例如存储或处理信息的下游节点）以及图的持久层访问。</p>
<h4 id="在工具内部更新状态"><a href="#在工具内部更新状态" class="headerlink" title="在工具内部更新状态"></a>在工具内部更新状态</h4><p>现在，在 <code>human_assistance</code> 工具内部填充状态键。这允许人工在信息存储到状态之前对其进行审查。使用 <a href="https://github.langchain.ac.cn/langgraph/concepts/low_level/#using-inside-tools"><code>Command</code></a> 从<strong>工具内部</strong>发出状态更新。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 从 langchain_core.messages 导入 ToolMessage，用于创建工具调用的响应消息</span><br><span class="line">from langchain_core.messages import ToolMessage </span><br><span class="line"># 从 langchain_core.tools 导入 InjectedToolCallId（用于自动注入工具调用ID）和 tool（工具装饰器）</span><br><span class="line">from langchain_core.tools import InjectedToolCallId, tool </span><br><span class="line"></span><br><span class="line"># 从 langgraph.types 导入 Command（用于向图发送指令）和 interrupt（用于中断图的执行）</span><br><span class="line">from langgraph.types import Command, interrupt </span><br><span class="line">from typing import Annotated</span><br><span class="line"># @tool 装饰器将这个函数声明为一个可供 LLM 调用的工具</span><br><span class="line">@tool </span><br><span class="line">def human_assistance(</span><br><span class="line">    name: str, </span><br><span class="line">    birthday: str, </span><br><span class="line">    # tool_call_id 这个参数非常特殊。Annotated[...] 和 InjectedToolCallId 告诉 LangGraph：</span><br><span class="line">    # 1. 这个参数不应暴露给 LLM，LLM 在调用此工具时不需要提供它。</span><br><span class="line">    # 2. LangGraph 在执行时，会自动将触发此工具的那个工具调用的 ID 注入到这个参数中。</span><br><span class="line">    # 这个 ID 对于创建与原始请求相关联的 ToolMessage 至关重要。</span><br><span class="line">    tool_call_id: Annotated[str, InjectedToolCallId]</span><br><span class="line">) -&gt; str: </span><br><span class="line">    &quot;&quot;&quot;当需要人工确认或更正信息时，请求人类协助。&quot;&quot;&quot; </span><br><span class="line">    # 调用 interrupt() 来暂停图的执行，并向人类审核者呈现一个包含问题和待确认数据的字典。</span><br><span class="line">    # 图会在此处暂停，直到人类通过 resume 指令提供了响应。</span><br><span class="line">    human_response = interrupt( </span><br><span class="line">        &#123; </span><br><span class="line">            &quot;question&quot;: &quot;Is this correct?&quot;, </span><br><span class="line">            &quot;name&quot;: name, </span><br><span class="line">            &quot;birthday&quot;: birthday, </span><br><span class="line">        &#125;,</span><br><span class="line">    ) </span><br><span class="line">    # 检查人类的响应。如果响应中 &#x27;correct&#x27; 键的值是 &#x27;yes&#x27; 或 &#x27;y&#x27; 开头，</span><br><span class="line">    # 则认为信息是正确的。</span><br><span class="line">    if human_response.get(&quot;correct&quot;, &quot;&quot;).lower().startswith(&quot;y&quot;): </span><br><span class="line">        # 如果信息正确，直接使用从 LLM 获取的原始信息。</span><br><span class="line">        verified_name = name </span><br><span class="line">        verified_birthday = birthday </span><br><span class="line">        response = &quot;Correct&quot; </span><br><span class="line">    # 否则，认为人类审核者提供了更正后的信息。</span><br><span class="line">    else: </span><br><span class="line">        # 从人类的响应中获取更正后的姓名和生日。</span><br><span class="line">        # 如果人类没有提供新的值，则使用 .get() 的默认值，即原始值。</span><br><span class="line">        verified_name = human_response.get(&quot;name&quot;, name) </span><br><span class="line">        verified_birthday = human_response.get(&quot;birthday&quot;, birthday) </span><br><span class="line">        response = f&quot;Made a correction: &#123;human_response&#125;&quot; </span><br><span class="line"></span><br><span class="line">    # 在工具内部直接构造一个用于更新图状态的字典。</span><br><span class="line">    state_update = &#123; </span><br><span class="line">        &quot;name&quot;: verified_name, # 更新状态中的 &#x27;name&#x27; 字段</span><br><span class="line">        &quot;birthday&quot;: verified_birthday, # 更新状态中的 &#x27;birthday&#x27; 字段</span><br><span class="line">        # 创建一个 ToolMessage，将其添加到状态的 &#x27;messages&#x27; 列表中。</span><br><span class="line">        # 这个消息将作为此工具调用的正式“答复”出现在对话历史中。</span><br><span class="line">        # tool_call_id 是必需的，用于将此答复与 LLM 的原始工具调用请求关联起来。</span><br><span class="line">        &quot;messages&quot;: [ToolMessage(response, tool_call_id=tool_call_id)], </span><br><span class="line">    &#125; </span><br><span class="line">    # 这个工具不返回一个简单的字符串或数字，而是返回一个 Command 对象。</span><br><span class="line">    # Command(update=...) 是一个明确的指令，告诉 LangGraph 执行器：</span><br><span class="line">    # “请不要将我的返回值当作普通工具输出，而是用 state_update 字典里的内容来直接更新当前的图状态。”</span><br><span class="line">    return Command(update=state_update) </span><br></pre></td></tr></table></figure>
<p>图的其余部分保持不变。</p>
<h4 id="提示聊天机器人调用人工审查"><a href="#提示聊天机器人调用人工审查" class="headerlink" title="提示聊天机器人调用人工审查"></a>提示聊天机器人调用人工审查</h4><p>提示聊天机器人查找 LangGraph 库的“生日”，并在其获取所需信息后，指示聊天机器人使用 <code>human_assistance</code> 工具。通过在工具参数中设置 <code>name</code> 和 <code>birthday</code>，您将强制聊天机器人为这些字段生成提议。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">user_input = (</span><br><span class="line">    &quot;你能查一下 LangGraph 是什么时候发布的吗？ &quot;</span><br><span class="line">    &quot;当你有了答案后，使用 human_assistance 工具进行审查。&quot;</span><br><span class="line">)</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=&quot;values&quot;,</span><br><span class="line">)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>我们再次在 <code>human_assistance</code> 工具中触发了 <code>interrupt</code>。</p>
<h4 id="添加人工协助"><a href="#添加人工协助" class="headerlink" title="添加人工协助"></a>添加人工协助</h4><p>聊天机器人未能识别正确的日期，因此为其提供信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">human_command = Command(</span><br><span class="line">    resume=&#123;</span><br><span class="line">        &quot;name&quot;: &quot;LangGraph&quot;,</span><br><span class="line">        &quot;birthday&quot;: &quot;Jan 17, 2024&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">events = graph.stream(human_command, config, stream_mode=&quot;values&quot;)</span><br><span class="line">for event in events:</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>请注意，这些字段现在已反映在状态中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">snapshot = graph.get_state(config)</span><br><span class="line"></span><br><span class="line">&#123;k: v for k, v in snapshot.values.items() if k in (&quot;name&quot;, &quot;birthday&quot;)&#125;</span><br></pre></td></tr></table></figure>
<p>这使得下游节点（例如，进一步处理或存储信息的节点）可以轻松访问它们。</p>
<h3 id="时间功能（从之前的某个状态开始）"><a href="#时间功能（从之前的某个状态开始）" class="headerlink" title="时间功能（从之前的某个状态开始）"></a>时间功能（从之前的某个状态开始）</h3><p>在典型的聊天机器人工作流程中，用户与机器人进行一次或多次交互以完成任务。<a href="https://github.langchain.ac.cn/langgraph/tutorials/get-started/3-add-memory/">记忆</a>和<a href="https://github.langchain.ac.cn/langgraph/tutorials/get-started/4-human-in-the-loop/">人工干预</a>功能可以为图状态启用检查点并控制未来的响应。</p>
<p>如果您希望用户能够从之前的响应开始并探索不同的结果，该怎么办？或者，如果您希望用户能够回溯聊天机器人的工作以纠正错误或尝试不同的策略，这在自主软件工程师等应用程序中很常见，那又该怎么办？</p>
<p>您可以使用 LangGraph 内置的<strong>时光旅行</strong>功能创建这些类型的体验。</p>
<h4 id="回溯您的图"><a href="#回溯您的图" class="headerlink" title="回溯您的图"></a>回溯您的图</h4><p>通过使用图的<code>get_state_history</code>方法获取检查点来回溯您的图。然后，您可以从之前的这个时间点恢复执行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 初始化一个变量 to_replay 为 None，它将用于存储我们想要“时间旅行”回去的特定状态。</span><br><span class="line"># to_replay 将在循环中被赋值为我们感兴趣的那个历史状态快照。</span><br><span class="line">to_replay = None</span><br><span class="line"></span><br><span class="line"># 遍历 `graph` 在给定 `config` 下的所有历史状态。</span><br><span class="line"># `graph.get_state_history(config)` 会返回一个迭代器，其中包含了从开始到当前的所有状态快照。</span><br><span class="line">for state in graph.get_state_history(config):</span><br><span class="line">    # 打印当前状态快照中的一些信息，以便我们观察和选择。</span><br><span class="line">    # `len(state.values[&quot;messages&quot;])` 显示了到该状态为止，对话历史中的消息总数。</span><br><span class="line">    # `state.next` 显示了在该状态之后，图将要执行的下一个节点或步骤的名称。</span><br><span class="line">    print(&quot;Num Messages: &quot;, len(state.values[&quot;messages&quot;]), &quot;Next: &quot;, state.next)</span><br><span class="line">    </span><br><span class="line">    # 打印一条分隔线，使输出更易读。</span><br><span class="line">    print(&quot;-&quot; * 80)</span><br><span class="line">    </span><br><span class="line">    # 这里是选择“时间旅行”目标点的关键逻辑。</span><br><span class="line">    # 我们设定一个条件：当对话历史中的消息数量正好等于4时，我们就找到了想要回到的那个点。</span><br><span class="line">    # 这是一个为了演示而设定的任意条件，在实际应用中，您可以根据需要设置更复杂的选择逻辑。</span><br><span class="line">    if len(state.values[&quot;messages&quot;]) == 4:</span><br><span class="line">        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.</span><br><span class="line">        # 将当前这个符合条件的状态（state）保存到 to_replay 变量中。</span><br><span class="line">        # 循环结束后，to_replay 变量将持有我们选中的那个历史时刻的完整状态，</span><br><span class="line">        # 之后我们就可以用它来恢复或修改执行流程。</span><br><span class="line">        to_replay = state</span><br></pre></td></tr></table></figure>
<p>图的每一步都会保存检查点。这<strong>跨越了调用</strong>，因此您可以回溯整个线程的历史。</p>
<h4 id="从特定时间点加载状态"><a href="#从特定时间点加载状态" class="headerlink" title="从特定时间点加载状态"></a>从特定时间点加载状态</h4><p>从<code>to_replay</code>状态恢复。从这一点恢复将接下来调用<strong>action</strong>节点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(to_replay.next)</span><br><span class="line">print(to_replay.config)</span><br></pre></td></tr></table></figure>
<p>检查点的<code>to_replay.config</code>包含一个<code>checkpoint_id</code>时间戳。提供此<code>checkpoint_id</code>值会告诉 LangGraph 的检查点器从该时间点<strong>加载</strong>状态。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for event in graph.stream(None, to_replay.config, stream_mode=&quot;values&quot;):</span><br><span class="line">    if &quot;messages&quot; in event:</span><br><span class="line">        event[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h3 id="运行本地服务器"><a href="#运行本地服务器" class="headerlink" title="运行本地服务器"></a>运行本地服务器</h3><h4 id="安装-LangGraph-CLI"><a href="#安装-LangGraph-CLI" class="headerlink" title="安装 LangGraph CLI"></a>安装 LangGraph CLI</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Python &gt;= 3.11 is required.</span><br><span class="line"></span><br><span class="line">pip install --upgrade &quot;langgraph-cli[inmem]&quot;</span><br></pre></td></tr></table></figure>
<h4 id="创建-LangGraph-应用-🌱"><a href="#创建-LangGraph-应用-🌱" class="headerlink" title="创建 LangGraph 应用 🌱"></a>创建 LangGraph 应用 🌱</h4><p>从 <a href="https://github.com/langchain-ai/new-langgraph-project"><code>new-langgraph-project-python</code> 模板</a> 或 <a href="https://github.com/langchain-ai/new-langgraphjs-project"><code>new-langgraph-project-js</code> 模板</a> 创建一个新应用。此模板展示了一个单节点应用程序，您可以根据自己的逻辑进行扩展。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">langgraph new . --template new-langgraph-project-python</span><br></pre></td></tr></table></figure>
<blockquote>
<p>使用 <code>langgraph new</code> 而不指定模板，系统将显示一个交互式菜单，您可以从中选择可用的模板列表。</p>
</blockquote>
<h4 id="使用uv安装依赖项"><a href="#使用uv安装依赖项" class="headerlink" title="使用uv安装依赖项"></a>使用uv安装依赖项</h4><p>uv 是一个用 Rust 编写的极速 Python 包和项目管理器 。它旨在解决传统 Python 包管理工具（如 pip 、 poetry 等）在速度和效率方面的痛点，提供更快的安装、依赖解析和环境管理。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install uv#安装uv</span><br></pre></td></tr></table></figure>
<p>运行<code>uv sync</code>会根据 <code>pyproject.toml</code>的依赖创建虚拟环境并安装依赖</p>
<blockquote>
<p><code>pyproject.toml</code> 文件是 Python 项目中用于统一配置项目元数据、构建系统、依赖管理和各种工具设置的标准化文件。它通常用于替代旧的 requirements.txt 文件，提供更现代和集中的项目配置方式。</p>
</blockquote>
<h4 id="创建一个-env-文件"><a href="#创建一个-env-文件" class="headerlink" title="创建一个 .env 文件"></a>创建一个 <code>.env</code> 文件</h4><p>您将在新 LangGraph 应用的根目录下找到一个 <code>.env.example</code> 文件。在新 LangGraph 应用的根目录下创建一个 <code>.env</code> 文件，并将 <code>.env.example</code> 文件的内容复制到其中，填入所需的 API 密钥。</p>
<p>添加环境变量如LANGSMITH_API_KEY，OPENAI_API_KEY等</p>
<h4 id="启动-LangGraph-服务器"><a href="#启动-LangGraph-服务器" class="headerlink" title="启动 LangGraph 服务器"></a>启动 LangGraph 服务器</h4><p>在本地启动 LangGraph API 服务器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">langgraph dev</span><br></pre></td></tr></table></figure>
<p>示例输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;    Ready!</span><br><span class="line">&gt;</span><br><span class="line">&gt;    - API: [https://:2024](https://:2024/)</span><br><span class="line">&gt;</span><br><span class="line">&gt;    - Docs: https://:2024/docs</span><br><span class="line">&gt;</span><br><span class="line">&gt;    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024</span><br></pre></td></tr></table></figure>
<p>LangGraph 服务器（如您通过 langgraph dev 命令启动的服务器）的主要作用是提供一个运行环境和接口，用于开发、测试、部署和管理基于 LangGraph 构建的 AI 代理和应用程序。具体来说，它有以下几个主要用途：</p>
<ol>
<li>API 接口暴露 ：它将您用 LangGraph 定义的复杂代理逻辑（即图结构）通过标准的 RESTful API 接口暴露出来。这意味着其他应用程序、前端界面或者其他服务可以通过 HTTP 请求与您的 LangGraph 代理进行交互，而无需直接集成 LangGraph 的 Python 代码。</li>
<li>简化部署 ：通过将 LangGraph 应用程序打包成一个可运行的服务，您可以更容易地将其部署到云服务器、容器（如 Docker）或其他生产环境中。这使得 LangGraph 代理可以作为一个独立的微服务运行，方便扩展和管理。</li>
<li><p>开发和调试便利 ：</p>
<ul>
<li>实时预览和调试 ：服务器通常会提供一个 Studio UI（如您在 <a href="http://127.0.0.1:2024/studio">http://127.0.0.1:2024/studio</a> 看到的），让开发者能够可视化地查看代理的图结构、执行流程、状态变化和中间步骤，这对于理解和调试复杂的代理行为至关重要。</li>
<li>API 文档 ：自动生成的 API 文档（如 <a href="http://127.0.0.1:2024/docs">http://127.0.0.1:2024/docs</a> ）提供了所有可用接口的详细说明和交互式测试功能，极大地加速了开发和集成过程。</li>
</ul>
</li>
<li>状态管理和持久化 ：LangGraph 代理通常涉及复杂的状态管理。服务器可以负责处理这些状态的持久化，确保代理在多次交互之间能够记住上下文和历史信息。</li>
</ol>
<h4 id="在-LangGraph-Studio-中测试您的应用程序"><a href="#在-LangGraph-Studio-中测试您的应用程序" class="headerlink" title="在 LangGraph Studio 中测试您的应用程序"></a>在 LangGraph Studio 中测试您的应用程序</h4><p><a href="https://github.langchain.ac.cn/langgraph/concepts/langgraph_studio/">LangGraph Studio</a> 是一个专门的 UI，您可以连接到 LangGraph API 服务器，以便在本地可视化、交互和调试您的应用程序。通过访问 <code>langgraph dev</code> 命令输出中提供的 URL，在 LangGraph Studio 中测试您的图。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;    - LangGraph Studio Web UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://github.langchain.ac.cn/langgraph/tutorials/get-started/1-build-basic-chatbot/#1-install-packages">构建一个基本聊天机器人 - LangChain 框架</a></p>
<p>官方教程，但是英文<a href="https://academy.langchain.com/collections">https://academy.langchain.com/collections</a></p>
<p><a href="https://www.bilibili.com/video/BV1AY4aeRETY/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">3.5 小时出证！LangGraph 官方课程 🆓 重磅上线🔥🔥🔥_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>LangGraph学习——agent——上</title>
    <url>/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本教程为langchain官方教程的学习记录</p>
<p><a href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a href="https://github.com/zxj-2023/learn-rag-langchain"><a href="https://github.com/zxj-2023/learn-rag-langchain/tree/main/academy-langgraph">learn-rag-langchain/academy-langgraph at main · zxj-2023/learn-rag-langchain</a></a></p>
<h3 id="module-1"><a href="#module-1" class="headerlink" title="module-1"></a>module-1</h3><h4 id="route路由"><a href="#route路由" class="headerlink" title="route路由"></a>route路由</h4><p>在 LangGraph 中，<strong>route（路由）\</strong>的核心作用是*<em>根据当前状态动态决定“下一步应该执行哪个节点”*</em></p>
<h5 id="定义工具"><a href="#定义工具" class="headerlink" title="定义工具"></a>定义工具</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def multiply(a: int, b: int) -&gt; int:</span><br><span class="line">    &quot;&quot;&quot;Multiply a and b.</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        a: first int</span><br><span class="line">        b: second int</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line">    </span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line"></span><br><span class="line">)</span><br><span class="line">llm_with_tools = llm.bind_tools([multiply])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>三引号字符串叫 <strong>docstring</strong>，它会被 LangChain 拿来做两件事：</p>
<ol>
<li><strong>生成工具的 description（给大模型看的“说明书”）</strong><br>没有它时，LangChain 只能退而求其次，把函数名 <code>multiply</code> 拼成一句 “multiply tool” 之类的默认描述。大模型拿到的工具列表里，这个工具就只有一个干巴巴的名字和参数列表，它可能猜不到这个工具到底是干什么的</li>
<li><strong>给人类开发者自己看</strong><br>IDE、文档生成器、静态检查工具都会读取这段文字，方便后期维护。</li>
</ol>
</blockquote>
<h5 id="构建条件边"><a href="#构建条件边" class="headerlink" title="构建条件边"></a>构建条件边</h5><p><code>tool_calling_llm</code> 是一个<strong>普通的计算节点</strong>（node），负责把当前对话状态交给大模型，让大模型决定要不要调用工具；</p>
<p>真正完成“路由”动作的是 <strong><code>tools_condition</code></strong> 这个函数——它才是 LangGraph 里的 <strong>route（条件边）</strong>。</p>
<p><code>tools_condition</code> 是 作为<strong>LangGraph 预置的“默认路由函数”</strong>，功能就是，如果大模型的最新回复中包含工具调用，就调用工具</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Node</span><br><span class="line">def tool_calling_llm(state: MessagesState):</span><br><span class="line">	#调用大模型后将最新的消息返回</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm_with_tools.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">#MessagesState 是 LangGraph 官方预置 的一种 状态（State）定义</span><br><span class="line">#这个状态维护了一个消息list，有新的消息就加进这个消息list</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;tool_calling_llm&quot;, tool_calling_llm)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode([multiply]))</span><br><span class="line">builder.add_edge(START, &quot;tool_calling_llm&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;tool_calling_llm&quot;,</span><br><span class="line">    # 如果助手（结果）的最新消息是工具调用 -&gt; tools_condition 路由到工具</span><br><span class="line">    # 如果助手（结果）的最新消息不是工具调用 -&gt; tools_condition 路由到 END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719142543838.png" alt="image-20250719142543838"></p>
<h5 id="调用"><a href="#调用" class="headerlink" title="调用"></a>调用</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage</span><br><span class="line">messages = [HumanMessage(content=&quot;你好，2乘2是多少&quot;)]</span><br><span class="line">messages = graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，2乘2是多少</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_e026ceb409e247748786ad)</span><br><span class="line"> Call ID: call_e026ceb409e247748786ad</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">4</span><br></pre></td></tr></table></figure>
<h4 id="agent代理"><a href="#agent代理" class="headerlink" title="agent代理"></a>agent代理</h4><p>在 LangGraph 中，<strong>代理（Agent）</strong> 被明确定义为<strong>“一个由大语言模型（LLM）驱动的、能够循环决策并调用外部工具来完成任务的节点或子图”</strong>。</p>
<p><strong>Agent = LLM + 工具集合 + 提示模板</strong>，三者在 LangGraph 的状态化图结构里循环运行，直到满足停止条件。</p>
<blockquote>
<p><a href="https://arxiv.org/abs/2210.03629">ReAct</a> 是一种流行的通用智能体架构，它结合了这些扩展，并整合了三个核心概念。</p>
<ol>
<li><a href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#tool-calling">工具调用</a>：允许LLM根据需要选择和使用各种工具。</li>
<li><a href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#memory">记忆</a>：使智能体能够保留和使用之前步骤的信息。</li>
<li><a href="https://github.langchain.ac.cn/langgraph/concepts/agentic_concepts/#planning">规划</a>：使LLM能够创建并遵循多步计划以实现目标。</li>
</ol>
<p>即</p>
<p><code>act</code>- 让模型调用特定工具</p>
<p><code>observe</code> - 将工具输出传递回模型  </p>
<p> <code>reason</code> - 让模型对工具输出进行推理，以决定下一步操作（例如，调用另一个工具或直接响应）</p>
</blockquote>
<h5 id="定义工具-1"><a href="#定义工具-1" class="headerlink" title="定义工具"></a>定义工具</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tools = [add, multiply, divide]#工具函数具体内容省略</span><br><span class="line">llm = ChatOpenAI()</span><br><span class="line"></span><br><span class="line"># 在这个 ipynb 文件中，我们将并行工具调用（parallel tool calling）设置为 false，因为数学计算通常是按顺序执行的，并且这次我们有3个可以进行数学计算的工具。</span><br><span class="line"># OpenAI 模型为了效率，默认进行并行工具调用，详情请参阅 `https://python.langchain.com/docs/how_to/tool_calling_parallel/`</span><br><span class="line"># 不妨尝试一下，看看模型在处理数学方程式时的表现！</span><br><span class="line">llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)</span><br></pre></td></tr></table></figure>
<h5 id="创建代理"><a href="#创建代理" class="headerlink" title="创建代理"></a>创建代理</h5><p>定义节点</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line"># System message</span><br><span class="line">sys_msg = SystemMessage(content=&quot;你是一个乐于助人的助手，负责对一组输入执行算术运算。&quot;)</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def assistant(state: MessagesState):</span><br><span class="line">   return &#123;&quot;messages&quot;: [llm_with_tools.invoke([sys_msg] + state[&quot;messages&quot;])]&#125;</span><br></pre></td></tr></table></figure>
<p>这一步相当于定义了系统提示词，然后在 assistant 这个节点里，通过 [sys_msg] + state[“messages”] 这部分代码，这个系统提示词被添加到了整个对话历史的最前面，然后一起发送给模型。这样一来，模型在生成回复时就会遵循这个系统提示词的指示。</p>
<p>与上一个不同的是，我们将 <code>Tools</code> 节点 <strong>回环</strong> 连接到 <code>Assistant</code>，从而形成一个回路。</p>
<p>在 assistant节点执行后，<code>tools_condition</code>检查模型的输出是否为工具调用。</p>
<p>如果是工具调用，则流程被导向至 <code>tools</code> 节点。  </p>
<p><code>tools</code>节点重新连接到<code>assistant</code><strong>。</strong> 只要模型决定调用工具，此循环就会继续。  </p>
<p>如果模型的响应不是工具调用，则流程被导向至结束，终止该过程。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line"></span><br><span class="line"># Define nodes: these do the work</span><br><span class="line">builder.add_node(&quot;assistant&quot;, assistant)</span><br><span class="line">builder.add_node(&quot;tools&quot;, ToolNode(tools))</span><br><span class="line"></span><br><span class="line"># Define edges: these determine how the control flow moves</span><br><span class="line">builder.add_edge(START, &quot;assistant&quot;)</span><br><span class="line">builder.add_conditional_edges(</span><br><span class="line">    &quot;assistant&quot;,</span><br><span class="line">    # If the latest message (result) from assistant is a tool call -&gt; tools_condition routes to tools</span><br><span class="line">    # If the latest message (result) from assistant is a not a tool call -&gt; tools_condition routes to END</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line">builder.add_edge(&quot;tools&quot;, &quot;assistant&quot;)</span><br><span class="line">react_graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># Show</span><br><span class="line">display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719145948088.png" alt="image-20250719145948088"></p>
<h5 id="调用-1"><a href="#调用-1" class="headerlink" title="调用"></a>调用</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">messages = [HumanMessage(content=&quot;将3和4相加。将结果乘以2。再将结果除以5。&quot;)]</span><br><span class="line">messages = react_graph.invoke(&#123;&quot;messages&quot;: messages&#125;)</span><br><span class="line"></span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=False的输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_6c69898dba0342bfbb889e)</span><br><span class="line"> Call ID: call_6c69898dba0342bfbb889e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_9940e7603ecf4a13a5f2fb)</span><br><span class="line"> Call ID: call_9940e7603ecf4a13a5f2fb</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  divide (call_d48fbbe205a14dfbaa3500)</span><br><span class="line"> Call ID: call_d48fbbe205a14dfbaa3500</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是2.8。</span><br></pre></td></tr></table></figure>
<p>parallel_tool_calls=True的输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">将3和4相加。将结果乘以2。再将结果除以5。</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  add (call_e0c7d8e65f2c49e8aecd3e)</span><br><span class="line"> Call ID: call_e0c7d8e65f2c49e8aecd3e</span><br><span class="line">  Args:</span><br><span class="line">    a: 3</span><br><span class="line">    b: 4</span><br><span class="line">  multiply (call_5bf824058e64489aaace91)</span><br><span class="line"> Call ID: call_5bf824058e64489aaace91</span><br><span class="line">  Args:</span><br><span class="line">    a: 7</span><br><span class="line">    b: 2</span><br><span class="line">  divide (call_36c34f69f6574028b28847)</span><br><span class="line"> Call ID: call_36c34f69f6574028b28847</span><br><span class="line">  Args:</span><br><span class="line">    a: 14</span><br><span class="line">    b: 5</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: add</span><br><span class="line"></span><br><span class="line">7</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">14</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: divide</span><br><span class="line"></span><br><span class="line">2.8</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">最终结果是 **2.8**。</span><br></pre></td></tr></table></figure>
<h4 id="Agent-memory代理记忆"><a href="#Agent-memory代理记忆" class="headerlink" title="Agent memory代理记忆"></a>Agent memory代理记忆</h4><p>使用chekpointer检查点的功能，最简单的检查点之一是 <code>MemorySaver</code>，这是一个用于图形状态的内存键值存储。</p>
<p>这个检查点就相当于把<strong>图的每一次“状态快照”持久化到外部存储</strong>的机制。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">react_graph_memory = builder.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p>我们可以使用 <a href="https://langchain-ai.github.io/langgraph/how-tos/persistence/">记忆功能</a> 来解决这个问题！LangGraph 可以使用检查点工具在每一步之后自动保存图的状态。这一内置的持久化层为我们提供了内存功能，使 LangGraph 能够从最后一次状态更新处继续。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Specify a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Specify an input</span><br><span class="line">messages = [HumanMessage(content=&quot;Add 3 and 4.&quot;)]</span><br><span class="line"></span><br><span class="line"># Run</span><br><span class="line">messages = react_graph_memory.invoke(&#123;&quot;messages&quot;: messages&#125;,config)</span><br><span class="line">for m in messages[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当我们使用内存时，我们需要指定一个 <code>thread_id</code>。这 <code>thread_id</code> 将存储我们的图形状态集合。</p>
<p>如下图，检查点在图的每一步写入状态，这些检查点保存在一个线程中 ，我们可以使用 <code>thread_id</code> 在未来访问该线程</p>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66e0e9f526b41a4ed9e2d28b_agent-memory2.png" alt="state.jpg"></p>
<h3 id="module-2"><a href="#module-2" class="headerlink" title="module-2"></a>module-2</h3><h4 id="state-scheme状态模式"><a href="#state-scheme状态模式" class="headerlink" title="state-scheme状态模式"></a>state-scheme状态模式</h4><p>LangGraph 的 <strong>state-scheme（状态模式）</strong> 就是“一张<strong>蓝图</strong>”，它告诉框架：“在整个图的生命周期里，状态对象应该长什么样、每个字段怎样被更新、以及节点之间如何共享或隔离数据。”</p>
<p>state-scheme 用 <strong>TypedDict</strong> 或 <strong>Pydantic BaseModel</strong> 来声明，定义了：</p>
<ul>
<li>状态里有哪些字段（key）</li>
<li>每个字段的 Python 类型</li>
<li><strong>可选</strong> 该字段的 <strong>reducer</strong>（更新规则）</li>
</ul>
<h5 id="TypedDict"><a href="#TypedDict" class="headerlink" title="TypedDict"></a><strong>TypedDict</strong></h5><p><strong>基本定义</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    foo: str</span><br><span class="line">    bar: str</span><br></pre></td></tr></table></figure>
<p><strong>可增加像 <code>Literal</code> 这样的类型提示，使其更有价值</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Literal</span><br><span class="line"></span><br><span class="line">class TypedDictState(TypedDict):</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p>在这里，<code>mood</code> 只能是 “happy” 或 “sad”。</p>
<p><strong>加 reducer：让更新“可追加”而不覆盖</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class MathState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line">    scratchpad: Annotated[list[str], add_message]  # 新元素自动追加</span><br><span class="line">    answer: int</span><br></pre></td></tr></table></figure>
<p><code>Annotated[list[str], add]</code> 告诉 LangGraph：当节点返回 <code>&#123;&quot;scratchpad&quot;: [&quot;新步骤&quot;]&#125;</code> 时，<strong>追加</strong>到现有列表，而不是替换</p>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import random</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">#定义节点</span><br><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state[&#x27;name&#x27;] + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state):</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;happy&quot;&#125;</span><br><span class="line"></span><br><span class="line">def node_3(state):</span><br><span class="line">    print(&quot;---Node 3---&quot;)</span><br><span class="line">    return &#123;&quot;mood&quot;: &quot;sad&quot;&#125;</span><br><span class="line">#路由函数</span><br><span class="line">def decide_mood(state) -&gt; Literal[&quot;node_2&quot;, &quot;node_3&quot;]:</span><br><span class="line">        </span><br><span class="line">    # Here, let&#x27;s just do a 50 / 50 split between nodes 2, 3</span><br><span class="line">    if random.random() &lt; 0.5:</span><br><span class="line"></span><br><span class="line">        # 50% of the time, we return Node 2</span><br><span class="line">        return &quot;node_2&quot;</span><br><span class="line">    </span><br><span class="line">    # 50% of the time, we return Node 3</span><br><span class="line">    return &quot;node_3&quot;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(TypedDictState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719154439415.png" alt="image-20250719154439415"></p>
<p>因为我们的状态是一个字典，我们只需用一个字典调用图，以设置状态中 <code>name</code> 键的初始值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;name&quot;:&quot;Lance&quot;&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="Dataclass数据类"><a href="#Dataclass数据类" class="headerlink" title="Dataclass数据类"></a><strong>Dataclass数据类</strong></h5><p>python的dataclasses库提供了一种简洁的语法，用于创建主要用于存储数据的类。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line"></span><br><span class="line">@dataclass</span><br><span class="line">class DataclassState:</span><br><span class="line">    name: str</span><br><span class="line">    mood: Literal[&quot;happy&quot;,&quot;sad&quot;]</span><br></pre></td></tr></table></figure>
<p><strong>示例</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def node_1(state):</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;name&quot;: state.name + &quot; is ... &quot;&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(DataclassState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line">builder.add_node(&quot;node_3&quot;, node_3)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_conditional_edges(&quot;node_1&quot;, decide_mood)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line">builder.add_edge(&quot;node_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>要访问 <code>dataclass</code> 的键，我们只需修改在 <code>node_1</code> 中使用的下标即可：</p>
<p>我们使用 <code>state.name</code> 来表示 <code>dataclass</code> 状态，而不是使用 <code>state[&quot;name&quot;]</code> 来表示上面的 <code>TypedDict</code>。</p>
<p>你会注意到一个有点奇怪的地方：在每个节点中，我们仍然返回一个字典来执行状态更新。</p>
<p><strong>Dataclass 只是“描述”状态的形状，而真正在 LangGraph 的节点之间流动的依旧是「字典」</strong>，这是框架设计层面的约定</p>
<p>在这种情况下，<code>dataclass</code> 拥有键 <code>name</code>，因此我们可以通过从节点传递一个字典来更新它，就像在状态为 <code>TypedDict</code> 时所做的那样。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.invoke(DataclassState(name=&quot;Lance&quot;,mood=&quot;sad&quot;))</span><br></pre></td></tr></table></figure>
<p>我们通过 <code>dataclass</code> 来设置状态中每个键/通道的初始值！</p>
<h4 id="State-Reducers状态更新函数"><a href="#State-Reducers状态更新函数" class="headerlink" title="State Reducers状态更新函数"></a><strong>State Reducers</strong>状态更新函数</h4><p><a href="https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers">Reducers</a> 为我们指定了如何执行更新。它接收 <strong>旧状态</strong> 与 <strong>一次变更指令（action / 增量字段）</strong>，<strong>返回全新的状态对象</strong>，整个过程中<strong>不能修改原有数据</strong>。</p>
<p>我们可以使用 <code>Annotated</code> 类型来指定一个 reducer 函数。在这种情况下，让我们将每个节点返回的值附加到结果中，而不是覆盖它们。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing import Annotated</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br></pre></td></tr></table></figure>
<p>我们只需要一个可以执行此操作的缩减器：<code>operator.add</code> 是 Python 内置 operator 模块中的一个函数。当 <code>operator.add</code> 应用于列表时，它执行列表连接。</p>
<h5 id="Custom-Reducers-自定义-Reducers"><a href="#Custom-Reducers-自定义-Reducers" class="headerlink" title="Custom Reducers 自定义 Reducers"></a><strong>Custom Reducers 自定义 Reducers</strong></h5><p>我们同样可以自定义reducers函数，解决一些特殊情况，比如，如下可以解决传入参数为none的情况</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def reduce_list(left: list | None, right: list | None) -&gt; list:</span><br><span class="line">    &quot;&quot;&quot;安全地合并两个列表，处理其中一个或两个输入可能为 None 的情况。</span><br><span class="line"></span><br><span class="line">    参数：</span><br><span class="line">        left (list | None): 要合并的第一个列表，或 None。</span><br><span class="line">        right (list | None): 要合并的第二个列表，或 None。</span><br><span class="line"></span><br><span class="line">    返回：</span><br><span class="line">        list: 一个包含两个输入列表所有元素的新列表。</span><br><span class="line">               如果输入为 None，则将其视为空列表。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if not left:</span><br><span class="line">        left = []</span><br><span class="line">    if not right:</span><br><span class="line">        right = []</span><br><span class="line">    return left + right</span><br><span class="line"></span><br><span class="line">class DefaultState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], add]</span><br><span class="line"></span><br><span class="line">class CustomReducerState(TypedDict):</span><br><span class="line">    foo: Annotated[list[int], reduce_list]</span><br></pre></td></tr></table></figure>
<h5 id="MessagesState"><a href="#MessagesState" class="headerlink" title="MessagesState"></a>MessagesState</h5><p>我可以使用内置的 reducer <code>add_messages</code> 来处理状态中的消息</p>
<p>而<em><code>MessagesState</code></em> <em>内置了一个</em> <em><code>messages</code></em> 键 它还为该键内置了一个 <code>add_messages</code> 合并器，这两个是等价的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Annotated</span><br><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">from langchain_core.messages import AnyMessage</span><br><span class="line">from langgraph.graph.message import add_messages</span><br><span class="line"></span><br><span class="line"># 定义一个自定义的 TypedDict，其中包含一个带有 add_messages reducer 的消息列表。</span><br><span class="line">class CustomMessagesState(TypedDict):</span><br><span class="line">    messages: Annotated[list[AnyMessage], add_messages]</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br><span class="line"></span><br><span class="line"># 使用 MessagesState ，它包含带有 add_messages reducer 的 messages 键。</span><br><span class="line">class ExtendedMessagesState(MessagesState):</span><br><span class="line">    # 添加除 messages 之外所需的任何键， messages 是预构建的。</span><br><span class="line">    added_key_1: str</span><br><span class="line">    added_key_2: str</span><br><span class="line">    # etc</span><br></pre></td></tr></table></figure>
<p>在使用 <code>add_messages</code> reducer 时，让我们展示一些有用的技巧。</p>
<p><strong>重写（Re-writing）</strong></p>
<p>如果我们传递的消息与 <code>messages</code> 列表中已有的消息具有相同的 ID，则该消息将被覆盖！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Initial state</span><br><span class="line">initial_messages = [AIMessage(content=&quot;Hello! How can I assist you?&quot;, name=&quot;Model&quot;, id=&quot;1&quot;),</span><br><span class="line">                    HumanMessage(content=&quot;I&#x27;m looking for information on marine biology.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line">                   ]</span><br><span class="line"></span><br><span class="line"># New message to add</span><br><span class="line">new_message = HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;)</span><br><span class="line"></span><br><span class="line"># Test</span><br><span class="line">add_messages(initial_messages , new_message)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[AIMessage(content=&#x27;Hello! How can I assist you?&#x27;, name=&#x27;Model&#x27;, id=&#x27;1&#x27;),</span><br><span class="line"> HumanMessage(content=&quot;I&#x27;m looking for information on whales, specifically&quot;, name=&#x27;Lance&#x27;, id=&#x27;2&#x27;)]</span><br></pre></td></tr></table></figure>
<p><strong>删除（Removal）</strong></p>
<p><code>add_messages</code> 也 <a href="https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/">同样支持删除</a>。为此，我们简单地使用 <a href="https://api.python.langchain.com/en/latest/messages/langchain_core.messages.modifier.RemoveMessage.html">RemoveMessage</a> 来自 <code>langchain_core</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Message list</span><br><span class="line">messages = [AIMessage(&quot;Hi.&quot;, name=&quot;Bot&quot;, id=&quot;1&quot;)]</span><br><span class="line">messages.append(HumanMessage(&quot;Hi.&quot;, name=&quot;Lance&quot;, id=&quot;2&quot;))</span><br><span class="line">messages.append(AIMessage(&quot;So you said you were researching ocean mammals?&quot;, name=&quot;Bot&quot;, id=&quot;3&quot;))</span><br><span class="line">messages.append(HumanMessage(&quot;Yes, I know about whales. But what others should I learn about?&quot;, name=&quot;Lance&quot;, id=&quot;4&quot;))</span><br><span class="line"></span><br><span class="line"># Isolate messages to delete</span><br><span class="line">delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]</span><br><span class="line">print(delete_messages)</span><br></pre></td></tr></table></figure>
<h4 id="Multiple-Schemas-多种状态"><a href="#Multiple-Schemas-多种状态" class="headerlink" title="Multiple Schemas 多种状态"></a><strong>Multiple Schemas</strong> 多种状态</h4><h5 id="Private-State-私有状态"><a href="#Private-State-私有状态" class="headerlink" title="Private State 私有状态"></a><strong>Private State</strong> 私有状态</h5><p>首先，让我们讨论在节点之间传递 <a href="https://langchain-ai.github.io/langgraph/how-tos/pass_private_state/">private state</a> 的情况。这对于图的中间计算逻辑中需要的任何内容都很有用，但与图的整体输入或输出无关。</p>
<p>示例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    foo: int</span><br><span class="line"></span><br><span class="line">class PrivateState(TypedDict):</span><br><span class="line">    baz: int</span><br><span class="line"></span><br><span class="line">def node_1(state: OverallState) -&gt; PrivateState:</span><br><span class="line">    print(&quot;---Node 1---&quot;)</span><br><span class="line">    return &#123;&quot;baz&quot;: state[&#x27;foo&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line">def node_2(state: PrivateState) -&gt; OverallState:</span><br><span class="line">    print(&quot;---Node 2---&quot;)</span><br><span class="line">    return &#123;&quot;foo&quot;: state[&#x27;baz&#x27;] + 1&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(OverallState)</span><br><span class="line">builder.add_node(&quot;node_1&quot;, node_1)</span><br><span class="line">builder.add_node(&quot;node_2&quot;, node_2)</span><br><span class="line"></span><br><span class="line"># Logic</span><br><span class="line">builder.add_edge(START, &quot;node_1&quot;)</span><br><span class="line">builder.add_edge(&quot;node_1&quot;, &quot;node_2&quot;)</span><br><span class="line">builder.add_edge(&quot;node_2&quot;, END)</span><br><span class="line"></span><br><span class="line"># Add</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719171509917.png" alt="image-20250719171509917"></p>
<p>我们将定义一个 <code>OverallState</code> 和一个 <code>PrivateState</code>。<code>node_2</code> 使用 <code>PrivateState</code> 作为输入，但输出写入到 <code>OverallState</code>。</p>
<p><code>baz</code> 仅包含在 <code>PrivateState</code> 中。因此，我们可以看到 <code>baz</code> 被排除在图形输出之外，因为它不在 <code>OverallState</code> 中。</p>
<h5 id="Input-Output-Schema-输入-输出模式"><a href="#Input-Output-Schema-输入-输出模式" class="headerlink" title="Input / Output Schema 输入/输出模式"></a><strong>Input / Output Schema </strong>输入/输出模式</h5><p>在 LangGraph 中，<strong>Input / Output Schema</strong> 就是“<strong>图的对外接口协议</strong>”：<strong>调用者只能按 Input Schema 传参；图运行完后，只吐出 Output Schema 规定的字段。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"># 定义输入的模式</span><br><span class="line">class InputState(TypedDict):</span><br><span class="line">    question: str</span><br><span class="line"></span><br><span class="line"># 定义输出的模式</span><br><span class="line">class OutputState(TypedDict):</span><br><span class="line">    answer: str</span><br><span class="line"></span><br><span class="line"># 定义整体模式，结合输入和输出</span><br><span class="line">class OverallState(InputState, OutputState):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"># 定义处理输入并生成答案的节点</span><br><span class="line">def answer_node(state: InputState):</span><br><span class="line">    # 示例答案和额外键</span><br><span class="line">    return &#123;&quot;answer&quot;: &quot;bye&quot;, &quot;question&quot;: state[&quot;question&quot;]&#125;</span><br><span class="line"></span><br><span class="line"># 构建图，并指定输入和输出模式</span><br><span class="line">builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)</span><br><span class="line">builder.add_node(answer_node)  # 添加答案节点</span><br><span class="line">builder.add_edge(START, &quot;answer_node&quot;)  # 定义起始边</span><br><span class="line">builder.add_edge(&quot;answer_node&quot;, END)  # 定义结束边</span><br><span class="line">graph = builder.compile()  # 编译图</span><br><span class="line"></span><br><span class="line"># 使用输入调用图并打印结果</span><br><span class="line">print(graph.invoke(&#123;&quot;question&quot;: &quot;hi&quot;&#125;))</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;answer&#x27;: &#x27;bye Lance&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，<code>input</code> / <code>output</code> 模式对图的输入和输出上允许的键进行 <strong>过滤</strong>。可以看到 <code>output</code> 模式将输出限制为仅包含 <code>answer</code> 键。</p>
<h4 id="Filtering-and-trimming-messages筛选和精简消息"><a href="#Filtering-and-trimming-messages筛选和精简消息" class="headerlink" title="Filtering and trimming messages筛选和精简消息"></a><strong>Filtering and trimming messages</strong>筛选和精简消息</h4><p>如果我们在处理长时间对话时不够小心，会导致高令牌使用量和延迟，因为我们传递给模型的是一系列不断增加的消息。所以要进行筛选和精简消息。</p>
<h5 id="简化器（Reducer）"><a href="#简化器（Reducer）" class="headerlink" title="简化器（Reducer）"></a><strong>简化器（Reducer）</strong></h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import RemoveMessage</span><br><span class="line"></span><br><span class="line"># Nodes</span><br><span class="line">def filter_messages(state: MessagesState):</span><br><span class="line">    # 删除除最近两条消息外的所有消息</span><br><span class="line">    delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]]</span><br><span class="line">    return &#123;&quot;messages&quot;: delete_messages&#125;</span><br><span class="line"></span><br><span class="line">def chat_model_node(state: MessagesState):    </span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;filter&quot;, filter_messages)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;filter&quot;)</span><br><span class="line">builder.add_edge(&quot;filter&quot;, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250719203204234.png" alt="image-20250719203204234"></p>
<h5 id="筛选消息（Filtering-messages）"><a href="#筛选消息（Filtering-messages）" class="headerlink" title="筛选消息（Filtering messages）"></a><strong>筛选消息（Filtering messages）</strong></h5><p>如果你不需要或不希望修改图状态，可以直接过滤传递给聊天模型的消息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(state[&quot;messages&quot;][-1:])]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p>例如，只需传递一个过滤后的列表：<code>llm.invoke(messages[-1:])</code> 给模型。</p>
<p>状态包含了所有消息。但这里模型调用仅使用最后一条消息</p>
<h5 id="裁剪消息（Trim-messages）"><a href="#裁剪消息（Trim-messages）" class="headerlink" title="裁剪消息（Trim messages）"></a><strong>裁剪消息（Trim messages）</strong></h5><p>另一种方法是根据设定一定数量的tokens进行 <a href="https://python.langchain.com/v0.2/docs/how_to/trim_messages/#getting-the-last-max_tokens-tokens">trim messages</a>。在把对话历史发给大模型之前，按 <strong>token 预算</strong> 把超长消息列表“剪”到合适长度。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import trim_messages</span><br><span class="line"></span><br><span class="line"># Node</span><br><span class="line">def chat_model_node(state: MessagesState):</span><br><span class="line">    # 使用 trim_messages 函数修剪消息列表</span><br><span class="line">    # max_tokens: 限制消息的最大令牌数</span><br><span class="line">    # strategy: 修剪策略，这里是“last”，表示保留最新的消息</span><br><span class="line">    # token_counter: 用于计算令牌数的模型实例</span><br><span class="line">    # allow_partial: 是否允许部分修剪</span><br><span class="line">    messages = trim_messages(</span><br><span class="line">            state[&quot;messages&quot;],</span><br><span class="line">            max_tokens=100,</span><br><span class="line">            strategy=&quot;last&quot;,</span><br><span class="line">            token_counter= ChatOpenAI(</span><br><span class="line">                model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">                api_key=&quot;sk-&quot;,</span><br><span class="line">                base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;),</span><br><span class="line">            allow_partial=False,</span><br><span class="line">        )</span><br><span class="line">    # 调用语言模型（llm）处理修剪后的消息，并返回结果</span><br><span class="line">    return &#123;&quot;messages&quot;: [llm.invoke(messages)]&#125;</span><br><span class="line"></span><br><span class="line"># Build graph</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;chat_model&quot;, chat_model_node)</span><br><span class="line">builder.add_edge(START, &quot;chat_model&quot;)</span><br><span class="line">builder.add_edge(&quot;chat_model&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-message-summarization带有消息总结功能的聊天机器人"><a href="#Chatbot-with-message-summarization带有消息总结功能的聊天机器人" class="headerlink" title="Chatbot with message summarization带有消息总结功能的聊天机器人"></a><strong>Chatbot with message summarization</strong>带有消息总结功能的聊天机器人</h4><p>与其仅仅修剪或过滤消息，我们将展示如何使用大型语言模型（LLMs）来生成对话的实时摘要。</p>
<p>这使我们能够保留整个对话的压缩表示，而不仅仅是通过修剪或过滤将其移除。</p>
<p>我们将为该聊天机器人配备记忆功能，支持长时间对话，同时不会产生高昂的 token 成本或延迟。</p>
<h5 id="定义总结状态"><a href="#定义总结状态" class="headerlink" title="定义总结状态"></a>定义总结状态</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import MessagesState</span><br><span class="line">class State(MessagesState):</span><br><span class="line">    summary: str</span><br></pre></td></tr></table></figure>
<p>除了内置的 <code>messages</code> 键之外，我们现在还将包含一个自定义键（<code>summary</code>）。</p>
<h5 id="定义LLM节点"><a href="#定义LLM节点" class="headerlink" title="定义LLM节点"></a>定义LLM节点</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage </span><br><span class="line"> </span><br><span class="line"> # 定义调用模型的逻辑</span><br><span class="line">def call_model(state: State): </span><br><span class="line">     </span><br><span class="line">     # 获取摘要（如果存在） </span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 如果有摘要，则添加它</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 将摘要添加到系统消息中</span><br><span class="line">         system_message = f&quot;先前对话的摘要：&#123;summary&#125;&quot; </span><br><span class="line"> </span><br><span class="line">         # 将摘要附加到任何较新的消息中</span><br><span class="line">         messages = [SystemMessage(content=system_message)] + state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     else: </span><br><span class="line">         messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     return &#123;&quot;messages&quot;: response&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>调用我们的LLM</strong>，如果存在摘要，则将其纳入提示中。</p>
<blockquote>
<p>当 call_model 函数返回 {“messages”: response} 时，它是在告诉 langgraph ：“请用 response （即模型的新输出）来更新 State 对象中 messages 键对应的值。” langgraph 会将这个新消息追加到 messages 列表中，从而保持了对话历史的连续性</p>
</blockquote>
<h5 id="定义摘要节点"><a href="#定义摘要节点" class="headerlink" title="定义摘要节点"></a>定义摘要节点</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def summarize_conversation(state: State): </span><br><span class="line">     </span><br><span class="line">     # 首先，我们获取任何现有的摘要</span><br><span class="line">     summary = state.get(&quot;summary&quot;, &quot;&quot;) </span><br><span class="line"> </span><br><span class="line">     # 创建我们的摘要提示</span><br><span class="line">     if summary: </span><br><span class="line">         </span><br><span class="line">         # 摘要已存在</span><br><span class="line">         summary_message = ( </span><br><span class="line">             f&quot;这是迄今为止对话的摘要：&#123;summary&#125;\n\n&quot; </span><br><span class="line">             &quot;请结合以上新消息扩展摘要：&quot; </span><br><span class="line">         ) </span><br><span class="line">         </span><br><span class="line">     else: </span><br><span class="line">         summary_message = &quot;创建以上对话的摘要：&quot; </span><br><span class="line"> </span><br><span class="line">     # 将提示添加到我们的历史记录中</span><br><span class="line">     messages = state[&quot;messages&quot;] + [HumanMessage(content=summary_message)] </span><br><span class="line">     response = model.invoke(messages) </span><br><span class="line">     </span><br><span class="line">     # 删除除最近2条消息外的所有消息</span><br><span class="line">     delete_messages = [RemoveMessage(id=m.id) for m in state[&quot;messages&quot;][:-2]] </span><br><span class="line">     return &#123;&quot;summary&quot;: response.content, &quot;messages&quot;: delete_messages&#125; </span><br></pre></td></tr></table></figure>
<p>我们将定义一个节点来<strong>生成摘要</strong>。请注意，这里我们将使用 <code>RemoveMessage</code> 在生成摘要后过滤我们的状态。</p>
<h5 id="定义路由函数"><a href="#定义路由函数" class="headerlink" title="定义路由函数"></a>定义路由函数</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import END </span><br><span class="line"> # 决定是结束对话还是总结对话</span><br><span class="line">def should_continue(state: State): </span><br><span class="line">     </span><br><span class="line">     &quot;&quot;&quot;返回要执行的下一个节点。&quot;&quot;&quot; </span><br><span class="line">     </span><br><span class="line">     messages = state[&quot;messages&quot;] </span><br><span class="line">     </span><br><span class="line">     # 如果消息超过六条，那么我们总结对话</span><br><span class="line">     if len(messages) &gt; 6: </span><br><span class="line">         return &quot;summarize_conversation&quot; </span><br><span class="line">     </span><br><span class="line">     # 否则我们就可以结束了</span><br><span class="line">     return END </span><br></pre></td></tr></table></figure>
<p>我们将添加一个条件边，以根据对话长度确定是否生成摘要。</p>
<blockquote>
<p>在 langgraph 中， Command 是一个特殊的类型，用于指导图形（graph）决定接下来应该执行哪个节点。 您可以把它看作是给图形下达的一个“命令”。</p>
</blockquote>
<h5 id="添加内存并编译图"><a href="#添加内存并编译图" class="headerlink" title="添加内存并编译图"></a>添加内存并编译图</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, START</span><br><span class="line"></span><br><span class="line"># Define a new graph</span><br><span class="line">workflow = StateGraph(State)</span><br><span class="line">workflow.add_node(&quot;conversation&quot;, call_model)</span><br><span class="line">workflow.add_node(&quot;summarize_conversation&quot;,summarize_conversation)</span><br><span class="line"></span><br><span class="line"># Set the entrypoint as conversation</span><br><span class="line">workflow.add_edge(START, &quot;conversation&quot;)</span><br><span class="line">workflow.add_conditional_edges(&quot;conversation&quot;, should_continue)</span><br><span class="line">workflow.add_edge(&quot;summarize_conversation&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Compile</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph = workflow.compile(checkpointer=memory)</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<h5 id="使用线程调用"><a href="#使用线程调用" class="headerlink" title="使用线程调用"></a>使用线程调用</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">input_message = HumanMessage(content=&quot;我喜欢玩lol，你知道这个游戏吗&quot;)</span><br><span class="line">output = graph.invoke(&#123;&quot;messages&quot;: [input_message]&#125;, config) </span><br><span class="line">for m in output[&#x27;messages&#x27;][-1:]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>当对话大于6，可生成概要</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.get_state(config).values.get(&quot;summary&quot;,&quot;&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-message-summarization-amp-external-DB-memory具有消息总结和外部数据库记忆的聊天机器人"><a href="#Chatbot-with-message-summarization-amp-external-DB-memory具有消息总结和外部数据库记忆的聊天机器人" class="headerlink" title="Chatbot with message summarization &amp; external DB memory具有消息总结和外部数据库记忆的聊天机器人"></a><strong>Chatbot with message summarization &amp; external DB memory</strong>具有消息总结和外部数据库记忆的聊天机器人</h4><h5 id="使用数据库"><a href="#使用数据库" class="headerlink" title="使用数据库"></a>使用数据库</h5><p><code>SqliteSaver</code> 是 LangGraph 提供的一个 <strong>轻量级状态持久化工具</strong>，它将图的运行状态（即 checkpoint）保存到本地的 SQLite 数据库中，使得你可以在程序中断或重启后<strong>恢复执行上下文</strong>，特别适合本地开发、实验性项目或中小规模应用。</p>
<p>如果我们提供 “:memory:” ，它将创建一个内存中的 SQLite 数据库。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import sqlite3</span><br><span class="line"># In memory</span><br><span class="line">conn = sqlite3.connect(&quot;:memory:&quot;, check_same_thread = False)</span><br></pre></td></tr></table></figure>
<p>如果我们提供一个 db 路径，那么它将为我们创建一个数据库！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#在本地创建一个目录 state_db，并尝试从 GitHub 下载一个名为 example.db 的 SQLite 数据库文件</span><br><span class="line">!mkdir -p state_db &amp;&amp; [ ! -f state_db/example.db ] &amp;&amp; wget -P state_db https://github.com/langchain-ai/langchain-academy/raw/main/module-2/state_db/example.db</span><br><span class="line"></span><br><span class="line">db_path = &quot;state_db/example.db&quot;</span><br><span class="line">conn = sqlite3.connect(db_path, check_same_thread=False)</span><br></pre></td></tr></table></figure>
<p>定义checkpoint</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.checkpoint.sqlite import SqliteSaver</span><br><span class="line">memory = SqliteSaver(conn)</span><br></pre></td></tr></table></figure>
<p>像上一个形式编译图</p>
<p>让我们确认一下我们的状态是否已保存到本地。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">graph_state = graph.get_state(config)</span><br><span class="line">graph_state</span><br></pre></td></tr></table></figure>
<p>使用像 Sqlite 这样的数据库意味着状态会被持久化！</p>
<h3 id="module-3"><a href="#module-3" class="headerlink" title="module-3"></a>module-3</h3><h4 id="Streaming-流式传输"><a href="#Streaming-流式传输" class="headerlink" title="Streaming 流式传输"></a><strong>Streaming</strong> 流式传输</h4><p>现在，让我们来谈谈 <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming">流式传输我们的图状态</a> 的方法。<code>.stream</code> 和 <code>.astream</code> 是用于流式返回结果的同步和异步方法。</p>
<p><code>values</code>：这将在每个节点被调用后流式传输图的完整状态。 <code>updates</code>：这将在每个节点被调用后流式传输图的状态更新。</p>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbaf892d24625a201744e5_streaming1.png" alt="values_vs_updates.png"></p>
<h5 id="stream-mode-”updates”"><a href="#stream-mode-”updates”" class="headerlink" title="stream_mode=”updates”"></a>stream_mode=”updates”</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create a thread</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    print(chunk)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;conversation&#x27;: &#123;&#x27;messages&#x27;: AIMessage(content=&#x27;你好，zxj！很高兴认识你～有什么我可以帮你的吗？😊&#x27;, additional_kwargs=&#123;&#x27;refusal&#x27;: None&#125;, response_metadata=&#123;&#x27;token_usage&#x27;: &#123;&#x27;completion_tokens&#x27;: 16, &#x27;prompt_tokens&#x27;: 576, &#x27;total_tokens&#x27;: 592, &#x27;completion_tokens_details&#x27;: None, &#x27;prompt_tokens_details&#x27;: None&#125;, &#x27;model_name&#x27;: &#x27;qwen-plus-2025-04-28&#x27;, &#x27;system_fingerprint&#x27;: None, &#x27;id&#x27;: &#x27;chatcmpl-891471ae-2fe8-9b3d-b5f7-f4fcd55a4e16&#x27;, &#x27;service_tier&#x27;: None, &#x27;finish_reason&#x27;: &#x27;stop&#x27;, &#x27;logprobs&#x27;: None&#125;, id=&#x27;run--f36409f3-af43-4e9b-8a46-39646ad7c106-0&#x27;, usage_metadata=&#123;&#x27;input_tokens&#x27;: 576, &#x27;output_tokens&#x27;: 16, &#x27;total_tokens&#x27;: 592, &#x27;input_token_details&#x27;: &#123;&#125;, &#x27;output_token_details&#x27;: &#123;&#125;&#125;)&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>让我们来看一下 <code>stream_mode=&quot;updates&quot;</code>。</p>
<p>因为我们使用 <code>updates</code> 进行流式传输，所以只有在图中的节点运行后，我们才能看到状态的更新。每个 <code>chunk</code> 是一个字典，以 <code>node_name</code> 为键，更新后的状态为值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Start conversation</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: [HumanMessage(content=&quot;你好我是zxj&quot;)]&#125;, config, stream_mode=&quot;updates&quot;):</span><br><span class="line">    chunk[&#x27;conversation&#x27;][&quot;messages&quot;].pretty_print()</span><br></pre></td></tr></table></figure>
<p>现在我们直接打印状态更新。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好呀，zxj！再次见到你真高兴～😊 有什么我可以帮忙的吗？</span><br></pre></td></tr></table></figure>
<h5 id="stream-mode-”values”"><a href="#stream-mode-”values”" class="headerlink" title="stream_mode=”values”"></a>stream_mode=”values”</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Start conversation, again</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Start conversation</span><br><span class="line">input_message = HumanMessage(content=&quot;你好我是zxj&quot;)</span><br><span class="line">for event in graph.stream(&#123;&quot;messages&quot;: [input_message]&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    for m in event[&#x27;messages&#x27;]:</span><br><span class="line">        m.pretty_print()</span><br><span class="line">    print(&quot;---&quot;*25)</span><br></pre></td></tr></table></figure>
<p>现在，我们可以看到 <code>stream_mode=&quot;values&quot;</code>.这是在 <code>conversation</code> 节点被调用后，图的整个状态。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好我是zxj</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，zxj！有什么我可以帮你的吗？😊</span><br><span class="line">---------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h5 id="Streaming-tokens-流式传输令牌"><a href="#Streaming-tokens-流式传输令牌" class="headerlink" title="Streaming tokens 流式传输令牌"></a><strong>Streaming tokens</strong> <strong>流式传输令牌</strong></h5><p>在 LangGraph 中，“流式传输令牌（Streaming tokens）”指的是<strong>在节点内部的大模型（LLM）生成过程中，逐 token 地将中间结果实时推送到客户端</strong>的能力。实现这一能力的核心方法是 <code>astream_events</code>，它会以事件流的形式暴露整个执行过程中的所有细节，包括每一次 LLM 调用产生的 token。</p>
<p>每个事件是一个包含几个键的字典：</p>
<p><code>event</code>：这是正在发出的事件的类型。</p>
<p> <code>name</code>：这是事件的名称。</p>
<p><code>data</code>：这是与事件相关联的数据。</p>
<p> <code>metadata</code>：包含 <code>langgraph_node</code>，即发出事件的节点。</p>
<p>要点是，图表中聊天模型的令牌具有 <code>on_chat_model_stream</code> 类型。我们可以使用 <code>event[&#39;metadata&#39;][&#39;langgraph_node&#39;]</code> 来选择要流式的节点。并且我们可以使用 <code>event[&#39;data&#39;]</code> 来获取每个事件的实际数据，而在这种情况下，数据是一个 <code>AIMessageChunk</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node_to_stream = &#x27;conversation&#x27;#定义流式传输的节点</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;5&quot;&#125;&#125;</span><br><span class="line">input_message = HumanMessage(content=&quot;为我介绍lol&quot;)</span><br><span class="line">async for event in graph.astream_events(&#123;&quot;messages&quot;: [input_message]&#125;, config, version=&quot;v2&quot;):</span><br><span class="line">    # 从特定节点获取聊天模型生成的 Token</span><br><span class="line">    #事件类型必须是 逐 token 流式输出（on_chat_model_stream）。</span><br><span class="line">    if event[&quot;event&quot;] == &quot;on_chat_model_stream&quot; and event[&#x27;metadata&#x27;].get(&#x27;langgraph_node&#x27;,&#x27;&#x27;) == node_to_stream:</span><br><span class="line">        data = event[&quot;data&quot;]</span><br><span class="line">        print(data[&quot;chunk&quot;].content, end=&quot;|&quot;)</span><br></pre></td></tr></table></figure>
<p>event的常见类型</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>事件类型 (<code>event</code>)</th>
<th>触发时机与说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>on_chain_start</code></td>
<td>任意 Runnable（节点、子图或整个图）开始执行</td>
</tr>
<tr>
<td><code>on_chain_stream</code></td>
<td>节点/图在运行过程中 <strong>增量输出</strong> chunk</td>
</tr>
<tr>
<td><code>on_chain_end</code></td>
<td>任意 Runnable 执行完成</td>
</tr>
<tr>
<td><code>on_chat_model_start</code></td>
<td><strong>ChatModel</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_chat_model_stream</code></td>
<td><strong>ChatModel</strong> 逐 token 返回内容（打字机效果）</td>
</tr>
<tr>
<td><code>on_chat_model_end</code></td>
<td><strong>ChatModel</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_tool_start</code></td>
<td><strong>Tool</strong> 开始调用</td>
</tr>
<tr>
<td><code>on_tool_end</code></td>
<td><strong>Tool</strong> 调用结束</td>
</tr>
<tr>
<td><code>on_retriever_start</code></td>
<td><strong>Retriever</strong> 开始检索</td>
</tr>
<tr>
<td><code>on_retriever_end</code></td>
<td><strong>Retriever</strong> 检索结束</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Breakpoints-断点"><a href="#Breakpoints-断点" class="headerlink" title="Breakpoints 断点"></a><strong>Breakpoints 断点</strong></h4><p><code>human-in-the-loop</code>（人工介入/人在回路）的三大动机：</p>
<p>1️⃣ Approval（审批）我们可以中断智能体，将当前状态呈现给用户，并让用户决定是否执行该操作。</p>
<p>2️⃣ Debugging（调试/回放）我们可以回退图形以重现或避免问题</p>
<p>3️⃣ Editing（编辑）AI 产出的中间结果不符合预期，但不想重跑整图，可以直接修改状态</p>
<p>我们将介绍 <a href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/#simple-usage">breakpoints</a>，它提供了一种在特定步骤停止图的简单方法。</p>
<h5 id="Breakpoints-for-human-approval用于人类审批的断点"><a href="#Breakpoints-for-human-approval用于人类审批的断点" class="headerlink" title="Breakpoints for human approval用于人类审批的断点"></a><strong>Breakpoints for human approval</strong>用于人类审批的断点</h5><p>假设我们关注工具的使用：我们希望批准代理使用其任何工具。</p>
<p>我们所需要做的就是简单地用 <code>interrupt_before=[&quot;tools&quot;]</code> 编译图形，其中 <code>tools</code> 是我们的工具节点。</p>
<p>这意味着在执行工具调用的节点 <code>tools</code> 之前，执行将被中断。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;tools&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720225640772.png" alt="image-20250720225640772"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: HumanMessage(content=&quot;2乘3&quot;)&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br></pre></td></tr></table></figure>
<p>我们可以获取状态并查看要调用的下一个节点。这是一种很好的方法，可以发现图已被中断。</p>
<p>现在，我们将介绍一个很好的技巧。当我们使用 <code>None</code> 调用图时，它将直接从最后一个状态检查点继续！</p>
<p><img src="https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png" alt="breakpoints.jpg"></p>
<p>状态快照（StateSnapshot）</p>
<ul>
<li>类型：专门用来存 <strong>一个时刻</strong> 的完整状态</li>
<li>获取方式：<ul>
<li><code>Graph.get_state()</code> → <strong>最新的</strong> 快照</li>
<li><code>Graph.get_state_history()</code> → <strong>所有</strong> 快照列表</li>
</ul>
</li>
</ul>
<p>继续/重跑图</p>
<ul>
<li><code>Graph.stream(None, &#123;&quot;thread_id&quot;: &quot;xxx&quot;&#125;)</code><ul>
<li>不传新输入 <code>None</code> 表示 <strong>从当前最新状态继续跑</strong></li>
<li>也可回退到历史快照，再重跑（调试/回放）</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line">Tool Calls:</span><br><span class="line">  multiply (call_92a4bcf88d25476d925775)</span><br><span class="line"> Call ID: call_92a4bcf88d25476d925775</span><br><span class="line">  Args:</span><br><span class="line">    a: 2</span><br><span class="line">    b: 3</span><br><span class="line">=================================[1m Tool Message [0m=================================</span><br><span class="line">Name: multiply</span><br><span class="line"></span><br><span class="line">6</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">2乘3的结果是6。</span><br></pre></td></tr></table></figure>
<h4 id="Editing-graph-state-编辑图状态"><a href="#Editing-graph-state-编辑图状态" class="headerlink" title="Editing graph state 编辑图状态"></a><strong>Editing graph state </strong>编辑图状态</h4><p>断点也是<a href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/">修改图状态的机会</a>让我们在 <code>assistant</code> 节点之前为代理设置断点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph = builder.compile(interrupt_before=[&quot;assistant&quot;], checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250720230924672.png" alt="image-20250720230924672"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Input</span><br><span class="line">initial_input = &#123;&quot;messages&quot;: &quot;2乘3&quot;&#125;</span><br><span class="line"></span><br><span class="line"># Thread</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br></pre></td></tr></table></figure>
<p>当状态中断时，我们可以直接应用状态更新</p>
<p>记住，对 <code>messages</code> 键的更新将使用 <code>add_messages</code> reducer：</p>
<p><strong>如果我们想覆盖现有的消息，可以提供带有<em> </em><code>id</code><em> </em>的消息。</strong> 如果我们只想将消息添加到消息列表中，则可以传递未指定 <code>id</code> 的消息，如下所示。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&quot;不要，实际上要3乘3!&quot;)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">new_state = graph.get_state(thread).values</span><br><span class="line">for m in new_state[&#x27;messages&#x27;]:</span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">2乘3</span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">不要，实际上要3乘3!</span><br></pre></td></tr></table></figure>
<p>现在，让我们继续进行我们的代理操作，只需传递 <code>None</code> 并允许其从当前状态继续执行。我们输出当前内容，然后继续执行剩余的节点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="Dynamic-breakpoints-动态断点"><a href="#Dynamic-breakpoints-动态断点" class="headerlink" title="Dynamic breakpoints 动态断点"></a><strong>Dynamic breakpoints </strong>动态断点</h4><p>你可以根据条件来实现它（从节点内部基于开发人员定义的逻辑）。您可以向用户说明其中断原因（通过将您想传递的内容发送到 <code>NodeInterrupt</code>）。</p>
<p>让我们创建一个图表，其中根据输入的长度会抛出一个 <code>NodeInterrupt</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.errors import NodeInterrupt</span><br><span class="line">from langgraph.graph import START, END, StateGraph</span><br><span class="line"></span><br><span class="line">class State(TypedDict):</span><br><span class="line">    input: str</span><br><span class="line"></span><br><span class="line">def step_1(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 1---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_2(state: State) -&gt; State:</span><br><span class="line">    # 如果输入字符串长度超过5个字符，我们可以选择抛出NodeInterrupt异常</span><br><span class="line">    if len(state[&#x27;input&#x27;]) &gt; 5:</span><br><span class="line">        raise NodeInterrupt(f&quot;收到长度超过5个字符的输入: &#123;state[&#x27;input&#x27;]&#125;&quot;)</span><br><span class="line">    </span><br><span class="line">    print(&quot;---Step 2---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">def step_3(state: State) -&gt; State:</span><br><span class="line">    print(&quot;---Step 3---&quot;)</span><br><span class="line">    return state</span><br><span class="line"></span><br><span class="line">builder = StateGraph(State)</span><br><span class="line">builder.add_node(&quot;step_1&quot;, step_1)</span><br><span class="line">builder.add_node(&quot;step_2&quot;, step_2)</span><br><span class="line">builder.add_node(&quot;step_3&quot;, step_3)</span><br><span class="line">builder.add_edge(START, &quot;step_1&quot;)</span><br><span class="line">builder.add_edge(&quot;step_1&quot;, &quot;step_2&quot;)</span><br><span class="line">builder.add_edge(&quot;step_2&quot;, &quot;step_3&quot;)</span><br><span class="line">builder.add_edge(&quot;step_3&quot;, END)</span><br><span class="line"></span><br><span class="line"># Set up memory</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># Compile the graph with memory</span><br><span class="line">graph = builder.compile(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"># View</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/image-20250721222709712.png" alt="image-20250721222709712"></p>
<p>让我们运行一个输入超过5个字符的图。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">initial_input = &#123;&quot;input&quot;: &quot;hello world&quot;&#125;</span><br><span class="line">thread_config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># Run the graph until the first interruption</span><br><span class="line">for event in graph.stream(initial_input, thread_config, stream_mode=&quot;values&quot;):</span><br><span class="line">    print(event)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br><span class="line">---Step 1---</span><br><span class="line">&#123;&#x27;input&#x27;: &#x27;hello world&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以尝试从断点恢复图。但是，这只会重新运行相同的节点！除非状态发生变化，否则我们将一直卡在这里。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.update_state(</span><br><span class="line">    thread_config,</span><br><span class="line">    &#123;&quot;input&quot;: &quot;hi&quot;&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>使用update_state更新状态</p>
<h4 id="Time-travel-时间旅行"><a href="#Time-travel-时间旅行" class="headerlink" title="Time travel 时间旅行"></a><strong>Time travel</strong> 时间旅行</h4><p>现在，让我们通过查看、重播，甚至从过去的状态叉出，来展示 LangGraph <a href="https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/">支持debug</a> 的功能。</p>
<h5 id="Browsing-History-浏览历史"><a href="#Browsing-History-浏览历史" class="headerlink" title="Browsing History 浏览历史"></a><strong>Browsing History</strong> <strong>浏览历史</strong></h5><p>我们可以使用 <code>get_state</code> 来查看给定 <code>thread_id</code> 的图的 当前 状态！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.get_state(&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;&#125;&#125;)</span><br></pre></td></tr></table></figure>
<p>我们还可以浏览代理的状态历史。<code>get_state_history</code> 让我们能够获取所有先前步骤的状态。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">all_states = [s for s in graph.get_state_history(thread)]</span><br><span class="line">len(all_states)</span><br><span class="line">print(all_states)</span><br></pre></td></tr></table></figure>
<h5 id="Replaying-回放"><a href="#Replaying-回放" class="headerlink" title="Replaying 回放"></a><strong>Replaying</strong> <strong>回放</strong></h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">to_replay = all_states[-2]</span><br><span class="line">to_replay.values</span><br><span class="line">&#123;&#x27;messages&#x27;: [HumanMessage(content=&#x27;2乘3&#x27;, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, id=&#x27;0676d9b5-cd59-4630-924d-b5c8d950e8d8&#x27;)]&#125;</span><br><span class="line">to_replay.next</span><br><span class="line">(&#x27;assistant&#x27;,)</span><br></pre></td></tr></table></figure>
<p>我们还获取了配置，它告诉了我们 <code>checkpoint_id</code> 以及 <code>thread_id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">to_replay.config</span><br><span class="line">&#123;&#x27;configurable&#x27;: &#123;&#x27;thread_id&#x27;: &#x27;1&#x27;,</span><br><span class="line">  &#x27;checkpoint_ns&#x27;: &#x27;&#x27;,</span><br><span class="line">  &#x27;checkpoint_id&#x27;: &#x27;1f066c0e-2ee2-66d5-8000-5dde78194aae&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>要从这里重播，我们只需将配置传回给代理！图知道这个检查点已经执行过了。它只是从这个检查点重新播放！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for event in graph.stream(None, to_replay.config, stream_mode=&quot;values&quot;):</span><br><span class="line">    event[&#x27;messages&#x27;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h5 id="Forking-分叉"><a href="#Forking-分叉" class="headerlink" title="Forking 分叉"></a><strong>Forking</strong> 分叉</h5><p>如果我们想从相同的步骤运行，但使用不同的输入，该怎么办呢？这是分叉。</p>
<p><img src="/2025/07/18/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent/66dbb038f89f2d847ee5c336_time-travel3.png" alt="fig3.jpg"></p>
<p>让我们修改此检查点的状态。我们可以直接使用提供的 <code>checkpoint_id</code> 来运行 <code>update_state</code>。</p>
<p>请记住我们对 <code>messages</code> 的 reducer 是如何工作的：</p>
<ul>
<li>它会追加消息，除非我们提供了一个消息 ID。</li>
<li>我们提供消息 ID 是为了覆盖消息，而不是将消息追加到状态中！</li>
</ul>
<p>因此，要覆盖消息，我们只需提供消息 ID，而我们已有 <code>to_fork.values[&quot;messages&quot;].id</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fork_config = graph.update_state(</span><br><span class="line">    to_fork.config,</span><br><span class="line">    &#123;&quot;messages&quot;: [HumanMessage(content=&#x27;5乘3&#x27;, </span><br><span class="line">                               id=to_fork.values[&quot;messages&quot;][0].id)]&#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><h4 id="message"><a href="#message" class="headerlink" title="message"></a>message</h4><p>LangChain 中的 HumanMessage 、 AIMessage 、 SystemMessage 和 ToolMessage 。这些消息类型是构建与语言模型（LLM）交互的核心组件，它们共同构成了一个完整的对话历史，帮助模型理解上下文并做出恰当的回应。</p>
<ol>
<li>SystemMessage</li>
</ol>
<p>SystemMessage 的结构最简单，它只包含内容和类型。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 消息的具体内容，即给 AI 的指令。</li>
<li>type (str): 固定为字符串 ‘system’ 。</li>
</ul>
<ol>
<li>HumanMessage</li>
</ol>
<p>HumanMessage 的结构也同样简单，代表用户的输入。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 用户输入的文本。</li>
<li>type (str): 固定为字符串 ‘human’ 。</li>
</ul>
<ol>
<li>AIMessage</li>
</ol>
<p>AIMessage 的结构相对复杂，因为它不仅可以包含文本响应，还可以包含对工具的调用请求。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): AI 生成的文本响应。如果 AI 的回复是发起工具调用，此字段可以为空字符串。</li>
<li>tool_calls (list[dict], 可选): 一个字典列表，每个字典代表一个工具调用请求。这是支持“Function Calling”或“Tool Calling”功能的核心。其结构通常包含：<ul>
<li>name (str): 要调用的工具名称。</li>
<li>args (dict): 调用工具时需要传入的参数。</li>
<li>id (str): 此次工具调用的唯一标识符，用于后续 ToolMessage 的关联。</li>
</ul>
</li>
<li>type (str): 固定为字符串 ‘ai’ 。</li>
</ul>
<ol>
<li>ToolMessage</li>
</ol>
<p>ToolMessage 用于承载工具执行后的返回结果。</p>
<p>数据结构 :</p>
<ul>
<li>content (str): 工具执行返回的结果。通常是一个字符串，比如 JSON 格式的字符串。</li>
<li>tool_call_id (str): 此次工具调用的唯一标识符， 必须 与之前 AIMessage 中 tool_calls 里的 id 相对应。这使得模型能够准确地将结果与请求匹配起来。</li>
<li>type (str): 固定为字符串 ‘tool’ 。</li>
</ul>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>LangGraph学习——agent——下</title>
    <url>/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本教程为langchain官方教程的学习记录</p>
<p><a href="https://academy.langchain.com/enrollments">academy.langchain.com/enrollments</a></p>
<p>代码见<a href="https://github.com/zxj-2023/learn-rag-langchain"><a href="https://github.com/zxj-2023/learn-rag-langchain/tree/main/academy-langgraph">learn-rag-langchain/academy-langgraph at main · zxj-2023/learn-rag-langchain</a></a></p>
<h3 id="module-4"><a href="#module-4" class="headerlink" title="module-4"></a>module-4</h3><h4 id="Parallel-node-execution-并行节点执行"><a href="#Parallel-node-execution-并行节点执行" class="headerlink" title="Parallel node execution 并行节点执行"></a><strong>Parallel node execution</strong> <strong>并行节点执行</strong></h4><h5 id="Waiting-for-nodes-to-finish-等待节点完成"><a href="#Waiting-for-nodes-to-finish-等待节点完成" class="headerlink" title="Waiting for nodes to finish 等待节点完成"></a><strong>Waiting for nodes to finish</strong> <strong>等待节点完成</strong></h5><p>现在，让我们考虑一个案例，其中一个并行路径的步骤比另一个多。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># Initialize each node with node_secret </span><br><span class="line">builder.add_node(&quot;a&quot;, ReturnNodeValue(&quot;I&#x27;m A&quot;))</span><br><span class="line">builder.add_node(&quot;b&quot;, ReturnNodeValue(&quot;I&#x27;m B&quot;))</span><br><span class="line">builder.add_node(&quot;b2&quot;, ReturnNodeValue(&quot;I&#x27;m B2&quot;))</span><br><span class="line">builder.add_node(&quot;c&quot;, ReturnNodeValue(&quot;I&#x27;m C&quot;))</span><br><span class="line">builder.add_node(&quot;d&quot;, ReturnNodeValue(&quot;I&#x27;m D&quot;))</span><br><span class="line"></span><br><span class="line"># Flow</span><br><span class="line">builder.add_edge(START, &quot;a&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;b&quot;)</span><br><span class="line">builder.add_edge(&quot;a&quot;, &quot;c&quot;)</span><br><span class="line">builder.add_edge(&quot;b&quot;, &quot;b2&quot;)</span><br><span class="line">builder.add_edge([&quot;b2&quot;, &quot;c&quot;], &quot;d&quot;)</span><br><span class="line">builder.add_edge(&quot;d&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722143802652.png" alt="image-20250722143802652"></p>
<p>在这种情况下，<code>b</code>、<code>b2</code> 和 <code>c</code> 都是同一个步骤的一部分。图形将在进入 <code>d</code> 步骤之前等待所有这些操作完成。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Adding I&#x27;m A to []</span><br><span class="line">Adding I&#x27;m B to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m C to [&quot;I&#x27;m A&quot;]</span><br><span class="line">Adding I&#x27;m B2 to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;]</span><br><span class="line">Adding I&#x27;m D to [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;]</span><br><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Setting-the-order-of-state-updates-设置状态更新的顺序"><a href="#Setting-the-order-of-state-updates-设置状态更新的顺序" class="headerlink" title="Setting the order of state updates 设置状态更新的顺序"></a><strong>Setting the order of state updates</strong> <strong>设置状态更新的顺序</strong></h5><p>然而，在每个步骤中，我们无法对状态更新的顺序进行具体控制！简单来说，它是基于图拓扑结构由 LangGraph 确定的确定性顺序，该顺序为 <strong><em>\</em>我们无法控制**</strong>。</p>
<p>上面，我们看到 <code>c</code> 被添加在 <code>b2</code> 之前</p>
<p>然而，我们可以使用自定义 reducer 来定制此功能，例如，对状态更新进行排序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def sorting_reducer(left, right):</span><br><span class="line">    &quot;&quot;&quot; 合并并排序列表中的值&quot;&quot;&quot;</span><br><span class="line">    # 如果 left 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(left, list):</span><br><span class="line">        left = [left]</span><br><span class="line"></span><br><span class="line">    # 如果 right 不是列表，则将其转换为列表</span><br><span class="line">    if not isinstance(right, list):</span><br><span class="line">        right = [right]</span><br><span class="line">    </span><br><span class="line">    # 合并 left 和 right 列表，然后升序排序</span><br><span class="line">    return sorted(left + right, reverse=False)</span><br><span class="line">class State(TypedDict):</span><br><span class="line">    # sorting_reducer 函数将对 state 中的值进行排序</span><br><span class="line">    state: Annotated[list, sorting_reducer]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph.invoke(&#123;&quot;state&quot;: []&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;state&#x27;: [&quot;I&#x27;m A&quot;, &quot;I&#x27;m B&quot;, &quot;I&#x27;m B2&quot;, &quot;I&#x27;m C&quot;, &quot;I&#x27;m D&quot;]&#125;</span><br></pre></td></tr></table></figure>
<p>现在，reducer 对更新的状态值进行排序！<code>sorting_reducer</code> 示例对所有值进行全局排序。我们还可以：</p>
<ol>
<li>在并行步骤期间将输出写入状态中的单独字段  </li>
<li>在并行步骤之后使用“汇”节点来合并和排序这些输出  </li>
<li>合并后清除临时字段</li>
</ol>
<p>请参阅 <a href="https://langchain-ai.github.io/langgraph/how-tos/branching/#stable-sorting">docs</a> 以获取更多详细信息。</p>
<h5 id="Working-with-LLMs-使用-LLMs"><a href="#Working-with-LLMs-使用-LLMs" class="headerlink" title="Working with LLMs  使用 LLMs"></a><strong>Working with LLMs</strong>  <strong>使用 LLMs</strong></h5><p>现在，让我们添加一个现实中的例子！我们希望从两个外部来源（Wikipedia 和 Web-Search）收集上下文信息，并让 LLM 回答一个问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br><span class="line">from langchain_community.tools import TavilySearchResults</span><br><span class="line"></span><br><span class="line">def search_web(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">    search_docs = tavily_search.invoke(state[&#x27;question&#x27;])</span><br><span class="line"></span><br><span class="line">     # 将多个搜索文档转换成了一个统一格式的长文本，每个文档都有自己的元数据（如URL），并且文档之间有明确的分隔，便于后续处理或展示。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    - 这是一个 列表推导式 (list comprehension) ，它会遍历 search_docs 列表中的每一个元素（这里我们称之为 doc ）。</span><br><span class="line">    - search_docs 里的每个 doc 应该是一个包含 &#x27;url&#x27; 和 &#x27;content&#x27; 键的字典。</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = WikipediaLoader(query=state[&#x27;question&#x27;], </span><br><span class="line">                                  load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def generate_answer(state):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 用于回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    question = state[&quot;question&quot;]</span><br><span class="line"></span><br><span class="line">    # 模板</span><br><span class="line">    answer_template = &quot;&quot;&quot;使用以下上下文回答问题 &#123;question&#125;: &#123;context&#125;&quot;&quot;&quot;</span><br><span class="line">    answer_instructions = answer_template.format(question=question, </span><br><span class="line">                                                       context=context)    </span><br><span class="line">    </span><br><span class="line">    # 回答</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=answer_instructions)]+[HumanMessage(content=f&quot;回答问题。&quot;)])</span><br><span class="line">      </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;answer&quot;: answer&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点</span><br><span class="line">builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"># 初始化每个节点</span><br><span class="line">builder.add_node(&quot;search_web&quot;,search_web)</span><br><span class="line">builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">builder.add_node(&quot;generate_answer&quot;, generate_answer)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">builder.add_edge(START, &quot;search_wikipedia&quot;)</span><br><span class="line">builder.add_edge(START, &quot;search_web&quot;)</span><br><span class="line">builder.add_edge(&quot;search_wikipedia&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;search_web&quot;, &quot;generate_answer&quot;)</span><br><span class="line">builder.add_edge(&quot;generate_answer&quot;, END)</span><br><span class="line">graph = builder.compile()</span><br><span class="line"></span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250722153534867.png" alt="image-20250722153534867"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">result = graph.invoke(&#123;&quot;question&quot;: &quot;英伟达2025年第一季度财报表现如何&quot;&#125;)</span><br><span class="line">result[&#x27;answer&#x27;].content</span><br></pre></td></tr></table></figure>
<h4 id="Sub-graphs-子图"><a href="#Sub-graphs-子图" class="headerlink" title="Sub-graphs 子图"></a><strong>Sub-graphs</strong> 子图</h4><p>子图允许你在图表的不同部分创建和管理不同的状态。这在多智能体系统中尤其有用，尤其是在每个智能体都有各自状态的智能体团队中。</p>
<p>让我们考虑一个简单的例子：</p>
<ul>
<li>我有一个系统，它接收日志。</li>
<li>该系统通过不同的代理执行两个独立的子任务（总结日志，查找故障模式）。</li>
<li>我希望在两个不同的子图中执行这两个操作。</li>
</ul>
<p>最重要的是要理解图表是如何传达信息的！</p>
<p>简而言之，通信是 <strong><em>\</em>通过重叠密钥**</strong> 实现的：</p>
<ul>
<li>子图可以访问父图中的 <code>docs</code>（文档）。</li>
<li>父图可以从子图中访问 <code>summary</code>（摘要）和 <code>failure_report</code>（故障报告）。</li>
</ul>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/66dbb1abf89f2d847ee6f1ff_sub-graph1.png" alt="subgraph.png"></p>
<ol>
<li><strong>Logs (Traces)</strong>:<ul>
<li>这是系统的输入，表示一系列的日志记录。</li>
</ul>
</li>
<li><strong>Entry Graph</strong>:<ul>
<li>这是系统的入口图，它包含了总体状态（Overall State），其中包含：<ul>
<li><code>docs</code>：文档或日志数据。</li>
<li><code>summary report</code>：摘要报告，这是系统执行摘要任务后生成的。</li>
<li><code>failure report</code>：故障报告，这是系统执行故障分析任务后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Call sub-graphs</strong>:<ul>
<li>这是从入口图调用两个子图的过程，分别用于执行摘要和故障分析任务。</li>
</ul>
</li>
<li><strong>Summarization</strong>:<ul>
<li>这个子图负责生成日志的摘要。它的状态（Summary State）包含：<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>summary</code>：摘要内容。</li>
<li><code>summary report</code>：摘要报告，这是摘要任务完成后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Failure Analysis</strong>:<ul>
<li>这个子图负责分析日志中的故障模式。它的状态（Failure Analysis State）包含：<ul>
<li><code>docs</code>：与入口图共享的文档数据。</li>
<li><code>failures</code>：故障模式。</li>
<li><code>failure report</code>：故障报告，这是故障分析任务完成后生成的。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Finish</strong>:<ul>
<li>这是流程的结束点，表示两个子图的任务都已完成，并且生成了摘要报告和故障报告。</li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from operator import add</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from typing import List, Optional, Annotated</span><br><span class="line"></span><br><span class="line">#logs结构</span><br><span class="line">class Log(TypedDict):</span><br><span class="line">    id: str</span><br><span class="line">    question: str</span><br><span class="line">    docs: Optional[List]</span><br><span class="line">    answer: str</span><br><span class="line">    grade: Optional[int]</span><br><span class="line">    grader: Optional[str]</span><br><span class="line">    feedback: Optional[str]</span><br></pre></td></tr></table></figure>
<h5 id="Sub-graphs"><a href="#Sub-graphs" class="headerlink" title="Sub graphs"></a><strong>Sub graphs</strong></h5><p>这里是失败分析子图，它使用了 <code>FailureAnalysisState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import StateGraph, START, END</span><br><span class="line"></span><br><span class="line"># 故障分析子图</span><br><span class="line">class FailureAnalysisState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于故障分析的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    failures: List[Log]     # 包含故障的日志列表</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class FailureAnalysisOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;故障分析的输出状态。&quot;&quot;&quot;</span><br><span class="line">    fa_summary: str         # 故障分析摘要</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def get_failures(state):</span><br><span class="line">    &quot;&quot;&quot;获取包含故障的日志&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 从清理后的日志中筛选出包含 &quot;grade&quot; 键的日志，这些被视为故障</span><br><span class="line">    failures = [log for log in cleaned_logs if &quot;grade&quot; in log]</span><br><span class="line">    return &#123;&quot;failures&quot;: failures&#125;</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;生成故障摘要&quot;&quot;&quot;</span><br><span class="line">    failures = state[&quot;failures&quot;]</span><br><span class="line">    # 添加功能：fa_summary = summary_generation(qs_summary)</span><br><span class="line">    fa_summary = &quot;Chroma 文档的检索质量不佳。&quot;</span><br><span class="line">    # 为每个故障日志生成一个处理过的日志标识符</span><br><span class="line">    return &#123;&quot;fa_summary&quot;: fa_summary, &quot;processed_logs&quot;: [f&quot;failure-analysis-on-log-&#123;failure[&#x27;id&#x27;]&#125;&quot; for failure in failures]&#125;</span><br><span class="line"></span><br><span class="line">fa_builder = StateGraph(state_schema=FailureAnalysisState,output_schema=FailureAnalysisOutputState)</span><br><span class="line">fa_builder.add_node(&quot;get_failures&quot;, get_failures)</span><br><span class="line">fa_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">fa_builder.add_edge(START, &quot;get_failures&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;get_failures&quot;, &quot;generate_summary&quot;)</span><br><span class="line">fa_builder.add_edge(&quot;generate_summary&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = fa_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723094949158.png" alt="image-20250723094949158"></p>
<p>这里是问题总结子图，它使用了 <code>QuestionSummarizationState</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 摘要生成子图</span><br><span class="line">class QuestionSummarizationState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;用于问题摘要的状态。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs: List[Log] # 清理后的日志列表</span><br><span class="line">    qs_summary: str         # 问题摘要</span><br><span class="line">    report: str             # 从摘要生成的报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">class QuestionSummarizationOutputState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;问题摘要的输出状态。&quot;&quot;&quot;</span><br><span class="line">    report: str             # 最终报告</span><br><span class="line">    processed_logs: List[str] # 已处理的日志标识符列表</span><br><span class="line"></span><br><span class="line">def generate_summary(state):</span><br><span class="line">    &quot;&quot;&quot;从日志生成摘要。&quot;&quot;&quot;</span><br><span class="line">    cleaned_logs = state[&quot;cleaned_logs&quot;]</span><br><span class="line">    # 添加功能：summary = summarize(generate_summary)</span><br><span class="line">    summary = &quot;问题集中在 ChatOllama 和 Chroma 向量存储的使用上。&quot;</span><br><span class="line">    # 返回摘要以及已处理的日志ID</span><br><span class="line">    return &#123;&quot;qs_summary&quot;: summary, &quot;processed_logs&quot;: [f&quot;summary-on-log-&#123;log[&#x27;id&#x27;]&#125;&quot; for log in cleaned_logs]&#125;</span><br><span class="line"></span><br><span class="line">def send_to_slack(state):</span><br><span class="line">    &quot;&quot;&quot;模拟发送报告。&quot;&quot;&quot;</span><br><span class="line">    qs_summary = state[&quot;qs_summary&quot;]</span><br><span class="line">    # 添加功能：report = report_generation(qs_summary)</span><br><span class="line">    report = &quot;foo bar baz&quot;</span><br><span class="line">    return &#123;&quot;report&quot;: report&#125;</span><br><span class="line"></span><br><span class="line">qs_builder = StateGraph(QuestionSummarizationState,output_schema=QuestionSummarizationOutputState)</span><br><span class="line">qs_builder.add_node(&quot;generate_summary&quot;, generate_summary)</span><br><span class="line">qs_builder.add_node(&quot;send_to_slack&quot;, send_to_slack)</span><br><span class="line">qs_builder.add_edge(START, &quot;generate_summary&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;generate_summary&quot;, &quot;send_to_slack&quot;)</span><br><span class="line">qs_builder.add_edge(&quot;send_to_slack&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = qs_builder.compile()</span><br><span class="line">display(Image(graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723100648199.png" alt="image-20250723100648199"></p>
<h5 id="Adding-sub-graphs-to-our-parent-graph-向父图添加子图"><a href="#Adding-sub-graphs-to-our-parent-graph-向父图添加子图" class="headerlink" title="Adding sub graphs to our parent graph  向父图添加子图"></a><strong>Adding sub graphs to our parent graph </strong> <strong>向父图添加子图</strong></h5><p>现在，我们可以将所有内容整合在一起。我们使用 <code>EntryGraphState</code> 创建父图。并且我们将我们的子图添加为节点！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 入口图</span><br><span class="line">class EntryGraphState(TypedDict):</span><br><span class="line">    # 原始日志数据列表</span><br><span class="line">    raw_logs: List[Log]</span><br><span class="line">    # 经过清洗处理后的日志数据列表</span><br><span class="line">    cleaned_logs: List[Log]</span><br><span class="line">    fa_summary: str # 这只会在故障分析子图中生成</span><br><span class="line">    report: str # 这只会在问题摘要子图中生成</span><br><span class="line">    processed_logs:  Annotated[List[int], add] # 跟踪哪些日志已经被处理过 ，尤其是在子图之间共享状态时。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def clean_logs(state):</span><br><span class="line">    # 获取日志</span><br><span class="line">    raw_logs = state[&quot;raw_logs&quot;]</span><br><span class="line">    # 数据清洗 raw_logs -&gt; docs</span><br><span class="line">    cleaned_logs = raw_logs</span><br><span class="line">    return &#123;&quot;cleaned_logs&quot;: cleaned_logs&#125;</span><br><span class="line"></span><br><span class="line">entry_builder = StateGraph(EntryGraphState)</span><br><span class="line">entry_builder.add_node(&quot;clean_logs&quot;, clean_logs)</span><br><span class="line">#添加子图</span><br><span class="line">entry_builder.add_node(&quot;question_summarization&quot;, qs_builder.compile())</span><br><span class="line">entry_builder.add_node(&quot;failure_analysis&quot;, fa_builder.compile())</span><br><span class="line"></span><br><span class="line">entry_builder.add_edge(START, &quot;clean_logs&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;failure_analysis&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;clean_logs&quot;, &quot;question_summarization&quot;)</span><br><span class="line">entry_builder.add_edge(&quot;failure_analysis&quot;, END)</span><br><span class="line">entry_builder.add_edge(&quot;question_summarization&quot;, END)</span><br><span class="line"></span><br><span class="line">graph = entry_builder.compile()</span><br><span class="line"></span><br><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line"># 将 xray 设置为 1 将显示嵌套图的内部结构</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723102913524.png" alt="image-20250723102913524"></p>
<h4 id="Map-reduce"><a href="#Map-reduce" class="headerlink" title="Map-reduce"></a><strong>Map-reduce</strong></h4><p>LangGraph 里的 <strong>Map-Reduce</strong> 是一种<strong>并行处理模式</strong>，用于将一个大任务拆分成多个子任务（Map），再汇总结果（Reduce）。这是 LangGraph 中处理<strong>批量数据或并行节点执行</strong>的核心机制之一。</p>
<p>让我们设计一个系统，该系统将完成两件事情：</p>
<p>(1) <strong>映射（Map）</strong> —— 根据主题生成一组笑话。<br>(2) <strong>归约（Reduce）</strong> —— 从这组笑话中挑出最棒的一条。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"># Prompts we will use</span><br><span class="line">subjects_prompt = &quot;&quot;&quot;生成一个包含3个子主题的列表，这些子主题都与以下总体主题相关：&#123;topic&#125;。&quot;&quot;&quot;</span><br><span class="line">joke_prompt = &quot;&quot;&quot;生成一个关于&#123;subject&#125;的笑话&quot;&quot;&quot;</span><br><span class="line">best_joke_prompt = &quot;&quot;&quot;下面是关于&#123;topic&#125;的一堆笑话。选择最好的一个！返回最好笑话的ID，第一个笑话的ID从0开始。笑话：\n\n  &#123;jokes&#125;&quot;&quot;&quot;</span><br><span class="line"># LLM</span><br><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=&quot;qwen-plus-2025-04-28&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h5 id="Parallelizing-joke-generation-并行化笑话生成"><a href="#Parallelizing-joke-generation-并行化笑话生成" class="headerlink" title="Parallelizing joke generation 并行化笑话生成"></a><strong>Parallelizing joke generation</strong> <strong>并行化笑话生成</strong></h5><p>首先，让我们定义图的入口点，它将：</p>
<ul>
<li>接收用户输入的主题  </li>
<li>基于该主题生成若干“笑话子主题”  </li>
<li>将每个子主题发送到上面定义的笑话生成节点</li>
</ul>
<p>我们的状态有一个 <code>jokes</code> 键，它将累积来自并行化笑话生成的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Subjects(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示主题列表。&quot;&quot;&quot;</span><br><span class="line">    subjects: list[str] # 主题字符串列表</span><br><span class="line"></span><br><span class="line">class BestJoke(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;定义一个Pydantic模型，用于表示最佳笑话的ID。&quot;&quot;&quot;</span><br><span class="line">    id: int # 最佳笑话的索引ID</span><br><span class="line">    </span><br><span class="line">class OverallState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;定义整个图的总体状态，使用TypedDict以便于类型提示和状态管理。&quot;&quot;&quot;</span><br><span class="line">    topic: str # 当前讨论的主题</span><br><span class="line">    subjects: list # 生成的子主题列表</span><br><span class="line">    jokes: Annotated[list, operator.add] # 笑话列表，使用operator.add表示列表内容会累加而不是覆盖</span><br><span class="line">    best_selected_joke: str # 最终选出的最佳笑话</span><br></pre></td></tr></table></figure>
<p>生成笑话的主题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#用于生成主题</span><br><span class="line">def generate_topics(state: OverallState):</span><br><span class="line">    #使用 Python 的 format() 方法来构建一个提示字符串（ prompt ）</span><br><span class="line">    prompt = subjects_prompt.format(topic=state[&quot;topic&quot;])</span><br><span class="line">    #.with_structured_output(Subjects) 它指示模型尝试将其输出格式化为 Subjects 类</span><br><span class="line">    response = model.with_structured_output(Subjects).invoke(prompt)</span><br><span class="line">    return &#123;&quot;subjects&quot;: response.subjects&#125;</span><br></pre></td></tr></table></figure>
<p>这就是妙处：我们利用 <a href="https://langchain-ai.github.io/langgraph/concepts/low_level/#send"><code>Send</code></a> 为每个主题并行生成笑话。</p>
<p>非常实用！无论主题数量多少，它都能自动并行处理。</p>
<ul>
<li><code>generate_joke</code>：图中节点的名字  </li>
<li><code>&#123;&quot;subject&quot;: s&#125;</code>：要传递的状态</li>
</ul>
<p><code>Send</code> 允许你向 <code>generate_joke</code> 节点发送<strong>任意</strong>结构的状态，无需与 <code>OverallState</code> 对齐。<br>在这里，<code>generate_joke</code> 使用自己的内部状态，我们通过 <code>Send</code> 按需填充即可。</p>
<blockquote>
<p>在 LangGraph 里，<code>Send</code> 是一个<strong>“动态派发器”</strong>：它让你<strong>在运行时</strong>决定“要把哪个节点运行多少次、每次给它什么数据”，并自动并行执行。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.types import Send</span><br><span class="line">def continue_to_jokes(state: OverallState):</span><br><span class="line">    # 该函数根据当前状态中的主题列表，为每个主题生成一个 Send 对象。</span><br><span class="line">    # 每个 Send 对象都指示图将数据发送到名为 &quot;generate_joke&quot; 的节点，</span><br><span class="line">    # 并将当前主题作为 &quot;subject&quot; 参数传递，从而实现并行生成笑话。</span><br><span class="line">    return [Send(&quot;generate_joke&quot;, &#123;&quot;subject&quot;: s&#125;) for s in state[&quot;subjects&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="Joke-generation-map-笑话生成"><a href="#Joke-generation-map-笑话生成" class="headerlink" title="Joke generation (map) 笑话生成"></a><strong>Joke generation (map)</strong> <strong>笑话生成</strong></h5><p>现在，我们只需定义一个节点来生成笑话，命名为 <code>generate_joke</code>！</p>
<p>生成的笑话会被写回到 <code>OverallState</code> 中的 <code>jokes</code> 字段。<br>该字段配有 reducer，能够自动把多次写入的列表合并成一个大列表。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 定义 JokeState，用于表示生成笑话任务的输入状态。</span><br><span class="line">class JokeState(TypedDict):</span><br><span class="line">    subject: str#笑话的主题</span><br><span class="line"></span><br><span class="line"># 定义 Joke 模型，用于表示模型生成的笑话的结构。</span><br><span class="line">class Joke(BaseModel):</span><br><span class="line">    joke: str#笑话的文本内容</span><br><span class="line"></span><br><span class="line"># 定义生成笑话的函数。</span><br><span class="line">def generate_joke(state: JokeState):</span><br><span class="line">    # 根据 joke_prompt 模板和当前状态中的主题格式化提示。</span><br><span class="line">    prompt = joke_prompt.format(subject=state[&quot;subject&quot;])</span><br><span class="line">    # 调用语言模型，并指定输出应结构化为 Joke 类型。</span><br><span class="line">    response = model.with_structured_output(Joke).invoke(prompt)</span><br><span class="line">    # 返回一个包含生成的笑话的字典，键为 &quot;jokes&quot;。</span><br><span class="line">    return &#123;&quot;jokes&quot;: [response.joke]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Best-joke-selection-reduce-最佳笑话选择"><a href="#Best-joke-selection-reduce-最佳笑话选择" class="headerlink" title="Best joke selection (reduce) 最佳笑话选择"></a><strong>Best joke selection (reduce)</strong> <strong>最佳笑话选择</strong></h5><p>现在，我们添加逻辑来挑选最好的笑话。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def best_joke(state: OverallState):</span><br><span class="line">    # 将状态中所有笑话列表连接成一个字符串，每个笑话之间用两个换行符分隔</span><br><span class="line">    jokes = &quot;\n\n&quot;.join(state[&quot;jokes&quot;])</span><br><span class="line">    # 使用主题和所有笑话格式化最佳笑话提示语</span><br><span class="line">    prompt = best_joke_prompt.format(topic=state[&quot;topic&quot;], jokes=jokes)</span><br><span class="line">    # 调用模型，期望其输出符合 BestJoke 结构（包含最佳笑话的ID）</span><br><span class="line">    response = model.with_structured_output(BestJoke).invoke(prompt)</span><br><span class="line">    # 根据模型返回的ID，从笑话列表中选择最佳笑话，并将其存储在状态的 best_selected_joke 字段中</span><br><span class="line">    return &#123;&quot;best_selected_joke&quot;: state[&quot;jokes&quot;][response.id]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Compile-编译"><a href="#Compile-编译" class="headerlink" title="Compile 编译"></a><strong>Compile</strong> 编译</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image</span><br><span class="line">from langgraph.graph import END, StateGraph, START</span><br><span class="line"></span><br><span class="line"># 构建图：将所有组件组合在一起构建我们的流程图</span><br><span class="line">graph = StateGraph(OverallState)</span><br><span class="line"></span><br><span class="line">graph.add_node(&quot;generate_topics&quot;, generate_topics)</span><br><span class="line">graph.add_node(&quot;generate_joke&quot;, generate_joke)</span><br><span class="line">graph.add_node(&quot;best_joke&quot;, best_joke)</span><br><span class="line"></span><br><span class="line">graph.add_edge(START, &quot;generate_topics&quot;)</span><br><span class="line"># 根据条件决定是否继续生成笑话</span><br><span class="line">graph.add_conditional_edges(&quot;generate_topics&quot;, continue_to_jokes, [&quot;generate_joke&quot;])</span><br><span class="line"># 生成笑话后执行选择最佳笑话</span><br><span class="line">graph.add_edge(&quot;generate_joke&quot;, &quot;best_joke&quot;)</span><br><span class="line"># 选择最佳笑话后流程结束</span><br><span class="line">graph.add_edge(&quot;best_joke&quot;, END)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = graph.compile()</span><br><span class="line">Image(app.get_graph().draw_mermaid_png())</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250723112736244.png" alt="image-20250723112736244"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for s in app.stream(&#123;&quot;topic&quot;: &quot;日本广岛原子弹&quot;&#125;):</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;generate_topics&#x27;: &#123;&#x27;subjects&#x27;: [&#x27;原子弹投放的历史背景与决策过程&#x27;, &#x27;广岛原爆对城市与居民的影响&#x27;, &#x27;战后和平运动与核裁军倡议&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&#x27;战后和平运动的人开会讨论核裁军，一个人站起来说：‘我们必须彻底销毁所有核武器！’ 另一个人犹豫地举手：‘那……我们保留一个吧，就一个，藏在冰箱后面，以防万一。’&#x27;]&#125;&#125;</span><br><span class="line">&#123;&#x27;generate_joke&#x27;: &#123;&#x27;jokes&#x27;: [&quot;杜鲁门宣布要结束战争，顾问问是否要使用原子弹。罗斯福的棺材板突然震动了一下，丘吉尔的雪茄掉在了地上，斯大林则默默拿起了电话：&#x27;同志，我们的计划可能需要再推迟一下。&#x27;&quot;]&#125;&#125;</span><br><span class="line">&#123;&#x27;best_joke&#x27;: &#123;&#x27;best_selected_joke&#x27;: &#x27;为什么广岛的重建计划从不担心交通堵塞？因为每个人都习惯了‘瞬间消失’！（注：此笑话为虚构创作，旨在以幽默方式引发思考，并非对历史事件的不尊重）&#x27;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Research Assistant</strong> <strong>研究助理</strong></p>
<p>见另一篇文章</p>
<h3 id="module-5"><a href="#module-5" class="headerlink" title="module-5"></a>module-5</h3><h4 id="Chatbot-with-Memory-带有记忆功能的聊天机器人"><a href="#Chatbot-with-Memory-带有记忆功能的聊天机器人" class="headerlink" title="Chatbot with Memory 带有记忆功能的聊天机器人"></a><strong>Chatbot with Memory</strong> <strong>带有记忆功能的聊天机器人</strong></h4><p>在这里，我们将介绍 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Memory Store</a> 作为一种保存和检索长期记忆的方法。</p>
<blockquote>
<p>LangGraph Memory Store 是 <strong>LangGraph 提供的长期记忆存储接口</strong>，用于在 <strong>不同对话线程之间</strong> 持久化保存和检索用户信息。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>名称</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BaseStore</strong></td>
<td>抽象接口，定义了 <code>put/get/search/delete</code> 等操作方法</td>
</tr>
<tr>
<td><strong>InMemoryStore</strong></td>
<td>内存实现，适合原型验证</td>
</tr>
<tr>
<td><strong>RedisStore / AsyncRedisStore</strong></td>
<td>生产级实现，支持向量搜索、元数据过滤和命名空间管理</td>
</tr>
</tbody>
</table>
</div>
</blockquote>
<p>我们将构建一个使用 <code>short-term (within-thread仅当前对话线程)</code> 和 <code>long-term (across-thread跨所有对话线程    )</code> 内存的聊天机器人。</p>
<p>我们将重点关注长期 <a href="https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory">semantic memory<strong>（语义记忆）</strong></a>，它将包含关于用户的事实信息。这些长期记忆将被用于创建一个个性化的聊天机器人，它可以记住有关用户的事实。</p>
<p>它将节省内存 <a href="https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories">“in the hot path”</a>，当用户与之聊天时。</p>
<blockquote>
<p><strong>“in the hot path”</strong> 指的是：<strong>在对话或任务执行的</strong>主流程中<strong>（即用户输入后立即、同步地）</strong>主动调用工具或写入记忆，使信息<strong>实时生效</strong>并可用于下一步决策。</p>
</blockquote>
<h5 id="Introduction-to-the-LangGraph-Store-LangGraph-存储简介"><a href="#Introduction-to-the-LangGraph-Store-LangGraph-存储简介" class="headerlink" title="Introduction to the LangGraph Store LangGraph 存储简介"></a><strong>Introduction to the LangGraph Store</strong> <strong>LangGraph 存储简介</strong></h5><p><a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Memory Store</a> 提供了一种在 LangGraph 中 <strong>跨线程</strong> 存储和检索信息的方式。这是一个用于持久化 <code>key-value</code> 存储的 <a href="https://blog.langchain.dev/launching-long-term-memory-support-in-langgraph/">开源基类</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line">in_memory_store = InMemoryStore()</span><br></pre></td></tr></table></figure>
<p>在 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">Store</a> 中存储对象（例如，记忆）时，我们提供：</p>
<p>- 对象的 <code>namespace</code>（类似于目录的元组）</p>
<p>- 对象的 <code>key</code>（类似于文件名）</p>
<p>- 对象的 <code>value</code>（类似于文件内容）</p>
<p>我们使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a> 方法通过 <code>namespace</code> 和 <code>key</code> 将对象保存到存储中。</p>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725155616205-1753430177489-3.png" alt="image-20250725155616205"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;  # 用户ID</span><br><span class="line">namespace_for_memory = (user_id, &quot;memories&quot;)  # 记忆命名空间</span><br><span class="line"></span><br><span class="line"># 生成一个唯一的键值</span><br><span class="line">key = str(uuid.uuid4())  # 使用UUID创建唯一标识符作为键</span><br><span class="line"></span><br><span class="line"># 值需要是一个字典格式</span><br><span class="line">value = &#123;&quot;food_preference&quot;: &quot;我喜欢披萨&quot;&#125;  # 存储的食物偏好信息</span><br><span class="line"></span><br><span class="line"># 保存记忆</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)  # 将记忆存储到内存中</span><br></pre></td></tr></table></figure>
<p>我们使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a> 通过 <code>namespace</code> 从存储中检索对象。这将返回一个列表。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">memories = in_memory_store.search(namespace_for_memory)</span><br><span class="line">type(memories)</span><br><span class="line"></span><br><span class="line"># Metatdata </span><br><span class="line">memories[0].dict()</span><br><span class="line"></span><br><span class="line"># The key, value</span><br><span class="line">print(memories[0].key, memories[0].value)</span><br><span class="line">9e65de8a-f404-4974-b509-0df0566d8fb5 &#123;&#x27;food_preference&#x27;: &#x27;我喜欢披萨&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a> 通过 <code>namespace</code> 和 <code>key</code> 检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Get the memory by namespace and key</span><br><span class="line">memory = in_memory_store.get(namespace_for_memory, key)</span><br><span class="line">memory.dict()</span><br></pre></td></tr></table></figure>
<h5 id="Chatbot-with-long-term-memory-具有长期记忆的聊天机器人"><a href="#Chatbot-with-long-term-memory-具有长期记忆的聊天机器人" class="headerlink" title="Chatbot with long-term memory 具有长期记忆的聊天机器人"></a><strong>Chatbot with long-term memory</strong> <strong>具有长期记忆的聊天机器人</strong></h5><p>我们想要一个聊天机器人，<a href="https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_156">有两种记忆的方式</a>:</p>
<ol>
<li><code>Short-term (within-thread) memory</code>: 聊天机器人可以保留会话历史记录和/或允许在聊天会话中进行中断。  </li>
<li><code>Long-term (cross-thread) memory</code>: 聊天机器人可以记住特定用户在所有聊天会话中的信息 <strong>跨会话</strong>。</li>
</ol>
<p>对于 <code>short-term memory</code>，我们将使用一个 <a href="https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries">checkpointer</a>。</p>
<ul>
<li>他们在每一步都将图状态写入线程中。</li>
<li>他们在该线程中持久化保存聊天历史记录。</li>
<li>他们允许图在该线程中的任何步骤被中断和/或恢复。</li>
</ul>
<p>对于 <code>long-term memory</code>，我们将使用上面介绍的 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的有用助手，能够提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;&quot;你正在收集用户信息以个性化你的回复。</span><br><span class="line"></span><br><span class="line">当前用户信息：</span><br><span class="line">&#123;memory&#125;</span><br><span class="line"></span><br><span class="line">指令：</span><br><span class="line">1. 仔细查看下面的聊天历史</span><br><span class="line">2. 识别有关用户的新信息，例如：</span><br><span class="line">   - 个人详情（姓名、位置）</span><br><span class="line">   - 偏好（喜欢、不喜欢）</span><br><span class="line">   - 兴趣和爱好</span><br><span class="line">   - 过去的经历</span><br><span class="line">   - 目标或未来计划</span><br><span class="line">3. 将任何新信息与现有记忆合并</span><br><span class="line">4. 将记忆格式化为清晰的项目符号列表</span><br><span class="line">5. 如果新信息与现有记忆冲突，请保留最新版本</span><br><span class="line"></span><br><span class="line">记住：只包括用户直接陈述的事实信息。不要做假设或推断。</span><br><span class="line"></span><br><span class="line">基于以下聊天历史，请更新用户信息：&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    existing_memory = store.get(namespace, key)</span><br><span class="line"></span><br><span class="line">    # 如果存在则提取实际的记忆内容并添加前缀</span><br><span class="line">    if existing_memory:</span><br><span class="line">        # 值是一个带有memory键的字典</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)</span><br><span class="line">    </span><br><span class="line">    # 使用记忆以及聊天历史进行回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">        </span><br><span class="line">    # 提取记忆</span><br><span class="line">    if existing_memory:</span><br><span class="line">        existing_memory_content = existing_memory.value.get(&#x27;memory&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        existing_memory_content = &quot;未找到现有记忆。&quot;</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)</span><br><span class="line">    new_memory = model.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖存储中的现有记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line"></span><br><span class="line">    # 将值写入为带有memory键的字典</span><br><span class="line">    store.put(namespace, key, &#123;&quot;memory&quot;: new_memory.content&#125;)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于跨线程的长期记忆存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于线程内的短期记忆检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点器和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250725161106319.png" alt="image-20250725161106319"></p>
<p>聊天历史将通过检查点工具保存到短期记忆中。聊天机器人将回顾聊天历史。然后，它将创建并保存一个记忆到 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a>。此内存可在未来的聊天会话中访问，以个性化聊天机器人的响应。</p>
<p>当我们与聊天机器人交互时，我们提供两样东西：</p>
<ol>
<li><code>Short-term (within-thread) memory</code>: 一个用于持久化聊天历史的 <code>thread ID</code>。  </li>
<li><code>Long-term (cross-thread) memory</code>: 一个用于将长期记忆命名空间到用户的 <code>user ID</code>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br><span class="line">    </span><br><span class="line">================================[1m Human Message [0m=================================</span><br><span class="line"></span><br><span class="line">你好，我的名字是Lance</span><br><span class="line">==================================[1m Ai Message [0m==================================</span><br><span class="line"></span><br><span class="line">你好，Lance！很高兴认识你。有什么我可以帮你的吗？😊</span><br></pre></td></tr></table></figure>
<p>我们正在使用 <code>MemorySaver</code> 检查点来管理线程内内存。这会将聊天历史保存到线程中。我们可以查看保存到线程的聊天历史记录。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line">state = graph.get_state(thread).values</span><br><span class="line">for m in state[&quot;messages&quot;]: </span><br><span class="line">    m.pretty_print()</span><br></pre></td></tr></table></figure>
<p>回想一下，我们使用存储库编译了该图：<code>across_thread_memory = InMemoryStore()</code>并且，我们向图中添加了一个节点 (<code>write_memory</code>)，该节点反映了聊天历史并保存了一段记忆到存储中。</p>
<p>我们可以查看内存是否已保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 为要保存的记忆设置命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.dict()</span><br><span class="line"></span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;memory&#x27;, &#x27;1&#x27;],</span><br><span class="line"> &#x27;key&#x27;: &#x27;user_memory&#x27;,</span><br><span class="line"> &#x27;value&#x27;: &#123;&#x27;memory&#x27;: &#x27;- 姓名：Lance  \n- 位置：旧金山  \n- 兴趣和爱好：骑自行车  \n- 喜欢的活动：在旧金山骑行，可能包括金门大桥和滨海区路线&#x27;&#125;,</span><br><span class="line"> &#x27;created_at&#x27;: &#x27;2025-07-25T08:12:35.877160+00:00&#x27;,</span><br><span class="line"> &#x27;updated_at&#x27;: &#x27;2025-07-25T08:12:35.877161+00:00&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>现在，让我们以 <strong>相同的用户ID</strong>启动一个<strong>新线程</strong>。我们应该看到聊天机器人记住了用户的个人资料，并将其用于个性化响应。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们提供用户ID用于跨线程记忆以及一个新的线程ID</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;2&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好！你推荐我去哪里骑自行车？&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<h4 id="Chatbot-with-Profile-Schema-带有配置文件模式的聊天机器人"><a href="#Chatbot-with-Profile-Schema-带有配置文件模式的聊天机器人" class="headerlink" title="Chatbot with Profile Schema 带有配置文件模式的聊天机器人"></a><strong>Chatbot with Profile Schema</strong> <strong>带有配置文件模式的聊天机器人</strong></h4><p>我们的聊天机器人将记忆保存为字符串。在实践中，我们通常希望记忆具有结构化格式。例如，记忆可以是<a href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">单个、持续更新的模式 </a>。在我们的案例中，我们希望这是一个单一的用户档案。</p>
<p>我们将扩展我们的聊天机器人，将语义记忆保存到单个<a href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">用户档案 </a>中。我们还将介绍一个库 <a href="https://github.com/hinthornw/trustcall">Trustcall</a>，用于使用新信息更新此模式。</p>
<h5 id="Defining-a-user-profile-schema-定义用户配置文件模式"><a href="#Defining-a-user-profile-schema-定义用户配置文件模式" class="headerlink" title="Defining a user profile schema 定义用户配置文件模式"></a><strong>Defining a user profile schema</strong> <strong>定义用户配置文件模式</strong></h5><p>Python 有许多不同类型的 <a href="https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition">structured data</a>，例如 TypedDict、字典、JSON 和 <a href="https://docs.pydantic.dev/latest/">Pydantic</a>。</p>
<p>让我们先使用 TypedDict 来定义一个用户资料模式。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import TypedDict, List</span><br><span class="line"></span><br><span class="line">class UserProfile(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;带有类型字段的用户档案模式&quot;&quot;&quot;</span><br><span class="line">    user_name: str  # 用户的首选名称</span><br><span class="line">    interests: List[str]  # 用户兴趣列表</span><br></pre></td></tr></table></figure>
<h5 id="Saving-a-schema-to-the-store-将模式保存到存储中"><a href="#Saving-a-schema-to-the-store-将模式保存到存储中" class="headerlink" title="Saving a schema to the store 将模式保存到存储中"></a><strong>Saving a schema to the store</strong> <strong>将模式保存到存储中</strong></h5><p><a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore">LangGraph Store</a> 接受任何 Python 字典作为 <code>value</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># TypedDict 实例</span><br><span class="line">user_profile: UserProfile = &#123;</span><br><span class="line">    &quot;user_name&quot;: &quot;Lance&quot;,  # 用户名</span><br><span class="line">    &quot;interests&quot;: [&quot;骑行&quot;, &quot;科技&quot;, &quot;咖啡&quot;]  # 兴趣爱好</span><br><span class="line">&#125;</span><br><span class="line">user_profile</span><br></pre></td></tr></table></figure>
<p>我们使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put">put</a> 方法将 TypedDict 保存到存储中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import uuid</span><br><span class="line">from langgraph.store.memory import InMemoryStore</span><br><span class="line"></span><br><span class="line"># 初始化内存存储</span><br><span class="line">in_memory_store = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 为要保存的记忆创建命名空间</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace_for_memory = (user_id, &quot;memory&quot;)</span><br><span class="line"></span><br><span class="line"># 将记忆以键值对的形式保存到命名空间中</span><br><span class="line">key = &quot;user_profile&quot;</span><br><span class="line">value = user_profile</span><br><span class="line">in_memory_store.put(namespace_for_memory, key, value)</span><br></pre></td></tr></table></figure>
<p>我们使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search">search</a> 按命名空间从存储中检索对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for m in in_memory_store.search(namespace_for_memory):</span><br><span class="line">    print(m.dict())</span><br><span class="line">    </span><br><span class="line">&#123;&#x27;namespace&#x27;: [&#x27;1&#x27;, &#x27;memory&#x27;], &#x27;key&#x27;: &#x27;user_profile&#x27;, &#x27;value&#x27;: &#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;, &#x27;created_at&#x27;: &#x27;2025-07-25T08:58:06.031770+00:00&#x27;, &#x27;updated_at&#x27;: &#x27;2025-07-25T08:58:06.031775+00:00&#x27;, &#x27;score&#x27;: None&#125;</span><br></pre></td></tr></table></figure>
<p>我们还可以使用 <a href="https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get">get</a> 通过命名空间和键来检索特定对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">profile = in_memory_store.get(namespace_for_memory, &quot;user_profile&quot;)</span><br><span class="line">profile.value</span><br><span class="line"></span><br><span class="line">&#123;&#x27;user_name&#x27;: &#x27;Lance&#x27;, &#x27;interests&#x27;: [&#x27;骑行&#x27;, &#x27;科技&#x27;, &#x27;咖啡&#x27;]&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Chatbot-with-profile-schema-带有配置文件模式的聊天机器人"><a href="#Chatbot-with-profile-schema-带有配置文件模式的聊天机器人" class="headerlink" title="Chatbot with profile schema 带有配置文件模式的聊天机器人"></a><strong>Chatbot with profile schema</strong> <strong>带有配置文件模式的聊天机器人</strong></h5><p>现在我们知道了如何为记忆指定一个模式，并将其保存到存储中。现在，我们如何根据这个特定的模式 <strong>创建</strong> 记忆？</p>
<p>在我们的聊天机器人中，我们 <a href="https://langchain-ai.github.io/langgraph/concepts/memory/#profile">想要从一个聊天里创建记忆</a>.这就是 <a href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">structured outputs格式化输出</a> 概念有用的地方。</p>
<p>LangChain 的 <a href="https://python.langchain.com/docs/concepts/chat_models/">chat model</a> 接口有一个 <a href="https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage">PROTECTED$11$</a> 方法用于强制结构化输出。这在我们需要确保输出符合某个模式时非常有用，而且它会为我们解析输出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将模式绑定到模型</span><br><span class="line">model_with_structure = model.with_structured_output(UserProfile)</span><br><span class="line"></span><br><span class="line"># 调用模型生成符合模式的结构化输出</span><br><span class="line">structured_output = model_with_structure.invoke([HumanMessage(&quot;我的名字是Lance，我喜欢骑自行车。&quot;)])</span><br><span class="line">structured_output</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Structured outputs（结构化输出）<br>指让大模型<strong>不再“随意说人话”</strong>，而是<strong>按你事先定义好的格式（JSON / 表格 / 枚举 / 嵌套对象等）精确返回数据</strong>。相当于给模型套了一个“模具”，保证输出可直接被代码解析、入库或传给下游系统，避免再用正则、字符串拼接去“猜”结果。</p>
<p>使用官方的大模型组件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">model=ChatTongyi(</span><br><span class="line">    model=&quot;qwen-plus-2025-07-14&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>现在，让我们在聊天机器人中使用它。这只需要对 <code>write_memory</code> 函数进行轻微修改。我们使用 <code>model_with_structure</code>，如上所述，来生成一个与我们模式匹配的配置文件。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line"></span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langgraph.graph import StateGraph, MessagesState, START, END</span><br><span class="line">from langgraph.store.base import BaseStore</span><br><span class="line"></span><br><span class="line">from langchain_core.messages import HumanMessage, SystemMessage, AIMessage</span><br><span class="line">from langchain_core.runnables.config import RunnableConfig</span><br><span class="line"></span><br><span class="line"># 聊天机器人指令</span><br><span class="line">MODEL_SYSTEM_MESSAGE = &quot;&quot;&quot;你是一个拥有记忆功能的 helpful 助手，可以提供关于用户的信息。</span><br><span class="line">如果你有这个用户的记忆，请使用它来个性化你的回复。</span><br><span class="line">以下是记忆内容（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 根据聊天历史和任何现有记忆创建新记忆</span><br><span class="line">CREATE_MEMORY_INSTRUCTION = &quot;&quot;&quot;根据用户的聊天历史创建或更新用户档案记忆。</span><br><span class="line">这将被保存为长期记忆。如果存在现有记忆，只需更新它。</span><br><span class="line">以下是现有记忆（可能为空）：&#123;memory&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;从存储中加载记忆并使用它来个性化聊天机器人的回复。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line"></span><br><span class="line">    # 在系统提示中格式化记忆</span><br><span class="line">    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 使用记忆以及聊天历史来回复</span><br><span class="line">    response = model.invoke([SystemMessage(content=system_msg)]+state[&quot;messages&quot;])</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;messages&quot;: response&#125;</span><br><span class="line"></span><br><span class="line">def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot;反思聊天历史并将记忆保存到存储中。&quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 从配置中获取用户ID</span><br><span class="line">    user_id = config[&quot;configurable&quot;][&quot;user_id&quot;]</span><br><span class="line"></span><br><span class="line">    # 从存储中检索现有记忆</span><br><span class="line">    namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">    existing_memory = store.get(namespace, &quot;user_memory&quot;)</span><br><span class="line"></span><br><span class="line">    # 为系统提示格式化记忆</span><br><span class="line">    if existing_memory and existing_memory.value:</span><br><span class="line">        memory_dict = existing_memory.value</span><br><span class="line">        formatted_memory = (</span><br><span class="line">            f&quot;姓名: &#123;memory_dict.get(&#x27;user_name&#x27;, &#x27;未知&#x27;)&#125;\n&quot;</span><br><span class="line">            f&quot;兴趣: &#123;&#x27;, &#x27;.join(memory_dict.get(&#x27;interests&#x27;, []))&#125;&quot;</span><br><span class="line">        )</span><br><span class="line">    else:</span><br><span class="line">        formatted_memory = None</span><br><span class="line">        </span><br><span class="line">    # 在指令中格式化现有记忆</span><br><span class="line">    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)</span><br><span class="line"></span><br><span class="line">    # 调用模型生成符合模式的结构化输出</span><br><span class="line">    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state[&#x27;messages&#x27;])</span><br><span class="line"></span><br><span class="line">    # 覆盖现有的用户档案记忆</span><br><span class="line">    key = &quot;user_memory&quot;</span><br><span class="line">    store.put(namespace, key, new_memory)</span><br><span class="line"></span><br><span class="line"># 定义图</span><br><span class="line">builder = StateGraph(MessagesState)</span><br><span class="line">builder.add_node(&quot;call_model&quot;, call_model)</span><br><span class="line">builder.add_node(&quot;write_memory&quot;, write_memory)</span><br><span class="line">builder.add_edge(START, &quot;call_model&quot;)</span><br><span class="line">builder.add_edge(&quot;call_model&quot;, &quot;write_memory&quot;)</span><br><span class="line">builder.add_edge(&quot;write_memory&quot;, END)</span><br><span class="line"></span><br><span class="line"># 用于长期（跨线程）记忆的存储</span><br><span class="line">across_thread_memory = InMemoryStore()</span><br><span class="line"></span><br><span class="line"># 用于短期（线程内）记忆的检查点</span><br><span class="line">within_thread_memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 使用检查点和存储编译图</span><br><span class="line">graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)</span><br><span class="line"></span><br><span class="line"># 显示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph-agent%E4%B8%8B/image-20250726103516996.png" alt="image-20250726103516996"></p>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们提供线程ID用于短期（线程内）记忆</span><br><span class="line"># 我们提供用户ID用于长期（跨线程）记忆 </span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;, &quot;user_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 用户输入 </span><br><span class="line">input_messages = [HumanMessage(content=&quot;你好，我的名字是Lance，我喜欢在旧金山骑自行车和在面包店吃饭。&quot;)]</span><br><span class="line"></span><br><span class="line"># 运行图</span><br><span class="line">for chunk in graph.stream(&#123;&quot;messages&quot;: input_messages&#125;, config, stream_mode=&quot;values&quot;):</span><br><span class="line">    chunk[&quot;messages&quot;][-1].pretty_print()</span><br></pre></td></tr></table></figure>
<p>查看记忆</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Namespace for the memory to save</span><br><span class="line">user_id = &quot;1&quot;</span><br><span class="line">namespace = (&quot;memory&quot;, user_id)</span><br><span class="line">existing_memory = across_thread_memory.get(namespace, &quot;user_memory&quot;)</span><br><span class="line">existing_memory.value</span><br></pre></td></tr></table></figure>
<h5 id="Trustcall-for-creating-and-updating-profile-schemas-Trustcall-用于创建和更新配置文件模式"><a href="#Trustcall-for-creating-and-updating-profile-schemas-Trustcall-用于创建和更新配置文件模式" class="headerlink" title="Trustcall for creating and updating profile schemas Trustcall 用于创建和更新配置文件模式"></a><strong>Trustcall for creating and updating profile schemas</strong> <strong>Trustcall 用于创建和更新配置文件模式</strong></h5><p>Trustcall 是一个由 LangChain 团队开发的开源 Python 库，旨在<strong>解决大型语言模型（LLM）在生成或修改复杂 JSON 数据结构时效率低、易出错的问题</strong>。</p>
<p>我们使用 <code>create_extractor</code>，传入模型以及我们的模式作为 <a href="https://python.langchain.com/docs/concepts/tools/">tool</a>。使用 TrustCall 时，可以以多种方式提供模式。</p>
<p>例如，我们可以传递一个 JSON 对象 / Python 字典或 Pydantic 模型。在底层，TrustCall 使用 <a href="https://python.langchain.com/docs/concepts/tool_calling/">tool calling</a> 从输入的 <a href="https://python.langchain.com/docs/concepts/messages/">messages</a> 列表中生成 <a href="https://python.langchain.com/docs/concepts/structured_outputs/">structured output</a>。为了强制 Trustcall 生成 <a href="https://python.langchain.com/docs/concepts/structured_outputs/">structured output</a>，我们可以在 <code>tool_choice</code> 参数中包含模式名称。</p>
<p>我仅做了解了，感觉用处不多，用结果化输出就能达到效果</p>
<h4 id="Chatbot-with-Collection-Schema-带集合模式的聊天机器人"><a href="#Chatbot-with-Collection-Schema-带集合模式的聊天机器人" class="headerlink" title="Chatbot with Collection Schema 带集合模式的聊天机器人"></a><strong>Chatbot with Collection Schema</strong> <strong>带集合模式的聊天机器人</strong></h4><p><strong>“collection”</strong> 指的是一种<strong>将语义记忆组织为多个独立文档（objects）的存储方式</strong>，而不是把所有信息都塞进一个巨大的“用户档案”（single profile）里。</p>
<p>假设你在做一个 AI 助手，用户说：</p>
<blockquote>
<p>“我下周要去东京出差，住在涩谷区的 Sakura Hotel。”<br>“我朋友 Ken 也要来，他喜欢吃拉面。”</p>
</blockquote>
<p>如果用 <strong>collection</strong>，你会存成两条记忆：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;trip&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;destination&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Tokyo&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2025-08-04&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hotel&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Sakura Hotel, Shibuya&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;friend&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Ken&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;food_preference&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ramen&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<p>每条记忆都是一个独立文档，后续你可以：</p>
<ul>
<li>搜索“trip”类型的记忆，找到用户的出差安排；</li>
<li>搜索“friend”类型的记忆，找到 Ken 的偏好；</li>
<li>更新 Ken 的信息时，<strong>只改一条记录</strong>，不会影响其它记忆。</li>
</ul>
<h4 id="Memory-Agent-内存代理"><a href="#Memory-Agent-内存代理" class="headerlink" title="Memory Agent 内存代理"></a><strong>Memory Agent</strong> <strong>内存代理</strong></h4><p>现在，我们将把学到的内容整合起来，构建一个具有长期记忆的 <a href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/">agent</a>。</p>
<p>我们的代理 <code>task_mAIstro</code> 将帮助我们管理待办事项列表！</p>
<p>我们之前构建的聊天机器人 <strong>始终</strong> 会反思对话并保存记忆。<code>task_mAIstro</code> 将决定 <strong>何时</strong> 保存记忆（待办事项列表中的项目）。</p>
<p>我们之前构建的聊天机器人始终保存一种类型的记忆，即个人资料或集合。<code>task_mAIstro</code> 可以决定将数据保存到用户个人资料或 ToDo 事项集合中。</p>
<p>除此之外，<code>task_mAIstro</code> 还将管理程序性记忆。这允许用户更新创建ToDo项的偏好设置。</p>
<h5 id="Creating-an-agent-创建一个代理"><a href="#Creating-an-agent-创建一个代理" class="headerlink" title="Creating an agent 创建一个代理"></a><strong>Creating an agent</strong> <strong>创建一个代理</strong></h5><p>有许多不同的 <a href="https://langchain-ai.github.io/langgraph/concepts/high_level/">agent</a> 架构可供选择。在这里，我们将实现一个简单的内容，一个 <a href="https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation">ReAct</a> 代理。这个代理将成为创建和管理待办事项列表的得力助手。</p>
<p>此代理可以决定更新三种类型的长期记忆：</p>
<p>(a) 创建或更新具有普通用户信息的用户 <code>profile</code></p>
<p>(b) 在ToDo列表中添加或更新项目 <code>collection</code></p>
<p>(c) 更新其自身的 <code>instructions</code> 以了解如何更新待办事项列表中的项目</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import TypedDict, Literal</span><br><span class="line"></span><br><span class="line"># 更新记忆工具</span><br><span class="line">class UpdateMemory(TypedDict):</span><br><span class="line">    &quot;&quot;&quot; 决定更新哪种记忆类型 &quot;&quot;&quot;</span><br><span class="line">    update_type: Literal[&#x27;user&#x27;, &#x27;todo&#x27;, &#x27;instructions&#x27;]</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li><code>&#39;user&#39;</code>：用户相关信息</li>
<li><code>&#39;todo&#39;</code>：待办事项</li>
<li><code>&#39;instructions&#39;</code>：指令信息</li>
</ul>
</blockquote>
<h5 id="Graph-definition-图定义"><a href="#Graph-definition-图定义" class="headerlink" title="Graph definition 图定义"></a><strong>Graph definition</strong> <strong>图定义</strong></h5><p>我们添加了一个简单的路由器 <code>route_message</code>，它通过二元决策来节省内存。</p>
<h3 id="module-6"><a href="#module-6" class="headerlink" title="module-6"></a>module-6</h3>]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>Research Assistant研究助理</title>
    <url>/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/</url>
    <content><![CDATA[<h4 id="Research-Assistant-研究助理"><a href="#Research-Assistant-研究助理" class="headerlink" title="Research Assistant 研究助理"></a><strong>Research Assistant</strong> <strong>研究助理</strong></h4><p>我们的目标是围绕聊天模型构建一个轻量级、多智能体系统，以定制研究过程。</p>
<p>Source Selection</p>
<ul>
<li>用户可为研究自行选择任意输入源。</li>
</ul>
<p>Planning</p>
<ul>
<li>用户提供主题后，系统生成一组 AI 分析师，每位分析师聚焦一个子主题。</li>
<li>在研究开始前，采用 <strong>人机协同</strong> 方式对子主题进行精调。</li>
</ul>
<p>LLM Utilization</p>
<ul>
<li>每位分析师基于所选源，与专家 AI 开展深度访谈。</li>
<li>访谈采用多轮对话形式，以 STORM 论文所示方式提取详尽洞见。</li>
<li>访谈过程将以“<strong>子图</strong>”形式记录，并保存各自内部状态。</li>
</ul>
<p>Research Process</p>
<ul>
<li>专家 AI 并行收集信息，实时回答分析师提问。</li>
<li>所有访谈通过 <strong>map-reduce</strong> 架构同时展开。</li>
</ul>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/66dbb164d61c93d48e604091_research-assistant1.png" alt="Screenshot 2024-08-26 at 7.26.33 PM.png"></p>
<h5 id="Generate-Analysts-Human-In-The-Loop-生成分析师"><a href="#Generate-Analysts-Human-In-The-Loop-生成分析师" class="headerlink" title="Generate Analysts: Human-In-The-Loop 生成分析师"></a><strong>Generate Analysts: Human-In-The-Loop</strong> <strong>生成分析师</strong></h5><p>创建分析师并使用人工循环（human-in-the-loop）来审查他们。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import List</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line">class Analyst(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    分析师模型类</span><br><span class="line">    用于定义单个分析师的基本信息和属性</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    affiliation: str = Field(</span><br><span class="line">        description=&quot;分析师的主要隶属机构。&quot;,</span><br><span class="line">    )</span><br><span class="line">    name: str = Field(</span><br><span class="line">        description=&quot;分析师的姓名&quot;</span><br><span class="line">    )</span><br><span class="line">    role: str = Field(</span><br><span class="line">        description=&quot;分析师在该主题背景下的角色。&quot;,</span><br><span class="line">    )</span><br><span class="line">    description: str = Field(</span><br><span class="line">        description=&quot;分析师的关注点、担忧和动机的描述。&quot;,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    @property#@property 装饰器的作用是将一个方法转换为只读属性 ，让方法可以像访问属性一样使用，而不需要加括号调用。</span><br><span class="line">    def persona(self) -&gt; str:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        生成分析师的人设信息</span><br><span class="line">        返回格式化的字符串包含分析师的所有关键信息</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        return f&quot;姓名: &#123;self.name&#125;\n角色: &#123;self.role&#125;\n隶属机构: &#123;self.affiliation&#125;\n描述: &#123;self.description&#125;\n&quot;</span><br><span class="line"></span><br><span class="line">class Perspectives(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    视角模型类</span><br><span class="line">    用于管理多个分析师的集合</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    analysts: List[Analyst] = Field(</span><br><span class="line">        description=&quot;包含角色和隶属机构的分析师综合列表。&quot;,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">class GenerateAnalystsState(TypedDict):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    生成分析师状态类型定义</span><br><span class="line">    用于类型提示，定义在生成分析师过程中需要的状态信息</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    topic: str # 研究主题 - 用户输入的研究话题</span><br><span class="line">    max_analysts: int # 分析师数量 - 需要生成的分析师最大数量</span><br><span class="line">    human_analyst_feedback: str # 人类反馈 - 来自用户的反馈信息，用于调整分析师生成</span><br><span class="line">    analysts: List[Analyst] # 提出问题的分析师 - 已生成的分析师列表</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>Field</code> 是 Pydantic 提供的一个函数，主要用于为模型字段添加额外的元数据和配置。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from IPython.display import Image, display</span><br><span class="line">from langgraph.graph import START, END, StateGraph</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line">from langchain_core.messages import AIMessage, HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line"># 分析师指令模板</span><br><span class="line">analyst_instructions=&quot;&quot;&quot;您需要创建一组AI分析师角色。请仔细遵循以下指令：</span><br><span class="line"></span><br><span class="line">1. 首先，查看研究主题：</span><br><span class="line">&#123;topic&#125;</span><br><span class="line">        </span><br><span class="line">2. 检查任何可选的编辑反馈，这些反馈用于指导分析师的创建： </span><br><span class="line">        </span><br><span class="line">&#123;human_analyst_feedback&#125;</span><br><span class="line">    </span><br><span class="line">3. 根据上述文档和/或反馈确定最有趣的主题。</span><br><span class="line">                    </span><br><span class="line">4. 选择前 &#123;max_analysts&#125; 个主题。</span><br><span class="line"></span><br><span class="line">5. 为每个主题分配一个分析师。</span><br><span class="line"></span><br><span class="line">6. 重要：请以JSON格式返回您的响应，结构如下：</span><br><span class="line">   &#123;&#123;</span><br><span class="line">     &quot;analysts&quot;: [</span><br><span class="line">       &#123;&#123;</span><br><span class="line">         &quot;name&quot;: &quot;分析师姓名&quot;,</span><br><span class="line">         &quot;affiliation&quot;: &quot;所属机构&quot;,</span><br><span class="line">         &quot;role&quot;: &quot;角色描述&quot;,</span><br><span class="line">         &quot;description&quot;: &quot;详细描述&quot;</span><br><span class="line">       &#125;&#125;</span><br><span class="line">     ]</span><br><span class="line">   &#125;&#125;</span><br><span class="line"></span><br><span class="line">7. 请确保响应中包含&#x27;json&#x27;这个词，这是必需的。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def create_analysts(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 创建分析师 &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    topic=state[&#x27;topic&#x27;]</span><br><span class="line">    max_analysts=state[&#x27;max_analysts&#x27;]</span><br><span class="line">    human_analyst_feedback=state.get(&#x27;human_analyst_feedback&#x27;, &#x27;&#x27;)#防止为空</span><br><span class="line">        </span><br><span class="line">    # 强制结构化输出</span><br><span class="line">    structured_llm = llm.with_structured_output(Perspectives)</span><br><span class="line"></span><br><span class="line">    # 系统消息</span><br><span class="line">    system_message = analyst_instructions.format(topic=topic,human_analyst_feedback=human_analyst_feedback, max_analysts=max_analysts)</span><br><span class="line"></span><br><span class="line">    # 生成分析师</span><br><span class="line">    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=&quot;生成分析师集合。&quot;)])</span><br><span class="line">    </span><br><span class="line">    # 将分析师列表写入状态</span><br><span class="line">    return &#123;&quot;analysts&quot;: analysts.analysts&#125;</span><br><span class="line"></span><br><span class="line">def human_feedback(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 无操作节点，应该在此处中断 &quot;&quot;&quot;</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">def should_continue(state: GenerateAnalystsState):</span><br><span class="line">    &quot;&quot;&quot; 返回下一个要执行的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否有用户反馈</span><br><span class="line">    human_analyst_feedback=state.get(&#x27;human_analyst_feedback&#x27;, None)</span><br><span class="line">    if human_analyst_feedback:</span><br><span class="line">        return &quot;create_analysts&quot;</span><br><span class="line">    </span><br><span class="line">    # 否则结束</span><br><span class="line">    return END</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">builder = StateGraph(GenerateAnalystsState)</span><br><span class="line">builder.add_node(&quot;create_analysts&quot;, create_analysts)  # 添加创建分析师节点</span><br><span class="line">builder.add_node(&quot;human_feedback&quot;, human_feedback)   # 添加用户反馈节点</span><br><span class="line">builder.add_edge(START, &quot;create_analysts&quot;)           # 从开始到创建分析师</span><br><span class="line">builder.add_edge(&quot;create_analysts&quot;, &quot;human_feedback&quot;) # 从创建分析师到用户反馈</span><br><span class="line">builder.add_conditional_edges(&quot;human_feedback&quot;, should_continue, [&quot;create_analysts&quot;, END]) # 条件边</span><br><span class="line"></span><br><span class="line"># 编译图</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph = builder.compile(interrupt_before=[&#x27;human_feedback&#x27;], checkpointer=memory)  # 在用户反馈前中断</span><br><span class="line"></span><br><span class="line"># 显示图</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))  # 显示流程图</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250723171742889.png" alt="image-20250723171742889"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 输入</span><br><span class="line">max_analysts = 3  # 最大分析师数量</span><br><span class="line">topic = &quot;采用LangGraph作为代理框架的好处&quot;  # 研究主题</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;  # 线程配置，用于会话跟踪</span><br><span class="line"></span><br><span class="line"># 运行图直到第一次中断</span><br><span class="line">for event in graph.stream(&#123;&quot;topic&quot;:topic,&quot;max_analysts&quot;:max_analysts,&#125;, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    # 审查结果</span><br><span class="line">    analysts = event.get(&#x27;analysts&#x27;, &#x27;&#x27;)  # 获取分析师列表</span><br><span class="line">    if analysts:</span><br><span class="line">        for analyst in analysts:</span><br><span class="line">            print(f&quot;姓名: &#123;analyst.name&#125;&quot;)        # 打印分析师姓名</span><br><span class="line">            print(f&quot;隶属机构: &#123;analyst.affiliation&#125;&quot;)  # 打印隶属机构</span><br><span class="line">            print(f&quot;角色: &#123;analyst.role&#125;&quot;)        # 打印角色</span><br><span class="line">            print(f&quot;描述: &#123;analyst.description&#125;&quot;)  # 打印描述</span><br><span class="line">            print(&quot;-&quot; * 50)  # 打印分隔线</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">姓名: 艾琳·史密斯</span><br><span class="line">隶属机构: 人工智能与代理系统研究所</span><br><span class="line">角色: LangGraph架构专家</span><br><span class="line">描述: 专注于研究基于图结构的AI代理框架，尤其是LangGraph在复杂决策流程中的模块化与可扩展性优势。</span><br><span class="line">--------------------------------------------------</span><br><span class="line">姓名: 拉胡尔·梅赫塔</span><br><span class="line">隶属机构: 分布式系统与AI实验室</span><br><span class="line">角色: 代理框架性能分析师</span><br><span class="line">描述: 研究LangGraph在多代理协作中的效率提升，以及其在异步通信、状态管理和错误恢复方面的优势。</span><br><span class="line">--------------------------------------------------</span><br><span class="line">姓名: 艾米丽·陈</span><br><span class="line">隶属机构: 人机交互与智能系统中心</span><br><span class="line">角色: 代理框架用户体验研究员</span><br><span class="line">描述: 分析LangGraph如何支持开发者构建更具交互性和可解释性的AI代理系统，特别是在可视化流程设计和调试方面的优势。</span><br><span class="line">--------------------------------------------------</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 我们现在像 human_feedback 节点一样更新状态</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            &quot;添加一个来自初创公司的人，以增加企业家视角&quot;&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 继续图的执行</span><br><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    # 审查结果</span><br><span class="line">    analysts = event.get(&#x27;analysts&#x27;, &#x27;&#x27;)  # 获取分析师列表</span><br><span class="line">    if analysts:</span><br><span class="line">        for analyst in analysts:</span><br><span class="line">            print(f&quot;姓名: &#123;analyst.name&#125;&quot;)        # 打印分析师姓名</span><br><span class="line">            print(f&quot;隶属机构: &#123;analyst.affiliation&#125;&quot;)  # 打印隶属机构</span><br><span class="line">            print(f&quot;角色: &#123;analyst.role&#125;&quot;)        # 打印角色</span><br><span class="line">            print(f&quot;描述: &#123;analyst.description&#125;&quot;)  # 打印描述</span><br><span class="line">            print(&quot;-&quot; * 50)  # 打印分隔线</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 如果我们满意，那么就不提供任何反馈</span><br><span class="line">further_feedback = None #如果满意就返回none，如果不满意就进行反馈</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            further_feedback&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<h5 id="Conduct-Interview-进行面试"><a href="#Conduct-Interview-进行面试" class="headerlink" title="Conduct Interview 进行面试"></a><strong>Conduct Interview</strong> <strong>进行面试</strong></h5><p><strong>生成问题</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import  Annotated</span><br><span class="line">from langgraph.graph import MessagesState</span><br><span class="line"></span><br><span class="line">class InterviewState(MessagesState):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    访谈状态类</span><br><span class="line">    继承自MessagesState，用于管理访谈过程中的各种状态信息</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    max_num_turns: int # 对话轮数上限</span><br><span class="line">    context: Annotated[list, operator.add] # 源文档，使用operator.add进行合并</span><br><span class="line">    analyst: Analyst # 提问的分析师</span><br><span class="line">    interview: str # 访谈记录（文字记录）</span><br><span class="line">    sections: list # 最终章节，我们在外部状态中重复此字段以用于Send() API</span><br><span class="line"></span><br><span class="line">class SearchQuery(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    搜索查询模型</span><br><span class="line">    用于定义搜索查询的结构</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    search_query: str = Field(None, description=&quot;用于检索的搜索查询。&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 问题生成指令</span><br><span class="line">question_instructions = &quot;&quot;&quot;你是一名分析师，任务是采访专家以了解特定主题。</span><br><span class="line"></span><br><span class="line">你的目标是提炼出与你主题相关的有趣且具体的见解。</span><br><span class="line"></span><br><span class="line">1. 有趣的：人们会感到惊讶或不明显的见解。</span><br><span class="line">        </span><br><span class="line">2. 具体的：避免泛泛而谈的见解，包含来自专家的具体例子。</span><br><span class="line"></span><br><span class="line">这是你的关注主题和目标集合：&#123;goals&#125;</span><br><span class="line">        </span><br><span class="line">首先使用符合你人设的名字介绍自己，然后提出你的问题。</span><br><span class="line"></span><br><span class="line">继续提问以深入挖掘和细化你对该主题的理解。</span><br><span class="line">        </span><br><span class="line">当你对理解满意时，用&quot;非常感谢您的帮助！&quot;来结束采访。</span><br><span class="line"></span><br><span class="line">记住在整个回复中保持角色特征，体现提供给你的人设和目标。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def generate_question(state: InterviewState):</span><br><span class="line">    &quot;&quot;&quot; 生成问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    analyst = state[&quot;analyst&quot;]      # 当前分析师</span><br><span class="line">    messages = state[&quot;messages&quot;]    # 对话历史</span><br><span class="line"></span><br><span class="line">    # 生成问题</span><br><span class="line">    system_message = question_instructions.format(goals=analyst.persona)  # 格式化系统消息</span><br><span class="line">    question = llm.invoke([SystemMessage(content=system_message)]+messages)  # 调用LLM生成问题</span><br><span class="line">        </span><br><span class="line">    # 将消息写入状态</span><br><span class="line">    return &#123;&quot;messages&quot;: [question]&#125;  # 返回新生成的问题</span><br></pre></td></tr></table></figure>
<p><strong>生成问题的并行处理</strong></p>
<p>专家将并行从多个来源收集信息以回答问题。</p>
<ul>
<li>特定网站：例如通过 <a href="https://python.langchain.com/v0.2/docs/integrations/document_loaders/web_base/">WebBaseLoader</a>  </li>
<li>已索引文档：例如通过 <a href="https://python.langchain.com/v0.2/docs/tutorials/rag/">RAG</a>  </li>
<li>网页搜索  </li>
<li>维基百科搜索</li>
</ul>
<p>你可以尝试不同的网络搜索工具，比如 <a href="https://tavily.com/">Tavily</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Web search tool</span><br><span class="line">from langchain_community.tools.tavily_search import TavilySearchResults</span><br><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line">#tavily_search = TavilySearchResults(max_results=3)</span><br><span class="line">tavily_search=TavilySearch(max_result=3)</span><br><span class="line"></span><br><span class="line"># Wikipedia search tool</span><br><span class="line">from langchain_community.document_loaders import WikipediaLoader</span><br></pre></td></tr></table></figure>
<p>现在，我们创建节点以搜索网络和维基百科。</p>
<p>我们还将创建一个节点来回答分析师的问题。最后，我们将创建节点以保存完整的采访内容，并撰写采访的摘要（“部分”）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.messages import get_buffer_string</span><br><span class="line"></span><br><span class="line"># 搜索查询编写</span><br><span class="line">search_instructions = SystemMessage(content=f&quot;&quot;&quot;你将获得分析师和专家之间的对话。</span><br><span class="line"></span><br><span class="line">你的目标是生成一个结构化的 JSON 对象，该对象包含一个用于网络搜索的查询字符串。</span><br><span class="line"></span><br><span class="line">请严格按照以下步骤操作：</span><br><span class="line"></span><br><span class="line">1.  仔细分析整个对话。</span><br><span class="line">2.  特别关注分析师提出的最后一个问题。</span><br><span class="line">3.  根据该问题，生成一个清晰、简洁、有效的搜索查询字符串。</span><br><span class="line">4.  **你的最终输出必须是一个严格的 JSON 对象，格式如下，不要包含任何其他文字或解释：**</span><br><span class="line">    &#123;&#123;&quot;search_query&quot;: &quot;你的查询字符串放在这里&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">**示例：**</span><br><span class="line">如果最后一个问题涉及 &quot;LangGraph 与其他代理框架（如 AutoGen）相比的优势&quot;，</span><br><span class="line">你的输出必须严格是：</span><br><span class="line">&#123;&#123;&quot;search_query&quot;: &quot;LangGraph vs AutoGen agent framework advantages&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">分析师的最后一个问题才是关键，请基于它生成查询。</span><br><span class="line"></span><br><span class="line">**你的输出：**&quot;&quot;&quot;)</span><br><span class="line"></span><br><span class="line">def search_web(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从网络搜索中检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 搜索查询</span><br><span class="line">    structured_llm = llm.with_structured_output(SearchQuery)</span><br><span class="line">    search_query = structured_llm.invoke([search_instructions]+state[&#x27;messages&#x27;])</span><br><span class="line">    </span><br><span class="line">    # 搜索</span><br><span class="line">    search_docs = tavily_search.invoke(search_query.search_query)</span><br><span class="line"></span><br><span class="line">     # 格式化</span><br><span class="line">    formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">        [</span><br><span class="line">            f&#x27;&lt;Document href=&quot;&#123;doc[&quot;url&quot;]&#125;&quot;/&gt;\n&#123;doc[&quot;content&quot;]&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">            for doc in search_docs</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line"></span><br><span class="line">def search_wikipedia(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 从维基百科检索文档 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # # 搜索查询</span><br><span class="line">    # structured_llm = llm.with_structured_output(SearchQuery)</span><br><span class="line">    # search_query = structured_llm.invoke([search_instructions]+state[&#x27;messages&#x27;])</span><br><span class="line">    </span><br><span class="line">    # # 搜索</span><br><span class="line">    # search_docs = WikipediaLoader(query=search_query.search_query, </span><br><span class="line">    #                               load_max_docs=2).load()</span><br><span class="line"></span><br><span class="line">    #  # 格式化</span><br><span class="line">    # formatted_search_docs = &quot;\n\n---\n\n&quot;.join(</span><br><span class="line">    #     [</span><br><span class="line">    #         f&#x27;&lt;Document source=&quot;&#123;doc.metadata[&quot;source&quot;]&#125;&quot; page=&quot;&#123;doc.metadata.get(&quot;page&quot;, &quot;&quot;)&#125;&quot;/&gt;\n&#123;doc.page_content&#125;\n&lt;/Document&gt;&#x27;</span><br><span class="line">    #         for doc in search_docs</span><br><span class="line">    #     ]</span><br><span class="line">    # )</span><br><span class="line"></span><br><span class="line">    # return &#123;&quot;context&quot;: [formatted_search_docs]&#125; </span><br><span class="line">    return &#123;&quot;context&quot;: [&quot;&quot;]&#125;</span><br><span class="line"></span><br><span class="line">answer_instructions = &quot;&quot;&quot;你是一位正在接受分析师采访的专家。</span><br><span class="line"></span><br><span class="line">这是分析师的关注领域：&#123;goals&#125;。</span><br><span class="line">        </span><br><span class="line">你的目标是回答面试官提出的问题。</span><br><span class="line"></span><br><span class="line">要回答问题，请使用此上下文：</span><br><span class="line">        </span><br><span class="line">&#123;context&#125;</span><br><span class="line"></span><br><span class="line">回答问题时，请遵循以下准则：</span><br><span class="line">        </span><br><span class="line">1. 仅使用上下文中提供的信息。</span><br><span class="line">        </span><br><span class="line">2. 不要引入外部信息或在上下文中明确说明之外进行假设。</span><br><span class="line"></span><br><span class="line">3. 上下文包含每个独立文档主题的来源。</span><br><span class="line"></span><br><span class="line">4. 在任何相关陈述旁边包含这些来源。例如，对于来源 # 1 使用 [1]。</span><br><span class="line"></span><br><span class="line">5. 在答案底部按顺序列出你的来源。 [1] 来源 1，[2] 来源 2，等等</span><br><span class="line">        </span><br><span class="line">6. 如果来源是：&lt;Document source=&quot;assistant/docs/llama3_1.pdf&quot; page=&quot;7&quot;/&gt;&#x27; 那么只需列出：</span><br><span class="line">        </span><br><span class="line">[1] assistant/docs/llama3_1.pdf, page 7 </span><br><span class="line">        </span><br><span class="line">并跳过括号的添加以及引用中的 Document source 前言。&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def generate_answer(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 回答问题的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    analyst = state[&quot;analyst&quot;]</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line"></span><br><span class="line">    # 回答问题</span><br><span class="line">    system_message = answer_instructions.format(goals=analyst.persona, context=context)</span><br><span class="line">    answer = llm.invoke([SystemMessage(content=system_message)]+messages)</span><br><span class="line">            </span><br><span class="line">    # 将消息命名为来自专家</span><br><span class="line">    answer.name = &quot;expert&quot;</span><br><span class="line">    </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;messages&quot;: [answer]&#125;</span><br><span class="line"></span><br><span class="line">def save_interview(state: InterviewState):</span><br><span class="line">    </span><br><span class="line">    &quot;&quot;&quot; 保存采访 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取消息</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    </span><br><span class="line">    # 将采访转换为字符串</span><br><span class="line">    interview = get_buffer_string(messages)</span><br><span class="line">    </span><br><span class="line">    # 保存到 interviews 键</span><br><span class="line">    return &#123;&quot;interview&quot;: interview&#125;</span><br><span class="line"></span><br><span class="line">def route_messages(state: InterviewState, </span><br><span class="line">                   name: str = &quot;expert&quot;):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 在问题和答案之间路由 &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 获取消息</span><br><span class="line">    messages = state[&quot;messages&quot;]</span><br><span class="line">    max_num_turns = state.get(&#x27;max_num_turns&#x27;,2)</span><br><span class="line"></span><br><span class="line">    # 检查专家答案的数量</span><br><span class="line">    #isinstance(m, AIMessage) ：检查当前消息 m 是否是 AIMessage 类的实例。这通常用于识别由 AI 模型生成的消息。</span><br><span class="line">    num_responses = len(</span><br><span class="line">        [m for m in messages if isinstance(m, AIMessage) and m.name == name]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 如果专家回答的次数超过最大轮数，则结束</span><br><span class="line">    if num_responses &gt;= max_num_turns:</span><br><span class="line">        return &#x27;save_interview&#x27;</span><br><span class="line"></span><br><span class="line">    # 获取提出的最后一个问题，以检查它是否表示讨论结束</span><br><span class="line">    #messages[-2] ：分析师提出的 最后一个问题 。</span><br><span class="line">    #messages[-1] ：专家对这个问题的 最新回答 。</span><br><span class="line">    last_question = messages[-2]</span><br><span class="line">    </span><br><span class="line">    if &quot;非常感谢你的帮助&quot; in last_question.content:</span><br><span class="line">        return &#x27;save_interview&#x27;</span><br><span class="line">    return &quot;ask_question&quot;</span><br><span class="line"></span><br><span class="line">section_writer_instructions = &quot;&quot;&quot;你是一位专业的科技作家。</span><br><span class="line">            </span><br><span class="line">你的任务是根据一组源文档创建一份简短、易于理解的报告部分。</span><br><span class="line"></span><br><span class="line">1. 分析源文档的内容：</span><br><span class="line">- 每个源文档的名称都在文档开头，带有 &lt;Document 标签。</span><br><span class="line">        </span><br><span class="line">2. 使用 markdown 格式创建报告结构：</span><br><span class="line">- 使用 ## 作为章节标题</span><br><span class="line">- 使用 ### 作为小节标题</span><br><span class="line">        </span><br><span class="line">3. 按照此结构编写报告：</span><br><span class="line">a. 标题 (## header)</span><br><span class="line">b. 摘要 (### header)</span><br><span class="line">c. 来源 (### header)</span><br><span class="line"></span><br><span class="line">4. 根据分析师的关注领域，使你的标题引人入胜：</span><br><span class="line">&#123;focus&#125;</span><br><span class="line"></span><br><span class="line">5. 对于摘要部分：</span><br><span class="line">- 设置与分析师关注领域相关的通用背景/上下文的摘要</span><br><span class="line">- 强调从采访中收集到的新颖、有趣或令人惊讶的见解</span><br><span class="line">- 创建一个使用过的源文档的编号列表</span><br><span class="line">- 不要提及面试官或专家的姓名</span><br><span class="line">- 目标是最多约 400 字</span><br><span class="line">- 根据源文档中的信息，在报告中使用编号来源（例如，[1]、[2]）</span><br><span class="line">        </span><br><span class="line">6. 在来源部分：</span><br><span class="line">- 包含报告中使用的所有来源</span><br><span class="line">- 提供相关网站或特定文档路径的完整链接</span><br><span class="line">- 每个来源用换行符分隔。在每行末尾使用两个空格以在 Markdown 中创建换行符。</span><br><span class="line">- 它看起来像：</span><br><span class="line"></span><br><span class="line">### 来源</span><br><span class="line">[1] 链接或文档名称</span><br><span class="line">[2] 链接或文档名称</span><br><span class="line"></span><br><span class="line">7. 务必合并来源。例如，这不正确：</span><br><span class="line"></span><br><span class="line">[3] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line">[4] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line"></span><br><span class="line">不应有冗余来源。它应该只是：</span><br><span class="line"></span><br><span class="line">[3] https://ai.meta.com/blog/meta-llama-3-1/</span><br><span class="line">        </span><br><span class="line">8. 最终审查：</span><br><span class="line">- 确保报告遵循所需的结构</span><br><span class="line">- 在报告标题之前不包含任何前言</span><br><span class="line">- 检查所有准则是否已遵循&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_section(state: InterviewState):</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 编写章节的节点 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 获取状态</span><br><span class="line">    interview = state[&quot;interview&quot;]</span><br><span class="line">    context = state[&quot;context&quot;]</span><br><span class="line">    analyst = state[&quot;analyst&quot;]</span><br><span class="line">   </span><br><span class="line">    # 使用从采访（上下文）或采访本身（interview）收集的源文档编写章节</span><br><span class="line">    system_message = section_writer_instructions.format(focus=analyst.description)</span><br><span class="line">    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f&quot;Use this source to write your section: &#123;context&#125;&quot;)]) </span><br><span class="line">                </span><br><span class="line">    # 将其附加到状态</span><br><span class="line">    return &#123;&quot;sections&quot;: [section.content]&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">interview_builder = StateGraph(InterviewState)</span><br><span class="line">interview_builder.add_node(&quot;ask_question&quot;, generate_question)</span><br><span class="line">interview_builder.add_node(&quot;search_web&quot;, search_web)</span><br><span class="line">interview_builder.add_node(&quot;search_wikipedia&quot;, search_wikipedia)</span><br><span class="line">interview_builder.add_node(&quot;answer_question&quot;, generate_answer)</span><br><span class="line">interview_builder.add_node(&quot;save_interview&quot;, save_interview)</span><br><span class="line">interview_builder.add_node(&quot;write_section&quot;, write_section)</span><br><span class="line"></span><br><span class="line"># 流程</span><br><span class="line">interview_builder.add_edge(START, &quot;ask_question&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;ask_question&quot;, &quot;search_web&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;ask_question&quot;, &quot;search_wikipedia&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;search_web&quot;, &quot;answer_question&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;search_wikipedia&quot;, &quot;answer_question&quot;)</span><br><span class="line">interview_builder.add_conditional_edges(&quot;answer_question&quot;, route_messages,[&#x27;ask_question&#x27;,&#x27;save_interview&#x27;])</span><br><span class="line">interview_builder.add_edge(&quot;save_interview&quot;, &quot;write_section&quot;)</span><br><span class="line">interview_builder.add_edge(&quot;write_section&quot;, END)</span><br><span class="line"></span><br><span class="line"># 采访</span><br><span class="line">memory = MemorySaver()</span><br><span class="line">interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=&quot;Conduct Interviews&quot;)</span><br><span class="line"></span><br><span class="line"># 视图</span><br><span class="line">display(Image(interview_graph.get_graph().draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725101725158.png" alt="image-20250725101725158"></p>
<h5 id="Map-Reduce（Parallelze-interviews-Map-Reduce）-并行化访谈"><a href="#Map-Reduce（Parallelze-interviews-Map-Reduce）-并行化访谈" class="headerlink" title="Map-Reduce（Parallelze interviews: Map-Reduce） 并行化访谈"></a><strong>Map-Reduce（Parallelze interviews: Map-Reduce）</strong> <strong>并行化访谈</strong></h5><p>我们通过 <code>Send()</code> API 并行化处理访谈，这是一个映射步骤。我们将它们在 reduce 步骤中组合成报告正文。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import List, Annotated</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line">class ResearchGraphState(TypedDict):</span><br><span class="line">    topic: str                           # 研究主题 (字符串类型)</span><br><span class="line">    max_analysts: int                   # 分析师数量 (整数类型)</span><br><span class="line">    human_analyst_feedback: str         # 人类分析师的反馈 (字符串类型)</span><br><span class="line">    analysts: List[Analyst]             # 提问的分析师列表 (Analyst 对象的列表)</span><br><span class="line">    sections: Annotated[list, operator.add] # 报告章节列表 (使用 operator.add 作为 Send() API 的键，意味着列表可以通过相加来合并)</span><br><span class="line">    introduction: str                   # 最终报告的引言部分 (字符串类型)</span><br><span class="line">    content: str                        # 最终报告的内容主体部分 (字符串类型)</span><br><span class="line">    conclusion: str                     # 最终报告的结论部分 (字符串类型)</span><br><span class="line">    final_report: str                   # 最终完整的报告 (字符串类型)</span><br><span class="line"></span><br><span class="line"># 从 langgraph.constants 导入 Send 类</span><br><span class="line">from langgraph.constants import Send</span><br><span class="line">def initiate_all_interviews(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 这是“map”（映射）步骤，我们使用 Send API 并行运行每个采访子图 &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否存在人类反馈</span><br><span class="line">    human_analyst_feedback = state.get(&#x27;human_analyst_feedback&#x27;)</span><br><span class="line">    if human_analyst_feedback:</span><br><span class="line">        # 如果有反馈，则返回到 &quot;create_analysts&quot; 节点进行调整</span><br><span class="line">        return &quot;create_analysts&quot;</span><br><span class="line"></span><br><span class="line">    # 否则，通过 Send() API 并行启动所有采访</span><br><span class="line">    else:</span><br><span class="line">        topic = state[&quot;topic&quot;]</span><br><span class="line">        # 为每个分析师创建一个 Send 对象</span><br><span class="line">        # 目标是 &quot;conduct_interview&quot; 节点</span><br><span class="line">        # 传递的参数包括该分析师对象和一条初始消息</span><br><span class="line">        return [Send(&quot;conduct_interview&quot;, &#123;&quot;analyst&quot;: analyst,</span><br><span class="line">                                           &quot;messages&quot;: [HumanMessage(</span><br><span class="line">                                               content=f&quot;所以你说你正在写一篇关于 &#123;topic&#125; 的文章？&quot;</span><br><span class="line">                                           )</span><br><span class="line">                                                       ]&#125;) for analyst in state[&quot;analysts&quot;]]</span><br></pre></td></tr></table></figure>
<h5 id="Finalize-最终确定"><a href="#Finalize-最终确定" class="headerlink" title="Finalize 最终确定"></a><strong>Finalize</strong> <strong>最终确定</strong></h5><p>我们添加最后一个步骤，为最终报告撰写引言和结论。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import List, Annotated</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"># 定义用于撰写最终报告的指令模板</span><br><span class="line">report_writer_instructions = &quot;&quot;&quot;你是一位正在撰写关于以下主题报告的技术作家：</span><br><span class="line"></span><br><span class="line">&#123;topic&#125;</span><br><span class="line">    </span><br><span class="line">你有一个分析师团队。每个分析师做了两件事：</span><br><span class="line"></span><br><span class="line">1. 他们就一个特定的子主题与专家进行了采访。</span><br><span class="line">2. 他们将他们的发现写成了一份备忘录。</span><br><span class="line"></span><br><span class="line">你的任务：</span><br><span class="line"></span><br><span class="line">1. 你将得到一份来自你所有分析师的备忘录集合。</span><br><span class="line">2. 仔细思考每份备忘录中的见解。</span><br><span class="line">3. 将这些见解整合成一个清晰的整体摘要，把所有备忘录中的核心思想联系起来。</span><br><span class="line">4. 将每份备忘录中的要点总结成一个连贯的单一叙述。</span><br><span class="line"></span><br><span class="line">报告格式要求：</span><br><span class="line"> </span><br><span class="line">1. 使用 Markdown 格式。</span><br><span class="line">2. 报告开头不要有前言。</span><br><span class="line">3. 不要使用子标题。</span><br><span class="line">4. 报告开头使用一个一级标题：## Insights （## 见解）</span><br><span class="line">5. 在报告中不要提及任何分析师的名字。</span><br><span class="line">6. 保留备忘录中的所有引用，这些引用会用方括号标注，例如 [1] 或 [2]。</span><br><span class="line">7. 创建一个最终的、合并的来源列表，并添加到以 `## Sources` 为标题的部分。</span><br><span class="line">8. 按顺序列出你的来源，不要重复。</span><br><span class="line"></span><br><span class="line">[1] 来源 1</span><br><span class="line">[2] 来源 2</span><br><span class="line"></span><br><span class="line">以下是你的分析师提供的备忘录，你需要根据它们来撰写报告：</span><br><span class="line"></span><br><span class="line">&#123;context&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_report(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告主体内容的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节（备忘录）</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节（备忘录）连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和备忘录内容，调用 LLM 生成最终报告</span><br><span class="line">    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)    </span><br><span class="line">    report = llm.invoke([SystemMessage(content=system_message)] + [HumanMessage(content=&quot;根据这些备忘录写一份报告。&quot;)]) </span><br><span class="line">    # 返回报告内容</span><br><span class="line">    return &#123;&quot;content&quot;: report.content&#125;</span><br><span class="line"></span><br><span class="line"># 定义用于撰写引言和结论的指令模板</span><br><span class="line">intro_conclusion_instructions = &quot;&quot;&quot;你是一位正在完成关于 &#123;topic&#125; 报告的技术作家。</span><br><span class="line"></span><br><span class="line">你将得到报告的所有章节。</span><br><span class="line"></span><br><span class="line">你的工作是撰写一个清晰且有说服力的引言或结论部分。</span><br><span class="line"></span><br><span class="line">用户会指示你是写引言还是结论。</span><br><span class="line"></span><br><span class="line">两个部分都不要有前言。</span><br><span class="line"></span><br><span class="line">目标大约 100 个词，简洁地预览（对于引言）或回顾（对于结论）报告的所有章节。</span><br><span class="line"></span><br><span class="line">使用 Markdown 格式。</span><br><span class="line"></span><br><span class="line">对于你的引言，创建一个引人注目的标题，并使用 # 标题级别。</span><br><span class="line">对于你的引言，使用 ## Introduction （## 引言） 作为部分标题。</span><br><span class="line"></span><br><span class="line">对于你的结论，使用 ## Conclusion （## 结论） 作为部分标题。</span><br><span class="line"></span><br><span class="line">以下是供你参考以撰写相应部分的章节：&#123;formatted_str_sections&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">def write_introduction(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告引言的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和章节内容，调用 LLM 生成引言</span><br><span class="line">    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    </span><br><span class="line">    intro = llm.invoke([instructions] + [HumanMessage(content=&quot;写报告的引言&quot;)]) </span><br><span class="line">    # 返回引言内容</span><br><span class="line">    return &#123;&quot;introduction&quot;: intro.content&#125;</span><br><span class="line"></span><br><span class="line">def write_conclusion(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 撰写报告结论的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取所有章节</span><br><span class="line">    sections = state[&quot;sections&quot;]</span><br><span class="line">    topic = state[&quot;topic&quot;]</span><br><span class="line"></span><br><span class="line">    # 将所有章节连接成一个字符串</span><br><span class="line">    formatted_str_sections = &quot;\n\n&quot;.join([f&quot;&#123;section&#125;&quot; for section in sections])</span><br><span class="line">    </span><br><span class="line">    # 使用指令模板和章节内容，调用 LLM 生成结论</span><br><span class="line">    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)    </span><br><span class="line">    conclusion = llm.invoke([instructions] + [HumanMessage(content=&quot;写报告的结论&quot;)]) </span><br><span class="line">    # 返回结论内容</span><br><span class="line">    return &#123;&quot;conclusion&quot;: conclusion.content&#125;</span><br><span class="line"></span><br><span class="line">def finalize_report(state: ResearchGraphState):</span><br><span class="line">    &quot;&quot;&quot; 这是“reduce”（归约）步骤，我们收集所有部分，将它们组合起来，并进行反思以写出引言/结论 &quot;&quot;&quot;</span><br><span class="line">    &quot;&quot;&quot; 最终整合报告的节点函数 &quot;&quot;&quot;</span><br><span class="line">    # 获取报告主体内容</span><br><span class="line">    content = state[&quot;content&quot;]</span><br><span class="line">    # 如果内容以 &quot;## Insights&quot; 开头，则移除这个标题</span><br><span class="line">    if content.startswith(&quot;## Insights&quot;):</span><br><span class="line">        content = content.strip(&quot;## Insights&quot;)</span><br><span class="line">    # 尝试分离报告主体和来源部分</span><br><span class="line">    if &quot;## Sources&quot; in content:</span><br><span class="line">        try:</span><br><span class="line">            content, sources = content.split(&quot;\n## Sources\n&quot;)</span><br><span class="line">        except:</span><br><span class="line">            sources = None # 如果分离失败，则来源部分为空</span><br><span class="line">    else:</span><br><span class="line">        sources = None</span><br><span class="line"></span><br><span class="line">    # 将引言、主体内容和结论连接起来形成最终报告</span><br><span class="line">    final_report = state[&quot;introduction&quot;] + &quot;\n\n---\n\n&quot; + content + &quot;\n\n---\n\n&quot; + state[&quot;conclusion&quot;]</span><br><span class="line">    # 如果存在来源部分，则将其附加到最终报告末尾</span><br><span class="line">    if sources is not None:</span><br><span class="line">        final_report += &quot;\n\n## Sources\n&quot; + sources</span><br><span class="line">    # 返回最终报告</span><br><span class="line">    return &#123;&quot;final_report&quot;: final_report&#125;</span><br><span class="line"></span><br><span class="line"># 添加节点和边</span><br><span class="line">builder = StateGraph(ResearchGraphState)</span><br><span class="line">builder.add_node(&quot;create_analysts&quot;, create_analysts)</span><br><span class="line">builder.add_node(&quot;human_feedback&quot;, human_feedback)</span><br><span class="line">builder.add_node(&quot;conduct_interview&quot;, interview_builder.compile()) # 将之前定义的采访图编译后作为一个节点</span><br><span class="line">builder.add_node(&quot;write_report&quot;, write_report)</span><br><span class="line">builder.add_node(&quot;write_introduction&quot;, write_introduction)</span><br><span class="line">builder.add_node(&quot;write_conclusion&quot;, write_conclusion)</span><br><span class="line">builder.add_node(&quot;finalize_report&quot;, finalize_report)</span><br><span class="line"></span><br><span class="line"># 定义工作流逻辑</span><br><span class="line">builder.add_edge(START, &quot;create_analysts&quot;) # 从开始到创建分析师</span><br><span class="line">builder.add_edge(&quot;create_analysts&quot;, &quot;human_feedback&quot;) # 创建分析师后进入人类反馈环节</span><br><span class="line"># 条件边：根据 human_feedback 节点的输出，决定是回到创建分析师还是开始采访</span><br><span class="line">builder.add_conditional_edges(&quot;human_feedback&quot;, initiate_all_interviews, [&quot;create_analysts&quot;, &quot;conduct_interview&quot;]) </span><br><span class="line"># 采访完成后，并行执行撰写报告、引言和结论</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_report&quot;)</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_introduction&quot;)</span><br><span class="line">builder.add_edge(&quot;conduct_interview&quot;, &quot;write_conclusion&quot;)</span><br><span class="line"># 撰写完报告的三个部分后，汇聚到最终整合步骤</span><br><span class="line">builder.add_edge([&quot;write_conclusion&quot;, &quot;write_report&quot;, &quot;write_introduction&quot;], &quot;finalize_report&quot;)</span><br><span class="line">builder.add_edge(&quot;finalize_report&quot;, END) # 最终整合后结束</span><br><span class="line"></span><br><span class="line"># 编译图</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"># 编译图，并设置在 &#x27;human_feedback&#x27; 节点前中断，以及使用检查点保存器</span><br><span class="line">graph = builder.compile(interrupt_before=[&#x27;human_feedback&#x27;], checkpointer=memory)</span><br><span class="line"># 显示图的可视化表示</span><br><span class="line">display(Image(graph.get_graph(xray=1).draw_mermaid_png()))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725102148881.png" alt="image-20250725102148881"></p>
<h5 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h5><p>让我们提出一个关于 LangGraph 的开放式问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">max_analysts = 3 </span><br><span class="line">topic = &quot;采用 LangGraph 作为代理框架的好处&quot;</span><br><span class="line">thread = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 使用 stream 但不执行打印逻辑</span><br><span class="line">for event in graph.stream(&#123;</span><br><span class="line">    &quot;topic&quot;: topic,</span><br><span class="line">    &quot;max_analysts&quot;: max_analysts</span><br><span class="line">&#125;, thread, stream_mode=&quot;values&quot;):</span><br><span class="line">    pass  # 不执行任何操作</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#人工更新节点</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                                &quot;请加入这家原生生成式 AI 创业公司的首席执行官。&quot;&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 确认我们已经满意，返回none</span><br><span class="line">graph.update_state(thread, &#123;&quot;human_analyst_feedback&quot;: </span><br><span class="line">                            None&#125;, as_node=&quot;human_feedback&quot;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 继续执行</span><br><span class="line">for event in graph.stream(None, thread, stream_mode=&quot;updates&quot;):</span><br><span class="line">    print(&quot;--Node--&quot;)</span><br><span class="line">    node_name = next(iter(event.keys()))</span><br><span class="line">    print(node_name)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/22/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E5%AE%9E%E6%88%98-Research%20Assistant%E7%A0%94%E7%A9%B6%E5%8A%A9%E7%90%86/image-20250725103159942.png" alt="image-20250725103159942"></p>
<p><a href="https://smith.langchain.com/public/6504cafd-d314-48d1-8640-57dc3f472e61/r">https://smith.langchain.com/public/6504cafd-d314-48d1-8640-57dc3f472e61/r</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>langgraph查漏补缺</title>
    <url>/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langgraph%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h3 id="注入上下文"><a href="#注入上下文" class="headerlink" title="注入上下文"></a>注入上下文</h3><p>“注入上下文”就是<strong>在运行过程中节点/大模型</strong> 可能需要、但<strong>不会</strong>（也不应该）去改变的<strong>只读信息</strong>的集合。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>场景</th>
<th>注入上下文里可能放什么</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>权限控制</strong></td>
<td><code>user_id</code>, <code>tenant_id</code>（决定能访问哪些数据）</td>
</tr>
<tr>
<td><strong>外部依赖</strong></td>
<td><code>db_connection</code>, <code>api_key</code>, <code>s3_bucket</code>（节点里要用）</td>
</tr>
<tr>
<td><strong>个性化参数</strong></td>
<td><code>language</code>, <code>timezone</code>, <code>model_temperature</code></td>
</tr>
<tr>
<td><strong>会话元信息</strong></td>
<td><code>session_id</code>, <code>channel</code>（Slack / 微信 / Web）</td>
</tr>
</tbody>
</table>
</div>
<h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line"></span><br><span class="line">from langgraph.graph import StateGraph</span><br><span class="line">from langgraph.runtime import Runtime</span><br><span class="line"></span><br><span class="line">@dataclass</span><br><span class="line">class Context:</span><br><span class="line">    &quot;&quot;&quot;Context schema defined by the developer.&quot;&quot;&quot;    </span><br><span class="line">    user_id: str    </span><br><span class="line">    db_connection: str</span><br><span class="line">    </span><br><span class="line">def node(state: State, runtime: Runtime[Context]):</span><br><span class="line">    # type safe access to context attributes    </span><br><span class="line">    user_id = runtime.context.user_id</span><br><span class="line">    db_conn = runtime.context.db_connection</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">builder = StateGraph(state_schema=State, context_schema=Context)</span><br><span class="line"></span><br><span class="line"># add nodes, edges, compile the graph...</span><br><span class="line"></span><br><span class="line"># top level context arg is typed as Context for autocomplete and type checking</span><br><span class="line">result = graph.invoke(</span><br><span class="line">    &#123;&#x27;input&#x27;: &#x27;abc&#x27;&#125;,</span><br><span class="line">    context=Context(user_id=&#x27;123&#x27;, db_conn=&#x27;conn_mock&#x27;)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><a href="https://langchain-ai.github.io/langgraph/reference/runtime/#runtime"><code>Runtime</code></a> 类提供了一个单一接口，用于访问信息，例如：</p>
<ul>
<li>上下文：在运行开始时传递的静态数据</li>
<li>存储：长期记忆的存储机制</li>
<li>流写入器：用于向图输出流写入的自定义函数</li>
<li>对于功能 API 用户，<code>previous</code> 也可用：给定线程的前一个返回值</li>
</ul>
<p>现在，开发者不再需要将上述所有内容作为单独的参数注入到节点函数中，<br>而是可以通过一个 <code>runtime</code> 参数来访问它们。</p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langgraph</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2025/08/06/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langmem/</url>
    <content><![CDATA[<p><a href="https://github.langchain.ac.cn/langmem/">简介 - LangChain 框架</a></p>
]]></content>
  </entry>
  <entry>
    <title>Langsmith</title>
    <url>/2025/07/15/%E5%AD%A6%E4%B9%A0/ai%E6%A1%86%E6%9E%B6/langsmith/</url>
    <content><![CDATA[<h3 id="配置langsmith"><a href="#配置langsmith" class="headerlink" title="配置langsmith"></a>配置langsmith</h3><h4 id="安装LangSmith-SDK"><a href="#安装LangSmith-SDK" class="headerlink" title="安装LangSmith SDK"></a>安装LangSmith SDK</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install langsmith</span><br></pre></td></tr></table></figure>
<h4 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h4><p>获取api<a href="https://smith.langchain.com/o/56031c2a-c402-41d4-83ed-ed15d0693548/settings/apikeys">LangSmith</a></p>
<p>设置相应的环境变量。这将把跟踪记录到<code>default</code>项目（尽管您可以轻松更改）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export LANGSMITH_TRACING=true</span><br><span class="line">export LANGSMITH_API_KEY=</span><br><span class="line">export LANGSMITH_PROJECT=default</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LANGSMITH_TRACING=true</span><br><span class="line">LANGSMITH_ENDPOINT=&quot;https://api.smith.langchain.com&quot;</span><br><span class="line">LANGSMITH_API_KEY=&quot;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&quot;</span><br><span class="line">LANGSMITH_PROJECT=&quot;langgraph&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h3><p>官网<a href="https://smith.langchain.com/o/56031c2a-c402-41d4-83ed-ed15d0693548/">《LangSmith》 —- LangSmith</a></p>
<p>参考文档<a href="https://langsmith.langchain.ac.cn/">LangSmith 入门 | 🦜️🛠️ LangSmith 文档</a></p>
<p><a href="https://docs.smith.langchain.com/">Get started with LangSmith | 🦜️🛠️ LangSmith</a></p>
]]></content>
      <categories>
        <category>ai框架</category>
        <category>langsmith</category>
      </categories>
      <tags>
        <tag>langsmith</tag>
      </tags>
  </entry>
  <entry>
    <title>A2A协议</title>
    <url>/2025/08/04/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/A2A%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<h3 id="什么是A2A协议"><a href="#什么是A2A协议" class="headerlink" title="什么是A2A协议"></a>什么是A2A协议</h3><p>A2A 协议（Agent2Agent Protocol，智能体间通信协议）是 Google 在 2025 年 4 月发布并开源的首个 AI 智能体交互标准。它通过统一的通信规范，解决不同团队、不同框架、不同供应商开发的 AI 智能体如何“对话”和协同工作的问题。</p>
<blockquote>
<p>与mcp区分，<strong>MCP</strong> 解决 <strong>“单个智能体如何调用外部工具/数据”</strong> 的问题，而<strong>A2A</strong> 解决 <strong>“多个智能体如何协同完成任务”</strong> 的问题。</p>
</blockquote>
<p><img src="/2025/08/04/%E5%AD%A6%E4%B9%A0/ai%E7%9B%B8%E5%85%B3/A2A%E5%8D%8F%E8%AE%AE/image-20250809222720192.png" alt="image-20250809222720192"></p>
<h3 id="为什么要使用A2A协议"><a href="#为什么要使用A2A协议" class="headerlink" title="为什么要使用A2A协议"></a>为什么要使用A2A协议</h3><p>随着 AI 应用深化，单一“万能”模型难以兼顾所有领域。A2A 鼓励构建“小而专”的智能体生态：</p>
<ul>
<li>每个智能体专注一个领域（如订票、报税、图像处理）。</li>
<li>通过 A2A 协议，它们像乐高积木一样自由组合，快速响应新的业务需求。</li>
</ul>
<p>比如你让一个agent使用多个工具，不仅会浪费tokens，也会降低其调用工具的准确性。所有，专业的领域使用专业的agent，而agent间的通信便要依靠A2A协议</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://github.com/a2aproject/a2a-samples?tab=readme-ov-file">a2aproject/a2a-samples: Samples using the Agent2Agent (A2A) Protocol</a></p>
<p><a href="https://a2a-protocol.org/latest/">Agent2Agent (A2A) Protocol</a></p>
<p><a href="https://github.com/a2aproject/a2a-python">a2aproject/a2a-python: Agent2Agent (A2A) 协议的官方 Python SDK —- a2aproject/a2a-python: Official Python SDK for the Agent2Agent (A2A) Protocol</a></p>
]]></content>
      <categories>
        <category>ai相关</category>
        <category>A2A协议</category>
      </categories>
      <tags>
        <tag>A2A协议</tag>
      </tags>
  </entry>
  <entry>
    <title>pgsql实现持久化</title>
    <url>/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/pgsql%E5%AE%9E%E7%8E%B0%E6%8C%81%E4%B9%85%E5%8C%96/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>常使用pgsql与redis配合langgraph的checkpoint与store进行持久化储存，完成长期记忆与短期记忆的实现</p>
<h3 id="pgsql实现持久化"><a href="#pgsql实现持久化" class="headerlink" title="pgsql实现持久化"></a>pgsql实现持久化</h3><h4 id="什么是pgsql"><a href="#什么是pgsql" class="headerlink" title="什么是pgsql"></a>什么是pgsql</h4><p>PostgreSQL（常简称pgsql或Postgres）是一个功能强大的开源对象-关系型数据库管理系统（ORDBMS），以其稳定性、扩展性和符合SQL标准著称。</p>
<h4 id="docker拉取"><a href="#docker拉取" class="headerlink" title="docker拉取"></a>docker拉取</h4><p>docker-compose</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">version: &#x27;3.8&#x27;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  postgres:</span><br><span class="line">    image: postgres:15        # 指定具体版本</span><br><span class="line">    container_name: postgres_db</span><br><span class="line">    environment:</span><br><span class="line">      POSTGRES_USER: postgres</span><br><span class="line">      POSTGRES_PASSWORD: postgres</span><br><span class="line">      POSTGRES_DB: postgres</span><br><span class="line">      TZ: Asia/Shanghai       # 设置时区</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5432:5432&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - pgdata:/var/lib/postgresql/data</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    healthcheck:             # 健康检查</span><br><span class="line">      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;nange&quot;]</span><br><span class="line">      interval: 10s</span><br><span class="line">      timeout: 5s</span><br><span class="line">      retries: 5</span><br><span class="line">    command: [&quot;postgres&quot;, &quot;-c&quot;, &quot;max_connections=200&quot;]  # 自定义配置</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  pgdata:</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Docker Compose</strong> 是一个 <strong>定义和运行多容器 Docker 应用</strong> 的 <strong>声明式工具</strong>。<br>它通过一个 <strong>YAML 文件（通常叫 <code>docker-compose.yml</code>）</strong> 描述整个应用的服务、网络、存储等配置，然后用一条命令即可 <strong>启动/停止/管理</strong> 所有容器，无需手动逐个 <code>docker run</code>。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#拉取并运行</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>
<h4 id="在pgsqsl安装依赖"><a href="#在pgsqsl安装依赖" class="headerlink" title="在pgsqsl安装依赖"></a>在pgsqsl安装依赖</h4><p>因为LangGraph的PostgresStore需要使用到pgvector，因此需要在容器中按照如下步骤进行操作，直接使用Docker Desktop软件中进行操作 </p>
<blockquote>
<ul>
<li>为什么需要 <code>pgvector</code>？</li>
<li><code>PostgresStore</code> 支持将 <strong>向量嵌入（embedding）</strong> 存储在 PostgreSQL 中，并基于它们进行 <strong>语义搜索</strong>。</li>
<li>该功能依赖 <code>pgvector</code> 扩展提供的 <code>vector</code> 类型和索引机制（如 HNSW）。</li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">安装依赖           </span><br><span class="line">apt update    #刷新本地软件包索引           </span><br><span class="line">apt install -y git build-essential postgresql-server-dev-15                          </span><br></pre></td></tr></table></figure>
<blockquote>
<p>apt install -y git build-essential postgresql-server-dev-15一次性安装 3 类依赖。</p>
<ul>
<li><code>git</code> —— 用来克隆 pgvector 源码。</li>
<li><code>build-essential</code> —— Debian/Ubuntu 的“编译工具链”元包，包含 gcc、make 等。</li>
<li><code>postgresql-server-dev-15</code> —— 与当前 Postgres <strong>主版本一致</strong> 的开发头文件和 <code>pg_config</code>。</li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">编译并安装 pgvector      </span><br><span class="line">#把 pgvector 的 v0.7.0 稳定版 源码克隆到本地目录 ./pgvector。</span><br><span class="line">git clone --branch v0.7.0 https://github.com/pgvector/pgvector.git                </span><br><span class="line">cd pgvector  </span><br><span class="line">#调用 Makefile 根据当前操作系统 + PostgreSQL 版本编译出二进制文件（.so 共享库）。</span><br><span class="line">make          </span><br><span class="line">#把刚刚编好的 .so 文件和 .sql/.control 文件复制到 PostgreSQL 的扩展目录</span><br><span class="line">make install                </span><br><span class="line">验证安装，检查扩展文件是否安装成功                    </span><br><span class="line">ls -l /usr/share/postgresql/15/extension/vector* </span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/pgvector/pgvector">pgvector/pgvector: Open-source vector similarity search for Postgres</a></p>
<p>接下来，若要在脚本中进行使用，首先在系统环境中需要安装PostgreSQL 的开发库（libpq），因为 psycopg 需要它来编译或运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install libpq-dev postgresql-server-dev-all</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>psycopg（Python 操作 PostgreSQL 的库）</strong> 在 <strong>Linux/macOS</strong> 上运行时，底层依赖于 <strong>PostgreSQL 的 C 语言开发库 libpq</strong>。<br>如果系统里 <strong>没有 libpq</strong>，psycopg 会出现以下两种问题：</p>
<ol>
<li><p><strong>编译安装失败</strong>（源码/旧版本）<br>当 <code>pip install psycopg2</code> 需要现场编译时，会找不到头文件 <code>libpq-fe.h</code> 或动态库 <code>libpq.so</code>，导致报错：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">error: libpq-fe.h: No such file or directory</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>运行时崩溃</strong><br>即使通过预编译的 wheel 包安装成功，运行时也可能提示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ImportError: libpq.so.5: cannot open shared object file</span><br></pre></td></tr></table></figure>
</li>
</ol>
</blockquote>
<p>最后，再安装相关依赖包  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install langgraph-checkpoint-postgres                    </span><br><span class="line">pip install psycopg psycopg-pool </span><br></pre></td></tr></table></figure>
<p>psycopg官方 PostgreSQL 驱动，在 <code>psycopg</code> 之上再包一层“<strong>连接池</strong>”，让并发访问更快、更稳定。</p>
<h4 id="连接pgsql"><a href="#连接pgsql" class="headerlink" title="连接pgsql"></a>连接pgsql</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.store.postgres import PostgresStore</span><br><span class="line">from langgraph.checkpoint.postgres import PostgresSaver</span><br><span class="line">from psycopg_pool import ConnectionPool</span><br><span class="line"># 1) 连接字符串（URI 语法）</span><br><span class="line">DB_URI = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line">#   协议://      用户   : 密码   @ 主机:端口 / 数据库名  ? 额外参数</span><br><span class="line"></span><br><span class="line"># 2) 连接级参数</span><br><span class="line">connection_kwargs = &#123;</span><br><span class="line">    &quot;autocommit&quot;: True,     # 每条 SQL 执行完立即提交，无需手动 commit</span><br><span class="line">    &quot;prepare_threshold&quot;: 0, # 禁用服务器端 prepared statement，可减少一次往返</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 3) 创建池</span><br><span class="line">connection_pool = ConnectionPool(</span><br><span class="line">    conninfo=DB_URI,</span><br><span class="line">    max_size=20,            # 最多 20 条物理连接</span><br><span class="line">    kwargs=connection_kwargs,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 4) 显式打开池（psycopg 3 的 ConnectionPool 默认懒启动，调 open() 会立即建 min_size 条连接）</span><br><span class="line">connection_pool.open()</span><br><span class="line">print(&quot;数据库连接池初始化成功&quot;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>正常情况每次 SQL 都新建一条 TCP 连接、做 SSL 握手、验证密码、分配内存，如果不复用连接，这些动作就要 <strong>每次都重新来一遍</strong>，<strong>成本非常高</strong>。</p>
<p>连接池（Connection Pool）是一种 <strong>数据库访问层资源管理组件</strong>，其核心目标是在 <strong>高并发、短事务</strong> 场景下，通过 <strong>复用已建立的数据库物理连接</strong> 来降低系统整体延迟、减少资源消耗，并防止数据库因瞬时连接风暴而崩溃。</p>
</blockquote>
<h4 id="初始化pgsql"><a href="#初始化pgsql" class="headerlink" title="初始化pgsql"></a>初始化pgsql</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 初始化PostgresStore</span><br><span class="line">in_postgres_store = PostgresStore(</span><br><span class="line">    pool,</span><br><span class="line">    index=&#123;</span><br><span class="line">        &quot;dims&quot;: 1536,</span><br><span class="line">        &quot;embed&quot;: embedding</span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line">in_postgres_store.setup()</span><br><span class="line"></span><br><span class="line">#初始化checkpoint</span><br><span class="line"># 使用传入的连接池创建 PostgresSaver</span><br><span class="line">checkpointer = PostgresSaver(pool)</span><br><span class="line">checkpointer.setup()</span><br><span class="line"></span><br><span class="line">#最后编译时添加</span><br><span class="line">graph_builder.compile(checkpointer=checkpointer, store=in_postgres_store)</span><br></pre></td></tr></table></figure>
<p><code>in_postgres_store.setup()</code> 的角色一句话就能说清：</p>
<blockquote>
<p><strong>把数据库里所有为了让向量存储正常工作的“一次性基建”全部建好</strong>——只建一次，后面再跑就不会重复执行。</p>
</blockquote>
<p>具体而言，它通常干下面三件事：1.<strong>建表 / 建扩展</strong>；2.<strong>建向量索引</strong>；3.<strong>元数据初始化</strong></p>
<h4 id="fastapi实现生命周期的管理"><a href="#fastapi实现生命周期的管理" class="headerlink" title="fastapi实现生命周期的管理"></a>fastapi实现生命周期的管理</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 定义了一个异步函数lifespan，它接收一个FastAPI应用实例app作为参数。这个函数将管理应用的生命周期，包括启动和关闭时的操作</span><br><span class="line"># 函数在应用启动时执行一些初始化操作，如加载上下文数据、以及初始化问题生成器</span><br><span class="line"># 函数在应用关闭时执行一些清理操作</span><br><span class="line"># @asynccontextmanager 装饰器用于创建一个异步上下文管理器，它允许你在 yield 之前和之后执行特定的代码块，分别表示启动和关闭时的操作</span><br><span class="line">@asynccontextmanager</span><br><span class="line">async def lifespan(app: FastAPI):</span><br><span class="line">    # 启动时执行</span><br><span class="line">    # 申明引用全局变量，在函数中被初始化，并在整个应用中使用</span><br><span class="line">    global graph, connection_pool</span><br><span class="line">    # 启动时执行</span><br><span class="line">    try:</span><br><span class="line">        logger.info(&quot;正在初始化模型、定义 Graph...&quot;)</span><br><span class="line">        # 初始化 LLM</span><br><span class="line">        llm, embedding = get_llm(llm_type)</span><br><span class="line">        # 创建数据库连接池</span><br><span class="line">        DB_URI = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line">        connection_kwargs = &#123;</span><br><span class="line">            &quot;autocommit&quot;: True,</span><br><span class="line">            &quot;prepare_threshold&quot;: 0,</span><br><span class="line">        &#125;</span><br><span class="line">        connection_pool = ConnectionPool(</span><br><span class="line">            conninfo=DB_URI,</span><br><span class="line">            max_size=20,</span><br><span class="line">            kwargs=connection_kwargs,</span><br><span class="line">        )</span><br><span class="line">        connection_pool.open()  # 显式打开连接池</span><br><span class="line">        logger.info(&quot;数据库连接池初始化成功&quot;)</span><br><span class="line">        # 短期记忆 初始化checkpointer</span><br><span class="line">        checkpointer = PostgresSaver(connection_pool)</span><br><span class="line">        checkpointer.setup()</span><br><span class="line">        # 长期记忆 初始化PostgresStore</span><br><span class="line">        in_postgres_store = PostgresStore(</span><br><span class="line">            connection_pool,</span><br><span class="line">            index=&#123;</span><br><span class="line">                &quot;dims&quot;: 1536,</span><br><span class="line">                &quot;embed&quot;: embedding</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        in_postgres_store.setup()</span><br><span class="line">        # 定义 Graph</span><br><span class="line">        graph = create_graph(llm, checkpointer, in_postgres_store )</span><br><span class="line">        # 保存 Graph 可视化图</span><br><span class="line">        save_graph_visualization(graph)</span><br><span class="line">        logger.info(&quot;初始化完成&quot;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        logger.error(f&quot;初始化过程中出错: &#123;str(e)&#125;&quot;)</span><br><span class="line">        raise</span><br><span class="line"></span><br><span class="line">    yield  # 应用运行期间</span><br><span class="line"></span><br><span class="line">    # 关闭时执行</span><br><span class="line">    logger.info(&quot;正在关闭...&quot;)</span><br><span class="line">    if connection_pool:</span><br><span class="line">        connection_pool.close()  # 关闭连接池</span><br><span class="line">        logger.info(&quot;数据库连接池已关闭&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># lifespan参数用于在应用程序生命周期的开始和结束时执行一些初始化或清理工作</span><br><span class="line">app = FastAPI(lifespan=lifespan)</span><br></pre></td></tr></table></figure>
<h3 id="pgsql的存储结构"><a href="#pgsql的存储结构" class="headerlink" title="pgsql的存储结构"></a>pgsql的存储结构</h3><h4 id="一、Checkpoints-系列"><a href="#一、Checkpoints-系列" class="headerlink" title="一、Checkpoints 系列"></a>一、Checkpoints 系列</h4><blockquote>
<p>作用：让 <strong>LangGraph Runtime</strong> 能在 <strong>分布式/长流程</strong> 场景下 <strong>断点续跑、重放、并发控制</strong>。</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>表名</th>
<th>存什么</th>
<th>典型字段（示意）</th>
<th>何时写入</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>checkpoints</strong></td>
<td>每个「图实例」的 <strong>最新快照</strong>（state 的完整 JSONB）</td>
<td><code>thread_id</code>, <code>checkpoint_ns</code>, <code>checkpoint_id</code>, <code>parent_checkpoint_id</code>, <code>state</code>, <code>created_at</code></td>
<td>每次节点执行成功后覆盖更新</td>
</tr>
<tr>
<td><strong>checkpoint_blobs</strong></td>
<td>checkpoints 里 <strong>大字段的拆分</strong>（避免行过大）</td>
<td><code>thread_id</code>, <code>checkpoint_ns</code>, <code>channel</code>, <code>type</code>, <code>blob</code></td>
<td>当 state 过大，自动拆分</td>
</tr>
<tr>
<td><strong>checkpoint_migrations</strong></td>
<td>记录 <strong>schema 版本/迁移脚本</strong></td>
<td><code>version</code>, <code>name</code>, <code>applied_at</code></td>
<td>只在 <code>setup()</code> 时写一次</td>
</tr>
<tr>
<td><strong>checkpoint_writes</strong></td>
<td><strong>写放大日志</strong>（每个节点写 state 的增量 diff）</td>
<td><code>thread_id</code>, <code>checkpoint_id</code>, <code>task_id</code>, <code>idx</code>, <code>channel</code>, <code>type</code>, <code>value</code></td>
<td>每次节点完成时追加</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>关系：<br><code>checkpoints</code> = 最新完整快照<br><code>checkpoint_writes</code> = 所有增量历史（用于重放/审计）<br><code>checkpoint_blobs</code> = checkpoints 里超大型 value 的切片</p>
</blockquote>
<h4 id="二、Store-系列"><a href="#二、Store-系列" class="headerlink" title="二、Store 系列"></a>二、Store 系列</h4><blockquote>
<p>作用：给 <strong>业务代码（开发者）</strong> 提供 <strong>持久化 KV / 向量存储</strong>，与图运行状态无关。</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>表名</th>
<th>存什么</th>
<th>典型字段（示意）</th>
<th>何时写入</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>store</strong></td>
<td><strong>任意 KV 文档</strong>（LangChain Document → JSONB）</td>
<td><code>uuid</code>, <code>namespace</code>, <code>key</code>, <code>value</code>, <code>created_at</code>, <code>updated_at</code></td>
<td>你调用 <code>store.amput</code> / <code>amset</code> 等 API</td>
</tr>
<tr>
<td><strong>store_migrations</strong></td>
<td>同 checkpoint_migrations，记录 store schema 版本</td>
<td><code>version</code>, <code>name</code>, <code>applied_at</code></td>
<td>只在第一次 <code>setup()</code></td>
</tr>
<tr>
<td><strong>store_vectors</strong></td>
<td><strong>向量索引表</strong>（embedding → vector 类型）</td>
<td><code>uuid</code>, <code>collection_id</code>, <code>embedding</code>, <code>document</code>, <code>metadata</code></td>
<td>你调用 <code>add_documents(..., embeddings=...)</code></td>
</tr>
<tr>
<td><strong>vector_migrations</strong></td>
<td>记录 pgvector 扩展及索引迁移版本</td>
<td><code>version</code>, <code>applied_at</code></td>
<td><code>setup()</code> 时若第一次装 pgvector</td>
</tr>
</tbody>
</table>
</div>
<h4 id="三、调用链脑图"><a href="#三、调用链脑图" class="headerlink" title="三、调用链脑图"></a>三、调用链脑图</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">┌──────────────┐</span><br><span class="line">│ LangGraph    │ 运行图实例</span><br><span class="line">└────┬─────────┘</span><br><span class="line">     │1. 写 checkpoints</span><br><span class="line">     │2. 写 checkpoint_writes</span><br><span class="line">     │3. 拆大字段到 checkpoint_blobs</span><br><span class="line">     ▼</span><br><span class="line">┌──────────────┐</span><br><span class="line">│ 业务代码     │ 读写 KV/向量</span><br><span class="line">└────┬─────────┘</span><br><span class="line">     │1. 写 store</span><br><span class="line">     │2. 写 store_vectors</span><br><span class="line">     ▼</span><br><span class="line"> PostgreSQL (pgsql)</span><br></pre></td></tr></table></figure>
<h3 id="在linux安装postgresql"><a href="#在linux安装postgresql" class="headerlink" title="在linux安装postgresql"></a>在linux安装postgresql</h3><h4 id="查看linux发行版本"><a href="#查看linux发行版本" class="headerlink" title="查看linux发行版本"></a>查看linux发行版本</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看发行版名称和版本</span><br><span class="line">cat /etc/os-release</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PRETTY_NAME=&quot;Ubuntu 24.04.2 LTS&quot;</span><br><span class="line">NAME=&quot;Ubuntu&quot;</span><br><span class="line">VERSION_ID=&quot;24.04&quot;</span><br><span class="line">VERSION=&quot;24.04.2 LTS (Noble Numbat)&quot;</span><br><span class="line">VERSION_CODENAME=noble</span><br><span class="line">ID=ubuntu</span><br><span class="line">ID_LIKE=debian</span><br><span class="line">HOME_URL=&quot;https://www.ubuntu.com/&quot;</span><br><span class="line">SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;</span><br><span class="line">PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;</span><br><span class="line">UBUNTU_CODENAME=noble</span><br><span class="line">LOGO=ubuntu-logo</span><br></pre></td></tr></table></figure>
<h4 id="安装postgresql"><a href="#安装postgresql" class="headerlink" title="安装postgresql"></a>安装postgresql</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 更新软件包索引</span><br><span class="line">sudo apt update</span><br><span class="line"></span><br><span class="line"># 安装 PostgreSQL 和常用扩展</span><br><span class="line">sudo apt install -y postgresql postgresql-contrib</span><br><span class="line"></span><br><span class="line"># 检查服务状态</span><br><span class="line">#Linux 容器/子系统（ Docker、WSL 或 LXC）没有使用 systemd ，因此 systemctl 无法工作</span><br><span class="line">sudo systemctl status postgresql</span><br><span class="line"></span><br><span class="line">#确认 PostgreSQL 已安装</span><br><span class="line">which psql            # 应该输出 /usr/bin/psql</span><br><span class="line">pg_ctl --version      # 显示版本号即已安装</span><br></pre></td></tr></table></figure>
<ul>
<li><code>postgresql</code> 是主程序</li>
<li><code>postgresql-contrib</code> 提供额外扩展（如 <code>uuid-ossp</code>、<code>pgcrypto</code> 等）</li>
</ul>
<blockquote>
<p>systemctl一般用于服务器上，完整的linux系统上</p>
<p>Linux 容器/子系统（ Docker、WSL 或 LXC）使用 service</p>
</blockquote>
<h4 id="pgsql常用指令"><a href="#pgsql常用指令" class="headerlink" title="pgsql常用指令"></a>pgsql常用指令</h4><p>启动pgsql服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service postgresql start</span><br></pre></td></tr></table></figure>
<p>停止pgsql服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service postgresql stop</span><br></pre></td></tr></table></figure>
<p>查看状态</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service postgresql status</span><br></pre></td></tr></table></figure>
<p>连接PostgreSQL 默认的系统用户，可以执行pgsql的相关指令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo -u postgres psql</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>psql</strong>为PostgreSQL 的终端客户端，默认会连接与当前操作系统用户名同名的数据库用户和数据库。</p>
<p><strong>postgres</strong>为PostgreSQL 自带的系统数据库，<code>postgres</code> 默认 <strong>数据库密码为空</strong>，可以通过以下指令进行设置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 设置postgres用户密码</span><br><span class="line">ALTER USER postgres PASSWORD &#x27;postgres&#x27;;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>数据库关于user的作用</p>
<p>数据库里的“用户”是 PostgreSQL <strong>内部用来做“访问控制”的一把钥匙</strong>。一句话：<strong>“谁能连哪个库、谁能读哪张表、谁能改哪些行”——全靠这些数据库用户（角色）来判定。</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>作用</th>
<th>举例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1. 认证</strong>（Authentication）</td>
<td>告诉 PostgreSQL “我连库时提供的用户名+密码是否合法”。</td>
</tr>
<tr>
<td><strong>2. 授权</strong>（Authorization）</td>
<td>决定 “这个用户连进来后，对哪些库、哪些表、哪些行有何种权限（SELECT/INSERT/UPDATE/DELETE…）”。</td>
</tr>
<tr>
<td><strong>3. 资源隔离</strong>（Isolation）</td>
<td>不同业务/团队用不同用户，方便审计、限流、回收权限，互不干扰。</td>
</tr>
</tbody>
</table>
</div>
<p>pgsql通用 URL 模板</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">postgresql://&lt;用户名&gt;:&lt;密码&gt;@127.0.0.1:5432/&lt;数据库名&gt;[?参数=值&amp;...]</span><br></pre></td></tr></table></figure>
<h4 id="连接pgsql-1"><a href="#连接pgsql-1" class="headerlink" title="连接pgsql"></a>连接pgsql</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 基于数据库持久化存储的short-term</span><br><span class="line">db_uri = &quot;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&quot;</span><br><span class="line"></span><br><span class="line"># short-term短期记忆 实例化PostgresSaver对象 并初始化checkpointer</span><br><span class="line"># long-term长期记忆 实例化PostgresStore对象 并初始化store</span><br><span class="line">async with (</span><br><span class="line">    AsyncPostgresSaver.from_conn_string(db_uri) as checkpointer,</span><br><span class="line">    AsyncPostgresStore.from_conn_string(db_uri) as store</span><br><span class="line"></span><br><span class="line">):</span><br><span class="line">    await store.setup()</span><br><span class="line">    await checkpointer.setup()</span><br></pre></td></tr></table></figure>
<h3 id="更换apt镜像源"><a href="#更换apt镜像源" class="headerlink" title="更换apt镜像源"></a>更换apt镜像源</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/apt/sources.list &lt;&lt;&#x27;EOF&#x27;</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm-updates main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian/ bookworm-backports main contrib non-free</span><br><span class="line">deb http://mirrors.aliyun.com/debian-security bookworm-security main contrib non-free</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">apt update</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://juejin.cn/post/7470702616906645540">postgresql向量扩展pgvector的安装与入门本文简答的介绍了 rag 的架构，引申出向量数据库的作用，介绍了 - 掘金</a></p>
<p>langchain支持向量存储<a href="https://python.langchain.com/docs/integrations/vectorstores/">向量存储 | 🦜️🔗 LangChain —- Vector stores | 🦜️🔗 LangChain</a></p>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>agent</tag>
        <tag>pgsql</tag>
      </tags>
  </entry>
  <entry>
    <title>Plan-and-Execute模式</title>
    <url>/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Plan-and-Execute%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<h3 id="什么是Plan-and-Execute模式"><a href="#什么是Plan-and-Execute模式" class="headerlink" title="什么是Plan-and-Execute模式"></a>什么是Plan-and-Execute模式</h3><p>与ReAct模式不同的是，ReAct只做一次规划，而Plan-and-Execute模式核心思想是首先制定一个多步骤计划，然后逐项执行该计划。完成特定任务后，可以重新审视计划并进行适当修改。</p>
<p>举个例子，用户在问一个问题后，agent产生一份任务清单，选取第一份任务开始执行，执行后的结果结合任务清单，执行replan，结合新的信息，更改任务清单的内容，让后续大模型更好地执行，并去除已经完成的任务</p>
<p>实际生产中，应该在planner之前再进行一次判断，如果问题过于简单，不需要进行Plan-and-Execute模式</p>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><h4 id="安装包"><a href="#安装包" class="headerlink" title="安装包"></a>安装包</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install --quiet -U langgraph langchain-community langchain-openai tavily-python</span><br></pre></td></tr></table></figure>
<h4 id="定义网络搜索工具与执行agent"><a href="#定义网络搜索工具与执行agent" class="headerlink" title="定义网络搜索工具与执行agent"></a>定义网络搜索工具与执行agent</h4><p>在产生plan后，要有一个agent对任务清单进行执行，这里以一个ReAct的网络搜索agent为例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#定义工具</span><br><span class="line">from langchain_tavily import TavilySearch</span><br><span class="line">tools = [TavilySearch(max_results=3)]</span><br><span class="line"></span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line">from langgraph.prebuilt import create_react_agent</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=&quot;qwen3-235b-a22b-thinking-2507&quot;,</span><br><span class="line">    api_key=&quot;sk-&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">)</span><br><span class="line">prompt = &quot;You are a helpful assistant.&quot;</span><br><span class="line">agent_executor = create_react_agent(llm, tools, prompt=prompt)</span><br></pre></td></tr></table></figure>
<p>测试功能</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">agent_executor.invoke(&#123;&quot;messages&quot;: [(&quot;user&quot;, &quot;今天是几月几日&quot;)]&#125;)</span><br></pre></td></tr></table></figure>
<p>定义执行节点</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Literal</span><br><span class="line">from langgraph.graph import END</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">async def execute_step(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;执行计划中的步骤&quot;&quot;&quot;</span><br><span class="line">    plan = state[&quot;plan&quot;]</span><br><span class="line">    # 将计划格式化为带编号的字符串</span><br><span class="line">    plan_str = &quot;\n&quot;.join(f&quot;&#123;i + 1&#125;. &#123;step&#125;&quot; for i, step in enumerate(plan))</span><br><span class="line">    task = plan[0]  # 获取第一个待执行的任务</span><br><span class="line">    task_formatted = f&quot;&quot;&quot;对于以下计划:</span><br><span class="line">&#123;plan_str&#125;\n\n你被分配执行第 &#123;1&#125; 步, &#123;task&#125;。&quot;&quot;&quot;</span><br><span class="line">    # 调用代理执行器来执行任务</span><br><span class="line">    agent_response = await agent_executor.ainvoke(</span><br><span class="line">        &#123;&quot;messages&quot;: [(&quot;user&quot;, task_formatted)]&#125;</span><br><span class="line">    )</span><br><span class="line">    # 返回执行结果，添加到历史步骤中</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;past_steps&quot;: [(task, agent_response[&quot;messages&quot;][-1].content)],</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>create_react_agent 是 LangGraph 提供的一个预构建函数，位于 langgraph.prebuilt 模块中，用于快速创建一个基于 ReAct（Reasoning + Acting）架构的智能代理。</p>
<p>langgraph预设的其他常用组件如下</p>
<p><strong>ToolNode</strong></p>
<p>功能：把 LangChain 工具（BaseTool）封装成一个图节点，负责：</p>
<ul>
<li><p>接收 LLM 生成的工具调用请求</p>
</li>
<li><p>真正执行工具</p>
</li>
<li><p>把结果返回给图</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.prebuilt import ToolNode</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[search, calculator])</span><br></pre></td></tr></table></figure>
<p><strong>tools_condition</strong></p>
<p>功能：判断 LLM 是否要继续调用工具的“路由函数”。</p>
<p>在 ReAct 图里通常放在节点之间的 条件边：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.prebuilt import tools_condition</span><br><span class="line"></span><br><span class="line">graph.add_conditional_edges(&quot;agent&quot;, tools_condition, &#123;</span><br><span class="line"></span><br><span class="line">  &quot;tools&quot;: &quot;tool_node&quot;,    # 需要工具 → 去 ToolNode</span><br><span class="line"></span><br><span class="line">  &quot;**__end__**&quot;: END       # 不需要 → 结束</span><br><span class="line"></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="定义状态"><a href="#定义状态" class="headerlink" title="定义状态"></a>定义状态</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import operator</span><br><span class="line">from typing import Annotated, List, Tuple</span><br><span class="line">from typing_extensions import TypedDict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class PlanExecute(TypedDict):</span><br><span class="line">    input: str</span><br><span class="line">    plan: List[str]</span><br><span class="line">    past_steps: Annotated[List[Tuple], operator.add]</span><br><span class="line">    response: str</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from pydantic import BaseModel, Field</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Plan(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;未来要遵循的计划&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    steps: List[str] = Field(</span><br><span class="line">        description=&quot;需要遵循的不同步骤，应该按排序顺序排列&quot;</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<h4 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_community.chat_models import ChatTongyi</span><br><span class="line">model=ChatTongyi(</span><br><span class="line"> model=&quot;qwen-plus-2025-07-14&quot;,</span><br><span class="line"> api_key=&quot;sk-&quot;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="定义初始计划节点"><a href="#定义初始计划节点" class="headerlink" title="定义初始计划节点"></a>定义初始计划节点</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_core.prompts import ChatPromptTemplate</span><br><span class="line"></span><br><span class="line">planner_prompt = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (</span><br><span class="line">            &quot;system&quot;,</span><br><span class="line">            &quot;&quot;&quot;对于给定的目标，制定一个简单的逐步计划。\</span><br><span class="line">这个计划应该包含独立的任务，如果正确执行这些任务将得到正确的答案。不要添加任何多余的步骤。\</span><br><span class="line">最后一步的结果应该是最终答案。确保每个步骤都包含所需的所有信息——不要跳过任何步骤。&quot;&quot;&quot;,</span><br><span class="line">        ),</span><br><span class="line">        (&quot;placeholder&quot;, &quot;&#123;messages&#125;&quot;),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">planner = planner_prompt | model.with_structured_output(Plan)</span><br><span class="line"></span><br><span class="line">async def plan_step(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;制定初始计划步骤&quot;&quot;&quot;</span><br><span class="line">    # 使用规划器为用户输入制定计划</span><br><span class="line">    plan = await planner.ainvoke(&#123;&quot;messages&quot;: [(&quot;user&quot;, state[&quot;input&quot;])]&#125;)</span><br><span class="line">    </span><br><span class="line">    return &#123;&quot;plan&quot;: plan.steps&#125;</span><br></pre></td></tr></table></figure>
<h4 id="定义再计划节点"><a href="#定义再计划节点" class="headerlink" title="定义再计划节点"></a>定义再计划节点</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from typing import Union</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Response(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;对用户的响应&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    response: str</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Act(BaseModel):</span><br><span class="line">    &quot;&quot;&quot;要执行的动作&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    action: Union[Response, Plan] = Field(</span><br><span class="line">        description=&quot;要执行的动作。如果你想响应用户，使用 Response。&quot;</span><br><span class="line">        &quot;如果你需要进一步使用工具来获取答案，使用 Plan。&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">replanner_prompt = ChatPromptTemplate.from_template(</span><br><span class="line">    &quot;&quot;&quot;对于给定的目标，制定一个简单的逐步计划。\</span><br><span class="line">这个    计划应该包含独立的任务，如果正确执行这些任务将得到正确的答案。不要添加任何多余的步骤。\</span><br><span class="line">最后一步的结果应该是最终答案。确保每个步骤都包含所需的所有信息——不要跳过任何步骤。</span><br><span class="line"></span><br><span class="line">你的目标是：</span><br><span class="line">&#123;input&#125;</span><br><span class="line"></span><br><span class="line">你的原始计划是：</span><br><span class="line">&#123;plan&#125;</span><br><span class="line"></span><br><span class="line">你目前已经完成了以下步骤：</span><br><span class="line">&#123;past_steps&#125;</span><br><span class="line"></span><br><span class="line">相应地更新你的计划。如果不需要更多步骤并且可以返回给用户，则直接响应。否则，填写计划。只添加仍需要完成的步骤到计划中。不要将已经完成的步骤作为计划的一部分返回。&quot;&quot;&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">replanner = replanner_prompt | model.with_structured_output(Act)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def replan_step(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;重新规划步骤&quot;&quot;&quot;</span><br><span class="line">    # 使用重新规划器根据当前状态更新计划</span><br><span class="line">    output = await replanner.ainvoke(state)</span><br><span class="line">    if isinstance(output.action, Response):</span><br><span class="line">        # 如果动作是响应，返回最终响应</span><br><span class="line">        return &#123;&quot;response&quot;: output.action.response&#125;</span><br><span class="line">    else:</span><br><span class="line">        # 如果动作是计划，返回新的计划步骤</span><br><span class="line">        return &#123;&quot;plan&quot;: output.action.steps&#125;</span><br></pre></td></tr></table></figure>
<h4 id="定义路由"><a href="#定义路由" class="headerlink" title="定义路由"></a>定义路由</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def should_end(state: PlanExecute):</span><br><span class="line">    &quot;&quot;&quot;判断是否结束执行流程&quot;&quot;&quot;</span><br><span class="line">    if &quot;response&quot; in state and state[&quot;response&quot;]:</span><br><span class="line">        # 如果存在响应内容，结束流程</span><br><span class="line">        return END</span><br><span class="line">    else:</span><br><span class="line">        # 否则继续执行代理步骤</span><br><span class="line">        return &quot;agent&quot;</span><br></pre></td></tr></table></figure>
<h4 id="编译图"><a href="#编译图" class="headerlink" title="编译图"></a>编译图</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langgraph.graph import StateGraph, START</span><br><span class="line">from langgraph.checkpoint.memory import MemorySaver</span><br><span class="line"></span><br><span class="line"># 创建内存检查点保存器</span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"># 创建工作流图，使用 PlanExecute 状态类型</span><br><span class="line">workflow = StateGraph(PlanExecute)</span><br><span class="line"></span><br><span class="line"># 添加计划节点</span><br><span class="line">workflow.add_node(&quot;planner&quot;, plan_step)</span><br><span class="line"></span><br><span class="line"># 添加执行步骤节点</span><br><span class="line">workflow.add_node(&quot;agent&quot;, execute_step)</span><br><span class="line"></span><br><span class="line"># 添加重新规划节点</span><br><span class="line">workflow.add_node(&quot;replan&quot;, replan_step)</span><br><span class="line"></span><br><span class="line"># 从开始节点连接到计划节点</span><br><span class="line">workflow.add_edge(START, &quot;planner&quot;)</span><br><span class="line"></span><br><span class="line"># 从计划节点连接到代理执行节点</span><br><span class="line">workflow.add_edge(&quot;planner&quot;, &quot;agent&quot;)</span><br><span class="line"></span><br><span class="line"># 从代理执行节点连接到重新规划节点</span><br><span class="line">workflow.add_edge(&quot;agent&quot;, &quot;replan&quot;)</span><br><span class="line"></span><br><span class="line"># 添加条件边 - 从重新规划节点根据条件决定下一步</span><br><span class="line">workflow.add_conditional_edges(</span><br><span class="line">    &quot;replan&quot;,</span><br><span class="line">    # 传入决定下一个调用节点的函数</span><br><span class="line">    should_end,</span><br><span class="line">    [&quot;agent&quot;, END],  # 可能的下一个节点：代理节点或结束</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 最后，编译工作流并添加检查点功能！</span><br><span class="line"># 这将其编译为 LangChain Runnable，</span><br><span class="line"># 意味着你可以像使用其他任何 runnable 一样使用它</span><br><span class="line">app = workflow.compile(checkpointer=memory)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/Plan-and-Execute%E6%A8%A1%E5%BC%8F/image-20250729092408872.png" alt="image-20250729092408872"></p>
<h4 id="调用"><a href="#调用" class="headerlink" title="调用"></a>调用</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 配置递归限制，防止无限循环</span><br><span class="line">config = &#123;&quot;configurable&quot;: &#123;</span><br><span class="line">        &quot;thread_id&quot;: &quot;1&quot;,  # 必需：线程ID</span><br><span class="line">    &#125;,&quot;recursion_limit&quot;: 50&#125;</span><br><span class="line"></span><br><span class="line"># 输入问题：2024年澳大利亚网球公开赛男单冠军的家乡是哪里？</span><br><span class="line">inputs = &#123;&quot;input&quot;: &quot;2024年澳大利亚网球公开赛男单冠军的家乡是哪里？&quot;&#125;</span><br><span class="line"></span><br><span class="line"># 异步流式执行应用</span><br><span class="line">async for event in app.astream(inputs, config=config):</span><br><span class="line">    # 遍历每个事件</span><br><span class="line">    for k, v in event.items():</span><br><span class="line">        # 排除结束标记，打印其他所有事件内容</span><br><span class="line">        if k != &quot;__end__&quot;:</span><br><span class="line">            print(v)</span><br></pre></td></tr></table></figure>
<h3 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h3><p><a href="https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute/">计划与执行 —- Plan-and-Execute</a></p>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title>redis存储状态</title>
    <url>/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/</url>
    <content><![CDATA[<h3 id="为什么用redis"><a href="#为什么用redis" class="headerlink" title="为什么用redis"></a>为什么用redis</h3><p>Redis通过 RedisSessionManager 类来管理用户会话，存储结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">session:&#123;user_id&#125; -&gt; &#123;</span><br><span class="line">  &quot;session_id&quot;: &quot;会话ID&quot;,</span><br><span class="line">  &quot;status&quot;: &quot;idle|running|interrupted|completed|error&quot;,</span><br><span class="line">  &quot;last_response&quot;: &quot;上次智能体响应&quot;,</span><br><span class="line">  &quot;last_query&quot;: &quot;用户上次查询&quot;,</span><br><span class="line">  &quot;last_updated&quot;: &quot;最后更新时间戳&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/image-20250809232853613.png" alt="image-20250809232853613"></p>
<p>主要功能</p>
<ul>
<li>会话创建与维护 ：为每个用户创建唯一会话，支持会话超时自动清理</li>
<li>状态跟踪 ：实时跟踪智能体执行状态（空闲、运行中、中断、完成、错误）</li>
<li>中断恢复支持 ：当智能体需要人工干预时，Redis保存中断状态，支持后续恢复执行</li>
<li>用户管理 ：统计活跃用户数量，管理多用户并发访问</li>
</ul>
<p>与PostgreSQL的分工</p>
<ul>
<li>Redis ：负责临时会话状态和实时数据（快速读写）</li>
<li>PostgreSQL ：负责智能体的长期记忆存储（通过LangGraph的checkpointer）</li>
</ul>
<blockquote>
<p>为什么不使用pgsql完成对状态的存储</p>
<p>频繁读写 ：会话状态需要频繁更新（每次请求都要更新状态），PostgreSQL的磁盘I/O比Redis内存操作慢很多4</p>
<p>短期记忆（PostgreSQL + LangGraph Checkpointer）</p>
<p>临时状态记忆（Redis）</p>
</blockquote>
<h3 id="redis实现状态存储业务逻辑总览图"><a href="#redis实现状态存储业务逻辑总览图" class="headerlink" title="redis实现状态存储业务逻辑总览图"></a>redis实现状态存储业务逻辑总览图</h3><p><img src="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/image-20250806164348663.png" alt="image-20250806164348663"></p>
<p>使用redis的根本逻辑：存储对话的状态，当出现由工具调用或者客户端崩溃导致的中断时，可以存储状态在redis，在开始对话时，通过session_id获取redis的状态，并根据状态判断是要恢复中断还是正常对话</p>
<p>存储的redis（调用invoke<em>agent接口）：开始（创建）对话时要根据会话user<em>id获取或创建redis；再调用agent后，根据响应是否存在<strong>status</strong>字段是否是”__interrupt</em></em>“，判断是否有终端，最后更新redis状态</p>
<p>恢复的redis（调用resume_agent接口）：获取redis状态，并根据请求的恢复内容，使用Command命令恢复agent，最后更新redis</p>
<p><img src="/2025/08/06/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/redis%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/image-20250809233037563.png" alt="image-20250809233037563"></p>
<h3 id="redis类"><a href="#redis类" class="headerlink" title="redis类"></a>redis类</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 初始化异步 Redis 连接和会话配置</span><br><span class="line">def __init__(self, redis_host, redis_port, redis_db, session_timeout):</span><br><span class="line">    self.redis_client = redis.Redis(</span><br><span class="line">        host=redis_host,</span><br><span class="line">        port=redis_port,</span><br><span class="line">        db=redis_db,</span><br><span class="line">        decode_responses=True</span><br><span class="line">    )</span><br><span class="line">    self.session_timeout = session_timeout  # 会话过期时间（秒）</span><br><span class="line"></span><br><span class="line"># 关闭 Redis 连接</span><br><span class="line">async def close(self):</span><br><span class="line">    await self.redis_client.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法名</th>
<th>作用</th>
<th>输入参数</th>
<th>返回值</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>__init__</code></td>
<td>建立与 Redis 的异步连接并设置会话超时</td>
<td><code>redis_host</code>, <code>redis_port</code>, <code>redis_db</code>, <code>session_timeout</code></td>
<td>-</td>
<td><code>decode_responses=True</code> 使 Redis 返回字符串而非字节</td>
</tr>
<tr>
<td><code>close</code></td>
<td>优雅关闭 Redis 连接</td>
<td>-</td>
<td>-</td>
<td>异步方法，需 <code>await</code></td>
</tr>
<tr>
<td><code>create_session</code></td>
<td>为指定用户新建（或覆盖）会话记录</td>
<td><code>user_id</code>, 可选 <code>session_id</code>, <code>status</code>, <code>last_query</code>, <code>last_response</code>, <code>last_updated</code></td>
<td><code>str</code>：生成的 <code>session_id</code></td>
<td>会话键格式：<code>session:&#123;user_id&#125;</code>；过期时间为 <code>session_timeout</code></td>
</tr>
<tr>
<td><code>get_session</code></td>
<td>读取指定用户的完整会话字典</td>
<td><code>user_id</code></td>
<td><code>dict</code> 或 <code>None</code></td>
<td>自动将 JSON 里的 <code>last_response</code> 反序列化为 <code>AgentResponse</code> 对象</td>
</tr>
<tr>
<td><code>update_session</code></td>
<td>增量更新已有会话的字段</td>
<td><code>user_id</code>, 可选 <code>status</code>, <code>last_query</code>, <code>last_response</code>, <code>last_updated</code></td>
<td><code>bool</code>：<code>True</code> 更新成功，<code>False</code> 用户不存在</td>
<td>更新后刷新过期时间</td>
</tr>
<tr>
<td><code>delete_session</code></td>
<td>删除单个用户的会话</td>
<td><code>user_id</code></td>
<td><code>bool</code>：<code>True</code> 删除成功</td>
<td>直接删除 <code>session:&#123;user_id&#125;</code></td>
</tr>
<tr>
<td><code>get_session_count</code></td>
<td>计算当前活跃会话总数</td>
<td>-</td>
<td><code>int</code></td>
<td>使用异步扫描 <code>session:*</code> 键空间</td>
</tr>
<tr>
<td><code>get_all_user_ids</code></td>
<td>取出所有已创建会话的 <code>user_id</code></td>
<td>-</td>
<td><code>List[str]</code></td>
<td>同样基于 <code>session:*</code> 扫描</td>
</tr>
<tr>
<td><code>user_id_exists</code></td>
<td>快速判断某用户是否已有会话</td>
<td><code>user_id</code></td>
<td><code>bool</code></td>
<td>利用 <code>EXISTS</code> 命令</td>
</tr>
</tbody>
</table>
</div>
<h3 id="安装redis"><a href="#安装redis" class="headerlink" title="安装redis"></a>安装redis</h3><h4 id="linux系统"><a href="#linux系统" class="headerlink" title="linux系统"></a>linux系统</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install -y redis-server</span><br><span class="line"># 启动 Redis 服务</span><br><span class="line">sudo service redis-server start</span><br><span class="line"># 检查 Redis 服务状态</span><br><span class="line">sudo service redis-server status</span><br></pre></td></tr></table></figure>
<h4 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Docker Compose 配置文件，用于启动 Redis 服务</span><br><span class="line"># 该配置为 FastAPI 应用提供 Redis 后端，支持分布式会话管理</span><br><span class="line">version: &#x27;3.8&#x27;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  redis:</span><br><span class="line">    # 使用官方 Redis 镜像</span><br><span class="line">    image: redis:latest</span><br><span class="line">    # 服务名称</span><br><span class="line">    container_name: redis</span><br><span class="line">    # 映射 Redis 默认端口到主机</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;6379:6379&quot;</span><br><span class="line">    # 持久化存储配置（可选）</span><br><span class="line">    volumes:</span><br><span class="line">      - redis-data:/data</span><br><span class="line">    # 确保容器在重启时自动启动</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    # 健康检查：验证 Redis 服务是否正常运行</span><br><span class="line">    healthcheck:</span><br><span class="line">      test: [&quot;CMD&quot;, &quot;redis-cli&quot;, &quot;ping&quot;]</span><br><span class="line">      interval: 30s</span><br><span class="line">      timeout: 10s</span><br><span class="line">      retries: 3</span><br><span class="line">      start_period: 10s</span><br><span class="line">    # 网络配置</span><br><span class="line">    networks:</span><br><span class="line">      - app-network</span><br><span class="line"></span><br><span class="line"># 定义持久化存储卷</span><br><span class="line">volumes:</span><br><span class="line">  redis-data:</span><br><span class="line">    name: redis-data</span><br><span class="line"></span><br><span class="line"># 定义网络</span><br><span class="line">networks:</span><br><span class="line">  app-network:</span><br><span class="line">    driver: bridge</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>agent</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>储存向量数据库Chroma</title>
    <url>/2025/07/31/%E5%AD%A6%E4%B9%A0/agent%E5%AE%9E%E6%88%98/%E5%82%A8%E5%AD%98%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93Chroma/</url>
    <content><![CDATA[<h3 id="Chroma是什么"><a href="#Chroma是什么" class="headerlink" title="Chroma是什么"></a>Chroma是什么</h3><p>Chroma（通常指 <strong>ChromaDB</strong>）是一款 <strong>开源、AI 原生的向量数据库</strong>，专为存储和检索 <strong>高维嵌入向量</strong> 而设计，目标是让开发者 <strong>5 分钟内在本地跑起一个语义搜索或 RAG 系统</strong>。</p>
<p><strong>极简安装</strong>：<code>pip install chromadb</code></p>
<p><strong>双运行模式</strong>：</p>
<ul>
<li><strong>内存模式</strong>：调试/原型随意重启；</li>
<li><strong>持久化模式</strong>：指定 <code>persist_directory</code> 即可落盘，生产也不怕丢数据。</li>
</ul>
<p><strong>HNSW 索引</strong>：百万级向量也能 <strong>毫秒级</strong> 响应。</p>
<h3 id="使用chroma存储"><a href="#使用chroma存储" class="headerlink" title="使用chroma存储"></a>使用chroma存储</h3><h4 id="文档分块"><a href="#文档分块" class="headerlink" title="文档分块"></a>文档分块</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.document_loaders import PyPDFLoader</span><br><span class="line">from langchain.text_splitter import RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">loader = PyPDFLoader(&quot;input/健康档案.pdf&quot;)</span><br><span class="line">docs = loader.load()</span><br><span class="line">#递归分块</span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_siz</span><br></pre></td></tr></table></figure>
<h4 id="定义embedding模型与chroma"><a href="#定义embedding模型与chroma" class="headerlink" title="定义embedding模型与chroma"></a>定义embedding模型与chroma</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">from langchain.vectorstores import Chroma</span><br><span class="line">from langchain_openai import OpenAIEmbeddings</span><br><span class="line">embedding = OpenAIEmbeddings(</span><br><span class="line">api_key=&quot;sk-&quot;, </span><br><span class="line">base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">model=&quot;text-embedding-v4&quot;,</span><br><span class="line">check_embedding_ctx_length = False,</span><br><span class="line">dimensions=1536</span><br><span class="line">)</span><br><span class="line"># 使用 Chroma 向量数据库存储文档 chunks</span><br><span class="line">vectorstore = Chroma.from_documents(</span><br><span class="line">    documents=chunks,           # 要存储的文档chunks列表（已处理好的文本片段）</span><br><span class="line">    embedding=embedding,        </span><br><span class="line">    persist_directory=&quot;chromaDB&quot;,  # 向量数据库的持久化存储目录路径</span><br><span class="line">    collection_name=&quot;demo001&quot;   # 集合名称，用于区分不同的文档集合</span><br><span class="line">)</span><br><span class="line">vectorstore.persist()</span><br></pre></td></tr></table></figure>
<h4 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h4><p>这里采取直接检索进行测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">results = vectorstore.similarity_search(</span><br><span class="line">    &quot;张三九的基本信息是什么&quot;,</span><br><span class="line">    k=2,</span><br><span class="line">    collection_name=&quot;demo001&quot;  # 指定检索的集合</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://python.langchain.com/docs/integrations/vectorstores/chroma/#add-items-to-vector-store">Chroma | 🦜️🔗 LangChain —- Chroma | 🦜️🔗 LangChain</a></p>
]]></content>
      <categories>
        <category>agent实战</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>agent</tag>
        <tag>Chroma</tag>
      </tags>
  </entry>
  <entry>
    <title>初识git</title>
    <url>/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/</url>
    <content><![CDATA[<h2 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h2><p>Git是目前世界上最先进的分布式版本控制系统，没有之一！说到Git,另一个需要知道的便是GitHub，GitHub是目前使用最多的社交代码托管平台。</p>
<p>输入git —version 查看Git版本信息</p>
<p>配置本地信息<br>为了在后面上传项目到github时方便知道是谁上传的，需要给本机git配置用户名和邮箱：</p>
<p>git config —global user.name “zxj”<br>git config —global user.email “zxj2902065320@163.com”<br><strong>查看配置命令：git config —list</strong></p>
<p><strong>配置SSH</strong></p>
<p>ssh key生成命令<code>ssh-keygen -t rsa -C “注册邮箱”</code></p>
<p>获取ssh key公钥内容（id_rsa.pub）<code>cd ~/.ssh       cat id_rsa.pub</code></p>
<p>Github账号上添加公钥</p>
<p>验证是否配置成功 <code>ssh -T git@github.com</code></p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>在检验ssh配置时，始终报错，问ai说是配置的原因，尝试删除后，报错<code>Could not resolve hostname github.com: Name or service not known</code>，琢磨无法解决，拼尽全力无法战胜，于是保留下来交给未来的自己</p>
<p><img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311172436506.png" alt="image-20250311172436506"></p>
<h2 id="git常用指令"><a href="#git常用指令" class="headerlink" title="git常用指令"></a>git常用指令</h2><p>克隆仓库git clone <a href="https://github.com/logan-zou/Chat_with_Datawhale_langchain.git">https://github.com/logan-zou/Chat_with_Datawhale_langchain.git</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git init：初始化一个git仓库</span><br><span class="line">git clone：clone一个git仓库</span><br><span class="line">git add 命令可将文件添加到缓存</span><br><span class="line">git status 命令来查看相关文件的状态</span><br><span class="line">git commit 将缓存区内容添加到仓库中，可以在后面加-m选项，以在命令行中提供提交注释</span><br><span class="line"></span><br><span class="line">git remote add：添加远程仓库</span><br><span class="line">git remote：查看当前的远程仓库</span><br><span class="line">git fetch、git pull：提取远程仓仓库</span><br><span class="line">git push：推送到远程仓库</span><br><span class="line">git remote rm：删除远程仓库</span><br></pre></td></tr></table></figure>
<p>先做记录，我没用过，我目前选择vscode+GitHub的可视化界面</p>
<h2 id="vscode-GitHub"><a href="#vscode-GitHub" class="headerlink" title="vscode+GitHub"></a>vscode+GitHub</h2><p><img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311173501909.png" alt="image-20250311173501909"></p>
<p>输入仓库名称 点击commit提交</p>
<p><img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311174519221.png" alt="image-20250311174519221"></p>
<p>每次更改代码都可以命名后再次提交</p>
<p>代理配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global http.proxy &quot;http://127.0.0.1:8080&quot; </span><br><span class="line">git config --global https.proxy &quot;http://127.0.0.1:8080&quot;</span><br></pre></td></tr></table></figure>
<p><img src="/2025/03/09/%E5%AD%A6%E4%B9%A0/git/%E5%88%9D%E8%AF%86git/image-20250311175047287.png" alt="image-20250311175047287"></p>
<p>分别代码本地和远程仓库的位置</p>
<p>天呐这图形化太方便了</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://blog.csdn.net/weixin_44406127/article/details/137540031">git安装配置教程(小白保姆教程2024最新版)_git安装及配置教程-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1Hkr7YYEh8/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">给傻子的Git教程_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/qq_36667170/article/details/79085301">Git教程 Git Bash详细教程-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/HD243608836/article/details/127869482">GIT Proxy 一键设置代理 让你的 git clone Github 再也不像百度云一样内行-CSDN博客</a></p>
]]></content>
      <categories>
        <category>开发工具</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP 学习笔记</title>
    <url>/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h3 id="什么是-MCP？"><a href="#什么是-MCP？" class="headerlink" title="什么是 MCP？"></a>什么是 MCP？</h3><ul>
<li><strong>全称</strong>：Model Context Protocol</li>
<li><strong>作用</strong>：让 AI 助手（如 Claude、Cline 等）在对话过程中，动态调用外部工具（Tool）完成复杂任务（读写文件、查询数据库、调用 API 等）。</li>
<li><strong>组成</strong>：<ol>
<li><strong>MCP Host</strong>（宿主，如 Cline、Claude Desktop）</li>
<li><strong>MCP Server</strong>（提供 Tool 的后台服务）</li>
<li><strong>Tool</strong>（具体功能单元，如 <code>read_file</code>, <code>exec_command</code> 等）</li>
</ol>
</li>
</ul>
<h3 id="核心概念速记"><a href="#核心概念速记" class="headerlink" title="核心概念速记"></a>核心概念速记</h3><ul>
<li><strong>MCP Server</strong><ul>
<li>一个独立进程，提供 1-N 个 Tool。</li>
<li>可以用任何语言编写，只要暴露标准 MCP 接口。</li>
</ul>
</li>
<li><strong>Tool</strong><ul>
<li>最小执行单元，必须包含：<ul>
<li>name（唯一）</li>
<li>description（让 LLM 理解何时调用）</li>
<li>input schema（参数结构，JSON Schema）</li>
</ul>
</li>
</ul>
</li>
<li><strong>交互流程（重点）</strong><ul>
<li>在启动mcp server时，server将tool信息传送给host</li>
<li>用户在 Host 输入自然语言需求。</li>
<li>Host 将需求 + 可用 Tool 列表发给 LLM。</li>
<li>LLM 判断调用哪个 Tool，并填充参数。</li>
<li>Host 通过 MCP 协议向对应 Server 发送请求。</li>
<li>Server 执行 Tool 并返回结果。</li>
<li>Host 将结果合并上下文，继续对话。</li>
</ul>
</li>
</ul>
<h3 id="安装mcp"><a href="#安装mcp" class="headerlink" title="安装mcp"></a>安装mcp</h3><p>在mcp server市场查找自己想用的mcp服务，如<a href="https://mcp.so/server/fetch/modelcontextprotocol?tab=content">Fetch MCP Server</a></p>
<p>复制mcp配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;mcpServers&quot;: &#123;</span><br><span class="line">    &quot;fetch&quot;: &#123;</span><br><span class="line">      &quot;command&quot;: &quot;uvx&quot;,</span><br><span class="line">      &quot;args&quot;: [</span><br><span class="line">        &quot;mcp-server-fetch&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在mcp host 中安装，如trae</p>
<p>host会自动完成对mcp的配置</p>
<h3 id="创建一个mcp-server"><a href="#创建一个mcp-server" class="headerlink" title="创建一个mcp server"></a>创建一个mcp server</h3><p>初始化项目</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uv init weather</span><br><span class="line"></span><br><span class="line">uv sync</span><br><span class="line"></span><br><span class="line">source .venv/bin/activate </span><br><span class="line"></span><br><span class="line">#添加依赖</span><br><span class="line">uv add &quot;mcp[cli]&quot; httpx</span><br></pre></td></tr></table></figure>
<p>创建weather.py</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 导入类型提示模块，用于类型注解</span><br><span class="line">from typing import Any</span><br><span class="line"></span><br><span class="line"># 导入httpx库，用于发送HTTP请求</span><br><span class="line">import httpx</span><br><span class="line"></span><br><span class="line"># 从mcp.server.fastmcp模块导入FastMCP类</span><br><span class="line"># FastMCP是一个快速构建MCP（Model Control Protocol）服务器的框架</span><br><span class="line">from mcp.server.fastmcp import FastMCP</span><br><span class="line"></span><br><span class="line"># 创建FastMCP实例，命名为&quot;weather&quot;，日志级别设置为ERROR（只显示错误信息）</span><br><span class="line">mcp = FastMCP(&quot;weather&quot;, log_level=&quot;ERROR&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 常量定义</span><br><span class="line"># NWS（National Weather Service）API的基础URL</span><br><span class="line">NWS_API_BASE = &quot;https://api.weather.gov&quot;</span><br><span class="line"># 用户代理字符串，用于标识应用程序</span><br><span class="line">USER_AGENT = &quot;weather-app/1.0&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">async def make_nws_request(url: str) -&gt; dict[str, Any] | None:</span><br><span class="line">    &quot;&quot;&quot;向NWS API发起请求并处理错误。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        url: 要请求的API URL</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        成功时返回解析后的JSON数据字典，失败时返回None</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 设置请求头信息</span><br><span class="line">    headers = &#123;</span><br><span class="line">        &quot;User-Agent&quot;: USER_AGENT,           # 用户代理标识</span><br><span class="line">        &quot;Accept&quot;: &quot;application/geo+json&quot;    # 接受的数据格式</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    # 创建异步HTTP客户端</span><br><span class="line">    async with httpx.AsyncClient() as client:</span><br><span class="line">        try:</span><br><span class="line">            # 发起GET请求，设置超时时间为30秒</span><br><span class="line">            response = await client.get(url, headers=headers, timeout=30.0)</span><br><span class="line">            # 如果响应状态码不是2xx，抛出异常</span><br><span class="line">            response.raise_for_status()</span><br><span class="line">            # 返回解析后的JSON数据</span><br><span class="line">            return response.json()</span><br><span class="line">        except Exception:</span><br><span class="line">            # 捕获所有异常，返回None表示请求失败</span><br><span class="line">            return None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def format_alert(feature: dict) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;将警报数据格式化为可读的字符串。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        feature: 包含警报信息的字典</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的警报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 获取警报属性</span><br><span class="line">    props = feature[&quot;properties&quot;]</span><br><span class="line">    # 格式化警报信息，使用get方法提供默认值防止键不存在</span><br><span class="line">    return f&quot;&quot;&quot;</span><br><span class="line">事件: &#123;props.get(&#x27;event&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">区域: &#123;props.get(&#x27;areaDesc&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">严重程度: &#123;props.get(&#x27;severity&#x27;, &#x27;未知&#x27;)&#125;</span><br><span class="line">描述: &#123;props.get(&#x27;description&#x27;, &#x27;无描述信息&#x27;)&#125;</span><br><span class="line">指示: &#123;props.get(&#x27;instruction&#x27;, &#x27;无具体指示&#x27;)&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 使用@mcp.tool()装饰器将函数注册为MCP工具</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_alerts(state: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定美国州的天气警报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        state: 两个字母的美国州代码（例如：CA, NY）</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的警报信息字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 构建获取州警报的URL</span><br><span class="line">    url = f&quot;&#123;NWS_API_BASE&#125;/alerts/active/area/&#123;state&#125;&quot;</span><br><span class="line">    # 发起API请求获取数据</span><br><span class="line">    data = await make_nws_request(url)</span><br><span class="line"></span><br><span class="line">    # 检查数据是否有效</span><br><span class="line">    if not data or &quot;features&quot; not in data:</span><br><span class="line">        return &quot;无法获取警报或未找到警报。&quot;</span><br><span class="line"></span><br><span class="line">    # 检查是否有警报</span><br><span class="line">    if not data[&quot;features&quot;]:</span><br><span class="line">        return &quot;该州无活动警报。&quot;</span><br><span class="line"></span><br><span class="line">    # 格式化所有警报</span><br><span class="line">    alerts = [format_alert(feature) for feature in data[&quot;features&quot;]]</span><br><span class="line">    # 用分隔符连接所有警报</span><br><span class="line">    return &quot;\n---\n&quot;.join(alerts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 注册为MCP工具的天气预报函数</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_forecast(latitude: float, longitude: float) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定位置的天气预报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        latitude: 位置的纬度</span><br><span class="line">        longitude: 位置的经度</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的天气预报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 首先获取预报网格端点</span><br><span class="line">    points_url = f&quot;&#123;NWS_API_BASE&#125;/points/&#123;latitude&#125;,&#123;longitude&#125;&quot;</span><br><span class="line">    points_data = await make_nws_request(points_url)</span><br><span class="line"></span><br><span class="line">    # 检查点数据是否获取成功</span><br><span class="line">    if not points_data:</span><br><span class="line">        return &quot;无法获取此位置的预报数据。&quot;</span><br><span class="line"></span><br><span class="line">    # 从点响应中获取预报URL</span><br><span class="line">    forecast_url = points_data[&quot;properties&quot;][&quot;forecast&quot;]</span><br><span class="line">    forecast_data = await make_nws_request(forecast_url)</span><br><span class="line"></span><br><span class="line">    # 检查预报数据是否获取成功</span><br><span class="line">    if not forecast_data:</span><br><span class="line">        return &quot;无法获取详细预报。&quot;</span><br><span class="line"></span><br><span class="line">    # 将时间段格式化为可读的预报</span><br><span class="line">    periods = forecast_data[&quot;properties&quot;][&quot;periods&quot;]</span><br><span class="line">    forecasts = []</span><br><span class="line">    # 只显示接下来的5个时间段</span><br><span class="line">    for period in periods[:5]:</span><br><span class="line">        forecast = f&quot;&quot;&quot;</span><br><span class="line">&#123;period[&#x27;name&#x27;]&#125;:</span><br><span class="line">温度: &#123;period[&#x27;temperature&#x27;]&#125;°&#123;period[&#x27;temperatureUnit&#x27;]&#125;</span><br><span class="line">风力: &#123;period[&#x27;windSpeed&#x27;]&#125; &#123;period[&#x27;windDirection&#x27;]&#125;</span><br><span class="line">预报: &#123;period[&#x27;detailedForecast&#x27;]&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">        forecasts.append(forecast)</span><br><span class="line"></span><br><span class="line">    # 用分隔符连接所有预报</span><br><span class="line">    return &quot;\n---\n&quot;.join(forecasts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 初始化并运行服务器，使用stdio传输方式</span><br><span class="line">    mcp.run(transport=&#x27;stdio&#x27;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>@mcp.tool()可以将函数内的字符串，参数类型等信息传给大模型，以供大模型决定何时调用这个tool</p>
<p>mcp.run(transport=’stdio’)说明mcp server和host的传输方式是输入和输出</p>
</blockquote>
<p>mcp server 配置信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;weather&quot;: &#123;</span><br><span class="line">    &quot;disabled&quot;: false,</span><br><span class="line">    &quot;timeout&quot;: 60,</span><br><span class="line">    &quot;command&quot;: &quot;uv&quot;,</span><br><span class="line">    &quot;args&quot;: [</span><br><span class="line">      &quot;--directory&quot;,</span><br><span class="line">      &quot;/Users/joeygreen/PycharmProjects/weather&quot;,</span><br><span class="line">      &quot;run&quot;,</span><br><span class="line">      &quot;weather.py&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;transportType&quot;: &quot;stdio&quot;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>“disabled”: false表示该服务是否被禁用。<code>false</code> 表示该服务是启用状态，可以正常运行。</p>
<p>“timeout”: 60设置该服务的超时时间，单位为秒。</p>
<p>“command”: “uv”指定执行该服务时使用的命令。</p>
<p>“args”出了执行 <code>command</code> 时需要传递的参数。</p>
<p>“transportType”: “stdio”指定服务的通信方式。<code>stdio</code> 表示标准输入输出流（Standard Input Output），通常用于进程间通信。</p>
</blockquote>
<h3 id="解析mcp-server与host的通信"><a href="#解析mcp-server与host的通信" class="headerlink" title="解析mcp server与host的通信"></a>解析mcp server与host的通信</h3><p><img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727154739013.png" alt="image-20250727154739013"></p>
<p>输入为host对server发送，输出为server对host发送，以下将列举几个重要的说明</p>
<p>输入中：<code>method</code>字段为host告诉server接下来要干什么，如<strong>初始化 (Initialization)</strong>，<strong>通知已初始化 (Notification)</strong>，<strong>查询可用工具 (Listing Tools)</strong>，<strong>调用工具 (Calling a Tool)</strong></p>
<p><code>protocolVersion</code>说明了mcp使用的协议版本</p>
<p>以下见server返回的tool信息，其中的一个参数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;name&quot;: &quot;get_forecast&quot;,</span><br><span class="line">    &quot;description&quot;: &quot;Get weather forecast for a location.\n\nArgs:\n    latitude: Latitude of the location\n    longitude: Longitude of the location\n&quot;,</span><br><span class="line">    &quot;inputSchema&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;latitude&quot;: &#123;</span><br><span class="line">                &quot;title&quot;: &quot;Latitude&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;number&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;longitude&quot;: &#123;</span><br><span class="line">                &quot;title&quot;: &quot;Longitude&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;number&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;required&quot;: [</span><br><span class="line">            &quot;latitude&quot;,</span><br><span class="line">            &quot;longitude&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;title&quot;: &quot;get_forecastArguments&quot;,</span><br><span class="line">        &quot;type&quot;: &quot;object&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以和定义的函数对比学习</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 注册为MCP工具的天气预报函数</span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_forecast(latitude: float, longitude: float) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;获取指定位置的天气预报。</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        latitude: 位置的纬度</span><br><span class="line">        longitude: 位置的经度</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        格式化后的天气预报字符串</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 首先获取预报网格端点</span><br><span class="line">    points_url = f&quot;&#123;NWS_API_BASE&#125;/points/&#123;latitude&#125;,&#123;longitude&#125;&quot;</span><br><span class="line">    points_data = await make_nws_request(points_url)</span><br><span class="line"></span><br><span class="line">    # 检查点数据是否获取成功</span><br><span class="line">    if not points_data:</span><br><span class="line">        return &quot;无法获取此位置的预报数据。&quot;</span><br><span class="line"></span><br><span class="line">    # 从点响应中获取预报URL</span><br><span class="line">    forecast_url = points_data[&quot;properties&quot;][&quot;forecast&quot;]</span><br><span class="line">    forecast_data = await make_nws_request(forecast_url)</span><br><span class="line"></span><br><span class="line">    # 检查预报数据是否获取成功</span><br><span class="line">    if not forecast_data:</span><br><span class="line">        return &quot;无法获取详细预报。&quot;</span><br><span class="line"></span><br><span class="line">    # 将时间段格式化为可读的预报</span><br><span class="line">    periods = forecast_data[&quot;properties&quot;][&quot;periods&quot;]</span><br><span class="line">    forecasts = []</span><br><span class="line">    # 只显示接下来的5个时间段</span><br><span class="line">    for period in periods[:5]:</span><br><span class="line">        forecast = f&quot;&quot;&quot;</span><br><span class="line">&#123;period[&#x27;name&#x27;]&#125;:</span><br><span class="line">温度: &#123;period[&#x27;temperature&#x27;]&#125;°&#123;period[&#x27;temperatureUnit&#x27;]&#125;</span><br><span class="line">风力: &#123;period[&#x27;windSpeed&#x27;]&#125; &#123;period[&#x27;windDirection&#x27;]&#125;</span><br><span class="line">预报: &#123;period[&#x27;detailedForecast&#x27;]&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">        forecasts.append(forecast)</span><br><span class="line"></span><br><span class="line">    # 用分隔符连接所有预报</span><br><span class="line">    return &quot;\n---\n&quot;.join(forecasts)</span><br></pre></td></tr></table></figure>
<p><code>description</code>内容即为我们在定义这个tool的时候写的<strong>文档字符串</strong>（Documentation String），通常简称为 <strong>docstring</strong></p>
<p><code>inputSchema</code> 是在MCP（Model Control Protocol）中用来<strong>描述工具（tool）所需参数的结构和类型的规范</strong>。它本质上是一个JSON Schema。</p>
<blockquote>
<p>JSON Schema 是一个用于<strong>描述和验证 JSON 数据结构的规范</strong>。你可以把它理解为 JSON 数据的“蓝图”或“模板”。</p>
</blockquote>
<p><code>required</code>指明哪些参数是必需的，哪些是可选的。</p>
<h3 id="理解mcp的本质"><a href="#理解mcp的本质" class="headerlink" title="理解mcp的本质"></a>理解mcp的本质</h3><p>以上内容皆是server与host直接的交互，本质上可以理解成host对server提供的工具进行注册与使用。这其中并不涉及到host与大模型的交互，也就是大模型是如何使用host提供的信息。实际上不同的mcp host与模型的交互协议也不同，如cline使用的是xml格式；cherry studio使用的则是fuction calling</p>
<p>再看mcp的全称Model Context Protocol，模型上下文协议，也就是mcp增加模型的扩展性，使他可以获取更多信息，而server就是为模型提供更多信息的工具</p>
<h3 id="mcp-host与模型的交互"><a href="#mcp-host与模型的交互" class="headerlink" title="mcp host与模型的交互"></a>mcp host与模型的交互</h3><p>使用中转服务器截获日志</p>
<p><img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727163811531-1753605912284-1.png" alt="image-20250727163811531"></p>
<p>以下为cline发送给模型的请求</p>
<p><img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727164527797.png" alt="image-20250727164527797"></p>
<p><code>messages</code>包含了系统提示词与用户输入</p>
<p>先来看系统提示词，cline提供的提示词包括工具使用格式，工具信息，工具使用方法等。这里重点说一下，cline的工具使用格式xml</p>
<p>结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;tool_name&gt;</span><br><span class="line">&lt;parameter1_name&gt;value1&lt;/parameter1_name&gt;</span><br><span class="line">&lt;parameter2_name&gt;value2&lt;/parameter2_name&gt;</span><br><span class="line">...</span><br><span class="line">&lt;/tool_name&gt;</span><br></pre></td></tr></table></figure>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;read_file&gt;</span><br><span class="line">src/main.js</span><br><span class="line">&lt;/read_file&gt;</span><br></pre></td></tr></table></figure>
<p>再举个例子</p>
<p>use_mcp_tool<br>描述：请求使用由连接的 MCP 服务器提供的工具。每个 MCP 服务器可以提供具有不同功能的多个工具。工具有定义的输入模式，用于指定必需和可选参数。<br>参数：</p>
<p>server_name: (必需) 提供该工具的 MCP 服务器的名称<br>tool_name: (必需) 要执行的工具的名称<br>arguments: (必需) 一个 JSON 对象，包含工具的输入参数，遵循工具的输入模式<br>用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;use_mcp_tool&gt;</span><br><span class="line">&lt;server_name&gt;服务器名称在此&lt;/server_name&gt;</span><br><span class="line">&lt;tool_name&gt;工具名称在此&lt;/tool_name&gt;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">&quot;param1&quot;: &quot;value1&quot;,</span><br><span class="line">&quot;param2&quot;: &quot;value2&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&lt;/use_mcp_tool&gt;</span><br></pre></td></tr></table></figure>
<p>模型返回响应如下</p>
<p><img src="/2025/07/27/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/MCP%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20250727174504506.png" alt="image-20250727174504506"></p>
<p>sse连接，流式输出</p>
<blockquote>
<p>SSE 是一种<strong>基于标准 HTTP</strong>、<strong>只允许服务器向客户端单向推送文本流</strong>的实时通信技术，浏览器原生支持，自动重连，常用于<strong>AI 流式回答</strong>、<strong>实时日志</strong>、<strong>股价/监控推送</strong>等场景。</p>
<p>即客户端发送一次请求，连续接受多次响应直到结束</p>
</blockquote>
<h3 id="mcp的三种传输协议"><a href="#mcp的三种传输协议" class="headerlink" title="mcp的三种传输协议"></a>mcp的三种传输协议</h3><div class="table-container">
<table>
<thead>
<tr>
<th>协议名称</th>
<th>通信方式</th>
<th>适用场景</th>
<th>优势</th>
<th>局限</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Stdio</strong>（标准输入输出）</td>
<td>使用进程的标准输入（stdin）和标准输出（stdout）进行本地通信，基于 JSON-RPC 2.0 格式</td>
<td>本地开发、调试、IDE插件、命令行工具</td>
<td>简单易实现、跨平台、低延迟</td>
<td>仅支持本地通信，无法跨网络，低并发</td>
</tr>
<tr>
<td><strong>SSE</strong>（Server-Sent Events）</td>
<td>客户端通过 HTTP POST 发送请求，服务器通过 SSE 单向推送流式响应</td>
<td>实时监控、新闻推送、远程服务调用</td>
<td>基于 HTTP，浏览器友好，支持流式数据</td>
<td>仅支持单向通信，MCP官方已标记为“即将废弃”</td>
</tr>
<tr>
<td><strong>Streamable HTTP</strong>（新型流式HTTP）</td>
<td>支持双向流式通信的现代 HTTP 协议，替代 SSE，支持会话恢复、OAuth 认证等</td>
<td>分布式系统、高并发、双向实时交互</td>
<td>双向通信、高性能、企业级安全机制</td>
<td>实现较复杂，生态仍在发展中</td>
</tr>
</tbody>
</table>
</div>
<h3 id="ReAct"><a href="#ReAct" class="headerlink" title="ReAct"></a>ReAct</h3><p>ReAct 是一种用于增强大型语言模型（LLMs）推理和行动能力的技术框架，它通过结合“推理”（Reasoning）和“行动”（Acting）来提升模型处理复杂任务的能力。</p>
<p>其工作流程通常包括以下几个步骤：</p>
<ol>
<li><strong>思考（Reasoning）</strong>：模型对当前问题进行分析，思考下一步需要采取的行动。</li>
<li><strong>行动（Acting）</strong>：模型决定调用哪些工具或函数，并提供必要的参数。</li>
<li><strong>观察（Observation）</strong>：工具执行后返回结果，模型对结果进行观察。</li>
<li><strong>响应（Response）</strong>：根据观察结果，模型生成最终的用户响应。</li>
</ol>
<p>实际应用上就是告诉大模型用ReAct这种模式来思考</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.bilibili.com/video/BV1uronYREWR?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">MCP终极指南 - 从原理到实战，带你深入掌握MCP（基础篇）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>mcp</category>
      </categories>
      <tags>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP 客户端实战</title>
    <url>/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建项目目录</span><br><span class="line">uv init mcp-client</span><br><span class="line">cd mcp-client</span><br><span class="line"></span><br><span class="line"># 创建虚拟环境</span><br><span class="line">uv venv</span><br><span class="line"></span><br><span class="line"># 激活虚拟环境</span><br><span class="line"># 在 Windows 上:</span><br><span class="line">.venv\Scripts\activate</span><br><span class="line"># 在 Unix 或 MacOS 上:</span><br><span class="line">source .venv/bin/activate</span><br><span class="line"></span><br><span class="line"># 安装所需包</span><br><span class="line">uv add mcp anthropic python-dotenv</span><br><span class="line">#使用镜像源安装</span><br><span class="line">uv add mcp anthropic python-dotenv --index-url https://pypi.tuna.tsinghua.edu.cn/simple/</span><br><span class="line"></span><br><span class="line"># 删除样板文件</span><br><span class="line"># 在 Windows 上:</span><br><span class="line">del main.py</span><br><span class="line"># 在 Unix 或 MacOS 上:</span><br><span class="line">rm main.py</span><br><span class="line"></span><br><span class="line"># 创建我们的主文件</span><br><span class="line">touch client.py</span><br></pre></td></tr></table></figure>
<h3 id="设置-API-密钥"><a href="#设置-API-密钥" class="headerlink" title="设置 API 密钥"></a>设置 API 密钥</h3><p>创建一个 <code>.env</code> 文件来存储它：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create .env file</span><br><span class="line">touch .env</span><br></pre></td></tr></table></figure>
<p>将您的密钥添加到 <code>.env</code> 文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ANTHROPIC_API_KEY=&lt;your key here&gt;</span><br></pre></td></tr></table></figure>
<p>将 <code>.env</code> 添加到您的 <code>.gitignore</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo &quot;.env&quot; &gt;&gt; .gitignore</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将 <code>.env</code> 文件名添加到 <code>.gitignore</code> 文件中，这样 Git 就会忽略 <code>.env</code> 文件，不会将其纳入版本控制。</p>
</blockquote>
<h3 id="创建客户端"><a href="#创建客户端" class="headerlink" title="创建客户端"></a>创建客户端</h3><h4 id="基本客户端结构"><a href="#基本客户端结构" class="headerlink" title="基本客户端结构"></a>基本客户端结构</h4><p>首先，让我们设置我们的导入并创建基本的客户端类：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">from typing import Optional</span><br><span class="line">from contextlib import AsyncExitStack</span><br><span class="line"></span><br><span class="line">from mcp import ClientSession, StdioServerParameters</span><br><span class="line">from mcp.client.stdio import stdio_client</span><br><span class="line"></span><br><span class="line">from anthropic import Anthropic</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line"></span><br><span class="line">load_dotenv()  # 从 .env 文件加载环境变量</span><br><span class="line"></span><br><span class="line">class MCPClient:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        # 初始化会话和客户端对象</span><br><span class="line">        self.session: Optional[ClientSession] = None  # MCP客户端会话</span><br><span class="line">        self.exit_stack = AsyncExitStack()  # 异步上下文管理器堆栈，用于资源清理</span><br><span class="line">        self.anthropic = Anthropic()  # Anthropic AI 客户端</span><br><span class="line">        </span><br><span class="line">    # 后续方法将在这里定义</span><br></pre></td></tr></table></figure>
<h4 id="服务器连接管理"><a href="#服务器连接管理" class="headerlink" title="服务器连接管理"></a>服务器连接管理</h4><p>接下来，我们将实现连接到 MCP 服务器的功能：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def connect_to_server(self, server_script_path: str):</span><br><span class="line">    &quot;&quot;&quot;连接到MCP服务器</span><br><span class="line"></span><br><span class="line">    Args:</span><br><span class="line">        server_script_path: 服务器脚本路径 (.py 或 .js 文件)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 检查是否为Python文件</span><br><span class="line">    is_python = server_script_path.endswith(&#x27;.py&#x27;)</span><br><span class="line">    # 检查是否为JavaScript文件</span><br><span class="line">    is_js = server_script_path.endswith(&#x27;.js&#x27;)</span><br><span class="line">    </span><br><span class="line">    # 如果不是Python或JavaScript文件，则抛出错误</span><br><span class="line">    if not (is_python or is_js):</span><br><span class="line">        raise ValueError(&quot;服务器脚本必须是 .py 或 .js 文件&quot;)</span><br><span class="line"></span><br><span class="line">    # 根据文件类型确定执行命令</span><br><span class="line">    command = &quot;python&quot; if is_python else &quot;node&quot;</span><br><span class="line">    </span><br><span class="line">    # 创建服务器参数对象</span><br><span class="line">    server_params = StdioServerParameters(</span><br><span class="line">        command=command,           # 执行命令</span><br><span class="line">        args=[server_script_path], # 脚本路径作为参数</span><br><span class="line">        env=None                   # 环境变量（使用默认环境）</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 建立stdio客户端连接并将其添加到异步上下文管理器中</span><br><span class="line">    stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))</span><br><span class="line">    self.stdio, self.write = stdio_transport</span><br><span class="line">    </span><br><span class="line">    # 创建客户端会话并将其添加到异步上下文管理器中</span><br><span class="line">    self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))</span><br><span class="line"></span><br><span class="line">    # 初始化会话</span><br><span class="line">    await self.session.initialize()</span><br><span class="line"></span><br><span class="line">    # 列出可用的工具</span><br><span class="line">    response = await self.session.list_tools()</span><br><span class="line">    tools = response.tools</span><br><span class="line">    </span><br><span class="line">    # 打印连接的服务器提供的工具列表</span><br><span class="line">    print(&quot;\n已连接到服务器，可用工具:&quot;, [tool.name for tool in tools])</span><br></pre></td></tr></table></figure>
<h4 id="查询处理逻辑"><a href="#查询处理逻辑" class="headerlink" title="查询处理逻辑"></a>查询处理逻辑</h4><p>现在让我们添加处理查询和调用工具的核心功能：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def process_query(self, query: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;使用Claude和可用工具处理查询&quot;&quot;&quot;</span><br><span class="line">    # 构建消息列表</span><br><span class="line">    messages = [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;role&quot;: &quot;user&quot;,      # 用户角色</span><br><span class="line">            &quot;content&quot;: query     # 用户查询内容</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    # 获取可用工具列表</span><br><span class="line">    response = await self.session.list_tools()</span><br><span class="line">    available_tools = [&#123;</span><br><span class="line">        &quot;name&quot;: tool.name,           # 工具名称</span><br><span class="line">        &quot;description&quot;: tool.description,  # 工具描述</span><br><span class="line">        &quot;input_schema&quot;: tool.inputSchema  # 工具输入模式</span><br><span class="line">    &#125; for tool in response.tools]</span><br><span class="line"></span><br><span class="line">    # 初始Claude API调用</span><br><span class="line">    response = self.anthropic.messages.create(</span><br><span class="line">        model=&quot;qwen3-235b-a22b&quot;,  # 使用的模型</span><br><span class="line">        max_tokens=1000,                     # 最大返回令牌数</span><br><span class="line">        messages=messages,                   # 消息历史</span><br><span class="line">        tools=available_tools               # 可用工具</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # 处理响应并处理工具调用</span><br><span class="line">    final_text = []  # 存储最终文本结果</span><br><span class="line"></span><br><span class="line">    assistant_message_content = []  # 存储助手消息内容</span><br><span class="line">    for content in response.content:  # 遍历响应内容</span><br><span class="line">        if content.type == &#x27;text&#x27;:  # 如果是文本内容</span><br><span class="line">            final_text.append(content.text)  # 添加到最终结果</span><br><span class="line">            assistant_message_content.append(content)  # 添加到助手消息</span><br><span class="line">        elif content.type == &#x27;tool_use&#x27;:  # 如果是工具调用</span><br><span class="line">            tool_name = content.name    # 工具名称</span><br><span class="line">            tool_args = content.input   # 工具参数</span><br><span class="line"></span><br><span class="line">            # 执行工具调用</span><br><span class="line">            result = await self.session.call_tool(tool_name, tool_args)</span><br><span class="line">            final_text.append(f&quot;[调用工具 &#123;tool_name&#125;，参数 &#123;tool_args&#125;]&quot;)</span><br><span class="line"></span><br><span class="line">            assistant_message_content.append(content)</span><br><span class="line">            # 添加助手消息到历史</span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                &quot;content&quot;: assistant_message_content</span><br><span class="line">            &#125;)</span><br><span class="line">            # 添加工具执行结果到历史</span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;tool_result&quot;,      # 工具结果类型</span><br><span class="line">                        &quot;tool_use_id&quot;: content.id,  # 工具使用ID</span><br><span class="line">                        &quot;content&quot;: result.content   # 工具执行结果</span><br><span class="line">                    &#125;</span><br><span class="line">                ]</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">            # 获取Claude的下一个响应</span><br><span class="line">            response = self.anthropic.messages.create(</span><br><span class="line">                model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">                max_tokens=1000,</span><br><span class="line">                messages=messages,</span><br><span class="line">                tools=available_tools</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            # 添加响应文本到最终结果</span><br><span class="line">            final_text.append(response.content[0].text)</span><br><span class="line"></span><br><span class="line">    # 返回连接后的最终文本结果</span><br><span class="line">    return &quot;\n&quot;.join(final_text)</span><br></pre></td></tr></table></figure>
<h4 id="交互式聊天界面"><a href="#交互式聊天界面" class="headerlink" title="交互式聊天界面"></a>交互式聊天界面</h4><p>现在我们将添加聊天循环和清理功能：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def chat_loop(self):</span><br><span class="line">    &quot;&quot;&quot;运行交互式聊天循环&quot;&quot;&quot;</span><br><span class="line">    print(&quot;\nMCP客户端已启动!&quot;)</span><br><span class="line">    print(&quot;输入您的问题或输入&#x27;quit&#x27;退出。&quot;)</span><br><span class="line"></span><br><span class="line">    while True:  # 无限循环，持续接收用户输入</span><br><span class="line">        try:</span><br><span class="line">            query = input(&quot;\n问题: &quot;).strip()  # 获取用户输入并去除首尾空格</span><br><span class="line"></span><br><span class="line">            if query.lower() == &#x27;quit&#x27;:  # 如果用户输入&#x27;quit&#x27;（不区分大小写）</span><br><span class="line">                break  # 退出循环</span><br><span class="line"></span><br><span class="line">            # 处理用户查询并获取响应</span><br><span class="line">            response = await self.process_query(query)</span><br><span class="line">            print(&quot;\n&quot; + response)  # 打印AI响应结果</span><br><span class="line"></span><br><span class="line">        except Exception as e:  # 捕获所有异常</span><br><span class="line">            print(f&quot;\n错误: &#123;str(e)&#125;&quot;)  # 打印错误信息</span><br><span class="line"></span><br><span class="line">async def cleanup(self):</span><br><span class="line">    &quot;&quot;&quot;清理资源&quot;&quot;&quot;</span><br><span class="line">    await self.exit_stack.aclose()  # 异步关闭所有在exit_stack中管理的资源</span><br></pre></td></tr></table></figure>
<h4 id="主入口点"><a href="#主入口点" class="headerlink" title="主入口点"></a>主入口点</h4><p>最后，我们将添加主要的执行逻辑：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">async def main():</span><br><span class="line">    # 检查命令行参数数量，如果少于2个则显示使用说明</span><br><span class="line">    if len(sys.argv) &lt; 2:</span><br><span class="line">        print(&quot;用法: python client.py &lt;服务器脚本路径&gt;&quot;)</span><br><span class="line">        sys.exit(1)  # 退出程序，返回错误码1</span><br><span class="line"></span><br><span class="line">    # 创建MCP客户端实例</span><br><span class="line">    client = MCPClient()</span><br><span class="line">    try:</span><br><span class="line">        # 连接到服务器，sys.argv[1]是第一个命令行参数（服务器脚本路径）</span><br><span class="line">        await client.connect_to_server(sys.argv[1])</span><br><span class="line">        # 启动交互式聊天循环</span><br><span class="line">        await client.chat_loop()</span><br><span class="line">    finally:</span><br><span class="line">        # 确保程序结束时清理资源</span><br><span class="line">        await client.cleanup()</span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    import sys  # 导入sys模块用于处理命令行参数</span><br><span class="line">    # 运行异步主函数</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>
<p><img src="/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/mcp%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%9E%E6%88%98/QQ20250801-164738.png" alt="QQ20250801-164738"></p>
<h3 id="运行客户端"><a href="#运行客户端" class="headerlink" title="运行客户端"></a>运行客户端</h3><p>要使您的客户端与任何 MCP 服务器运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uv run client.py path/to/server.py # python server</span><br><span class="line">uv run client.py path/to/build/index.js # node server</span><br></pre></td></tr></table></figure>
<p>客户端将：</p>
<ol>
<li>连接到指定服务器</li>
<li>列出可用工具</li>
<li>开始一个交互式聊天会话，您可以在其中：<ul>
<li>输入查询</li>
<li>查看工具执行情况</li>
<li>从 Claude 获取响应</li>
</ul>
</li>
</ol>
<h3 id="运作流程"><a href="#运作流程" class="headerlink" title="运作流程"></a>运作流程</h3><p>当你提交查询时：</p>
<ol>
<li>客户端从服务器获取可用工具列表</li>
<li>你的查询连同工具描述一起发送给 Claude</li>
<li>Claude 决定使用哪些工具（如果有的话）</li>
<li>客户端通过服务器执行任何请求的工具调用</li>
<li>结果会发送回 Claude</li>
<li>Claude 提供自然语言响应</li>
<li>响应显示给您</li>
</ol>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://modelcontextprotocol.io/quickstart/client#main-entry-point">Build an MCP Client - Model Context Protocol</a></p>
<h3 id="适配openai版本"><a href="#适配openai版本" class="headerlink" title="适配openai版本"></a>适配openai版本</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import json</span><br><span class="line">import sys</span><br><span class="line">from typing import Optional</span><br><span class="line">from contextlib import AsyncExitStack</span><br><span class="line"></span><br><span class="line">from mcp import ClientSession, StdioServerParameters</span><br><span class="line">from mcp.client.stdio import stdio_client</span><br><span class="line"></span><br><span class="line">from openai import OpenAI</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">load_dotenv()  # 从 .env 文件加载环境变量</span><br><span class="line"></span><br><span class="line">class MCPClient:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        # 初始化会话和客户端对象</span><br><span class="line">        self.session: Optional[ClientSession] = None  # MCP客户端会话</span><br><span class="line">        self.exit_stack = AsyncExitStack()  # 异步上下文管理器堆栈，用于资源清理</span><br><span class="line">        self.anthropic = OpenAI(</span><br><span class="line">            api_key=os.getenv(&quot;DASHSCOPE_API_KEY&quot;),</span><br><span class="line">            base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">        )  # 使用OpenAI兼容模式连接通义千问</span><br><span class="line">        </span><br><span class="line">    async def connect_to_server(self, server_script_path: str):</span><br><span class="line">        &quot;&quot;&quot;连接到MCP服务器</span><br><span class="line">        </span><br><span class="line">        Args:</span><br><span class="line">            server_script_path (str): 服务器脚本路径，支持.py或.js文件</span><br><span class="line">        </span><br><span class="line">        Raises:</span><br><span class="line">            ValueError: 当脚本文件不是.py或.js格式时抛出</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 检查是否为Python文件</span><br><span class="line">        is_python = server_script_path.endswith(&#x27;.py&#x27;)</span><br><span class="line">        # 检查是否为JavaScript文件</span><br><span class="line">        is_js = server_script_path.endswith(&#x27;.js&#x27;)</span><br><span class="line">        </span><br><span class="line">        # 如果不是Python或JavaScript文件，则抛出错误</span><br><span class="line">        if not (is_python or is_js):</span><br><span class="line">            raise ValueError(&quot;服务器脚本必须是 .py 或 .js 文件&quot;)</span><br><span class="line"></span><br><span class="line">        # 根据文件类型确定执行命令</span><br><span class="line">        command = &quot;python&quot; if is_python else &quot;node&quot;</span><br><span class="line">        </span><br><span class="line">        # 创建服务器参数对象</span><br><span class="line">        server_params = StdioServerParameters(</span><br><span class="line">            command=command,           # 执行命令</span><br><span class="line">            args=[server_script_path], # 脚本路径作为参数</span><br><span class="line">            env=None                   # 环境变量（使用默认环境）</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        # 建立stdio客户端连接并将其添加到异步上下文管理器中</span><br><span class="line">        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))</span><br><span class="line">        self.stdio, self.write = stdio_transport</span><br><span class="line">        </span><br><span class="line">        # 创建客户端会话并将其添加到异步上下文管理器中</span><br><span class="line">        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))</span><br><span class="line"></span><br><span class="line">        # 初始化会话</span><br><span class="line">        await self.session.initialize()</span><br><span class="line"></span><br><span class="line">        # 列出可用的工具</span><br><span class="line">        response = await self.session.list_tools()</span><br><span class="line">        tools = response.tools</span><br><span class="line">        </span><br><span class="line">        # 打印连接的服务器提供的工具列表</span><br><span class="line">        print(&quot;\n已连接到服务器，可用工具:&quot;, [tool.name for tool in tools])</span><br><span class="line"></span><br><span class="line">    async def process_query(self, query: str) -&gt; str:</span><br><span class="line">        &quot;&quot;&quot;使用Qwen和可用工具处理查询&quot;&quot;&quot;</span><br><span class="line">        # 构建消息列表</span><br><span class="line">        messages = [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;role&quot;: &quot;user&quot;,</span><br><span class="line">                &quot;content&quot;: query</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        # 获取可用工具列表并转换为OpenAI格式</span><br><span class="line">        response = await self.session.list_tools()</span><br><span class="line">        available_tools = []</span><br><span class="line">        for tool in response.tools:</span><br><span class="line">            schema = tool.inputSchema</span><br><span class="line">            if isinstance(schema, str):</span><br><span class="line">                schema = json.loads(schema)</span><br><span class="line">            if isinstance(schema, dict) and &quot;properties&quot; in schema:</span><br><span class="line">                schema = &#123;&quot;type&quot;: &quot;object&quot;, **schema&#125;</span><br><span class="line"></span><br><span class="line">            available_tools.append(&#123;</span><br><span class="line">                &quot;type&quot;: &quot;function&quot;,</span><br><span class="line">                &quot;function&quot;: &#123;</span><br><span class="line">                    &quot;name&quot;: tool.name,</span><br><span class="line">                    &quot;description&quot;: tool.description,</span><br><span class="line">                    &quot;parameters&quot;: schema</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">        # 第一次调用模型</span><br><span class="line">        response = self.anthropic.chat.completions.create(</span><br><span class="line">            model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">            max_tokens=1000,</span><br><span class="line">            messages=messages,</span><br><span class="line">            tools=available_tools,</span><br><span class="line">            extra_body=&#123;&quot;enable_thinking&quot;: False&#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        final_text = []</span><br><span class="line">        message = response.choices[0].message</span><br><span class="line"></span><br><span class="line">        # 处理文本内容</span><br><span class="line">        if message.content:</span><br><span class="line">            final_text.append(message.content)</span><br><span class="line"></span><br><span class="line">        # 处理工具调用</span><br><span class="line">        if message.tool_calls:</span><br><span class="line">            for tool_call in message.tool_calls:</span><br><span class="line">                tool_name = tool_call.function.name</span><br><span class="line">                tool_args = json.loads(tool_call.function.arguments)</span><br><span class="line">                </span><br><span class="line">                # 执行工具调用</span><br><span class="line">                result = await self.session.call_tool(tool_name, tool_args)</span><br><span class="line">                final_text.append(f&quot;[调用工具 &#123;tool_name&#125;，参数 &#123;tool_args&#125;]&quot;)</span><br><span class="line">                </span><br><span class="line">                # 处理工具结果</span><br><span class="line">                tool_result_content = &quot;&quot;</span><br><span class="line">                if result.content:</span><br><span class="line">                    for item in result.content:</span><br><span class="line">                        if hasattr(item, &#x27;type&#x27;) and item.type == &#x27;text&#x27;:</span><br><span class="line">                            tool_result_content += item.text</span><br><span class="line">                        else:</span><br><span class="line">                            tool_result_content += str(item)</span><br><span class="line"></span><br><span class="line">                # 添加助手消息到历史</span><br><span class="line">                messages.append(&#123;</span><br><span class="line">                    &quot;role&quot;: &quot;assistant&quot;,</span><br><span class="line">                    &quot;content&quot;: None,</span><br><span class="line">                    &quot;tool_calls&quot;: [tool_call]</span><br><span class="line">                &#125;)</span><br><span class="line">                </span><br><span class="line">                # 添加工具执行结果到历史</span><br><span class="line">                messages.append(&#123;</span><br><span class="line">                    &quot;role&quot;: &quot;tool&quot;,</span><br><span class="line">                    &quot;tool_call_id&quot;: tool_call.id,</span><br><span class="line">                    &quot;content&quot;: tool_result_content</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">                # 再次调用模型</span><br><span class="line">                response = self.anthropic.chat.completions.create(</span><br><span class="line">                    model=&quot;qwen3-235b-a22b&quot;,</span><br><span class="line">                    max_tokens=1000,</span><br><span class="line">                    messages=messages,</span><br><span class="line">                    tools=available_tools,</span><br><span class="line">                    extra_body=&#123;&quot;enable_thinking&quot;: False&#125;</span><br><span class="line">                )</span><br><span class="line">                </span><br><span class="line">                # 处理最终响应</span><br><span class="line">                if response.choices and response.choices[0].message.content:</span><br><span class="line">                    final_text.append(response.choices[0].message.content)</span><br><span class="line"></span><br><span class="line">        return &quot;\n&quot;.join(final_text)</span><br><span class="line"></span><br><span class="line">    async def chat_loop(self):</span><br><span class="line">        &quot;&quot;&quot;运行交互式聊天循环&quot;&quot;&quot;</span><br><span class="line">        print(&quot;\nMCP客户端已启动!&quot;)</span><br><span class="line">        print(&quot;输入您的问题或输入&#x27;quit&#x27;退出。&quot;)</span><br><span class="line"></span><br><span class="line">        while True:  # 无限循环，持续接收用户输入</span><br><span class="line">            try:</span><br><span class="line">                query = input(&quot;\n问题: &quot;).strip()  # 获取用户输入并去除首尾空格</span><br><span class="line"></span><br><span class="line">                if query.lower() == &#x27;quit&#x27;:  # 如果用户输入&#x27;quit&#x27;（不区分大小写）</span><br><span class="line">                    break  # 退出循环</span><br><span class="line"></span><br><span class="line">                # 处理用户查询并获取响应</span><br><span class="line">                response = await self.process_query(query)</span><br><span class="line">                print(&quot;\n&quot; + response)  # 打印AI响应结果</span><br><span class="line"></span><br><span class="line">            except Exception as e:  # 捕获所有异常</span><br><span class="line">                print(f&quot;\n错误: &#123;str(e)&#125;&quot;)  # 打印错误信息</span><br><span class="line">                import traceback</span><br><span class="line">                traceback.print_exc()  # 打印详细错误信息</span><br><span class="line"></span><br><span class="line">    async def cleanup(self):</span><br><span class="line">        &quot;&quot;&quot;清理资源&quot;&quot;&quot;</span><br><span class="line">        await self.exit_stack.aclose()  # 异步关闭所有在exit_stack中管理的资源</span><br><span class="line"></span><br><span class="line">async def main():</span><br><span class="line">    # 检查命令行参数数量，如果少于2个则显示使用说明</span><br><span class="line">    if len(sys.argv) &lt; 2:</span><br><span class="line">        print(&quot;用法: python client.py &lt;服务器脚本路径&gt;&quot;)</span><br><span class="line">        sys.exit(1)  # 退出程序，返回错误码1</span><br><span class="line"></span><br><span class="line">    # 创建MCP客户端实例</span><br><span class="line">    client = MCPClient()</span><br><span class="line">    try:</span><br><span class="line">        # 连接到服务器，sys.argv[1]是第一个命令行参数（服务器脚本路径）</span><br><span class="line">        await client.connect_to_server(sys.argv[1])</span><br><span class="line">        # 启动交互式聊天循环</span><br><span class="line">        await client.chat_loop()</span><br><span class="line">    finally:</span><br><span class="line">        # 确保程序结束时清理资源</span><br><span class="line">        await client.cleanup()</span><br><span class="line"></span><br><span class="line"># 程序入口点</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 运行异步主函数</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>
<h3 id="openai和claude在工具调用的差异"><a href="#openai和claude在工具调用的差异" class="headerlink" title="openai和claude在工具调用的差异"></a>openai和claude在工具调用的差异</h3><ol>
<li><strong>工具格式转换修复</strong></li>
</ol>
<p><strong>问题</strong>：MCP工具格式与OpenAI API不兼容<br><strong>修复</strong>：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原错误格式</span></span><br><span class="line">available_tools = [&#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">    <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">    <span class="string">&quot;input_schema&quot;</span>: tool.inputSchema</span><br><span class="line">&#125;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后格式（符合OpenAI规范）</span></span><br><span class="line">available_tools = [&#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">    <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">        <span class="string">&quot;parameters&quot;</span>: schema  <span class="comment"># 正确的JSON Schema格式</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure></p>
<ol>
<li><strong>API响应处理修复</strong></li>
</ol>
<p><strong>问题</strong>：错误访问了OpenAI响应对象的属性<br><strong>修复</strong>：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原错误代码</span></span><br><span class="line"><span class="keyword">for</span> content <span class="keyword">in</span> response.content:  <span class="comment"># ❌ response没有content属性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后代码</span></span><br><span class="line">message = response.choices[<span class="number">0</span>].message  <span class="comment"># ✅ 正确的访问路径</span></span><br><span class="line"><span class="keyword">if</span> message.content:</span><br><span class="line">    final_text.append(message.content)</span><br><span class="line"><span class="keyword">if</span> message.tool_calls:</span><br><span class="line">    <span class="keyword">for</span> tool_call <span class="keyword">in</span> message.tool_calls:</span><br><span class="line">        <span class="comment"># 处理工具调用</span></span><br></pre></td></tr></table></figure></p>
<ol>
<li><strong>工具调用结果处理修复</strong></li>
</ol>
<p><strong>问题</strong>：错误处理MCP工具调用返回的结果结构<br><strong>修复</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 原错误代码</span></span><br><span class="line"><span class="string">&quot;content&quot;</span>: result.content  <span class="comment"># ❌ 可能包含复杂对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复后代码</span></span><br><span class="line">tool_result_content = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> result.content:</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> result.content:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(item, <span class="string">&#x27;type&#x27;</span>) <span class="keyword">and</span> item.<span class="built_in">type</span> == <span class="string">&#x27;text&#x27;</span>:</span><br><span class="line">            tool_result_content += item.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tool_result_content += <span class="built_in">str</span>(item)</span><br></pre></td></tr></table></figure>
<ol>
<li><strong>消息历史构建修复</strong></li>
</ol>
<p><strong>问题</strong>：工具调用后消息历史格式不正确<br><strong>修复</strong>：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 正确的消息历史格式</span></span><br><span class="line">messages.append(&#123;</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>,</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: <span class="literal">None</span>,</span><br><span class="line">    <span class="string">&quot;tool_calls&quot;</span>: [tool_call]</span><br><span class="line">&#125;)</span><br><span class="line">messages.append(&#123;</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">    <span class="string">&quot;tool_call_id&quot;</span>: tool_call.<span class="built_in">id</span>,</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: tool_result_content</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p>
<ol>
<li><strong>JSON Schema兼容性处理</strong></li>
</ol>
<p><strong>问题</strong>：MCP返回的schema可能缺少必要的根类型定义<br><strong>修复</strong>：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">schema = tool.inputSchema</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(schema, <span class="built_in">str</span>):</span><br><span class="line">    schema = json.loads(schema)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(schema, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&quot;properties&quot;</span> <span class="keyword">in</span> schema:</span><br><span class="line">    schema = &#123;<span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>, **schema&#125;  <span class="comment"># 确保有根类型</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>mcp</category>
      </categories>
      <tags>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>langgraph实战mcp</title>
    <url>/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/langgraph%E5%AE%9E%E6%88%98mcp/</url>
    <content><![CDATA[<h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install langchain-mcp-adapters</span><br></pre></td></tr></table></figure>
<h3 id="使用langgraph调用mcp"><a href="#使用langgraph调用mcp" class="headerlink" title="使用langgraph调用mcp"></a>使用langgraph调用mcp</h3><p>要点主要是利用MultiServerMCPClient构建服务，获取tool</p>
<p>利用预设的create_react_agent构建ReAct架构的智能体并调用工具</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import asyncio # 需要导入 asyncio 来运行异步函数</span><br><span class="line"># 从langchain_mcp_adapters.client模块导入MultiServerMCPClient类</span><br><span class="line"># 从langgraph.prebuilt模块导入create_react_agent函数</span><br><span class="line">from langchain_mcp_adapters.client import MultiServerMCPClient</span><br><span class="line">from langgraph.prebuilt import create_react_agent</span><br><span class="line"></span><br><span class="line"># 导入 LLM 相关库</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line"></span><br><span class="line"># 将主要逻辑封装在一个异步函数中</span><br><span class="line">async def main():</span><br><span class="line">    # 创建MultiServerMCPClient实例，配置两个不同的服务</span><br><span class="line">    client = MultiServerMCPClient(</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;math&quot;: &#123;  # 数学计算服务</span><br><span class="line">                &quot;command&quot;: &quot;python&quot;,  # 使用python命令启动</span><br><span class="line">                # 替换为你的math_server.py文件的绝对路径</span><br><span class="line">                &quot;args&quot;: [&quot;/workspace/langgraph-mcp/math_server.py&quot;],</span><br><span class="line">                &quot;transport&quot;: &quot;stdio&quot;,  # 使用标准输入输出传输</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;weather&quot;: &#123;  # 天气服务</span><br><span class="line">                # 确保你的天气服务器在8000端口运行</span><br><span class="line">                # *** 确保这个 URL 是正确的，并且服务器正在运行 ***</span><br><span class="line">                &quot;url&quot;: &quot;http://localhost:8000/mcp&quot;,</span><br><span class="line">                &quot;transport&quot;: &quot;streamable_http&quot;,  # 使用可流式HTTP传输</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tools = []</span><br><span class="line">    try:</span><br><span class="line">        # 在异步函数内部正确使用 await</span><br><span class="line">        tools = await client.get_tools()</span><br><span class="line">        print(f&quot;成功获取到 &#123;len(tools)&#125; 个MCP工具。&quot;)</span><br><span class="line">        for tool_item in tools:</span><br><span class="line">            print(f&quot;  - &#123;tool_item.name&#125;: &#123;tool_item.description&#125;&quot;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;获取MCP工具失败: &#123;e&#125;&quot;)</span><br><span class="line">        print(&quot;请确保MCP服务URL有效且可访问，或者您已正确配置了认证信息。&quot;)</span><br><span class="line">        # 在函数内部，如果出错可以选择返回或继续处理</span><br><span class="line">        # return # 这里可以 return，但会结束 main 函数</span><br><span class="line"></span><br><span class="line">    if not tools:</span><br><span class="line">        print(&quot;没有获取到工具，无法创建代理。&quot;)</span><br><span class="line">        return</span><br><span class="line"></span><br><span class="line">    # 创建ReAct代理</span><br><span class="line">    llm = ChatOpenAI(</span><br><span class="line">        model=&quot;qwen3-235b-a22b-thinking-2507&quot;,</span><br><span class="line">        api_key=&quot;sk-a8ef27c47ea84224ac6eed6d4bba1bab&quot;,</span><br><span class="line">        base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot; # 修正了末尾多余的空格</span><br><span class="line">    )</span><br><span class="line">    agent = create_react_agent(llm, tools)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    # 异步调用代理来解决数学问题</span><br><span class="line">    # 确保在异步函数内部使用 await</span><br><span class="line">    math_response = await agent.ainvoke(</span><br><span class="line">        &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what&#x27;s (3 + 5) x 12?&quot;&#125;]&#125;</span><br><span class="line">    )</span><br><span class="line">    print(&quot;\n--- 数学问题回答 ---&quot;)</span><br><span class="line">    print(math_response[&quot;messages&quot;][-1].content) # 打印最后一条消息（LLM的回答）</span><br><span class="line"></span><br><span class="line">    # 异步调用代理来查询天气</span><br><span class="line">    weather_response = await agent.ainvoke(</span><br><span class="line">        &#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;what is the weather in nyc?&quot;&#125;]&#125;</span><br><span class="line">    )</span><br><span class="line">    print(&quot;\n--- 天气问题回答 ---&quot;)</span><br><span class="line">    print(weather_response[&quot;messages&quot;][-1].content) # 打印最后一条消息（LLM的回答）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># --- 这是脚本的入口点 ---</span><br><span class="line"># 使用 asyncio.run() 来运行你的主异步函数</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    asyncio.run(main())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://github.langchain.ac.cn/langgraph/agents/mcp/">使用 MCP - LangChain 框架</a></p>
<h3 id="框架流程"><a href="#框架流程" class="headerlink" title="框架流程"></a>框架流程</h3><p><img src="/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/langgraph%E5%AE%9E%E6%88%98mcp/image-20250801164905578.png" alt="image-20250801164905578"></p>
<p>✅ 三个角色（系统组件）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>角色</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Client</strong></td>
<td>前端或用户界面，发起请求</td>
</tr>
<tr>
<td><strong>Auth Provider</strong></td>
<td>认证服务（如 OAuth、JWT 提供者），负责登录和签发 token</td>
</tr>
<tr>
<td><strong>LangGraph Backend</strong></td>
<td>应用的后端服务，处理业务逻辑</td>
</tr>
<tr>
<td><strong>Secret Store</strong></td>
<td>存放用户敏感信息（如 token、密钥等）</td>
</tr>
<tr>
<td><strong>MCP Server</strong></td>
<td>后端工具服务，提供具体的工具或资源接口</td>
</tr>
</tbody>
</table>
</div>
<p>✅ 流程详解（12步）</p>
<p>🔐 阶段一：用户登录 &amp; 获取 Token（1~6）</p>
<ol>
<li><p><strong>用户登录</strong><br>Client 提交用户名和密码给 Auth Provider。</p>
</li>
<li><p><strong>返回 Token</strong><br>Auth Provider 验证成功后，返回一个访问令牌（token）。</p>
</li>
<li><p><strong>携带 Token 请求</strong><br>Client 将 token 附加在请求头中，发给 LangGraph Backend。</p>
</li>
<li><p><strong>验证 Token</strong><br>LangGraph Backend 使用 <code>@auth.authenticate</code> 中间件验证 token 是否有效。</p>
</li>
<li><p><strong>获取用户信息</strong><br>验证通过后，LangGraph Backend 从 Auth Provider 拉取用户详细信息。</p>
</li>
<li><p><strong>确认有效性</strong><br>后端确认用户信息无误，流程继续。</p>
</li>
</ol>
<p>🔑 阶段二：获取用户权限 Token（6a~6b）</p>
<p>6a. <strong>拉取用户权限 Token</strong><br>   LangGraph Backend 从 Secret Store 获取该用户对应的权限 token（可能是 MCP 所需的访问凭证）。</p>
<p>6b. <strong>返回权限 Token</strong><br>   Secret Store 返回该 token。</p>
<p>🛠️ 阶段三：调用工具 &amp; 返回结果（7~12）</p>
<ol>
<li><p><strong>权限控制检查</strong><br>LangGraph Backend 使用 <code>@auth.on.*</code> 权限控制逻辑，确认用户是否有权调用该工具。</p>
</li>
<li><p><strong>构建 MCP Client</strong><br>后端用用户的权限 token 构建一个 MCP 客户端。</p>
</li>
<li><p><strong>调用 MCP 工具</strong><br>MCP Client 发起请求，调用某个具体工具，携带 token（通常放在请求头中）。</p>
</li>
<li><p><strong>MCP 验证并执行</strong><br>MCP Server 验证 token 是否有效，确认无误后执行工具逻辑。</p>
</li>
<li><p><strong>工具返回结果</strong><br>MCP Server 返回工具执行结果或资源数据。</p>
</li>
<li><p><strong>返回给前端</strong><br>LangGraph Backend 将结果返回给 Client，完成整个链路。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>mcp</category>
      </categories>
      <tags>
        <tag>langgraph</tag>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP 服务端实战</title>
    <url>/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/mcp%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create a new directory for our project</span><br><span class="line">uv init weather</span><br><span class="line">cd weather</span><br><span class="line"></span><br><span class="line"># Create virtual environment and activate it</span><br><span class="line">uv venv</span><br><span class="line">source .venv/bin/activate</span><br><span class="line"></span><br><span class="line"># Install dependencies</span><br><span class="line">uv add &quot;mcp[cli]&quot; httpx</span><br><span class="line"></span><br><span class="line"># Create our server file</span><br><span class="line">touch weather.py</span><br></pre></td></tr></table></figure>
<h3 id="mcp-studio样例"><a href="#mcp-studio样例" class="headerlink" title="mcp studio样例"></a>mcp studio样例</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from mcp.server.fastmcp import FastMCP</span><br><span class="line"></span><br><span class="line">mcp = FastMCP(&quot;Math&quot;)</span><br><span class="line"></span><br><span class="line">@mcp.tool()</span><br><span class="line">def add(a: int, b: int) -&gt; int:</span><br><span class="line">    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;</span><br><span class="line">    return a + b</span><br><span class="line"></span><br><span class="line">@mcp.tool()</span><br><span class="line">def multiply(a: int, b: int) -&gt; int:</span><br><span class="line">    &quot;&quot;&quot;Multiply two numbers&quot;&quot;&quot;</span><br><span class="line">    return a * b</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    mcp.run(transport=&quot;stdio&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="mcp-streamable-http-样例"><a href="#mcp-streamable-http-样例" class="headerlink" title="mcp streamable-http 样例"></a>mcp streamable-http 样例</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from mcp.server.fastmcp import FastMCP</span><br><span class="line"></span><br><span class="line">mcp = FastMCP(&quot;Weather&quot;)</span><br><span class="line"></span><br><span class="line">@mcp.tool()</span><br><span class="line">async def get_weather(location: str) -&gt; str:</span><br><span class="line">    &quot;&quot;&quot;Get weather for location.&quot;&quot;&quot;</span><br><span class="line">    return &quot;It&#x27;s always sunny in New York&quot;</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    mcp.run(transport=&quot;streamable-http&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>mcp市场<a href="https://www.modelscope.cn/mcp">MCP 广场 · 魔搭社区</a></p>
<p><strong>使用 uv（推荐）</strong></p>
<p>当使用 <a href="https://docs.astral.sh/uv/"><code>uv</code></a> 时不需要特定的安装步骤。我们将使用 <a href="https://docs.astral.sh/uv/guides/tools/"><code>uvx</code></a> 直接运行 <em>mcp-server-fetch</em>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;mcpServers&quot;: &#123;</span><br><span class="line">  &quot;fetch&quot;: &#123;</span><br><span class="line">    &quot;command&quot;: &quot;uvx&quot;,</span><br><span class="line">    &quot;args&quot;: [&quot;mcp-server-fetch&quot;]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>使用 PIP</strong></p>
<p>或者，您可以通过 pip 安装 <code>mcp-server-fetch</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install mcp-server-fetch</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;mcpServers&quot;: &#123;</span><br><span class="line">  &quot;fetch&quot;: &#123;</span><br><span class="line">    &quot;command&quot;: &quot;python&quot;,</span><br><span class="line">    &quot;args&quot;: [&quot;-m&quot;, &quot;mcp_server_fetch&quot;]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>远程托管</strong></p>
<p><img src="/2025/08/01/%E5%AD%A6%E4%B9%A0/mcp%E5%AD%A6%E4%B9%A0/mcp%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%AE%9E%E6%88%98/image-20250802120145192.png" alt="image-20250802120145192"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;mcpServers&quot;: &#123;</span><br><span class="line">    &quot;fetch&quot;: &#123;</span><br><span class="line">      &quot;type&quot;: &quot;sse&quot;,</span><br><span class="line">      &quot;url&quot;: &quot;https://mcp.api-inference.modelscope.net/991cf46/sse&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://modelcontextprotocol.io/quickstart/server#core-mcp-concepts">构建 MCP 服务器 - 模型上下文协议 —- Build an MCP Server - Model Context Protocol</a></p>
]]></content>
      <categories>
        <category>mcp</category>
      </categories>
      <tags>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>weatherweb开发学习记录</title>
    <url>/2025/06/01/%E5%AD%A6%E4%B9%A0/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/</url>
    <content><![CDATA[<h3 id="项目要求"><a href="#项目要求" class="headerlink" title="项目要求"></a>项目要求</h3><p>智能天气提醒助手</p>
<p>描述：开发一款web应用，实时获取天气数据并支持个性化提醒（如雨天带伞）。</p>
<p>要求：</p>
<p>调用天气API获取实时数据（如OpenWeatherMap，每天1000次免费调用）</p>
<p>使用前端三件套设计交互界面，展示当前及未来天气信息，空气质量、体感温度、日出日落、月相等信息；</p>
<p>使用fastapi做后端</p>
<p>支持地点设置和天气提醒条件配置，在预设的提醒条件下提醒用户，并且将用户偏好保存至本地文件。</p>
<p>多城市切换、历史天气查询、全球地图展示等额外功能（可选*）。</p>
<h3 id="技术栈"><a href="#技术栈" class="headerlink" title="技术栈"></a>技术栈</h3><p>fastapi，前端三件套(fetchapi)，apifox</p>
<h3 id="fetchapi"><a href="#fetchapi" class="headerlink" title="fetchapi"></a>fetchapi</h3><p><strong>Fetch API</strong> 是现代浏览器提供的标准网络请求接口，允许开发者通过 JavaScript 发起异步 HTTP 请求（如 GET、POST、PUT、DELETE 等），并处理响应数据（如 JSON、文本、图片等）。它是传统 <code>XMLHttpRequest</code>（AJAX）的替代方案，语法更简洁，且支持 Promise 异步编程。</p>
<p><strong>简单来说，就是用作给后端发送请求，实现前后端分离</strong></p>
<p><img src="/2025/06/01/%E5%AD%A6%E4%B9%A0/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/image-20250609163335375.png" alt="image-20250609163335375"></p>
<h4 id="用法学习"><a href="#用法学习" class="headerlink" title="用法学习"></a>用法学习</h4><p>在使用 <code>fetch</code> 发起 HTTP 请求时，<code>method</code>、<code>headers</code> 和 <code>body</code> 是配置请求的核心参数，它们共同决定了请求的行为和数据格式。以下是每个参数的具体作用及示例：</p>
<h5 id="1-method-39-POST-39"><a href="#1-method-39-POST-39" class="headerlink" title="1. method: &#39;POST&#39;"></a><strong>1. <code>method: &#39;POST&#39;</code></strong></h5><p><strong>作用</strong></p>
<p>指定 HTTP 请求的方法（动词），<code>POST</code> 表示向服务器提交数据（如创建资源）。</p>
<ul>
<li><strong>常见方法</strong>：<ul>
<li><code>GET</code>：获取数据（默认方法，无需显式声明）。</li>
<li><code>POST</code>：提交数据（如新增记录）。</li>
<li><code>PUT</code>：更新数据。</li>
<li><code>DELETE</code>：删除数据。</li>
</ul>
</li>
<li><strong>与后端交互</strong>：FastAPI 的路由通过 <code>@app.post()</code>、<code>@app.get()</code> 等装饰器匹配请求方法。</li>
</ul>
<p><strong>示例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="title function_">fetch</span>(<span class="string">&#x27;https://api.example.com/submit&#x27;</span>, &#123;</span><br><span class="line">  <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span>, <span class="comment">// 告诉服务器这是一个提交请求</span></span><br><span class="line">  <span class="comment">// ...其他配置</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h5 id="2-headers-请求头"><a href="#2-headers-请求头" class="headerlink" title="2. headers 请求头"></a><strong>2. <code>headers</code> 请求头</strong></h5><p><strong>作用</strong></p>
<p>定义请求的元信息，用于告知服务器如何处理请求和数据格式。</p>
<ul>
<li><strong>关键字段</strong>：<ul>
<li><strong><code>Content-Type</code></strong>：指定请求体（<code>body</code>）的数据格式。<ul>
<li><code>application/json</code>：表示发送 JSON 数据。</li>
<li><code>application/x-www-form-urlencoded</code>：表示表单数据（键值对）。</li>
<li><code>multipart/form-data</code>：用于上传文件。</li>
</ul>
</li>
<li><strong><code>Authorization</code></strong>：携带身份凭证（如 Token）。</li>
<li><strong><code>Accept</code></strong>：声明客户端期望的响应格式（如 JSON、XML）。</li>
</ul>
</li>
</ul>
<p><strong>示例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="attr">headers</span>: &#123;</span><br><span class="line">  <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span>, <span class="comment">// 告诉服务器请求体是 JSON</span></span><br><span class="line">  <span class="string">&#x27;Authorization&#x27;</span>: <span class="string">&#x27;Bearer your_token_here&#x27;</span> <span class="comment">// 身份验证（可选）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="3-body-JSON-stringify-item"><a href="#3-body-JSON-stringify-item" class="headerlink" title="3. body: JSON.stringify(item)"></a><strong>3. <code>body: JSON.stringify(item)</code></strong></h5><p><strong>作用</strong></p>
<p>定义请求体（即发送给服务器的数据），需根据 <code>Content-Type</code> 的类型进行格式化。</p>
<ul>
<li><strong><code>JSON.stringify(item)</code></strong>：将 JavaScript 对象转换为 JSON 字符串。<ul>
<li>因为 HTTP 协议只能传输文本，不能直接传输对象。</li>
</ul>
</li>
<li><strong>注意事项</strong>：<ul>
<li>若未设置 <code>Content-Type: application/json</code>，服务器可能无法正确解析数据。</li>
<li>若使用 <code>FormData</code> 上传文件，需使用 <code>multipart/form-data</code> 格式。</li>
</ul>
</li>
</ul>
<p><strong>示例</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> item = &#123; <span class="attr">name</span>: <span class="string">&quot;Apple&quot;</span>, <span class="attr">price</span>: <span class="number">1.99</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="attr">body</span>: <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(item) <span class="comment">// 转换为 &#x27;&#123;&quot;name&quot;:&quot;Apple&quot;,&quot;price&quot;:1.99&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<h5 id="完整示例：向-FastAPI-提交数据"><a href="#完整示例：向-FastAPI-提交数据" class="headerlink" title="完整示例：向 FastAPI 提交数据"></a><strong>完整示例：向 FastAPI 提交数据</strong></h5><p><strong>FastAPI 后端定义</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Item</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    price: <span class="built_in">float</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/items/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_item</span>(<span class="params">item: Item</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;Item created&quot;</span>, <span class="string">&quot;item&quot;</span>: item&#125;</span><br></pre></td></tr></table></figure>
<p><strong>前端调用</strong></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> item = &#123; <span class="attr">name</span>: <span class="string">&quot;Banana&quot;</span>, <span class="attr">price</span>: <span class="number">0.99</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="title function_">fetch</span>(<span class="string">&#x27;http://localhost:8000/items/&#x27;</span>, &#123;</span><br><span class="line">  <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span>,</span><br><span class="line">  <span class="attr">headers</span>: &#123;</span><br><span class="line">    <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span> <span class="comment">// 必须与数据格式匹配</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">body</span>: <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(item) <span class="comment">// 将对象转为 JSON 字符串</span></span><br><span class="line">&#125;)</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">response</span> =&gt;</span> response.<span class="title function_">json</span>())</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">data</span> =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(data))</span><br><span class="line">  .<span class="title function_">catch</span>(<span class="function"><span class="params">error</span> =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">error</span>(<span class="string">&#x27;Error:&#x27;</span>, error));</span><br></pre></td></tr></table></figure>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h5><div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>作用</th>
<th>必填性</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>method</code></td>
<td>定义请求类型（如 <code>POST</code>）</td>
<td>必填（非 <code>GET</code> 时）</td>
</tr>
<tr>
<td><code>headers</code></td>
<td>声明数据格式、身份凭证等</td>
<td>必填（尤其 <code>Content-Type</code>）</td>
</tr>
<tr>
<td><code>body</code></td>
<td>发送的数据（需格式化为字符串）</td>
<td>必填（<code>POST</code>/<code>PUT</code> 时）</td>
</tr>
</tbody>
</table>
</div>
<p><strong>关键点</strong>：  </p>
<ul>
<li><code>POST</code> 请求必须设置 <code>headers[&#39;Content-Type&#39;]</code> 和 <code>body</code>。</li>
<li><code>JSON.stringify()</code> 是发送 JSON 数据的关键步骤。</li>
<li>FastAPI 会根据 <code>Content-Type</code> 自动解析请求体并进行数据校验（通过 Pydantic 模型）。</li>
</ul>
<h3 id="CORS"><a href="#CORS" class="headerlink" title="CORS"></a>CORS</h3><h4 id="CORS-是什么？"><a href="#CORS-是什么？" class="headerlink" title="CORS 是什么？"></a><strong>CORS 是什么？</strong></h4><p><strong>CORS（Cross-Origin Resource Sharing）</strong> 是一种浏览器安全机制，用于解决 <strong>跨域请求</strong> 的问题。它允许服务器明确授权某些跨域请求，从而在保障安全的前提下，实现前后端分离架构中的跨域通信。</p>
<h4 id="为什么需要-CORS？"><a href="#为什么需要-CORS？" class="headerlink" title="为什么需要 CORS？"></a><strong>为什么需要 CORS？</strong></h4><p><strong>1. 同源策略（Same-Origin Policy）</strong></p>
<p>浏览器默认遵循 <strong>同源策略</strong>，即网页只能请求与自身 <strong>同源（相同域名、协议、端口）</strong> 的资源。<br><strong>例如</strong>：</p>
<ul>
<li>前端地址：<code>http://localhost:3000</code></li>
<li>后端地址：<code>http://localhost:8000</code><br>此时，前端向后端发起的请求会被浏览器 <strong>拦截</strong>，因为端口不同（3000 vs 8000）。</li>
</ul>
<p><strong>2. 跨域场景</strong></p>
<p>跨域是前后端分离架构中的常见问题，例如：</p>
<ul>
<li>前端部署在 <code>https://example.com</code>，后端 API 在 <code>https://api.example.com</code>。</li>
<li>前端本地开发（<code>localhost:3000</code>）调用后端服务（<code>localhost:8000</code>）。</li>
</ul>
<p><strong>3. CORS 的作用</strong></p>
<p>CORS 通过 <strong>服务器响应头</strong> 告诉浏览器：“这个跨域请求是安全的，允许它通过”。<br>浏览器根据这些响应头决定是否放行请求。</p>
<h4 id="如何配置-CORS？"><a href="#如何配置-CORS？" class="headerlink" title="如何配置 CORS？"></a><strong>如何配置 CORS？</strong></h4><p>以 <strong>FastAPI</strong> 为例，配置允许跨域请求的步骤如下：</p>
<p><strong>启用 CORS 中间件</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> fastapi.middleware.cors <span class="keyword">import</span> CORSMiddleware</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 CORS</span></span><br><span class="line">app.add_middleware(</span><br><span class="line">    CORSMiddleware,</span><br><span class="line">    allow_origins=[<span class="string">&quot;http://localhost:3000&quot;</span>],  <span class="comment"># 允许的源</span></span><br><span class="line">    allow_credentials=<span class="literal">True</span>,                    <span class="comment"># 允许携带凭证</span></span><br><span class="line">    allow_methods=[<span class="string">&quot;*&quot;</span>],                       <span class="comment"># 允许所有方法（GET、POST 等）</span></span><br><span class="line">    allow_headers=[<span class="string">&quot;*&quot;</span>],                       <span class="comment"># 允许所有头信息</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="CORS-的实际应用场景"><a href="#CORS-的实际应用场景" class="headerlink" title="CORS 的实际应用场景"></a><strong>CORS 的实际应用场景</strong></h4><p><strong>1. 前后端分离开发</strong></p>
<ul>
<li>前端（React/Vue）运行在 <code>localhost:3000</code>，后端（FastAPI）运行在 <code>localhost:8000</code>。</li>
<li>配置 <code>allow_origins=[&quot;http://localhost:3000&quot;]</code> 允许跨域通信。</li>
</ul>
<p><strong>2. 第三方 API 调用</strong></p>
<ul>
<li>前端直接调用第三方服务（如天气 API），需服务器启用 CORS。</li>
<li>示例：<code>Access-Control-Allow-Origin: *</code> 表示允许所有来源。</li>
</ul>
<p><strong>3. 需要凭证的场景</strong></p>
<ul>
<li>前端需携带 Cookie 或 Token 访问后端接口：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">app.add_middleware(</span><br><span class="line">    CORSMiddleware,</span><br><span class="line">    allow_origins=[<span class="string">&quot;http://localhost:3000&quot;</span>],</span><br><span class="line">    allow_credentials=<span class="literal">True</span>,  <span class="comment"># 允许携带凭证</span></span><br><span class="line">    allow_methods=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line">    allow_headers=[<span class="string">&quot;*&quot;</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a><strong>总结</strong></h4><div class="table-container">
<table>
<thead>
<tr>
<th>概念</th>
<th>作用</th>
<th>配置示例</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>同源策略</strong></td>
<td>浏览器安全机制，阻止跨域请求</td>
<td>默认启用</td>
</tr>
<tr>
<td><strong>CORS</strong></td>
<td>服务器通过响应头授权跨域请求</td>
<td><code>Access-Control-Allow-Origin</code></td>
</tr>
<tr>
<td><strong>预检请求</strong></td>
<td>OPTIONS 请求，验证复杂跨域请求的合法性</td>
<td>自动触发</td>
</tr>
<tr>
<td><strong>FastAPI 配置</strong></td>
<td>使用 <code>CORSMiddleware</code> 中间件</td>
<td><code>app.add_middleware(...)</code></td>
</tr>
</tbody>
</table>
</div>
<p><strong>最佳实践</strong>：</p>
<ol>
<li><strong>开发阶段</strong>：允许所有来源（<code>allow_origins=[&quot;*&quot;]</code>），方便调试。</li>
<li><strong>生产环境</strong>：严格限制允许的源、方法、头信息，避免安全风险。</li>
<li><strong>携带凭证</strong>：启用 <code>allow_credentials=True</code> 并明确指定允许的源（避免使用 <code>*</code>）。</li>
</ol>
<h3 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h3><h4 id="Nginx-是什么？"><a href="#Nginx-是什么？" class="headerlink" title="Nginx 是什么？"></a><strong>Nginx 是什么？</strong></h4><p><strong>Nginx</strong>（发音为 “engine-x”）是一个高性能的开源 <strong>Web 服务器、反向代理服务器、负载均衡器和 HTTP 缓存</strong>，广泛用于现代 Web 架构中。它以轻量级、低资源消耗和高并发处理能力著称，常用于优化网站性能、管理流量和提升安全性。</p>
<h4 id="Nginx-的核心功能"><a href="#Nginx-的核心功能" class="headerlink" title="Nginx 的核心功能"></a><strong>Nginx 的核心功能</strong></h4><p><strong>1. Web 服务器</strong></p>
<ul>
<li><strong>静态资源托管</strong>：直接提供 HTML、CSS、JS、图片等静态文件服务。</li>
<li><strong>动态请求转发</strong>：将动态请求（如 API）转发给后端应用（如 FastAPI、Django、Node.js）。</li>
</ul>
<p><strong>2. 反向代理</strong></p>
<ul>
<li><strong>作用</strong>：接收客户端请求，转发给后端服务器（如 FastAPI），隐藏真实服务器地址。</li>
<li><strong>优势</strong>：提高安全性、支持负载均衡、缓存和 SSL 终端。</li>
</ul>
<p><strong>3. 负载均衡</strong></p>
<ul>
<li><strong>作用</strong>：将请求分发到多个后端服务器（如多个 FastAPI 实例），避免单点故障。</li>
<li><strong>算法</strong>：轮询（Round Robin）、最少连接（Least Connections）、IP 哈希（IP Hash）等。</li>
</ul>
<p><strong>4. SSL/TLS 终端</strong></p>
<ul>
<li><strong>作用</strong>：处理 HTTPS 加密和解密，减轻后端服务器的压力。</li>
<li><strong>配置</strong>：绑定证书和私钥，强制 HTTPS。</li>
</ul>
<p><strong>5. 缓存</strong></p>
<ul>
<li><strong>作用</strong>：缓存静态资源（如图片、CSS）或动态内容（如 API 响应），减少后端负载。</li>
</ul>
<p><strong>6. 高可用性和容错</strong></p>
<ul>
<li><strong>健康检查</strong>：自动检测后端服务器状态，故障时切换备用节点。</li>
</ul>
<h4 id="Nginx-的典型应用场景"><a href="#Nginx-的典型应用场景" class="headerlink" title="Nginx 的典型应用场景"></a><strong>Nginx 的典型应用场景</strong></h4><p><strong>1. 反向代理 FastAPI 服务</strong></p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/nginx/sites-available/fastapi.conf</span></span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server_name</span> example.com;</span><br><span class="line"></span><br><span class="line">    <span class="section">location</span> / &#123;</span><br><span class="line">        <span class="attribute">proxy_pass</span> http://127.0.0.1:8000;  <span class="comment"># FastAPI 服务地址</span></span><br><span class="line">        <span class="attribute">proxy_set_header</span> Host <span class="variable">$host</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        <span class="attribute">proxy_set_header</span> X-Forwarded-Proto <span class="variable">$scheme</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：将 <code>example.com</code> 的请求转发给运行在 <code>127.0.0.1:8000</code> 的 FastAPI 服务。</li>
</ul>
<p><strong>2. 静态文件托管</strong></p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">location</span> /static/ &#123;</span><br><span class="line">    <span class="attribute">alias</span> /var/www/static/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>作用</strong>：直接提供 <code>/var/www/static/</code> 目录下的静态文件（如图片、CSS）。</li>
</ul>
<h4 id="Nginx-与-FastAPI-的协作流程"><a href="#Nginx-与-FastAPI-的协作流程" class="headerlink" title="Nginx 与 FastAPI 的协作流程"></a><strong>Nginx 与 FastAPI 的协作流程</strong></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">客户端 -&gt; Nginx（反向代理） -&gt; FastAPI（处理业务逻辑） -&gt; 数据库/其他服务</span><br></pre></td></tr></table></figure>
<ol>
<li><strong>静态资源</strong>：由 Nginx 直接返回（如 HTML、CSS、JS）。</li>
<li><strong>API 请求</strong>：Nginx 转发给 FastAPI，FastAPI 处理后返回 JSON 数据。</li>
<li><strong>HTTPS</strong>：Nginx 处理加密和解密，FastAPI 无需关心 SSL。</li>
</ol>
<p><strong>最佳实践</strong>：</p>
<ol>
<li><strong>开发阶段</strong>：直接运行 FastAPI（<code>uvicorn main:app --reload</code>）。</li>
<li><strong>生产环境</strong>：Nginx + FastAPI（Gunicorn/Uvicorn） + 数据库。</li>
<li><strong>性能优化</strong>：启用 Gzip 压缩、HTTP/2、缓存静态资源。</li>
</ol>
<p>通过 Nginx 的反向代理和负载均衡，可以显著提升 FastAPI 应用的性能、安全性和可扩展性。</p>
<h3 id="反向代理是什么？"><a href="#反向代理是什么？" class="headerlink" title="反向代理是什么？"></a>反向代理是什么？</h3><p><strong>反向代理（Reverse Proxy）</strong> 是一种服务器角色，它位于客户端与服务器之间，接收客户端的请求后，将请求转发给后端服务器（如 FastAPI、Django、Node.js 等），并将后端服务器的响应返回给客户端。<strong>它的核心作用是隐藏后端服务器的真实地址，优化请求处理流程，并增强安全性</strong>。</p>
<p>反向代理是现代 Web 架构中不可或缺的组件，尤其在前后端分离、微服务、高并发场景下作用显著。通过 Nginx 等工具实现反向代理，可以：</p>
<ul>
<li>提升安全性（隐藏后端、过滤攻击）。</li>
<li>优化性能（负载均衡、缓存静态资源）。</li>
<li>简化运维（集中管理 SSL、日志）。</li>
</ul>
<p>对于 FastAPI 项目，推荐在生产环境中使用 Nginx 作为反向代理，以充分发挥其高性能和灵活性优势。</p>
<h3 id="二级域名是什么？"><a href="#二级域名是什么？" class="headerlink" title="二级域名是什么？"></a>二级域名是什么？</h3><p><strong>二级域名（Second-Level Domain, SLD）</strong> 是域名系统（DNS）中的一个层级，通常位于顶级域名（TLD）之下，主域名（一级域名）之上。它是域名结构中的关键部分，用于标识网站或服务的主体。</p>
<p><strong>域名层级结构</strong></p>
<p>域名由多个层级组成，从右向左层级递增，具体如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mail.example.com</span><br><span class="line">|     |        |</span><br><span class="line">|     |        └── 顶级域名（TLD）：com/net/org</span><br><span class="line">|     └────────── 二级域名（SLD）：example</span><br><span class="line">└──────────────── 子域名（Subdomain）：mail</span><br></pre></td></tr></table></figure>
<p><strong>1. 顶级域名（TLD）</strong></p>
<ul>
<li><strong>定义</strong>：域名的最后一部分，表示域名的类别或国家/地区。</li>
<li><strong>示例</strong>：<code>.com</code>（商业）、<code>.org</code>（非营利组织）、<code>.net</code>（网络服务）、<code>.cn</code>（中国）、<code>.jp</code>（日本）。</li>
</ul>
<p><strong>2. 二级域名（SLD）</strong></p>
<ul>
<li><strong>定义</strong>：位于 TLD 之下的域名部分，是域名的主体，通常由用户注册并拥有。</li>
<li><strong>示例</strong>：在 <code>example.com</code> 中，<code>example</code> 是二级域名。</li>
</ul>
<p><strong>3. 子域名（Subdomain）</strong></p>
<ul>
<li><strong>定义</strong>：在二级域名前添加的前缀，用于进一步细分网站或服务。</li>
<li><strong>示例</strong>：在 <code>mail.example.com</code> 中，<code>mail</code> 是子域名。</li>
</ul>
<p><strong>二级域名的常见用途</strong></p>
<ol>
<li><strong>品牌标识</strong>：<br>二级域名是品牌的核心标识，如 <code>google.com</code>、<code>apple.com</code>。</li>
<li><strong>服务划分</strong>：<br>通过子域名区分不同服务，例如：<ul>
<li><code>mail.google.com</code>：邮件服务</li>
<li><code>drive.google.com</code>：云存储服务</li>
<li><code>maps.google.com</code>：地图服务</li>
</ul>
</li>
<li><strong>多语言或地区支持</strong>：<br>通过二级域名提供本地化内容，例如：<ul>
<li><code>fr.wikipedia.org</code>（法语版）</li>
<li><code>zh.wikipedia.org</code>（中文版）</li>
</ul>
</li>
</ol>
<h3 id="DOM元素"><a href="#DOM元素" class="headerlink" title="DOM元素"></a>DOM元素</h3><p><strong>DOM（Document Object Model，文档对象模型）</strong> 是浏览器将 HTML 或 XML 文档解析为树状结构的编程接口。<strong>DOM 元素</strong> 是构成这棵树的节点（如 <code>&lt;div&gt;</code>、<code>&lt;p&gt;</code>、<code>&lt;button&gt;</code> 等），它们不仅是页面内容的载体，更是实现动态交互的核心工具。</p>
<h3 id="开发日志"><a href="#开发日志" class="headerlink" title="开发日志"></a>开发日志</h3><h4 id="api"><a href="#api" class="headerlink" title="api"></a>api</h4><p>获取api<a href="https://home.openweathermap.org/api_keys">https://home.openweathermap.org/api_keys</a></p>
<p>api文档<a href="https://openweathermap.org/api">Weather API - OpenWeatherMap</a></p>
<h4 id="版本1-0"><a href="#版本1-0" class="headerlink" title="版本1.0"></a>版本1.0</h4><p><img src="/2025/06/01/%E5%AD%A6%E4%B9%A0/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/image-20250602191448931.png" alt="image-20250602191448931"></p>
<p>完成基本天气功能的开发</p>
<h4 id="版本2-0"><a href="#版本2-0" class="headerlink" title="版本2.0"></a>版本2.0</h4><p><img src="/2025/06/01/%E5%AD%A6%E4%B9%A0/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/weatherweb%E5%BC%80%E5%8F%91%E6%97%A5%E5%BF%97/image-20250604095743649.png" alt="image-20250604095743649"></p>
<p>完成ai建议功能</p>
]]></content>
      <categories>
        <category>weatherweb开发日志</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>fastapi</tag>
        <tag>后端</tag>
        <tag>项目</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo常用指令</title>
    <url>/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<p>以下是 Hexo 常用的指令整理，方便快速查阅：</p>
<hr>
<h3 id="基础操作"><a href="#基础操作" class="headerlink" title="基础操作"></a><strong>基础操作</strong></h3><ol>
<li><p><strong>初始化博客</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init [文件夹名]  <span class="comment"># 创建新博客（不指定文件夹则在当前目录生成）</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>安装依赖</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install           <span class="comment"># 安装 Hexo 核心依赖（初始化后可能需要执行）</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>本地预览</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server           <span class="comment"># 启动本地服务器（默认端口 4000），缩写：hexo s</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>生成静态文件</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo generate         <span class="comment"># 生成 public 文件夹的静态文件，缩写：hexo g</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>部署到服务器</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo deploy           <span class="comment"># 部署到 GitHub Pages 或其他平台，缩写：hexo d</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="文章与页面"><a href="#文章与页面" class="headerlink" title="文章与页面"></a><strong>文章与页面</strong></h3><ol>
<li><p><strong>新建文章</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;文章标题&quot;</span>    <span class="comment"># 生成新文章（Markdown 文件），缩写：hexo n</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>新建页面</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new page <span class="string">&quot;页面名&quot;</span> <span class="comment"># 创建自定义页面（如 about、tags）</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="清理与调试"><a href="#清理与调试" class="headerlink" title="清理与调试"></a><strong>清理与调试</strong></h3><ol>
<li><p><strong>清理缓存</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean            <span class="comment"># 删除生成的 public 和缓存文件（修改主题后建议执行）</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>查看帮助</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo <span class="built_in">help</span>             <span class="comment"># 查看所有指令说明</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<hr>
<h3 id="组合指令（高效操作）"><a href="#组合指令（高效操作）" class="headerlink" title="组合指令（高效操作）"></a><strong>组合指令（高效操作）</strong></h3><ul>
<li><p><strong>生成并部署</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g -d          <span class="comment"># 先生成静态文件，再部署（等同 hexo generate &amp;&amp; hexo deploy）</span></span><br><span class="line">hexo d -g          <span class="comment"># 同上，顺序不影响结果</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>生成并预览</strong>  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo s -g          <span class="comment"># 先生成文件，再启动本地服务器</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a><strong>注意事项</strong></h3><ul>
<li><strong>部署前配置</strong>：需在 <code>_config.yml</code> 中设置 <code>deploy</code> 参数（如 GitHub 仓库地址）。</li>
<li><strong>安装部署插件</strong>：首次部署需运行 <code>npm install hexo-deployer-git</code>。</li>
<li><strong>主题安装</strong>：将主题克隆到 <code>themes/</code> 文件夹后，在配置文件中指定主题名称。</li>
</ul>
<p>如果需要更详细的操作说明，可以补充具体场景（如更换主题、设置分类等）！</p>
<h3 id="hexo-d上传失败，网络连接问题解决方案"><a href="#hexo-d上传失败，网络连接问题解决方案" class="headerlink" title="hexo d上传失败，网络连接问题解决方案"></a>hexo d上传失败，网络连接问题解决方案</h3><p>原因：<strong>Clash 虽然开启了代理，但 Git 默认不会走这个代理</strong>，导致连接 GitHub 时失败</p>
<p><img src="/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/image-20250722204420664.png" alt="image-20250722204420664"></p>
<p>解决方案：</p>
<p>查看端口号</p>
<p><img src="/2025/04/16/%E5%AD%A6%E4%B9%A0/hexo/hexo%E7%9B%B8%E5%85%B3/image-20250722204512612.png" alt="image-20250722204512612"></p>
<p>查看git代理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global --get http.proxy</span><br><span class="line">git config --global --get https.proxy</span><br></pre></td></tr></table></figure>
<p>更改代理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global http.proxy socks5://127.0.0.1:1080</span><br><span class="line">git config --global https.proxy socks5://127.0.0.1:1080</span><br></pre></td></tr></table></figure>
<h3 id="参考教程"><a href="#参考教程" class="headerlink" title="参考教程"></a>参考教程</h3><p><a href="https://tech.yemengstar.com/hexo-tutorial-deploy-githubpages-beginner/">HEXO系列教程 | 使用GitHub部署静态博客HEXO | 小白向教程 – 夜梦星尘の折腾日记</a></p>
<p><a href="https://www.bilibili.com/video/BV12H4y1N7Q4/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Github王炸功能Pages,免费免服务器上线网站,详细教程_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer学习</title>
    <url>/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>本文基于<a href="https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/blob/master/PaperNotes/Transformer 论文精读.md#前言">AI-Guide-and-Demos-zh_CN/PaperNotes/Transformer 论文精读.md at master · Hoper-J/AI-Guide-and-Demos-zh_CN</a>与<a href="https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Transformer论文逐段精读【论文精读】_哔哩哔哩_bilibili</a>阅读学习</p>
<h3 id="transformer贡献"><a href="#transformer贡献" class="headerlink" title="transformer贡献"></a>transformer贡献</h3><p>实际在这一阶段的工作中，<strong>注意力机制</strong>就已经在<strong>编码器-解码器架构</strong>中被广泛应用（与 RNN 一起使用），但 Transformer 彻底颠覆了默认采取的逻辑：<strong>直接放弃 RNN 的递归结构，只使用注意力机制来编码和解码序列信息</strong>。</p>
<p>Transformer 的主要贡献如下：</p>
<ul>
<li><p><strong>取消递归结构，实现并行计算</strong></p>
<p>通过采用<strong>自注意力机制（Self-Attention）</strong>，Transformer 可以同时处理多个输入序列，极大提高了计算的并行度和训练速度。</p>
</li>
<li><p><strong>引入位置编码（Positional Encoding）并结合 Attention 机制巧妙地捕捉位置信息</strong></p>
<p>在不依赖 RNN 结构的情况下，通过位置编码为序列中的每个元素嵌入位置信息，从而使模型能够感知输入的顺序。</p>
</li>
</ul>
<h3 id="transformer架构"><a href="#transformer架构" class="headerlink" title="transformer架构"></a>transformer架构</h3><p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807135151542.png" alt="image-20250807135151542"></p>
<p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807145354145.png" alt="image-20250807145354145"></p>
<p><a href="https://www.bilibili.com/video/BV1MY41137AK?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Transformer模型】曼妙动画轻松学，形象比喻贼好记_哔哩哔哩_bilibili</a></p>
<p>Transformer 模型基于<strong>编码器</strong>（左）- <strong>解码器</strong>（右）架构</p>
<p><strong>Transformer编码器</strong>同样由 <strong>N 个完全相同的层</strong>（原始论文中 N=6）堆叠而成，每层只有两个子层，而解码器有三个。</p>
<ol>
<li>多头自注意力（Multi-Head Self-Attention）<br>让输入序列中的每个位置都能关注序列内所有位置，直接建模全局依赖。</li>
<li>前馈全连接网络（Position-wise Feed-Forward Network）<br>对每个位置独立地做一次两层的全连接变换（通常先升维再降维）。</li>
</ol>
<p>同样，每个子层后都有</p>
<ul>
<li>残差连接（Residual Connection）</li>
<li>层归一化（Layer Normalization）</li>
</ul>
<p>另外，编码器在输入端还会用到</p>
<ul>
<li>位置编码（Positional Encoding）——给模型提供序列位置信息，因为注意力本身不包含顺序信息。</li>
</ul>
<p><strong>Transformer解码器</strong>由多个相同的层堆叠而成，每一层包含三个核心子层：</p>
<ol>
<li><strong>掩蔽多头自注意力机制</strong>（Masked Multi-Head Attention）<br>用于处理目标序列，通过掩码防止当前位置关注未来位置，确保生成过程的自回归特性。</li>
<li><strong>编码器-解码器注意力机制</strong>（Encoder-Decoder Attention）<br>使解码器能够关注编码器输出的上下文信息，建立输入与输出序列之间的关联。</li>
<li><strong>前馈神经网络</strong>（Feed-Forward Neural Network）<br>对注意力机制的输出进行非线性变换，增强模型的表达能力。</li>
</ol>
<p>此外，每个子层后均包含<strong>残差连接</strong>（Residual Connection）和<strong>层归一化</strong>（Layer Normalization），以稳定训练过程并加速收敛。最终，解码器的输出通过线性层和Softmax层映射为词汇表上的概率分布。</p>
<h3 id="嵌入（Embeddings）"><a href="#嵌入（Embeddings）" class="headerlink" title="嵌入（Embeddings）"></a>嵌入（Embeddings）</h3><p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808103256344.png" alt="image-20250808103256344"></p>
<p>在 Transformer 模型中，<strong>嵌入层</strong>（Embedding Layer） 是处理输入和输出数据的关键步骤，因为模型实际操作的是<strong>张量</strong>（tensor），而非<strong>字符串</strong>（string）。在将输入文本传递给模型之前，首先需要进行<strong>分词</strong>（tokenization），即将文本拆解为多个 <strong>token</strong>，随后这些 token 会被映射为对应的 <strong>token ID</strong>，从而转换为模型可理解的数值形式。此时，数据的形状为 <code>(seq_len,)</code>，其中 <code>seq_len</code> 表示输入序列的长度。</p>
<p>目的：为了让模型捕捉到 token 背后复杂的语义（Semantic meaning）关系，我们需要将离散的 token ID 映射到一个高维的连续向量空间（Continuous, dense）。这意味着每个 token ID 会被转换为一个<strong>嵌入向量</strong>（embedding vector），期望通过这种方式让语义相近的词汇在向量空间中距离更近，使模型能更好地捕捉词汇之间的关系。</p>
<p>流程：（前面要进行分词，后面要进行位置编码）</p>
<p>初始化一个可学习的矩阵 <code>E ∈ ℝ^(|V| × d_model)</code><br><code>|V|</code> = 词表大小（比如 32 k、50 k），<code>d_model</code> = 512/768/1024…</p>
<p>把 token id 作为行号，直接取对应行：<br><code>x_i = E[token_id_i]</code><br>得到 <code>[batch, seq_len, d_model]</code> 的浮点张量。</p>
<h3 id="位置编码（Positional-Encoding）"><a href="#位置编码（Positional-Encoding）" class="headerlink" title="位置编码（Positional Encoding）"></a>位置编码（Positional Encoding）</h3><p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808103418150.png" alt="image-20250808103418150"></p>
<p>Transformer 的自注意力机制（Self-Attention）是<strong>位置无关（position-agnostic）</strong>的。也就是说，如果不做任何处理，模型无法区分“我爱你”和“你爱我”这两个句子的差异，因为自注意力机制只关注 token 之间的相关性，而不考虑它们在序列中的顺序。</p>
<p>为了让模型感知到 token 的位置信息，Transformer 引入了<strong>位置编码</strong>。</p>
<p>在原始论文中，Transformer 使用的是固定位置编码（Positional Encoding），其公式如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
PE_{(pos, 2i)} &= \sin\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right), \\
PE_{(pos, 2i+1)} &= \cos\left(\frac{pos}{10000^{2i/d_{\text{model}}}}\right).
\end{aligned}</script><p>其中：</p>
<ul>
<li>$pos$ 表示位置索引（Position）。</li>
<li>$i$ 表示维度索引。</li>
<li>$d_{\text{model}}$ 是嵌入向量的维度。</li>
</ul>
<p>流程：输入的是一个<strong>整数索引</strong>（位置序号 0,1,2,…）。位置编码模块先把这些整数映射成与词向量同维度的向量（例如 512 维），再把结果加到词向量上。</p>
<h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808111823715.png" alt="image-20250808111823715"></p>
<p>在 Transformer 模型中，<strong>Softmax</strong> 函数不仅在计算<strong>注意力权重</strong>时用到，在预测阶段的输出处理环节也会用到，因为预测 token 的过程可以看成是<strong>多分类问题</strong>。</p>
<p><strong>Softmax</strong> 函数是一种常用的激活函数，能够将任意实数向量转换为<strong>概率分布</strong>，确保每个元素的取值范围在 [0, 1] 之间，并且所有元素的和为 1。其数学定义如下：</p>
<script type="math/tex; mode=display">
\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}</script><p>其中：</p>
<ul>
<li>$x_i$ 表示输入向量中的第 $i$ 个元素。</li>
<li>$\text{Softmax}(x_i)$ 表示输入 $x_i$ 转换后的概率。</li>
</ul>
<p>我们可以把 Softmax 看作一种<strong>归一化的指数变换</strong>。相比于简单的比例归一化 $\frac{x_i}{\sum_j x_j}$, <strong>Softmax 通过指数变换放大数值间的差异，让较大的值对应更高的概率，同时避免了负值和数值过小的问题，让模型聚焦于权重最高的位置</strong>，同时保留全局信息（低权重仍非零）。</p>
<h3 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h3><p><a href="https://www.bilibili.com/video/BV1xS4y1k7tn?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Attention 注意力机制】激情告白transformer、Bert、GNN的精髓_哔哩哔哩_bilibili</a></p>
<p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808135811744.png" alt="image-20250808135811744"></p>
<h4 id="缩放点积注意力机制（Scaled-Dot-Product-Attention）"><a href="#缩放点积注意力机制（Scaled-Dot-Product-Attention）" class="headerlink" title="缩放点积注意力机制（Scaled Dot-Product Attention）"></a><strong>缩放点积注意力机制（Scaled Dot-Product Attention）</strong></h4><p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808140834132.png" alt="image-20250808140834132"></p>
<p>Transformer 的核心是<strong>多头注意力机制（Multi-Head Attention）</strong>，它能够捕捉输入序列中不同位置之间的依赖关系，并从多个角度对信息进行建模。模块将自底向上的进行讲解：在深入理解注意力机制前，首先需要理解论文使用的<strong>缩放点积注意力机制（Scaled Dot-Product Attention）</strong>。</p>
<p>给定查询矩阵 $Q$、键矩阵 $K$ 和值矩阵 $V$, 其注意力输出的数学表达式如下：</p>
<script type="math/tex; mode=display">
\text{Attention}(Q, K, V) = \text{Softmax}\left(\frac{Q K^\top}{\sqrt{d_k}}\right) V</script><ul>
<li><strong>$Q$（Query）</strong>: 用于查询的向量矩阵。</li>
<li><strong>$K$（Key）</strong>: 表示键的向量矩阵，用于与查询匹配。</li>
<li><strong>$V$（Value）</strong>: 值矩阵，注意力权重最终会作用在该矩阵上。</li>
<li><strong>$d_k$</strong>: 键或查询向量的维度。</li>
</ul>
<blockquote>
<p>理解 Q、K、V 的关键在于代码，它们实际上是通过线性变换从输入序列生成的</p>
</blockquote>
<p>公式解释</p>
<ol>
<li><p><strong>点积计算（Dot Produce）</strong></p>
<p>将查询矩阵 $Q$ 与键矩阵的转置 $K^\top$ 做点积，计算每个查询向量与所有键向量之间的相似度：</p>
<p>$<code>\text&#123;Scores&#125; = Q K^\top</code>$</p>
<ul>
<li><strong>每一行</strong>表示某个查询与所有键之间的相似度（匹配分数）。</li>
<li><strong>每一列</strong>表示某个键与所有查询之间的相似度（匹配分数）。</li>
</ul>
</li>
<li><p><strong>缩放（Scaling）</strong></p>
<p>当 $d_k$ 较大时，点积的数值可能会过大，导致 Softmax 过后的梯度变得极小，因此除以 $\sqrt{d_k}$ 缩放点积结果的数值范围：</p>
<p>$<code>\text&#123;Scaled Scores&#125; = \frac&#123;Q K^\top&#125;&#123;\sqrt&#123;d_k&#125;&#125;</code>$</p>
<p>缩放后（Scaled Dot-Product）也称为注意力分数（<strong>attention scores</strong>）。</p>
</li>
<li><p><strong>Softmax 归一化</strong></p>
<p>使用 Softmax 函数将缩放后的分数转换为概率分布：</p>
<p>$<code>\text&#123;Attention Weights&#125; = \text&#123;Softmax&#125;\left(\frac&#123;Q K^\top&#125;&#123;\sqrt&#123;d_k&#125;&#125;\right)</code>$</p>
<blockquote>
<p><strong>注意</strong>：Softmax 是在每一行上进行的，这意味着每个查询的匹配分数将归一化为概率，总和为 1。</p>
</blockquote>
</li>
<li><p><strong>加权求和（Weighted Sum）</strong></p>
<p>最后，使用归一化后的注意力权重对值矩阵 $V$ 进行加权求和，得到每个查询位置的最终输出：<br>$<code>\text&#123;Output&#125; = \text&#123;Attention Weights&#125; \times V</code>$</p>
</li>
</ol>
<h3 id="单头注意力机制（Single-Head-Attention）"><a href="#单头注意力机制（Single-Head-Attention）" class="headerlink" title="单头注意力机制（Single-Head Attention）"></a>单头注意力机制（Single-Head Attention）</h3><p>将输入序列（Inputs）通过线性变换生成<strong>查询矩阵</strong>（Query, Q）、<strong>键矩阵</strong>（Key, K）和<strong>值矩阵</strong>（Value, V），随后执行<strong>缩放点积注意力</strong>（Scaled Dot-Product Attention）。</p>
<h4 id="掩码注意力机制（Masked-Attention）"><a href="#掩码注意力机制（Masked-Attention）" class="headerlink" title="掩码注意力机制（Masked Attention）"></a>掩码注意力机制（Masked Attention）</h4><p>如果使用 mask 掩盖将要预测的词汇，那么 Attention 就延伸为 Masked Attention</p>
<p>在这段代码中，<code>mask</code> 矩阵用于指定哪些位置应该被遮蔽（即填充为 -∞），从而保证这些位置的注意力权重在 softmax 输出中接近于零。注意，掩码机制并不是直接在截断输入序列，也不是在算分数的时候就排除不应该看到的位置，因为看到也没有关系，不会影响与其他位置的分数，所以在传入 Softmax（计算注意力权重）之前排除就可以了。</p>
<p>另外，根据输入数据的来源，还可以将注意力分为<strong>自注意力（Self-Attention）和交叉注意力（Cross-Attention)</strong>。</p>
<h4 id="自注意力机制（Self-attention）"><a href="#自注意力机制（Self-attention）" class="headerlink" title="自注意力机制（Self-attention）"></a>自注意力机制（Self-attention）</h4><p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808142109091.png" alt="image-20250808142109091"></p>
<p>Transformer 模型架构使用到了三个看起来不同的注意力机制，我们继续忽视共有的 Multi-Head。观察输入，线条一分为三传入 Attention 模块，这意味着查询（query）、键（key）和值（value）实际上都来自<strong>同一输入序列 $\mathbf{X}$</strong>，数学表达如下：</p>
<script type="math/tex; mode=display">
Q = XW^Q, \quad K = XW^K, \quad V = XW^V</script><ul>
<li><strong>$W^Q, W^K, W^V$</strong>：可训练的线性变换权重，实际上就是简单的线性层</li>
</ul>
<h4 id="交叉注意力机制（Cross-Attention）"><a href="#交叉注意力机制（Cross-Attention）" class="headerlink" title="交叉注意力机制（Cross-Attention）"></a>交叉注意力机制（Cross-Attention）</h4><p>在 Transformer 解码器中，除了自注意力外，还使用了 <strong>交叉注意力（Cross-Attention）</strong>。</p>
<p>如下图所示，解码器（右）在自底向上的处理过程中，先执行自注意力机制，然后通过交叉注意力从编码器的输出中获取上下文信息。</p>
<p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808142428374.png" alt="image-20250808142428374"></p>
<p>数学表达如下：</p>
<script type="math/tex; mode=display">
Q = X_{\text{decoder}} W^Q, \quad K = X_{\text{encoder}} W^K, \quad V = X_{\text{encoder}} W^V</script><h4 id="对比学习"><a href="#对比学习" class="headerlink" title="对比学习"></a>对比学习</h4><p><strong>Masked Attention</strong>、<strong>Self-Attention</strong> 和 <strong>Cross-Attention</strong> 的本质是一致的，这一点从代码调用可以看出来，三者的区别在于未来掩码的使用和输入数据的来源：</p>
<ul>
<li><p><strong>Masked Attention</strong>：用于解码过程，通过掩码屏蔽未来的时间步，确保模型只能基于已生成的部分进行预测，论文中解码器部分的第一个 Attention 使用的是 Masked Self-Attention。</p>
</li>
<li><p><strong>Self-Attention</strong>：查询、键和值矩阵来自同一输入序列，模型通过自注意力机制学习输入序列的全局依赖关系。</p>
</li>
<li><p><strong>Cross-Attention</strong>：查询矩阵来自解码器的输入，而键和值矩阵来自编码器的输出，解码器的第二个 Attention 模块就是 Cross-Attention，用于从编码器输出中获取相关的上下文信息。</p>
<ul>
<li><p>以<strong>机器翻译</strong>中的<strong>中译英任务</strong>为例：对于中文句子“<strong>中国的首都是北京</strong>”，假设模型已经生成了部分译文“The capital of China is”，此时需要预测下一个单词。</p>
<p>在这一阶段，<strong>解码器中的交叉注意力机制</strong>会使用<strong>当前已生成的译文“The capital of China is”的编码表示作为查询</strong>，并将<strong>编码器对输入句子“中国的首都是北京”编码表示</strong>作为<strong>键</strong>和<strong>值</strong>，通过计算<strong>查询与键之间的匹配程度</strong>，生成相应的注意力权重，以此从值中提取上下文信息，基于这些信息生成下一个可能的单词（token），比如：“Beijing”。</p>
</li>
</ul>
</li>
</ul>
<h3 id="多头注意力机制（Multi-Head-Attention）"><a href="#多头注意力机制（Multi-Head-Attention）" class="headerlink" title="多头注意力机制（Multi-Head Attention）"></a>多头注意力机制（Multi-Head Attention）</h3><p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808143810965.png" alt="image-20250808143810965"></p>
<p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808143822630.png" alt="image-20250808143822630"></p>
<p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808143845681.png" alt="image-20250808143845681"></p>
<p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808145725202.png" alt="image-20250808145725202"></p>
<p>多头注意力机制就是存在多个不同的权重矩阵，形成多个矩阵Z，再把它们 <strong>按最后一维（hidden）拼接（concat）→ 做一次线性变换</strong> 得到最终输出。</p>
<blockquote>
<p>线性bian’h把拼接后的多头结果 <code>Z_concat</code>（形状 batch×seq×d_model）重新<strong>线性映射</strong>回与输入相同的维度，同时让网络可以<strong>学习如何融合不同头的信息</strong>。</p>
</blockquote>
<p><a href="https://www.bilibili.com/video/BV1MY41137AK?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【Transformer模型】曼妙动画轻松学，形象比喻贼好记_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1HsTyz8ECC?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Transformer原理及架构：多头自注意力机制_哔哩哔哩_bilibili</a></p>
<h3 id="残差连接（Residual-Connection）和层归一化（Layer-Normalization-LayerNorm）"><a href="#残差连接（Residual-Connection）和层归一化（Layer-Normalization-LayerNorm）" class="headerlink" title="残差连接（Residual Connection）和层归一化（Layer Normalization, LayerNorm）"></a>残差连接（Residual Connection）和层归一化（Layer Normalization, LayerNorm）</h3><p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808150313758.png" alt="image-20250808150313758"></p>
<p>在 Transformer 架构中，<strong>残差连接</strong>（Residual Connection）与<strong>层归一化</strong>（LayerNorm）结合使用，统称为 <strong>Add &amp; Norm</strong> 操作。</p>
<h4 id="Add（残差连接，Residual-Connection）"><a href="#Add（残差连接，Residual-Connection）" class="headerlink" title="Add（残差连接，Residual Connection）"></a>Add（残差连接，Residual Connection）</h4><p>残差连接是一种跳跃连接（Skip Connection），它将层的输入直接加到输出上（观察架构图中的箭头），对应的公式如下：</p>
<script type="math/tex; mode=display">
\text{Output} = \text{SubLayer}(x) + x</script><p>这种连接方式有效缓解了<strong>深层神经网络的梯度消失</strong>问题。</p>
<p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250808151004667.png" alt="image-20250808151004667"></p>
<p>在transform中，就是输入的矩阵x加上经过注意力机制计算出来的z矩阵</p>
<h4 id="Norm（层归一化，Layer-Normalization）"><a href="#Norm（层归一化，Layer-Normalization）" class="headerlink" title="Norm（层归一化，Layer Normalization）"></a>Norm（层归一化，Layer Normalization）</h4><p><strong>层归一化</strong>（LayerNorm）是一种归一化技术，用于提升训练的稳定性和模型的泛化能力。</p>
<p>假设输入向量为 $x = (x_1, x_2, \dots, x_d)$, LayerNorm 的计算步骤如下：</p>
<ol>
<li><p><strong>计算均值和方差</strong>：<br>对输入的所有特征求均值 $\mu$ 和方差 $\sigma^2$：</p>
<p>$<code>\mu = \frac&#123;1&#125;&#123;d&#125; \sum_&#123;j=1&#125;^&#123;d&#125; x_j, \quad 
\sigma^2 = \frac&#123;1&#125;&#123;d&#125; \sum_&#123;j=1&#125;^&#123;d&#125; (x_j - \mu)^2</code>$</p>
</li>
<li><p><strong>归一化公式</strong>：<br>将输入特征 $\hat{x}_i$ 进行归一化：</p>
<p>$<code>\hat&#123;x&#125;_i = \frac&#123;x_i - \mu&#125;&#123;\sqrt&#123;\sigma^2 + \epsilon&#125;&#125;</code>$</p>
<p>其中, $\epsilon$ 是一个很小的常数（比如 1e-9），用于防止除以零的情况。</p>
</li>
<li><p><strong>引入可学习参数</strong>：<br>归一化后的输出乘以 $\gamma$ 并加上 $\beta$, 公式如下：</p>
<p>$<code>\text&#123;Output&#125; = \gamma \hat&#123;x&#125; + \beta</code>$</p>
<p>其中 $\gamma$ 和 $\beta$ 是可学习的参数，用于进一步调整归一化后的输出。</p>
</li>
</ol>
<h3 id="前馈神经网络-Position-wise-Feed-Forward-Networks（FFN）"><a href="#前馈神经网络-Position-wise-Feed-Forward-Networks（FFN）" class="headerlink" title="前馈神经网络 Position-wise Feed-Forward Networks（FFN）"></a>前馈神经网络 Position-wise Feed-Forward Networks（FFN）</h3><p>在 Transformer 中，前馈网络层（Feed-Forward Network，FFN）的作用可以概括为一句话：<br><strong>“对每个位置的向量进行非线性变换，增加模型的表达能力。”</strong></p>
<p>在编码器-解码器架构中，另一个看起来“大一点”的模块就是 Feed Forward，它在每个位置 $i$ 上的计算可以表示为：</p>
<script type="math/tex; mode=display">
\text{FFN}(x_i) = \text{max}(0, x_i W_1 + b_1) W_2 + b_2</script><p>其中：</p>
<ul>
<li>$x<em>i \in \mathbb{R}^{d</em>{\text{model}}}$ 表示第 $i$ 个位置的输入向量。 </li>
<li>$W<em>1 \in \mathbb{R}^{d</em>{\text{model}} \times d<em>{\text{ff}}}$ 和 $W_2 \in \mathbb{R}^{d</em>{\text{ff}} \times d_{\text{model}}}$ 是两个线性变换的权重矩阵。</li>
<li>$b<em>1 \in \mathbb{R}^{d</em>{\text{ff}}}$ 和 $b<em>2 \in \mathbb{R}^{d</em>{\text{model}}}$ 是对应的偏置向量。</li>
<li>$\text{max}(0, \cdot)$ 是 <strong>ReLU 激活函数</strong>，用于引入非线性。</li>
</ul>
<h3 id="大模型发展树"><a href="#大模型发展树" class="headerlink" title="大模型发展树"></a>大模型发展树</h3><p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807171237889.png" alt="image-20250807171237889"></p>
<p><img src="/2025/07/28/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/Transformer%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/image-20250807173520481.png" alt="image-20250807173520481"></p>
<h3 id="预训练语言模型"><a href="#预训练语言模型" class="headerlink" title="预训练语言模型"></a>预训练语言模型</h3><p>预训练语言模型（PLM）是一种通过大量文本数据进行无监督或弱监督训练的语言模型，目的是学习语言的通用表示（即语言的模式、语法、语义等）。这些模型通常在大规模文本数据上进行预训练，然后可以被微调（Fine - tuning）以适应各种下游任务，如文本分类、问答、命名实体识别等。</p>
<p>预训练语言模型的核心思想是利用大量的无标注文本数据来学习语言的通用特征，从而为各种自然语言处理任务提供强大的语言理解能力。预训练模型可以显著提高任务的性能，减少对标注数据的依赖，并且能够快速适应新的任务。</p>
<h4 id="BERT模型（Encoder-only-PLM）"><a href="#BERT模型（Encoder-only-PLM）" class="headerlink" title="BERT模型（Encoder-only PLM）"></a>BERT模型（Encoder-only PLM）</h4><p>针对 Encoder、Decoder 的特点，引入 ELMo 的预训练思路，开始出现不同的、对 Transformer 进行优化的思路。例如，<strong>Google 仅选择了 Encoder 层</strong>，通过将 Encoder 层进行堆叠，再提出不同的预训练任务-掩码语言模型（Masked Language Model，MLM），打造了一统自然语言理解（Natural Language Understanding，NLU）任务的代表模型——<strong>BERT</strong>。</p>
<p>BERT，全名为 Bidirectional Encoder Representations from Transformers，是由 Google 团队在 2018年发布的预训练语言模型。该模型发布于论文《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》，实现了包括 GLUE、MultiNLI 等七个自然语言处理评测任务的最优性能（State Of The Art，SOTA），堪称里程碑式的成果。</p>
<h4 id="T5（Encoder-Decoder-PLM）"><a href="#T5（Encoder-Decoder-PLM）" class="headerlink" title="T5（Encoder-Decoder PLM）"></a>T5（Encoder-Decoder PLM）</h4><p>BERT 也存在一些问题，例如 MLM 任务和下游任务微调的不一致性，以及无法处理超过模型训练长度的输入等问题。为了解决这些问题，研究者们提出了 <strong>Encoder-Decoder 模型</strong>，通过引入 Decoder 部分来解决这些问题，同时也为 NLP 领域带来了新的思路和方法。</p>
<p><strong>T5（Text-To-Text Transfer Transformer）是由 Google 提出的一种预训练语言模型</strong>，通过将所有 NLP 任务统一表示为文本到文本的转换问题，大大简化了模型设计和任务处理。T5 基于 Transformer 架构，包含编码器和解码器两个部分，使用自注意力机制和多头注意力捕捉全局依赖关系，利用相对位置编码处理长序列中的位置信息，并在每层中包含前馈神经网络进一步处理特征。</p>
<h4 id="LLama模型（Decoder-Only-PLM）"><a href="#LLama模型（Decoder-Only-PLM）" class="headerlink" title="LLama模型（Decoder-Only PLM）"></a>LLama模型（Decoder-Only PLM）</h4><p>LLaMA模型是由Meta（前Facebook）开发的一系列大型预训练语言模型。从LLaMA-1到LLaMA-3，LLaMA系列模型展示了大规模预训练语言模型的演进及其在实际应用中的显著潜力。</p>
<h4 id="GPT模型（Decoder-Only-PLM）"><a href="#GPT模型（Decoder-Only-PLM）" class="headerlink" title="GPT模型（Decoder-Only PLM）"></a>GPT模型（Decoder-Only PLM）</h4><p>GPT，即 Generative Pre-Training Language Model，是由 OpenAI 团队于 2018年发布的预训练语言模型。虽然学界普遍认可 BERT 作为预训练语言模型时代的代表，但首先明确提出<strong>预训练-微调思想的模型</strong>其实是 GPT。</p>
<p>GPT 提出了通用预训练的概念，也就是在海量无监督语料上预训练，进而在每个特定任务上进行微调，从而实现这些任务的巨大收益。虽然在发布之初，由于性能略输于不久后发布的 BERT，没能取得轰动性成果，也没能让 GPT 所使用的 <strong>Decoder-Only 架构</strong>成为学界研究的主流，但 OpenAI 团队坚定地选择了不断扩大预训练数据、增加模型参数，在 GPT 架构上不断优化，最终在 2020年发布的 GPT-3 成就了 LLM 时代的基础，并以 GPT-3 为基座模型的 ChatGPT 成功打开新时代的大门，成为 LLM 时代的最强竞争者也是目前的最大赢家。</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://transformers.run/">Hello! · Transformers快速入门</a></p>
<p><a href="https://github.com/jsksxs360/How-to-use-Transformers">jsksxs360/How-to-use-Transformers: Transformers 库快速入门教程</a></p>
<p><a href="https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN">Hoper-J/AI-Guide-and-Demos-zh_CN: 这是一份入门AI/LLM大模型的逐步指南，包含教程和演示代码，带你从API走进本地大模型部署和微调，代码文件会提供Kaggle或Colab在线版本，即便没有显卡也可以进行学习。项目中还开设了一个小型的代码游乐场🎡，你可以尝试在里面实验一些有意思的AI脚本。同时，包含李宏毅 (HUNG-YI LEE）2024生成式人工智能导论课程的完整中文镜像作业。</a></p>
<p><a href="https://datawhalechina.github.io/happy-llm/#/">Happy-LLM</a></p>
<p><a href="https://gengzhige.ai/video.html">梗直哥</a></p>
<p><a href="https://www.bilibili.com/video/BV1RBdTYxENw/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">90%人不知道的LLM黑科技：拆解Transformer如何吃透全网知识！_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大模型算法</category>
        <category>transformer</category>
      </categories>
      <tags>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>tokenizer</title>
    <url>/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/</url>
    <content><![CDATA[<h3 id="什么是-Tokenizer？"><a href="#什么是-Tokenizer？" class="headerlink" title="什么是 Tokenizer？"></a>什么是 Tokenizer？</h3><p><strong>Tokenizer</strong>（分词器）可以将原始文本（raw text）转换为模型能够理解的数字序列，在模型输入和输出的两个主要阶段中发挥重要作用：</p>
<h4 id="模型输入（编码-Encode）阶段"><a href="#模型输入（编码-Encode）阶段" class="headerlink" title="模型输入（编码 Encode）阶段"></a>模型输入（编码 Encode）阶段</h4><ol>
<li><p><strong>分词（Tokenize）</strong></p>
<p>将文本拆分为词元（Token），常见的分词方式包括字级、词级、子词级（如 BPE、WordPiece）、空格分词等。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">输入: &quot;你好&quot;</span><br><span class="line">分词: [&quot;你&quot;, &quot;好&quot;]</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>映射（Mapping）</strong></p>
<p>将每个词元映射为词汇表中的唯一 ID，生成的数字序列即为模型的输入。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">分词: [&quot;你&quot;, &quot;好&quot;]</span><br><span class="line">映射: [<span class="number">1001</span>, <span class="number">1002</span>]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="模型输出（解码-Decode）阶段"><a href="#模型输出（解码-Decode）阶段" class="headerlink" title="模型输出（解码 Decode）阶段"></a>模型输出（解码 Decode）阶段</h4><ol>
<li><p><strong>反映射（De-mapping）</strong></p>
<p>模型输出的数字序列通过词汇表映射回对应的词元，二者是一一对应的关系。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">输出: [<span class="number">1001</span>, <span class="number">1002</span>]</span><br><span class="line">反映射: [&quot;你&quot;, &quot;好&quot;]</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>文本重组</strong></p>
<p>将解码后的词元以某种规则重新拼接为完整文本。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">反映射: [&quot;你&quot;, &quot;好&quot;]</span><br><span class="line">重组: &quot;你好&quot;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="直观感受"><a href="#直观感受" class="headerlink" title="直观感受"></a>直观感受</h4><p>访问 <a href="https://tiktokenizer.vercel.app">Tiktokenizer</a>，通过右上角选取不同的 Tokenizer 进行尝试</p>
<h3 id="词汇表"><a href="#词汇表" class="headerlink" title="词汇表"></a>词汇表</h3><p>两种常见的构建词汇表的方法：</p>
<ul>
<li><strong>BPE（Byte-Pair Encoding）</strong>：用于 GPT、GPT-2、RoBERTa、BART 和 DeBERTa 等模型。</li>
<li><strong>WordPiece</strong>：用于 DistilBERT、MobileBERT、Funnel Transformers 和 MPNET 等模型。</li>
</ul>
<h4 id="BPE"><a href="#BPE" class="headerlink" title="BPE"></a>BPE</h4><p>BPE（Byte Pair Encoding，字节对编码）在 NLP 里是一种<strong>贪心式的子词（subword）分词算法</strong>。<br>理解：从“字符”开始，反复把<strong>出现次数最多的相邻字符对</strong>合并成新的符号，并加入词汇表，直到达到预设的词汇表大小。</p>
<blockquote>
<p>为什么可以处理 OOV（Out-Of-Vocabulary）情况</p>
<p>因为所有词汇都是由字符或词根组成的，通过对单个字符的学习，可以组成oov的词汇</p>
<p>为什么需要词汇表</p>
<p>编码时，从文本到模型：需要将文本分词为 Tokens，再通过词汇表将 Tokens 转换为 Token IDs，再传给transformer</p>
<p>解码时，从模型到文本：需要通过词汇表Token IDs 转换为 Tokens，再把Tokens 拼接为文本</p>
</blockquote>
<h5 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h5><ol>
<li><strong>初始化词汇表 $V$</strong>：<ul>
<li>$V$ 包含语料库中的所有唯一字符，即单词字符的集合。</li>
</ul>
</li>
<li><strong>统计字符对的频次</strong>：<ul>
<li>对于每个单词的字符序列，统计相邻字符对的出现频次。</li>
</ul>
</li>
<li><strong>找到频次（Score）最高的字符对并合并</strong>：<ul>
<li>选择出现频率最高的字符对 $(x, y)$，将其合并为新符号 $xy$。</li>
</ul>
</li>
<li><strong>更新词汇表并重复步骤 2 到 4</strong>：<ul>
<li>将新符号添加到词汇表 $V = V \cup {xy}$。</li>
<li>更新语料库中的单词表示，重复统计和合并过程，直到满足停止条件（例如，词汇表达到预定大小）。</li>
</ul>
</li>
</ol>
<p><strong>示例</strong></p>
<p>我们需要将语料库（corpus）的文本拆分为单词，假设当前语料库包含的单词和对应频次如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&quot;low&quot;, 5), (&quot;lower&quot;, 2), (&quot;newest&quot;, 6), (&quot;widest&quot;, 3)</span><br></pre></td></tr></table></figure>
<p><strong>步骤 1：初始化词汇表</strong></p>
<p><strong>将单词拆分为字符序列</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;), 5  </span><br><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;, &quot;e&quot;, &quot;r&quot;), 2  </span><br><span class="line">(&quot;n&quot;, &quot;e&quot;, &quot;w&quot;, &quot;e&quot;, &quot;s&quot;, &quot;t&quot;), 6  </span><br><span class="line">(&quot;w&quot;, &quot;i&quot;, &quot;d&quot;, &quot;e&quot;, &quot;s&quot;, &quot;t&quot;), 3</span><br></pre></td></tr></table></figure>
<p><strong>词汇表 V</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;l&#x27;, &#x27;o&#x27;, &#x27;w&#x27;, &#x27;e&#x27;, &#x27;r&#x27;, &#x27;n&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, &#x27;i&#x27;, &#x27;d&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>步骤 2：统计字符对的频次</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">字符对频次统计结果:</span><br><span class="line">(&#x27;l&#x27;, &#x27;o&#x27;): 7        # 5 (low) + 2 (lower)</span><br><span class="line">(&#x27;o&#x27;, &#x27;w&#x27;): 7        # 5 (low) + 2 (lower)</span><br><span class="line">(&#x27;w&#x27;, &#x27;e&#x27;): 8        # 2 (lower) + 6 (newest)</span><br><span class="line">(&#x27;e&#x27;, &#x27;r&#x27;): 2</span><br><span class="line">(&#x27;n&#x27;, &#x27;e&#x27;): 6</span><br><span class="line">(&#x27;e&#x27;, &#x27;w&#x27;): 6</span><br><span class="line">(&#x27;e&#x27;, &#x27;s&#x27;): 9        # 6 (newest) + 3 (widest)</span><br><span class="line">(&#x27;s&#x27;, &#x27;t&#x27;): 9        # 6 (newest) + 3 (widest)</span><br><span class="line">(&#x27;w&#x27;, &#x27;i&#x27;): 3</span><br><span class="line">(&#x27;i&#x27;, &#x27;d&#x27;): 3</span><br><span class="line">(&#x27;d&#x27;, &#x27;e&#x27;): 3</span><br></pre></td></tr></table></figure>
<p><strong>步骤 3：找到频次最高的字符对并合并</strong></p>
<p><strong>选择频次最高的字符对</strong>：</p>
<ul>
<li><code>(&quot;e&quot;, &quot;s&quot;)</code> 和 <code>(&quot;s&quot;, &quot;t&quot;)</code>，频次均为 9。可以任选其一进行合并，假设选择排序第一的： <code>(&quot;e&quot;, &quot;s&quot;)</code>。</li>
</ul>
<p><strong>合并 <code>(&quot;e&quot;, &quot;s&quot;)</code> 为新符号 <code>es</code></strong>。</p>
<p><strong>记录合并操作</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Merge 1: (&quot;e&quot;, &quot;s&quot;) -&gt; &quot;es&quot;</span><br></pre></td></tr></table></figure>
<p><strong>步骤 4：更新词汇表并重复</strong></p>
<p><strong>更新单词序列</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;), 5  </span><br><span class="line">(&quot;l&quot;, &quot;o&quot;, &quot;w&quot;, &quot;e&quot;, &quot;r&quot;), 2  </span><br><span class="line">(&quot;n&quot;, &quot;e&quot;, &quot;w&quot;, &quot;es&quot;, &quot;t&quot;), 6  </span><br><span class="line">(&quot;w&quot;, &quot;i&quot;, &quot;d&quot;, &quot;es&quot;, &quot;t&quot;), 3</span><br></pre></td></tr></table></figure>
<p><strong>更新词汇表 V</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;l&#x27;, &#x27;o&#x27;, &#x27;w&#x27;, &#x27;e&#x27;, &#x27;r&#x27;, &#x27;n&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, &#x27;i&#x27;, &#x27;d&#x27;, &#x27;es&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p><strong>重复步骤 2 到 4，直到达到预定的词汇表大小</strong>。</p>
<h4 id="WordPiece"><a href="#WordPiece" class="headerlink" title="WordPiece"></a>WordPiece</h4><p>WordPiece 是 Google 在 2016 年为语音识别与 BERT 提出的<strong>子词（subword）分词算法</strong>，可看作 BPE 的“似然改进版”。理解：“<strong>用概率贪心而不是频次贪心，从字符开始逐步合并子词</strong>。”</p>
<p>与 BPE 不同，WordPiece 的 Score 由字符对频次与其组成部分频次的比值决定，定义 Score：</p>
<script type="math/tex; mode=display">
\text{Score}_{\text{WordPiece}}(x, y) = \frac{\text{freq}(xy)}{\text{freq}(x) \times \text{freq}(y)}</script><p>其中, $\text{freq}(x)$, $\text{freq}(y)$ 和 $\text{freq}(xy)$ 分别表示符号 $x$, $y$ 和它们合并后的符号 $xy$ 的频次。</p>
<h5 id="步骤-1"><a href="#步骤-1" class="headerlink" title="步骤"></a>步骤</h5><ol>
<li><strong>初始化词汇表 $V$</strong>：<ul>
<li>与 BPE 相同, $V$ 包含语料库中的所有唯一字符，但处理方式略有不同：<strong>对于每个单词，除了首个字符外，其他字符前都加上 <code>##</code> 前缀。</strong></li>
</ul>
</li>
<li><strong>统计字符对的频次及 Score</strong>：<ul>
<li>对于每个可能的字符对 $(x, y)$，计算 $\text{freq}(x)$, $\text{freq}(y)$, $\text{freq}(xy)$，并计算 Score。</li>
</ul>
</li>
<li><strong>找到 Score 最高的字符对并合并</strong>：<ul>
<li>选择 Score 最高的字符对 $(x, y)$，将其合并为新符号 $xy$，注意：<ul>
<li>如果第二个符号以 <code>##</code> 开头，合并时去掉 <code>##</code> 前缀再进行连接。</li>
<li>新符号是否以 <code>##</code> 开头，取决于第一个符号是否以 <code>##</code> 开头。</li>
</ul>
</li>
</ul>
</li>
<li><strong>更新词汇表并重复步骤 2 到 4</strong>：<ul>
<li>将新符号添加到词汇表 $V = V \cup {xy}$。</li>
<li>更新语料库中的单词表示，重复统计和合并过程，直到满足停止条件。</li>
</ul>
</li>
</ol>
<h3 id="映射（Mapping）"><a href="#映射（Mapping）" class="headerlink" title="映射（Mapping）"></a>映射（Mapping）</h3><p>以 BPE 为例，最终词汇表 $V$ 中的 Token 和对应的频次分别为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vocab = &#123;</span><br><span class="line">    &#x27;lo&#x27;: 7,</span><br><span class="line">    &#x27;w&#x27;: 16,</span><br><span class="line">    &#x27;e&#x27;: 8,</span><br><span class="line">    &#x27;r&#x27;: 2,</span><br><span class="line">    &#x27;n&#x27;: 6,</span><br><span class="line">    &#x27;est&#x27;: 9,</span><br><span class="line">    &#x27;i&#x27;: 3,</span><br><span class="line">    &#x27;d&#x27;: 3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Token to ID: &#123;&#x27;lo&#x27;: 0, &#x27;w&#x27;: 1, &#x27;e&#x27;: 2, &#x27;r&#x27;: 3, &#x27;n&#x27;: 4, &#x27;est&#x27;: 5, &#x27;i&#x27;: 6, &#x27;d&#x27;: 7&#125;</span><br><span class="line">ID to Token: &#123;0: &#x27;lo&#x27;, 1: &#x27;w&#x27;, 2: &#x27;e&#x27;, 3: &#x27;r&#x27;, 4: &#x27;n&#x27;, 5: &#x27;est&#x27;, 6: &#x27;i&#x27;, 7: &#x27;d&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>当然，也可以根据频次或者其他规则进行特殊处理。</p>
<p>以上是编码部分的概述，实际上在文本预处理的时候还会增加特殊标记，但这些以及后续的解码部分大多是一些文本处理的规则，这里就不过多赘述了，Tokenizer 之间的核心差异在于使用的分割方法和词汇表的构建策略。</p>
<h3 id="transformer中的分词"><a href="#transformer中的分词" class="headerlink" title="transformer中的分词"></a>transformer中的分词</h3><p>在 Transformers 中，<strong>分词（tokenization）</strong> 实际上包含以下几个步骤：</p>
<ol>
<li><strong>标准化（Normalization）</strong>：对文本进行必要的清理操作，例如删除多余空格或重音符号、进行 Unicode 标准化等。</li>
<li><strong>预分词（Pre-tokenization）</strong>：将输入拆分为单词。</li>
<li><strong>通过模型处理输入（Running the input through the model）</strong>：使用预分词后的单词生成一系列词元（tokens）。</li>
<li><strong>后处理（Post-processing）</strong>：添加分词器的特殊标记，生成注意力掩码（attention mask）和词元类型 ID（token type IDs）。</li>
</ol>
<p>流程图如下</p>
<p><img src="/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/image-20250808100051423.png" alt="image-20250808100051423"></p>
<h4 id="注意力掩码（Attention-Mask）和词元类型-ID-（Token-Type-IDs）是什么？"><a href="#注意力掩码（Attention-Mask）和词元类型-ID-（Token-Type-IDs）是什么？" class="headerlink" title="注意力掩码（Attention Mask）和词元类型 ID （Token Type IDs）是什么？"></a>注意力掩码（Attention Mask）和词元类型 ID （Token Type IDs）是什么？</h4><p><img src="/2025/08/08/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AE%97%E6%B3%95/tokenizer/image-20250808100813881.png" alt="image-20250808100813881"></p>
<p>1️⃣ 注意力掩码（Attention Mask）<br>• 目的：告诉模型“哪些位置可以被看到”，其余位置直接屏蔽。<br>• 典型场景：<br>– <strong>自注意力里做 padding 掩码</strong>：把 <code>&lt;pad&gt;</code> 对应的位置设为 −∞，softmax 后权重=0。<br>– <strong>解码器自回归掩码</strong>：生成任务用下三角掩码，避免第 i 个 token 看到未来 token。</p>
<p>2️⃣ 词元类型 ID（Token Type IDs，也叫 Segment IDs）<br>• 目的：区分<strong>同一次输入里不同句子或段落</strong>，让模型知道“这段属于 A，那段属于 B”。<br>• 典型场景：<br>– BERT 做句子对分类（NSP）：<code>[CLS] 句子A [SEP] 句子B [SEP]</code> → TypeID = 0 0 0 0 1 1 1。<br>– RoBERTa、GPT 等单句模型则<strong>不需要</strong> Token Type IDs。</p>
<p><strong>注意力掩码</strong>确保模型只关注实际的词元，忽略填充部分，从而避免无效的计算：</p>
<ul>
<li><strong>1</strong>：表示模型应关注的词元（Tokens）</li>
<li><strong>0</strong>：表示模型应忽略的词元（通常是填充 <code>padding</code> 的部分）。</li>
</ul>
<p><strong>词元类型 ID</strong> 用于区分输入中的不同句子或段落：</p>
<ul>
<li><strong>0</strong>：表示第一个句子的词元。</li>
<li><strong>1</strong>：表示第二个句子的词元。</li>
</ul>
<blockquote>
<p>CLS，SEP，PAD都是什么意思</p>
<p><code>[CLS]</code>（Classification），作用：对应位置的隐藏状态被当作<strong>整句/句对的“整体表示”</strong>，用来接分类头做句子级任务（情感分类、NLI 等）。</p>
<p><code>[SEP]</code>（Separator），作用：让模型知道<strong>分段 / 句子边界</strong>，配合 Token Type IDs 区分句子 A 和句子 B。</p>
<p><code>[PAD]</code>（padding token）的作用是 <strong>批量训练时把不同长度的序列补齐到同一长度</strong>，让张量可以堆叠成规整的矩阵；模型在计算注意力时通过 Attention Mask 把 <code>[PAD]</code> 对应的位置屏蔽掉，不让它们影响有效 token 的表示。</p>
</blockquote>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/blob/master/Guide/21. BPE vs WordPiece：理解 Tokenizer 的工作原理与子词分割方法.md">AI-Guide-and-Demos-zh_CN/Guide/21. BPE vs WordPiece：理解 Tokenizer 的工作原理与子词分割方法.md at master · Hoper-J/AI-Guide-and-Demos-zh_CN</a></p>
]]></content>
      <categories>
        <category>大模型算法</category>
        <category>tokenizer</category>
      </categories>
      <tags>
        <tag>tokenizer</tag>
      </tags>
  </entry>
  <entry>
    <title>前端1——入门</title>
    <url>/2025/02/15/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/</url>
    <content><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>vscode</p>
<p>插件：</p>
<p>HTML CSS Support 写css代码</p>
<p>Live Serve 实时预览html网页</p>
<p>Auto Rename Tag 同步修改标签名称</p>
<h2 id="HTML"><a href="#HTML" class="headerlink" title="HTML"></a>HTML</h2><p>html （hyper text markup language） 超文本标记语言</p>
<p>网页是又html标签描述出来的</p>
<p>html文件结构</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span>//文档编码格式</span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;viewport&quot;</span> <span class="attr">content</span>=<span class="string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Document<span class="tag">&lt;/<span class="name">title</span>&gt;</span>//文档标题</span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span>//页面内容</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>块元素（block）：块级元素通常用于组织和布局页面的主要结构和内容，例如段落、标题、列表、表格等。它们用于创建页面的主要部分，将内容分隔成逻辑块。</p>
<p>行内元素（inline）：行内元素通常用于添加文本样式或为文本中的一部分应用样式。它们可以在文本中插入小的元素，例如超链接、强调文本等。</p>
<p>常用标签</p>
<p><code>&lt;h1&gt; &lt;/h1&gt;</code>一级标签</p>
<p><code>&lt;p&gt; &lt;/p&gt;</code>段落标签</p>
<p><code>&lt;b&gt; &lt;/b&gt;</code> bold 文本加粗</p>
<p><code>&lt;u&gt; &lt;/u&gt;</code> 下划线</p>
<p><code>&lt;s&gt; &lt;/s&gt;</code> 删除线</p>
<p>无序列表</p>
<p><code>&lt;ul&gt;</code><br>    <code>&lt;li&gt;1&lt;/li&gt;</code><br>    <code>&lt;li&gt;2&lt;/li&gt;</code><br><code>&lt;/ul&gt;</code></p>
<p>有序列表</p>
<p><code>&lt;ol&gt;</code><br>    <code>&lt;li&gt;1&lt;/li&gt;</code><br>    <code>&lt;li&gt;2&lt;/li&gt;</code><br><code>&lt;/ol&gt;</code></p>
<p>表格</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">table</span> <span class="attr">border</span>=<span class="string">&quot;1&quot;</span>&gt;</span>//边框宽度为1</span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">th</span>&gt;</span>标题1<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">th</span>&gt;</span>标题2<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>元素1<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>元素2<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>html属性 基本语法：&lt;开始标签 属性名=“属性值”&gt;</p>
<p><code>&lt;a href=&quot;www.zxj-2023.github.io&quot; target=&quot;_blank&quot;&gt;超链接&lt;/a&gt;</code> 超链接，target决定链接打开方式</p>
<p><code>&lt;br&gt;</code> 换行</p>
<p><code>&lt;hr&gt;</code> 分割线</p>
<p><code>&lt;img src=&quot;图片路径或链接&quot; alt=&quot;代替文本&quot; width=&quot;宽度&quot; height=&quot;高度&quot;&gt;&lt;/img&gt;</code> 图片</p>
<p><code>&lt;div class=&quot;名称&quot;&gt;&lt;/div&gt;</code>块级标签，用于创建页面的布局结构，如导航栏，页眉等</p>
<p>优先级：id&gt;class&gt;标签名</p>
<p><code>&lt;span&gt;&lt;/span&gt;</code>包装文本以便对其使用css，js行为或样式等</p>
<p>form标签是html表单的容器</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;#&quot;</span>&gt;</span>//URL</span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">&quot;username&quot;</span>&gt;</span>用户名：<span class="tag">&lt;/<span class="name">label</span>&gt;</span>//与span类似，for用于和input的id绑定</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">id</span>=<span class="string">&quot;username&quot;</span> <span class="attr">placehoud</span>=<span class="string">&quot;请输入用户名&quot;</span>&gt;</span></span><br><span class="line">	//input其他属性，value：规定input内的值</span><br><span class="line">	<span class="tag">&lt;<span class="name">label</span>&gt;</span>密码：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;password&quot;</span> <span class="attr">placehoud</span>=<span class="string">&quot;请输入密码&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span>&gt;</span>性别：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span>&gt;</span> 男//单选择 名称一致</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;radio&quot;</span> <span class="attr">name</span>=<span class="string">&quot;gender&quot;</span>&gt;</span> 女</span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">label</span>&gt;</span>爱好：<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span>&gt;</span> 唱歌//多选</span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;hobby&quot;</span>&gt;</span> 跳舞</span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span>&gt;</span>//提交按钮 提交表单数据</span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="CSS"><a href="#CSS" class="headerlink" title="CSS"></a>CSS</h2><p>css cascading style sheets 用于定义网页样式和布局的样式表语言，通过CSS，可以指定页面中各个元素的颜色、字体、大小、间距、边框、背景等样式，从而实现更精确的页面设计。</p>
<p>语法：</p>
<p>选择器{</p>
<p>​    属性1：属性值1；</p>
<p>​    属性2：属性值2；</p>
<p>}</p>
<p>内部样式表：放在head里面</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css">        <span class="selector-tag">p</span>&#123;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">color</span>:bule;</span></span><br><span class="line"><span class="language-css">            <span class="attribute">font-size</span>:<span class="number">16px</span>;//字体大小</span></span><br><span class="line"><span class="language-css">            <span class="attribute">background-color</span>:yellow//背景色</span></span><br><span class="line"><span class="language-css">            font-family:<span class="string">&#x27;KaiTi&#x27;</span>//修改字体，楷体</span></span><br><span class="line"><span class="language-css">        &#125;</span></span><br><span class="line"><span class="language-css">    </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span></span><br><span class="line">        内容</span><br><span class="line">    <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>外部样式：需在head链接</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;路径&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>内联样式：标签内</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span> <span class="attr">style</span>=<span class="string">&quot;color=red;&quot;</span>&gt;</span></span><br><span class="line">    内容</span><br><span class="line"><span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>优先级：内联样式&gt;内部样式表&gt;外部样式</p>
<p>css选择器：</p>
<p>元素选择器：标签名</p>
<p>类选择器：.+类名</p>
<p>id选择器：#+id名</p>
<p>通用选择器：*</p>
<p>子代选择器：父+&gt;+子</p>
<p>后代选择器：父+空格+子</p>
<p>相邻元素选择器：1+2    需要满足相邻条件</p>
<p>伪类选择器</p>
<p>css属性：</p>
<p><a href="https://www.runoob.com/cssref/css-reference.html">CSS 参考手册 |菜鸟教程</a></p>
<p><code>&lt;h1 style=&quot;font: bolder 50px &#39;KaiTi&#39;;&quot;&gt;复合属性&lt;/h1&gt;</code> font符合属性示例</p>
<p>区分块、行内、行内块元素width和height的差异</p>
<p>通过display转换以上三者(block,inline,inline-block)</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.div-inline&#123;</span><br><span class="line">	display:inline;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>盒子模型：</p>
<ol>
<li>内容（content）</li>
<li>内边距（padding）：内容与边框之间的空间</li>
<li>边框（border）：盒子的边界  上右下左</li>
<li>外边距（margin）：盒子与其他元素之间的空间</li>
</ol>
<p><img src="/2025/02/15/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/asdsdf.png" alt="asdsdf"></p>
<p>浮动：改变元素默认的排列顺序，使网页布局更加灵活多变(letf right)</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.son&#123;</span><br><span class="line">	float:left;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>清除浮动的方式</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.father&#123;</span><br><span class="line">	overflow: hidden;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定位布局：</p>
<p>相对定位(relative)∶相对于元素在文档流中的正常位置进行定位。</p>
<p>绝对定位(absolute)︰相对于其最近的已定位祖先元素进行定位，不占据文档流。</p>
<p>固定定位(fixed)︰相对于浏览器窗口进行定位。不占据文档流，固定在屏幕上的位置，不随滚动而移动。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.box-relative&#123;</span><br><span class="line">	position: relative;//相对定位</span><br><span class="line">	left:</span><br><span class="line">	right:</span><br><span class="line">	top:</span><br><span class="line">	bottom:</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript"></a>JavaScript</h2><p>JavaScript是一种轻量级、解释型、面向对象的脚本语言。它主要被设计用于在网页上实现动态效果，增加用户与网页的交互性。<br>作为一种客户端脚本语言，JavaScript可以直接嵌入HTML，并在浏览器中执行。<br>与HTML和CSS不同，JavaScript使得网页不再是静态的，而是可以根据用户的操作动态变化的。</p>
<p><code>客户端脚本</code>:用于在用户浏览器中执行，实现动态效果和用户交互。</p>
<p><code>网页开发</code>:与HTML和CSS协同工作，使得网页具有更强的交互性和动态性。</p>
<p><code>后端开发</code>︰使用Node.js，JavaScript 也可以在服务器端运行，实现服务器端应用的开发。</p>
<p>js的导入</p>
<p>内联</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">	<span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;hello,world&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>外联</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;相对路径&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;hello,world&#x27;</span>)<span class="comment">//控制台输出</span></span><br><span class="line"><span class="title function_">alert</span>(<span class="string">&#x27;&#x27;</span>)<span class="comment">//内联弹窗</span></span><br></pre></td></tr></table></figure>
<p>js语句</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">//变量</span></span><br><span class="line"><span class="keyword">var</span> x;<span class="comment">//varible</span></span><br><span class="line"><span class="keyword">let</span> t=<span class="number">5</span>;<span class="comment">//块级作用域</span></span><br><span class="line"><span class="keyword">const</span> <span class="variable constant_">PI</span> =<span class="number">3.14</span>;<span class="comment">//常量</span></span><br><span class="line"><span class="comment">//条件语句</span></span><br><span class="line"><span class="keyword">if</span>()&#123;&#125;<span class="keyword">else</span>&#123;&#125;</span><br><span class="line"><span class="comment">//循环，for，while</span></span><br><span class="line"><span class="comment">//函数</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">function_name</span>(<span class="params"></span>)&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> 返回值;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用html属性触发事件</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span> <span class="attr">onclick</span>=<span class="string">&quot;click_event()&quot;</span>&gt;</span></span><br><span class="line">        点击事件</span><br><span class="line">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">onfocus</span>=<span class="string">&quot;focus_event()&quot;</span> <span class="attr">onblur</span>=<span class="string">&quot;blur_event()&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="language-javascript"></span></span><br><span class="line"><span class="language-javascript">    	<span class="keyword">function</span> <span class="title function_">click_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="title function_">alert</span>(<span class="string">&#x27;触发点击事件&#x27;</span>)</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">        </span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">function</span> <span class="title function_">focus_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;获取焦点&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">        </span></span><br><span class="line"><span class="language-javascript">        <span class="keyword">function</span> <span class="title function_">blur_event</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="language-javascript">        &#123;</span></span><br><span class="line"><span class="language-javascript">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;失去焦点&#x27;</span>);</span></span><br><span class="line"><span class="language-javascript">        &#125;</span></span><br><span class="line"><span class="language-javascript">    </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>DOM</p>
<p>当网页被加载时，浏览器会创建页面的文档对象模型，也就是DOM (Document Object Model) .每个HTML或XML文档都可以被视为一个文档树，文档树是整个文档的层次结构表示。</p>
<p>文档节点是整个文档树的根节点。</p>
<p>DOM为这个文档树提供了一个编程接口，开发者可以使用JavaScript来操作这个树状结构。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;box1&quot;</span>&gt;</span>ID选择器标签<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;box2&quot;</span>&gt;</span>类选择器标签<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">button</span>&gt;</span></span><br><span class="line">        点击按钮</span><br><span class="line">    <span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">scrip</span>&gt;</span></span><br><span class="line">    	var element_id = document.getElementById(&#x27;box1&#x27;);//id唯一，获取的是元素</span><br><span class="line">        console.log(element_id)</span><br><span class="line">		</span><br><span class="line">        var element_class = document.getElementsByClassName(&#x27;box2&#x27;)[0];//类不唯一，获取的是数组</span><br><span class="line">        console.log(element_id)</span><br><span class="line">        </span><br><span class="line">        element_id.innerHTML = &#x27;修改id标签内容&#x27;;</span><br><span class="line">        element_id.innerText</span><br><span class="line">        element_id.style.color</span><br><span class="line">        element_id.style.fontSize</span><br><span class="line">        </span><br><span class="line">        //DOM属性绑定事件</span><br><span class="line">        var button_element = document.getElementsByTagName(&#x27;button&#x27;);</span><br><span class="line">        </span><br><span class="line">        button_element.onclick = function()&#123;</span><br><span class="line">        	alert(&#x27;DOM 属性按键触发&#x27;)</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        button)element.addEventListener(&#x27;click&#x27;,click_event)</span><br><span class="line">        function click_event()&#123;</span><br><span class="line">        	alert(&#x27;通过addEventListener触发&#x27;)</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">scrip</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>对象</strong></p>
<p>对象（object）是 JavaScript 语言的核心概念，也是最重要的数据类型</p>
<p>简单说，对象就是一组“键值对”（key-value）的集合，是一种无序的复合数据集合</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> user = &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="string">&#x27;itbaizhan&#x27;</span>,</span><br><span class="line">  <span class="attr">age</span>: <span class="string">&#x27;13&#x27;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>对象的每一个键名又称为“属性”（property），它的“键</p>
<p>值”可以是任何数据类型。如果一个属性的值为函数，通常把这个属性称为“方法”，它可以像函数那样调用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> user = &#123;</span><br><span class="line">  <span class="attr">getName</span>: <span class="keyword">function</span> (<span class="params">name</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> name;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">user.<span class="title function_">getName</span>(<span class="string">&quot;itbaizhan&quot;</span>) <span class="comment">// itbaizhan</span></span><br></pre></td></tr></table></figure>
<p><img src="/2025/02/15/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF1/image-20211025173456785.png" alt="image-20211025173456785"></p>
<h2 id="参考视频"><a href="#参考视频" class="headerlink" title="参考视频"></a>参考视频</h2><p><a href="https://www.bilibili.com/video/BV1BT4y1W7Aw/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">3小时前端入门教程（HTML+CSS+JS）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型开发学习之路——动手学大模型应用开发</title>
    <url>/2025/04/19/%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/%E5%8A%A8%E6%89%8B%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<h3 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h3><p>技术栈：streamlit，fastapi，Gradio，langchain，dify，coze</p>
<h4 id="conda常用指令"><a href="#conda常用指令" class="headerlink" title="conda常用指令"></a>conda常用指令</h4><p><strong>列出所有环境</strong>conda env list</p>
<p><strong>删除指定环境</strong>conda env remove —name 环境名称</p>
<p>创建 Conda 环境conda create -n llm-universe python==3.9.0</p>
<p>激活 Conda 环境conda activate llm-universe</p>
<p>安装依赖项pip install -r requirements.txt</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p><a href="https://www.datawhale.cn/learn/content/19/445">动手学大模型应用开发-课程详情 | Datawhale</a></p>
<p><a href="https://datawhalechina.github.io/llm-universe/#/">动手学大模型应用开发</a></p>
<p><a href="https://www.bilibili.com/video/BV1QuZAY2EW1?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">10 分钟！零基础彻底学会 Cursor AI 编程 | Cursor AI 编程｜Cursor 进阶技巧 | Cursor 开发小程序 | 小白 AI 编程_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV12TLAzuEni?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=12">【Langchain进阶篇】12.Prompt templates Few shot. Example selector(提示模板：少镜头。示例选择器)_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.langchain.com.cn/docs/concepts/">概念指南 | LangChain中文网</a></p>
]]></content>
      <categories>
        <category>大模型开发学习之路</category>
        <category>动手学大模型应用开发</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>开发</tag>
      </tags>
  </entry>
  <entry>
    <title>前端2——巩固</title>
    <url>/2025/02/18/%E5%AD%A6%E4%B9%A0/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF2/</url>
    <content><![CDATA[<h3 id="vscode"><a href="#vscode" class="headerlink" title="vscode"></a>vscode</h3><p>代码格式化：shift+alt+f</p>
<p>向上或向下移动一行:Alt+Up或Alt+Down</p>
<p>快速开始新一行：ctrl+enter</p>
<p>快速复制一行代码:Shift+Alt+Up 或Shift+Alt+Down</p>
<p>快速保存:Ctrl +S</p>
<p>快速查找:Ctrl + F</p>
<p>快速替换:Ctrl+ H</p>
<p>快速移动一行 alt + ↓或↑</p>
<p>多光标： alt + 鼠标左键</p>
<h3 id="html5"><a href="#html5" class="headerlink" title="html5"></a>html5</h3><p><strong>合并单元格</strong></p>
<ul>
<li>水平合并：colspan</li>
<li>垂直合并：rowspan</li>
</ul>
<p><strong>h5新标签</strong></p>
<ol>
<li><code>&lt;header&gt;&lt;/header&gt;</code>  头部</li>
<li><code>&lt;nav&gt;&lt;/nav&gt;</code>  导航</li>
<li><code>&lt;section&gt;&lt;/section&gt;</code>定义文档中的节,比如章节、页眉、页脚</li>
<li><code>&lt;aside&gt;&lt;/aside&gt;</code>  侧边栏</li>
<li><code>&lt;footer&gt;&lt;/footer&gt;</code> 脚部</li>
<li><code>&lt;article&gt;&lt;/article&gt;</code>  代表一个独立的、完整的相关内容块,例如一篇完整的论坛帖子，一篇博客文章，一个用户评论等</li>
</ol>
<p><strong>查漏补缺</strong></p>
<p><code>&lt;figure&gt;</code>元素表示文档流中独立的内容块。这个内容通常与主文档相关，但可以被移动到文档的其他位置（如侧边栏、脚注或独立的附件）而不会影响理解文档的其余部分。</p>
<p><code>&lt;section&gt;</code>元素用于定义文档中的一个区域（section），它通常表示文档中的一个主题或内容块。</p>
<p>图像标题（<code>figcaption</code>）元素用于添加标题以描述 <code>figure</code> 元素中包含的图像。<code>&lt;figcaption&gt;</code> 必须是 <code>&lt;figure&gt;</code> 元素的子元素，并且它必须是 <code>&lt;figure&gt;</code> 中的第一个或最后一个子元素</p>
<p>“URL” 是 “Uniform Resource Locator” 的缩写，中文意思是 “统一资源定位符”。它是一种用于在互联网上定位和访问资源（如网页、图像、视频等）的地址。</p>
<p><code>fieldset</code> 元素用于在 Web 表单中将相关的输入和标签组合在一起。 <code>fieldset</code> 元素是块级元素，这意味着它们出现在新的一行上。</p>
<p><code>legend</code> 元素充当 <code>fieldset</code> 元素中内容的标题。 它为用户提供了应该在表单的该部分中输入什么的上下文。</p>
<p> <code>&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;</code>是一个非常重要的 HTML 元标签，用于控制网页在移动设备上的布局和显示方式</p>
<p>article和section</p>
<p>article标签表示文档、页面、应用或网站的一部分，具有独立性和完整性。它通常包含一些内容，如新闻报道、博客文章、论坛帖子等，这些内容可以被单独地分享、链接和索引。</p>
<p>section标签则表示文档或应用的一部分，但不具有独立性和完整性。它通常用于组织内容，将页面或应用分成不同的部分，例如头部、主体、脚注等。</p>
<p><code>method</code> 属性指定了如何将表单数据发送到 <code>action</code> 属性中指定的 URL。 表单数据可以通过 <code>GET</code> 请求作为 URL 参数发送（<code>method=&quot;get&quot;</code>）或通过 <code>POST</code> 请求作为请求正文中的数据发送（<code>method=&quot;post&quot;</code>）。</p>
<p>给密码 <code>input</code> 元素添加 <code>pattern</code> 属性，要求输入匹配 <code>[a-z0-5]&#123;8,&#125;</code>。上面是一个正则表达式，匹配 8 个以上的小写字母或数字 <code>0</code> 到 <code>5</code>。</p>
<p><code>&lt;select&gt;</code> 和 <code>&lt;option&gt;</code> 是 HTML 中用于创建下拉列表的元素</p>
<p><code>&lt;textarea&gt;</code> 是 HTML 中的一个表单元素，用于多行文本输入，允许用户输入和编辑大量文本。</p>
<p><strong>英文全称记忆</strong></p>
<p><code>&lt;ul&gt;</code> ： “Unordered List” </p>
<p><code>&lt;li&gt;</code> ： “List - item”</p>
<p><code>src</code>： “source”</p>
<p><code>css text-align</code>: “text alignment”（文本对齐方式）</p>
<p><code>link rel</code>:relationship</p>
<p><code>&lt;hr&gt;</code>:”Horizontal Rule”</p>
<h3 id="css3"><a href="#css3" class="headerlink" title="css3"></a>css3</h3><p><strong>查漏补缺</strong></p>
<p><code>opacity</code> 是 CSS 中用于控制元素透明度的属性。它可以设置一个元素的透明度级别，取值范围从 <code>0</code>（完全透明）到 <code>1</code>（完全不透明）</p>
<p><code>box-shadow</code> 属性允许你在元素周围应用一个或多个阴影。<code>box-shadow: offsetX offsetY blurRadius color;</code></p>
<p><code>linear-gradient</code> 是 CSS 中用于创建线性渐变背景的属性。它允许你在元素的背景中定义多种颜色之间的平滑过渡效果</p>
<p><code>hsla</code>（Hue色相, Saturation饱和度, Lightness, Alpha透明度）是一种在 CSS 中定义颜色的方式，基于 HSL（色相、饱和度、亮度）颜色模型，并且允许设置透明度（alpha 值）。</p>
<p><code>vh</code> 是 CSS 中的一种相对长度单位，表示视口高度（Viewport Height）的百分比。具体来说，<code>1vh</code> 等于视口高度的 1%。视口是指浏览器窗口中可见的部分，不包括工具栏、地址栏等非内容区域。</p>
<p><code>em</code> 是 CSS 中的一种相对单位，用于表示元素的字体大小（<code>font-size</code>）的倍数。具体来说，<code>1em</code> 等于当前元素的字体大小。例如，如果一个元素的字体大小为 <code>16px</code>，那么 <code>1em</code> 就等于 <code>16px</code>。</p>
<p><code>rem</code>（Root Em）是 CSS 中的一种相对单位，表示相对于根元素（<code>html</code> 元素）的字体大小（<code>font-size</code>）的倍数。</p>
<p>在 CSS 中，<code>cursor</code> 属性用于定义鼠标指针位于元素上时的形状或图标。它对于改善用户体验非常重要，因为它为用户提供了视觉反馈，让他们知道可与页面上的不同元素进行哪些操作。</p>
<p><code>z-index</code>属性设置元素的堆叠顺序。拥有更高堆叠顺序的元素总是会处于堆叠顺序较低的元素的前面</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.box1</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">200px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">position</span>:absolute;</span><br><span class="line">    <span class="attribute">z-index</span>: <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.box2</span>&#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: green;</span><br><span class="line">    <span class="attribute">position</span>:absolute;</span><br><span class="line">    <span class="attribute">z-index</span>: <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>css3新特性</strong></p>
<p><strong>圆角</strong></p>
<p>使用 CSS3 <code>border-radius</code> 属性，你可以给任何元素制作 “圆角”</p>
<p><code>border-radius</code> 属性，可以使用以下规则：</p>
<ol>
<li>四个值: 第一个值为左上角，第二个值为右上角，第三个值为右下角，第四个值为左下角</li>
<li>三个值: 第一个值为左上角, 第二个值为右上角和左下角，第三个值为右下角</li>
<li>两个值: 第一个值为左上角与右下角，第二个值为右上角与左下角</li>
<li>一个值： 四个圆角值相同</li>
</ol>
<p><strong>阴影</strong></p>
<p>box-shadow 向框添加一个或多个阴影。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">box-shadow</span>: h-shadow v-shadow blur color;</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>h-shadow</td>
<td>必选，水平阴影的位置</td>
</tr>
<tr>
<td>v-shadow</td>
<td>必选，垂直阴影的位置</td>
</tr>
<tr>
<td>blur</td>
<td>可选，模糊距离</td>
</tr>
<tr>
<td>color</td>
<td>可选，阴影的颜色</td>
</tr>
</tbody>
</table>
</div>
<p><strong>动画</strong></p>
<p>使用<code>@keyframes</code>规则，你可以创建动画</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="keyword">@keyframes</span> name &#123;</span><br><span class="line">    <span class="selector-tag">from</span>|<span class="number">0%</span>&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">    percent&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="selector-tag">to</span>|<span class="number">100%</span>&#123;</span><br><span class="line">    	css样式</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>name：动画名称，开发人员自己命名；</p>
<p>percent：为百分比值，可以添加多个百分比值；</p>
<p><strong>animation执行动画</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="attribute">animation</span>: name duration timing-function delay iteration-count direction;</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>设置动画的名称</td>
</tr>
<tr>
<td>duration</td>
<td>设置动画的持续时间</td>
</tr>
<tr>
<td>timing-function</td>
<td>设置动画效果的速率（如下）</td>
</tr>
<tr>
<td>delay</td>
<td>设置动画的开始时间（延时执行）</td>
</tr>
<tr>
<td>iteration-count</td>
<td>设置动画循环的次数，infinite为无限次数的循环</td>
</tr>
<tr>
<td>direction</td>
<td>设置动画播放的方向（如下）</td>
</tr>
<tr>
<td>animation-play-state</td>
<td>控制动画的播放状态：running代表播放，而paused代表停止播放</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>timing-function值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>ease</td>
<td>逐渐变慢（默认）</td>
</tr>
<tr>
<td>linear</td>
<td>匀速</td>
</tr>
<tr>
<td>ease-in</td>
<td>加速</td>
</tr>
<tr>
<td>ease-out</td>
<td>减速</td>
</tr>
<tr>
<td>ease-in-out</td>
<td>先加速后减速</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>direction值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>normal</td>
<td>默认值为normal表示向前播放</td>
</tr>
<tr>
<td>alternate</td>
<td>动画播放在第偶数次向前播放，第奇数次向反方向播放</td>
</tr>
</tbody>
</table>
</div>
<p><strong>切换背景颜色</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;animation&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.animation</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">300px</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: red;</span><br><span class="line">    <span class="attribute">animation</span>: anima <span class="number">5s</span> linear <span class="number">5s</span> infinite;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.animation</span><span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">    <span class="attribute">animation-play-state</span>: paused;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">@keyframes</span> anima &#123;</span><br><span class="line">    <span class="number">0%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: red;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">50%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: green;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="number">100%</span> &#123;</span><br><span class="line">        <span class="attribute">background-color</span>: blueviolet;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>设置meta标签</strong></p>
<p>使用设备的宽度作为视图宽度并禁止初始的缩放。在<code>&lt;head&gt;</code>标签里加入这个meta标签。 </p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&lt;meta name=&quot;viewport&quot; <span class="attribute">content</span>=&quot;<span class="attribute">width</span>=device-<span class="attribute">width</span>, initial-<span class="attribute">scale</span>=<span class="number">1</span>,maximum-<span class="attribute">scale</span>=<span class="number">1</span>, user-scalable=no&quot;&gt;</span><br></pre></td></tr></table></figure>
<p><strong>参数解释</strong></p>
<ol>
<li><code>width = device-width</code> 宽度等于当前设备的宽度</li>
<li><code>initial-scale</code> 初始的缩放比例（默认设置为1.0）</li>
<li><code>maximum-scale</code> 允许用户缩放到的最大比例（默认设置为1.0）</li>
<li><code>user-scalable</code> 用户是否可以手动缩放（默认设置为no）</li>
</ol>
<h3 id="JS"><a href="#JS" class="headerlink" title="JS"></a>JS</h3><p> <code>querySelector()</code></p>
<h3 id="ES6"><a href="#ES6" class="headerlink" title="ES6"></a>ES6</h3><p>常用命令行工具有两种</p>
<ol>
<li><code>CMD</code> 命令行工具</li>
<li><code>PowerShell</code> 命令行工具</li>
</ol>
<p><strong>CMD命令行</strong></p>
<ol>
<li>打开命令行窗口<ol>
<li>win：左下角开始，找到运行，点击，输入<code>cmd</code>，回车</li>
<li>win：<code>win+r</code> 快速打开命令行窗口</li>
</ol>
</li>
<li>选择盘符：盘符名加冒号<code>E:</code></li>
<li>查看盘符及目录下文件与文件夹：<code>win:dir</code></li>
<li>清空命令行信息：<code>win:cls</code></li>
<li>进入文件夹或目录：<code>cd  文件夹名称</code></li>
<li>返回到上一级目录：<code>cd ../</code></li>
<li>快速补全目录或文件夹名称：<code>tab</code></li>
<li>创建文件夹：<code>mkdir 文件夹名称</code></li>
<li>查看历史输入过的命令：上下按键</li>
</ol>
<p><strong>PowerShell</strong></p>
<ol>
<li>打开方式<ol>
<li>在开始位置搜索<code>PowerShell</code>打开</li>
<li>在对应目录按住<code>shift</code>+右键，打开</li>
</ol>
</li>
<li>其他保持一直</li>
</ol>
<p>ECMAScript 和 JavaScript 的关系是，前者是后者的规格，后者是前者的一种实现，通常场合，这两个词是可以互换的。</p>
<p>ECMAScript 6（以下简称 ES6）是 JavaScript 语言的标准，在 2015 年 6 月发布。它的目标，是使得 JavaScript 语言可以用来编写复杂的大型应用程序，成为企业级开发语言。</p>
<h3 id="TypeScript"><a href="#TypeScript" class="headerlink" title="TypeScript"></a>TypeScript</h3><p><a href="https://www.bilibili.com/video/BV1xL4y1B7DG/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">为什么你应当使用 TypeScript? TS 十分钟快速入门_哔哩哔哩_bilibili</a></p>
<h3 id="参考视频和网站推荐"><a href="#参考视频和网站推荐" class="headerlink" title="参考视频和网站推荐"></a>参考视频和网站推荐</h3><p><a href="https://www.bilibili.com/video/BV1oz421q7BB/?spm_id_from=333.337.search-card.all.click">【HTML+CSS+JS+Vue】比大学课程还详细的Web前端教程，整整180集，学完即可兼职就业！附学习文档PDF，随时都能学<em>前端开发_WEB入门</em>哔哩哔哩_bilibili</a></p>
<p><a href="https://www.freecodecamp.org/learn/">Learn to Code — For Free — Coding Courses for Busy People</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>qwen3-8b微调实战</title>
    <url>/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/qwen3-8b%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在完成微调前备知识的学习后，正式开始使用unsloth对Qwen3-8B-unsloth-bnb-4bit模型的lora微调实战</p>
<h3 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from unsloth import FastLanguageModel</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line">max_seq_length = 8192</span><br><span class="line">dtype = None</span><br><span class="line">load_in_4bit = True</span><br><span class="line"></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = &quot;/workspace/qwen3-8b&quot;,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    dtype = dtype,</span><br><span class="line">    load_in_4bit = load_in_4bit,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>FastLanguageModel</code> 是 <strong>Unsloth 框架的核心入口类</strong>，即<strong>“把 Hugging Face 的 transformers 模型‘加速’成支持 QLoRA 微调、显存占用减半、速度提升 2-5 倍的封装器。”</strong></p>
<p><code>max_seq_length = 8192</code><strong>作用</strong>：告诉框架 <strong>“后续所有输入序列的最大长度”</strong>。<strong>内部一次性为位置编码、注意力掩码、KV-Cache 等开辟的张量尺寸</strong>，因此显存随它 <strong>平方级增长</strong>。</p>
<p><code>dtype = None</code><strong>作用</strong>：让 Unsloth <strong>自动选择最合适的浮点精度</strong>。</p>
<p><code>load_in_4bit = True</code><strong>作用</strong>：把模型<strong>权重量化成 4-bit</strong>，显存降到 1/4，QLoRA 微调必备。</p>
</blockquote>
<h3 id="查看模型与分词器信息"><a href="#查看模型与分词器信息" class="headerlink" title="查看模型与分词器信息"></a>查看模型与分词器信息</h3><h4 id="模型信息"><a href="#模型信息" class="headerlink" title="模型信息"></a>模型信息</h4><p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">model</span><br></pre></td></tr></table></figure>
<p>通过阅读模型信息我们可以了解到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(embed_tokens): Embedding(151936, 4096, padding_idx=151654)</span><br></pre></td></tr></table></figure>
<p><strong>模型有 15 万个 token 的字典，每个字/词被翻译成 4096 维向量，第 151 654 号 token 被官方指定为填充符。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(layers): ModuleList(</span><br><span class="line">      (0-2): 3 x Qwen3DecoderLayer(</span><br><span class="line">        (self_attn): Qwen3Attention(</span><br><span class="line">          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)</span><br><span class="line">          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)</span><br><span class="line">          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)</span><br><span class="line">          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)</span><br><span class="line">          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)</span><br><span class="line">          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)</span><br><span class="line">          (rotary_emb): LlamaRotaryEmbedding()</span><br><span class="line">        )</span><br><span class="line">        (mlp): Qwen3MLP(</span><br><span class="line">          (gate_proj): Linear(in_features=4096, out_features=12288, bias=False)</span><br><span class="line">          (up_proj): Linear(in_features=4096, out_features=12288, bias=False)</span><br><span class="line">          (down_proj): Linear(in_features=12288, out_features=4096, bias=False)</span><br><span class="line">          (act_fn): SiLU()</span><br><span class="line">        )</span><br><span class="line">        (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)</span><br><span class="line">        (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)</span><br><span class="line">      )</span><br></pre></td></tr></table></figure>
<p>共有36层<strong>Qwen3DecoderLayer</strong>，每层包含<strong>Qwen3Attention</strong>，<strong>Qwen3MLP</strong>（<strong>一个 SwiGLU 前馈网络</strong>），<strong>Qwen3RMSNorm</strong>（两个<strong>归一化层</strong>，对 4096 维的隐藏向量做“均方根归一化”，防止梯度爆炸、稳定训练。）</p>
<p><img src="/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/qwen3-8b%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98/image-20250812153659843.png" alt="image-20250812153659843"></p>
<p><a href="https://www.cnblogs.com/cavalier-chen/p/18937098">大模型-qwen3 模型结构解读-66 - jack-chen666 - 博客园</a></p>
<blockquote>
<p><strong>LoRA可以插到哪里呢？</strong></p>
<p><strong>凡是打印里每层 Decoder 中出现的 <code>Linear4bit</code>（q/k/v/o + gate/up/down）就是 LoRA 可插、且默认会被插入的位置。</strong></p>
</blockquote>
<h4 id="分词器信息"><a href="#分词器信息" class="headerlink" title="分词器信息"></a>分词器信息</h4><p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tokenizer</span><br></pre></td></tr></table></figure>
<p>查看tokenizer信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Qwen2TokenizerFast(name_or_path=&#x27;/workspace/qwen3-8b&#x27;, vocab_size=151643, model_max_length=40960, is_fast=True, padding_side=&#x27;left&#x27;, truncation_side=&#x27;right&#x27;, special_tokens=&#123;&#x27;eos_token&#x27;: &#x27;&lt;|im_end|&gt;&#x27;, &#x27;pad_token&#x27;: &#x27;&lt;|vision_pad|&gt;&#x27;, &#x27;additional_special_tokens&#x27;: [&#x27;&lt;|im_start|&gt;&#x27;, &#x27;&lt;|im_end|&gt;&#x27;, &#x27;&lt;|object_ref_start|&gt;&#x27;, &#x27;&lt;|object_ref_end|&gt;&#x27;, &#x27;&lt;|box_start|&gt;&#x27;, &#x27;&lt;|box_end|&gt;&#x27;, &#x27;&lt;|quad_start|&gt;&#x27;, &#x27;&lt;|quad_end|&gt;&#x27;, &#x27;&lt;|vision_start|&gt;&#x27;, &#x27;&lt;|vision_end|&gt;&#x27;, &#x27;&lt;|vision_pad|&gt;&#x27;, &#x27;&lt;|image_pad|&gt;&#x27;, &#x27;&lt;|video_pad|&gt;&#x27;]&#125;, clean_up_tokenization_spaces=False, added_tokens_decoder=&#123;</span><br><span class="line">	151643: AddedToken(&quot;&lt;|endoftext|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),</span><br><span class="line">	151644: AddedToken(&quot;&lt;|im_start|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),</span><br><span class="line">	151645: AddedToken(&quot;&lt;|im_end|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),</span><br><span class="line">	151646: AddedToken(&quot;&lt;|object_ref_start|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),</span><br><span class="line">	截取部分</span><br><span class="line">&#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>vocab_size=151643：<strong>模型真正能理解和生成的子词/符号有这 151643 种，其余位置是预留空白。</strong></p>
<p>model_max_length=40960：<strong>理论最大输入长度 40k token</strong>（实际受显存限制）</p>
<p>is_fast=True：表示 <strong>tokenizer 使用的是 Hugging Face 的「Rust 高速实现」</strong>（即 <em>tokenizers</em> 库）</p>
<p>special_tokens：打印的 <code>special_tokens</code> 字典 &amp; <code>added_tokens_decoder</code> 已经把 <strong>151643-151668</strong> 全部列出，共 <strong>26 个</strong>。</p>
<h3 id="模拟一次模型处理流程"><a href="#模拟一次模型处理流程" class="headerlink" title="模拟一次模型处理流程"></a>模拟一次模型处理流程</h3><p>将对话内容通过tokenizer进行处理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;&quot;role&quot; : &quot;user&quot;, &quot;content&quot; : &quot;你好，好久不见！&quot;&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tokenize = False,</span><br><span class="line">    add_generation_prompt = True, </span><br><span class="line">    enable_thinking = False, # 设置不思考</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><code>apply_chat_template</code> 是把「人类对话格式的 Python 列表」一键翻译成 <strong>模型能直接理解的带特殊标记的文本字符串（或 token id 序列）</strong> 的“官方模板引擎”。</p>
<p>转化后的格式为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;&lt;|im_start|&gt;user\n你好，好久不见！&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n&lt;think&gt;\n\n&lt;/think&gt;\n\n&#x27;</span><br></pre></td></tr></table></figure>
<p>然后将转化后的字符串<strong>转成 GPU 上的 PyTorch token 张量，准备直接送进模型推理或训练。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">inputs = tokenizer(text, return_tensors=&quot;pt&quot;).to(&quot;cuda&quot;)</span><br></pre></td></tr></table></figure>
<p>以上代码共做了三步：</p>
<ol>
<li><strong>tokenizer(text)</strong><br>把前面 <code>apply_chat_template</code> 得到的字符串按词表切成 <strong>token id 列表</strong>。</li>
<li><strong>return_tensors=”pt”</strong><br>把列表包成 <strong>PyTorch 张量</strong>（shape = [1, seq_len]）。</li>
<li><strong>.to(“cuda”)</strong><br>把张量搬到 <strong>GPU 显存</strong>。</li>
</ol>
<p>输出如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;input_ids&#x27;: tensor([[151644,    872,    198, 108386,   3837, 111920, 101571,   6313, 151645,</span><br><span class="line">            198, 151644,  77091,    198, 151667,    271, 151668,    271]],</span><br><span class="line">       device=&#x27;cuda:0&#x27;), &#x27;attention_mask&#x27;: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device=&#x27;cuda:0&#x27;)&#125;</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>键</th>
<th>形状</th>
<th>每个数字的含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>input_ids</strong></td>
<td><code>[1, 17]</code></td>
<td>17 个 token 的 ID 列表，已放到 GPU</td>
</tr>
<tr>
<td><strong>attention_mask</strong></td>
<td><code>[1, 17]</code></td>
<td>17 个 <strong>1</strong>，表示“这些位置都是有效 token，无填充”</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">outputs = model.generate(</span><br><span class="line">    input_ids=inputs.input_ids,</span><br><span class="line">    attention_mask=inputs.attention_mask,</span><br><span class="line">    max_new_tokens=max_seq_length,</span><br><span class="line">    use_cache=True,#启用 KV-Cache，避免重复计算，显存换时间</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>让模型在 GPU 上 <strong>根据已有 token 继续生成文本</strong>，直到达到 <code>max_new_tokens</code> 或遇到终止符。</p>
<p>outputs格式和inputs类似，使用nput_ids表示后续字符</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">response = tokenizer.batch_decode(outputs)</span><br></pre></td></tr></table></figure>
<p>把模型输出的 <strong>token id 序列</strong>（<code>outputs</code>）一次性还原成 <strong>人类可读的字符串</strong>。</p>
<p>输出如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;&lt;|im_start|&gt;user\n你好，好久不见！&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n&lt;think&gt;\n\n&lt;/think&gt;\n\n你好！好久不见！最近过得怎么样？有什么新鲜事想和我分享吗？😊&lt;|im_end|&gt;&#x27;</span><br></pre></td></tr></table></figure>
<p>这里展示的是没有思考过程的，最简单对话流程，若设置思考模式，完整代码如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tools = tools,#同样，可以设置function calling</span><br><span class="line">    tokenize = False,</span><br><span class="line">    add_generation_prompt = True, </span><br><span class="line">    enable_thinking = True, # 设置思考</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">inputs = tokenizer(text, return_tensors=&quot;pt&quot;).to(&quot;cuda&quot;)</span><br><span class="line"></span><br><span class="line">outputs = model.generate(</span><br><span class="line">    input_ids=inputs.input_ids,</span><br><span class="line">    attention_mask=inputs.attention_mask,</span><br><span class="line">    max_new_tokens=max_seq_length,</span><br><span class="line">    use_cache=True,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response = tokenizer.batch_decode(outputs)</span><br></pre></td></tr></table></figure>
<p>当然，除了使用上述底层API进行对话外，Unsloth还提供了更加便捷的流式输出模型对话信息的函数，基本对话效果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;&quot;role&quot; : &quot;user&quot;, &quot;content&quot; : &quot;你好，好久不见！&quot;&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tokenize = False,</span><br><span class="line">    add_generation_prompt = True, </span><br><span class="line">    enable_thinking = False, </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">_ = model.generate(</span><br><span class="line">    **tokenizer(text, return_tensors = &quot;pt&quot;).to(&quot;cuda&quot;),</span><br><span class="line">    max_new_tokens = 256, # Increase for longer outputs!</span><br><span class="line">    temperature = 0.7, top_p = 0.8, top_k = 20, # For non thinking</span><br><span class="line">    streamer = TextStreamer(tokenizer, skip_prompt = True),#实时流式输出：每解码一个 token 就立刻打印到终端</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h3><h4 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h4><p>选取的两个数据集</p>
<ol>
<li>我们使用 Open Math Reasoning 数据集，该数据集曾被用于赢得 AIMO（AI 数学奥林匹克 - 第二届进步奖）挑战！我们从中抽取了 10% 可验证的推理轨迹，这些轨迹是基于 DeepSeek R1 模型生成的，并且准确率超过 95%。数据集地址：<a href="https://huggingface.co/datasets/unsloth/OpenMathReasoning-mini">https://huggingface.co/datasets/unsloth/OpenMathReasoning-mini</a></li>
<li>我们还利用了 Maxime Labonne 的 FineTome-100k 数据集，该数据集风格类似 ShareGPT。但我们需要将其转换为 HuggingFace 通用的多轮对话格式。数据集地址：<a href="https://huggingface.co/datasets/mlabonne/FineTome-100k">https://huggingface.co/datasets/mlabonne/FineTome-100k</a></li>
</ol>
<p>在实际微调过程中，大多都会使用huggingface的datasets库进行数据集下载和管理，实际下载流程如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">!pip install --upgrade datasets huggingface_hub</span><br></pre></td></tr></table></figure>
<p><code>datasets</code> 是 Hugging Face 提供的一个高效数据处理库，专为机器学习和大语言模型（LLM）训练而设计。它支持加载、处理、转换和保存各种格式的数据（如 JSON、CSV、Parquet 等），并能与 <code>transformers</code> 模型无缝集成。通过 <code>datasets</code>，开发者可以快速完成数据清洗、切分、tokenization 等常见任务，大大提升训练效率，特别适合用于指令微调、对话生成、Function Calling 等任务的数据预处理。</p>
<p>然后分别下载并导入这两个库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_dataset = load_dataset(&quot;unsloth/OpenMathReasoning-mini&quot;, split = &quot;cot&quot;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>cot全称为<strong>Chain-of-Thought，思维链</strong>，是「<strong>一步一步把思考过程写出来</strong>」的解题方式，而不是直接给出最终答案。</p>
<p><strong>只下 cot 是因为任务只需要“带推理过程”的那部分数据，其他子集对当前微调目标无用，避免冗余下载。</strong></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">non_reasoning_dataset = load_dataset(&quot;mlabonne/FineTome-100k&quot;, split = &quot;train&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="查看数据集"><a href="#查看数据集" class="headerlink" title="查看数据集"></a>查看数据集</h4><p>然后输入数据集名称，即可查看数据集基本信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_dataset</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;expected_answer&#x27;, &#x27;problem_type&#x27;, &#x27;problem_source&#x27;, &#x27;generation_model&#x27;, &#x27;pass_rate_72b_tir&#x27;, &#x27;problem&#x27;, &#x27;generated_solution&#x27;, &#x27;inference_mode&#x27;],</span><br><span class="line">    num_rows: 19252</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>一共 19 252 条</strong> <strong>CoT（思维链）数学题</strong>，每条包含 8 个字段，可直接用来训练/评估模型的逐步推理能力。</p>
<p>generated_solution：模型自己写的 逐步推理 + 最终答案（就是你想要的 CoT）</p>
<p>expected_answer：标准答案（通常是一个简洁数字或表达式）</p>
<p>generation_model：生成这条 CoT 的“教师模型”名字，比如 qwen2-72b</p>
<p>加上索引则可以直接查看对应数据集信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_dataset[0]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;expected_answer&#x27;: &#x27;14&#x27;,</span><br><span class="line"> &#x27;problem_type&#x27;: &#x27;has_answer_extracted&#x27;,</span><br><span class="line"> &#x27;problem_source&#x27;: &#x27;aops_c4_high_school_math&#x27;,</span><br><span class="line"> &#x27;generation_model&#x27;: &#x27;DeepSeek-R1&#x27;,</span><br><span class="line"> &#x27;pass_rate_72b_tir&#x27;: &#x27;0.96875&#x27;,</span><br><span class="line"> &#x27;problem&#x27;: &#x27;Given $\\sqrt&#123;x^2+165&#125;-\\sqrt&#123;x^2-52&#125;=7$ and $x$ is positive, find all possible values of $x$.&#x27;,</span><br><span class="line"> &#x27;generated_solution&#x27;: &quot;&lt;think&gt;\nOkay, let&#x27;s see. I need to solve the equation √(x² + 165) - √(x² - 52) = 7, a截取部分&quot;,</span><br><span class="line"> &#x27;inference_mode&#x27;: &#x27;cot&#x27;&#125;</span><br></pre></td></tr></table></figure>
<p>能够看出这是一个基于DeepSeek R1回答的数学数据集，其中<code>problem</code>是问题，<code>generated_solution</code>是数学推导过程（即思考过程），而<code>expected_answer</code>则是最终的答案。该数据集总共接近2万条数据</p>
<p>而对话数据集如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">non_reasoning_dataset</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;conversations&#x27;, &#x27;source&#x27;, &#x27;score&#x27;],</span><br><span class="line">    num_rows: 100000</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">non_reasoning_dataset[0]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;conversations&#x27;: [&#123;&#x27;from&#x27;: &#x27;human&#x27;,</span><br><span class="line">   &#x27;value&#x27;: &#x27;Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and prov截取&#x27;&#125;,</span><br><span class="line">  &#123;&#x27;from&#x27;: &#x27;gpt&#x27;,</span><br><span class="line">   &#x27;value&#x27;: &#x27;Boolean operators are logical operators used in programming to manipulate boolean values. The截取&#x27;&#125;],</span><br><span class="line"> &#x27;source&#x27;: &#x27;infini-instruct-top-500k&#x27;,</span><br><span class="line"> &#x27;score&#x27;: 5.212620735168457&#125;</span><br></pre></td></tr></table></figure>
<p>其中每一条数据都是一个对话，包含一组或者多组ChatGPT的聊天信息，其中<code>from</code>代表是用户消息还是大模型回复消息，而<code>value</code>则是对应的文本。该对话数据集总共包含10万条数据</p>
<p>能够看出dataset是一种类似json的数据格式，每条数据都以字段格式进行存储，在实际微调过程中，我们需要先将数据集的目标字段进行提取和拼接，然后加载到Qwen3模型的提示词模板中，并最终带入Unsloth进行微调。</p>
<h3 id="数据集清洗"><a href="#数据集清洗" class="headerlink" title="数据集清洗"></a>数据集清洗</h3><h4 id="对话数据集的清洗"><a href="#对话数据集的清洗" class="headerlink" title="对话数据集的清洗"></a>对话数据集的清洗</h4><p>接下来尝试对上述两个格式各异的数据集进行数据清洗，主要是围绕数据集进行<strong>数据格式</strong>的调整，便于后续<strong>带入Qwen3提示词模板</strong>。对于dataset格式的数据对象来说，可以先创建满足格式调整的函数，然后使用map方法对数据集格式进行调整。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def generate_conversation(examples):</span><br><span class="line">    problems  = examples[&quot;problem&quot;]</span><br><span class="line">    solutions = examples[&quot;generated_solution&quot;]</span><br><span class="line">    conversations = []</span><br><span class="line">    for problem, solution in zip(problems, solutions):</span><br><span class="line">        conversations.append([</span><br><span class="line">            &#123;&quot;role&quot; : &quot;user&quot;,      &quot;content&quot; : problem&#125;,</span><br><span class="line">            &#123;&quot;role&quot; : &quot;assistant&quot;, &quot;content&quot; : solution&#125;,</span><br><span class="line">        ])</span><br><span class="line">    return &#123; &quot;conversations&quot;: conversations, &#125;</span><br></pre></td></tr></table></figure>
<p>这里先创建generate_conversation函数，用于对reasoning_dataset中的每一条数据进行格式调整，即通过新创建一个新的特征conversations，来以对话形式保存历史问答数据：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_data = reasoning_dataset.map(</span><br><span class="line">    generate_conversation,  # 处理函数</span><br><span class="line">    batched=True            # 批量处理，加快速度</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>map：对数据集中的每一批样本调用 generate_conversation</p>
<p>batched=True：一次传入一批（几百到几千条）样本，避免逐行慢速 Python 循环</p>
</blockquote>
<p>接下来将其带入Qwen3的提示词模板中进行转化：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">reasoning_conversations = tokenizer.apply_chat_template(</span><br><span class="line">    reasoning_data[&quot;conversations&quot;],</span><br><span class="line">    tokenize = False,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>之后即可带入这些数据进行微调。能看出每条数据的格式都和Unsloth底层对话API创建的数据格式类似，之后我们或许可以借助Unsloth底层对话API来创建微调数据集。</p>
<h4 id="推理数据集的推理"><a href="#推理数据集的推理" class="headerlink" title="推理数据集的推理"></a>推理数据集的推理</h4><p>然后继续处理non_reasoning_conversations数据集，由于该数据集采用了sharegpt对话格式，因此可以直接借助Unsloth的standardize_sharegpt库进行数据集的格式转化，转化效果如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from unsloth.chat_templates import standardize_sharegpt</span><br></pre></td></tr></table></figure>
<blockquote>
<p>standardize_sharegpt的作用</p>
<p><strong>把“ShareGPT 格式”的对话数据一键转成 Unsloth / Hugging Face 通用的 <code>role/content</code> 列表，后续就能直接用 <code>apply_chat_template</code> 生成训练文本。</strong></p>
<p>1️⃣ ShareGPT 原始长什么样？</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1+1=?&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span>  <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>2️⃣ 转换后长什么样？</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span>      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1+1=?&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dataset = standardize_sharegpt(non_reasoning_dataset)</span><br></pre></td></tr></table></figure>
<p>接下来即可直接带入Qwen3对话模板中进行格式调整：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">non_reasoning_conversations = tokenizer.apply_chat_template(</span><br><span class="line">    dataset[&quot;conversations&quot;],</span><br><span class="line">    tokenize = False,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="数据集采样"><a href="#数据集采样" class="headerlink" title="数据集采样"></a>数据集采样</h4><p>自此即完成了每个数据集的格式调整工作，不过这两个数据集并不均衡，能看得出非推理类数据集的长度更长。我们假设希望模型保留一定的推理能力，但又特别希望它作为一个聊天模型来使用。</p>
<p>因此，我们需要定义一个 <strong>仅聊天数据的比例</strong>。<strong>目标是从两个数据集中构建一个混合训练集</strong>。这里我们可以设定一个 25% 推理数据、75% 聊天数据的比例：也就是说，从推理数据集中抽取 25%（或者说，抽取占比为 100% - 聊天数据占比 的部分），最后将这两个数据集合并起来即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chat_percentage = 0.75</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line">#先把非推理对话列表转成 Pandas Series，方便后续抽样</span><br><span class="line">non_reasoning_subset = pd.Series(non_reasoning_conversations)</span><br><span class="line"></span><br><span class="line">non_reasoning_subset = non_reasoning_subset.sample(#sample(...)为无放回随机抽样</span><br><span class="line">    int(len(reasoning_conversations) * (1.0 - chat_percentage)),#计算 需要抽多少条非推理样本</span><br><span class="line">    random_state = 2407,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这里我们需要先将上述list格式的数据转化为pd.Series数据，然后进行采样，并最终将其转化为dataset类型对象。（此外也可以先转化为dataset对象类型，然后再进行采样）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data = pd.concat([</span><br><span class="line">    pd.Series(reasoning_conversations),</span><br><span class="line">    pd.Series(non_reasoning_subset)</span><br><span class="line">])</span><br><span class="line">data.name = &quot;text&quot;</span><br><span class="line"></span><br><span class="line">from datasets import Dataset</span><br><span class="line"></span><br><span class="line">combined_dataset = Dataset.from_pandas(pd.DataFrame(data))</span><br><span class="line">combined_dataset = combined_dataset.shuffle(seed = 3407)#用固定种子随机打乱顺序</span><br></pre></td></tr></table></figure>
<blockquote>
<p>pd.concat([…])：纵向拼接 → 一条长 Series，顺序：先推理，后非推理</p>
<p>Dataset.from_pandas(…)：把 Pandas Series 转成 Hugging Face Dataset</p>
</blockquote>
<p><strong>把“推理对话”和“抽样后的非推理对话”合并成一个</strong> <strong>随机打乱</strong> <strong>的 <code>Dataset</code> 对象，后面可直接拿去训练。</strong></p>
<h4 id="查看数据集-1"><a href="#查看数据集-1" class="headerlink" title="查看数据集"></a>查看数据集</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">combined_dataset[0]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;text&#x27;: &quot;&lt;|im_start|&gt;user\nCalculate the pH during a titration when 9.54 mL of a 0.15 M HCl solution has reacted with 22.88 mL of a 0.14 M NaOH solution?&lt;|im_end|&gt;\n&lt;|im_st截取&quot;,</span><br><span class="line"> &#x27;__index_level_0__&#x27;: 49038&#125;</span><br></pre></td></tr></table></figure>
<p>其中text字段就是后续带入微调的字段。</p>
<h4 id="数据集保存"><a href="#数据集保存" class="headerlink" title="数据集保存"></a>数据集保存</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">combined_dataset.save_to_disk(&quot;/workspace/cleaned_qwen3_dataset&quot;)</span><br></pre></td></tr></table></figure>
<p>后续使用时即可使用如下代码进行读取：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from datasets import load_from_disk</span><br><span class="line">combined_dataset = load_from_disk(&quot;cleaned_qwen3_dataset&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="Qwen3推理能力高效微调流程"><a href="#Qwen3推理能力高效微调流程" class="headerlink" title="Qwen3推理能力高效微调流程"></a>Qwen3推理能力高效微调流程</h3><p>准备完数据之后，即可开始进行微调。这里我们先进行少量数据微调测试，程序能够基本跑通后，我们再进行大规模数据集微调。</p>
<h4 id="进行LoRA参数注入"><a href="#进行LoRA参数注入" class="headerlink" title="进行LoRA参数注入"></a>进行LoRA参数注入</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,</span><br><span class="line">    r = 32,           # 秩（LoRA 低秩矩阵的列数）。越大可学习参数越多，显存也越高。常用 8/16/32/64/128</span><br><span class="line">    target_modules = [&quot;q_proj&quot;, &quot;k_proj&quot;, &quot;v_proj&quot;, &quot;o_proj&quot;,</span><br><span class="line">                      &quot;gate_proj&quot;, &quot;up_proj&quot;, &quot;down_proj&quot;],  # 在哪些线性层插入 LoRA 适配器（Attention + MLP）</span><br><span class="line">    lora_alpha = 32,  # 缩放因子。经验值 = rank 或 2×rank，控制更新强度</span><br><span class="line">    lora_dropout = 0, # LoRA 本身的 dropout 比例；0 省显存且速度最快</span><br><span class="line">    bias = &quot;none&quot;,    # 是否训练原 Linear 的偏置。设为 &quot;none&quot; 不训练，进一步节省显存</span><br><span class="line">    use_gradient_checkpointing = &quot;unsloth&quot;,  # 梯度检查点：True 省显存，&quot;unsloth&quot; 再省 30 %，超长上下文必开</span><br><span class="line">    random_state = 3407,  # 随机种子，保证 LoRA 初始化可复现</span><br><span class="line">    use_rslora = False,   # 默认 False，True 则启用 Rank-Stabilized LoRA（训练更稳，但显存稍高）</span><br><span class="line">    loftq_config = None,  # LoftQ 量化初始化，None 表示不用；若配置可进一步压缩初始权重</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这一步<strong>“LoRA 参数注入”</strong>就是：<strong>在不改动原模型权重的前提下，给指定层插入少量</strong> <strong>可训练低秩矩阵</strong> <strong>（LoRA 适配器），从而只更新 &lt; 1 % 的参数，完成高效微调。</strong></p>
<blockquote>
<p>不是“在原有层之外再增加一层”，而是<strong>把 LoRA 的“小矩阵”插到</strong> <strong>原有线性层内部</strong>：</p>
<ul>
<li>原层结构（冻结）：<br><code>x → Linear4bit(W) → y</code></li>
<li>注入后结构（冻结 + 可训练）：<br><code>x → [Linear4bit(W)  +  LoRA(A·B)] → y</code></li>
</ul>
<p><code>A</code> 和 <code>B</code> 两个低秩矩阵被 <strong>注册为同一层的新参数</strong>，<strong>不新建网络层</strong>，参数在 <strong>前向时相加</strong>，<strong>反向只更新 A 和 B</strong>。</p>
</blockquote>
<h4 id="设置微调参数"><a href="#设置微调参数" class="headerlink" title="设置微调参数"></a>设置微调参数</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from trl import SFTTrainer, SFTConfig</span><br><span class="line"></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model=model,                       # 已插入 LoRA 的 4-bit 模型</span><br><span class="line">    tokenizer=tokenizer,               # 对应 tokenizer（含 chat 模板）</span><br><span class="line">    train_dataset=combined_dataset,    # 训练集：聊天+推理对话</span><br><span class="line">    eval_dataset=None,                 # 如需验证，把验证集放进来即可</span><br><span class="line"></span><br><span class="line">    args=SFTConfig(</span><br><span class="line">        dataset_text_field=&quot;text&quot;,      # 训练集中每条样本的字段名（对话列表）</span><br><span class="line">        per_device_train_batch_size=2,  # 每张显卡上的 batch_size（显存决定）</span><br><span class="line">        gradient_accumulation_steps=4,  # 4 次累积 → 全局有效 batch = 2×4 = 8</span><br><span class="line">        warmup_steps=5,                # 前 5 步线性预热学习率</span><br><span class="line">        max_steps=30,                  # 训练 30 步（调试阶段）；正式可用 num_train_epochs</span><br><span class="line">        learning_rate=2e-4,            # LoRA 常用 2e-4；长训降到 2e-5</span><br><span class="line">        logging_steps=1,               # 每 1 步打印一次日志</span><br><span class="line">        optim=&quot;adamw_8bit&quot;,            # 8-bit AdamW，省显存</span><br><span class="line">        weight_decay=0.01,             # L2 正则</span><br><span class="line">        lr_scheduler_type=&quot;linear&quot;,    # 线性衰减到 0</span><br><span class="line">        seed=3407,                     # 固定随机种子</span><br><span class="line">        report_to=&quot;swanlab&quot;,             # 把指标推送到 swanlab</span><br><span class="line">    ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/huggingface/trl">TRL</a> (Transformers Reinforcement Learning，用强化学习训练Transformers模型) 是一个领先的Python库，旨在通过监督微调（SFT）、近端策略优化（PPO）和直接偏好优化（DPO）等先进技术，对基础模型进行训练后优化。TRL 建立在 🤗 Transformers 生态系统之上，支持多种模型架构和模态，并且能够在各种硬件配置上进行扩展。</p>
<p>其中<code>SFTTrainer</code>：一个专门为指令微调设计的训练器，封装了 Hugging Face 的 <code>Trainer</code>，而<code>SFTConfig</code>：配置训练参数的专用类，功能类似 <code>TrainingArguments</code>。而SFTConfig核心参数解释如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数名</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>dataset_text_field=&quot;text&quot;</code></td>
<td>数据集中用于训练的字段名称，如 <code>text</code> 或 <code>prompt</code></td>
</tr>
<tr>
<td><code>per_device_train_batch_size=2</code></td>
<td>每张 GPU 上的 batch size 是 2</td>
</tr>
<tr>
<td><code>gradient_accumulation_steps=4</code></td>
<td>梯度累计 4 次后才进行一次反向传播（等效于总 batch size = 2 × 4 = 8）</td>
</tr>
<tr>
<td><code>warmup_steps=5</code></td>
<td>前 5 步进行 warmup（缓慢提升学习率）</td>
</tr>
<tr>
<td><code>max_steps=30</code></td>
<td>最多训练 30 步（适合调试或快速实验）</td>
</tr>
<tr>
<td><code>learning_rate=2e-4</code></td>
<td>初始学习率（短训练可用较高值）</td>
</tr>
<tr>
<td><code>logging_steps=1</code></td>
<td>每训练 1 步就打印一次日志</td>
</tr>
<tr>
<td><code>optim=&quot;adamw_8bit&quot;</code></td>
<td>使用 8-bit AdamW 优化器（节省内存，Unsloth 支持）</td>
</tr>
<tr>
<td><code>weight_decay=0.01</code></td>
<td>权重衰减，用于防止过拟合</td>
</tr>
<tr>
<td><code>lr_scheduler_type=&quot;linear&quot;</code></td>
<td>线性学习率调度器（从高到低线性下降）</td>
</tr>
<tr>
<td><code>seed=3407</code></td>
<td>固定随机种子，确保结果可复现</td>
</tr>
<tr>
<td><code>report_to=&quot;none&quot;</code></td>
<td>不使用 WandB 或 TensorBoard 等日志平台（可改为 <code>&quot;wandb&quot;</code>）</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<ol>
<li><p><strong>per_device_train_batch_size=2</strong><br><strong>每次前向只用了 2 条样本</strong> → 显存占用小，单卡就能跑。</p>
<p><strong>batch_size 决定「每一步真正喂给模型的样本数量」，越大训练越稳，但对显存要求越高。</strong></p>
</li>
<li><p><strong>gradient_accumulation_steps=4</strong><br><strong>把这 2 条样本算出的梯度先攒起来，攒够 4 次再一次性做反向传播</strong> → 等效于一次性看了 <strong>2 × 4 = 8 条样本</strong>，但显存仍按 2 条算。</p>
</li>
</ol>
</blockquote>
<p>此时基本训练过程为：</p>
<ol>
<li>从 <code>combined_dataset</code> 中取出一批样本（2 条）</li>
<li>重复上面过程 4 次（<code>gradient_accumulation_steps=4</code>）</li>
<li>将累计的梯度用于更新模型一次参数（等效于一次大 batch 更新）</li>
<li>重复上述过程，直到 <code>max_steps=30</code> 停止</li>
</ol>
<h4 id="设置训练可视化swanlab"><a href="#设置训练可视化swanlab" class="headerlink" title="设置训练可视化swanlab"></a>设置训练可视化swanlab</h4><p><a href="https://docs.swanlab.cn/guide_cloud/integration/integration-huggingface-trl.html">🤗HuggingFace Trl | SwanLab官方文档</a></p>
<p>只需要在你的训练代码中，找到HF的<code>Config</code>部分（比如<code>SFTConfig</code>、<code>GRPOConfig</code>等），添加<code>report_to=&quot;swanlab&quot;</code>参数，即可完成集成。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from trl import SFTConfig, SFTTrainer</span><br><span class="line"></span><br><span class="line">args = SFTConfig(</span><br><span class="line">    ...,</span><br><span class="line">    report_to=&quot;swanlab&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(..., args=args)</span><br></pre></td></tr></table></figure>
<p>默认下，项目名会使用你运行代码的<code>目录名</code>。</p>
<p>如果你想自定义项目名，可以设置<code>SWANLAB_PROJECT</code>环境变量：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&quot;SWANLAB_PROJECT&quot;]=&quot;qwen2-sft&quot;</span><br></pre></td></tr></table></figure>
<h4 id="微调执行流程"><a href="#微调执行流程" class="headerlink" title="微调执行流程"></a>微调执行流程</h4><p>一切准备就绪后，接下来即可开始进行微调。由于本次微调总共只运行30个step，整个过程并不会很长，实际执行过程如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">trainer_stats = trainer.train()</span><br></pre></td></tr></table></figure>
<h4 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h4><p> <strong>1. 保存 LoRA Adapter</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 保存 LoRA adapter（仅几十 MB）</span><br><span class="line">save_path = &quot;./lora-adapter&quot;</span><br><span class="line">model.save_pretrained(save_path)          # LoRA 权重</span><br><span class="line">tokenizer.save_pretrained(save_path)      # 词表</span><br></pre></td></tr></table></figure>
<p>以后加载：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = <span class="string">&quot;base-model-name-or-path&quot;</span>,</span><br><span class="line">    max_seq_length = <span class="number">2048</span>,</span><br><span class="line">    load_in_4bit = <span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">model = FastLanguageModel.get_peft_model(model, ...)  <span class="comment"># 同训练时参数</span></span><br><span class="line">model.load_adapter(save_path)   <span class="comment"># 把 LoRA 权重挂回去</span></span><br></pre></td></tr></table></figure>
<p><strong>2.合并 LoRA → 完整模型</strong></p>
<p>如果你想把 <strong>LoRA 权重合并到基座</strong> 得到一个独立的大模型（方便推理、上传 Hub）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 合并权重</span></span><br><span class="line">merged_model = model.merge_and_unload()   <span class="comment"># 返回普通 transformers 模型</span></span><br><span class="line">merged_model.save_pretrained(<span class="string">&quot;./merged-model&quot;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;./merged-model&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>合并后就是完整的大模型（GB 级），可直接用 <code>AutoModelForCausalLM.from_pretrained(&quot;./merged-model&quot;)</code> 加载，不依赖 Unsloth。</p>
<h3 id="微调结果"><a href="#微调结果" class="headerlink" title="微调结果"></a>微调结果</h3><h4 id="可视化结果"><a href="#可视化结果" class="headerlink" title="可视化结果"></a>可视化结果</h4><p><img src="/2025/08/12/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/qwen3-8b%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98/image-20250813111238359.png" alt="image-20250813111238359"></p>
<p><a href="https://swanlab.cn/@zxj123/Fine-tune-Qwen-8B/runs/e2l6g6s3v7dlb7hmfircv/chart">图表 ｜ Fine-tune-Qwen-8B/rat-2</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>指标名称</th>
<th>含义</th>
<th>单位/范围提示</th>
<th>常见关注点</th>
</tr>
</thead>
<tbody>
<tr>
<td>train/loss</td>
<td>训练损失（Training Loss）</td>
<td>标量，越小越好</td>
<td>是否持续下降、是否震荡、是否过拟合</td>
</tr>
<tr>
<td>train/grad_norm</td>
<td>梯度范数（Gradient Norm）</td>
<td>标量，通常 0.01–1.0 为合理区间</td>
<td>是否爆炸（&gt;10）或消失（&lt;1e-4）</td>
</tr>
<tr>
<td>train/learning_rate</td>
<td>学习率（Learning Rate）</td>
<td>标量，如 1e-4、5e-4 等</td>
<td>是否过大导致震荡、过小导致收敛慢</td>
</tr>
<tr>
<td>train/epoch</td>
<td>已训练的轮次（Epoch）</td>
<td>标量，1.0 表示完整遍历一次训练集</td>
<td>当前已训练多少轮、是否还需继续训练</td>
</tr>
<tr>
<td>train/global_step</td>
<td>全局步数（Global Step）</td>
<td>整数，每个 batch +1</td>
<td>与 epoch 对应，计算已见样本量</td>
</tr>
</tbody>
</table>
</div>
<h4 id="对话测试"><a href="#对话测试" class="headerlink" title="对话测试"></a>对话测试</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;&quot;role&quot; : &quot;user&quot;, &quot;content&quot; : &quot;解决(x + 2)^2 = 0.&quot;&#125;</span><br><span class="line">]</span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    tokenize = False,</span><br><span class="line">    add_generation_prompt = True, # Must add for generation</span><br><span class="line">    enable_thinking = True, # Disable thinking</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">from transformers import TextStreamer</span><br><span class="line">_ = model.generate(</span><br><span class="line">    **tokenizer(text, return_tensors = &quot;pt&quot;).to(&quot;cuda&quot;),</span><br><span class="line">    max_new_tokens = 20488, # Increase for longer outputs!</span><br><span class="line">    temperature = 0.6, top_p = 0.95, top_k = 20, # For thinking</span><br><span class="line">    streamer = TextStreamer(tokenizer, skip_prompt = True),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>模型</category>
        <category>微调</category>
      </categories>
      <tags>
        <tag>模型微调</tag>
        <tag>LoRA</tag>
      </tags>
  </entry>
  <entry>
    <title>模型微调——LoRA</title>
    <url>/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/</url>
    <content><![CDATA[<h3 id="为什么要微调"><a href="#为什么要微调" class="headerlink" title="为什么要微调"></a>为什么要微调</h3><p>预训练大模型在海量通用语料上学到的知识，在垂直场景（医疗、法律、零售客服等）里往往“泛而浅”。</p>
<p>从零训练一个同等规模的大模型成本极高（千卡周级别），而微调只需在已有权重上做小步调整，算力/数据量都指数级下降。</p>
<h3 id="什么是全量微调"><a href="#什么是全量微调" class="headerlink" title="什么是全量微调"></a>什么是全量微调</h3><p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811104846104.png" alt="image-20250811104846104"></p>
<p>全量微调（full fine-tuning）通俗来说，对于参数的每一个权重，都要学习一个新的值（或者偏移量），更新所有 Transformer 层里的权重矩阵（包括 embedding、attention、FFN），这样的开销是很大的。</p>
<h3 id="什么是LoRA"><a href="#什么是LoRA" class="headerlink" title="什么是LoRA"></a>什么是LoRA</h3><p>LoRA（Low-Rank Adaptation，低秩适配）是一种<strong>参数高效微调（PEFT）</strong>技术，核心目的：<br><strong>“冻结大模型 99 % 以上原始权重，只额外训练极少量低秩矩阵，就能让模型在下游任务上达到近似全量微调的效果。”</strong></p>
<p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811105145633.png" alt="image-20250811105145633"></p>
<p>通俗来说，通过学习两个低秩的矩阵，来近似于完整的矩阵，如图，W=A*B，矩阵相乘</p>
<p>在实际应用中，<strong>LoRA可以直接和transformer的FFN层（线性层）对齐</strong></p>
<p>Transformer 模型的核心是注意力机制，其中涉及到 Query, Key, Value 的计算，这些都是线性变换。</p>
<p>在标准的注意力机制中，计算公式为：</p>
<script type="math/tex; mode=display">
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V</script><p>其中 $Q$, $K$, $V$ 的计算为：</p>
<script type="math/tex; mode=display">
Q = X_Q W_Q, \quad K = X_K W_K, \quad V = X_V W_V</script><p> $X_Q$, $X_K$, $X_V$ 的输入可以相同，也可以不同。例如，在 Cross-Attention 中，解码器的隐藏状态作为 $X_Q$，编码器的输出作为 $X_K$ 和 $X_V$。</p>
<p><strong>LoRA 可以应用到 $W_Q$, $W_K$, $W_V$ 上，采用与线性层类似的方式</strong>。</p>
<h3 id="为什么要用lora"><a href="#为什么要用lora" class="headerlink" title="为什么要用lora"></a>为什么要用lora</h3><p>首先要理解低秩：秩可以理解成一个矩阵所代表的信息，低秩矩阵，便是带有少量信息的矩阵，当然这样的矩阵计算效率是更高的，</p>
<p>在全量微调中，由于训练一个完整的矩阵开销是非常大的；在lora中就通过训练低秩矩阵，来近似<strong>模型权重更新</strong>的效果</p>
<blockquote>
<p>若模型参数比较小，使用冻结部分参数或全量微调的方式，往往更好</p>
</blockquote>
<p>初学者不禁会思考，这样难道不会损失信息导致大模型的性能变差吗？但是，实验下来效果还是不错的，通过牺牲一点性能，来换取开销的大幅度减少</p>
<blockquote>
<p> LoRA 原文实验<br>在 GPT-3 175 B 上，仅用 rank 4 的 LoRA 就能在全量微调 99 % 参数量的情况下，保持 97 % 的下游指标。</p>
</blockquote>
<h3 id="什么是QLoRA"><a href="#什么是QLoRA" class="headerlink" title="什么是QLoRA"></a>什么是QLoRA</h3><p>QLoRA（Quantized Low-Rank Adaptation，量化低秩适应）是 <strong>LoRA 的“极致省内存”版本</strong>。它把 LoRA 的“低秩增量”思路再往前推一步：<strong>先把整个底座模型权重压到 4-bit，再在上面做 LoRA 微调</strong>。</p>
<p>QLoRA 是另一个热门术语，它与 LoRA 之间的唯一区别在于首字母“Q”，代表“量化（quantized）”。“量化”一词指的是用来减少存储神经元权重的比特数。</p>
<p>例如，神经网络的权重通常以浮点数表示，每个权重需要 32 位。量化的思想是将神经网络的权重压缩为更低的精度，而不会显著损失模型性能或产生重大影响。因此，不再使用 32 位，而是可以舍弃部分比特，例如只用 16 位。</p>
<p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811142432782.png" alt="image-20250811142432782"></p>
<h3 id="微调工具的介绍"><a href="#微调工具的介绍" class="headerlink" title="微调工具的介绍"></a>微调工具的介绍</h3><h4 id="unsloth"><a href="#unsloth" class="headerlink" title="unsloth"></a>unsloth</h4><p><a href="https://github.com/unslothai/unsloth?tab=readme-ov-file">unslothai/unsloth: Fine-tuning &amp; Reinforcement Learning for LLMs. 🦥 Train OpenAI gpt-oss, Qwen3, Llama 4, DeepSeek-R1, Gemma 3, TTS 2x faster with 70% less VRAM.</a></p>
<p>unsloth是一个专为大型语言模型（LLM）设计的动态量化与微调框架，旨在提高微调效率并减少显存占用，因此主要用于单机单卡的模型微调。</p>
<p>值得一提的是，Unsloth动态量化模型：<a href="https://unsloth.ai/blog/dynamic-v2">https://unsloth.ai/blog/dynamic-v2</a></p>
<p>Unsloth的动态量化方法，特别是其最新的Dynamic 2.0版本，旨在在尽量减少性能损失的同时显著压缩大型语言模型（LLMs）的体积。对于Qwen3模型，尤其是4-bit动态量化版本，现有的评测显示其性能下降非常有限，甚至在某些任务上与原始模型相当。</p>
<blockquote>
<p>Unsloth 的「动态量化」可以一句话概括为：<br><strong>“按层、按敏感度自动决定每块权重到底用 2.5 / 3.5 / 4 / 6 / 8 / 32 bit 的精细化量化策略，而不是一股脑全量化到 4 bit。”</strong></p>
</blockquote>
<p>这也使得Unsloth的动态量化模型成为<strong>个人配置</strong>下的最佳微调工具。</p>
<p>不过需要注意的是，动态量化由利也有弊，其<strong>好处在于可以极大程度压缩模型运行所需占用的显存大小，同时几乎不损失性能</strong>，但问题在于动态量化的模型，无论是推理还是微调，<strong>只能单卡运行</strong>，这就使得其吞吐量有限，无法在一台物理机上实现多GPU并行从而扩大吞吐量。</p>
<h4 id="LLaMA-Factory"><a href="#LLaMA-Factory" class="headerlink" title="LLaMA Factory"></a><strong>LLaMA Factory</strong></h4><p><a href="https://github.com/hiyouga/LLaMA-Factory/tree/main">hiyouga/LLaMA-Factory: Unified Efficient Fine-Tuning of 100+ LLMs &amp; VLMs (ACL 2024)</a></p>
<p>LLaMA Factory 是一个简单易用且高效的大型语言模型训练与微调平台。通过它，用户可以在无需编写任何代码的前提下，在本地完成上百种预训练模型的微调。</p>
<p>LLaMA Factory 提供了API Server 和一站式 WebUI Board，方便企业进行模型的管理和部署。适合不会写代码或代码基础比较弱的同学快速上手进行微调。</p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>ms-SWIFT GitHub项目主页：<a href="https://github.com/modelscope/swift">https://github.com/modelscope/swift</a></p>
<p>ColossalAI GitHub项目主页：<a href="https://github.com/hpcaitech/ColossalAI">https://github.com/hpcaitech/ColossalAI</a></p>
<p>除此之外，也可以借助更加底层的库，如peft、LoRA、transformer等实现高效微调。</p>
<h3 id="模型性能评估框架"><a href="#模型性能评估框架" class="headerlink" title="模型性能评估框架"></a>模型性能评估框架</h3><h4 id="EvalScope"><a href="#EvalScope" class="headerlink" title="EvalScope"></a>EvalScope</h4><p>项目地址： <a href="https://github.com/modelscope/evalscope">https://github.com/modelscope/evalscope</a></p>
<p>EvalScope 是由阿里巴巴魔搭社区（ModelScope）推出的一款开源模型评估框架，旨在为大语言 模型（LLM）和多模态模型提供统一、系统化的性能评估方案。该框架具备高度的自动化和可扩展性， 适用于研究机构、工业界以及模型开发者在模型验证与性能对比场景中的广泛需求。</p>
<h3 id="可视化框架"><a href="#可视化框架" class="headerlink" title="可视化框架"></a>可视化框架</h3><h4 id="wandb"><a href="#wandb" class="headerlink" title="wandb"></a>wandb</h4><p><strong>Weights &amp; Biases（简称 wandb）</strong> 是一个专为机器学习 / 深度学习设计的 <strong>云端实验管理、可视化与协作平台</strong>。它帮你把“训练过程中发生了什么”全部自动化地记录下来，并以网页仪表盘的形式实时展示，省去你手动保存日志、画图、整理表格的麻烦。</p>
<p>wandb官网： <a href="https://wandb.ai/site">https://wandb.ai/site</a></p>
<h4 id="swanlab"><a href="#swanlab" class="headerlink" title="swanlab"></a>swanlab</h4><p>SwanLab 是一款<strong>开源、轻量</strong>的 AI 模型训练跟踪与可视化工具，提供了一个<strong>跟踪、记录、比较、和协作实验</strong>的平台。</p>
<p>SwanLab 面向人工智能研究者，设计了友好的Python API 和漂亮的UI界面，并提供<strong>训练可视化、自动日志记录、超参数记录、实验对比、多人协同等功能</strong>。在SwanLab上，研究者能基于直观的可视化图表发现训练问题，对比多个实验找到研究灵感，并通过<strong>在线网页</strong>的分享与基于组织的<strong>多人协同训练</strong>，打破团队沟通的壁垒，提高组织训练效率。</p>
<p><a href="https://docs.swanlab.cn/">SwanLab官方文档 | 先进的AI团队协作与模型创新引擎</a></p>
<h3 id="构造微调数据集"><a href="#构造微调数据集" class="headerlink" title="构造微调数据集"></a>构造微调数据集</h3><h4 id="为什么要构造微调数据集"><a href="#为什么要构造微调数据集" class="headerlink" title="为什么要构造微调数据集"></a>为什么要构造微调数据集</h4><p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811162229104.png" alt="image-20250811162229104"></p>
<p>其中 &lt;∣im_start∣&gt; 代表文本开始,而user则代表消息身份,用于构建多轮对话,而<lim_end>则代表文本结束,即用户输入结束,而<lim_start>代表新一段文本开始,assistant代表接下来由模型创建消息,而<lim_end>同样代表模型创建消息的结束。</lim_end></lim_start></lim_end></p>
<p>而模型其实是通过这样一组<strong>特殊字符标记</strong>来规范自己的行为,<strong>判断当前消息类型,以及通过输出特殊标记来确定停止时间</strong>。对于绝大多数模型,我们可以在模型的<strong>tokenizer_config.json中看到完整的特殊标记符</strong>(以及系统提示词模板):</p>
<p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811163120092.png" alt="image-20250811163120092"></p>
<p>而在实际微调过程中,我们都知道需要<strong>有监督的数据集</strong>、也就是需要输入QA对来进行微调。以著名的<strong>alpaca_zh中文微调数据集</strong>来说,其基本格式如下:</p>
<p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811163232521.png" alt="image-20250811163232521"></p>
<p>就可以表示为下列json格式数据集:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">json&#123;  &quot;instruction&quot;: &quot;&quot;,  &quot;input&quot;: &quot;输入:你好。&quot;,  &quot;output&quot;: &quot;输出:你好,有什么可以帮到你的?&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>而在真实的微调过程中,如果是针对Qwen3进行微调,微调脚本会将这条数据集(无论什么格式)转化为如下格式:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xml&lt;im_start|&gt;user\n你好&lt;im_end|&gt;\n&lt;im_start|&gt;assistant\n你好,有什么可以帮到你的?&lt;im_end|&gt;</span><br></pre></td></tr></table></figure>
<p>而在实际训练过程中,模型就会根据assistant前的内容,学习assistant后面的输出内容。</p>
<p><strong>因此我们要在下载数据集后，进行微调前，对数据集进行预处理</strong>，接下来引出构造数据集的几种场景</p>
<h4 id="带有系统提示微调数据集格式"><a href="#带有系统提示微调数据集格式" class="headerlink" title="带有系统提示微调数据集格式"></a>带有系统提示微调数据集格式</h4><p>在很多场景下,我们还会发现一些<strong>带有instruction字段的微调数据集</strong>,那instruction字段是如何带入到微调过程中的呢?</p>
<p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811163232521.png" alt="image-20250811163232521"></p>
<p>答案非常简单,还是依靠特殊字符。例如有一个对话内容如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- 系统提示词(instruction):你是一名助人为乐的助手。</span><br><span class="line">- 用户输入(input):你好,好久不见。</span><br><span class="line">- 助手回复(output):是的呀,好久不见,最近有什么有趣的事情要和我分享么?</span><br></pre></td></tr></table></figure>
<p>此时模型的输入和输出如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;lim_start|&gt;system你是一名助人为乐的助手。&lt;/im_end&gt;</span><br><span class="line">&lt;lim_start|&gt;user 你好,好久不见。&lt;/lim_end&gt;</span><br><span class="line">&lt;lim_start|&gt;assistant 是的呀,好久不见,最近有什么有趣的事情要和我分享么?&lt;/lim_end&gt;</span><br></pre></td></tr></table></figure>
<p>即会通过<lim_start|>system…<lim_end|>来标记系统提示词。实际进行微调时,模型会根据assistant为界,学习assistant之前的文本输入情况下应该如何输出。</lim_end|></lim_start|></p>
<h4 id="带Function-calling微调数据集格式"><a href="#带Function-calling微调数据集格式" class="headerlink" title="带Function calling微调数据集格式"></a>带Function calling微调数据集格式</h4><p>更进一步的,如果对话过程中带入了<strong>Function calling</strong>,此时首先模型会读取提前准备好的tool schema(也可能是自动生成的,例如MCP即可自动创建tool schema):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;tool_schema&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;get_weather&quot;,</span><br><span class="line">      &quot;description&quot;: &quot;查询指定城市的天气信息&quot;,</span><br><span class="line">      &quot;parameters&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;object&quot;,</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">          &quot;location&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;string&quot;,</span><br><span class="line">            &quot;description&quot;: &quot;要查询天气的城市名称&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;required&quot;: [&quot;location&quot;]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而假设我们的对话内容如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- 系统提示词(instruction):你是一名助人为乐的助手。当用户查询天气的时候,请调用get_weather函数进行天气信息查询。</span><br><span class="line">- 用户输入(input):你好,请帮我查询下北京天气。</span><br><span class="line">- 助手回复(output):&#123;&quot;name&quot;: &quot;get_weather&quot;, &quot;arguments&quot;: &#123;&quot;location&quot;: &quot;北京&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>此时回复内容就是一条Function call message</p>
</blockquote>
<p>而此时模型真实的输入和输出内容如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;|im_start|&gt;system</span><br><span class="line">你是天气助手，当用户查询天气时请调用 get_weather 函数。</span><br><span class="line"># Tools</span><br><span class="line">You may call one or more functions to assist with the user query.</span><br><span class="line">You are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:</span><br><span class="line">&lt;tools&gt;</span><br><span class="line">[&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;description&quot;:&quot;查询指定城市的天气信息&quot;,&quot;parameters&quot;:&#123;&quot;type&quot;:&quot;object&quot;,&quot;properties&quot;:&#123;&quot;location&quot;:&#123;&quot;type&quot;:&quot;string&quot;,&quot;description&quot;:&quot;要查询天气的城市名称&quot;&#125;&#125;,&quot;required&quot;:[&quot;location&quot;]&#125;&#125;]</span><br><span class="line">&lt;/tools&gt;</span><br><span class="line">&lt;tool_call&gt;</span><br><span class="line"> &#123;&quot;name&quot;: &lt;function-name&gt;, &quot;arguments&quot;: &lt;args-json-object&gt;&#125;</span><br><span class="line">&lt;/tool_call&gt;.</span><br><span class="line">&lt;|im_end|&gt;</span><br><span class="line">&lt;|im_start|&gt;user</span><br><span class="line">北京天气如何？</span><br><span class="line">&lt;|im_end|&gt;</span><br><span class="line">&lt;|im_start|&gt;assistant</span><br><span class="line">&lt;tool_call&gt;&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;arguments&quot;:&#123;&quot;location&quot;:&quot;北京&quot;&#125;&#125;&lt;/tool_call&gt;</span><br><span class="line">&lt;|im_end|&gt;</span><br></pre></td></tr></table></figure>
<p>接下来在进行训练时,模型同样根据assistant前的内容,学习assistant后面的输出内容。不过需要注意的是,由于高效微调调整的参数量较少,因此只能优化模型的Function calling能力,并不能从无到有让模型学会Function calling。</p>
<h4 id="带有思考过程的微调数据集结构"><a href="#带有思考过程的微调数据集结构" class="headerlink" title="带有思考过程的微调数据集结构"></a>带有思考过程的微调数据集结构</h4><p>而如果是带有思考链,则一个简单的问答数据如下:</p>
<p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250811165802090.png" alt="image-20250811165802090"></p>
<ul>
<li>系统提示词(instruction):你是一名助人为乐的助手。</li>
<li>用户输入(input):你好,好久不见。</li>
<li>助手回复(output):好的,用户发来“你好,好久不见!”,我需要回应。首先,用户可能希望得到亲切的回应,所以应该用友好的语气。/n是的呀,好久不见,最近有什么有趣的事情要和我分享么?</li>
</ul>
<p>此时模型真实的内部输入和输出结果如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;lim_start|&gt;system</span><br><span class="line">你是一名助人为乐的助手。&lt;lim_end|&gt;</span><br><span class="line">&lt;lim_start|&gt;user</span><br><span class="line">你好,好久不见。&lt;lim_end|&gt;</span><br><span class="line">&lt;lim_start|&gt;assistant</span><br><span class="line"></span><br><span class="line">&lt;think&gt;  好的,用户发来“你好,好久不见!”,我需要回应。首先,用户可能希望得到亲切的回应,所以应该用友好的语气。&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">是的呀,好久不见,最近有什么有趣的事情要和我分享么?&lt;/lim_end|&gt;</span><br></pre></td></tr></table></figure>
<p>模型同样根据assistant前的内容,学习assistant后面的输出内容。也就是说,所谓的思考过程,本质上其实是一种文本响应格式,通过模型训练而来。</p>
<h4 id="混合推理模型构造微调数据集基本方法"><a href="#混合推理模型构造微调数据集基本方法" class="headerlink" title="混合推理模型构造微调数据集基本方法"></a>混合推理模型构造微调数据集基本方法</h4><p>在了解了微调数据集结构背后的基本原理后,接下来的问题是应该如何构造微调数据集呢?</p>
<p>一般来说我们可以在huggingface、ModelScope或llama- factory中挑选合适的数据集,并根据实际情况进行组装。</p>
<p>例如围绕Qwen3模型的高效微调,为了确保其仍然<strong>保留混合推理能力,</strong>我们可以考虑在微调数据集中加入如普<strong>通对话数据集</strong><a href="https://huggingface.co/datasets/mlabonne/FineTome-100k">FineTome</a>,以及<strong>带有推理字段的数学类数据集</strong><a href="https://huggingface.co/datasets/nvidia/OpenMathReasoning">OpenMathReasoning</a>,<strong>并围绕这两个数据集进行拼接</strong>,从而在确保能提升模型的数学能力的同时,保留非推理的功能。</p>
<p>同时还需要在持续微调训练过程中<strong>不断调整COT数学数据集和普通文本问答数据集之间的配比</strong>,以确保模型能够在提升数学能力的同时,保留混合推理的性能。</p>
<blockquote>
<p>Qwen3 的「混合推理能力」= <strong>在同一个模型里内置两套“大脑”</strong>：<br>• <strong>快思考（非思考模式）</strong>：轻量算力、秒级响应，适合简单问答；<br>• <strong>慢思考（思考模式）</strong>：多步链式推理、深度推敲，适合复杂逻辑、数学、代码。<br>系统会自动或按用户指令在两种模式之间 <strong>动态切换</strong>，从而 <strong>既省算力又保证难题精度</strong>。</p>
</blockquote>
<h3 id="微调的基本流程"><a href="#微调的基本流程" class="headerlink" title="微调的基本流程"></a>微调的基本流程</h3><p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E2%80%94%E2%80%94LoRA/image-20250812105535330.png" alt="image-20250812105535330"></p>
<h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p><strong>安装Unsloth</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo</span><br></pre></td></tr></table></figure>
<p><strong>安装Qwen3-8B-unsloth-bnb-4bit</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">modelscope download --model unsloth/Qwen3-8B-unsloth-bnb-4bit --local_dir /workspace/qwen3-8b</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#模型下载</span><br><span class="line">from modelscope import snapshot_download</span><br><span class="line">model_dir = snapshot_download(&#x27;unsloth/Qwen3-8B-unsloth-bnb-4bit&#x27;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p> <strong>unsloth/Qwen3-8B-unsloth-bnb-4bit</strong> 这个模型它是 <strong>专门为Unsloth微调框架优化过的4bit量化版本</strong></p>
<p>原始 Qwen3-8B（FP16）需要约 <strong>22GB 显存</strong>，而 4bit 量化后仅需 <strong>6GB 左右</strong></p>
<p><strong>只要显存允许，原始 FP16/BF16 模型也可以用 Unsloth 做 4-bit LoRA（即 QLoRA）微调；官方预量化 4-bit 模型只是帮你把“量化”这一步提前做完了，二者本质相同。</strong></p>
<p><strong>Unsloth 的两种用法示例</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">场景</th>
<th style="text-align:left">代码片段</th>
<th style="text-align:left">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">A. 用官方已量化好的 4-bit 权重</td>
<td style="text-align:left"><code>model_name=&quot;unsloth/Qwen3-8B-bnb-4bit&quot;</code></td>
<td style="text-align:left">显卡 6 GB 就能跑，省去自己量化</td>
</tr>
<tr>
<td style="text-align:left">B. 用原始 FP16 权重并现场 4-bit 量化</td>
<td style="text-align:left"><code>model_name=&quot;Qwen/Qwen3-8B&quot;</code> + <code>load_in_4bit=True</code></td>
<td style="text-align:left">显卡仍需 6 GB，显存占用与 A 相同</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两种写法效果等价</span></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name=<span class="string">&quot;Qwen/Qwen3-8B&quot;</span>,   <span class="comment"># 原始权重</span></span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,            <span class="comment"># 现场量化到 4-bit</span></span><br><span class="line">    max_seq_length=<span class="number">2048</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>安装EvalScope</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install evalscope                </span><br><span class="line"># 安装 Native backend (默认)</span><br><span class="line"> # 额外选项</span><br><span class="line">pip install &#x27;evalscope[opencompass]&#x27;   # 安装 OpenCompass backend</span><br><span class="line"> pip install &#x27;evalscope[vlmeval]&#x27;       </span><br><span class="line"># 安装 VLMEvalKit backend</span><br><span class="line"> pip install &#x27;evalscope[rag]&#x27;           </span><br><span class="line">pip install &#x27;evalscope[perf]&#x27;          </span><br><span class="line">pip install &#x27;evalscope[app]&#x27;           </span><br><span class="line"># 或可以直接输入all，安装全部模块</span><br><span class="line"># pip install &#x27;evalscope[all]&#x27;           </span><br><span class="line"># 安装 RAGEval backend</span><br><span class="line"> # 安装 模型压测模块 依赖</span><br><span class="line"># 安装 可视化 相关依赖</span><br><span class="line"># 安装所有 backends (Native, OpenCompass, </span><br><span class="line">VLMEvalKit, RAGEval)</span><br></pre></td></tr></table></figure>
<p><strong>安装wandb</strong></p>
<p>wandb官网： <a href="https://wandb.ai/site">https://wandb.ai/site</a></p>
<p>安装wandb： </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install wandb</span><br></pre></td></tr></table></figure>
<blockquote>
<p><a href="https://github.com/SwanHubX/SwanLab?tab=readme-ov-file#-快速开始">SwanHubX/SwanLab: ⚡️SwanLab - an open-source, modern-design AI training tracking and visualization tool. Supports Cloud / Self-hosted use. Integrated with PyTorch / Transformers / LLaMA Factory / veRL/ Swift / Ultralytics / MMEngine / Keras etc.</a></p>
<p>与其类似，一个开源、现代化设计的深度学习训练跟踪与可视化工具</p>
</blockquote>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.bilibili.com/video/BV13BKozLEXE/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">DIY你的AI梦中情人？Qwen3微调手把手教你！_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1tthPeFEWb/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">通俗易懂理解全量微调和LoRA微调_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1DT421r7Et?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">通俗易懂理解大模型预训练和微调_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1YLE1zyEvX?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=3">3.四大微调框架及微调硬件环境介绍_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1s2AUe2EBq/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">如何把你的 DeePseek-R1 微调为某个领域的专家？（实战篇）_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/javatiange/article/details/149964743?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=149964743&amp;sharerefer=PC&amp;sharesource=2501_91530961&amp;sharefrom=from_link">一文详解：8种常见的大模型微调方法，看这篇就够了！-CSDN博客</a></p>
]]></content>
      <categories>
        <category>模型</category>
        <category>微调</category>
      </categories>
      <tags>
        <tag>模型微调</tag>
        <tag>LoRA</tag>
      </tags>
  </entry>
  <entry>
    <title>LoRA其他的模型微调方法</title>
    <url>/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/LoRA%E5%85%B6%E4%BB%96%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p><a href="https://mp.weixin.qq.com/s?__biz=MzkzODI1NzQyNA==&amp;mid=2247494667&amp;idx=1&amp;sn=c3af7d2472de61752ef8b8df28746f2e&amp;poc_token=HCyNmWijps0ViWD6wPgqFiDYUZVRSs7xUDRfowWE">大模型微调技巧：LoRA 与 QLoRA讲解</a></p>
<p><a href="https://blog.csdn.net/javatiange/article/details/149964743?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=149964743&amp;sharerefer=PC&amp;sharesource=2501_91530961&amp;sharefrom=from_link">一文详解：8种常见的大模型微调方法，看这篇就够了！-CSDN博客</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/682082440">大模型微调技术 - 知乎</a></p>
]]></content>
      <categories>
        <category>模型</category>
        <category>微调</category>
      </categories>
      <tags>
        <tag>模型微调</tag>
      </tags>
  </entry>
  <entry>
    <title>jupyter转markdown</title>
    <url>/2025/03/06/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/jupyter%E8%BD%ACmarkdown/</url>
    <content><![CDATA[<h2 id="jupyter转markdown"><a href="#jupyter转markdown" class="headerlink" title="jupyter转markdown"></a>jupyter转markdown</h2><h3 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h3><p>安装nbconverter: <a href="https://link.zhihu.com/?target=https%3A//nbconvert.readthedocs.io/en/latest/">nbconvert: Convert Notebooks to other formats</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install nbconvert</span><br></pre></td></tr></table></figure>
<p><strong>注意依赖项：</strong></p>
<ul>
<li><strong>基本依赖：pandoc</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install pandoc</span><br></pre></td></tr></table></figure>
<h3 id="二、使用方法"><a href="#二、使用方法" class="headerlink" title="二、使用方法"></a>二、使用方法</h3><p>命令行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ jupyter nbconvert --to FORMAT notebook.ipynb</span><br></pre></td></tr></table></figure>
<p>这里<code>FORMAT</code> 用具体的格式替换，如 <code>markdown</code>, <code>html</code>等。</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ jupyter nbconvert --to markdown notebook.ipynb</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/371132826">Jupyter Notebook文件转markdown - 知乎</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>杂项</tag>
      </tags>
  </entry>
  <entry>
    <title>python-uv包管理</title>
    <url>/2025/08/02/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/python-uv%E5%8C%85%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h3 id="什么是uv"><a href="#什么是uv" class="headerlink" title="什么是uv"></a>什么是uv</h3><p><code>uv</code> 是由 <strong>Astral</strong> 团队开发的一个<strong>超高速 Python 包管理器</strong>，用 <strong>Rust</strong> 编写，目标是替代 <code>pip</code>、<code>venv</code>、<code>pip-tools</code>、<code>poetry</code> 等多个工具。</p>
<h3 id="uv常用命令"><a href="#uv常用命令" class="headerlink" title="uv常用命令"></a>uv常用命令</h3><p>uv init myproj    创建新项目</p>
<p>source .venv/bin/activate（Linux/macOS）激活虚拟环境</p>
<p>uv add requests    安装依赖并写入 pyproject.toml</p>
<p>uv remove requests    移除依赖</p>
<p>uv sync    同步依赖到虚拟环境</p>
<p>uv export    导出 lock 文件为 requirements.txt 等格式</p>
<p>uv build    构建源码包和 wheel</p>
<p>uv publish    发布到 PyPI</p>
<h3 id="uvx是什么"><a href="#uvx是什么" class="headerlink" title="uvx是什么"></a>uvx是什么</h3><p><strong><code>uvx</code></strong> 是：</p>
<blockquote>
<p><strong>uv tool run</strong> 的<strong>快捷别名</strong>（alias），用于<strong>无需安装即可运行 Python 包提供的命令行工具</strong>。</p>
</blockquote>
<p><code>uvx</code> 就像 Python 世界的 <strong><code>npx</code></strong> 或 <strong><code>pipx run</code></strong> ——<br><strong>临时拉取、构建隔离环境、运行工具，用完即走，不留痕迹</strong>。</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.bilibili.com/video/BV1ajJ7zPEa5/?spm_id_from=333.1387.upload.video_card.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【uv】Python迄今最好的项目管理+环境管理工具（吧？）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV13WGHz8EEz?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">从pip到uv：一口气梳理现代Python项目管理全流程！_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型训练流程</title>
    <url>/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/</url>
    <content><![CDATA[<h3 id="什么是大模型"><a href="#什么是大模型" class="headerlink" title="什么是大模型"></a>什么是大模型</h3><p>随着2022年底 ChatGPT 再一次刷新 NLP 的能力上限，大<strong>语言模型（Large Language Model，LLM）开始接替传统的预训练语言模型（Pre-trained Language Model，PLM）</strong> 成为 NLP 的主流方向，基于 LLM 的全新研究范式也正在刷新被 BERT 发扬光大的<strong>预训练-微调范式</strong>，NLP 由此迎来又一次翻天覆地的变化。</p>
<p>LLM，即 Large Language Model，中文名为大语言模型或大型语言模型，是一种相<strong>较传统语言模型参数量更多、在更大规模语料上进行预训练的语言模型</strong>。</p>
<p>一般来说，LLM 指包含<strong>数百亿（或更多）参数的语言模型</strong>，它们往往在<strong>数 T token 语料上</strong>通过多卡分布式集群进行预训练，具备远超出传统预训练模型的文本理解与生成能力。不过，随着 LLM 研究的不断深入，多种参数尺寸的 LLM 逐渐丰富，广义的 LLM 一般覆盖了从<strong>十亿参数</strong>（如 Qwen-1.5B）到<strong>千亿参数</strong>（如 Grok-314B）的所有大型语言模型。只要模型展现出<strong>涌现能力</strong>，即在一系列复杂任务上表现出远超传统预训练模型（如 BERT、T5）的能力与潜力，都可以称之为 LLM。</p>
<p>一般认为，GPT-3（1750亿参数）是 LLM 的开端，基于 GPT-3 通过 <strong>预训练（Pretraining）、监督微调（Supervised Fine-Tuning，SFT）、强化学习与人类反馈（Reinforcement Learning with Human Feedback，RLHF）</strong>三阶段训练得到的 ChatGPT 更是主导了 LLM 时代的到来。</p>
<blockquote>
<p>区分 LLM 与传统 PLM 最显著的特征即是 LLM 具备 <code>涌现能力</code> 。涌现能力是指同样的模型架构与预训练任务下，某些能力在小型模型中不明显，但在大型模型中特别突出。</p>
</blockquote>
<h3 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h3><p><img src="/2025/08/11/%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/image-20250811092459843.png" alt="image-20250811092459843"></p>
<p>一般而言，训练一个完整的 LLM 需要经过图1中的三个阶段——Pretrain、SFT 和 RLHF。</p>
<h3 id="Pretrain"><a href="#Pretrain" class="headerlink" title="Pretrain"></a>Pretrain</h3><p>Pretrain，即预训练，是训练 LLM 最核心也是工程量最大的第一步。</p>
<h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><div class="table-container">
<table>
<thead>
<tr>
<th>模型</th>
<th>hidden_layers</th>
<th>hidden_size</th>
<th>heads</th>
<th>整体参数量</th>
<th>预训练数据量</th>
</tr>
</thead>
<tbody>
<tr>
<td>BERT-base</td>
<td>12</td>
<td>768</td>
<td>12</td>
<td>0.1B</td>
<td>3B</td>
</tr>
<tr>
<td>BERT-large</td>
<td>24</td>
<td>1024</td>
<td>16</td>
<td>0.3B</td>
<td>3B</td>
</tr>
<tr>
<td>Qwen-1.8B</td>
<td>24</td>
<td>2048</td>
<td>16</td>
<td>1.8B</td>
<td>2.2T</td>
</tr>
<tr>
<td>LLaMA-7B</td>
<td>32</td>
<td>4096</td>
<td>32</td>
<td>7B</td>
<td>1T</td>
</tr>
<tr>
<td>GPT-3</td>
<td>96</td>
<td>12288</td>
<td>96</td>
<td>175B</td>
<td>300B</td>
</tr>
</tbody>
</table>
</div>
<p>根据定义，LLM 的核心特点即在于其具有<strong>远超传统预训练模型的参数量</strong>，<strong>同时在更海量的语料上进行预训练</strong>。传统预训练模型如 BERT，有 base 和 large 两个版本。BERT-base 模型由 12个 Encoder 层组成，其 hidden_size 为 768，使用 12个头作为多头注意力层，整体参数量为 1亿（110M）；而 BERT-large 模型由 24个 Encoder 层组成，hidden_size 为 1024，有 16个头，整体参数量为 3亿（340M）。同时，BERT 预训练使用了 33亿（3B）token 的语料，在 64块 TPU 上训练了 4天。事实上，相对于传统的深度学习模型，3亿参数量、33亿训练数据的 BERT 已经是一个能力超群、资源消耗巨大的庞然大物。</p>
<p>但是，前面我们提到，<strong>一般而言的 LLM 通常具有数百亿甚至上千亿参数</strong>，即使是广义上最小的 LLM，一般也有十亿（1B）以上的参数量。例如以开山之作 GPT-3 为例，其有 96个 Decoder 层，12288 的 hidden_size 和 96个头，<strong>共有 1750亿（175B）参数，比 BERT 大出快 3个数量级</strong>。即使是目前流行的小型 LLM 如 Qwen-1.8B，其也有 24个 Decoder 层、2048的 hidden_size 和 16个注意力头，整体参数量达到 18亿（1.8B）。</p>
<h4 id="分布式训练"><a href="#分布式训练" class="headerlink" title="分布式训练"></a>分布式训练</h4><p>也正因如此，<strong>分布式训练框架也成为 LLM 训练必不可少的组成部分</strong>。分布式训练框架的核心思路是<strong>数据并行和模型并行</strong>。所谓数据并行，是指训练模型的尺寸可以被单个 GPU 内存容纳，但是由于增大训练的 batch_size 会增大显存开销，无法使用较大的 batch_size 进行训练；同时，训练数据量非常大，使用单张 GPU 训练时长难以接受。</p>
<h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><strong>训练数据本身也是预训练 LLM 的一个重大挑战</strong>。训练一个 LLM，至少需要数百 B 甚至上 T 的预训练语料。根据研究，LLM 所掌握的知识绝大部分都是在预训练过程中学会的，因此，为了使训练出的 LLM 能够覆盖尽可能广的知识面，预训练语料需要组织多种来源的数据，并以一定比例进行混合。目前，主要的开源预训练语料包括 CommonCrawl、C4、Github、Wikipedia 等。<strong>不同的 LLM 往往会在开源预训练语料基础上，加入部分私有高质量语料，再基于自己实验得到的最佳配比来构造预训练数据集</strong>。事实上，<strong>数据配比</strong>向来是预训练 LLM 的“核心秘籍”，不同的配比往往会相当大程度影响最终模型训练出来的性能。</p>
<p>训练一个中文 LLM，训练数据的难度会更大。目前，高质量语料还是大部分集中在英文范畴，例如上表的 Wikipedia、Arxiv 等，均是英文数据集；而 C4 等多语言数据集中，英文语料也占据主要地位。目前开源的中文 LLM 如 ChatGLM、Baichuan 等模型均未开放其预训练数据集，开源的中文预训练数据集目前仅有昆仑天工开源的<a href="https://huggingface.co/datasets/Skywork/SkyPile-150B">SkyPile</a>（150B）、中科闻歌开源的<a href="https://huggingface.co/datasets/wenge-research/yayi2_pretrain_data">yayi2</a>（100B）等，相较于英文开源数据集有明显差距。</p>
<h4 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h4><p><strong>预训练数据的处理与清洗</strong>也是 LLM 预训练的一个重要环节。诸多研究证明，预训练数据的质量往往比体量更加重要。预训练数据处理一般包括以下流程：</p>
<ol>
<li>文档准备。由于海量预训练语料往往是从互联网上获得，一般需要从爬取的网站来获得自然语言文档。文档准备主要包括 URL 过滤（根据网页 URL 过滤掉有害内容）、文档提取（从 HTML 中提取纯文本）、语言选择（确定提取的文本的语种）等。</li>
<li>语料过滤。语料过滤的核心目的是去除低质量、无意义、有毒有害的内容，例如乱码、广告等。语料过滤一般有两种方法：基于模型的方法，即通过高质量语料库训练一个文本分类器进行过滤；基于启发式的方法，一般通过人工定义 web 内容的质量指标，计算语料的指标值来进行过滤。</li>
<li>语料去重。实验表示，大量重复文本会显著影响模型的泛化能力，因此，语料去重即删除训练语料中相似度非常高的文档，也是必不可少的一个步骤。去重一般基于 hash 算法计算数据集内部或跨数据集的文档相似性，将相似性大于指定阈值的文档去除；也可以基于子串在序列级进行精确匹配去重。</li>
</ol>
<h3 id="SFT-指令微调"><a href="#SFT-指令微调" class="headerlink" title="SFT 指令微调"></a>SFT 指令微调</h3><p>预训练赋予了 LLM 能力，却还需要第二步将其激发出来。经过预训练的 LLM 好像一个博览群书但又不求甚解的书生，对什么样的偏怪问题，都可以流畅地接出下文，但他偏偏又<strong>不知道问题本身的含义</strong>，只会“死板背书”。这一现象的本质是因为，LLM 的预训练任务就是经典的 <strong>CLM</strong>，也就是训<strong>练其预测下一个 token 的能力</strong>，在没有进一步微调之前，其无法与其他下游任务或是用户指令适配。</p>
<p>因此，我们还需要第二步来教这个博览群书的学生如何去使用它的知识，也就是 <strong>SFT（Supervised Fine-Tuning，有监督微调）</strong>。</p>
<p>面对能力强大的 LLM，我们往往不再是在指定下游任务上构造有监督数据进行微调，而是选择训练模型的“通用指令遵循能力”，也就是一般<strong>通过<code>指令微调</code>的方式来进行 SFT</strong>。</p>
<p>所谓指令微调，即我们训练的输入是各种类型的用户指令，而需要模型拟合的输出则是我们希望模型在收到该指令后做出的回复。例如，我们的一条训练样本可以是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input:告诉我今天的天气预报？</span><br><span class="line">output:根据天气预报，今天天气是晴转多云，最高温度26摄氏度，最低温度9摄氏度，昼夜温差大，请注意保暖哦</span><br></pre></td></tr></table></figure>
<p>也就是说，SFT 的主要目标是让模型从多种类型、多种风格的指令中获得泛化的指令遵循能力，也就是能够理解并回复用户的指令。</p>
<h3 id="RLHF"><a href="#RLHF" class="headerlink" title="RLHF"></a>RLHF</h3><p>RLHF，全称是 <strong>Reinforcement Learning from Human Feedback，即人类反馈强化学习</strong>，是利用强化学习来训练 LLM 的关键步骤。相较于在 GPT-3 就已经初见雏形的 SFT，RLHF 往往被认为是 ChatGPT 相较于 GPT-3 的最核心突破。事实上，从功能上出发，我们可以将 LLM 的训练过程分成<strong>预训练与对齐（alignment）两个阶段</strong>。预训练的核心作用是赋予模型海量的知识，而所谓对齐，其实就是让模型与人类价值观一致，从而输出人类希望其输出的内容。在这个过程中，SFT 是让 LLM 和人类的指令对齐，从而具有指令遵循能力；而 RLHF 则是从更深层次令 LLM 和人类价值观对齐，令其达到安全、有用、无害的核心标准。</p>
<p>RLHF 分为两个步骤：<strong>训练 RM 和 PPO 训练</strong>。</p>
<p><strong>RM，Reward Model，即奖励模型</strong>。RM 是用于拟合人类偏好，来给 LLM 做出反馈的。在强化学习的训练中，对于 LLM 的每一个回复，RM 会进行打分，这个打分反映了生成回复符合人类偏好的程度。然后 LLM 会根据强化学习的原理，基于 RM 的打分来进行优化训练。</p>
<p>在完成 RM 训练之后，就可以使用 PPO 算法来进行强化学习训练。<strong>PPO，Proximal Policy Optimization，近端策略优化算法</strong>，是一种经典的 RL 算法。事实上，强化学习训练时也可以使用其他的强化学习算法，但目前 PPO 算法因为成熟、成本较低，还是最适合 RLHF 的算法。</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://datawhalechina.github.io/happy-llm/#/./chapter4/第四章 大语言模型">第四章 大语言模型</a></p>
]]></content>
      <categories>
        <category>模型</category>
        <category>微调</category>
      </categories>
      <tags>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>python-logging模块</title>
    <url>/2025/08/02/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/python-logging%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<h3 id="日志级别"><a href="#日志级别" class="headerlink" title="日志级别"></a>日志级别</h3><div class="table-container">
<table>
<thead>
<tr>
<th>级别</th>
<th>方法</th>
<th>用途</th>
</tr>
</thead>
<tbody>
<tr>
<td>DEBUG</td>
<td><code>logging.debug()</code></td>
<td>调试信息</td>
</tr>
<tr>
<td>INFO</td>
<td><code>logging.info()</code></td>
<td>普通信息</td>
</tr>
<tr>
<td>WARNING</td>
<td><code>logging.warning()</code></td>
<td>警告信息</td>
</tr>
<tr>
<td>ERROR</td>
<td><code>logging.error()</code></td>
<td>错误信息</td>
</tr>
<tr>
<td>CRITICAL</td>
<td><code>logging.critical()</code></td>
<td>严重错误</td>
</tr>
</tbody>
</table>
</div>
<p>python默认只会打印warning以上级别的日志，可通过<code>basicConfig</code>进行设置，如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 基础配置</span><br><span class="line">logging.basicConfig(level=logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># 记录不同级别的日志</span><br><span class="line">logging.debug(&quot;这是一个DEBUG级别的日志&quot;)</span><br><span class="line">logging.info(&quot;这是一个INFO级别的日志&quot;)</span><br><span class="line">logging.warning(&quot;这是一个WARNING级别的日志&quot;)</span><br><span class="line">logging.error(&quot;这是一个ERROR级别的日志&quot;)</span><br><span class="line">logging.critical(&quot;这是一个CRITICAL级别的日志&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="格式化log并输出"><a href="#格式化log并输出" class="headerlink" title="格式化log并输出"></a>格式化log并输出</h3><p>我们可以使用全局配置，完成log的格式化和输出成文件，如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">logging.basicConfig(level=logging.DEBUG,format=&#x27;%(asctime)s - %(levelname)s - %(message)s&#x27;,filename=&#x27;basic.log&#x27;,filemode=&#x27;w&#x27;)</span><br></pre></td></tr></table></figure>
<p>同样，我们可以自定义logger</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 创建自定义logger</span><br><span class="line">logger = logging.getLogger(&#x27;my_app&#x27;)</span><br><span class="line">logger.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># 清除之前的处理器</span><br><span class="line">logger.handlers.clear()</span><br><span class="line"></span><br><span class="line"># 创建文件处理器</span><br><span class="line">file_handler = logging.FileHandler(&#x27;logs/my_app.log&#x27;, encoding=&#x27;utf-8&#x27;)</span><br><span class="line">file_handler.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line"># 创建控制台处理器</span><br><span class="line">console_handler = logging.StreamHandler()</span><br><span class="line">console_handler.setLevel(logging.WARNING)</span><br><span class="line"></span><br><span class="line"># 创建不同的格式器</span><br><span class="line">file_formatter = logging.Formatter(</span><br><span class="line">    &#x27;%(asctime)s | %(name)s | %(levelname)s | %(funcName)s:%(lineno)d | %(message)s&#x27;</span><br><span class="line">)</span><br><span class="line">console_formatter = logging.Formatter(</span><br><span class="line">    &#x27;🚨 %(levelname)s: %(message)s&#x27;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">file_handler.setFormatter(file_formatter)</span><br><span class="line">console_handler.setFormatter(console_formatter)</span><br><span class="line"></span><br><span class="line"># 添加处理器</span><br><span class="line">logger.addHandler(file_handler)</span><br><span class="line">logger.addHandler(console_handler)</span><br><span class="line"></span><br><span class="line"># 测试不同级别的日志</span><br><span class="line">logger.debug(&quot;调试信息 - 只写入文件&quot;)</span><br><span class="line">logger.info(&quot;普通信息 - 只写入文件&quot;)</span><br><span class="line">logger.warning(&quot;警告信息 - 控制台和文件都有&quot;)</span><br><span class="line">logger.error(&quot;错误信息 - 控制台和文件都有&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="异常捕获"><a href="#异常捕获" class="headerlink" title="异常捕获"></a>异常捕获</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">try:</span><br><span class="line">    result = divide(10, 0)</span><br><span class="line">except ZeroDivisionError as exc:</span><br><span class="line">    # 方式 1：记录异常对象</span><br><span class="line">    logger.error(&quot;除零异常发生: &#123;&#125;&quot;, exc)</span><br><span class="line"></span><br><span class="line">    # 方式 2：记录完整 traceback（推荐）</span><br><span class="line">    logger.exception(&quot;捕获到异常，详情如下&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="loguru的常用使用方法"><a href="#loguru的常用使用方法" class="headerlink" title="loguru的常用使用方法"></a>loguru的常用使用方法</h3><p>基础用法</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from loguru import logger</span><br><span class="line"></span><br><span class="line">logger.debug(&quot;这是 debug&quot;)</span><br><span class="line">logger.info(&quot;这是 info&quot;)</span><br><span class="line">logger.warning(&quot;这是 warning&quot;)</span><br><span class="line">logger.error(&quot;这是 error&quot;)</span><br><span class="line">logger.critical(&quot;这是 critical&quot;)</span><br></pre></td></tr></table></figure>
<p>输出到文件    logger.add(“app.log”)</p>
<p>过滤级别    logger.add(“app.log”, level=”WARNING”)</p>
<p>移除默认控制台输出       logger.remove()</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.bilibili.com/video/BV1rJv8eNE1x?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">[Python] logging模块怎么用_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1VnW7edEq7?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">[Python] 打印log神器 —— loguru_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>杂项</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Retrieval</title>
    <url>/2025/07/21/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/Retrieval/</url>
    <content><![CDATA[<h3 id="elastic-search"><a href="#elastic-search" class="headerlink" title="elastic search"></a>elastic search</h3><p>Elasticsearch 是当今最流行的 <strong>开源分布式搜索与分析引擎</strong>，用 Java 开发，基于 <strong>Apache Lucene</strong> 构建。它把<strong>全文检索、实时分析、时序数据、地理空间查询</strong>和<strong>向量检索</strong>统一到一个平台，被广泛用于日志、指标、安全、企业搜索以及 AI/RAG 场景。</p>
<p> RAG 系统中，<strong>Elasticsearch 不仅是向量数据库，更是语义检索引擎和上下文构建器</strong>，更准确地说，是<strong>向量数据库 + 全文检索引擎</strong>的混合角色。</p>
<h4 id="查找语句"><a href="#查找语句" class="headerlink" title="查找语句"></a>查找语句</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GET /test_full_v1/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot;: &#123;</span><br><span class="line">      &quot;query&quot;: &quot;高压旁路管道磁粉检测使用的是哪种磁化方法和磁悬液浓度？&quot;,</span><br><span class="line">      &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;,&quot;report_url&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices?v#查看所有的所有</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_count#查看文件数</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_mapping#查看映射</span><br><span class="line"></span><br><span class="line">GET test_full_v1#查看索引内容</span><br><span class="line"></span><br><span class="line">GET test_full_v1/_search#查看索引内容</span><br><span class="line">&#123;</span><br><span class="line">  &quot;size&quot;: 3,</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /_cat/indices/zxj_test#查看索引是否存在</span><br></pre></td></tr></table></figure>
<p>可视化平台kibana的内网路径：</p>
<ul>
<li><code>http://10.117.128.50:5601</code></li>
<li><a href="http://10.117.128.50:5601/app/dev_tools#/console/shell">http://10.117.128.50:5601/app/dev_tools#/console/shell</a> 开发者工具</li>
</ul>
<h4 id="es支持的几种检索函数"><a href="#es支持的几种检索函数" class="headerlink" title="es支持的几种检索函数"></a>es支持的几种检索函数</h4><h5 id="向量搜索"><a href="#向量搜索" class="headerlink" title="向量搜索"></a>向量搜索</h5><p>这里的向量搜索也就是稠密向量检索，过程为<strong>“把文本/图像等非结构化数据映射成高维向量 → 在向量空间里做近似最近邻（ANN）搜索 → 按相似度排序返回结果”</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def vector_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建Elasticsearch KNN查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;knn&quot;: &#123;</span><br><span class="line">            &quot;field&quot;: dense_vector_field,      # 指定存储向量的字段名</span><br><span class="line">            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">            &quot;k&quot;: 5,                          # 返回最相似的5个结果</span><br><span class="line">            &quot;num_candidates&quot;: 10,            # 在10个候选中选择最优的5个（提高搜索效率和准确性）</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="bm25"><a href="#bm25" class="headerlink" title="bm25"></a>bm25</h5><p>BM25（<strong>Best Matching 25</strong>）也就是全文关键词搜索，或者叫传统关键词搜索，他的核心思想为<strong>“词频越高、文档越短、词越稀有，则相关性越高”</strong>，在 TF-IDF 的基础上引入词频饱和、文档长度归一化两项修正。</p>
<blockquote>
<p>TF-IDF（<strong>Term Frequency–Inverse Document Frequency，词频-逆文档频率</strong>）是一种经典的 <strong>文本特征权重计算方法</strong>，用于衡量 <strong>一个词对一篇文档的重要性</strong>。</p>
</blockquote>
<p>项目中的bm25检索采取多字段匹配的方式，还有几个参数需要了解，如下</p>
<ol>
<li><p><strong>‘type’</strong> :决定了<strong>如何把多个字段的 BM25 打分合并成最终得分</strong>,常用的参数有以下三种</p>
<p>| type                    | 中文含义     | 打分逻辑                                                     |<br>| :——————————— | :—————- | :—————————————————————————————- |<br>| <strong>best_fields</strong>（默认） | 最佳字段优先 | 取 <strong>得分最高的那个字段</strong> 做最终分（可用 <code>tie_breaker</code> 让次佳字段再贡献一点点）。 |<br>| <strong>most_fields</strong>         | 最多字段优先 | 把所有命中字段的得分 <strong>直接相加</strong>（类似 OR 逻辑），字段越多分越高。 |<br>| <strong>cross_fields</strong>        | 跨字段合并   | 把多个字段视为 <strong>一个虚拟大字段</strong>，统一计算 TF 和 IDF，解决“关键词分散在不同字段”问题。 |</p>
</li>
<li><p><strong><code>&#39;tie_breaker&#39;</code></strong>：当多个字段都匹配时，<strong>“最佳字段”得分 + 其余字段得分×tie_breaker</strong> 作为最终得分。</p>
</li>
<li><strong><code>&#39;operator&#39;</code></strong>:控制<strong>单个字段内</strong>的多个词项是“AND”还是“OR”关系。<ul>
<li><strong><code>&quot;AND&quot;</code></strong><br>要求<strong>同一个字段</strong>必须同时包含所有查询词，减少噪音，提高精准度。适合地址、姓名等跨字段严格匹配。</li>
<li><strong><code>&quot;OR&quot;</code></strong><br>只要字段里出现任意一个词就匹配，召回量大，但可能引入不相关结果。</li>
</ul>
</li>
</ol>
<p>最后，每个字段还可以人工设置权重，如<code>&quot;fields&quot;: [&quot;title^3&quot;, &quot;content&quot;, &quot;tags^2&quot;]</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def bm25_query(search_query: str):</span><br><span class="line">    # 使用BM25算法进行传统关键词匹配</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            &quot;multi_match&quot;: &#123;  # 多字段匹配查询</span><br><span class="line">                &quot;query&quot;: search_query,</span><br><span class="line">                &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;size&quot;: 8,  # 返回最多8个结果</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="混合检索"><a href="#混合检索" class="headerlink" title="混合检索"></a>混合检索</h5><p>混合检索也就是 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html">Reciprocal Rank Fusion</a>（RRF），通过结合向量搜索和 BM25 搜索的结果综合判断。</p>
<p>但由于es中混合检索需要付费使用，后续检索效果评估时不做测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def hybrid_query(search_query: str):</span><br><span class="line">    # 使用与索引时相同的嵌入模型将查询文本转换为向量</span><br><span class="line">    vector = embeddings.embed_query(search_query)</span><br><span class="line">    </span><br><span class="line">    # 构建混合搜索查询结构</span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;retriever&quot;: &#123;</span><br><span class="line">            # 使用RRF (Reciprocal Rank Fusion) 算法融合多个检索器的结果</span><br><span class="line">            &quot;rrf&quot;: &#123;</span><br><span class="line">                # 定义多个检索器列表</span><br><span class="line">                &quot;retrievers&quot;: [</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第一个检索器：多字段BM25关键词搜索</span><br><span class="line">                        &quot;standard&quot;: &#123;</span><br><span class="line">                            &quot;query&quot;: &#123;</span><br><span class="line">                                # 使用multi_match在多个字段上进行BM25搜索</span><br><span class="line">                                &quot;multi_match&quot;: &#123;</span><br><span class="line">                                    &quot;query&quot;: search_query,</span><br><span class="line">                                    &quot;type&quot;: &quot;best_fields&quot;,      # 选择最佳匹配字段</span><br><span class="line">                                    &quot;fields&quot;: [&quot;text&quot;, &quot;report_name&quot;, &quot;report_url&quot;]  # 在这些字段中搜索</span><br><span class="line">                                &#125;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &#123;</span><br><span class="line">                        # 第二个检索器：KNN向量近似搜索</span><br><span class="line">                        &quot;knn&quot;: &#123;</span><br><span class="line">                            &quot;field&quot;: dense_vector_field,      # 向量字段名（使用定义的变量）</span><br><span class="line">                            &quot;query_vector&quot;: vector,           # 查询向量</span><br><span class="line">                            &quot;k&quot;: 5,                          # 返回5个最相似的向量结果</span><br><span class="line">                            &quot;num_candidates&quot;: 10,            # 候选向量数量，用于提高搜索准确性</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h5 id="模糊检索"><a href="#模糊检索" class="headerlink" title="模糊检索"></a>模糊检索</h5><p>无论是在网页搜索、文件检索，还是数据库查询中，我们时常会因为拼写错误或信息不完整而无法找到需要的结果。<strong>模糊搜索</strong>（Fuzzy Search）应运而生，它通过识别与查询相似的词语来帮助我们获得更加灵活的搜索结果。</p>
<p>这里是将bm25与模糊搜索结合起来</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def fuzzy_query(search_query: str):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    创建模糊搜索查询函数，支持拼写错误和近似匹配</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        search_query (str): 用户输入的搜索查询文本</span><br><span class="line">        </span><br><span class="line">    Returns:</span><br><span class="line">        Dict: Elasticsearch模糊搜索查询体</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    return &#123;</span><br><span class="line">        &quot;query&quot;: &#123;</span><br><span class="line">            # 使用match查询进行文本匹配</span><br><span class="line">            &quot;match&quot;: &#123;</span><br><span class="line">                # 在指定的文本字段中进行搜索</span><br><span class="line">                text_field: &#123;</span><br><span class="line">                    &quot;query&quot;: search_query,        # 用户的搜索查询文本</span><br><span class="line">                    &quot;fuzziness&quot;: &quot;AUTO&quot;,          # 自动模糊匹配设置</span><br><span class="line">                    # fuzziness参数说明：</span><br><span class="line">                    # - &quot;AUTO&quot;：根据词长度自动调整模糊度</span><br><span class="line">                    #   - 0-2个字符：不允许错误</span><br><span class="line">                    #   - 3-5个字符：允许1个编辑距离错误</span><br><span class="line">                    #   - 5个以上字符：允许2个编辑距离错误</span><br><span class="line">                    # - 也可以设置具体数值：0, 1, 2</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><code>AUTO</code> 规则：<strong>0~2 字符</strong>不允许错；<strong>3~5 字符</strong>最多1错；<strong>&gt;5 字符</strong>最多2错。</li>
<li>对 <strong>text 字段</strong>先分词，再对每个 token 做模糊 → 召回 <code>Elasticsearch</code>。</li>
</ul>
<h4 id="elasticsearch的连接"><a href="#elasticsearch的连接" class="headerlink" title="elasticsearch的连接"></a>elasticsearch的连接</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_elasticsearch import ElasticsearchRetriever</span><br><span class="line">from embeddings_model import select_embeddings_model</span><br><span class="line"># 根据模型名称选择嵌入模型</span><br><span class="line">embedding_model_name=&#x27;bge&#x27;</span><br><span class="line">embeddings = select_embeddings_model(embedding_model_name)</span><br><span class="line">dense_vector_field=&#x27;vector&#x27;</span><br><span class="line">text_field=&#x27;text&#x27;</span><br><span class="line">search_func=fuzzy_query</span><br><span class="line"># 创建Elasticsearch检索器</span><br><span class="line">retriever = ElasticsearchRetriever.from_es_params(</span><br><span class="line">    index_name=&quot;zxj_test&quot;,  # 指定索引名称</span><br><span class="line">    body_func=fuzzy_query,  # 查询函数</span><br><span class="line">    content_field=&quot;text&quot;,  # 内容字段名</span><br><span class="line">    url=&#x27;http://elasticsearch:9200/&#x27;# Elasticsearch服务器地址</span><br><span class="line">)</span><br><span class="line">print(&quot;连接成功&quot;)</span><br></pre></td></tr></table></figure>
<h4 id="elasticsearch的入库"><a href="#elasticsearch的入库" class="headerlink" title="elasticsearch的入库"></a>elasticsearch的入库</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">document = []</span><br><span class="line">id_list = []</span><br><span class="line"></span><br><span class="line"># 遍历文件夹中的所有.md文件</span><br><span class="line">for filename in os.listdir(folder_path):</span><br><span class="line">    if filename.endswith(&quot;.md&quot;):</span><br><span class="line">        file_path = os.path.join(folder_path, filename)</span><br><span class="line"></span><br><span class="line">        # 从文件名中提取chunk_id（去除.md扩展名）</span><br><span class="line">        chunk_id = filename.replace(&quot;.md&quot;, &quot;&quot;)</span><br><span class="line"></span><br><span class="line">        # 读取MD文件内容</span><br><span class="line">        with open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as file:</span><br><span class="line">            text_content = file.read()</span><br><span class="line">  </span><br><span class="line">        # 查找对应的URL（根据文件名匹配）</span><br><span class="line">        report_url = &quot;&quot;</span><br><span class="line">        # 从folder_name中提取核心文档名（最后一个^后面的部分）</span><br><span class="line">        core_folder_name = folder_name.split(&#x27;^&#x27;)[-1]  # 提取核心文档名</span><br><span class="line"></span><br><span class="line">        # 根据core_folder_name查找对应的URL</span><br><span class="line">        report_url = find_url_by_name_from_list(docs_data, core_folder_name)</span><br><span class="line"></span><br><span class="line">        # 构建document结构</span><br><span class="line">        doc = Document(</span><br><span class="line">            page_content=text_content,</span><br><span class="line">            metadata=&#123;</span><br><span class="line">                &quot;report_name&quot;: folder_name,</span><br><span class="line">                &quot;report_url&quot;: report_url,</span><br><span class="line">                &quot;chunk_id&quot;: chunk_id</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        document.append(doc)</span><br><span class="line">        id_list.append(folder_name + &quot;_&quot; + chunk_id)</span><br><span class="line"></span><br><span class="line"># 批量添加到向量库</span><br><span class="line">es_vector_store.add_documents(documents=document, ids=id_list)</span><br><span class="line">print(f&quot;    文件夹 &#123;folder_name&#125; 已成功入库，共 &#123;len(document)&#125; 个文档块&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h4><p><a href="https://python.langchain.ac.cn/docs/integrations/retrievers/elasticsearch_retriever/#bm25">Elasticsearch检索器 | 🦜️🔗 LangChain 框架</a></p>
<h3 id="主流的检索策略"><a href="#主流的检索策略" class="headerlink" title="主流的检索策略"></a>主流的检索策略</h3><h4 id="BM25-全文关键词检索"><a href="#BM25-全文关键词检索" class="headerlink" title="BM25 全文关键词检索"></a>BM25 全文关键词检索</h4><p>BM25（Best Matching 25）是一种久经考验的排序算法，广泛应用于传统搜索引擎中。它基于“词袋模型”，核心思想是通过关键词匹配程度来衡量文档与查询的相关性。</p>
<p>核心原理概览：</p>
<p>词频 (Term Frequency, TF)：一个词在文档中出现的次数越多，通常意味着这篇文档与该词相关性越高。但BM25会进行“饱和度”处理，避免某些超高频词过度影响结果。可以想象成，一篇文章提到“苹果”10次，比提到1次更相关，但提到100次和提到50次，在“苹果”这个主题上的相关性增加可能就没那么显著了。<br>逆文档频率 (Inverse Document Frequency, IDF)：如果一个词在整个文档集合中都很罕见（只在少数文档中出现），那么它对于区分文档主题就更重要，IDF值就高。比如“量子纠缠”这个词远比“的”、“是”这类词更能锁定专业文档。<br>文档长度归一化：用于平衡长短文档的得分，避免长文档仅仅因为内容多而获得不公平的高分。<br>工作方式举例：当用户搜索“深度学习入门教程”时，BM25会倾向于找出那些更频繁出现“深度学习”、“入门”、“教程”这些词，且这些词相对不那么常见的文档。</p>
<p><strong>1. 公式整体结构</strong></p>
<script type="math/tex; mode=display">
\text{score}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \underbrace{\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot \left(1 - b + b \cdot \frac{|D|}{\text{avgdl}}\right)}}_{\text{词频归一化项（TF）}}</script><ul>
<li><strong>IDF 部分</strong>：衡量词项 $ q_i $ 的区分能力（逆文档频率）。</li>
<li><strong>TF 部分</strong>：衡量词项 $ q_i $ 在文档 $ D $ 中的匹配程度（词频归一化）。</li>
<li><strong>求和</strong>：对查询中的所有词项 $ q_i $ 的得分求和，得到最终相关性分数。</li>
</ul>
<p><strong>2. IDF 部分</strong></p>
<script type="math/tex; mode=display">
\text{IDF}(q_i) = \ln\left(\frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}\right)</script><ul>
<li><strong>意义</strong>：IDF 值越高，词项 $ q_i $ 越能区分文档（常见于少数文档中的词）。</li>
<li><strong>平滑处理</strong>：分子和分母均加 0.5，避免极端值（如 $ n(q_i) = 0 $ 时 ID 无限大）。</li>
<li><strong>参数</strong>：<ul>
<li>$ N $：文档总数。</li>
<li>$ n(q_i) $：包含 $ q_i $ 的文档数。</li>
</ul>
</li>
</ul>
<p><strong>3. 词频归一化项（TF）</strong></p>
<script type="math/tex; mode=display">
\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot \left(1 - b + b \cdot \frac{|D|}{\text{avgdl}}\right)}</script><ul>
<li><strong>非线性饱和</strong>：分子和分母均包含 $ f(q_i, D) $，使词频增长带来的增益逐渐减小（避免长文档中重复词项的过度影响）。</li>
<li><strong>文档长度归一化</strong>：<ul>
<li>$ |D| $：文档 $ D $ 的长度（词数）。</li>
<li>$ \text{avgdl} $：整个文档集合的平均文档长度。</li>
<li>$ b $：控制文档长度对得分的影响（$ b=1 $ 时完全归一化，$ b=0 $ 时忽略长度）。</li>
</ul>
</li>
<li><strong>参数</strong>：<ul>
<li>$ k_1 $：控制词频饱和的系数（通常 $ k_1 \in [1.2, 2.0] $，默认 $ k_1 = 1.5 $）。</li>
<li>$ b $：默认 $ b = 0.75 $。</li>
</ul>
</li>
</ul>
<p>这个公式虽然看起来有些复杂，但它精妙地平衡了词频、词的稀有度以及文档长度这几个核心因素，是BM25算法效果出色的关键。</p>
<h6 id="BM25、全文搜索与倒排索引：它们是如何协同工作的？"><a href="#BM25、全文搜索与倒排索引：它们是如何协同工作的？" class="headerlink" title="BM25、全文搜索与倒排索引：它们是如何协同工作的？"></a>BM25、全文搜索与倒排索引：它们是如何协同工作的？</h6><p><strong>这三者是构建搜索系统的关键组件：</strong></p>
<ul>
<li><p>全文搜索 (Full-Text Search)：这是我们希望达成的目标——在大量文本中找到包含特定信息的文档。</p>
</li>
<li><p>倒排索引 (Inverted Index)：这是实现高效全文搜索的数据结构基础。它像一本书末尾的详细“关键词索引”，记录了每个词出现在哪些文档中以及相关位置信息。当用户查询时，系统可以通过倒排索引快速定位到包含查询词的候选文档。</p>
</li>
<li>BM25：在通过倒排索引找到候选文档后，BM25算法登场，为每个文档计算一个相关性得分，然后按分排序，将最相关的结果呈现给用户。</li>
</ul>
<p><strong>把它们比作在图书馆找特定主题的书籍：</strong></p>
<ul>
<li>你告诉图书管理员你要找关于“天体物理学”的书（用户查询）。</li>
<li>管理员查阅一个总卡片索引（倒排索引），迅速告诉你哪些书架（文档ID）上有包含“天体物理学”这个词的书。</li>
<li>你走到这些书架，快速翻阅这些书（BM25评分过程），根据目录、摘要和提及“天体物理学”的频繁程度及重要性，判断哪几本最符合你的需求，并把它们按相关性高低排好。</li>
</ul>
<h4 id="Dense-Vector-kNN-向量语义检索"><a href="#Dense-Vector-kNN-向量语义检索" class="headerlink" title="Dense Vector / kNN 向量语义检索"></a>Dense Vector / kNN 向量语义检索</h4><p>向量语义检索（Dense Vector / k-Nearest Neighbor，简称 kNN）是一种<strong>基于高维稠密向量表示的语义检索技术</strong>，与传统关键词倒排索引不同，它通过<strong>自然语言的上下文含义</strong>而非字面匹配来寻找最相关的文档或实体。</p>
<ol>
<li><p><strong>Embedding</strong>：使用预训练语言模型（如 BERT、Sentence-Transformers）把文本映射为<strong>固定维度的稠密向量</strong>（通常 128–1024 维）。</p>
</li>
<li><p><strong>kNN 搜索</strong>：给定查询向量，<strong>在向量空间中找距离最近的 k 个文档向量</strong>。距离度量常见：</p>
<ul>
<li>余弦相似度（cosine）</li>
<li>内积 / dot-product</li>
<li>L2 欧氏距离</li>
</ul>
</li>
</ol>
<h4 id="Hybrid-Retrieval-混合检索"><a href="#Hybrid-Retrieval-混合检索" class="headerlink" title="Hybrid Retrieval 混合检索"></a>Hybrid Retrieval 混合检索</h4><p>既然不同的检索策略各有千秋（例如，BM25擅长关键词精确匹配，Embedding擅长语义理解），那么将它们结合起来，是不是能达到“1+1&gt;2”的效果呢？答案是肯定的，这就是混合检索的核心思想。</p>
<p>常见做法：同时使用BM25（或其他稀疏检索方法）和一种或多种Embedding检索方法，然后将它们各自的检索结果进行融合排序。</p>
<p>融合策略举例：</p>
<p>RRF (Reciprocal Rank Fusion, 倒数排序融合)：一种简单但鲁棒的融合方法。它不关心不同检索系统输出的原始得分，只关心每个文档在各自结果列表中的排名。一个文档 doc 的RRF得分计算如下：</p>
<script type="math/tex; mode=display">
Score_RRF(doc) = Σ_{s ∈ Systems} (1 / (k + rank_s(doc)))</script><p>其中：</p>
<ul>
<li>Systems 是所有参与融合的检索系统的集合。</li>
<li>rank_s(doc) 是文档 doc 在检索系统 s 给出的结果列表中的排名（例如，第一名是1，第二名是2）。</li>
<li>k 是一个小常数（例如，常设置为60），用于平滑得分，避免排名靠后的文档得分过小或排名第一的文档得分占比过高。</li>
</ul>
<h4 id="Reranker-重排序器"><a href="#Reranker-重排序器" class="headerlink" title="Reranker  重排序器"></a>Reranker  重排序器</h4><p>经过上述一种或多种检索策略的“粗筛”（召回阶段），我们通常会得到一个包含较多候选文档的列表（比如几百个）。为了进一步提升最终喂给LLM的文档质量，Reranker（重排序器）应运而生。它相当于一位“精炼师”或“质量品鉴官”，对初步召回的结果进行更细致、更精准的二次排序。</p>
<ol>
<li>召回<br>倒排 / 向量 / 混合先给 <strong>Top-N</strong>（N≈100~1 k）。</li>
<li>拼特征<br>把 <code>(query, doc)</code> 拼成一条输入：<br><code>[CLS] 用户问题 [SEP] 标题+正文 [SEP]</code>。</li>
<li>打分<br>扔给 Cross-Encoder 或 ColBERT → 输出<strong>一个相关性分数</strong>。</li>
<li>重排<br>按分数从高到低重新排序，只留 <strong>Top-K</strong>（K≈10~20）。</li>
<li>返回<br>重排后的短列表交给前端或 LLM，完成一次“精读”。</li>
</ol>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a href="https://blog.csdn.net/m0_59614665/article/details/149066780">大模型RAG | 深入了解几种主流的检索策略（BM25、Embedding、混合检索、Reranker）-CSDN博客</a></p>
<h3 id="项目关于elasticsearch代码阅读记录"><a href="#项目关于elasticsearch代码阅读记录" class="headerlink" title="项目关于elasticsearch代码阅读记录"></a>项目关于elasticsearch代码阅读记录</h3><p>阅读elasticsearch代码相关记录:</p>
<ol>
<li><strong>embedding_model</strong>.select_embeddings_model:根据指定的模型名称加载</li>
<li><strong>make_es_vector_store</strong>：<ol>
<li>docs_url = pd.read_excel(‘docs_new.xlsx’)，从excel加载url并进行数据处理，保存筛选后的ur</li>
<li>完成文件加载测试：xizhang/retrival/docfile_test/test.py；</li>
<li>初始化es，使用elastic_search.load_es_index加载存储索引</li>
<li>完成测试elasticsearch连接与索引构建（索引名zxj_test）：/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_es_connect.py，/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_add_es.py</li>
<li>顺序批量处理文件：共16000多份，每十份为一批进行处理，使用download_pdf.py进行文件下载，使用，使用vector_base.rewrite_file对文件进行处理，这里可以修改代码，增加对mineru处理pdf的markdown文件的处理，返回Document对象列表；</li>
</ol>
</li>
<li><strong>elastic_search</strong></li>
</ol>
<p>重写了检索策略的函数，包括BM25，KNN，混合搜索</p>
<ol>
<li><p>elastic_retriever创建Elasticsearch检索器：根据搜索类型选择对应的查询函数，创建Elasticsearch检索器ElasticsearchRetriever.from_es_params</p>
</li>
<li><p><strong>retrievers</strong></p>
<ol>
<li>定义函数select_retriever，根据指定的名称选择并返回相应的检索器，目前只有bm25</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>学习</tag>
        <tag>实习</tag>
        <tag>retrieval</tag>
        <tag>rag</tag>
      </tags>
  </entry>
  <entry>
    <title>chunk分块策略</title>
    <url>/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/</url>
    <content><![CDATA[<h3 id="分块策略"><a href="#分块策略" class="headerlink" title="分块策略"></a>分块策略</h3><p>以下是 RAG 应用程序的典型工作流程：</p>
<p><img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/6878b8fa-5e74-45a1-9a89-5aab92889126_2366x990.gif" alt="6878b8fa-5e74-45a1-9a89-5aab92889126_2366x990"></p>
<p>主流主要有五种分块策略：</p>
<p><img src="https___substack-post-media.s3.amazonaws.com_public_images_92c70184-ba0f-4877-9a55-e4add0e311ad_870x1116.gif" alt="https___substack-post-media.s3.amazonaws.com_public_images_92c70184-ba0f-4877-9a55-e4add0e311ad_870x1116"></p>
<h4 id="Fixed-size-chunking-固定大小的分块"><a href="#Fixed-size-chunking-固定大小的分块" class="headerlink" title="Fixed-size chunking 固定大小的分块"></a>Fixed-size chunking 固定大小的分块</h4><p><img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/98c422a0-f0e2-457c-a256-4476a56a601f_943x232.png" alt="98c422a0-f0e2-457c-a256-4476a56a601f_943x232"></p>
<p>将文本以固定长度分块，overlap为每个块的重合程度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">text = <span class="string">&quot;大家好，我是果粒奶优有果粒，欢迎关注我，让我们一起探索AI。&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> CharacterTextSplitter</span><br><span class="line"></span><br><span class="line">text_splitter = CharacterTextSplitter(</span><br><span class="line">    separator=<span class="string">&quot;&quot;</span>,<span class="comment">#按字切分</span></span><br><span class="line">    chunk_size=<span class="number">5</span>,</span><br><span class="line">    chunk_overlap=<span class="number">1</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span>,<span class="comment">#以长度计算</span></span><br><span class="line">    is_separator_regex=<span class="literal">False</span>,<span class="comment">#不视为正则表达式</span></span><br><span class="line">)</span><br><span class="line">text_splitter.split_text(text)</span><br></pre></td></tr></table></figure>
<h4 id="Semantic-chunking-语义分块"><a href="#Semantic-chunking-语义分块" class="headerlink" title="Semantic chunking 语义分块"></a>Semantic chunking 语义分块</h4><p><img src="https___substack-post-media.s3.amazonaws.com_public_images_a6ad83a6-2879-4c77-9e49-393f16577aef_1066x288.gif" alt="https___substack-post-media.s3.amazonaws.com_public_images_a6ad83a6-2879-4c77-9e49-393f16577aef_1066x288"></p>
<p>先将文本分段，然后为每个段进行嵌入，若两个段有较高的余弦相似度，则合并成一个块，一直合并到余弦相似度显著下降，再从新的块开始</p>
<p>需要设定阈值来确定余弦相似度是否显著下降，这因文档而异。</p>
<p><img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/image-20250710150106274.png" alt="image-20250710150106274"></p>
<p>具体实现思路：利用滑动窗口，从第一句往后移动滑动窗口，如图，emed1与emed2相差sen3，计算出来的distance决定sen3是否加入chunk1，以此类推</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#利用langchain调用</span></span><br><span class="line"><span class="keyword">from</span> langchain_experimental.text_splitter <span class="keyword">import</span> SemanticChunker</span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> DashScopeEmbeddings</span><br><span class="line">embeddings_model = DashScopeEmbeddings(</span><br><span class="line">        model=<span class="string">&quot;text-embedding-v2&quot;</span>,</span><br><span class="line">        dashscope_api_key=<span class="string">&quot;&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">semantic_chunk=SemanticChunker(</span><br><span class="line">    embeddings=embeddings_model,<span class="comment">#嵌入模型</span></span><br><span class="line">    breakpoint_threshold_type=<span class="string">&quot;percentile&quot;</span>,<span class="comment">#定义如何计算语义断点阈值</span></span><br><span class="line">    breakpoint_threshold_amount=<span class="number">95</span>,<span class="comment">#设定阈值</span></span><br><span class="line">    <span class="comment">#min_chunk_size=500#限制生成块最小的字符数，避免生成无意义的块</span></span><br><span class="line">    sentence_split_regex=<span class="string">r&#x27;[。！？.\n]&#x27;</span>,<span class="comment">#语句切分</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><a href="https://developer.aliyun.com/article/1664186">LangChain 搭配 QWen 踩坑-阿里云开发者社区</a></p>
<p>使用OpenAIEmbeddings配置embedding模型，需要设置一个关键参数</p>
<p><code>check_embedding_ctx_length = False</code> 的作用是：</p>
<blockquote>
<p><strong>关闭 langchain_openai 在调用嵌入模型前对输入文本长度的检查与自动截断/分段逻辑。</strong></p>
</blockquote>
<p>但 DashScope 的 <code>text-embedding-v4</code> 接口：</p>
<ul>
<li>对输入格式要求更严格（必须是字符串或字符串列表，不能是分段后的复杂结构）。</li>
<li>不接受 <code>langchain_openai</code> 默认生成的<strong>分段后的列表嵌套结构</strong>。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain_openai import OpenAIEmbeddings,  OpenAI</span><br><span class="line">embeddings = OpenAIEmbeddings(</span><br><span class="line">api_key=&quot;sk-&quot;, </span><br><span class="line">base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,</span><br><span class="line">model=&quot;text-embedding-v4&quot;,</span><br><span class="line">check_embedding_ctx_length = False,</span><br><span class="line">dimensions=1536</span><br><span class="line">)</span><br><span class="line">result=embeddings.embed_query(&quot;Hello, world!&quot;)</span><br><span class="line">print(len(result))</span><br></pre></td></tr></table></figure>
</blockquote>
<p>源代码理解见最后</p>
<h4 id="Recursive-chunking-递归分块"><a href="#Recursive-chunking-递归分块" class="headerlink" title="Recursive chunking 递归分块"></a>Recursive chunking 递归分块</h4><p><img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/f4009caa-34fc-48d6-8102-3d0f6f2c1386_1066x316.gif" alt="f4009caa-34fc-48d6-8102-3d0f6f2c1386_1066x316"></p>
<p>先依据大的段落进行分块，再对每个块进行处理，若符合chunk-size的限制，则不会再分</p>
<p>结果可能如下</p>
<p><img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/b0e40cc1-996f-48f4-9306-781b112536e4_984x428.png" alt="b0e40cc1-996f-48f4-9306-781b112536e4_984x428"></p>
<p>首先，我们定义两个块（紫色的两个段落。接下来，第1段进一步拆分为更小的块。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter</span><br><span class="line"></span><br><span class="line">recursive_splitter_chinese = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">50</span>,</span><br><span class="line">    chunk_overlap=<span class="number">10</span>,</span><br><span class="line">    length_function=<span class="built_in">len</span>,</span><br><span class="line">    separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;。&quot;</span>, <span class="string">&quot;，&quot;</span>, <span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>]<span class="comment">#中文的分隔符，可以用逗号句号</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="Document-structure-based-chunking-基于文档结构的分块"><a href="#Document-structure-based-chunking-基于文档结构的分块" class="headerlink" title="Document structure-based chunking 基于文档结构的分块"></a>Document structure-based chunking 基于文档结构的分块</h4><p><img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/e8febecd-ee68-42ff-ab06-41a0a3a43cd3_1102x306.gif" alt="e8febecd-ee68-42ff-ab06-41a0a3a43cd3_1102x306"></p>
<p>根据文档的固有结构进行分块，如markdown的一级标题二级标题等</p>
<p><code>langchain.text_splitter</code>中有两个用于md文档分块的类，<code>MarkdownTextSplitter</code>与<code>MarkdownHeaderTextSplitter</code></p>
<p>二者区别主要在：前者继承于<code>RecursiveCharacterTextSplitter</code>递归分块，它会尝试沿着 Markdown 格式的标题进行分割，但其核心仍然是基于字符的递归分割；后者专注于 基于 Markdown 标题的结构化分割 ，并能将标题信息作为元数据保留，更适合需要保持 Markdown 文档层级结构的应用场景。</p>
<p>需要注意的是<code>MarkdownHeaderTextSplitter</code> 本身不直接提供限制块内容长度的参数，但可以通过与 <code>RecursiveCharacterTextSplitter</code> 等其他文本分割器结合使用来有效控制块的大小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> MarkdownHeaderTextSplitter</span><br><span class="line">headers_to_split_on = [</span><br><span class="line">    (<span class="string">&quot;#&quot;</span>, <span class="string">&quot;Header 1&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;##&quot;</span>, <span class="string">&quot;Header 2&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;###&quot;</span>, <span class="string">&quot;Header 3&quot;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)</span><br><span class="line">md_header_splits = markdown_splitter.split_text(markdown_document)</span><br></pre></td></tr></table></figure>
<p>存储结构类似如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Document(metadata=&#123;&#x27;Header 1&#x27;: &#x27;Foo&#x27;, &#x27;Header 2&#x27;: &#x27;Bar&#x27;&#125;, page_content=&#x27;Hi this is Jim  \nHi this is Joe&#x27;),</span><br><span class="line"> Document(metadata=&#123;&#x27;Header 1&#x27;: &#x27;Foo&#x27;, &#x27;Header 2&#x27;: &#x27;Bar&#x27;, &#x27;Header 3&#x27;: &#x27;Boo&#x27;&#125;, page_content=&#x27;Hi this is Lance&#x27;),</span><br><span class="line"> Document(metadata=&#123;&#x27;Header 1&#x27;: &#x27;Foo&#x27;, &#x27;Header 2&#x27;: &#x27;Baz&#x27;&#125;, page_content=&#x27;Hi this is Molly&#x27;)]</span><br></pre></td></tr></table></figure>
<h4 id="LLM-based-chunking-基于-LLM-的分块"><a href="#LLM-based-chunking-基于-LLM-的分块" class="headerlink" title="LLM-based chunking 基于 LLM 的分块"></a>LLM-based chunking 基于 LLM 的分块</h4><p><img src="/2025/07/09/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/chunk%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5/4d1b6d60-8956-4030-8525-d899ee61a9d5_1140x198.gif" alt="4d1b6d60-8956-4030-8525-d899ee61a9d5_1140x198"></p>
<p>利用大模型进行分块</p>
<p>langchain没有提供官方的类实现LLM-based chunking</p>
<p>但是我在找到了别人实现的agentic_chunker<a href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/agentic_chunker.py">RetrievalTutorials/tutorials/LevelsOfTextSplitting/agentic_chunker.py at main · FullStackRetrieval-com/RetrievalTutorials</a>，可供参考</p>
<p>后记：agentic chunk大概的思路为先进行初步分段，按照长度或递归，然后让大模型生成这一段的概要，将段与段合并生成块，但是测试下来，一个文档的内容同质化很严重，基本上都分到一块里了，而且这个主要还是提示词工程，分块并不系统，看个乐吧</p>
<p><a href="https://github.com/zxj-2023/chunks-strategy-/blob/main/agentic_chunker.py">chunks-strategy-/agentic_chunker.py at main · zxj-2023/chunks-strategy-</a>代码稍作更新，弃用了部分库</p>
<h3 id="embedding"><a href="#embedding" class="headerlink" title="embedding"></a>embedding</h3><p>之前对chunking和embedding的理解不够清晰，chunking是对文本进行分块，由于大多数文本嵌入模型对输入文本长度有严格限制，如果不分块则无法embedding，从而无法更好的进行向量化或者更好地储存在知识库中，提升retriever性能；embedding则是将文本映射到向量空间，为了更好的相似度计算</p>
<h3 id="语义分块的源代码实战"><a href="#语义分块的源代码实战" class="headerlink" title="语义分块的源代码实战"></a>语义分块的源代码实战</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">将文本划分成单句，可以按照标点符号划分</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">single_sentences_list = re.split(<span class="string">r&#x27;(?&lt;=[。！？])&#x27;</span>, essay)</span><br><span class="line"><span class="comment"># 移除可能存在的空字符串</span></span><br><span class="line">single_sentences_list = [s.strip() <span class="keyword">for</span> s <span class="keyword">in</span> single_sentences_list <span class="keyword">if</span> s.strip()]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">我们需要为单个句子拼接更多的句子，但是 `list` 添加比较困难。因此将其转换为字典列（`List[dict]`）</span></span><br><span class="line"><span class="string">&#123; &#x27;sentence&#x27; : XXX  , &#x27;index&#x27; : 0&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">sentences = [&#123;<span class="string">&#x27;sentence&#x27;</span>: x, <span class="string">&#x27;index&#x27;</span> : i&#125; <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(single_sentences_list)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用滑动窗口分段</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">combine_sentences</span>(<span class="params">sentences, buffer_size=<span class="number">1</span></span>):</span><br><span class="line">    combined_sentences = [</span><br><span class="line">        <span class="string">&#x27; &#x27;</span>.join(sentences[j][<span class="string">&#x27;sentence&#x27;</span>] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">max</span>(i - buffer_size, <span class="number">0</span>), <span class="built_in">min</span>(i + buffer_size + <span class="number">1</span>, <span class="built_in">len</span>(sentences))))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences))</span><br><span class="line">    ]   </span><br><span class="line">    <span class="comment"># 更新原始字典列表，添加组合后的句子</span></span><br><span class="line">    <span class="keyword">for</span> i, combined_sentence <span class="keyword">in</span> <span class="built_in">enumerate</span>(combined_sentences):</span><br><span class="line">        sentences[i][<span class="string">&#x27;combined_sentence&#x27;</span>] = combined_sentence</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sentences</span><br><span class="line"></span><br><span class="line">sentences = combine_sentences(sentences)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">接下来使用**embedding model**对**sentences** 进行编码</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> DashScopeEmbeddings</span><br><span class="line">embeddings_model = DashScopeEmbeddings(</span><br><span class="line">        model=<span class="string">&quot;text-embedding-v2&quot;</span>,</span><br><span class="line">        dashscope_api_key=<span class="string">&quot;&quot;</span>,</span><br><span class="line"></span><br><span class="line">    )</span><br><span class="line"><span class="comment"># 提取所有组合后的句子用于 embedding</span></span><br><span class="line">combined_sentences_to_embed = [x[<span class="string">&#x27;combined_sentence&#x27;</span>] <span class="keyword">for</span> x <span class="keyword">in</span> sentences]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对句子进行 embedding</span></span><br><span class="line">embeddings = embeddings_model.embed_documents(combined_sentences_to_embed)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;成功对 <span class="subst">&#123;<span class="built_in">len</span>(embeddings)&#125;</span> 个句子进行了 embedding。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#将embedding添加到sentence中</span></span><br><span class="line"><span class="keyword">for</span> i, sentence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentences):</span><br><span class="line">    sentence[<span class="string">&#x27;combined_sentence_embedding&#x27;</span>] = embeddings[i]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">接下来需要根据余弦相似度进行切分</span></span><br><span class="line"><span class="string">通过计算两个向量的夹角余弦值来衡量相似性</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cosine_similarity</span>(<span class="params">vec1, vec2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Calculate the cosine similarity between two vectors.&quot;&quot;&quot;</span></span><br><span class="line">    dot_product = np.dot(vec1, vec2)</span><br><span class="line">    norm_vec1 = np.linalg.norm(vec1)</span><br><span class="line">    norm_vec2 = np.linalg.norm(vec2)</span><br><span class="line">    <span class="keyword">return</span> dot_product / (norm_vec1 * norm_vec2)</span><br><span class="line"><span class="comment">#遍历，计算余弦相似度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_cosine_distances</span>(<span class="params">sentences</span>):</span><br><span class="line">    distances = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences) - <span class="number">1</span>):</span><br><span class="line">        embedding_current = sentences[i][<span class="string">&#x27;combined_sentence_embedding&#x27;</span>]</span><br><span class="line">        embedding_next = sentences[i + <span class="number">1</span>][<span class="string">&#x27;combined_sentence_embedding&#x27;</span>]</span><br><span class="line">        <span class="comment"># Calculate cosine similarity</span></span><br><span class="line">        similarity = cosine_similarity(embedding_current, embedding_next)</span><br><span class="line">        <span class="comment"># Convert to cosine distance</span></span><br><span class="line">        distance = <span class="number">1</span> - similarity</span><br><span class="line">        distances.append(distance)</span><br><span class="line">        <span class="comment"># Store distance in the dictionary</span></span><br><span class="line">        sentences[i][<span class="string">&#x27;distance_to_next&#x27;</span>] = distance</span><br><span class="line">    <span class="keyword">return</span> distances, sentences</span><br><span class="line"></span><br><span class="line">distances, sentences = calculate_cosine_distances(sentences)</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据阈值划分</span></span><br><span class="line">breakpoint_percentile_threshold = <span class="number">95</span></span><br><span class="line">breakpoint_distance_threshold = np.percentile(distances, breakpoint_percentile_threshold)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;距离的第95个百分位阈值是:&quot;</span>, breakpoint_distance_threshold)</span><br><span class="line"><span class="comment"># 找到所有距离大于阈值的点的索引，这些索引就是我们的切分点</span></span><br><span class="line">indices_above_thresh = [i <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(distances) <span class="keyword">if</span> x &gt; breakpoint_distance_threshold]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化块的起始句子索引。我们将根据之前计算出的语义分割点（`indices_above_thresh`）来切分句子列表。</span></span><br><span class="line">start_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个列表，用于存储最终组合成的、具有语义连贯性的文本块。</span></span><br><span class="line">chunks = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有识别出的语义分割点（这些是句子列表 `sentences` 中的索引）。</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> indices_above_thresh:</span><br><span class="line">    <span class="comment"># 确定当前文本块的结束点，即当前的分割点索引。</span></span><br><span class="line">    end_index = index</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从原始句子列表（`sentences`）中切片，提取从上一个分割点到当前分割点之间的所有句子。</span></span><br><span class="line">    <span class="comment"># `end_index + 1` 是为了在切片时包含结束索引指向的那个句子。</span></span><br><span class="line">    group = sentences[start_index:end_index + <span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将切分出的句子组（`group`）中的所有 &#x27;sentence&#x27; 字段的值合并成一个单独的字符串，句子之间用空格隔开。</span></span><br><span class="line">    combined_text = <span class="string">&#x27; &#x27;</span>.join([d[<span class="string">&#x27;sentence&#x27;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> group])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将合并后的文本块添加到 `chunks` 列表中。</span></span><br><span class="line">    chunks.append(combined_text)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新下一个文本块的起始索引，设置为当前分割点的下一个位置，为处理下一个块做准备。</span></span><br><span class="line">    start_index = index + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理最后一个文本块。</span></span><br><span class="line"><span class="comment"># 循环结束后，如果 `start_index` 仍然小于句子总数，说明从最后一个分割点到文本末尾还有剩余的句子。</span></span><br><span class="line"><span class="keyword">if</span> start_index &lt; <span class="built_in">len</span>(sentences):</span><br><span class="line">    <span class="comment"># 将这些剩余的句子合并成最后一个文本块。</span></span><br><span class="line">    combined_text = <span class="string">&#x27; &#x27;</span>.join([d[<span class="string">&#x27;sentence&#x27;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> sentences[start_index:]])</span><br><span class="line">    chunks.append(combined_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时，`chunks` 列表包含了所有根据语义距离切分和重组后的文本块。</span></span><br><span class="line"><span class="keyword">for</span> i, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(chunks):</span><br><span class="line">    buffer = <span class="number">200</span></span><br><span class="line">    <span class="built_in">print</span> (<span class="string">f&quot;Chunk #<span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span> (chunk[:buffer].strip())</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;...&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span> (chunk[-buffer:].strip())</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.dailydoseofds.com/p/5-chunking-strategies-for-rag/">RAG 的 5 种分块策略 —- 5 Chunking Strategies For RAG</a></p>
<p><a href="https://blog.csdn.net/wjinjie/article/details/148660229">一文读懂 Qwen3 最新开源的 Embedding 和 Rerank 模型优势！_qwen-rerank-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1dr421x7Su/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">一站帮你选择RAG中的文本切分策略_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/The_Thieves/article/details/148747334">LangChain 语义文本拆分指南：基于语义相似度的智能分块技术实战_langchain 语义分割-CSDN博客</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>学习</tag>
        <tag>实习</tag>
        <tag>rag</tag>
        <tag>chunk</tag>
      </tags>
  </entry>
  <entry>
    <title>docker</title>
    <url>/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/</url>
    <content><![CDATA[<h2 id="镜像（Image）"><a href="#镜像（Image）" class="headerlink" title="镜像（Image）"></a>镜像（Image）</h2><p>镜像可以被看作是一个轻量级、可执行的独立软件包，包含了运行某个应用所需的所有代码、库、环境变量和配置文件。它是容器的<strong>静态模板</strong>，在创建容器时用作基础。</p>
<p><strong>只读</strong>：镜像本身是只读的，无法修改。</p>
<p><strong>可重用</strong>：镜像是可以多次重用的，你可以基于相同的镜像创建多个容器。</p>
<h2 id="容器（Container）"><a href="#容器（Container）" class="headerlink" title="容器（Container）"></a>容器（Container）</h2><p>与虚拟机通过操作系统实现隔离不同，容器技术<strong>只隔离应用程序的运行时环境但容器之间可以共享同一个操作系统</strong>，这里的运行时环境指的是程序运行依赖的各种库以及配置。</p>
<p>容器更加的<strong>轻量级且占用的资源更少</strong>，与操作系统动辄几G的内存占用相比，容器技术只需数M空间，因此我们可以在同样规格的硬件上<strong>大量部署容器</strong>，这是虚拟机所不能比拟的，而且不同于操作系统数分钟的启动时间容器几乎瞬时启动，容器技术为<strong>打包服务栈</strong>提供了一种更加高效的方式</p>
<h2 id="镜像与容器的关系"><a href="#镜像与容器的关系" class="headerlink" title="镜像与容器的关系"></a>镜像与容器的关系</h2><p><strong>镜像是静态的</strong>：它只包含应用和运行环境，不能进行任何运行时的操作。你可以把它看作是软件的<strong>安装包</strong>。</p>
<p><strong>容器是动态的</strong>：它是在镜像的基础上创建的，可以运行、执行代码、修改文件系统等。你可以把它看作是镜像的<strong>运行实例</strong>。</p>
<h2 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h2><p>docker将程序以及程序所有的依赖都打包到<a href="https://zhida.zhihu.com/search?content_id=129800958&amp;content_type=Article&amp;match_order=1&amp;q=docker+container&amp;zhida_source=entity">docker container</a>，这样你的程序可以在任何环境都会有一致的表现</p>
<p>此外docker的另一个好处就是<strong>快速部署</strong>，这是当前互联网公司最常见的一个应用场景，一个原因在于容器启动速度非常快，另一个原因在于只要确保一个容器中的程序正确运行，那么你就能确信无论在生产环境部署多少都能正确运行。</p>
<p>每一种容器都是一个完整的运行环境，容器之间互相隔离。</p>
<p>简单来说，docker将程序打包部署，方便了软件的部署，避免了环境冲突等问题</p>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p>查看所有容器（包括停止的容器）：<code>docker ps -a</code></p>
<p>在Docker中运行容器：<code>docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</code></p>
<ul>
<li>• <code>[OPTIONS]</code>：可选参数，用于配置容器的各种选项，如端口映射、容器名称等。</li>
<li>• <code>IMAGE</code>：要运行的镜像名称或ID。</li>
<li>• <code>[COMMAND] [ARG...]</code>：可选的命令和参数，用于在容器内执行特定的命令。</li>
</ul>
<p>停止正在运行的容器：<code>docker stop [OPTIONS] CONTAINER [CONTAINER...]</code></p>
<p>启动已停止的容器：<code>docker start [OPTIONS] CONTAINER [CONTAINER...]</code></p>
<p>删除已停止的容器或镜像：<code>docker rm [OPTIONS] CONTAINER [CONTAINER...]   docker rmi [OPTIONS] IMAGE [IMAGE...]</code></p>
<ul>
<li>• <code>docker rm</code>：删除容器的命令。</li>
<li>• <code>docker rmi</code>：删除镜像的命令。</li>
</ul>
<p>从Docker仓库中拉取现有的镜像：<code>docker pull [OPTIONS] NAME[:TAG|@DIGEST]</code></p>
<ul>
<li>• <code>docker pull</code>：拉取镜像的命令。</li>
<li>• <code>[OPTIONS]</code>：可选参数，用于配置拉取过程，如认证信息等。</li>
<li>• <code>NAME[:TAG|@DIGEST]</code>：要拉取的镜像名称、标签或摘要。</li>
</ul>
<h2 id="docker部分指令"><a href="#docker部分指令" class="headerlink" title="docker部分指令"></a>docker部分指令</h2><p><strong>linux安装docker</strong>：<code>sudo apt-get update &amp;&amp; sudo apt-get install docker.io</code></p>
<p><strong>查看 Docker 版本信息</strong>：<code>docker version</code></p>
<p><strong>查看镜像</strong>：<code>docker images</code></p>
<p><strong>查看所有的容器</strong>：<code>docker ps -a</code> </p>
<blockquote>
<p><code>systemctl</code> 是 <strong>systemd</strong> 系统和服务管理器的核心工具，用于管理系统和服务的状态及配置。</p>
</blockquote>
<p><code>mysql-client</code> 是 MySQL 数据库的命令行客户端工具。它允许你通过命令行连接和操作 MySQL 数据库服务器，比如执行 SQL 查询、管理数据库和用户等。</p>
<p>常用命令格式如下：<code>mysql -h 主机地址 -P 端口号 -u 用户名 -p</code></p>
<p>你可以在终端输入以下命令来检查是否已安装 <code>mysql-client</code>：<code>mysql --version</code></p>
<p>可以使用以下命令安装：<code>sudo apt-get update  sudo apt-get install mysql-client</code></p>
<blockquote>
<p><code>sudo apt-get update</code> 这个命令的作用是<strong>更新本地软件包列表</strong>。</p>
</blockquote>
<p><strong>停止并删除容器</strong>：<code>docker stop fastapi  docker rm fastapi</code></p>
<p><strong>Linux修改镜像源</strong>：<a href="https://blog.csdn.net/couragehope/article/details/137777158">如何查看docker配置的镜像仓库_查看docker镜像地址-CSDN博客</a></p>
<h2 id="常见参数"><a href="#常见参数" class="headerlink" title="常见参数"></a>常见参数</h2><p>基础参数：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><code>-d</code>或<code>--detach</code></th>
<th>后台运行容器（detached mode）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--name &lt;name&gt;</code></td>
<td>为容器指定名称（如<code>--name my_container</code>）</td>
</tr>
<tr>
<td><code>--rm</code></td>
<td>容器停止后自动删除（适用于临时容器）</td>
</tr>
</tbody>
</table>
</div>
<p>端口映射：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><code>-p &lt;主机端口&gt;:&lt;容器端口&gt;</code></th>
<th>映射主机端口到容器端口（如<code>-p 80:80</code>）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-p &lt;主机IP&gt;:&lt;主机端口&gt;:&lt;容器端口&gt;</code></td>
<td>指定主机IP绑定（如<code>-p 127.0.0.1:8080:80</code>）</td>
</tr>
<tr>
<td><code>-P</code>或<code>--publish-all</code></td>
<td>自动映射所有暴露的端口（随机分配主机端口）</td>
</tr>
</tbody>
</table>
</div>
<p>卷挂载：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><code>-v &lt;主机路径&gt;:&lt;容器路径&gt;</code></th>
<th>挂载主机目录到容器（如<code>-v //app</code>）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-v &lt;卷名&gt;:&lt;容器路径&gt;</code></td>
<td>使用命名卷（如<code>-v my_volume:/data</code>）</td>
</tr>
</tbody>
</table>
</div>
<p>环境变量：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><code>-e &lt;KEY=VALUE&gt;</code></th>
<th>设置环境变量（如<code>-e DEBUG=true</code>）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--env-file &lt;文件名&gt;</code></td>
<td>从文件加载环境变量（每行<code>KEY=VALUE</code>）</td>
</tr>
</tbody>
</table>
</div>
<p>网络配置：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><code>--network &lt;网络名&gt;</code></th>
<th>指定容器使用的网络（如<code>--network bridge</code>或自定义网络）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--network host</code></td>
<td>使用主机网络（共享主机网络命名空间）</td>
</tr>
</tbody>
</table>
</div>
<h2 id="拯救被wsl占用的内存"><a href="#拯救被wsl占用的内存" class="headerlink" title="拯救被wsl占用的内存"></a>拯救被wsl占用的内存</h2><p>以笔者的情况来说，我的wsl中只有一些必备的开发环境，项目源代码 和 docker。前两者显然没啥可操作的空间，所以只有一个靶子 —— docker。</p>
<p>首先，我们可以进入wsl，通过以下命令，看看 Docker 的磁盘使用情况和资源总量。</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">docker system df </span><br></pre></td></tr></table></figure>
<p>大家都知道，docker运行一段时间后，可能会产生一些无用的镜像文件。要清理无用的 Docker 镜像，则可以运行以下命令：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">docker image prune </span><br></pre></td></tr></table></figure>
<p>该命令可以删除所有未被任何容器使用的镜像。如果想清理所有已停止的容器和未使用的镜像：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">docker system prune -a</span><br></pre></td></tr></table></figure>
<p>执行完后咱们可以再运行第一个命令查看磁盘使用情况，大概率能看到释放了一部分磁盘空间。如果确实长时间为清理过，很大可能可释放几十G。</p>
<p>然而这时候我们退出wsl回到win10, 你可能会看到磁盘空间几乎没啥变化。这是因为wsl还需要我们手动释放这部分空间，即压缩磁盘。</p>
<h2 id="修改docker存储镜像位置"><a href="#修改docker存储镜像位置" class="headerlink" title="修改docker存储镜像位置"></a>修改docker存储镜像位置</h2><p>windows</p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250709095041821.png" alt="image-20250709095041821"></p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250709092539404.png" alt="image-20250709092539404"></p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250709092605183.png" alt="image-20250709092605183"></p>
<p>Linux</p>
<p><a href="https://blog.csdn.net/weixin_43412762/article/details/134571411">修改Docker默认镜像和容器存储位置（超详细！！！）_docker更改存储位置-CSDN博客</a></p>
<h2 id="修改镜像源"><a href="#修改镜像源" class="headerlink" title="修改镜像源"></a>修改镜像源</h2><p>查看可用的镜像源<a href="https://tools.opsnote.top/registry-mirrors/">DockerHub加速器可用性监控</a></p>
<h3 id="如何使用vscode进入远程服务器的docker容器内部调试代码"><a href="#如何使用vscode进入远程服务器的docker容器内部调试代码" class="headerlink" title="如何使用vscode进入远程服务器的docker容器内部调试代码"></a>如何使用vscode进入远程服务器的docker容器内部调试代码</h3><p>安装一下插件</p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/9a3be11a07b5a0866d09d1bcbbaae4dc.png" alt="9a3be11a07b5a0866d09d1bcbbaae4dc"></p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/docker/image-20250716165555700.png" alt="image-20250716165555700"></p>
<h2 id="build，pull与run"><a href="#build，pull与run" class="headerlink" title="build，pull与run"></a>build，pull与run</h2><p><strong><code>docker build</code>：从源代码构建镜像</strong></p>
<ul>
<li><strong>作用</strong>：根据你提供的 <code>Dockerfile</code>（一个包含构建镜像所需指令的文本文件）以及上下文（通常是包含 <code>Dockerfile</code> 的目录及其子目录），<strong>创建</strong>一个新的 Docker 镜像。</li>
</ul>
<p><strong><code>docker pull</code>：从注册中心下载镜像</strong></p>
<ul>
<li><strong>作用</strong>：从 Docker 注册中心（默认是 Docker Hub，也可以是私有注册中心如 Harbor, GitLab Registry, AWS ECR 等）<strong>下载</strong>一个已经构建好的 Docker 镜像到你的本地机器。</li>
</ul>
<p><strong><code>docker run</code>：创建并启动容器</strong></p>
<ul>
<li><strong>作用</strong>：基于一个<strong>本地已有的镜像</strong>（无论这个镜像是你刚 <code>build</code> 出来的，还是 <code>pull</code> 下来的，或是之前就存在的），<strong>创建</strong>一个新的容器实例，并按照指定的命令（或镜像默认的命令）<strong>启动</strong>它。</li>
</ul>
<h2 id="docker的自定义网络"><a href="#docker的自定义网络" class="headerlink" title="docker的自定义网络"></a>docker的自定义网络</h2><p>创建自定义桥接网络</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker network create mynet</span><br></pre></td></tr></table></figure>
<p>启动服务容器（不映射宿主机端口也能被同网络容器访问）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name api --network demo-net fastapi-svc</span><br></pre></td></tr></table></figure>
<p>列出所有网络（包括自定义网络）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker network ls</span><br><span class="line"></span><br><span class="line">#只列出自定义网络（过滤掉默认网络）</span><br><span class="line">docker network ls --filter type=custom</span><br></pre></td></tr></table></figure>
<p>查看某个自定义网络的详细信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker network inspect network_test </span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.bilibili.com/video/BV1ai421S7zj/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">改变软件行业的技术！程序员、软件爱好者必须掌握的Docker，到底是什么？_哔哩哔哩_bilibili</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/187505981">什么是Docker？看这一篇干货文章就够了！ - 知乎</a></p>
<p><a href="https://blog.csdn.net/Python_0011/article/details/140313812">Docker常用命令大全（非常详细）零基础入门到精通，收藏这一篇就够了-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1THKyzBER6/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">40分钟的Docker实战攻略，一期视频精通Docker_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Libreoffice</title>
    <url>/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/</url>
    <content><![CDATA[<h3 id="libreoffice部署"><a href="#libreoffice部署" class="headerlink" title="libreoffice部署"></a>libreoffice部署</h3><h4 id="查看Linux发行版"><a href="#查看Linux发行版" class="headerlink" title="查看Linux发行版"></a>查看Linux发行版</h4><p><img src="/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/libreoffice/image-20250718095931232.png" alt="image-20250718095931232"></p>
<p>系统是 <strong>银河麒麟高级服务器操作系统 V10（Kylin Linux Advanced Server V10）</strong>，属于 <strong>中国国产、兼容 CentOS/RHEL 生态</strong> 的 Linux 发行版。</p>
<p>因此它使用 <strong>RPM 包管理</strong>（<code>dnf</code>/<code>yum</code>），而不是 <code>.deb</code>。</p>
<h4 id="查看CPU-处理器架构"><a href="#查看CPU-处理器架构" class="headerlink" title="查看CPU 处理器架构"></a>查看<strong>CPU 处理器架构</strong></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uname -m</span><br></pre></td></tr></table></figure>
<p>是<strong>x86_64</strong></p>
<h4 id="不用部署了，镜像里有，直接用了"><a href="#不用部署了，镜像里有，直接用了" class="headerlink" title="不用部署了，镜像里有，直接用了"></a>不用部署了，镜像里有，直接用了</h4><h4 id="使用libreoffice处理doc文件，转成pdf"><a href="#使用libreoffice处理doc文件，转成pdf" class="headerlink" title="使用libreoffice处理doc文件，转成pdf"></a>使用libreoffice处理doc文件，转成pdf</h4><p>将当前目录下所有 <code>.doc</code> 和 <code>.docx</code> 转为 PDF：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">libreoffice --headless --convert-to pdf *.doc *.docx --outdir ./pdf_output/</span><br><span class="line"></span><br><span class="line"># 检查是否有残留进程</span><br><span class="line">ps aux | grep libreoffice</span><br><span class="line"></span><br><span class="line"># 如果有残留进程，杀死它们</span><br><span class="line">killall soffice.bin 2&gt;/dev/null</span><br></pre></td></tr></table></figure>
<h4 id="python"><a href="#python" class="headerlink" title="python"></a>python</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import os</span><br><span class="line">import subprocess</span><br><span class="line">import argparse</span><br><span class="line">import glob</span><br><span class="line">from pathlib import Path</span><br><span class="line">def batch_convert_documents(input_path, output_dir):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    批量转换文档的函数版本</span><br><span class="line">    </span><br><span class="line">    Args:</span><br><span class="line">        input_path (str): 输入路径（文件、目录或通配符）</span><br><span class="line">        output_dir (str): 输出目录</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">        bool: 转换是否成功</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # 确保输出目录存在</span><br><span class="line">    Path(output_dir).mkdir(parents=True, exist_ok=True)</span><br><span class="line">    </span><br><span class="line">    # 收集所有要转换的文件</span><br><span class="line">    files_to_convert = []</span><br><span class="line">    </span><br><span class="line">    if os.path.isfile(input_path):</span><br><span class="line">        # 单个文件</span><br><span class="line">        if input_path.lower().endswith((&#x27;.doc&#x27;, &#x27;.docx&#x27;)):</span><br><span class="line">            files_to_convert.append(input_path)</span><br><span class="line">    elif os.path.isdir(input_path):</span><br><span class="line">        # 目录中的所有doc/docx文件</span><br><span class="line">        for pattern in [&#x27;*.doc&#x27;, &#x27;*.docx&#x27;]:</span><br><span class="line">            files_to_convert.extend(glob.glob(os.path.join(input_path, pattern)))</span><br><span class="line">    else:</span><br><span class="line">        # 通配符模式</span><br><span class="line">        files_to_convert = glob.glob(input_path)</span><br><span class="line">        # 过滤出doc和docx文件</span><br><span class="line">        files_to_convert = [f for f in files_to_convert if f.lower().endswith((&#x27;.doc&#x27;, &#x27;.docx&#x27;))]</span><br><span class="line">    </span><br><span class="line">    if not files_to_convert:</span><br><span class="line">        print(&quot;未找到要转换的文档文件&quot;)</span><br><span class="line">        return False</span><br><span class="line">    </span><br><span class="line">    print(f&quot;找到 &#123;len(files_to_convert)&#125; 个文件需要转换&quot;)</span><br><span class="line">    </span><br><span class="line">    # 构建命令</span><br><span class="line">    cmd = [</span><br><span class="line">        &#x27;libreoffice&#x27;,</span><br><span class="line">        &#x27;--headless&#x27;,</span><br><span class="line">        &#x27;--convert-to&#x27;, &#x27;pdf&#x27;,</span><br><span class="line">        &#x27;--outdir&#x27;, output_dir</span><br><span class="line">    ] + files_to_convert</span><br><span class="line">    </span><br><span class="line">    try:</span><br><span class="line">        print(&quot;正在转换文件...&quot;)</span><br><span class="line">        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)</span><br><span class="line">        </span><br><span class="line">        if result.returncode == 0:</span><br><span class="line">            print(f&quot;成功转换 &#123;len(files_to_convert)&#125; 个文件&quot;)</span><br><span class="line">            return True</span><br><span class="line">        else:</span><br><span class="line">            print(f&quot;转换失败: &#123;result.stderr&#125;&quot;)</span><br><span class="line">            return False</span><br><span class="line">            </span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;转换过程中发生错误: &#123;e&#125;&quot;)</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    success = batch_convert_documents(&quot;./docs&quot;, &quot;./pdf_output&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="Linux扫盲"><a href="#Linux扫盲" class="headerlink" title="Linux扫盲"></a>Linux扫盲</h3><h4 id="发行版"><a href="#发行版" class="headerlink" title="发行版"></a>发行版</h4><p>像Ubuntu，CentOS都属于Linux的发行版，就像Windows11属于Windows的关系</p>
<p>常见发行版分类：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>系列</th>
<th>代表发行版</th>
<th>包格式</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Debian 系</strong></td>
<td>Debian、Ubuntu、Kali、Linux Mint</td>
<td><code>.deb</code></td>
<td>包多、社区大、教程多</td>
</tr>
<tr>
<td><strong>Red Hat 系</strong></td>
<td>CentOS、RHEL、Rocky、Alma、Fedora</td>
<td><code>.rpm</code></td>
<td>企业级稳定、官方支持长</td>
</tr>
<tr>
<td><strong>SUSE 系</strong></td>
<td>openSUSE Leap / Tumbleweed</td>
<td><code>.rpm</code></td>
<td>YaST 管理工具、欧洲流行</td>
</tr>
<tr>
<td><strong>Arch 系</strong></td>
<td>Arch Linux、Manjaro</td>
<td><code>.pkg.tar.zst</code></td>
<td>滚动更新、极客向</td>
</tr>
<tr>
<td><strong>轻量/最小</strong></td>
<td>Alpine、Debian netinst、CentOS Stream Minimal</td>
<td>任意</td>
<td>镜像小、资源占用低</td>
</tr>
</tbody>
</table>
</div>
<p>如何查看Linux发行版</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat /etc/os-release</span><br></pre></td></tr></table></figure>
<h4 id="deb和rpm"><a href="#deb和rpm" class="headerlink" title="deb和rpm"></a>deb和rpm</h4><p> <code>.deb</code> 和 <code>.rpm</code> 想象成 <strong>“Linux 世界里的安装程序”</strong>，就像 Windows 的 <code>.exe</code> / <code>.msi</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>格式</th>
<th>适用系统</th>
<th>安装命令</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>.deb</code></strong></td>
<td>Debian、Ubuntu、Linux Mint、Kali 等</td>
<td><code>sudo dpkg -i xxx.deb</code> 或 <code>sudo apt install ./xxx.deb</code></td>
</tr>
<tr>
<td><strong><code>.rpm</code></strong></td>
<td>CentOS、RHEL、Fedora、openSUSE、Rocky、Alma 等</td>
<td><code>sudo rpm -ivh xxx.rpm</code> 或 <code>sudo dnf/yum install xxx.rpm</code></td>
</tr>
</tbody>
</table>
</div>
<h4 id="cpu处理器架构"><a href="#cpu处理器架构" class="headerlink" title="cpu处理器架构"></a>cpu处理器架构</h4><div class="table-container">
<table>
<thead>
<tr>
<th>目录名</th>
<th>代表架构</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>x86_64</strong></td>
<td><strong>Intel/AMD 64 位</strong></td>
<td>绝大多数台式机、服务器（如 Xeon、EPYC、Core、Ryzen）</td>
</tr>
<tr>
<td><strong>aarch64</strong></td>
<td><strong>ARM 64 位</strong></td>
<td>树莓派 4/5、苹果 M 系列（Asahi Linux）、鲲鹏、飞腾、Ampere ARM 服务器等</td>
</tr>
</tbody>
</table>
</div>
<p>查看处理器架构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uname -m</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
        <tag>Linux</tag>
        <tag>Libreoffice</tag>
      </tags>
  </entry>
  <entry>
    <title>MinerU</title>
    <url>/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/</url>
    <content><![CDATA[<h3 id="docker部署"><a href="#docker部署" class="headerlink" title="docker部署"></a>docker部署</h3><p>使用dockerfile构建镜像：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU@master/docker/china/Dockerfile</span><br><span class="line">docker build -t mineru-sglang:latest -f Dockerfile .</span><br></pre></td></tr></table></figure>
<p>使用<code>wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU @master/docker/china/Dockerfile -O Dockerfile</code>将指定的 Dockerfile 下载到本地</p>
<p>Dockerfile：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用官方的 sglang 镜像作为基础镜像</span><br><span class="line">FROM lmsysorg/sglang:v0.4.9-cu126</span><br><span class="line"></span><br><span class="line"># 安装 OpenCV 依赖库</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y libgl1 &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line"># 安装 mineru Python 包</span><br><span class="line">RUN python3 -m pip install -U &#x27;mineru[core]&#x27; -i https://mirrors.aliyun.com/pypi/simple --break-system-packages</span><br><span class="line"></span><br><span class="line"># 下载模型并配置</span><br><span class="line">RUN /bin/bash -c &quot;mineru-models-download -s modelscope -m all&quot;</span><br><span class="line"></span><br><span class="line"># 设置容器入口命令</span><br><span class="line">ENTRYPOINT [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;export MINERU_MODEL_SOURCE=local &amp;&amp; exec \&quot;$@\&quot;&quot;, &quot;--&quot;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>SGLang（全称可能为 <strong>Serving Large Language Models with Golang</strong> ）是由斯坦福大学研究团队开发的一个<strong>高效的大语言模型（LLM）推理服务框架</strong> ，旨在通过优化模型推理过程，显著提升生成式AI服务的吞吐量和响应速度。</p>
<ul>
<li><strong>SGlang 版本</strong> ：<code>v0.4.8.post1</code>（SGlang 是一个用于大语言模型（LLM）推理和服务的高性能框架）。</li>
<li><strong>CUDA 版本</strong> ：<code>cu126</code> 表示使用 <strong>CUDA 12.6</strong> ，适用于 <strong>Turing/Ampere/Ada Lovelace/Hopper 架构的 GPU</strong> （如 RTX 30/40 系列、A100、H100）。</li>
</ul>
</blockquote>
<h4 id="报错排查"><a href="#报错排查" class="headerlink" title="报错排查"></a>报错排查</h4><p>之前由于默认dockerfile内容为<code>FROM lmsysorg/sglang:v0.4.8.post1-cu126</code>报错</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lmsysorg/sglang:v0.4.8.post1-cu126: failed to resolve source metadata for docker.io/lmsysorg/sglang:v0.4.8.post1-cu126: unexpected status from HEAD request to https://yaj2teeh.mirror.aliyuncs.com/v2/lmsysorg/sglang/manifests/v0.4.8.post1-cu126?ns=docker.io: 403 Forbidden</span><br></pre></td></tr></table></figure>
<p>之前以为是sglang版本问题，然后去dockerhub上查找，并通过<code>docker pull sglang:v0.4.8.post1-cu126</code>测试，是可以拉取的，最后认为原因还是网络问题</p>
<p>解决方法，更换了镜像源</p>
<h4 id="镜像源配置"><a href="#镜像源配置" class="headerlink" title="镜像源配置"></a>镜像源配置</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;registry-mirrors&quot;: [</span><br><span class="line">  &quot;https://registry.docker-cn.com&quot;,</span><br><span class="line">  &quot;http://hub-mirror.c.163.com&quot;,</span><br><span class="line">  &quot;https://dockerhub.azk8s.cn&quot;,</span><br><span class="line">  &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class="line">  &quot;https://registry.cn-hangzhou.aliyuncs.com&quot;,</span><br><span class="line">  &quot;https://docker.mirrors.ustc.edu.cn&quot;,</span><br><span class="line">  &quot;https://docker.m.daocloud.io&quot;,  </span><br><span class="line">  &quot;https://noohub.ru&quot;, </span><br><span class="line">  &quot;https://huecker.io&quot;,</span><br><span class="line">  &quot;https://dockerhub.timeweb.cloud&quot; </span><br><span class="line"> ]</span><br></pre></td></tr></table></figure>
<p><a href="https://www.bilibili.com/video/BV1xHA3euEcn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">保姆级Docker安装+镜像加速 计算机系必备技能_哔哩哔哩_bilibili</a></p>
<h4 id="为什么要指定基础镜像"><a href="#为什么要指定基础镜像" class="headerlink" title="为什么要指定基础镜像"></a>为什么要指定基础镜像</h4><ul>
<li><strong>提供操作系统和依赖</strong><br>基础镜像包含操作系统（如 Ubuntu、Alpine）、运行时环境（如 Python、Node.js）或框架（如 TensorFlow、PyTorch）等核心组件，后续所有操作（如安装依赖、拷贝文件）都基于此环境。<ul>
<li>例如：<code>FROM python:3.9</code> 提供了 Python 3.9 的运行环境，后续可以直接用 <code>pip install</code> 安装 Python 包。</li>
</ul>
</li>
<li><strong>避免重复造轮子</strong><br>如果直接从空镜像（<code>scratch</code>）开始，需要手动安装所有依赖，效率低下且容易出错。使用现有基础镜像可以复用已验证的环境配置。</li>
</ul>
<h4 id="确认支持的cuda版本"><a href="#确认支持的cuda版本" class="headerlink" title="确认支持的cuda版本"></a>确认支持的cuda版本</h4><p>命令<code>nvidia-smi</code></p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250708160948192.png" alt="image-20250708160948192"></p>
<p><strong>CUDA Version</strong> 显示当前驱动支持的最高 CUDA 版本</p>
<h4 id="问题：使用dockerfile直接部署，始终出现网络问题"><a href="#问题：使用dockerfile直接部署，始终出现网络问题" class="headerlink" title="问题：使用dockerfile直接部署，始终出现网络问题"></a>问题：使用dockerfile直接部署，始终出现网络问题</h4><p>解决方案</p>
<p>先修改了一下docker储存镜像的位置，太大了</p>
<p>先拉取基础镜像<code>docker pull lmsysorg/sglang:v0.4.8.post1-cu126</code></p>
<p>再使用<code>docker build -t mineru-sglang:latest -f Dockerfile .</code>，可以直接跳过基础镜像的拉取</p>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>官方启动命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name sglang-server \          # 容器命名（便于管理）</span><br><span class="line">  --gpus all \                   # 启用所有GPU</span><br><span class="line">  --shm-size 32g \               # 共享内存大小</span><br><span class="line">  -p 30000:30000 \               # 端口映射（主机端口:容器端口）</span><br><span class="line">  --ipc=host \                   # 共享主机IPC命名空间</span><br><span class="line">  mineru-sglang:latest \</span><br><span class="line">  mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name sglang-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host mineru-sglang:latest mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将mineru-sglang-server暴露到30000端口的作用</p>
<p>为了支持 vlm-sglang-client 后端模式，使得MinerU客户端可以通过网络连接到这个服务器，实现多个客户端可以同时连接到同一个服务器</p>
</blockquote>
<p>使用<code>docker exec -it sglang-server bash</code>命令进入容器</p>
<p>或</p>
<p>使用docker desk</p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250709152627120.png" alt="image-20250709152627120"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 -p 7860:7860 -p 8000:8000 --ipc=host \</span><br><span class="line">-v &quot;F:/project python/实习/mineru/demo/pdfs:/pdfs&quot; \</span><br><span class="line">-v &quot;F:/project python/实习/mineru/output:/output&quot; \</span><br><span class="line">mineru-sglang:latest \</span><br><span class="line">mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<p>使用挂载卷启动</p>
<ul>
<li>将本地的PDF文件目录挂载到容器内的 /pdfs 目录</li>
<li>将本地的输出目录挂载到容器内的 /output 目录</li>
<li>把8000，和7860端口暴露，方便调用fastapi与gradio webui 可视化</li>
</ul>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250710100047464.png" alt="image-20250710100047464"></p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250710103505453.png" alt="image-20250710103505453"></p>
<h3 id="调用"><a href="#调用" class="headerlink" title="调用"></a>调用</h3><h4 id="命令行调用sglang-server-client-模式"><a href="#命令行调用sglang-server-client-模式" class="headerlink" title="命令行调用sglang-server/client 模式"></a>命令行调用sglang-server/client 模式</h4><p><code>docker exec mineru-server mineru -p /pdfs/demo1.pdf -o /output -b vlm-sglang-client -u http://localhost:30000</code></p>
<p>这条命令在名为 mineru-server 的容器内执行 mineru 工具，处理 /pdfs 目录下的 demo1.pdf 文件，输出结果到 /output 目录，使用 vlm-sglang-client 后端，并连接到 <a href="http://localhost:30000">http://localhost:30000</a> 的SGLang服务器。</p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250710103615272.png" alt="image-20250710103615272"></p>
<h4 id="fastapi调用与gradio-webui-可视化"><a href="#fastapi调用与gradio-webui-可视化" class="headerlink" title="fastapi调用与gradio webui 可视化"></a>fastapi调用与gradio webui 可视化</h4><p>在完成docker的端口映射之后，运行<code>mineru-api --host 0.0.0.0 --port 8080</code>启动fastapi服务，</p>
<blockquote>
<p>FastAPI服务的使用场景</p>
<p>FastAPI服务提供了一个<code>/file_parse</code>端点，用于处理PDF和图像文件的解析请求</p>
<p>微服务架构部署，FastAPI服务可以独立部署</p>
<p>服务提供了标准的HTTP API接口，允许客户端通过网络请求进行文档解析</p>
</blockquote>
<p>运行<code>mineru-gradio --server-name 0.0.0.0 --server-port 7860</code>启动gradio webui服务</p>
<p>或<code>mineru-gradio --server-name 0.0.0.0 --server-port 7860 --enable-sglang-engine true</code></p>
<blockquote>
<p>注意，模型下载需要配置环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在容器内设置环境变量</span><br><span class="line">export MINERU_MODEL_SOURCE=local</span><br><span class="line"># 验证环境变量是否设置成功</span><br><span class="line">echo $MINERU_MODEL_SOURCE</span><br></pre></td></tr></table></figure>
</blockquote>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/115678648318f55f1fe3a5baaeac2aaf.png" alt="115678648318f55f1fe3a5baaeac2aaf"></p>
<p><strong>在调用过程中关于端口的问题与思考</strong></p>
<p>调用过程中发现，在容器中使用<code>mineru-api --host 127.0.0.1 --port 8000</code>，宿主机无法访问<code>http://127.0.0.1:8000/docs/</code>，经过查询ai，命令改为<code>mineru-api --host 0.0.0.0 --port 8000</code>就可以正常访问，那么关键在于对这两个地址的理解</p>
<blockquote>
<p>查看端口<code>netstat -ano | findstr LISTENING</code></p>
</blockquote>
<p>127.0.0.1与0.0.0.0</p>
<ul>
<li>127.0.0.1 (localhost) ：仅表示本机回环地址，只能在 同一设备内 访问</li>
<li>0.0.0.0 ：表示监听所有可用的网络接口，允许 来自任何地址 的连接</li>
</ul>
<p>当您在Docker容器内运行服务时：</p>
<ol>
<li><p>使用127.0.0.1作为绑定地址 ：</p>
<ul>
<li>服务只接受来自容器内部的连接</li>
<li>即使您映射了端口，宿主机也无法访问该服务</li>
<li>只有容器内的应用程序可以通过 127.0.0.1:端口 访问</li>
</ul>
</li>
<li><p>使用0.0.0.0作为绑定地址 ：</p>
<ul>
<li>服务接受来自任何网络接口的连接请求</li>
<li>允许从容器外部（包括宿主机）访问该服务</li>
<li>当您映射端口时（如 -p 8000:8000 ），宿主机可以通过 localhost:8000 或 127.0.0.1:8000 访问</li>
</ul>
</li>
</ol>
<p><strong>为什么需要在容器内使用0.0.0.0</strong></p>
<p>在Docker环境中，容器有自己独立的网络命名空间，这意味着容器内的 127.0.0.1 与宿主机的 127.0.0.1 是完全不同的两个环境。因此：</p>
<ul>
<li>当您在容器内使用 —host 0.0.0.0 启动服务时，该服务会监听容器的所有网络接口</li>
<li>当您在宿主机上访问 127.0.0.1:映射端口 时，Docker会将请求转发到容器内监听在 0.0.0.0:容器端口 的服务</li>
</ul>
<h3 id="mineru相关知识"><a href="#mineru相关知识" class="headerlink" title="mineru相关知识"></a>mineru相关知识</h3><h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Usage: mineru [OPTIONS]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -v, --version                   显示版本并退出</span><br><span class="line">  -p, --path PATH                 输入文件路径或目录（必填）</span><br><span class="line">  -o, --output PATH               输出目录（必填）</span><br><span class="line">  -m, --method [auto|txt|ocr]     解析方法：auto（默认）、txt、ocr（仅用于 pipeline 后端）</span><br><span class="line">  -b, --backend [pipeline|vlm-transformers|vlm-sglang-engine|vlm-sglang-client]</span><br><span class="line">                                  解析后端（默认为 pipeline）</span><br><span class="line">  -l, --lang [ch|ch_server|ch_lite|en|korean|japan|chinese_cht|ta|te|ka|latin|arabic|east_slavic|cyrillic|devanagari]</span><br><span class="line">                                  指定文档语言（可提升 OCR 准确率，仅用于 pipeline 后端）</span><br><span class="line">  -u, --url TEXT                  当使用 sglang-client 时，需指定服务地址</span><br><span class="line">  -s, --start INTEGER             开始解析的页码（从 0 开始）</span><br><span class="line">  -e, --end INTEGER               结束解析的页码（从 0 开始）</span><br><span class="line">  -f, --formula BOOLEAN           是否启用公式解析（默认开启）</span><br><span class="line">  -t, --table BOOLEAN             是否启用表格解析（默认开启）</span><br><span class="line">  -d, --device TEXT               推理设备（如 cpu/cuda/cuda:0/npu/mps，仅 pipeline 后端）</span><br><span class="line">  --vram INTEGER                  单进程最大 GPU 显存占用(GB)（仅 pipeline 后端）</span><br><span class="line">  --source [huggingface|modelscope|local]</span><br><span class="line">                                  模型来源，默认 huggingface</span><br><span class="line">  --help                          显示帮助信息</span><br></pre></td></tr></table></figure>
<h4 id="后端的区别"><a href="#后端的区别" class="headerlink" title="后端的区别"></a>后端的区别</h4><p>pipeline (默认后端) :</p>
<ul>
<li>含义 : 这是 MinerU 的默认后端，它使用本地安装的 mineru 库来执行文档解析任务。它通常不依赖于外部的 VLM（视觉语言模型）服务，而是直接在本地处理 PDF 文件。</li>
</ul>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/10d6d1a7f702c5806e29ee7b1c51283.png" alt="10d6d1a7f702c5806e29ee7b1c51283"></p>
<p>vlm-transformers :</p>
<ul>
<li>含义 : 这个后端利用 Hugging Face transformers 库中提供的 VLM 模型进行文档分析。它会在本地加载并运行一个基于 transformers 的 VLM 模型来处理 PDF 中的视觉信息和文本内容。</li>
</ul>
<blockquote>
<p>VLM（Vision-Language Model，视觉语言模型）是一种结合计算机视觉和自然语言处理能力的多模态人工智能模型。</p>
<p>OCR 是 Optical Character Recognition（光学字符识别）的缩写。它是一种技术，用于将图像中的手写、打印或打字文本转换为机器编码的文本，使其可以被计算机编辑、搜索、存储和处理。</p>
</blockquote>
<p>vlm-sglang-engine :</p>
<ul>
<li>含义 : 这个后端表示 MinerU 将直接集成并使用 SGLang 引擎进行 VLM 推理。SGLang 是一个高性能的推理引擎，旨在优化大型语言模型（LLM）和 VLM 的推理速度和效率。在这种模式下，SGLang 引擎作为 MinerU 进程的一部分运行。</li>
</ul>
<p>vlm-sglang-client :</p>
<ul>
<li>含义 : 这个后端表示 MinerU 作为 SGLang 服务器的客户端。在这种模式下，MinerU 不会直接运行 VLM 模型，而是将 PDF 处理请求发送到一个独立的 SGLang 服务器（通过 -u 参数指定的 URL，例如 <a href="http://localhost:30000">http://localhost:30000</a> ）。SGLang 服务器负责执行实际的 VLM 推理，并将结果返回给 MinerU 客户端。</li>
</ul>
<blockquote>
<p>用场景 : 这是我们之前讨论的 Docker 容器部署场景中推荐的模式。它非常适合以下情况：</p>
<ul>
<li>资源隔离 : 将 VLM 推理的计算密集型任务从 MinerU 主进程中分离出来，允许独立扩展和管理 SGLang 服务器。</li>
<li>集中管理 : 可以在一个或多个 SGLang 服务器上集中管理 VLM 模型，供多个 MinerU 客户端共享使用。</li>
<li>性能优化 : SGLang 服务器可以针对 VLM 推理进行专门优化，提供更好的吞吐量和延迟。</li>
<li>灵活部署 : SGLang 服务器可以部署在不同的机器上，甚至作为微服务运行，提供更大的部署灵活性。</li>
</ul>
</blockquote>
<h4 id="关于吞吐量的相关知识"><a href="#关于吞吐量的相关知识" class="headerlink" title="关于吞吐量的相关知识"></a>关于吞吐量的相关知识</h4><p><strong>“吞吐量”（throughput）\</strong>指的是系统在单位时间内能处理的 **Token 数量**，单位通常是 **tokens/秒**。这个指标衡量的是整体系统*<em>处理并发请求的能力*</em>，而不仅仅是单个请求的速度。</p>
<p>SGLang 支持两种主要并行方式来提升吞吐量：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>并行类型</th>
<th>作用</th>
<th>对吞吐量的影响</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>张量并行（TP）</strong></td>
<td>把模型权重切分到多张卡上，<strong>减少单卡负载</strong></td>
<td>提升单请求处理能力，<strong>但通信开销大</strong></td>
</tr>
<tr>
<td><strong>数据并行（DP）</strong></td>
<td>把不同请求分发到不同卡上，<strong>并行处理多个请求</strong></td>
<td>直接提升并发吞吐量，<strong>尤其适合高并发场景</strong></td>
</tr>
</tbody>
</table>
</div>
<h3 id="mineru的并发测试和吞吐量测试"><a href="#mineru的并发测试和吞吐量测试" class="headerlink" title="mineru的并发测试和吞吐量测试"></a>mineru的并发测试和吞吐量测试</h3><p>并发能力是测试mineru同时处理多个请求的能力，吞吐量是测试mineru处理文件时的tokens</p>
<p>明确要的是哪个吞吐量：一个是<strong>MinerU 内部推理引擎（如 vLLM/SGLang）的 token/s 输出</strong>，即 <strong>生成阶段（decode）的吞吐量</strong>，一个是你压测 <code>/file_parse</code> 接口时的 <strong>端到端 tokens/s</strong>。</p>
<p>是否有缓存（kvcache）</p>
<p><strong>测试场景</strong>：10页的pdf，50用户并发</p>
<p><strong>工具</strong>：locust</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">locust \</span><br><span class="line">  -f locustfile.py \</span><br><span class="line">  --headless \</span><br><span class="line">  -u 50 \               # 并发用户数</span><br><span class="line">  -r 5 \                # 每秒启动用户数</span><br><span class="line">  --host=http://mineru-server:30000 \</span><br><span class="line">  --html=report.html \  # 自动生成 HTML 报告</span><br><span class="line">  --csv=result          # 同时保存 csv（result_stats.csv / result_failures.csv）</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">locust -f locustfile.py --headless -u 100 -r 5 --host=http://mineru-server:30000 --html=report.html --csv=result</span><br></pre></td></tr></table></figure>
<p><strong>测试结果</strong></p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250805152017255.png" alt="image-20250805152017255"></p>
<p>对于推理模型的吞吐量，在3个gpu开启数据并行的情况下，平均每秒单个gpu处理tokens为1500左右</p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250805152149822.png" alt="image-20250805152149822"></p>
<p>gpu状态如上:<strong>显存几乎打满 85–87 %</strong>,<strong>GPU 利用率 59–63 %</strong>,<strong>功耗 170–188 W / 350 W</strong></p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250805153516235.png" alt="image-20250805153516235"></p>
<p>完整压测结果如上</p>
<p>重要指标：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>指标</th>
<th>数值</th>
<th>通俗解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>平均响应时间</strong></td>
<td><strong>241 秒</strong> ≈ <strong>4 分钟</strong></td>
<td>上传一个 PDF → 拿到解析结果，平均要等 4 分钟。</td>
</tr>
<tr>
<td><strong>中位数</strong></td>
<td><strong>215 秒</strong> ≈ <strong>3.6 分钟</strong></td>
<td>一半请求在 3.6 分钟内完成。</td>
</tr>
<tr>
<td><strong>95% 用户</strong></td>
<td><strong>361 秒</strong> ≈ <strong>6 分钟</strong></td>
<td>最慢的 5% 要等 6 分钟以上。</td>
</tr>
<tr>
<td><strong>吞吐量</strong></td>
<td><strong>0.18 req/s</strong></td>
<td>这台 MinerU <strong>每分钟只能处理约11 个 PDF</strong>。</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250806104340935.png" alt="image-20250806104340935"></p>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250806110438932.png" alt="image-20250806110438932"></p>
<p>参考资料</p>
<p><a href="https://github.com/opendatalab/MinerU/blob/be4f3de32b58ccf81c6a6dcb9d3e4998424cee6a/projects/multi_gpu_v2/README_zh.md">MinerU/projects/multi_gpu_v2/README_zh.md at be4f3de32b58ccf81c6a6dcb9d3e4998424cee6a · opendatalab/MinerU</a></p>
<h3 id="部署服务器并运行"><a href="#部署服务器并运行" class="headerlink" title="部署服务器并运行"></a>部署服务器并运行</h3><p>load镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker load -i mineru-sglang-latest.tar</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">free -h</span><br><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/mineru/image-20250716092152823.png" alt="image-20250716092152823"></p>
<p>每秒刷新<code>watch -n1 nvidia-smi          # 每秒刷新</code></p>
<p>查看Linux路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pwd </span><br></pre></td></tr></table></figure>
<p>启动容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 -p 7860:7860 -p 8000:8000 --ipc=host \</span><br><span class="line">-v &quot;/aisys/repo_dev/xizhang/pdfs:/pdfs&quot; \</span><br><span class="line">-v &quot;/aisys/repo_dev/xizhang/outputs:/output&quot; \</span><br><span class="line">mineru-sglang:latest \</span><br><span class="line">mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host -v &quot;/aisys/repo_dev/xizhang/pdfs:/pdfs&quot; -v &quot;/aisys/repo_dev/xizhang/outputs:/output&quot; mineru-sglang:latest mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec mineru-server mineru -p /pdfs/demo1.pdf -o /output -b vlm-sglang-client -u http://localhost:30000`</span><br></pre></td></tr></table></figure>
<p>进入容器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it mineru-server /bin/bash</span><br></pre></td></tr></table></figure>
<p>使用pipline解析后端模式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mineru -p /pdfs/demo1.pdf -o /output --source local</span><br></pre></td></tr></table></figure>
<p>使用sglang加速推理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1,2,3 mineru -p /pdfs/small_ocr.pdf -o /output -b vlm-sglang-engine --source local</span><br></pre></td></tr></table></figure>
<blockquote>
<p>vlm模式同样可以处理扫描件</p>
</blockquote>
<p>使用ocr解析扫描件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mineru -p /pdfs/small_ocr.pdf -o /output --source local -m ocr</span><br></pre></td></tr></table></figure>
<p>增加推理设备</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mineru -p /pdfs/small_ocr.pdf -o /output --source local -m ocr -d cuda</span><br></pre></td></tr></table></figure>
<p>通过在命令行的开头添加<code>CUDA_VISIBLE_DEVICES</code> 环境变量来指定可见的 GPU 设备。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1,2,3 mineru -p /pdfs/small_ocr.pdf -o /output --source local -m ocr</span><br></pre></td></tr></table></figure>
<p>使用sglang加速模式的多GPU并行</p>
<p>数据并行（dp-size）和张量并行（tp-size）</p>
<p>MinerU支持通过sglang的多GPU并行模式来提升推理速度。您可以使用以下参数：</p>
<ul>
<li><code>--dp-size</code>: 数据并行，通过多卡同时处理多个输入来增加吞吐量</li>
<li><code>--tp-size</code>: 张量并行，将模型分布到多张GPU上以扩展可用显存</li>
</ul>
<blockquote>
<p>如果您已经可以正常使用sglang对vlm模型进行加速推理，但仍然希望进一步提升推理速度，可以尝试以下参数：</p>
<ul>
<li>如果您有超过多张显卡，可以使用sglang的多卡并行模式来增加吞吐量：<code>--dp-size 2</code></li>
<li>同时您可以启用<code>torch.compile</code>来将推理速度加速约15%：<code>--enable-torch-compile</code></li>
</ul>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1,2,3 mineru -p /pdfs -o /output -b vlm-sglang-engine --source local --dp-size 3 --enable-torch-compile</span><br></pre></td></tr></table></figure>
<p>将python文件上传docker并运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker cp demo.py mineru-server:/demo.py</span><br><span class="line"></span><br><span class="line">docker exec mineru-server python /demo.py</span><br><span class="line"></span><br><span class="line">#删除</span><br><span class="line">rm -i demo.py</span><br></pre></td></tr></table></figure>
<p>添加自定义网络，修改挂载卷</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host -v /aisys/:/aisys/ --network network_test mineru-sglang:latest mineru-sglang-server --host 0.0.0.0 --port 30000</span><br></pre></td></tr></table></figure>
<p>后面才知道，上面这个命令会自动启动sglang-server服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host -v /aisys/:/aisys/ --network network_test mineru-sglang:latest tail -f /dev/null</span><br><span class="line">docker start mineru-server</span><br></pre></td></tr></table></figure>
<p>使用上面这个命令启动容器，但不启动sglang-server服务，使用下面指令手动启动</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it mineru-server /bin/bash</span><br><span class="line">MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3 mineru-sglang-server --port 30000 --dp-size 3 --enable-torch-compile</span><br></pre></td></tr></table></figure>
<p>启动服务后在另一个容器尝试访问</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl http://mineru-server:30000/get_model_info</span><br></pre></td></tr></table></figure>
<p>在另一个容器使用服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mineru -p /test -o / -b vlm-sglang-client -u http://mineru-server:30000</span><br></pre></td></tr></table></figure>
<hr>
<p>启动fastapi服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3 mineru-api --host 0.0.0.0 --port 30000 --dp-size 3 --enable-torch-compile</span><br></pre></td></tr></table></figure>
<p>在另一个容器验证</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl http://mineru-server:30000/openapi.json</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在容器内设置环境变量</span><br><span class="line">export CUDA_VISIBLE_DEVICES=1,2,3</span><br><span class="line"># 验证环境变量是否设置成功</span><br><span class="line">echo $CUDA_VISIBLE_DEVICES</span><br><span class="line"></span><br><span class="line"># 在容器内设置环境变量</span><br><span class="line">export MINERU_MODEL_SOURCE=local</span><br><span class="line"># 验证环境变量是否设置成功</span><br><span class="line">echo $MINERU_MODEL_SOURCE</span><br></pre></td></tr></table></figure>
<h3 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h3><p><a href="https://blog.csdn.net/liuzhenghua66/article/details/148980203">MinerU 2.0部署-CSDN博客</a></p>
<p><a href="https://github.com/opendatalab/MinerU?tab=readme-ov-file#local-deployment">https://github.com/opendatalab/MinerU?tab=readme-ov-file#local-deployment</a> </p>
<p><a href="https://deepwiki.com/opendatalab/MinerU">https://deepwiki.com/opendatalab/MinerU</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
        <tag>docker</tag>
        <tag>MineU</tag>
      </tags>
  </entry>
  <entry>
    <title>rag评估</title>
    <url>/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/</url>
    <content><![CDATA[<h3 id="rag评估的指标"><a href="#rag评估的指标" class="headerlink" title="rag评估的指标"></a>rag评估的指标</h3><h4 id="忠诚度Faithfulness"><a href="#忠诚度Faithfulness" class="headerlink" title="忠诚度Faithfulness"></a>忠诚度Faithfulness</h4><p>Faithfulness：衡量生成答案与给定上下文之间的事实一致性。忠实度得分是基于答案和检索到的上下文<br>计算出来的，答案的评分范围在0到1之间，分数越高越好。</p>
<p><img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711154457878.png" alt="image-20250711154457878"></p>
<p>计算方式：将大模型给出的答案进行切片，检索给出的上下文，计算这些切片是否在上下文中</p>
<p><img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711155257239.png" alt="image-20250711155257239"></p>
<h4 id="答案相关性Answerrelevance"><a href="#答案相关性Answerrelevance" class="headerlink" title="答案相关性Answerrelevance"></a>答案相关性Answerrelevance</h4><p>Answerrelevance：答案相关性的评估指标旨在评估生成的答案与给定提示的相关程度。如果答案不完<br>整或包含冗余信息，则会被赋予较低的分数。这个指标使用问题和答案来计算，其值介于0到1之间，得<br>分越高表明答案的相关性越好</p>
<p><img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711155128553.png" alt="image-20250711155128553"></p>
<p>计算方式：根据答案生成多个问题，然后计算生成的答案与原答案的余弦相似度，再取平均</p>
<p><img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250711155407518.png" alt="image-20250711155407518"></p>
<h4 id="上下文精确度ContextPrecision"><a href="#上下文精确度ContextPrecision" class="headerlink" title="上下文精确度ContextPrecision"></a>上下文精确度ContextPrecision</h4><p>ContextPrecision：上下文精确度衡量上下文中所有相关的真实信息是否被排在了较高的位置。理想情<br>况下，所有相关的信息块都应该出现在排名的最前面。这个指标是根据问题和上下文来计算的，数值范<br>围在0到1之间，分数越高表示精确度越好。</p>
<script type="math/tex; mode=display">
\text{Context Precision} = \frac{\sum_{k=1}^{K} (\text{rel}(k) \times \frac{\text{Precision@k}}{\text{Ideal Precision@k}})}{\text{Total Relevant Documents}}</script><ul>
<li><code>K</code>：检索返回的文档总数（如 top-5）</li>
<li><code>rel(k)</code>：第 <code>k</code> 个文档是否相关（相关=1，无关=0）</li>
<li><code>Precision@k</code>：前 <code>k</code> 个文档的精确率（相关文档数 / k）</li>
<li><code>Ideal Precision@k</code>：理想情况下前 <code>k</code> 个文档的精确率（假设所有相关文档都排在最前面）</li>
</ul>
<h4 id="上下文召回率ContextRecall"><a href="#上下文召回率ContextRecall" class="headerlink" title="上下文召回率ContextRecall"></a>上下文召回率ContextRecall</h4><p>ContextRecall：用来衡量检索到的上下文与被视为事实真相的标注答案的一致性程度。它根据事实真相<br>和检索到的上下文来计算，数值范围在0到1之间，数值越高表示性能越好。<br>为了从事实真相的答案中估计上下文召回率，需要分析答案中的每个句子是否可以归因于检索到的<br>上下文。在理想情况下，事实真相答案中的所有句子都应该能够对应到检索到的上下文中。</p>
<script type="math/tex; mode=display">
\text{Context Recall} = \frac{|\{\text{返回的相关文档}\} \cap \{\text{标准相关文档}\}|}{|\{\text{标准相关文档}\}|}</script><p>计算方式：上下文是否包括了标准答案的内容</p>
<h3 id="利用RAGAS评估rag性能"><a href="#利用RAGAS评估rag性能" class="headerlink" title="利用RAGAS评估rag性能"></a>利用RAGAS评估rag性能</h3><p><a href="https://github.com/zxj-2023/learn-rag-langchain/blob/main/RAGAS-langchian.ipynb">learn-rag-langchain/RAGAS-langchian.ipynb at main · zxj-2023/learn-rag-langchain</a></p>
<p>检索器<br>1.Contextprecision(上下文精确度)：评估检索质量。<br>2.Context Recall(上下文召回率)：衡量检索的完整性。<br>生成器<br>1.Faithfulness(忠实度)：衡量生成答案中的幻觉情况。<br>2.AnswerRelevance(答案相关性):衡量答案对问题的直接性(紧扣问题的核心)。</p>
<p>最终的RAGAS得分是以上各个指标得分的调和平均值。简而言之，这些指标用来综合评估<br>-个系统整体的性能。</p>
<h4 id="RAG的构建"><a href="#RAG的构建" class="headerlink" title="RAG的构建"></a>RAG的构建</h4><p>创建RAG文本分割、Embedding model 、 向量库存储Chroma</p>
<p>我们主要使用 <code>RecursiveCharacterTextSplitter</code> 切割文本，通过<code>OpenAIEmbeddings()</code>进行文本编码，存储到 <code>VectorStore</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.vectorstores import Chroma</span><br><span class="line">from langchain.embeddings import OpenAIEmbeddings</span><br><span class="line">from langchain.text_splitter import RecursiveCharacterTextSplitter</span><br><span class="line">from langchain_community.embeddings import DashScopeEmbeddings</span><br><span class="line">embeddings_model = DashScopeEmbeddings(</span><br><span class="line">        model=&quot;text-embedding-v2&quot;,</span><br><span class="line">        dashscope_api_key=openai.api_key,</span><br><span class="line">    )</span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)</span><br><span class="line">#进行文本分割，生成更小、更易于处理的文档块</span><br><span class="line">docs = text_splitter.split_documents(paper_docs)</span><br><span class="line"></span><br><span class="line">vectorstore = Chroma.from_documents(docs, embeddings_model)</span><br></pre></td></tr></table></figure>
<p>Chroma 向量数据库默认情况下是内存存储，这意味着数据在程序运行结束后不会保留。<br>但是，Chroma 也支持持久化存储，您可以指定一个路径将数据保存到磁盘上。这样，即使程序关闭，数据也会被保留，并在下次启动时自动加载。</p>
<h4 id="检索器的构建"><a href="#检索器的构建" class="headerlink" title="检索器的构建"></a>检索器的构建</h4><p>现在我们可以利用 <code>Chroma</code> 向量库的 <code>.as_retriever()</code> 方式进行检索，需要控制的主要参数为 <code>k</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">base_retriever = vectorstore.as_retriever(search_kwargs=&#123;&quot;k&quot; : 3&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>ectorstore.as_retriever() : 这个方法的作用是将一个向量数据库实例（ vectorstore ）转换为 LangChain 中的一个检索器（ Retriever ）对象。检索器是 LangChain 中负责根据用户查询从数据源中获取相关文档的核心组件。</li>
<li>“k” : 这个键表示要检索的“最相似”文档的数量。在这里， “k” : 3 意味着当检索器接收到一个查询时，它将从向量存储中返回与该查询最相似的 3 个文档。这在 RAG（检索增强生成）系统中非常常见，用于限制传递给大型语言模型的上下文信息量，以提高效率和相关性。</li>
</ul>
<p>检索器的作用<br>检索器（Retriever）是一个核心组件，其主要作用是从一个数据源（如向量数据库、文档加载器等）中根据给定的查询（query）检索出相关的文档或信息。</p>
<h4 id="prompt的构建"><a href="#prompt的构建" class="headerlink" title="prompt的构建"></a>prompt的构建</h4><p>我们需要利用<code>LLM</code>对<code>Context</code> 生成一系列的问题的<code>answer</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain import PromptTemplate</span><br><span class="line"></span><br><span class="line">template = &quot;&quot;&quot;You are an assistant for question-answering tasks. </span><br><span class="line">Use the following pieces of retrieved context to answer the question. </span><br><span class="line">If you don&#x27;t know the answer, just say that you don&#x27;t know. </span><br><span class="line"></span><br><span class="line">Question: &#123;question&#125; </span><br><span class="line"></span><br><span class="line">Context: &#123;context&#125; </span><br><span class="line"></span><br><span class="line">Answer:</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    template=template, </span><br><span class="line">    input_variables=[&quot;context&quot;,&quot;question&quot;]</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">print(prompt)</span><br></pre></td></tr></table></figure>
<h4 id="生成answer-利用LLM"><a href="#生成answer-利用LLM" class="headerlink" title="生成answer,利用LLM"></a>生成<code>answer</code>,利用LLM</h4><p>利用 <code>Runnable</code> 定义一个 <code>chain</code> 实现rag全流程。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from langchain.schema.runnable import RunnablePassthrough</span><br><span class="line">from langchain.schema.output_parser import StrOutputParser</span><br><span class="line">from langchain_openai import ChatOpenAI</span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model_name=&quot;qwen-plus-2025-04-28&quot;, </span><br><span class="line">    temperature=0,</span><br><span class="line">    api_key=&quot;&quot;,</span><br><span class="line">    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span><br><span class="line">    )</span><br><span class="line">#RunnablePassthrough将输入数据原封不动地传递到输出</span><br><span class="line">#StrOutputParser() 它被用作 RAG 链的最后一步，确保最终的答案以字符串形式输出。</span><br><span class="line">rag_chain = (</span><br><span class="line">    &#123;&quot;context&quot;: base_retriever,  &quot;question&quot;: RunnablePassthrough()&#125; </span><br><span class="line">    | prompt </span><br><span class="line">    | llm</span><br><span class="line">    | StrOutputParser() </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="创建-RAGAs-所需的数据"><a href="#创建-RAGAs-所需的数据" class="headerlink" title="创建 RAGAs 所需的数据"></a>创建 RAGAs 所需的数据</h4><p>question  Answer   contexts  ground_truths</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Ragas 数据集格式要求  [&#x27;question&#x27;, &#x27;answer&#x27;, &#x27;contexts&#x27;, &#x27;ground_truths&#x27;]</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;question&quot;: [], &lt;-- 问题基于Context的</span><br><span class="line">    &quot;answer&quot;: [], &lt;-- 答案基于LLM生成的</span><br><span class="line">    &quot;contexts&quot;: [], &lt;-- context</span><br><span class="line">    &quot;ground_truths&quot;: [] &lt;-- 标准答案</span><br><span class="line">&#125;</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">from datasets import Dataset</span><br><span class="line">#构建问题与标准答案（黄金数据集）</span><br><span class="line">questions = [&quot;What is faithfulness ?&quot;, </span><br><span class="line">             &quot;How many pages are included in the WikiEval dataset, and which years do they cover information from?&quot;,</span><br><span class="line">             &quot;Why is evaluating Retrieval Augmented Generation (RAG) systems challenging?&quot;,</span><br><span class="line">            ]</span><br><span class="line">ground_truths = [&quot;Faithfulness refers to the idea that the answer should be grounded in the given context.&quot;,</span><br><span class="line">                  &quot; To construct the dataset, we first selected 50 Wikipedia pages covering events that have happened since the start of 2022.&quot;,</span><br><span class="line">                &quot;Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself.&quot;]              </span><br><span class="line">answers = []</span><br><span class="line">contexts = []</span><br><span class="line"></span><br><span class="line"># 生成答案</span><br><span class="line">for query in questions:</span><br><span class="line">    answers.append(rag_chain.invoke(query))</span><br><span class="line">    contexts.append([docs.page_content for docs in base_retriever.get_relevant_documents(query)])</span><br><span class="line"></span><br><span class="line"># 构建数据</span><br><span class="line">data = &#123;</span><br><span class="line">    &quot;user_input&quot;: questions,</span><br><span class="line">    &quot;response&quot;: answers,</span><br><span class="line">    &quot;retrieved_contexts&quot;: contexts,</span><br><span class="line">    &quot;reference&quot;: ground_truths</span><br><span class="line">&#125;</span><br><span class="line">dataset = Dataset.from_dict(data)</span><br></pre></td></tr></table></figure>
<h4 id="使用RAGAs-进行评估"><a href="#使用RAGAs-进行评估" class="headerlink" title="使用RAGAs 进行评估"></a>使用RAGAs 进行评估</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#将评估数据转换成 Ragas 框架专用的格式 。</span><br><span class="line">from ragas import EvaluationDataset</span><br><span class="line">evaluation_dataset = EvaluationDataset.from_list(dataset)</span><br></pre></td></tr></table></figure>
<p>我们可以使用一组常用的RAG评估指标，在收集的数据集上评估我们的RAG系统。您可以选择任何模型作为评估用LLM来进行评估。<br>ragas默认使用openai的api</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from ragas.llms import LangchainLLMWrapper</span><br><span class="line">evaluator_llm = LangchainLLMWrapper(llm)</span><br></pre></td></tr></table></figure>
<p>调用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness</span><br><span class="line">from ragas import evaluate</span><br><span class="line">result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)</span><br><span class="line">result</span><br></pre></td></tr></table></figure>
<p><img src="/2025/07/11/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/rag%E8%AF%84%E4%BC%B0/image-20250713164037571.png" alt="image-20250713164037571"></p>
<h4 id="查看结果"><a href="#查看结果" class="headerlink" title="查看结果"></a>查看结果</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">pd.set_option(&quot;display.max_colwidth&quot;, None)</span><br><span class="line"></span><br><span class="line">df = result.to_pandas()</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://zhuanlan.zhihu.com/p/1892529470419736435">RAG系统效果难评？2025年必备的RAG评估框架与工具详解 - 知乎</a></p>
<p><a href="https://www.bilibili.com/video/BV1Jz421Q7Lw?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">如何利用RAGAs评估RAG系统的好坏_哔哩哔哩_bilibili</a></p>
<p>ragas中文文档<a href="https://www.aidoczh.com/ragas/getstarted/rag_eval/index.html#want-help-in-improving-your-ai-application-using-evals">Evaluate a simple RAG - Ragas</a></p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>学习</tag>
        <tag>实习</tag>
        <tag>rag</tag>
      </tags>
  </entry>
  <entry>
    <title>实战</title>
    <url>/2025/07/18/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>部署日志见实习日志那篇文章</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>查看mineru提取的markdown文档后，发现mineru暂时无法提取多级标题，所以可以舍弃根据markdown文档结构的分块策略</p>
<p>UnstructuredMarkdownLoader会丢失表格格式，不能使用</p>
<h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><p>将 <code>Markdown</code> 文档加载到 LangChain <a href="https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document">文档</a> 对象中，以便我们可以在后续使用</p>
<h4 id="使用UnstructuredMarkdownLoader-对象"><a href="#使用UnstructuredMarkdownLoader-对象" class="headerlink" title="使用UnstructuredMarkdownLoader 对象"></a>使用<a href="https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html">UnstructuredMarkdownLoader</a> 对象</h4><p>UnstructuredMarkdownLoader 是 LangChain 中的一个 文档加载器（Document Loader） ，专门用于加载和解析 Markdown ( .md ) 文件。它的特别之处在于，它底层依赖于一个强大的开源库 unstructured 。</p>
<p><strong>UnstructuredMarkdownLoader 的核心功能</strong></p>
<p>传统的文本加载器可能会将整个 Markdown 文件作为一个大字符串读入。而 UnstructuredMarkdownLoader 凭借 unstructured 库的能力，可以 智能地识别 Markdown 文件内部的结构 。</p>
<p>它能够将文档分解成多个有意义的<strong>“元素” (Elements)</strong>，例如：</p>
<ul>
<li>标题 (Titles)</li>
<li>叙述性文本 (Narrative Text / Paragraphs)</li>
<li>列表项 (List Items)</li>
<li>代码块 (Code Blocks)<br>这种智能分区对于后续的 RAG (Retrieval-Augmented Generation) 应用非常重要，因为它能让您以更小的、逻辑上连贯的块来处理文本，从而提高检索的准确性。</li>
</ul>
<p><strong>重要的 mode 参数</strong></p>
<p>UnstructuredMarkdownLoader 的构造函数中有一个非常重要的 mode 参数，它决定了文档的加载方式：</p>
<ol>
<li><p>mode=”single” (默认值)</p>
<ul>
<li>将整个 Markdown 文件的所有内容加载成 一个单独的 Document 对象 。</li>
<li>page_content 包含文件的全部文本。</li>
</ul>
</li>
<li><p>mode=”elements”</p>
<ul>
<li>这是它最强大的模式。它会将文件解析成多个 Document 对象， 每个对象对应一个识别出的元素 （如一个标题、一个段落）。</li>
<li>这对于创建精细的文本块以进行向量嵌入和检索非常有用。</li>
</ul>
</li>
</ol>
<h4 id="使用libreoffice处理doc文件，转成pdf"><a href="#使用libreoffice处理doc文件，转成pdf" class="headerlink" title="使用libreoffice处理doc文件，转成pdf"></a>使用libreoffice处理doc文件，转成pdf</h4><p>将当前目录下所有 <code>.doc</code> 和 <code>.docx</code> 转为 PDF：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">libreoffice --headless --convert-to pdf *.doc *.docx --outdir ./pdf_output/</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>学习</tag>
        <tag>实习</tag>
        <tag>rag</tag>
        <tag>chunk</tag>
      </tags>
  </entry>
  <entry>
    <title>prompt Engineering与context Engineering</title>
    <url>/2025/07/13/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/prompt%20Engineering%E4%B8%8Econtext%20Engineering/</url>
    <content><![CDATA[<h3 id="prompt-Engineering"><a href="#prompt-Engineering" class="headerlink" title="prompt Engineering"></a>prompt Engineering</h3><p>Prompt Engineering是与大型语言模型（LLM）交互的基础，其核心在于精心设计输入内容，以引导模型生成期望的输出。</p>
<p>尽管 Prompt Engineering 至关重要，但对于构建稳健、可用于生产环境的系统而言，它存在固有的局限性：</p>
<ul>
<li><p><strong>脆弱性&amp;不可复现性：</strong> 提示中微小的措辞变化可能导致输出结果的巨大差异，使得这一过程更像是一种依赖反复试错的“艺术”，而非可复现的“科学” 。</p>
</li>
<li><p><strong>扩展性差：</strong> 手动、迭代地优化提示的过程，在面对大量用户、多样化用例和不断出现的边缘情况时，难以有效扩展 。</p>
</li>
<li><p><strong>用户负担：</strong> 这种方法将精心构建一套详尽指令的负担完全压在了用户身上，对于需要自主运行、或处理高并发请求的系统而言是不切实际的 。</p>
</li>
<li><p><strong>无状态性：</strong> Prompt Engineering 本质上是为单轮、“一次性”的交互而设计的，难以处理需要记忆和状态管理的长对话或多步骤任务 。</p>
</li>
</ul>
<h3 id="Context-Engineering"><a href="#Context-Engineering" class="headerlink" title="Context Engineering"></a>Context Engineering</h3><p><strong>Context Engineering是一门设计、构建并优化动态自动化系统的学科，旨在为大型语言模型在正确的时间、以正确的格式，提供正确的信息和工具，从而可靠、可扩展地完成复杂任务</strong> 。</p>
<p><strong>prompt 告诉模型如何思考，而 Context 则赋予模型完成工作所需的知识和工具。</strong></p>
<ul>
<li><p>Context Engineering 决定<strong>用什么内容填充 Context Window</strong> ，</p>
</li>
<li><p>Prompt Engineering 则负责优化<strong>窗口内的具体指令</strong> 。</p>
</li>
</ul>
<h3 id="Context-Engineering-的基石：RAG（Retrieval-Augmented-Generation）"><a href="#Context-Engineering-的基石：RAG（Retrieval-Augmented-Generation）" class="headerlink" title="Context Engineering 的基石：RAG（Retrieval-Augmented Generation）"></a>Context Engineering 的基石：RAG（Retrieval-Augmented Generation）</h3><p>本部分将阐述检索增强生成（RAG）作为实现 Context Engineering 的主要架构模式。</p>
<h4 id="解决LLM的核心弱点"><a href="#解决LLM的核心弱点" class="headerlink" title="解决LLM的核心弱点"></a>解决LLM的核心弱点</h4><p>RAG直接解决了标准LLM在企业应用中存在的固有局限性：</p>
<ul>
<li><p><strong>知识冻结：</strong> LLM的知识被冻结在<strong>其训练数据的时间点</strong>。RAG通过在推理时注入实时的、最新的信息来解决这个问题 。</p>
</li>
<li><p><strong>缺乏领域专有知识：</strong> 标准LLM无法访问组织的内部私有数据。RAG则能够将LLM连接到这些内部知识库，如技术手册、政策文件等 。</p>
</li>
<li><p><strong>幻觉（Hallucination）：</strong> LLM 会不同程度上地编造事实。RAG通过将模型的回答“锚定”在可验证的、检索到的证据上，提高事实的准确性和可信度 。</p>
</li>
</ul>
<h4 id="RAG工作流"><a href="#RAG工作流" class="headerlink" title="RAG工作流"></a>RAG工作流</h4><ol>
<li><p><strong>索引（离线阶段）：</strong> 在这个阶段，系统会处理外部知识源。文档被加载、分割成更小的 chunks，然后通过Embedding Model 转换为向量表示，并最终存储在专门的向量数据库中以备检索 。</p>
</li>
<li><p><strong>推理（在线阶段）：</strong> 当用户提出请求时，系统执行以下步骤：</p>
<ol>
<li><strong>检索（Retrieve）：</strong> 将用户的查询同样转换为向量，然后在向量数据库中进行相似性搜索，找出与查询最相关的文档块。</li>
<li><strong>增强（Augment）：</strong> 将检索到的这些文档块与原始的用户查询、系统指令等结合起来，构建一个内容丰富的、增强的最终提示。</li>
<li><strong>生成（Generate）：</strong> 将这个增强后的提示输入给LLM，LLM会基于提供的上下文生成一个有理有据的回答 。</li>
</ol>
</li>
</ol>
<h3 id="Context-工程化：如何判断和提取哪些内容应该进入上下文？"><a href="#Context-工程化：如何判断和提取哪些内容应该进入上下文？" class="headerlink" title="Context 工程化：如何判断和提取哪些内容应该进入上下文？"></a>Context 工程化：如何判断和提取哪些内容应该进入上下文？</h3><h4 id="1-chunking"><a href="#1-chunking" class="headerlink" title="1.chunking"></a>1.chunking</h4><p>文本分块（Chunking）是RAG流程中最关键也最容易被忽视的一步。其目标是创建在语义上自成一体的文本块。</p>
<h4 id="2-Reranking"><a href="#2-Reranking" class="headerlink" title="2.Reranking"></a>2.Reranking</h4><p>为了平衡检索的速度和准确性，业界普遍采用两阶段检索流程。</p>
<ul>
<li><p><strong>两阶段流程：</strong></p>
<ul>
<li><strong>第一阶段（召回）：</strong> 使用一个快速、高效的检索器（如基于 bi-encoder 的向量搜索或BM25等词法搜索）进行广泛撒网，召回一个较大的候选文档集（例如，前100个） 。</li>
<li><strong>第二阶段（精排/重排序）：</strong> 使用一个更强大但计算成本更高的模型，对这个较小的候选集进行重新评估，以识别出最相关的少数几个文档（例如，前5个） 。</li>
</ul>
</li>
<li><p><strong>Cross-Encoder：</strong> 交叉编码器之所以在重排序阶段表现优越，是因为它与双编码器的工作方式不同。双编码器独立地为查询和文档生成嵌入向量，然后计算它们的相似度。而交叉编码器则是将查询和文档<strong>同时</strong>作为输入，让模型在内部通过 Attention Mechanism 对二者进行深度交互。这使得模型能够捕捉到更细微的语义关系，从而给出更准确的相关性评分 。</p>
</li>
<li><p><strong>实际影响：</strong> 重排序显著提高了最终送入LLM的上下文质量，从而产出更准确、幻觉更少的答案。在金融、法律等高风险领域，重排序被认为是必不可少而非可选的步骤 。</p>
</li>
</ul>
<h4 id="3-优化上下文窗口：压缩与摘要"><a href="#3-优化上下文窗口：压缩与摘要" class="headerlink" title="3.优化上下文窗口：压缩与摘要"></a>3.优化上下文窗口：压缩与摘要</h4><p>本节详细介绍用于主动管理上下文的技术，确保最有价值的信息被优先呈现。</p>
<ul>
<li><p><strong>上下文压缩的目标：</strong> 缩短检索到的文档列表和/或精简单个文档的内容，只将<strong>最相关的信息传递给LLM</strong>。这能有效降低API调用成本、减少延迟，并缓解 Lost in the Middle 的问题 。</p>
</li>
<li><p><strong>压缩方法：</strong></p>
<ul>
<li><strong>过滤式压缩：</strong> 这类方法决定是保留还是丢弃整个检索到的文档。<ul>
<li><strong>LLMChainFilter：</strong> 利用一个LLM对每个文档的相关性做出简单的“是/否”判断 。</li>
<li><strong>EmbeddingsFilter：</strong> 更经济快速的方法，根据文档嵌入与查询嵌入的余弦相似度来过滤文档 。</li>
</ul>
</li>
<li><strong>内容提取式压缩：</strong> 这类方法会直接修改文档内容。<ul>
<li><strong>LLMChainExtractor：</strong> 遍历每个文档，并使用LLM从中提取仅与查询相关的句子或陈述 。</li>
</ul>
</li>
<li><strong>用 top N 代替压缩：</strong> 像LLMListwiseRerank这样的技术，使用LLM对检索到的文档进行重排序，并只返回排名最高的N个，从而起到高质量过滤器的作用 。</li>
</ul>
</li>
<li><p><strong>作为压缩策略的摘要：</strong> 对于非常长的文档或冗长的对话历史，可以利用LLM生成摘要。这些摘要随后被注入上下文，既保留了关键信息，又大幅减少了 Token 数量。这是在长时程运行的智能体中管理上下文的关键技术 。</p>
</li>
</ul>
<h3 id="智能体架构中的数据流与工作流编排"><a href="#智能体架构中的数据流与工作流编排" class="headerlink" title="智能体架构中的数据流与工作流编排"></a>智能体架构中的数据流与工作流编排</h3><h4 id="工作流（Workflow）-vs-智能体（Agent）"><a href="#工作流（Workflow）-vs-智能体（Agent）" class="headerlink" title="工作流（Workflow） vs. 智能体（Agent）"></a>工作流（Workflow） vs. 智能体（Agent）</h4><ul>
<li><p><strong>工作流（Workflows）</strong></p>
<ul>
<li>指的是LLM和工具通过<strong>预定义的代码路径</strong>进行编排的系统。在这种模式下，数据流动的路径是固定的、由开发者明确设计的，类似于上世纪流行的“专家系统”。例如，“第一步：分析用户邮件；第二步：根据分析结果在日历中查找空闲时段；第三步：起草会议邀请邮件”。这种模式确定性高，易于调试和控制，非常适合有明确业务流程的场景（如风控需求高、数据敏感、安全等级要求）。</li>
</ul>
</li>
<li><p><strong>智能体（Agents）</strong></p>
<ul>
<li>指的是LLM<strong>动态地指导</strong>自己的流程和工具使用，自主控制如何完成任务的系统。在这种模式下，数据流动的路径不是预先固定的，而是由LLM在每一步根据当前情况和目标动态决定的。这种模式灵活性高，能处理开放式问题，但可控性和可预测性较低 。</li>
</ul>
</li>
</ul>
<p>复杂的智能体通常是这两种模式的混合体，在宏观层面遵循一个预定义的工作流，但在某些节点内部，又赋予LLM一定的自主决策权。管理这一切的核心，我们称之为<strong>编排层（Orchestration Layer）</strong> 。</p>
<h4 id="核心架构：预定义数据流的实现"><a href="#核心架构：预定义数据流的实现" class="headerlink" title="核心架构：预定义数据流的实现"></a><strong>核心架构：预定义数据流的实现</strong></h4><ol>
<li><p><strong>链式工作流（Prompt Chaining）</strong></p>
</li>
<li><p><strong>路由工作流（Routing)</strong></p>
</li>
<li><p><strong>编排器-工作者模式（Orchestrator-Workers）</strong></p>
</li>
</ol>
<h4 id="框架与工具"><a href="#框架与工具" class="headerlink" title="框架与工具"></a>框架与工具</h4><p>上述的架构和机制并非凭空存在，而是通过具体的开发框架实现的。其中，LangGraph作为LangChain的扩展，为构建具有显式数据流的智能体系统提供了强大的工具集。</p>
<p><strong>LangGraph：用图（Graph）定义工作流（Workflow）</strong></p>
<p>LangGraph的核心思想是将智能体应用构建成一个<strong>状态图（State Graph）</strong> 。这个图由节点和边组成，清晰地定义了数据如何在不同模块间流动</p>
<ul>
<li><p><strong>状态（State）：</strong> 这是整个图的核心，一个所有节点共享的中央数据对象。</p>
<ul>
<li>你可以把它想象成一个“数据总线”或共享内存。开发者需要预先定义State的结构，每个节点在执行时都可以读取和更新这个State对象 。</li>
</ul>
</li>
<li><p><strong>节点（Nodes）：</strong> 代表工作流中的一个计算单元或一个步骤。</p>
<ul>
<li>每个节点通常是一个Python函数，它接收当前的State作为输入，执行特定任务（如调用LLM、执行工具、处理数据），然后返回对State的更新 。</li>
</ul>
</li>
<li><p><strong>边（Edges）</strong>： 连接节点，定义了工作流的路径，即数据在State更新后应该流向哪个节点。</p>
<ul>
<li><strong>简单边（Simple Edges）：</strong> 定义了固定的、无条件的流向，用于实现链式工作流 。</li>
<li><strong>条件边（Conditional Edges）：</strong> 用于实现路由逻辑。它会根据一个函数的输出来决定接下来应该走向哪个节点，从而实现流程的分支 。</li>
</ul>
</li>
<li><p><strong>检查点（Checkpointer）：</strong> LangGraph提供了持久化机制，可以在每一步执行后自动保存State的状态。这对于构建需要长期记忆、可中断和恢复、或需要 Human-in-the-Loop 的复杂业务流程至关重要 。</p>
</li>
</ul>
<p>复杂业务流程的AI智能体，其核心挑战已从单纯优化信息检索（如RAG）或提示词，转向了对内部<strong>工作流和数据流的精心设计与编排</strong>。</p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>学习</tag>
        <tag>实习</tag>
        <tag>rag</tag>
        <tag>prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——初读论文与初步学习</title>
    <url>/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/</url>
    <content><![CDATA[<h1 id="视频异常检测初步了解"><a href="#视频异常检测初步了解" class="headerlink" title="视频异常检测初步了解"></a>视频异常检测初步了解</h1><h2 id="传统方法检测异常样本："><a href="#传统方法检测异常样本：" class="headerlink" title="传统方法检测异常样本："></a>传统方法检测异常样本：</h2><ul>
<li>高斯分布 Gaussian Distribute</li>
<li>高斯混合模型 Gaussian Mixture Model</li>
</ul>
<h2 id="深度学习方法下的异常检测："><a href="#深度学习方法下的异常检测：" class="headerlink" title="深度学习方法下的异常检测："></a>深度学习方法下的异常检测：</h2><ul>
<li>两种主流的异常检测任务：<ul>
<li>重构任务 Reconstruction：图像通过深度神经网络DNN输出一张重构图像，通过损失函数，先训练调整DNN，测试结果由AUC评判（AUC（Area Under the Curve）是用于评估分类模型性能的一个重要指标）</li>
<li>预测任务 Prediction：连续输入图像，预测新图像，用预测与非预测比较</li>
</ul>
</li>
<li>自动编码器 Auto-Encoder：U-Net 是一种用于图像分割的深度学习模型，主要特点是采用了编码器-解码器结构（也叫对称结构），并在编码器和解码器之间引入了跳跃连接（skip connections）</li>
</ul>
<blockquote>
<p><strong>编码器（Contracting Path）</strong>：这一部分类似于卷积神经网络（CNN），用于提取输入图像的特征。</p>
<p><strong>瓶颈层（Bottleneck）</strong>：编码器和解码器之间的连接层，负责处理最深层次的特征。</p>
<p><strong>解码器（Expansive Path）</strong>：这一部分用于将编码器提取的特征还原回原始图像的大小。</p>
<p><strong>跳跃连接（Skip Connections）</strong>：解码器部分会与编码器的对应层进行直接连接，从而帮助模型在恢复空间分辨率的过程中更好地保留细节信息。</p>
<p><img src="./../../images/大创/v2-39073bacc426f0e464b53336c83e19da_1440w.jpg" alt="v2-39073bacc426f0e464b53336c83e19da_1440w"></p>
</blockquote>
<h2 id="根据学习方法分类："><a href="#根据学习方法分类：" class="headerlink" title="根据学习方法分类："></a>根据学习方法分类：</h2><ul>
<li>无监督学习 unsupervised learning 只有正常样本训练</li>
<li>半监督学习 weakly spervised learning 以不平衡的样本比例训练</li>
<li>监督学习 spervised learning 都训练</li>
</ul>
<h2 id="视频异常检测领域未来挑战："><a href="#视频异常检测领域未来挑战：" class="headerlink" title="视频异常检测领域未来挑战："></a>视频异常检测领域未来挑战：</h2><ul>
<li>异常检测视频大部分采用mini-batch训练方法，非常消耗时间和资源，无法实时进行视频检测</li>
<li>现实的数据集，模型难以训练</li>
<li>异常的情况定义模糊</li>
<li>模型的迁移性差，shanghaiTech的数据集是多摄像头融合的数据集，大部分数据集表现一般</li>
</ul>
<h2 id="了解yolo"><a href="#了解yolo" class="headerlink" title="了解yolo"></a>了解yolo</h2><p>YOLO（You Only Look Once）系列算法是计算机视觉领域中重要的<a href="https://so.csdn.net/so/search?q=目标检测技术&amp;spm=1001.2101.3001.7020">目标检测技术</a>。凭借其高效的实时处理能力，YOLO被广泛应用于视频监控、自动驾驶等多个领域。</p>
<h1 id="论文一：Human-Action-Recognition-from-Various-Data-Modalities-A-Review"><a href="#论文一：Human-Action-Recognition-from-Various-Data-Modalities-A-Review" class="headerlink" title="论文一：Human Action Recognition from Various Data Modalities: A Review"></a>论文一：Human Action Recognition from Various Data Modalities: A Review</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><strong>人类动作识别（Human Action Recognition, HAR）</strong>旨在理解人类的行为，并为每个行为分配一个标签。</p>
<p>多种不同的数据形态都可以用来表示人类的动作和行为。这些模态可以分为2类：<strong>视觉模态和非视觉模态</strong></p>
<p>视觉模态和非视觉模态的主要区别在于：视觉模态的数据对人类行为的表示相对直观，但是非视觉模态的数据则不是。视觉模态主要包括：如RGB，骨架，深度，红外，点云，事件流（event stream）等数据模态，而非视觉模态则主要包括音频，加速度，雷达，wifi信号等数据模态</p>
<p>然而，由于不同的模态对 HAR 具有不同的优势和局限性，因此多种数据模态的融合和跨模态的知识传递以提高 HAR 的准确性和稳健性，近年来也受到了极大的关注 [23]，[24]。更具体地说，融合是指将两种或多种模态的信息组合起来，以识别动作</p>
<p>该综述对基于不同数据模态的深度学习HAR方法的最新进展做了一个综合调研。介绍调研的主要内容分为三部分</p>
<ul>
<li>当前主流的单模态深度学习方法</li>
<li>当前主流的多模态深度学习方法，包括基于融合（fusion）和协同学习（co-learning）的学习框架</li>
<li>当前HAR任务的主流数据集</li>
</ul>
<h2 id="单一模态-SINGLE-MODALITY"><a href="#单一模态-SINGLE-MODALITY" class="headerlink" title="单一模态 SINGLE MODALITY"></a>单一模态 SINGLE MODALITY</h2><h3 id="RGB模态-RGB-MODALITY"><a href="#RGB模态-RGB-MODALITY" class="headerlink" title="RGB模态 RGB MODALITY"></a>RGB模态 RGB MODALITY</h3><p>RGB 模态通常是指由 RGB 相机捕获的图像或视频（图像序列），旨在重现人眼所见。</p>
<p>RGB模态优点主要有：（1）RGB数据容易收集，通常是最常用的数据模态。（2）RGB模态包含所捕获的场景上下文的信息。（3）基于RGB的HAR方法也可以用来做pretrained model。</p>
<p>缺点主要有：（1）由于RGB数据中存在背景、视点、尺度和光照条件的变化，所以在RGB模态中进行识别通常具有挑战性。（2）RGB 视频通常具有较大的数据量，导致在为 HAR 的时空环境建模时会产生高计算成本。</p>
<p>下面介绍面向基于 RGB 的 HAR 的高级深度学习，主要可分为四大类，即双流 2D 卷积神经网络 （CNN）、递归神经网络 （RNN）、3D CNN 和基于 Transformer 的方法</p>
<p><img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/v2-4ec2f54d013bb5ab6996585c53f7755d_1440w.png" alt="v2-4ec2f54d013bb5ab6996585c53f7755d_1440w"></p>
<p><img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/sadasd.png" alt="sadasd"></p>
<h3 id="骨骼模态-SKELETON-MODALITY"><a href="#骨骼模态-SKELETON-MODALITY" class="headerlink" title="骨骼模态 SKELETON MODALITY"></a>骨骼模态 SKELETON MODALITY</h3><p>骨骼序列编码人体关节的轨迹，这些轨迹表征了信息丰富的人体运动。因此，骨架数据也是 HAR 的合适模式。</p>
<p>骨架数据提供的是身体结构与姿态信息，其具有两个明显的优点：（1）具有比例不变性。（2）对服装纹理和背景是鲁棒的。</p>
<p>但同时也有两个缺点：（1）骨架信息的表示比较稀疏，存在噪声。（2）骨架数据缺少人-物交互时可能存在的形状信息。</p>
<p><img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/v2-f3f49680590c848b02f3e7911c5d7d3c_1440w.png" alt="v2-f3f49680590c848b02f3e7911c5d7d3c_1440w"></p>
<h3 id="深度模态-DEPTH-MODALITY"><a href="#深度模态-DEPTH-MODALITY" class="headerlink" title="深度模态 DEPTH MODALITY"></a>深度模态 DEPTH MODALITY</h3><p>深度图其中像素值表示从给定视点到场景中的点的距离信息。深度模态通常对颜色和纹理的变化具有鲁棒性，提供了可靠的人体三维结构和几何形状信息，因此可用于 HAR。随着技术的发展，现在已经有多种设备可以捕获场景中的深度图。现有的对深度数据学习的方法大多数还是利用CNN提取深度图中的feature。深度数据可以提供几何形状信息，但是对外观数据的提供是缺失的，所以深度数据通常不单独使用，而是与其他模态的数据融合使用。</p>
<h3 id="红外模态-INFRARED-MODALITY"><a href="#红外模态-INFRARED-MODALITY" class="headerlink" title="红外模态 INFRARED MODALITY"></a>红外模态 INFRARED MODALITY</h3><p>通常，红外传感器不需要依赖外部环境光，因此特别适用于夜间 HARat。红外传感技术可分为有源和无源两种。一些红外传感器（如 Kinect）依赖于主动红外技术，该技术发射红外线并利用目标反射光线来感知场景中的物体。在目前基于深度学习的方法中，比较多的做法是把红外图像作为其中一个stream输入双流或多流网络中。红外数据以其不需要依赖外部环境的可见光的特点，特别适合于夜间的HAR，但是，红外图像也有着对比度低和信噪比低的固有缺点。</p>
<h3 id="点云模态-POINT-CLOUDMODALITY"><a href="#点云模态-POINT-CLOUDMODALITY" class="headerlink" title="点云模态 POINT CLOUDMODALITY"></a>点云模态 POINT CLOUDMODALITY</h3><p>点云数据由许多点集合组成，这些点表示空间参考系统下目标的空间分布和表面特征。获取 3D 点云数据有两种主要方法，即 （1） 使用 3D 传感器，例如 LiDAR 和 Kinect，或 （2） 使用基于图像的 3D 重建。点云作为一种 3D 数据模态，具有强大的能力来表示主体的空间轮廓和 3D 几何形状，因此可以用于 HAR。但是点云中通常存在噪声和高度不均匀的点分布。</p>
<h3 id="事件流模态-EVENT-STREAM-MODALITY"><a href="#事件流模态-EVENT-STREAM-MODALITY" class="headerlink" title="事件流模态 EVENT STREAM MODALITY"></a>事件流模态 EVENT STREAM MODALITY</h3><p>事件照相机（event camera）可以捕捉照明条件的变化并为每个像素独立产生异步事件。传统的摄像机通常会捕捉整个图像阵列，而事件摄像机仅响应视觉场景的变化。事件照相机能够有效地滤除背景信息，而只保留前景运动信息，这样可以避免视觉信息中的大量冗余，但是其捕捉到的信息通常在时间和空间维度上是稀疏的，而且是异步的。因此一些现有的方法主要聚焦于设计事件聚合策略，将事件摄像机的异步输出转换为同步的视觉帧。</p>
<h3 id="音频模态-AUDIO-MODALITY"><a href="#音频模态-AUDIO-MODALITY" class="headerlink" title="音频模态 AUDIO MODALITY"></a>音频模态 AUDIO MODALITY</h3><p>音频信号通常与视频信号一起提供，由于音频和视频是同步的，所以音频数据可以用定位动作。因为音频信号中的信息量是不足的，所以单独使用音频数据执行HAR任务相对比较少见。更常见的情况是音频信号作为HAR的补充信息，与其他模态（如rgb图像）一起使用。</p>
<h3 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h3><p>还有加速度模态，雷达模态，wifi模态，我先不了解，后续若有需要再完善知识</p>
<h2 id="多模态-MULTI-MODALITY"><a href="#多模态-MULTI-MODALITY" class="headerlink" title="多模态 MULTI-MODALITY"></a>多模态 MULTI-MODALITY</h2><p>在现实生活中，人类经常以多模态认知方式感知环境。同样，多模态机器学习是一种建模方法，旨在处理和关联来自多种模态的感觉信息[358]。通过聚合各种数据模态的优势和功能，多模态机器学习通常可以提供更强大、更准确的 HAR。</p>
<p>多模态学习方法主要有两种，融合（fusion）和协同学习（co-learning）。其中融合指的是对来自两个或更多模态的信息进行集成，并将其用于训练或推理，而协同学习指的则是对不同模态之间的知识进行迁移。图4展示了多模态学习方法的分类</p>
<p><img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/v2-04335982349266acffdb93355ce2686c_1440w.png" alt="v2-04335982349266acffdb93355ce2686c_1440w"></p>
<h3 id="HAR任务中的多模态融合"><a href="#HAR任务中的多模态融合" class="headerlink" title="HAR任务中的多模态融合"></a>HAR任务中的多模态融合</h3><p>模态融合的目的是利用不同数据模态的互补优势，以达到更好的识别性能。现有的多模态融合方案主要有两种：（1）评分融合（score fusion），即对不同模态输出的score做融合，例如使用加权平均或学习一个分数融合模型。（2）特征融合，即对来自不同模态的特征进行组合。数据融合（在特征提取之前就融合不同模态的输入数据）可以看成是特征融合，因为某一模态的数据数据可以被视为该模态的原始特征。</p>
<p>依据输入模态的不同，现有的多模态融合方法大概可以分为视觉模态之间的融合，与视觉+非视觉模态之间的融合两种</p>
<h4 id="视觉模态之间的融合"><a href="#视觉模态之间的融合" class="headerlink" title="视觉模态之间的融合"></a><strong>视觉模态之间的融合</strong></h4><ol>
<li>RGB+深度模态：RGB和深度模态分别能够捕捉外观信息和3D形状信息，因此它们具有比较强的互补性。</li>
<li>RGB+骨架模态：骨架模态可以提供身体位置和关节运动信息，同样和RGB模态是互补的。[28]提出了一个双流深度网络，两个stream分别是CNN和RNN，用以分别处理RGB和骨架数据，融合方式同时尝试了特征融合和分数融合，并发现应用特征融合策略可以取得更好的效果。</li>
<li>深度图+骨架模态：[31]将身体的每个部分与其他部分之间的相对几何关系作为骨架特征，将不同身体部分周围的深度图像块作为外观特征，以编码身体-对象和身体部分-身体部分之间的关系，进而实现可靠的HAR。</li>
<li>RGB+深度图+骨架模态：这类方法大多是前文提到了三类多模态融合方法的扩展。</li>
</ol>
<h4 id="视觉模态-非视觉模态的融合"><a href="#视觉模态-非视觉模态的融合" class="headerlink" title="视觉模态+非视觉模态的融合"></a><strong>视觉模态+非视觉模态的融合</strong></h4><ol>
<li>视频与音频的融合：前文中已经提到，音频可以为视频的外观和运动信息提供补充信息。所以目前已经有一些基于深度学习的方法来融合这种模态的数据</li>
<li>视频与加速度模态的融合</li>
<li>其他类型的模态融合：[43]的核心思想是将非RGB模态的数据，包括骨架、加速度和wifi数据都转换成彩色图像，然后送入CNN中。</li>
</ol>
<h3 id="HAR任务中的多模态协同学习"><a href="#HAR任务中的多模态协同学习" class="headerlink" title="HAR任务中的多模态协同学习"></a>HAR任务中的多模态协同学习</h3><p>多模态协同学习旨在探索如何利用辅助模态学习到的知识帮助另一个模态的学习，希望通过跨模态的知识传递和迁移可以克服单一模态的缺点，提高性能。多模态协同学习与多模态融合的一个关键区别在于，在多模态协同学习中，辅助模态的数据仅仅在训练阶段需要，测试阶段并不需要。所以多模态协同学习尤其适用于模态缺失的场景。此外对于模态样本数较小的场景，多模态协同学习也可以起到一定的帮助作用。</p>
<h4 id="视觉模态的协同学习"><a href="#视觉模态的协同学习" class="headerlink" title="视觉模态的协同学习"></a><strong>视觉模态的协同学习</strong></h4><ol>
<li>RGB和深度模态的协同学习</li>
<li>RGB和骨架模态的协同学习。如[48]利用CNN+LSTM执行基于RGB视频的分类，并利用在骨架数据上训练的LSTM模型充当调节器，强制两个模型的输出特征相似。</li>
</ol>
<h4 id="视觉和非视觉模态的协同学习"><a href="#视觉和非视觉模态的协同学习" class="headerlink" title="视觉和非视觉模态的协同学习"></a><strong>视觉和非视觉模态的协同学习</strong></h4><p>第一种类型是在不同模态之间进行知识的迁移，如[50]中的teacher network使用非视觉模态训练，而student network使用RGB模态作为输入，通过强制teacher和student的attention map相似以弥补模态间的形态差距，并实现知识的提炼。</p>
<p>第二种类型是利用不同模态之间的相关性进行自监督学习，比如[51]分别利用音频/视频模态中的无监督聚类结果作为视频/音频模态的监督信号。[52]使用视频和音频的时间同步信息作为自监督信号。</p>
<h1 id="论文二：RWF-2000-An-Open-Large-Scale-Video-Database-for-Violence-Detection"><a href="#论文二：RWF-2000-An-Open-Large-Scale-Video-Database-for-Violence-Detection" class="headerlink" title="论文二：RWF-2000: An Open Large Scale Video Database for Violence Detection"></a>论文二：RWF-2000: An Open Large Scale Video Database for Violence Detection</h1><p><a href="https://github.com/mchengny/RWF2000-Video-Database-for-Violence-Detection">mchengny/RWF2000-Video-Database-for-Violence-Detection：一个用于暴力检测的大型视频数据库，其中包含 2,000 个包含暴力或非暴力行为的视频剪辑。</a></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>近年来，监控摄像头在公共场所广泛部署，由于这些无处不在的设备，总体犯罪率已显著降低。通常，这些摄像头会在犯罪发生后提供线索和证据，而很少用于及时预防或制止犯罪活动。手动监控来自监控摄像头的大量视频数据既费时又费力。因此，从视频信号中自动识别暴力行为变得至关重要。</p>
<p>本文总结了几个现有的用于暴力检测的视频数据集，并提出了 RWF-2000 数据库，其中包含监控摄像头在真实场景中捕获的 2,000 个视频。此外，我们还提出了一种同时利用 3D-CNN 和光流优点的新方法，即流门控网络。所提出的方法在我们提出的数据库的测试集上获得了 87.25% 的准确率。数据库和源代码目前对 Access 1 开放。</p>
<h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>通常，基于视频的暴力检测的定义是检测视频数据中的暴力行为。它是人类动作识别的一个子集，旨在识别常见的人类动作。与静止图像相比，视频数据具有额外的时间序列。一组连续的帧表示连续的运动，而相邻的帧由于帧间相关性高而包含冗余信息。</p>
<p>一些早期的方法依赖于检测高度相关物体（例如，枪击、火焰、血腥、爆炸）的存在，而不是直接识别暴力事件</p>
<p>此前数据的劣势：尽管存在一些用于暴力检测的视频数据集，但它们仍然存在规模小、多样性少和图像分辨率低的缺点。此外，一些具有高图像质量的相关数据集来自电影，这些电影与真实场景不够接近。为解决真实暴力活动中高质量数据不足的问题</p>
<p>本文工作：</p>
<ol>
<li>为了解决真实暴力活动中高质量数据不足的问题，我们收集了一个新的视频数据集 （RWF-2000） 并将其免费发布给研究界。该数据集规模较大，包含从监控视频中提取的 2,000 个剪辑</li>
<li>我们提出了一种新的具有自学习池机制的模型，该模型可以很好地兼顾外观特征和时间特征。</li>
</ol>
<h2 id="先前数据集"><a href="#先前数据集" class="headerlink" title="先前数据集"></a>先前数据集</h2><p>根据注释方法，仍然存在两种用于暴力检测的视频数据集：修剪和未修剪。裁剪后的数据集中的视频都是几秒长的短片，每个视频都有一个视频级标注。而视频未修剪的数据集通常具有更长的持续时间。此外，暴力活动的开始时间和结束时间都有帧级注释。</p>
<p>总结这些提议的数据集，每个数据集都至少具有以下一个或多个限制：</p>
<ul>
<li>图像质量低;缺乏足够的数据量</li>
<li>视频时长但注释粗糙</li>
<li>与现实暴力不够接近的视频混合来源</li>
</ul>
<p>为了解决上述问题，我们从 YouTube 网站收集了一个新的 RWF 2000（真实世界格斗）数据集，其中包括 2,000 个由监控枪式摄像机从真实场景中拍摄的修剪视频剪辑。</p>
<h2 id="先前方法"><a href="#先前方法" class="headerlink" title="先前方法"></a>先前方法</h2><p>传统方法通常会尝试找到一个 powfer 特征提取算法，并实现一个基于机器学习的分类器来完成暴力检测任务。</p>
<p>总之，基于深度学习的方法通常优于传统的基于特征提取的模型。此外，大多数最先进的结果都使用多通道输入（例如，原始 RGB 图像、光流、加速度图）。同时，复杂模型对过拟合不是很鲁棒。</p>
<p>在本文中，我们只采用 RGB 图像和光流来构建神经网络，它可以处理空间和时间信息。此外，我们提出的 Flow-Gated 架构可以通过自学习来减少输入视频的时间通道，而不是传统的池化策略。</p>
<h2 id="RWF-2000-数据库和建议的方法"><a href="#RWF-2000-数据库和建议的方法" class="headerlink" title="RWF-2000 数据库和建议的方法"></a>RWF-2000 数据库和建议的方法</h2><h3 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h3><p>为了使暴力检测在现实应用中更加实用，我们从 YouTube 平台收集了一个新的真实世界格斗 （RWF） 数据集，其中包含监控摄像头在真实场景中拍摄的 2,000 个视频剪辑。</p>
<p>拟议的数据集有 2,000 个视频剪辑，分为两部分：训练集 （80%） 和测试集 （20%）。一半的视频包含暴力行为，而其他视频属于非暴力活动。</p>
<h3 id="Flow-Gated-Network"><a href="#Flow-Gated-Network" class="headerlink" title="Flow Gated Network"></a>Flow Gated Network</h3><p>以前的大多数方法都探索从单个帧中提取外观特征，然后将它们融合以对时间信息进行建模。由于粗略的池化机制，运动信息可能毫无用处，我们的目标是设计一种通过网络自学习实现的时间池化机制</p>
<p><img src="/2024/11/15/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B/asdasf.png" alt="asdasf"></p>
<p>由四个部分组成：RGB 通道、光流通道、合并块和全连接层。RGB 通道和光流通道由级联的 3D CNN 组成，它们具有一致的结构，因此它们的输出可以融合。Merging Block 也由基本的 3D CNN 组成，这些 CNN 在自学时间池化后处理信息。最后，全连接层生成输出。</p>
<p>该模型的亮点是利用光流通道的一个分支来帮助构建池化机制。</p>
<h1 id="后续学习"><a href="#后续学习" class="headerlink" title="后续学习"></a>后续学习</h1><p><a href="https://blog.csdn.net/qq_32892383/article/details/136413119">基于YOLOv8/YOLOv7/YOLOv6/YOLOv5的暴力行为检测系统（深度学习模型+UI界面+Python代码+训练数据集）-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/qq_42681787/article/details/134423818">YOLO8实战：暴力行为检测系统_yolov8 打架检测-CSDN博客</a></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://www.bilibili.com/video/BV1aR4y1J7uv/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">科研分享|视频异常检测_哔哩哔哩_bilibili</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/553262457">[领域综述] TPAMI 2022 | Human Action Recognition from Various Data Modalities: A Review - 知乎</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/105360879">RWF-2000 暴力行为检测视频数据集 - 知乎</a></p>
<p>另一个暴力行为数据集<a href="https://roc-ng.github.io/XD-Violence/">XD-暴力</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——基础知识储备</title>
    <url>/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/</url>
    <content><![CDATA[<h1 id="学习计划"><a href="#学习计划" class="headerlink" title="学习计划"></a>学习计划</h1><ul>
<li>[ ] yolo深入学习，代码初步运行尝试</li>
<li>[x] 视频异常检测与视频动作识别的概念明晰与区分</li>
<li>[ ] 实际操作知识储备：视频预处理，训练，测试</li>
<li>[x] 具体算法知识储备：<strong>3D CNN</strong> ，<strong>2D CNN + RNN</strong>，<strong>LSTM</strong></li>
<li>[x] 根据PPT初步构建立项书框架</li>
</ul>
<h1 id="视频异常检测与视频动作识别的概念明晰与区分"><a href="#视频异常检测与视频动作识别的概念明晰与区分" class="headerlink" title="视频异常检测与视频动作识别的概念明晰与区分"></a>视频异常检测与视频动作识别的概念明晰与区分</h1><p>我们后续做的主要是<strong>暴力行为的识别</strong>，我个人原本概念并没有清楚，以为是属于视频异常检测领域，但这里更关注的是人的动作，应该与视频动作识别更贴合，以下是我结合网上文章理解的二者区别，用词不严谨处还请指正</p>
<p>视频异常检测系统能够检测明显偏离正常的异常行为或实体，例如在视频监控的先验知识有限的情况下识别多个移动物体，或检测特定事件，例如打架、踩踏、交通事故和流浪。<strong>视频异常通常是上下文的，并根据真实场景定义</strong>。具体来说，检测过程集中于识别所有视频中包含异常的视频片段，而定位致力于确定哪一帧是异常的，并解释该帧的哪一部分是异常的。</p>
<p><strong>视频动作识别</strong>是通过已标记的数据集训练模型实现视频理解视频分类的功能。动作识别的目标是识别出视频中出现的动作，通常是视频中人的动作。视频可以看作是由一组图像帧按时间顺序排列而成的数据结构，比图像多了一个时间维度。动作识别不仅要分析视频中每帧图像的内容，还需要从视频帧之间的时序信息中挖掘线索。动作识别是视频理解的核心领域，虽然动作识别主要是识别视频中人的动作，但是该领域发展出来的算法大多数不特定针对人，也可以用于其他视频分类场景。</p>
<h1 id="二维卷积-2D-CNN"><a href="#二维卷积-2D-CNN" class="headerlink" title="二维卷积 2D CNN"></a>二维卷积 2D CNN</h1><p>卷积神经网络（convolutional neural network）是含有卷积层（convolutional layer）的神经网络。它有高和宽两个空间维度，常用来处理图像数据。</p>
<h2 id="卷积神经网络的结构"><a href="#卷积神经网络的结构" class="headerlink" title="卷积神经网络的结构"></a>卷积神经网络的结构</h2><p>层级网络，数据包括输入层，卷积层，激活层，池化层，全连接层等</p>
<p><strong>输入层</strong>：就是原始图像，非提取的信息，因此卷积神经网络是一个无监督的特征学习网络，数据输入层主要对原始图像数据进行预处理，基础的操作包括去均值、灰度归一化，数据增强等；</p>
<p><strong>卷积层</strong>：就是特征提取层，一般卷积神经网络包含多个卷积层，一个卷积层可以有多个不同的卷积核。通过不同的多个卷积核对图像进行预处理，提取特征，每个卷积核会映射出新的特征平面。再通过非线性激活函数对卷积结果进行处理；</p>
<p><strong>激活层</strong>：卷积神经网络需要激活层进行特征的选择和抑制；</p>
<p><strong>池化层</strong>：用于降低特征平面分辨率及抽象特征，可以有效的压缩网络参数和数据，减少过拟合。池化层最主要的作用就是压缩图像同时保存图像的特征不变；</p>
<p><strong>全连接层</strong>：是卷积神经网络的最后，具有卷积核和偏移量两个参数。（fully connected layers，FC）在整个卷积神经网络中起到“分类器”的作用，全连接层则起到将学到的“分布式特征表示”映射到样本标记空间的作用。在实际使用中，全连接层可由卷积操作实现：对前层是全连接的全连接层可以转化为卷积核为1x1的卷积；而前层是卷积层的全连接层可以转化为卷积核为hxw的全局卷积，h和w分别为前层卷积结果的高和宽</p>
<p><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/3c266da23107494b04b09683b8427f0e.png" alt="3c266da23107494b04b09683b8427f0e"></p>
<p>卷积核的运算</p>
<p><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/7b8af7c9507e7652df6ff7e3c14f8a1f.png" alt="7b8af7c9507e7652df6ff7e3c14f8a1f"></p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>2D卷积神经网络（2D CNN）则主要用于处理二维图像数据，如<a href="https://cloud.baidu.com/product/face">人脸识别</a>、物体检测和自动驾驶等任务。2D CNN通过将图像划分为多个小的矩形区域（也称为滤波器或卷积核），可以对每个区域进行<strong>独立的特征提取</strong>。这种网络结构可以有效地减少计算量，同时提高特征提取的精度。在计算机视觉领域，2D CNN已经成为许多重要应用的基石，如人脸识别和目标检测等。</p>
<h1 id="三维卷积-3D-CNN"><a href="#三维卷积-3D-CNN" class="headerlink" title="三维卷积 3D CNN"></a>三维卷积 3D CNN</h1><p>三维卷积输入多了深度C这个维度，输入是高度H<em>宽度W</em>深度C的三维矩阵。</p>
<p><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/7d1a499a0a3c3a43c7677e57c85e1890.png" alt="7d1a499a0a3c3a43c7677e57c85e1890"></p>
<p>3D CNN是如何对时间维度进行操作的，如下图所示，我们将时间维度看成是第三维，这里是对连续的四帧图像进行卷积操作，3D卷积是通过堆叠多个连续的帧组成一个立方体，然后在立方体中运用3D卷积核。在这个结构中，卷积层中每一个特征map都会与上一层中多个邻近的连续帧相连，因此捕捉运动信息。<br><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/f8c08dd50063b71d02bbfe5c73c364dd.png" alt="f8c08dd50063b71d02bbfe5c73c364dd"></p>
<h2 id="三维卷积和多通道卷积的区别"><a href="#三维卷积和多通道卷积的区别" class="headerlink" title="三维卷积和多通道卷积的区别"></a>三维卷积和多通道卷积的区别</h2><h3 id="多通道卷积"><a href="#多通道卷积" class="headerlink" title="多通道卷积"></a>多通道卷积</h3><p><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/61bbb9de76c74320cb9d22077a128612.jpg" alt="61bbb9de76c74320cb9d22077a128612"></p>
<p>具体的实现过程为：</p>
<p><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B2/968772caaeba0e8b02257717f4019d97.png" alt="968772caaeba0e8b02257717f4019d97"></p>
<p>   3D CNN主要运用在视频分类、动作识别等领域，它是在2D CNN的基础上改变而来。由于2D CNN不能很好的捕获时序上的信息，因此我们采用3D CNN，这样就能将视频中时序信息进行很好的利用。</p>
<h1 id="循环神经网络-RNN-与-长短期记忆-LSTM"><a href="#循环神经网络-RNN-与-长短期记忆-LSTM" class="headerlink" title="循环神经网络 RNN 与 长短期记忆 LSTM"></a>循环神经网络 RNN 与 长短期记忆 LSTM</h1><p><a href="https://zhuanlan.zhihu.com/p/123211148">史上最详细循环神经网络讲解（RNN/LSTM/GRU） - 知乎</a></p>
<p><a href="https://www.bilibili.com/video/BV1z5411f7Bm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【循环神经网络】5分钟搞懂RNN，3D动画深入浅出_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1Z34y1k7mc?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【LSTM长短期记忆网络】3D模型一目了然，带你领略算法背后的逻辑_哔哩哔哩_bilibili</a></p>
<h1 id="立项书框架构建"><a href="#立项书框架构建" class="headerlink" title="立项书框架构建"></a>立项书框架构建</h1><h2 id="工作清单"><a href="#工作清单" class="headerlink" title="工作清单"></a>工作清单</h2><ol>
<li>每个人写一份自我介绍，包括自身具备的知识条件、自己的特长、兴趣、已有的实践创新成果</li>
<li>每个人查找8篇关于人体动作识别或者暴力事件识别的相关论文，要求：1.国内外论文都要有  2.每个人找好后打成一个压缩包发群里，并把论文名发群里，后面发的就不要跟上面重复了  3.压缩包中除了包含论文，再有一个word文档，简单说明收集每个论文的主要内容</li>
<li>简单看一下我发群里的两份去年的立项书，结合立项书框架想一想，后续会进行分工</li>
</ol>
<h2 id="立项书框架"><a href="#立项书框架" class="headerlink" title="立项书框架"></a>立项书框架</h2><ol>
<li>项目研究背景<ol>
<li>研究意义</li>
<li>国内外研究现状<ol>
<li>人类动作识别现状</li>
<li>暴力行为识别现状</li>
</ol>
</li>
<li>项目研究目标及主要内容</li>
<li>项目创新特色概述</li>
<li>项目研究技术路线</li>
<li>项目方案设计</li>
</ol>
</li>
</ol>
<h2 id="PPT思路初步构建"><a href="#PPT思路初步构建" class="headerlink" title="PPT思路初步构建"></a>PPT思路初步构建</h2><h3 id="背景与意义"><a href="#背景与意义" class="headerlink" title="背景与意义"></a>背景与意义</h3><ol>
<li>人体行为事件的含义与应用</li>
<li>视频暴力行为识别的意义</li>
<li>暴力行为的定义，早期与后续方法的比较，数据集的比较，暴力行为识别任务和应用</li>
</ol>
<h3 id="研究现状"><a href="#研究现状" class="headerlink" title="研究现状"></a>研究现状</h3><p>单模态与多模态的优点和挑战</p>
<p>行为识别和暴力行为的识别和挑战</p>
<p>数据集的对比</p>
<p>解决方法的比较：3D CNN, 2D CNN+ RNN, 骨架</p>
<h3 id="研究方法：抓住识别暴力的要素"><a href="#研究方法：抓住识别暴力的要素" class="headerlink" title="研究方法：抓住识别暴力的要素"></a>研究方法：抓住识别暴力的要素</h3><p>一方面：抓住重要因素进行特征提取</p>
<p>另一方面：尽可能去除冗余信息（裁剪 / 去背景）</p>
<p>算法框架</p>
<p>注意力融合模块</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol>
<li>提出了一种基于多模态特征融合的视频暴力行为识别算法。通过融合RGB模态提供的外观信息、RGB帧差提供的运动信息以及Depth模态提供的相对位置信息，丰富、完善了暴力行为的特征，使其能够准确、鲁棒地在复杂的真实环境下进行暴力行为识别。</li>
</ol>
<ol>
<li>提出了一种自适应的注意力算法用于多模态融合。让模型自适应地学习不同模态特征之间的权重关系，允许模型根据具体任务动态调整每个模态的重要性，从而更灵活地应对不同的场景。</li>
</ol>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://blog.csdn.net/qq_63019407/article/details/125805364">【视频异常检测综述-论文阅读】Deep Video Anomaly Detection: Opportunities and Challenges-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/Yong_Qi2015/article/details/120837919">视频理解综述：动作识别、时序动作定位、视频Embedding-CSDN博客</a></p>
<p><a href="https://blog.csdn.net/YOULANSHENGMENG/article/details/121328554">深度学习笔记——三维卷积及其应用（3DCNN,PointNet,3D U-Net）-CSDN博客</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——论文筛选</title>
    <url>/2024/11/19/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B3%E2%80%94%E2%80%94%E8%AE%BA%E6%96%87%E7%AD%9B%E9%80%89/</url>
    <content><![CDATA[<p>本文对目前已收集到的论文进行筛选工作，并简单概述可取之处</p>
<h1 id="视频监控中人体暴力行为检测系统设计与应用"><a href="#视频监控中人体暴力行为检测系统设计与应用" class="headerlink" title="视频监控中人体暴力行为检测系统设计与应用"></a>视频监控中人体暴力行为检测系统设计与应用</h1><p>非常非常好的一篇，跟我们要做的方向很贴合，每个人都要看一下，以下是我认为可以学习的地方：</p>
<ol>
<li><p>绪论部分：课题研究的背景和意义；从智能视频监控技术和行为识别算法两个方面介绍了研究现状</p>
</li>
<li><p>同样选用了RWF-2000数据集，并给出了理由，同时介绍了三大常见数据集并进行了比较（HMDB-51，UCF101，Kinetics）；在模型框架技术选型方面，简要介绍了 传统方法，然后对比了深度学习下的基于人体骨架的方法以及基于视频的方法。 之后详细介绍了三类基于视频的深度学习方法（双流法，3D卷积方法 和基于时序模型的方法）</p>
</li>
</ol>
<p>​    本文文采用了双流模型 作为基础框架，我后续了解双流法与我们的    多模态方向是很贴合的</p>
<ol>
<li>本文完成了人体暴力行为检测系统的设计与实现，包含离线分析和在线监测两种模式，这跟我们的设想很符合</li>
</ol>
<h1 id="基于注意力机制的暴力音视频检测方法研究"><a href="#基于注意力机制的暴力音视频检测方法研究" class="headerlink" title="基于注意力机制的暴力音视频检测方法研究"></a>基于注意力机制的暴力音视频检测方法研究</h1><p>与上一篇同样是哈尔滨工业大学的硕士论文，侧重点也是多模态暴力检测，本文先提出分别基于视觉通道和基于听觉通道的暴力音频检测，再提出了基于视听觉通道的音视频特征融合的暴力音视频检测</p>
<p>本文开头的课题研究的背景和意义和研究现状同样值得参考</p>
<h1 id="基于多模态的校园暴力检测"><a href="#基于多模态的校园暴力检测" class="headerlink" title="基于多模态的校园暴力检测"></a>基于多模态的校园暴力检测</h1><p>给我感觉一般，多模态的部分写的并不是很好，他还说的一个基于多模态的校园暴力检测，感觉什么都写到了什么都写的不是很精</p>
<p>但是他在相关理论基础详细地介绍了深度学习网络（RNN，LSTM，GRU）和人体动作识别（openpose），可以参考学习</p>
<h1 id="基于对比学习的视频暴力行为检测算法及-TensorRT-平台实现"><a href="#基于对比学习的视频暴力行为检测算法及-TensorRT-平台实现" class="headerlink" title="基于对比学习的视频暴力行为检测算法及 TensorRT 平台实现"></a>基于对比学习的视频暴力行为检测算法及 TensorRT 平台实现</h1><p>里面的对比学习和注意力机制不是很看得懂，但感觉写的挺好的，这篇还把识别系统做在TensorRT 平台实现轻量化，这个跟我们关系不大，只做了解</p>
<h1 id="基于YOLO和ConvLSTM混合神经网络的暴力视频检测"><a href="#基于YOLO和ConvLSTM混合神经网络的暴力视频检测" class="headerlink" title="基于YOLO和ConvLSTM混合神经网络的暴力视频检测"></a>基于YOLO和ConvLSTM混合神经网络的暴力视频检测</h1><p>有yolo相关知识，后续可做参考学习</p>
<h1 id="国外论文"><a href="#国外论文" class="headerlink" title="国外论文"></a>国外论文</h1><p>因为英文看的太费劲，对国外论文暂时只做初步筛选</p>
<p>Conv3D-Based Video Violence Detection Network Using Optical<br>Flow and RGB Data：光流和RGB数据多模态</p>
<p>Multimodal vision-based human action recognition using deep learning: a review：关于多模态的综述论文，这一篇写的不错，有时间值得啃一下</p>
<p>A Real-Time 3-Dimensional Object Detection Based Human Action Recognition Model：3D卷积神经网络（3DCNN）、LSTM乘法递归网络和YOLOv6实时目标检测</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——模型环境配置</title>
    <url>/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h3 id="模型环境配置"><a href="#模型环境配置" class="headerlink" title="模型环境配置"></a>模型环境配置</h3><p>利用yml导入conda虚拟环境</p>
<p><img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/sad.png" alt="sad"></p>
<p>安装cuda与cudnn</p>
<p><a href="https://blog.csdn.net/weixin_44779079/article/details/141528972">cuda和cudnn的安装教程(全网最详细保姆级教程)_cudnn安装-CSDN博客</a></p>
<p>使用国内源安装</p>
<p><code>pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p><code>pip install --upgrade tensorflow -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<p>测试gpu运行</p>
<p><img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/as.png" alt="as"></p>
<p><img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/daf.png" alt="daf"></p>
<p>根据提示补全依赖项</p>
<p>datasetProcess.py 将视频文件转换为 NumPy 数组（.npy 文件），并保存到指定目录中</p>
<p>models_rgb_depth.py 模型</p>
<p>evaluate_rgb_depth.py 跑数据集，返回准确度</p>
<p><img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/asd.png" alt="asd"></p>
<p>prediction_test.py 返回true or false</p>
<p><img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/sadff.png" alt="sadff"></p>
<p>前两者需要输入命令行参数</p>
<p><code>python evaluate_rgb_depth.py --dataset rwf2000 --vidLen 32 --batchSize 4 --mode all --lstmType sepconv --fusionType C --weightsPath models/rgb_rgbdiff_depth_C_6/rwf2000_best_val_acc_Model</code></p>
<p><img src="/2025/01/21/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/gadga.png" alt="gadga"></p>
<ul>
<li><code>--dataset rwf2000</code>: 指定数据集为 <code>rwf2000</code>。</li>
<li><code>--vidLen 32</code>: 每个视频序列的帧数为 32。</li>
<li><code>--batchSize 4</code>: 训练和评估的批量大小为 4。</li>
<li><code>--mode all</code>: 模型工作模式为 <code>all</code>，即使用视频帧、帧差和深度图三种输入。</li>
<li><code>--lstmType sepconv</code>: 使用 <code>sepconv</code> 类型的 LSTM 层。</li>
<li><code>--fusionType C</code>: 使用 <code>C</code> 类型的融合策略（特征拼接和注意力机制）。</li>
<li><code>--weightsPath models/rgb_rgbdiff_depth_C_6/rwf2000_best_val_acc_Model</code>: 指定预训练权重文件路径。</li>
</ul>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>大创——立项答辩</title>
    <url>/2024/12/08/%E7%A7%91%E7%A0%94/%E5%A4%A7%E5%88%9B/%E5%A4%A7%E5%88%9B4%E2%80%94%E2%80%94%E7%AB%8B%E9%A1%B9%E7%AD%94%E8%BE%A9/</url>
    <content><![CDATA[<h2 id="答辩稿"><a href="#答辩稿" class="headerlink" title="答辩稿"></a>答辩稿</h2><p>各位评委老师大家好，我是我们组的主持人张熙浚，我们组的研究方向是基于多模态特征融合的视频暴力行为识别方法的研究</p>
<p>接下来我会从四个方面介绍我们的项目</p>
<p>首先是背景与意义，暴力行为对社会危害极大，即使公共场所存在大量监控摄像头，但这些视频片段通常被用来在暴力犯罪发生后提供线索和证据，而很少被用来实时监控并阻止暴力行为。</p>
<p>由于监控人员不可能实时监控每一个摄像头产生的视频，所以部署暴力行为监测系统，能够节约人力资源，降低监控人员因疲劳而造成的风险，这十分关键</p>
<p>接下来，我将讲述当前暴力行为检测的研究现状。主流的人体动作识别把数据模态分为2类：视觉模态和非视觉模态。不同模态的数据有着各自的独特优势。</p>
<p>目前主流的单模态深度学习方法存在以下缺点。但真实的暴力事件场景往往存在以下特点。因此，我们提出了基于多模态的暴力事件检测，通过结合多种数据来源，从多个角度捕捉行为特征，尤其是在面对复杂环境、多人交互和遮挡等问题时，具有显著的优势。</p>
<p>接下来我会通过几篇论文中的方法介绍行为识别算法的研究现状</p>
<p>这一篇提出了数据集Rwf-2000，同时提出一种的双流网络架构，他们充分利用了RGB数据提供的外观信息和光流提供的运动信息，但缺点在于光流法计算量大、存储成本高，仅仅适用于光照条件良好、不拥挤的情况</p>
<p>这一篇是基于骨架的方法，通过提取人体骨骼关节，构成三维骨架阵列，通过骨架点卷积，实现分类。</p>
<p>优点是骨架可以很好的表示人体运动信息，但问题在于仅使用骨架数据，效果高度依赖于位姿估计的精度，无法有效应对存在遮挡的情况，同时因为仅使用骨架数据，其他信息存在缺失</p>
<p>这一篇是基于 2D CNN + RNN 的方法，2D CNN 提供强大的空间特征提取能力，RNN 提供强大的时间序列建模能力。将两者结合，能够更好地理解视频中的空间和时间信息。这一篇使用简单快速的预处理方法减少了冗余的背景信息，但其仅使用RGB模态，提取的特征不够全面</p>
<p>接下来我将介绍我们的研究内容与方法</p>
<p>我们的研究内容大致包含三个部分：1.提出一种基于多模态特征融合的视频暴力行为识别算法2.提出一种自适应的注意力算法用于多模态融合3.完成人体暴力行为检测系统的设计，接下来我将依次为大家介绍</p>
<p>第一部分，在特征提取阶段，为了区分暴力行为与非暴力行为，我们选择了三个要素进行提取：人体姿态、运动趋势和幅度、人物之间的位置关系，为了获取以上三个要素，研究工作包括下列内容： </p>
<p>a.RGB模态的去除冗余信息<br>为了避免原生RGB图像冗余信息影响模型判断，我们决定对于原生RGB图像进行冗余信息去除工作，首先计算一个视频中所有帧的均值，记为平均帧，用每一帧减去平均帧：去除不变的背景，保留运动的人体。</p>
<p>b.运动趋势与幅度特征的提取<br>目前主流反映物体运动趋势的方法是光流法，但我们考虑到光流图像在低像素复杂场景下效果不佳，且易受光照条件改变，并且计算量巨大，于是我们决定采取帧差法，通过对视频图像序列中相邻两帧作差分运算，来获得运动目标轮廓，以很好地适用于存在多个运动目标的情况。</p>
<p>c.深度模态的提取<br>在原始的RGB模态，复杂场景中难以分辨人物间的相对位置关系。因此，我们选取深度模态，其去除了颜色和纹理信息，并提供三维结构信息和人体轮廓，我们利用该论文提出的深度估计算法，对原始RGB视频进行深度估计，得到深度图，其清晰地反映了三维空间中人物间的相对位置关系。</p>
<p>算法框架方面，我们选择了CNN-LSTM的深度学习网络<strong>。</strong>LSTM擅长处理时序数据，而CNN能够从视频帧中提取空间特征。通过结合两者的优势，并以此构建了算法框架。</p>
<p>第二部分我们提出了一种自适应的注意力算法用于多模态融合，动态调整每个模态的权重，强调有用的信息特征，抑制不太有用的特征，从而应对不同场景。</p>
<p>池化，全连接层，归一化函数</p>
<p>第三部分，我们完成了人体暴力行为检测系统的设计，刻画了系统的边界及大小，人体暴力行为检测系统是一个自动检测暴力行为的智能视频监控系统。该系统采用了四层架构，即访问层，表示层、业务层以及数据层。 包含暴力检测模块，用户管理模块，视频源管理模块</p>
<p>我们已经初步构建了暴力行为的检测流程，系统包含离线分析和在线监测两种模式</p>
<p>为了提高检测速度和避免资源浪费，根据传入视频的总帧数进行判断，采取提示过短、一次预测或是多轮预测。</p>
<p>离线分析不依赖实时的监控视频，可对任意视频进行分析。它 的优点是它不依赖于视频监控系统，可以直接选择视频开始分析。</p>
<p>在线监测是暴力行为检测系统提供的另一种检测方式。它旨在利用监控视频资源，进行实时的暴力行为检测，达到即时分析并报警提示的功能。</p>
<p>最后是进度安排，我们已经完成算法大部分的编写，后续会继续完成系统的开发</p>
<p>谢谢各位老师观看，请各位老师批评指正</p>
<h2 id="疑问与解惑"><a href="#疑问与解惑" class="headerlink" title="疑问与解惑"></a>疑问与解惑</h2><h3 id="为什么暴力行为检测隶属于人体行为识别"><a href="#为什么暴力行为检测隶属于人体行为识别" class="headerlink" title="为什么暴力行为检测隶属于人体行为识别"></a>为什么暴力行为检测隶属于人体行为识别</h3><p>人体行为识别（Human Activity Recognition, HAR）是一个广泛的领域，旨在通过传感器或视频数据来识别和分析人的各种动作或行为。暴力行为检测（Violent Behavior Detection, VBD）是这一领域的一个子任务，其核心目标是识别出具有暴力性质的特定行为，如打斗、推搡、殴打等。</p>
<p>暴力行为检测隶属于人体行为识别，主要原因是暴力行为本质上也是一种“人体行为”，通过分析人体的运动模式、姿态变化、动作轨迹等特征，能够有效识别出暴力事件。</p>
<h3 id="对于暴力行为的定义是什么？"><a href="#对于暴力行为的定义是什么？" class="headerlink" title="对于暴力行为的定义是什么？"></a>对于暴力行为的定义是什么？</h3><p>暴力行为通常指的是一种以伤害他人或具有威胁性、攻击性目的的行为。</p>
<h3 id="之前的暴力行为检测方向是什么，现在侧重于人体动作本身有什么好处吗？"><a href="#之前的暴力行为检测方向是什么，现在侧重于人体动作本身有什么好处吗？" class="headerlink" title="之前的暴力行为检测方向是什么，现在侧重于人体动作本身有什么好处吗？"></a>之前的暴力行为检测方向是什么，现在侧重于人体动作本身有什么好处吗？</h3><p>暴力行为的检测方法<strong>传统上</strong>主要依赖于视频监控中检测到的图像信息、声音信号以及动作的特征。早期的检测方法侧重于基于背景和环境的变化,声学信号分析</p>
<p>现代的暴力行为检测越来越注重<strong>人体动作本身的识别</strong>，这有几个显著的好处：</p>
<ol>
<li><strong>精确度提高</strong>：通过分析人体动作的细节，尤其是肢体的动态变化（如运动轨迹、速度、姿势变化），可以更准确地判断是否为暴力行为。</li>
<li><strong>降低误报率</strong>：单纯依靠环境变化或者声学分析容易受其他因素干扰（如背景噪音、非暴力事件的运动），而人体动作本身可以提供更加直接、可靠的行为判定依据。</li>
<li><strong>多模态融合</strong>：现代的暴力行为检测往往不仅仅依赖于单一的视觉信息，还结合了深度学习、动作识别等技术，可以从多个角度进行判断。通过分析人体动作特征和其他环境数据（如声音、位置等），可以更好地识别暴力事件。</li>
<li><strong>实时监控</strong>：实时检测人体动作变化对于暴力行为的早期预警至关重要，尤其是在公共安全或视频监控系统中，动作识别可以即时检测到潜在的暴力行为并进行响应。</li>
</ol>
<p>综上，侧重人体动作本身不仅可以提升检测的准确性，还能更好地从动态和连续的角度识别暴力行为，提高系统的实时性和鲁棒性。</p>
<h3 id="单模态的人体动作识别的缺点有哪些"><a href="#单模态的人体动作识别的缺点有哪些" class="headerlink" title="单模态的人体动作识别的缺点有哪些"></a>单模态的人体动作识别的缺点有哪些</h3><p>单模态人体动作识别（即仅使用一种数据模态，如视觉、声音、加速度等）存在以下主要缺点：</p>
<ol>
<li><p><strong>信息局限性</strong>：</p>
<p>单一模态只能捕获动作的部分信息，可能导致对动作的理解不够全面。例如，仅依赖视觉模态可能无法捕获细微的物理接触或动作的力度变化。</p>
</li>
<li><p><strong>环境敏感性</strong>：</p>
<p>单模态方法对环境条件过于依赖。例如，视觉模态在光照不足或存在遮挡的情况下表现不佳，而非视觉模态（如加速度计）在传感器未正确佩戴或被干扰时表现不佳。</p>
</li>
<li><p><strong>无法应对模糊或模态冲突</strong>：</p>
<p>单模态方法难以处理模糊的行为信号或区分相似动作。例如，在视觉模态中，某些动作（如挥手与投掷）可能在外观上十分相似。</p>
</li>
<li><p><strong>鲁棒性差</strong>：</p>
<p>单模态在面对复杂场景（如多人交互、噪音、遮挡等）时，容易出现误判或漏判。例如，在仅依赖声音模态时，背景噪音可能干扰动作识别。</p>
</li>
<li><p><strong>缺乏上下文信息</strong>：</p>
<p>单模态通常难以捕获行为发生的上下文。例如，仅通过视觉识别到一个人弯腰的动作，可能无法判断是捡拾物品还是摔倒</p>
</li>
</ol>
<h3 id="暴力行为场景有哪些特点，使用多模态对这些特点的优势有哪些"><a href="#暴力行为场景有哪些特点，使用多模态对这些特点的优势有哪些" class="headerlink" title="暴力行为场景有哪些特点，使用多模态对这些特点的优势有哪些"></a>暴力行为场景有哪些特点，使用多模态对这些特点的优势有哪些</h3><p>暴力行为场景通常具有以下几个显著特点，这些特点对检测系统提出了更高的要求：</p>
<ol>
<li><p><strong>动态性强</strong>：</p>
<p>暴力行为往往是迅速发生的，例如打斗、推搡、摔倒等动作可能在短时间内完成，导致动作的变化非常快。</p>
</li>
<li><p><strong>多人交互</strong>：</p>
<p>暴力行为通常涉及两个或更多个体之间的互动，如互相推搡、打斗或攻击等。多个目标的运动和交互增加了识别的复杂度。</p>
</li>
<li><p><strong>复杂的姿态变化</strong>：</p>
<p>暴力行为中的人物姿态变化通常非常剧烈，涉及肢体的快速摆动、抓握、推拉等动作，且可能伴随一定的身体接触。</p>
</li>
<li><p><strong>不规则的空间布局</strong>：</p>
<p>在暴力行为场景中，人物可能会在空间内迅速移动，动作的方向和速度可能会发生剧烈变化。背景也可能因为人物的动态而发生显著变化。</p>
</li>
<li><p><strong>潜在的遮挡</strong>：</p>
<p>在暴力行为中，人物之间的动作可能会出现遮挡（例如，两人打斗时，其中一个人可能被另一个人挡住）。这种情况给基于视觉的检测带来了挑战。</p>
</li>
<li><p><strong>噪声与干扰因素</strong>：</p>
<p>背景中的其他活动、环境变化、背景噪声等都可能干扰暴力行为的识别。例如，打斗声可能被背景音乐、交通噪声等因素掩盖。</p>
</li>
</ol>
<p>多模态（即结合多种数据来源或感知方式，如视觉、声音、传感器数据等）方法能够弥补单模态方法的不足，通过结合视觉、声音和传感器等多模态信息，可以更好地应对这些挑战，提升暴力行为检测的准确性、鲁棒性和实时性。多模态方法能够综合各类信息，从多个角度捕捉行为特征，尤其是在面对复杂环境、多人交互和遮挡等问题时，具有显著的优势。</p>
<h3 id="2D-CNN-RNN-的优点"><a href="#2D-CNN-RNN-的优点" class="headerlink" title="2D CNN + RNN 的优点"></a>2D CNN + RNN 的优点</h3><p>2D CNN（卷积神经网络）与 RNN（递归神经网络）的结合是行为识别中的一种常见方法，尤其适用于视频行为识别任务。其主要优点包括：</p>
<ol>
<li><strong>空间特征与时间依赖性的有效结合</strong>：</li>
</ol>
<ul>
<li><strong>2D CNN</strong>：能够从视频帧中提取空间特征，如人物的姿态、背景和动作细节。通过多层卷积，CNN能够识别局部和全局的空间信息。</li>
<li><strong>RNN（LSTM/GRU）</strong>：RNN特别擅长处理时序数据，可以建模视频帧之间的时间依赖关系，捕捉动作的动态变化和时间长短的依赖，适应动作序列的连续性和长期依赖。</li>
<li><strong>优点</strong>：2D CNN 提供强大的空间特征提取能力，RNN 提供强大的时间序列建模能力。将两者结合，能够更好地理解视频中的空间和时间信息，提升行为识别的准确性。</li>
</ul>
<ol>
<li><strong>自动特征学习</strong>：</li>
</ol>
<ul>
<li>传统方法依赖手工特征提取（如HOG、光流等），需要依赖专家知识且难以适应多样的场景。而 <strong>2D CNN</strong> 能够自动学习空间特征，减少了人工设计特征的依赖，提高了对复杂场景的适应能力。</li>
<li><strong>RNN</strong> 则可以自动从数据中学习到行为模式的时间序列特征，不需要事先设定固定的时间模型或参数。</li>
</ul>
<ol>
<li><strong>鲁棒性强，适应性好</strong>：</li>
</ol>
<ul>
<li><strong>2D CNN</strong> 通过卷积层提取多层次的空间特征，具有较好的鲁棒性，能够应对不同背景和复杂场景中的视频数据。</li>
<li><strong>RNN</strong> 具有处理不规则、可变时间长度序列的能力，能够识别动态变化的动作和突发行为，提高了模型的适应性。</li>
</ul>
<ol>
<li><strong>可扩展性强</strong>：</li>
</ol>
<ul>
<li>2D CNN 和 RNN 的组合能够很好地扩展到不同的视频数据规模、场景和复杂度上。随着数据集的增大，模型仍然能够通过更深的网络层次和更多的时序数据进行训练，进一步提升识别效果。</li>
</ul>
<h2 id="答辩稿——初版"><a href="#答辩稿——初版" class="headerlink" title="答辩稿——初版"></a>答辩稿——初版</h2><p>各位评委老师大家好，我是我们组的主持人张熙浚，我们组的研究方式是基于多模态特征融合的视频暴力行为识别方法研究</p>
<p>接下来我会从五个方面介绍我们的项目</p>
<p>首先是背景与意义，暴力行为对社会危害极大，即使诸如学校、商场、银行、车站等公共场所存在大量监控摄像头，产生了大量的视频片段，但这些片段通常被用来在暴力犯罪发生后提供线索和证据，而很少被用来实时识别并停止暴力行为。</p>
<p>这便引出了我们项目的目的，我们希望利用计算机视觉技术，赋予机器暴力行为的判别能力，从而及时发现暴力行为并能有效降低其带来的危害，而且大大降低了人力成本，在安防领域有极大的应用价值。</p>
<p>暴力行为的检测方法早期的检测方法主要是依靠设立一些规则，或是依靠背景和环境的变化，这些方法在很多方面存在不足，包括受环境因素影响大，特征提取和分析能力有限，计算效率低等问题</p>
<p>而现代的暴力行为检测越来越注重<strong>人体动作本身的识别</strong>，其通过分析人体动作的细节，尤其是肢体的动态变化，不仅可以提升检测的准确性，还能更好地从动态和连续的角度识别暴力行为，提高系统的实时性和鲁棒性。</p>
<p>由于监控人员不可能实时监控每一个摄像头产生的视频，所以部署视频暴力行为识别系统，能够节约用于监控的人力资源，降低监控人员因疲劳或走神而造成的漏检风险，一旦识别到暴力行为立即警示相关人员，进一步采取相应措施。由此可以得出我们项目研究的现实意义和应用场景。</p>
<p>接下来，我将讲述当前暴力行为检测的研究背景和挑战，并引出我们的解决方案。多种不同的数据形态都可以用来表示人类的动作和行为。主流的人体动作识别把这些模态分为2类：视觉模态和非视觉模态。这些数据模态是对不同的信息来源进行编码，根据应用场景的不同，不同模态的数据有着不同的独特优势。</p>
<p>目前主流的单模态深度学习方法存在以下缺点：信息单一、对环境敏感、鲁棒性较差，难以应对复杂场景等。但真实的暴力事件场景往往存在以下特点：存在复杂姿态变化，多人交互，大量环境噪声等。因此，我们提出了基于多模态的暴力事件检测，通过结合多种数据来源，从多个角度捕捉行为特征，尤其是在面对复杂环境、多人交互和遮挡等问题时，具有显著的优势。</p>
<p>随着深度学习和计算机视觉技术的发展，深度学习方法已经成为了行为识别算法的主流方向，接下来我会通过几篇论文中的方法介绍研究现状</p>
<p>这一篇是早提出使用深度学习方法解决视频暴力行为识别任务，直接将视频输入三维卷积进行建模</p>
<p>这一篇提出了数据集Rwf-2000，同时提出一种的双流网络架构，他们充分利用了RGB数据提供的外观信息和光流提供的运动信息，但缺点在于光流法计算、存储成本高，适用于光照条件良好、不拥挤的情况</p>
<p>这一篇提出了一种弱监督方法，即通过少量的标签（例如，仅标记视频是否包含暴力，而不是标记具体的暴力事件位置和类型）来训练模型。他选取视频帧最关键的区域，但使用I3D作为骨干网络，参数量巨大（1300万）</p>
<p>这一篇是基于骨架的方法，通过提取人体骨骼关节点构成三维骨架阵列，根据局部区域点的特征和时空位置信息，构建特定的权重分布策略，通过骨架点卷积实现分类。优点是骨架可以很好的表示人体运动信息，但问题在于仅使用骨架数据，效果高度依赖于位姿估计的精度，无法有效遮挡情况，同时因为仅使用骨架数据，其他信息缺失</p>
<p>这一篇是基于 2D CNN + RNN 的方法，2D CNN 提供强大的空间特征提取能力，RNN 提供强大的时间序列建模能力。将两者结合，能够更好地理解视频中的空间和时间信息，提升行为识别的准确性。这一篇使用简单快速的预处理方法突出了人体，减少了冗余的背景信息，但其仅使用RGB模态，提取的特征不够全面</p>
<p>我们的研究内容大致包含三个部分：1.提出一种基于多模态特征融合的视频暴力行为识别算法2.提出一种自适应的注意力算法用于多模态融合3.完成人体暴力行为检测系统的设计，接下来我将依次为大家介绍</p>
<p>第一部分，在特征提取阶段，为了区分暴力行为与非暴力行为，我们选择了三个要素进行提取：人体姿态、运动（趋势、幅度）、人物之间的位置关系，为了获取以上三个要素，并保证模型的通用性和现实性，需要从原始的RGB图像中提取以上特征，研究工作包括下列内容： </p>
<p>a.RGB模态的去除冗余信息<br>  为了避免原生RGB图像冗余信息影响模型判断，减少计算量，我们决定对于原生RGB图像进行冗余信息去除工作，首先计算一个视频中所有帧的均值，记为平均帧（主要包含背景信息，因为背景在所有视频帧中几乎保持不变）用每一帧减去平均帧：去除（不变的）背景，保留（运动的）人体。通过简易的预处理，去除了冗余的背景信息，聚焦于人体的外观、姿态。</p>
<p>b.运动趋势与幅度特征的提取<br>目前主流反映物体运动趋势的方法是光流法，但我们考虑到光流图像在低像素复杂场景下效果不佳，且易受光照条件改变的影响，于是决定采取帧差法，通过对视频图像序列中相邻两帧作差分运算来获得运动目标轮廓的方法，以很好地适用于存在多个运动目标的情况，算法相对实现简单，程序设计复杂度低，对光线等场景变化不太敏感，能够适应各种动态环境，有着比较强的鲁棒。</p>
<p>c.深度模态的提取<br>在原始的RGB模态中，复杂场景中，人物多且受光照影响严重，难以分辨人物间的相对位置关系。为了反映人物之间的位置关系，我们选取深度模态，其去除了颜色和纹理信息并提供三维结构信息和人体轮廓，我们利用Depth estimation算法，对原始RGB视频进行深度估计，得到视点到场景中各点之间的距离作为像素点的图片，即深度图，其划分了近景与远景，刻画了人物的轮廓，反映了三维空间中人物间的相对位置关系。</p>
<p>我们选择了CNN-LSTM的深度学习方法<strong>。</strong>LSTM擅长处理时序数据，可以建模视频帧之间的时间依赖关系，而CNN能够从视频帧中提取空间特征。通过结合两者的优势，我们可以让模型同时考虑到数据的时序信息和空间信息，减少参数降低过拟合风险，从而提供更精确的预测、更出色的性能以及更高的训练效率，并以此构建了算法思路。</p>
<p>第二部分，针对多模态融合中权重数值处理的问题，我们提出了一种自适应的注意力算法用于多模态融合，让模型自适应地学习不同模态特征之间的权重关系，允许模型根据具体任务动态调整每个模态的重要性，强调信息特征，抑制不太有用的特征,从而更灵活地应对不同的场景。</p>
<p>第三部分，我们完成了人体暴力行为检测系统的设计，刻画了系统的边界及大小，人体暴力行为检测系统是一个自动检测暴力行为的智能视频监控系统。该系统采用了三层架构，即表示层、业务层以及数据层。 它被设计成一个Web系统，主要以网页的形式显示在PC 显示器上</p>
<p>我们已经初步构建了暴力行为的检测流程，系统包含离线分析和在线监测两种模式</p>
<p>离线分析不依赖实时的监控视频，可对任意视频进行后处理式的分析。它 的优点是它不依赖于视频监控系统，可以直接选择视频开始分析，在视频来源 和分析时机的选择上更自由。</p>
<p>在线监测是人体暴力行为检测系统提供的另一种检测方式。它旨在利用监 控视频资源，进行实时的暴力行为检测，达到即时分析并报警提示的功能。这 一功能极大地降低了人工分析实时监控视频的成本，便于管理人员进行安全监 管，提高了监管的效率。</p>
<p>为了提高检测速度和避免资源浪费，根据传入视频的总帧数进行判断，采取提示过短、一次预测或是多轮预测。</p>
<p>最后是进度安排，我们已经完成算法大部分的编写，后续会继续完成系统的开发</p>
<p>谢谢各位老师观看，请各位老师批评指正</p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>大创</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——Langchain与LLM集成解决方案</title>
    <url>/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/</url>
    <content><![CDATA[<h2 id="了解Langchain"><a href="#了解Langchain" class="headerlink" title="了解Langchain"></a>了解Langchain</h2><p>LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如 API 和数据库。</p>
<p>一句话概括就是：<strong>langchain 完成了对数据一个提炼、查找的完全链路。</strong>它并不能提供数据源、查找理由，只是一种方法的凝练。</p>
<p>数据源支持由用户等自行提供，因此它支持本地知识库的搭建，合理想象未来的学生课设系统将会是：金融知识系统（使用 langchain 爬取金融网站提取摘要凝练成知识）、图书简介系统（使用 langchain 对图书提取摘要进行展示）……</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>Jupyter 就是一个非常好用的 Python 语言编程工具。</p>
<p>或者说是一个 Python 编程语言、以及更多其他编程语言的，交互式集成开发环境。</p>
<p>Jupyter 的一个非常重要的优点，就是 写程序的界面，和运行程序的界面，在一起。</p>
<p>jubyter notebook的安装：<code>pip install jupyterlab</code></p>
<p>web页面的启动：<code>jupyter-lab</code></p>
<p>vscode：创建.ipynb格式的文件</p>
<hr>
<p>langchain的安装：<code>pip install langchain</code></p>
<h2 id="提供一种LLM集成解决方案，一份代码支持快速同时支持gpt大模型、国产大模型-通义千问、文心一言、百度千帆、讯飞星火等-、本地开源大模型-Ollama"><a href="#提供一种LLM集成解决方案，一份代码支持快速同时支持gpt大模型、国产大模型-通义千问、文心一言、百度千帆、讯飞星火等-、本地开源大模型-Ollama" class="headerlink" title="提供一种LLM集成解决方案，一份代码支持快速同时支持gpt大模型、国产大模型(通义千问、文心一言、百度千帆、讯飞星火等)、本地开源大模型(Ollama)"></a>提供一种LLM集成解决方案，一份代码支持快速同时支持gpt大模型、国产大模型(通义千问、文心一言、百度千帆、讯飞星火等)、本地开源大模型(Ollama)</h2><p>项目地址：<a href="https://github.com/NanGePlus/LLMTest">NanGePlus/LLMTest: 为实现代码的高扩展性和兼容性，提出一套综合解决方案，支持多种大模型类型的无缝集成，包括GPT系列大模型、国内主流模型（如通义千问、智谱AI等），以及本地化部署的大模型（如qwen2.5）。</a></p>
<h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><p>openai-api代理：<a href="https://api.wlai.vip/">云雾 API</a></p>
<p>安装One-Api</p>
<p><a href="https://github.com/songquanpeng/one-api">songquanpeng/one-api: OpenAI 接口管理 &amp; 分发系统，支持 Azure、Anthropic Claude、Google PaLM 2 &amp; Gemini、智谱 ChatGLM、百度文心一言、讯飞星火认知、阿里通义千问、360 智脑以及腾讯混元，可用于二次分发管理 key，仅单可执行文件，已打包好 Docker 镜像，一键部署，开箱即用. OpenAI key management &amp; redistribution system, using a single API for all LLMs, and features an English UI.</a></p>
<p>利用exe</p>
<p><a href="http://localhost:3000/">One API</a></p>
<p>默认账号密码：root     12345</p>
<p>创建渠道，这里以阿里通义千问为例</p>
<p>获取API-KEY：<a href="https://bailian.console.aliyun.com/?spm=5176.29619931.J__Z58Z6CX7MY__Ll8p1ZOR.1.136959fcA1q1xF&amp;accounttraceid=a01e32df30fa4776a42f6cb88a6f938dfnlu#/model-market/detail/qwen-plus">阿里云百炼</a></p>
<p><a href="https://blog.csdn.net/qq_26303031/article/details/140987551">2024年最新免费AI大模型API汇总及国内大模型使用教程（附代码）_免费大模型api-CSDN博客</a></p>
<p><img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216103856131.png" alt="image-20241216103856131"></p>
<hr>
<p>使用 Ollama 非常简单，只需要按照以下步骤：</p>
<ol>
<li><strong>安装 Ollama</strong> ： 根据你的操作系统，从 <a href="https://ollama.com/">Ollama 官网 </a>下载并安装最新版本。</li>
<li><strong>启动 Ollama</strong> ： 打开终端或命令行，输入 <code>ollama serve</code> 命令启动 Ollama 服务器。</li>
<li><strong>下载模型</strong>： 在<a href="https://ollama.com/library">模型仓库 </a>找到想要的模型，然后使用 <code>ollama pull</code> 命令下载，例如 <code>ollama pull llama3:70b</code> 。</li>
<li><strong>运行模型</strong> ： 使用 <code>ollama run</code> 命令启动模型，例如 <code>ollama run llama3:70b</code> 。</li>
<li><strong>开始聊天</strong> ： 在终端中输入你的问题或指令，Ollama 会根据模型生成相应的回复。</li>
<li><strong>查看模型列表</strong> ：<code>ollama list</code></li>
</ol>
<p><img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216115902772.png" alt="image-20241216115902772"></p>
<h3 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h3><p>初始化：采用pycharm+anaconda</p>
<p><img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216120328229.png" alt="image-20241216120328229"></p>
<p>安装依赖</p>
<p>pip install -r requirements.txt<br>每个软件包后面都指定了本次视频测试中固定的版本号<br><strong>注意：</strong> 截止2024.10.18，langchain最新版本为0.3.3，langchain-openai最新版本为0.2.2</p>
<p>调整api，调整 utils/myLLM.py 内容</p>
<p><img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LangChain/image-20241216131346999.png" alt="image-20241216131346999"></p>
<p>调整 llmTest.py 内容</p>
<p>LLM_TYPE = “oneapi” # openai：调用gpt模型;oneapi：调用oneapi方案支持的模型（这里调用通义千问）</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://github.com/langchain-ai/langchain?tab=readme-ov-file">langchain-ai/langchain：🦜🔗构建上下文感知推理应用程序</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/680828606">LangChain 入门与避坑指北 - 知乎</a></p>
<p><a href="https://www.langchain.com.cn/docs/introduction/">LangChain中文网</a></p>
<p><a href="https://blog.csdn.net/franklfeng/article/details/117562667">Jupyter 是什么-CSDN博客</a></p>
<p><a href="https://vscode.github.net.cn/docs/datascience/jupyter-notebooks#_save-your-jupyter-notebook">在 Visual Studio Code 中使用 Jupyter Notebook_Vscode中文网</a></p>
<p><a href="https://cuterwrite.top/p/ollama/#:~:text=如何使用 Ollama？ 1 安装 Ollama： 根据你的操作系统，从 Ollama 官网,ollama run llama3%3A70b 。 5 开始聊天： 在终端中输入你的问题或指令，Ollama 会根据模型生成相应的回复。">Ollama：从入门到进阶</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——LightRAG与GraphRAG</title>
    <url>/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/</url>
    <content><![CDATA[<h2 id="GraphRAG"><a href="#GraphRAG" class="headerlink" title="GraphRAG"></a>GraphRAG</h2><p>最新消息是11.26凌晨，微软宣布将推出 GraphRAG 的全新迭代版本LazyGraphRAG<br>核心亮点是极低的使用成本，其数据索引成本仅为现有GraphRAG 的 0.1%。此外，LazyGraphRAG 引入了全新的混合数据检索方法，大幅提升了生成结果的准确性和效率。该版本将很快开源，并纳入到 GitHub GraphRAG 库中<br>原文链接如下:<a href="https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/">https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/</a></p>
<hr>
<p><strong>支持的检索方式</strong></p>
<p><strong>Naive Search</strong><br>Naive 模式是最简单的检索策略，它直接基于输入查询计算向量相似度，返回最接近的结果，不进行任何额外的优化或复杂处理<br><strong>Local Search</strong><br>Local 模式只在本地上下文范围内进行检索。它聚焦于用户当前输入的特定领域或某部分数据，不会考虑全局数据<br><strong>Global Search</strong><br>Global 模式会在整个知识库范围内进行检索，试图找到与查询最相关的信息，而不局限于当前上下文或局部区域<br><strong>Hybrid Search</strong><br>Hybrid 模式结合了 Local 和 Global 的优势，同时考虑局部上下文和全局信息，综合结果以提高答案的相关性和覆盖范围</p>
<h2 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h2><p>Anaconda，中文大蟒蛇，是一个开源的Anaconda是专注于数据分析的Python发行版本，包含了conda、Python等190多个科学包及其依赖项。</p>
<p>Anaconda就是可以便捷获取包且对包能够进行管理，包括了python和很多常见的软件库和一个包管理器conda。常见的科学计算类的库都包含在里面了，使得安装比常规python安装要容易，同时对环境可以统一管理的发行版本</p>
<h3 id="为什么要安装Anaconda？"><a href="#为什么要安装Anaconda？" class="headerlink" title="为什么要安装Anaconda？"></a>为什么要安装Anaconda？</h3><p>Anaconda对于python初学者而言及其友好，相比单独安装python主程序，选择Anaconda可以帮助省去很多麻烦，Anaconda里添加了许多常用的功能包，如果单独安装python，这些功能包则需要一条一条自行安装，在Anaconda中则不需要考虑这些，同时Anaconda还附带捆绑了两个非常好用的交互式代码编辑器（Spyder、Jupyter notebook）。</p>
<p>简单来说，Anconda，可以理解成运输车，每当下载Anconda的时候，里面不仅包含了python，还有180多个库（武器)一同被打包下载下来。</p>
<p>下载完Anconda之后，再也不用一个个下载那些库了。</p>
<h3 id="集成开发环境搭建Anaconda-PyCharm"><a href="#集成开发环境搭建Anaconda-PyCharm" class="headerlink" title="集成开发环境搭建Anaconda+PyCharm"></a>集成开发环境搭建Anaconda+PyCharm</h3><p><a href="https://www.bilibili.com/video/BV1q9HxeEEtT/?vd_source=30acb5331e4f5739ebbad50f7cc6b949">【大模型应用开发基础】集成开发环境搭建Anaconda+PyCharm_哔哩哔哩_bilibili</a></p>
<h2 id="LightRAG与GraphRAG运行对比"><a href="#LightRAG与GraphRAG运行对比" class="headerlink" title="LightRAG与GraphRAG运行对比"></a>LightRAG与GraphRAG运行对比</h2><p><a href="https://github.com/NanGePlus/LightRAGTest">NanGePlus/LightRAGTest: LightRAG与GraphRAG在索引构建、检索测试中的耗时、模型请求次数、Token消耗金额、检索质量等方面进行对比</a></p>
<p>命令行终端中执行如下命令安装依赖包<br>cd LightRAG<br>pip install -e .<br>cd GraphRAG<br>pip install graphrag==0.5.0</p>
<hr>
<p><strong>测试文本</strong> 测试文本均为使用西游记白话文前九回内容，文件名为book.txt<br><strong>模型配置</strong> 大模型使用OpenAI(代理方案)，Chat模型均使用gpt-4o-mini,Embedding模型均使用text-embedding-3-small<br><strong>其他配置</strong> 笔记本均为MacBook Pro2017,网速、python环境均相同</p>
<hr>
<p>LightRAG测试</p>
<p>(1)构建索引</p>
<p>打开命令行终端，执行如下指令<br>cd LightRAG/nangeAGICode<br>python test.py<br><strong>注意</strong> 在运行脚本之前，需要调整相关代码将如下代码块打开，检索相关的代码块注释</p>
<p>(2)逐一测试</p>
<p>执行如下指令<br>cd LightRAG/nangeAGICode<br>python test.py<br><strong>注意</strong> 在运行脚本之前，需要注释如下构建索引代码，取消检索相关的代码块注释</p>
<p>GraphRAG测试</p>
<p>(1)构建索引</p>
<p>打开命令行终端，执行如下指令<br>cd GraphRAG<br>graphrag index —root ./</p>
<p>(2)逐一测试</p>
<p>graphrag query —root ./ —method local —query “这个故事的核心主题是什么?”<br>graphrag query —root ./ —method global —query “这个故事的核心主题是什么?”<br>graphrag query —root ./ —method drift —query “这个故事的核心主题是什么?”</p>
<hr>
<p><img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/img.png" alt="img"></p>
<h2 id="利用neo4j可视化"><a href="#利用neo4j可视化" class="headerlink" title="利用neo4j可视化"></a>利用neo4j可视化</h2><p><strong>测试文本</strong> 测试文本均为使用西游记白话文前九回内容<br><strong>模型配置</strong> 大模型均使用OpenAI(代理方案)，Chat模型均使用gpt-4o,Embedding模型均使用text-embedding-3-small<br><strong>其他配置</strong> 笔记本均为MacBook Pro2017,网速、python环境均相同</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># gpt大模型相关配置根据自己的实际情况进行调整</span><br><span class="line">OPENAI_API_BASE = &quot;https://api.wlai.vip/v1&quot;</span><br><span class="line">OPENAI_CHAT_API_KEY = &quot;sk-Tuza9B8WYo1vkBAAmmLeQjuOl1VTP9Dd0nuKxqnLOaJJMZZd&quot;</span><br><span class="line">OPENAI_CHAT_MODEL = &quot;gpt-4o&quot;</span><br><span class="line">OPENAI_EMBEDDING_MODEL = &quot;text-embedding-3-small&quot;</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="LightRAG构建索引测试"><a href="#LightRAG构建索引测试" class="headerlink" title="LightRAG构建索引测试"></a>LightRAG构建索引测试</h3><h4 id="1-安装textract依赖包"><a href="#1-安装textract依赖包" class="headerlink" title="(1)安装textract依赖包"></a>(1)安装textract依赖包</h4><p>通过指令 pip install textract 安装时会报错，报错的原因是<br>其元数据文件中使用了不再被支持的版本约束符号（&lt;=0.29.*），而当前 pip 和 setuptools 不再接受这种格式<br>解决方案:下载依赖包源码，修改相应参数后本地进行安装<br><a href="https://pypi.org/project/textract/1.6.5/#description">https://pypi.org/project/textract/1.6.5/#description</a><br>cd textract-1.6.5<br>pip install .</p>
<h4 id="2-创建neo4j数据库实例"><a href="#2-创建neo4j数据库实例" class="headerlink" title="(2) 创建neo4j数据库实例"></a>(2) 创建neo4j数据库实例</h4><p>推荐使用云服务进行测试，链接地址如下:<br><a href="https://console-preview.neo4j.io/tools/query">https://console-preview.neo4j.io/tools/query</a><br>注册登录成功，直接新建实例即可</p>
<p>也可以用本地neo4j</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据库连接相关参数配置</span></span><br><span class="line">NEO4J_URI=<span class="string">&quot;bolt://localhost:7687&quot;</span></span><br><span class="line">NEO4J_USERNAME=<span class="string">&quot;neo4j&quot;</span></span><br><span class="line">NEO4J_PASSWORD=<span class="string">&quot;zxj03051218&quot;</span></span><br><span class="line">NEO4J_DATABASE=<span class="string">&quot;neo4j&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="3-增量索引构建及知识图谱可视化测试"><a href="#3-增量索引构建及知识图谱可视化测试" class="headerlink" title="(3)增量索引构建及知识图谱可视化测试"></a>(3)增量索引构建及知识图谱可视化测试</h4><p>运行如下指令进行索引构建<br>cd LightRAG/nangeAGICode1201<br>python insertTest.py<br>python queryTest.py<br>每一次构建完成，先清除数据库中的数据再运行如下指令进行可视化<br>在运行之前需要根据自己的实际情况进行参数的调整<br>python graph_visual_with_html.py</p>
<p>python graph_visual_with_neo4j.py<br><strong>在数据库中进行查询测试</strong><br>MATCH (n:<code>PERSON</code>)<br>WHERE n.displayName CONTAINS ‘唐僧’<br>RETURN n LIMIT 25;</p>
<p>MATCH (n:<code>PERSON</code>)<br>WHERE n.displayName CONTAINS ‘八戒’<br>RETURN n LIMIT 25;</p>
<p>MATCH (n:<code>PERSON</code>)<br>WHERE n.displayName CONTAINS ‘沙和尚’<br>RETURN n LIMIT 25;</p>
<p><strong>清除数据</strong><br>MATCH (n)<br>CALL { WITH n DETACH DELETE n } IN TRANSACTIONS OF 25000 ROWS;</p>
<p>MATCH (n)<br>OPTIONAL MATCH (n)-[r]-()<br>DELETE n,r</p>
<p><img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/image-20241221160947727.png" alt="image-20241221160947727"></p>
<p><img src="/2024/12/07/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94LightRAG%E4%B8%8EGraphRAG/image-20241221160843951.png" alt="image-20241221160843951"></p>
<h3 id="LightRAG和GraphRAG生成的知识图谱对比"><a href="#LightRAG和GraphRAG生成的知识图谱对比" class="headerlink" title="LightRAG和GraphRAG生成的知识图谱对比"></a>LightRAG和GraphRAG生成的知识图谱对比</h3><p>运行如下指令将GraphRAG生成的知识图谱进行可视化展示<br>cd GraphRAG/utils<br>python graph<em>visual<em>with_neo4j.py<br>在运行脚本前根据自己的实际情况进行调整,修改文件所在路径为存储增量数据的文件路径<br>GRAPHRAG_FOLDER=”/Users/janetjiang/Desktop/agi_code/LightRAGTest/GraphRAG/output”<br><strong>在数据库中进行查询测试</strong><br>MATCH (n:`__Entity</em></em>`)<br>WHERE n.name CONTAINS ‘唐僧’<br>RETURN n LIMIT 25;</p>
<p>MATCH (n:<code>__Entity__</code>)<br>WHERE n.name CONTAINS ‘八戒’<br>RETURN n LIMIT 25;</p>
<p>MATCH (n:<code>__Entity__</code>)<br>WHERE n.name CONTAINS ‘沙和尚’<br>RETURN n LIMIT 25;</p>
<p><strong>清除数据</strong><br>MATCH (n)<br>CALL { WITH n DETACH DELETE n } IN TRANSACTIONS OF 25000 ROWS;</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.bilibili.com/video/BV1CmzEYcEnS/?spm_id_from=333.1007.tianma.1-1-1.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">LightRAG与GraphRAG对比评测，从索引构建、本地检索、全局检索、混合检索等维度对请求大模型次数、Token消耗、金额消耗、检索质量等方面进行全面对比_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/weixin_56197703/article/details/124630222">还是搞不懂Anaconda是什么?读这一篇文章就够了-CSDN博客</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——Neo4j</title>
    <url>/2024/12/06/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94Neo4j/</url>
    <content><![CDATA[<h2 id="什么是-Neo4j？"><a href="#什么是-Neo4j？" class="headerlink" title="什么是 Neo4j？"></a>什么是 Neo4j？</h2><p><strong>Neo4j</strong> 是一个开源的<strong>图形数据库</strong>，由 Neo4j 公司开发和维护。作为图数据库的代表，Neo4j 使用图理论中的节点和边（关系）来表示和存储数据，相较于传统的关系型数据库（如 MySQL、PostgreSQL）和其他 NoSQL 数据库（如文档型、键值型数据库），Neo4j 在处<strong>理复杂关系和连接性强的数据方面</strong>具有显著优势。</p>
<h3 id="主要特点："><a href="#主要特点：" class="headerlink" title="主要特点："></a>主要特点：</h3><ul>
<li><strong>图模型</strong>：使用节点、关系和属性来建模数据，直观地反映实体及其之间的关联。</li>
<li><strong>Cypher 查询语言</strong>：专为图数据库设计的声明式查询语言，语法简洁，易于表达复杂的图形查询。</li>
<li><strong>高性能</strong>：优化的存储和索引机制，能够高效地处理大规模图数据和复杂查询。</li>
<li><strong>ACID 事务支持</strong>：保证数据的一致性和可靠性，适用于需要强事务保障的应用场景。</li>
</ul>
<h2 id="为什么需要-Neo4j？"><a href="#为什么需要-Neo4j？" class="headerlink" title="为什么需要 Neo4j？"></a>为什么需要 Neo4j？</h2><p>在许多应用场景中，<strong>数据之间存在复杂的关系和连接性</strong>。传统的关系型数据库在处理多层级的关联查询时，往往需要大量的联接操作（JOIN），这会导致查询性能下降，尤其是在数据规模庞大时。而 Neo4j 通过图模型天然适合表示和处理这种高度连接的数据，能够更高效地执行复杂的关系查询。</p>
<h3 id="主要需求原因："><a href="#主要需求原因：" class="headerlink" title="主要需求原因："></a>主要需求原因：</h3><ol>
<li><strong>复杂关系处理</strong>：需要频繁进行多级关联查询，如社交网络、推荐系统等。</li>
<li><strong>灵活的数据模型</strong>：数据结构可能随时间变化，图数据库提供了更大的灵活性。</li>
<li><strong>性能需求</strong>：需要在大规模数据集上执行快速的关系查询和遍历操作。</li>
<li><strong>实时性</strong>：需要实时分析和处理数据关系，如欺诈检测、网络安全等。</li>
</ol>
<p><img src="/2024/12/06/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94Neo4j/ed250b8ea580015278be07a9233448c2.png" alt="ed250b8ea580015278be07a9233448c2"></p>
<h2 id="GraphRAG的理解"><a href="#GraphRAG的理解" class="headerlink" title="GraphRAG的理解"></a>GraphRAG的理解</h2><p><strong>GraphRAG=Graph(知识图谱)+RAG技术</strong></p>
<p><strong>GraphRAG</strong> 是一种结合了<strong>图结构</strong>和<strong>检索增强生成（RAG）</strong>的方法，旨在增强语言模型（如大规模预训练的变换器模型）的推理能力和信息检索能力。这个方法通常用于处理复杂的推理任务，尤其是当涉及到大规模知识库或图形数据时，GraphRAG可以通过图的结构来有效地组织信息，从而提高模型在生成和推理时的效率和准确性。</p>
<p><strong>图结构（Graph）</strong>：</p>
<ul>
<li><strong>图</strong>通常用于表示节点之间的关系和依赖，在处理复杂知识结构时非常有用。在GraphRAG中，图结构帮助捕捉信息之间的关系，能够有效地组织和链接不同的知识点，尤其是在涉及多个实体和关系的任务中。</li>
</ul>
<p><strong>检索增强生成（RAG）</strong>：</p>
<ul>
<li>RAG 是一种将信息检索与生成模型结合的框架。它的核心思想是，模型在生成答案时不仅仅依赖于其预训练时获得的知识，还会从一个外部数据库或文档库中检索相关的信息来增强回答的准确性和上下文适应性。</li>
</ul>
<h2 id="Neo4j的安装"><a href="#Neo4j的安装" class="headerlink" title="Neo4j的安装"></a>Neo4j的安装</h2><ol>
<li>官网下载社区版</li>
<li>安装JDK，java11</li>
<li>配置环境变量</li>
<li>启动Neo4j</li>
</ol>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">常用命令</span><br><span class="line"># 启动服务</span><br><span class="line">neo4j(.bat) start</span><br><span class="line"># 重启服务</span><br><span class="line">neo4j(.bat) restart</span><br><span class="line"># 停止服务</span><br><span class="line">neo4j(.bat) stop</span><br><span class="line"># 控制台模式启动</span><br><span class="line">neo4j(.bat) console</span><br></pre></td></tr></table></figure>
</blockquote>
<ol>
<li>进入到 <a href="http://localhost:7474">http://localhost:7474</a></li>
</ol>
<p>账号密码  neo4j    zxj03051218</p>
<p>第一次进入前安装neo4j 的服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">neo4j install-service</span><br></pre></td></tr></table></figure>
<p>查看版本   neo4j —version</p>
<h2 id="apoc用处"><a href="#apoc用处" class="headerlink" title="apoc用处"></a>apoc用处</h2><p>数据导入和导出：使用APOC插件可以轻松导入和导出不同格式的数据到Neo4j图数据库。您可以将数据从关系型数据库、CSV文件、JSON等转换为图形数据，并相反地，将图形数据导出到其他格式。<br>图形算法：APOC提供了许多有用的图形算法，如PageRank、社区发现（例如Louvain算法），路径分析等。这些算法可以帮助您发现数据之间的关联性和模式，并从中提取有价值的信息。<br>数据清洗和转换：APOC提供了丰富的过程和函数，用于数据清洗和转换。您可以使用它来处理字符串、时间、密码学等方面的数据，并进行必要的清洗和格式化。<br>可视化：APOC支持将图形数据转换为其他可视化工具所需的格式，例如Gephi、D3.js等。这使得您可以将您的图形数据以更直观的方式呈现，进一步探索和交流。<br>地理空间分析：APOC提供了与地理空间数据相关的功能，如计算两个地点之间的距离、查找附近的地点等。这对于在地理空间上分析和查询数据特别有用。</p>
<p>我应该是主要用到了数据导入和导出的功能，因为要将构建好的所以传到本地neo4j上</p>
<h2 id="apoc插件安装"><a href="#apoc插件安装" class="headerlink" title="apoc插件安装"></a>apoc插件安装</h2><p><a href="https://blog.csdn.net/shdabai/article/details/132880323">知识图谱基本工具Neo4j使用笔记 五 ：APOC插件安装及简单应用_neo4j apoc-CSDN博客</a></p>
<p>版本 neo4j 4.4.39</p>
<p>APOC插件下载：apoc-4.4.0.9-all.jar（注意apoc要与neo4j版本对应）</p>
<p><a href="https://github.com/neo4j/apoc/releases?page=2">Releases · neo4j/apoc</a></p>
<p>将下载的 <code>apoc-4.4.0.9-all.jar</code> 直接复制到neo4j/plugins文件夹</p>
<p>修改APOC的配置文件</p>
<p>打开配置文件将，这一下内容的注释去掉</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dbms.security.procedures.unrestricted=apoc.*</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://segmentfault.com/a/1190000037690548#item-0-2">java - 我的Neo4j探索之旅 - 初识Neo4j（一） - 个人文章 - SegmentFault 思否</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——初识RAG</title>
    <url>/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>基于 <strong>LLM （Large Language Model）</strong>最火热的应用技术是什么，检索增强生成（<strong>RAG，Retrieval Augmented Generation</strong>）技术必占据重要的一席。RAG 最初是为了解决 LLM 的各类问题的产生的，但后面大家发现在现阶段的很多企业痛点上，使用RAG好像是更好的解决方案。</p>
<p>LLM的问题</p>
<p>尽管LLM拥有令人印象深刻的能力，但是它们还面临着一些问题和挑战：</p>
<ul>
<li><p>幻觉问题：大模型的底层原理是基于概率，在没有答案的情况下经常会胡说八道，提供虚假信息。</p>
</li>
<li><p>时效性问题：规模越大（参数越多、tokens 越多），大模型训练的成本越高。类似 ChatGPT3.5，起初训练数据是截止到 2021 年的，对于之后的事情就不知道了。而且对于一些高时效性的事情，大模型更加无能为力，比如帮我看看今天晚上有什么电影值得去看？这种任务是需要去淘票票、猫眼等网站先去获取最新电影信息的，大模型本身无法完成这个任务。</p>
</li>
<li><p>数据安全：OpenAI 已经遭到过几次隐私数据的投诉，而对于企业来说，如果把自己的经营数据、合同文件等机密文件和数据上传到互联网上的大模型，那想想都可怕。既要保证安全，又要借助 AI 能力，那么最好的方式就是<strong>把数据全部放在本地，企业数据的业务计算全部在本地完成</strong>。而在线的大模型仅仅完成一个归纳的功能，甚至，LLM 都可以完全本地化部署。</p>
</li>
</ul>
<hr>
<p>解决这些挑战对于 LLMs 在各个领域的有效利用至关重要。一个有效的解决方案是集成检索增强生成（RAG）技术，该技术通过获取外部数据来响应查询来补充模型，从而确保更准确和最新的输出。主要表现方面如下：</p>
<ul>
<li><p>有效避免幻觉问题：虽然无法 100% 解决大模型的幻觉问题，但通过 RAG 技术能够有效的降低幻觉，在软件系统中结合大模型提供幂等的API接口就可以发挥大模型的重要作用。</p>
</li>
<li><p>经济高效的处理知识&amp;开箱即用：只需要借助信息检索和向量技术，将用户的问题和知识库进行相关性搜索结合，就能高效的提供大模型不知道的知识，同时具有权威性。</p>
</li>
<li><p>数据安全：企业的数据可以得到有效的保护，通过私有化部署基于 RAG 系统开发的AI产品，能够在体验AI带来的便利性的同时，又能避免企业隐私数据的泄漏。</p>
</li>
</ul>
<h1 id="什么是RAG"><a href="#什么是RAG" class="headerlink" title="什么是RAG"></a>什么是RAG</h1><p>RAG 是检索增强生成（Retrieval Augmented Generation ）的简称，它为大语言模型 (LLMs) 提供了从数据源检索信息的能力，并以此为基础生成回答。简而言之，RAG 结合了信息检索技术和大语言模型的提示功能，即模型根据搜索算法找到的信息作为上下文来查询回答问题。无论是查询还是检索的上下文，都会被整合到发给大语言模型的提示中。<br><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/v2-76c9a386a70bbcd610f76f1f32423165_1440w.png" alt="v2-76c9a386a70bbcd610f76f1f32423165_1440w"></p>
<p><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/e9280ebbd3c04d400de7c0619fd0bb50.jpg" alt="e9280ebbd3c04d400de7c0619fd0bb50"></p>
<p>RAG 的架构如图中所示。它既不是一个特定的开源代码库，也不是某个特定的应用，是一个开发框架。</p>
<p>完整的 RAG 应用流程主要包含两个阶段：</p>
<p>数据准备阶段：（A）数据提取—&gt; （B）分块（Chunking）—&gt; （C）向量化（embedding）—&gt; （D）数据入库</p>
<p>检索生成阶段：（1）问题向量化—&gt; （2）根据问题查询匹配数据—&gt; （3）获取索引数据 —&gt; （4）将数据注入Prompt—&gt; （5）LLM生成答案</p>
<h2 id="向量数据库"><a href="#向量数据库" class="headerlink" title="向量数据库"></a>向量数据库</h2><h3 id="GPT-的缺陷"><a href="#GPT-的缺陷" class="headerlink" title="GPT 的缺陷"></a>GPT 的缺陷</h3><p>GPT-3.5/4 带给我们无限震撼的同时，其天然的缺陷和诸多的限制也让开发者头痛不已，例如其输入端上下文（tokens）大小的限制困扰着很多的开发者和消费者，像 gpt-3.5-turbo 模型它的限制是 4K tokens(～3000字)，这意味着使用者最多只能输入 3000 字给 GPT 来理解和推理答案。</p>
<h3 id="向量数据库的崛起"><a href="#向量数据库的崛起" class="headerlink" title="向量数据库的崛起"></a>向量数据库的崛起</h3><p>在 GPT 模型的限制下，开发者们不得不寻找其他的解决方案，而向量数据库就是其中之一。向量数据库的核心思想是将文本转换成向量，然后将向量存储在数据库中，当用户输入问题时，将问题转换成向量，然后在数据库中搜索最相似的向量和上下文，最后将文本返回给用户。</p>
<p>当我们有一份文档需要 GPT 处理时，例如这份文档是客服培训资料或者操作手册，我们可以先将这份文档的所有内容转化成向量（这个过程称之为 Vector Embedding），然后当用户提出相关问题时，我们将用户的搜索内容转换成向量，然后在数据库中搜索最相似的向量，匹配最相似的几个上下文，最后将上下文返回给 GPT。这样不仅可以大大减少 GPT 的计算量，从而提高响应速度，更重要的是降低成本，并绕过 GPT 的 tokens 限制。</p>
<h1 id="RAG的挑战"><a href="#RAG的挑战" class="headerlink" title="RAG的挑战"></a>RAG的挑战</h1><p>一个基本的 RAG 通常集成了一个向量数据库和一个 LLM，其中<a href="https://zilliz.com/learn/what-is-vector-database">向量数据库</a>存储并检索与用户查询相关的上下文信息，LLM 根据检索到的上下文生成答案。虽然这种方法在大部分情况下效果都很好，但在处理复杂任务时却面临一些挑战，如多跳推理（multi-hop reasoning）或联系不同信息片段全面回答问题。</p>
<p>以这个问题为例：“<em>What name was given to the son of the man who defeated the usurper Allectus?</em>”</p>
<p>一个基本的 RAG 通常会遵循以下步骤来回答这个问题：</p>
<ol>
<li>识别那个人：确定谁打败了 Allectus。</li>
<li>研究那个人的儿子：查找有关这个人家庭的信息，特别是他的儿子。</li>
<li>找到名字：确定儿子的名字。</li>
</ol>
<p>通常第一步就会面临挑战，因为基本的 RAG 根据<a href="https://zilliz.com/glossary/semantic-similarity">语义相似性</a>检索文本，而不是基于在数据集中没有明确提及具体细节来回答复杂的查询问题。这种局限性让我们很难找到所需的确切信息。解决方案通常是为常见查询手动创建问答对。但这种解决方案通常十分昂贵甚至不切实际。</p>
<p>为了应对这些挑战，微软研究院引入了 <a href="https://microsoft.github.io/graphrag/">GraphRAG</a>，这是一种全新方法，它通过知识图谱增强 RAG 的检索和生成。</p>
<h1 id="GraphRAG的诞生"><a href="#GraphRAG的诞生" class="headerlink" title="GraphRAG的诞生"></a>GraphRAG的诞生</h1><p>与使用向量数据库检索语义相似文本的基本 RAG 不同，GraphRAG 通过结合知识图谱（KGs）来增强 RAG。知识图谱是一种数据结构，它根据数据间的关系来存储和联系相关或不相关的数据。</p>
<p>GraphRAG 流程通常包括两个基本过程：索引和查询。</p>
<p><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/1_03c0dcc161.png" alt="1_03c0dcc161"></p>
<h1 id="GraphRAG的优势"><a href="#GraphRAG的优势" class="headerlink" title="GraphRAG的优势"></a>GraphRAG的优势</h1><p>基础 RAG 和 GraphRAG 都被问到了同样的问题，这需要汇总整个数据集中的信息来构成答案。</p>
<p>问：What are the top 5 themes in the dataset?</p>
<p>下图为答案。基础 RAG 提供的结果与战争主题无关，因为向量搜索检索到了无关的文本，导致了答案的不准确。相比之下，GraphRAG 提供了一个清晰且高度相关的答案，识别了主要的主题和相关细节。结果与数据集一致，并引用了源材料。</p>
<p>上述例子展示了 GraphRAG 如何通过结合知识图谱和向量数据库，更有效地处理需要跨数据集整合信息的复杂查询，从而提高答案的相关性和准确性。</p>
<p><img src="/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94RAG/5_8bd8df7ac9.png" alt="5_8bd8df7ac9"></p>
<p>GraphRAG 在多跳推理和复杂信息总结方面性能明显更佳。研究表明GraphRAG 在全面性和多样性方面都超过了基础 RAG：</p>
<ul>
<li><strong>全面性</strong>：答案覆盖问题的所有方面。</li>
<li><strong>多样性</strong>：答案提供的观点和见解具有多样性和丰富性。</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://blog.csdn.net/Python_0011/article/details/139752344">大模型RAG入门及实践（非常详细）零基础入门到精通，收藏这一篇就够了-CSDN博客</a></p>
<p><a href="https://cloud.tencent.com/developer/article/2312534">向量数据库｜一文全面了解向量数据库的基本概念、原理、算法、选型-腾讯云开发者社区-腾讯云</a></p>
<p><a href="https://zilliz.com.cn/blog/graphrag-explained-enhance-rag-with-knowledge-graphs">GraphRAG 详解: 通过知识图谱提升 RAG 系统 - Zilliz 向量数据库</a></p>
<p>论文： <a href="https://arxiv.org/pdf/2404.16130">https://arxiv.org/pdf/2404.16130</a></p>
<p><a href="https://www.bilibili.com/video/av1256338452?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">GraphRAG：知识图谱+RAG、更高质量的检索_哔哩哔哩_bilibili</a></p>
<p>微软开源的GraphRAG代码： <a href="https://github.com/microsoft/graphrag">https://github.com/microsoft/graphrag</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>机设——初识zinc</title>
    <url>/2024/11/16/%E7%A7%91%E7%A0%94/%E6%9C%BA%E8%AE%BE/%E6%9C%BA%E8%AE%BE%E2%80%94%E2%80%94zinc/</url>
    <content><![CDATA[<p>安装，注意配置环境变量<br>$env:ZINC_FIRST_ADMIN_USER=”admin”<br>$env:ZINC_FIRST_ADMIN_PASSWORD=”admin”<br>.\zinc.exe</p>
<p>加载示例数据，利用bash<br>curl -L <a href="https://github.com/zincsearch/zincsearch/releases/download/v0.1.1/olympics.ndjson.gz">https://github.com/zincsearch/zincsearch/releases/download/v0.1.1/olympics.ndjson.gz</a> -o olympics.ndjson.gz<br>gzip -d  olympics.ndjson.gz<br>curl <a href="http://localhost:4080/api/_bulk">http://localhost:4080/api/_bulk</a> -i -u admin:Complexpass#123  —data-binary “@olympics.ndjson”</p>
<p>概念<br>ZincSearch 是一个搜索引擎，允许您在上传到 ZincSearch 时搜索自己的数据。将其视为“Google”或“Bing”搜索，但仅用于您自己的数据。<br>ZincSearch 允许您索引 （json） 文档并允许进行全文搜索。</p>
<p>添加索引<br>使用 JSON 格式：{ “分析”： { “分析器”： { “默认”： { “type”： “standard” } } } }<br>{<br>    “index”: “my_index”,<br>    “settings”: {<br>        “analysis”: {<br>            “analyzer”: {<br>                “default”: {<br>                    “type”: “standard”<br>                }<br>            }<br>        }<br>    }<br>}’<br>“index”: 指定你要创建的索引名称，这里是 my_index。<br>“settings”: 包含索引的设置。<br>“analysis”: 定义分析器的部分。<br>“analyzer”: 指定分析器的配置。<br>“default”: 定义默认分析器，类型为 standard。</p>
<p>索引的映射（mapping）<br>映射（mapping）是指在数据存储系统（如数据库或搜索引擎）中定义索引中字段的结构和属性的过程。它类似于数据库中的表结构定义<br>使用 JSON 格式：{ “属性”： { “内容”： { “type”： “text” } } }</p>
<p>参考文献<br><a href="https://geekdaxue.co/read/ZincSearch-doc/create-update-index">https://geekdaxue.co/read/ZincSearch-doc/create-update-index</a><br><a href="https://prabhatsharma.in/blog/in-search-of-a-search-engine-beyond-elasticsearch-introducing-zinc/">https://prabhatsharma.in/blog/in-search-of-a-search-engine-beyond-elasticsearch-introducing-zinc/</a></p>
]]></content>
      <categories>
        <category>项目经历</category>
        <category>机设</category>
      </categories>
      <tags>
        <tag>科研</tag>
      </tags>
  </entry>
  <entry>
    <title>算法期末复习</title>
    <url>/2025/06/12/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/%E7%AE%97%E6%B3%95%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="贪心问题"><a href="#贪心问题" class="headerlink" title="贪心问题"></a>贪心问题</h3><h4 id="找零钱"><a href="#找零钱" class="headerlink" title="找零钱"></a>找零钱</h4><p>用最少数量的钱币凑出目标金额 m 元。</p>
<p><strong>核心思想</strong> ：<br>每次选择<strong>不超过剩余金额的最大面值</strong> ，直到凑够目标金额。</p>
<p><strong>步骤：</strong></p>
<ol>
<li>将钱币面值按从大到小排序。</li>
<li>对于当前剩余金额，不断减去最大可用面值，直到金额为 0。</li>
</ol>
<p><strong>贪心策略的适用性</strong></p>
<p><strong>仅当钱币面值满足以下条件时有效</strong> ：</p>
<ul>
<li>面值序列中每个元素都是前一个元素的因数（如 <code>1, 2, 5, 10</code>）。</li>
<li>否则，贪心可能失败（例如面值 <code>[1, 3, 4]</code>，目标 <code>6</code>：贪心选 <code>4+1+1</code> 需 3 枚，而最优解是 <code>3+3</code> 需 2 枚）。</li>
</ul>
<p><strong>代码问题分析</strong></p>
<p>用户提供的代码是一个基于贪心策略的找零钱实现，但在<strong>硬币面值不满足贪心条件</strong>时可能无法得到最优解。以下是具体分析：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">findMinCoins</span>(<span class="params">coins, amount</span>):</span><br><span class="line">    coins.sort(reverse=<span class="literal">True</span>)  <span class="comment"># 降序排序</span></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(coins)):</span><br><span class="line">        <span class="keyword">while</span> amount &gt;= coins[i]:</span><br><span class="line">            res.append(coins[i])</span><br><span class="line">            amount -= coins[i]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">coins = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line">amount = <span class="number">1136</span></span><br><span class="line">out = findMinCoins(coins, amount)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;钱币数量为<span class="subst">&#123;<span class="built_in">len</span>(out)&#125;</span>.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>问题点：</strong></p>
<ol>
<li><p><strong>贪心策略的局限性</strong><br>仅当硬币面值满足 <strong>每种面值是前一种面值的因数</strong>（如 <code>[1, 2, 5, 10, 50, 100]</code>）时，贪心算法才能保证最优解。若面值不满足此条件（如 <code>[1, 3, 4]</code>），则可能失败。</p>
</li>
<li><p><strong>未处理特殊情况</strong>  </p>
<ul>
<li>若 <code>amount</code> 无法被硬币组合凑出（如硬币为 <code>[2, 5]</code>，目标 <code>3</code>），代码会返回非最优解或死循环。</li>
</ul>
</li>
</ol>
<p><strong>改进方案</strong></p>
<p>适用于任意硬币面值，确保最优解：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">min_coins_dp</span>(<span class="params">coins, amount</span>):</span><br><span class="line">    dp = [<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)] * (amount + <span class="number">1</span>)</span><br><span class="line">    dp[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, amount + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> coin <span class="keyword">in</span> coins:</span><br><span class="line">            <span class="keyword">if</span> a &gt;= coin <span class="keyword">and</span> dp[a - coin] + <span class="number">1</span> &lt; dp[a]:</span><br><span class="line">                dp[a] = dp[a - coin] + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dp[amount] <span class="keyword">if</span> dp[amount] != <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">coins = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">50</span>, <span class="number">100</span>]</span><br><span class="line">amount = <span class="number">1136</span></span><br><span class="line"><span class="built_in">print</span>(min_coins_dp(coins, amount))  <span class="comment"># 输出 16</span></span><br></pre></td></tr></table></figure></p>
<h4 id="最优装载问题"><a href="#最优装载问题" class="headerlink" title="最优装载问题"></a>最优装载问题</h4><p>🧮 问题描述</p>
<p>给定一个集装箱重量列表 <code>weights</code> 和轮船的最大载重 <code>W</code>，目标是 <strong>尽可能多地装载集装箱</strong>（不考虑体积限制）。</p>
<p>✅ 算法思路</p>
<ol>
<li><strong>排序</strong>：将所有集装箱按重量从小到大排序。</li>
<li><strong>贪心装载</strong>：依次尝试装载每个集装箱，若当前总重量加上该集装箱的重量不超过 <code>W</code>，则装载；否则停止。</li>
<li><strong>返回结果</strong>：返回成功装载的集装箱数量。</li>
</ol>
<p>🧾 Python 实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">max_loaded_containers</span>(<span class="params">weights, W</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    返回在总载重 W 下，最多可以装载的集装箱数量。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    weights (list of int/float): 集装箱重量列表</span></span><br><span class="line"><span class="string">    W (int/float): 轮船的最大载重</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    int: 最多可以装载的集装箱数量</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 按重量从小到大排序</span></span><br><span class="line">    weights.sort()</span><br><span class="line">    </span><br><span class="line">    total_weight = <span class="number">0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> weight <span class="keyword">in</span> weights:</span><br><span class="line">        <span class="keyword">if</span> total_weight + weight &lt;= W:</span><br><span class="line">            total_weight += weight</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    weights = [<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">    W = <span class="number">10</span></span><br><span class="line">    result = max_loaded_containers(weights, W)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;最多可以装载 <span class="subst">&#123;result&#125;</span> 个集装箱&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="活动选择问题（最大相容活动子集）"><a href="#活动选择问题（最大相容活动子集）" class="headerlink" title="活动选择问题（最大相容活动子集）"></a>活动选择问题（最大相容活动子集）</h4><p>📌 问题描述</p>
<p>给定 $ n $ 个活动的集合 $ C = {1, 2, …, n} $，每个活动 $ i $ 都有起始时间 $ s_i $ 和结束时间 $ f_i $（满足 $ s_i &lt; f_i $）。要求选择一个<strong>最大相容活动子集</strong>，使得被选中的活动之间<strong>时间互不重叠</strong>。</p>
<p>两个活动 $ i $ 和 $ j $ 相容的条件为：</p>
<script type="math/tex; mode=display">
s_i \geq f_j \quad \text{或} \quad s_j \geq f_i</script><p>✅ 贪心策略与正确性</p>
<p><strong>贪心策略</strong>：  </p>
<ol>
<li><strong>按活动结束时间 $ f_i $ 从小到大排序</strong>。</li>
<li><strong>依次选择结束最早的活动</strong>，并跳过与其冲突的所有活动。</li>
</ol>
<p><strong>正确性证明（归纳法）</strong>：</p>
<ul>
<li><strong>基础情况</strong>：当只有一项活动时，显然选择它是最优的。</li>
<li><strong>归纳假设</strong>：对于前 $ k $ 个活动，该策略能得到最大相容子集。</li>
<li><strong>归纳步骤</strong>：考虑第 $ k+1 $ 个活动。若选择结束最早的活动 $ A $，则剩下的可用时间区间为 $ [f_A, +\infty) $，此时在该区间内继续应用该策略，仍能得到最大子集。若不选 $ A $ 而选其他活动，则剩余时间更少，无法容纳更多活动。</li>
</ul>
<p>🧾 Python 实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">max_compatible_activities</span>(<span class="params">activities</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    返回最大相容活动子集的数量及具体活动列表。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    activities (list of tuples): 每个元素为 (s_i, f_i)，表示活动的起始和结束时间</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    tuple: (最大活动数量, 相容活动列表)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 按结束时间从小到大排序</span></span><br><span class="line">    sorted_activities = <span class="built_in">sorted</span>(activities, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    selected = []</span><br><span class="line">    last_end = -<span class="number">1</span>  <span class="comment"># 上一个选中的活动的结束时间</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> activity <span class="keyword">in</span> sorted_activities:</span><br><span class="line">        s, f = activity</span><br><span class="line">        <span class="keyword">if</span> s &gt;= last_end:</span><br><span class="line">            selected.append(activity)</span><br><span class="line">            last_end = f</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(selected), selected</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    activities = [</span><br><span class="line">        (<span class="number">1</span>, <span class="number">4</span>), (<span class="number">3</span>, <span class="number">5</span>), (<span class="number">0</span>, <span class="number">6</span>), (<span class="number">5</span>, <span class="number">7</span>), </span><br><span class="line">        (<span class="number">3</span>, <span class="number">8</span>), (<span class="number">5</span>, <span class="number">9</span>), (<span class="number">6</span>, <span class="number">10</span>), (<span class="number">8</span>, <span class="number">11</span>)</span><br><span class="line">    ]</span><br><span class="line">    count, selected = max_compatible_activities(activities)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;最大相容活动数: <span class="subst">&#123;count&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;所选活动:&quot;</span>, selected)</span><br></pre></td></tr></table></figure>
<h4 id="使用堆优化的-Dijkstra-算法（Python-实现）"><a href="#使用堆优化的-Dijkstra-算法（Python-实现）" class="headerlink" title="使用堆优化的 Dijkstra 算法（Python 实现）"></a>使用堆优化的 Dijkstra 算法（Python 实现）</h4><p>🧠 <strong>核心思想</strong></p>
<ul>
<li>使用<strong>最小堆</strong>（优先队列）高效选择当前距离最小的节点，避免暴力遍历。</li>
<li>每次从堆中取出当前最短路径的节点，进行<strong>松弛操作</strong>（Relaxation）。</li>
<li>若发现堆中存在过时的路径记录，则跳过（因为已找到更优路径）。</li>
</ul>
<p>📦 <strong>图的表示</strong></p>
<p>使用邻接表（字典嵌套列表）：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">graph = &#123;</span><br><span class="line">    <span class="string">&#x27;A&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">4</span>)],</span><br><span class="line">    <span class="string">&#x27;B&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">5</span>)],</span><br><span class="line">    <span class="string">&#x27;C&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">1</span>)],</span><br><span class="line">    <span class="string">&#x27;D&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">1</span>)]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>🧾 <strong>Python 代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dijkstra_with_heap</span>(<span class="params">graph, start</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用堆优化的 Dijkstra 算法求单源最短路径。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    graph (dict): 邻接表形式的图，格式为 &#123;节点: [(邻接节点, 权重), ...]&#125;</span></span><br><span class="line"><span class="string">    start (str/int): 起始节点</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    dict: 从起始节点到所有节点的最短路径长度</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 初始化距离字典，所有节点初始距离为无穷大</span></span><br><span class="line">    distances = &#123;node: <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">for</span> node <span class="keyword">in</span> graph&#125;</span><br><span class="line">    distances[start] = <span class="number">0</span>  <span class="comment"># 起始节点到自身的距离为 0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 优先队列（最小堆），存储 (距离, 节点)</span></span><br><span class="line">    heap = [(<span class="number">0</span>, start)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> heap:</span><br><span class="line">        current_distance, current_node = heapq.heappop(heap)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果当前弹出的距离大于记录的距离，说明该节点已被处理过，跳过</span></span><br><span class="line">        <span class="keyword">if</span> current_distance &gt; distances[current_node]:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历当前节点的所有邻接边</span></span><br><span class="line">        <span class="keyword">for</span> neighbor, weight <span class="keyword">in</span> graph[current_node]:</span><br><span class="line">            distance = current_distance + weight</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果找到更短路径，更新距离并推入堆</span></span><br><span class="line">            <span class="keyword">if</span> distance &lt; distances[neighbor]:</span><br><span class="line">                distances[neighbor] = distance</span><br><span class="line">                heapq.heappush(heap, (distance, neighbor))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> distances</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例测试</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    graph = &#123;</span><br><span class="line">        <span class="string">&#x27;A&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">4</span>)],</span><br><span class="line">        <span class="string">&#x27;B&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">5</span>)],</span><br><span class="line">        <span class="string">&#x27;C&#x27;</span>: [(<span class="string">&#x27;A&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">1</span>)],</span><br><span class="line">        <span class="string">&#x27;D&#x27;</span>: [(<span class="string">&#x27;B&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">1</span>)]</span><br><span class="line">    &#125;</span><br><span class="line">    start_node = <span class="string">&#x27;A&#x27;</span></span><br><span class="line">    shortest_paths = dijkstra_with_heap(graph, start_node)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;从节点 <span class="subst">&#123;start_node&#125;</span> 出发的最短路径：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> node, dist <span class="keyword">in</span> shortest_paths.items():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;start_node&#125;</span> → <span class="subst">&#123;node&#125;</span> : <span class="subst">&#123;dist&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="哈夫曼编码"><a href="#哈夫曼编码" class="headerlink" title="哈夫曼编码"></a><strong>哈夫曼编码</strong></h4><p><strong>2. 构建哈夫曼树的步骤</strong></p>
<p><strong>步骤 1：统计字符频率</strong></p>
<p>假设输入字符串为 <code>&quot;BCCABBDDAECCBAAAEC&quot;</code>，统计每个字符的出现次数：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A: 6, B: 4, C: 5, D: 2, E: 1</span><br></pre></td></tr></table></figure></p>
<p><strong>步骤 2：创建最小堆（优先队列）</strong></p>
<ul>
<li>将每个字符及其频率构建成节点，并按频率升序排列。</li>
<li>初始堆：<code>[E(1), D(2), B(4), C(5), A(6)]</code></li>
</ul>
<p><strong>步骤 3：合并节点，构建哈夫曼树</strong></p>
<ol>
<li>取出两个频率最小的节点 <code>E(1)</code> 和 <code>D(2)</code>，合并为新节点 <code>ED(3)</code>。</li>
<li>将新节点插入堆：<code>[B(4), C(5), ED(3), A(6)]</code> → 重新排序为 <code>[ED(3), B(4), C(5), A(6)]</code></li>
<li>重复上述步骤，直到堆中只剩一个根节点（哈夫曼树）。</li>
</ol>
<p>最终树结构示意图（频率越小越靠近叶子）：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">        (18)</span><br><span class="line">       /    \</span><br><span class="line">     (8)    A(6)</span><br><span class="line">    /   \</span><br><span class="line"> (4)   (4)</span><br><span class="line">B     C(5)</span><br></pre></td></tr></table></figure></p>
<p><strong>步骤 4：生成哈夫曼编码表</strong></p>
<p>从根节点出发，左子树标记为 <code>0</code>，右子树标记为 <code>1</code>：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A: 11</span><br><span class="line">B: 00</span><br><span class="line">C: 01</span><br><span class="line">D: 100</span><br><span class="line">E: 101</span><br></pre></td></tr></table></figure></p>
<p><strong>4. Python 实现哈夫曼编码</strong></p>
<p>以下代码展示如何用 Python 构建哈夫曼树并生成编码表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HuffmanNode</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, char, freq</span>):</span><br><span class="line">        <span class="variable language_">self</span>.char = char</span><br><span class="line">        <span class="variable language_">self</span>.freq = freq</span><br><span class="line">        <span class="variable language_">self</span>.left = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.right = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__lt__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.freq &lt; other.freq</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_huffman_tree</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="comment"># 统计频率</span></span><br><span class="line">    frequency = Counter(text)</span><br><span class="line">    <span class="comment"># 创建最小堆</span></span><br><span class="line">    heap = [HuffmanNode(char, freq) <span class="keyword">for</span> char, freq <span class="keyword">in</span> frequency.items()]</span><br><span class="line">    heapq.heapify(heap)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 合并节点</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(heap) &gt; <span class="number">1</span>:</span><br><span class="line">        left = heapq.heappop(heap)</span><br><span class="line">        right = heapq.heappop(heap)</span><br><span class="line">        merged = HuffmanNode(<span class="literal">None</span>, left.freq + right.freq)</span><br><span class="line">        merged.left = left</span><br><span class="line">        merged.right = right</span><br><span class="line">        heapq.heappush(heap, merged)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> heapq.heappop(heap) <span class="keyword">if</span> heap <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_huffman_codes</span>(<span class="params">root</span>):</span><br><span class="line">    codes = &#123;&#125;</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">node, current_code</span>):</span><br><span class="line">        <span class="keyword">if</span> node:</span><br><span class="line">            <span class="keyword">if</span> node.char <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                codes[node.char] = current_code</span><br><span class="line">            dfs(node.left, current_code + <span class="string">&quot;0&quot;</span>)</span><br><span class="line">            dfs(node.right, current_code + <span class="string">&quot;1&quot;</span>)</span><br><span class="line">    dfs(root, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> codes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">text = <span class="string">&quot;BCCABBDDAECCBAAAEC&quot;</span></span><br><span class="line">root = build_huffman_tree(text)</span><br><span class="line">codes = build_huffman_codes(root)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;哈夫曼编码表:&quot;</span>, codes)</span><br></pre></td></tr></table></figure>
<p><strong>输出示例：</strong><br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">哈夫曼编码表: &#123;&#x27;B&#x27;: &#x27;0&#x27;, &#x27;C&#x27;: &#x27;10&#x27;, &#x27;A&#x27;: &#x27;11&#x27;, &#x27;D&#x27;: &#x27;110&#x27;, &#x27;E&#x27;: &#x27;111&#x27;&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="prim"><a href="#prim" class="headerlink" title="prim"></a>prim</h4><p>以下是 <strong>朴素 Prim 算法</strong> 的实现与详解，适用于稠密图（如邻接矩阵存储的图）：</p>
<p><strong>Prim 算法核心思想</strong></p>
<ol>
<li>从任意顶点开始（如 <code>start=0</code>）。</li>
<li>维护一个集合 <code>selected</code>，记录已加入生成树的顶点。</li>
<li>每次从未选顶点中选择到当前生成树的最小权重边的顶点。</li>
<li>重复步骤 3，直到所有顶点加入生成树。</li>
</ol>
<p>时间复杂度：<strong>O(V²)</strong>，其中 V 是顶点数。</p>
<p><strong>Python 实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prim</span>(<span class="params">graph, start=<span class="number">0</span></span>):</span><br><span class="line">    V = <span class="built_in">len</span>(graph)  <span class="comment"># 顶点数量</span></span><br><span class="line">    selected = [<span class="literal">False</span>] * V  <span class="comment"># 标记顶点是否已加入生成树</span></span><br><span class="line">    key = [sys.maxsize] * V  <span class="comment"># 记录各顶点到生成树的最小权重</span></span><br><span class="line">    parent = [-<span class="number">1</span>] * V         <span class="comment"># 记录最小生成树的父节点</span></span><br><span class="line"></span><br><span class="line">    key[start] = <span class="number">0</span>  <span class="comment"># 起始顶点的权值设为0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(V):</span><br><span class="line">        <span class="comment"># 找到当前未选顶点中 key 最小的顶点 u</span></span><br><span class="line">        min_key = sys.maxsize</span><br><span class="line">        u = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(V):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> selected[v] <span class="keyword">and</span> key[v] &lt; min_key:</span><br><span class="line">                min_key = key[v]</span><br><span class="line">                u = v</span><br><span class="line">        <span class="keyword">if</span> u == -<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span>  <span class="comment"># 无连通顶点，生成树结束</span></span><br><span class="line">        </span><br><span class="line">        selected[u] = <span class="literal">True</span>  <span class="comment"># 将 u 加入生成树</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新 u 的所有邻接顶点的 key 值</span></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(V):</span><br><span class="line">            <span class="keyword">if</span> graph[u][v] &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> selected[v] <span class="keyword">and</span> graph[u][v] &lt; key[v]:</span><br><span class="line">                key[v] = graph[u][v]</span><br><span class="line">                parent[v] = u  <span class="comment"># 记录 v 的父节点为 u</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> key, parent</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：邻接矩阵表示的图</span></span><br><span class="line">graph = [</span><br><span class="line">    [<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">6</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">5</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>],</span><br><span class="line">    [<span class="number">6</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">9</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">0</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">key, parent = prim(graph)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最小生成树的总权重:&quot;</span>, <span class="built_in">sum</span>(key))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;父节点数组:&quot;</span>, parent)</span><br></pre></td></tr></table></figure>
<h4 id="kruskal"><a href="#kruskal" class="headerlink" title="kruskal"></a>kruskal</h4><p><strong>2. Kruskal 算法的核心思想</strong></p>
<ol>
<li><strong>按权重从小到大排序所有边</strong>。</li>
<li><strong>依次选择边</strong>：<ul>
<li>如果这条边的两个顶点不在同一个连通分量中（即不形成环），则将这条边加入生成树。</li>
<li>否则跳过这条边。</li>
</ul>
</li>
<li><strong>重复步骤2，直到生成树中有 <code>V-1</code> 条边</strong>（<code>V</code> 是顶点数）。</li>
</ol>
<p><strong>6. Python 实现示例</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UnionFind</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size</span>):</span><br><span class="line">        <span class="variable language_">self</span>.parent = <span class="built_in">list</span>(<span class="built_in">range</span>(size))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.parent[x] != x:</span><br><span class="line">            <span class="variable language_">self</span>.parent[x] = <span class="variable language_">self</span>.find(<span class="variable language_">self</span>.parent[x])  <span class="comment"># 路径压缩</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.parent[x]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        rootX = <span class="variable language_">self</span>.find(x)</span><br><span class="line">        rootY = <span class="variable language_">self</span>.find(y)</span><br><span class="line">        <span class="keyword">if</span> rootX == rootY:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span>  <span class="comment"># 已在同一个集合</span></span><br><span class="line">        <span class="variable language_">self</span>.parent[rootY] = rootX  <span class="comment"># 合并</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kruskal</span>(<span class="params">n, edges</span>):</span><br><span class="line">    <span class="comment"># edges: [(权重, u, v), ...]</span></span><br><span class="line">    edges.sort()</span><br><span class="line">    uf = UnionFind(n)</span><br><span class="line">    mst = []</span><br><span class="line">    cost = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> weight, u, v <span class="keyword">in</span> edges:</span><br><span class="line">        <span class="keyword">if</span> uf.union(u, v):</span><br><span class="line">            mst.append((u, v))</span><br><span class="line">            cost += weight</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(mst) == n - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">break</span>  <span class="comment"># 已选够 n-1 条边</span></span><br><span class="line">    <span class="keyword">return</span> mst, cost</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">n = <span class="number">5</span>  <span class="comment"># 顶点数（0~4）</span></span><br><span class="line">edges = [</span><br><span class="line">    (<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>),  <span class="comment"># A(0)-B(1)</span></span><br><span class="line">    (<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>),  <span class="comment"># B(1)-C(2)</span></span><br><span class="line">    (<span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>),  <span class="comment"># C(2)-D(3)</span></span><br><span class="line">    (<span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>),  <span class="comment"># D(3)-E(4)</span></span><br><span class="line">    (<span class="number">5</span>, <span class="number">0</span>, <span class="number">4</span>),  <span class="comment"># A(0)-E(4)</span></span><br><span class="line">    (<span class="number">6</span>, <span class="number">1</span>, <span class="number">3</span>)   <span class="comment"># B(1)-D(3)</span></span><br><span class="line">]</span><br><span class="line">mst, total = kruskal(n, edges)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MST 边：&quot;</span>, mst)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;总权重：&quot;</span>, total)</span><br></pre></td></tr></table></figure>
<h3 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h3><h4 id="完全背包"><a href="#完全背包" class="headerlink" title="完全背包"></a>完全背包</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def unbounded_knapsack_2d(weights, values, capacity):</span><br><span class="line">    n = len(weights)</span><br><span class="line">    dp = [[0] * (capacity + 1) for _ in range(n + 1)]</span><br><span class="line"></span><br><span class="line">    for i in range(1, n + 1):</span><br><span class="line">        for j in range(1, capacity + 1):</span><br><span class="line">            if weights[i-1] &lt;= j:</span><br><span class="line">                dp[i][j] = max(</span><br><span class="line">                    dp[i-1][j],</span><br><span class="line">                    dp[i][j - weights[i-1]] + values[i-1]</span><br><span class="line">                )</span><br><span class="line">            else:</span><br><span class="line">                dp[i][j] = dp[i-1][j]</span><br><span class="line">    </span><br><span class="line">    return dp[n][capacity]</span><br><span class="line"></span><br><span class="line"># 示例</span><br><span class="line">weights = [1, 2, 3]</span><br><span class="line">values = [15, 20, 50]</span><br><span class="line">capacity = 5</span><br><span class="line">print(unbounded_knapsack_2d(weights, values, capacity))  # 输出 80</span><br></pre></td></tr></table></figure>
<h4 id="最优二叉搜索树"><a href="#最优二叉搜索树" class="headerlink" title="最优二叉搜索树"></a>最优二叉搜索树</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def optimal_bst(p, q, n):</span><br><span class="line">    # 初始化 dp 和 w 数组（大小为 (n+2) x (n+2)，避免越界）</span><br><span class="line">    dp = [[0] * (n+2) for _ in range(n+2)]</span><br><span class="line">    w = [[0] * (n+2) for _ in range(n+2)]</span><br><span class="line">    root = [[0] * (n+2) for _ in range(n+2)]</span><br><span class="line"></span><br><span class="line">    # 初始化虚拟键的权重</span><br><span class="line">    for i in range(n+1):</span><br><span class="line">        w[i][i] = q[i]</span><br><span class="line">    </span><br><span class="line">    # 填表顺序：链长从 1 到 n</span><br><span class="line">    for l in range(1, n+1):  # l 为关键字数量</span><br><span class="line">        for i in range(n - l + 1):</span><br><span class="line">            j = i + l</span><br><span class="line">            w[i][j] = w[i][j-1] + p[j] + q[j]</span><br><span class="line">            dp[i][j] = float(&#x27;inf&#x27;)</span><br><span class="line">            # 枚举根节点 r（i &lt; r ≤ j）</span><br><span class="line">            for r in range(i+1, j+1):</span><br><span class="line">                cost = dp[i][r-1] + dp[r][j]</span><br><span class="line">                if cost &lt; dp[i][j]:</span><br><span class="line">                    dp[i][j] = cost</span><br><span class="line">                    root[i][j] = r</span><br><span class="line">    </span><br><span class="line">    return dp[0][n], root</span><br><span class="line"></span><br><span class="line"># 示例输入</span><br><span class="line">p = [0, 0.15, 0.1, 0.05]  # 关键字概率（从 k₁ 开始）</span><br><span class="line">q = [0.05, 0.1, 0.05, 0.05]  # 虚拟键概率（从 d₀ 开始）</span><br><span class="line">n = 3  # 关键字数量</span><br><span class="line">min_cost, root = optimal_bst(p, q, n)</span><br><span class="line">print(&quot;最小期望搜索代价:&quot;, min_cost)</span><br></pre></td></tr></table></figure>
<h3 id="回溯法"><a href="#回溯法" class="headerlink" title="回溯法"></a>回溯法</h3><h4 id="八皇后"><a href="#八皇后" class="headerlink" title="八皇后"></a>八皇后</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">https://leetcode.cn/problems/n-queens/</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">n=4</span><br><span class="line">ans=[]</span><br><span class="line">path=[]</span><br><span class="line">onpath=[False]*n#记录哪一列有皇后</span><br><span class="line">diag1=[False]*(2*n-1)#记录主对角线是否有皇后</span><br><span class="line">diag2=[False]*(2*n-1)#记录副对角线是否有皇后</span><br><span class="line">def dfs(row,path:list):</span><br><span class="line">    if row==n:</span><br><span class="line">        #print(path)</span><br><span class="line">        chess=[]</span><br><span class="line">        # 生成棋盘</span><br><span class="line">        for i in range(n):</span><br><span class="line">            chess.append(&quot;.&quot;*path[i]+&quot;Q&quot;+&quot;.&quot;*(n-path[i]-1))</span><br><span class="line">        ans.append(chess)</span><br><span class="line">        return</span><br><span class="line">    for col in range(n):</span><br><span class="line">        if isvalid(row,col):</span><br><span class="line">            path.append(col)#放置皇后</span><br><span class="line">            onpath[col]=diag1[row+col]=diag2[row-col+n-1]=True</span><br><span class="line">            dfs(row+1,path)#递归下一行</span><br><span class="line">            path.pop()#回溯，取消放置</span><br><span class="line">            onpath[col]=diag1[row+col]=diag2[row-col+n-1]=False</span><br><span class="line">    </span><br><span class="line">def isvalid(row,col):</span><br><span class="line">    if onpath[col] or diag1[row+col] or diag2[row-col+n-1]:</span><br><span class="line">        return False</span><br><span class="line">    return True</span><br><span class="line">dfs(0,path)</span><br><span class="line">print(ans)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第一章：第三节探索性数据分析</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%89%E8%8A%82%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>在前面我们已经学习了Pandas基础，知道利用Pandas读取csv数据的增删查改，今天我们要学习的就是<strong>探索性数据分析</strong>，主要介绍如何利用Pandas进行排序、算术计算以及计算描述函数describe()的使用。</p>
<h1 id="1-第一章：探索性数据分析"><a href="#1-第一章：探索性数据分析" class="headerlink" title="1 第一章：探索性数据分析"></a>1 第一章：探索性数据分析</h1><h4 id="开始之前，导入numpy、pandas包和数据"><a href="#开始之前，导入numpy、pandas包和数据" class="headerlink" title="开始之前，导入numpy、pandas包和数据"></a>开始之前，导入numpy、pandas包和数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载所需的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#载入之前保存的train_chinese.csv数据，关于泰坦尼克号的任务，我们就使用这个数据</span></span><br><span class="line">train_chinese = pd.read_csv(<span class="string">&#x27;./titanic/train_chinese.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="1-6-了解你的数据吗？"><a href="#1-6-了解你的数据吗？" class="headerlink" title="1.6 了解你的数据吗？"></a>1.6 了解你的数据吗？</h3><p>教材《Python for Data Analysis》第五章</p>
<h4 id="1-6-1-任务一：利用Pandas对示例数据进行排序，要求升序"><a href="#1-6-1-任务一：利用Pandas对示例数据进行排序，要求升序" class="headerlink" title="1.6.1 任务一：利用Pandas对示例数据进行排序，要求升序"></a>1.6.1 任务一：利用Pandas对示例数据进行排序，要求升序</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 具体请看《利用Python进行数据分析》第五章 排序和排名 部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己构建一个都为数字的DataFrame数据</span></span><br><span class="line">frame = pd.DataFrame(np.arange(<span class="number">8</span>).reshape((<span class="number">2</span>, <span class="number">4</span>)), </span><br><span class="line">                     index=[<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;1&#x27;</span>], </span><br><span class="line">                     columns=[<span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">frame</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>d</th>
      <th>a</th>
      <th>b</th>
      <th>c</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
      <td>7</td>
    </tr>
  </tbody>
</table>


<p>【代码解析】</p>
<p>pd.DataFrame() ：创建一个DataFrame对象 </p>
<p>np.arange(8).reshape((2, 4)) : 生成一个二维数组（2*4）,第一列：0，1，2，3 第二列：4，5，6，7</p>
<p>index=[‘2, 1] ：DataFrame 对象的索引列</p>
<p>columns=[‘d’, ‘a’, ‘b’, ‘c’] ：DataFrame 对象的索引行</p>
<p>【问题】：大多数时候我们都是想根据列的值来排序,所以将你构建的DataFrame中的数据根据某一列，升序排列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#回答代码</span></span><br><span class="line"><span class="comment">#指定按列名 &#x27;b&#x27; 的值进行排序，ascending=False设置降序排列（默认是升序）</span></span><br><span class="line">frame.sort_values(by=<span class="string">&#x27;b&#x27;</span>,ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>d</th>
      <th>a</th>
      <th>b</th>
      <th>c</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
  </tbody>
</table>


<p>【思考】通过书本你能说出Pandas对DataFrame数据的其他排序方式吗？</p>
<p>【总结】下面将不同的排序方式做一个总结</p>
<p>1.让行索引升序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame.sort_index(ascending=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>d</th>
      <th>a</th>
      <th>b</th>
      <th>c</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
2.让列索引升序排序

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line"><span class="comment">#axis=1指定对 列索引（columns） 进行排序（默认 axis=0 是对行索引排序）。</span></span><br><span class="line">frame.sort_index(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>a</th>
      <th>b</th>
      <th>c</th>
      <th>d</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>6</td>
      <td>7</td>
      <td>4</td>
    </tr>
  </tbody>
</table>


<p>3.让列索引降序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame.sort_index(axis=<span class="number">1</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>d</th>
      <th>c</th>
      <th>b</th>
      <th>a</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>7</td>
      <td>6</td>
      <td>5</td>
    </tr>
  </tbody>
</table>


<p>4.让任选两列数据同时降序排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame.sort_values(by=[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>],ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>d</th>
      <th>a</th>
      <th>b</th>
      <th>c</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
#### 1.6.2 任务二：对泰坦尼克号数据（trian.csv）按票价和年龄两列进行综合排序（降序排列），从这个数据中你可以分析出什么？


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">在开始我们已经导入了train_chinese.csv数据，而且前面我们也学习了导入数据过程，根据上面学习，我们直接对目标列进行排序即可</span></span><br><span class="line"><span class="string">head(20) : 读取前20条数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">train_chinese.sort_values(by=[<span class="string">&#x27;票价&#x27;</span>,<span class="string">&#x27;年龄&#x27;</span>], ascending=<span class="literal">False</span>).head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>乘客ID</th>
      <th>是否幸存</th>
      <th>仓位等级</th>
      <th>姓名</th>
      <th>性别</th>
      <th>年龄</th>
      <th>兄弟姐妹个数</th>
      <th>父母子女个数</th>
      <th>船票信息</th>
      <th>票价</th>
      <th>客舱</th>
      <th>登船港口</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>679</th>
      <td>680</td>
      <td>1</td>
      <td>1</td>
      <td>Cardeza, Mr. Thomas Drake Martinez</td>
      <td>male</td>
      <td>36.0</td>
      <td>0</td>
      <td>1</td>
      <td>PC 17755</td>
      <td>512.3292</td>
      <td>B51 B53 B55</td>
      <td>C</td>
    </tr>
    <tr>
      <th>258</th>
      <td>259</td>
      <td>1</td>
      <td>1</td>
      <td>Ward, Miss. Anna</td>
      <td>female</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>PC 17755</td>
      <td>512.3292</td>
      <td>NaN</td>
      <td>C</td>
    </tr>
    <tr>
      <th>737</th>
      <td>738</td>
      <td>1</td>
      <td>1</td>
      <td>Lesurer, Mr. Gustave J</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>PC 17755</td>
      <td>512.3292</td>
      <td>B101</td>
      <td>C</td>
    </tr>
    <tr>
      <th>438</th>
      <td>439</td>
      <td>0</td>
      <td>1</td>
      <td>Fortune, Mr. Mark</td>
      <td>male</td>
      <td>64.0</td>
      <td>1</td>
      <td>4</td>
      <td>19950</td>
      <td>263.0000</td>
      <td>C23 C25 C27</td>
      <td>S</td>
    </tr>
    <tr>
      <th>341</th>
      <td>342</td>
      <td>1</td>
      <td>1</td>
      <td>Fortune, Miss. Alice Elizabeth</td>
      <td>female</td>
      <td>24.0</td>
      <td>3</td>
      <td>2</td>
      <td>19950</td>
      <td>263.0000</td>
      <td>C23 C25 C27</td>
      <td>S</td>
    </tr>
    <tr>
      <th>88</th>
      <td>89</td>
      <td>1</td>
      <td>1</td>
      <td>Fortune, Miss. Mabel Helen</td>
      <td>female</td>
      <td>23.0</td>
      <td>3</td>
      <td>2</td>
      <td>19950</td>
      <td>263.0000</td>
      <td>C23 C25 C27</td>
      <td>S</td>
    </tr>
    <tr>
      <th>27</th>
      <td>28</td>
      <td>0</td>
      <td>1</td>
      <td>Fortune, Mr. Charles Alexander</td>
      <td>male</td>
      <td>19.0</td>
      <td>3</td>
      <td>2</td>
      <td>19950</td>
      <td>263.0000</td>
      <td>C23 C25 C27</td>
      <td>S</td>
    </tr>
    <tr>
      <th>742</th>
      <td>743</td>
      <td>1</td>
      <td>1</td>
      <td>Ryerson, Miss. Susan Parker "Suzette"</td>
      <td>female</td>
      <td>21.0</td>
      <td>2</td>
      <td>2</td>
      <td>PC 17608</td>
      <td>262.3750</td>
      <td>B57 B59 B63 B66</td>
      <td>C</td>
    </tr>
    <tr>
      <th>311</th>
      <td>312</td>
      <td>1</td>
      <td>1</td>
      <td>Ryerson, Miss. Emily Borie</td>
      <td>female</td>
      <td>18.0</td>
      <td>2</td>
      <td>2</td>
      <td>PC 17608</td>
      <td>262.3750</td>
      <td>B57 B59 B63 B66</td>
      <td>C</td>
    </tr>
    <tr>
      <th>299</th>
      <td>300</td>
      <td>1</td>
      <td>1</td>
      <td>Baxter, Mrs. James (Helene DeLaudeniere Chaput)</td>
      <td>female</td>
      <td>50.0</td>
      <td>0</td>
      <td>1</td>
      <td>PC 17558</td>
      <td>247.5208</td>
      <td>B58 B60</td>
      <td>C</td>
    </tr>
    <tr>
      <th>118</th>
      <td>119</td>
      <td>0</td>
      <td>1</td>
      <td>Baxter, Mr. Quigg Edmond</td>
      <td>male</td>
      <td>24.0</td>
      <td>0</td>
      <td>1</td>
      <td>PC 17558</td>
      <td>247.5208</td>
      <td>B58 B60</td>
      <td>C</td>
    </tr>
    <tr>
      <th>380</th>
      <td>381</td>
      <td>1</td>
      <td>1</td>
      <td>Bidois, Miss. Rosalie</td>
      <td>female</td>
      <td>42.0</td>
      <td>0</td>
      <td>0</td>
      <td>PC 17757</td>
      <td>227.5250</td>
      <td>NaN</td>
      <td>C</td>
    </tr>
    <tr>
      <th>716</th>
      <td>717</td>
      <td>1</td>
      <td>1</td>
      <td>Endres, Miss. Caroline Louise</td>
      <td>female</td>
      <td>38.0</td>
      <td>0</td>
      <td>0</td>
      <td>PC 17757</td>
      <td>227.5250</td>
      <td>C45</td>
      <td>C</td>
    </tr>
    <tr>
      <th>700</th>
      <td>701</td>
      <td>1</td>
      <td>1</td>
      <td>Astor, Mrs. John Jacob (Madeleine Talmadge Force)</td>
      <td>female</td>
      <td>18.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17757</td>
      <td>227.5250</td>
      <td>C62 C64</td>
      <td>C</td>
    </tr>
    <tr>
      <th>557</th>
      <td>558</td>
      <td>0</td>
      <td>1</td>
      <td>Robbins, Mr. Victor</td>
      <td>male</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>PC 17757</td>
      <td>227.5250</td>
      <td>NaN</td>
      <td>C</td>
    </tr>
    <tr>
      <th>527</th>
      <td>528</td>
      <td>0</td>
      <td>1</td>
      <td>Farthing, Mr. John</td>
      <td>male</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>PC 17483</td>
      <td>221.7792</td>
      <td>C95</td>
      <td>S</td>
    </tr>
    <tr>
      <th>377</th>
      <td>378</td>
      <td>0</td>
      <td>1</td>
      <td>Widener, Mr. Harry Elkins</td>
      <td>male</td>
      <td>27.0</td>
      <td>0</td>
      <td>2</td>
      <td>113503</td>
      <td>211.5000</td>
      <td>C82</td>
      <td>C</td>
    </tr>
    <tr>
      <th>779</th>
      <td>780</td>
      <td>1</td>
      <td>1</td>
      <td>Robert, Mrs. Edward Scott (Elisabeth Walton Mc...</td>
      <td>female</td>
      <td>43.0</td>
      <td>0</td>
      <td>1</td>
      <td>24160</td>
      <td>211.3375</td>
      <td>B3</td>
      <td>S</td>
    </tr>
    <tr>
      <th>730</th>
      <td>731</td>
      <td>1</td>
      <td>1</td>
      <td>Allen, Miss. Elisabeth Walton</td>
      <td>female</td>
      <td>29.0</td>
      <td>0</td>
      <td>0</td>
      <td>24160</td>
      <td>211.3375</td>
      <td>B5</td>
      <td>S</td>
    </tr>
    <tr>
      <th>689</th>
      <td>690</td>
      <td>1</td>
      <td>1</td>
      <td>Madill, Miss. Georgette Alexandra</td>
      <td>female</td>
      <td>15.0</td>
      <td>0</td>
      <td>1</td>
      <td>24160</td>
      <td>211.3375</td>
      <td>B5</td>
      <td>S</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【思考】排序后，如果我们仅仅关注年龄和票价两列。根据常识我知道发现票价越高的应该客舱越好，所以我们会明显看出，票价前20的乘客中存活的有14人，这是相当高的一个比例，那么我们后面是不是可以进一步分析一下票价和存活之间的关系，年龄和存活之间的关系呢？当你开始发现数据之间的关系了，数据分析就开始了。</p>
<p>当然，这只是我的想法，你还可以有更多想法，欢迎写在你的学习笔记中。</p>
<p><strong>多做几个数据的排序</strong></p>
<h4 id="1-6-3-任务三：利用Pandas进行算术计算，计算两个DataFrame数据相加结果"><a href="#1-6-3-任务三：利用Pandas进行算术计算，计算两个DataFrame数据相加结果" class="headerlink" title="1.6.3 任务三：利用Pandas进行算术计算，计算两个DataFrame数据相加结果"></a>1.6.3 任务三：利用Pandas进行算术计算，计算两个DataFrame数据相加结果</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 具体请看《利用Python进行数据分析》第五章 算术运算与数据对齐 部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己构建两个都为数字的DataFrame数据</span></span><br><span class="line"></span><br><span class="line">frame1_a = pd.DataFrame(np.arange(<span class="number">9.</span>).reshape(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                     columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">                     index=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>])</span><br><span class="line">frame1_b = pd.DataFrame(np.arange(<span class="number">12.</span>).reshape(<span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">                     columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;c&#x27;</span>],</span><br><span class="line">                     index=[<span class="string">&#x27;first&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;second&#x27;</span>])</span><br><span class="line">frame1_a, frame1_b</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>(         a    b    c
 one    0.0  1.0  2.0
 two    3.0  4.0  5.0
 three  6.0  7.0  8.0,
           a     e     c
 first   0.0   1.0   2.0
 one     3.0   4.0   5.0
 two     6.0   7.0   8.0
 second  9.0  10.0  11.0)
</code></pre><p>将frame_a和frame_b进行相加</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame1_a+frame1_b</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>a</th>
      <th>b</th>
      <th>c</th>
      <th>e</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>first</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>one</th>
      <td>3.0</td>
      <td>NaN</td>
      <td>7.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>second</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>three</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>two</th>
      <td>9.0</td>
      <td>NaN</td>
      <td>13.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>


<p>【提醒】两个DataFrame相加后，会返回一个新的DataFrame，对应的行和列的值会相加，没有对应的会变成空值NaN。<br><br>当然，DataFrame还有很多算术运算，如减法，除法等，有兴趣的同学可以看《利用Python进行数据分析》第五章 算术运算与数据对齐 部分，多在网络上查找相关学习资料。</p>
<h4 id="1-6-4-任务四：通过泰坦尼克号数据如何计算出在船上最大的家族有多少人？"><a href="#1-6-4-任务四：通过泰坦尼克号数据如何计算出在船上最大的家族有多少人？" class="headerlink" title="1.6.4 任务四：通过泰坦尼克号数据如何计算出在船上最大的家族有多少人？"></a>1.6.4 任务四：通过泰坦尼克号数据如何计算出在船上最大的家族有多少人？</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">还是用之前导入的chinese_train.csv如果我们想看看在船上，最大的家族有多少人（‘兄弟姐妹个数’+‘父母子女个数’），我们该怎么做呢？</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">max</span>(train_chinese[<span class="string">&#x27;兄弟姐妹个数&#x27;</span>] + train_chinese[<span class="string">&#x27;父母子女个数&#x27;</span>])</span><br></pre></td></tr></table></figure>
<pre><code>10
</code></pre><p>【提醒】我们只需找出”兄弟姐妹个数“和”父母子女个数“之和最大的数，当然你还可以想出很多方法和思考角度，欢迎你来说出你的看法。</p>
<p><strong>多做几个数据的相加，看看你能分析出什么？</strong></p>
<h4 id="1-6-5-任务五：学会使用Pandas-describe-函数查看数据基本统计信息"><a href="#1-6-5-任务五：学会使用Pandas-describe-函数查看数据基本统计信息" class="headerlink" title="1.6.5 任务五：学会使用Pandas describe()函数查看数据基本统计信息"></a>1.6.5 任务五：学会使用Pandas describe()函数查看数据基本统计信息</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#(1) 关键知识点示例做一遍（简单数据）</span></span><br><span class="line"><span class="comment"># 具体请看《利用Python进行数据分析》第五章 汇总和计算描述统计 部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己构建一个有数字有空值的DataFrame数据</span></span><br><span class="line"></span><br><span class="line">frame2 = pd.DataFrame([[<span class="number">1.4</span>, np.nan], </span><br><span class="line">                       [<span class="number">7.1</span>, -<span class="number">4.5</span>],</span><br><span class="line">                       [np.nan, np.nan], </span><br><span class="line">                       [<span class="number">0.75</span>, -<span class="number">1.3</span>]</span><br><span class="line">                      ], index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>], columns=[<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>])</span><br><span class="line">frame2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>one</th>
      <th>two</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>a</th>
      <td>1.40</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>b</th>
      <td>7.10</td>
      <td>-4.5</td>
    </tr>
    <tr>
      <th>c</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>d</th>
      <td>0.75</td>
      <td>-1.3</td>
    </tr>
  </tbody>
</table>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">frame2.describe()  <span class="comment">#描述统计</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">count : 样本数据大小</span></span><br><span class="line"><span class="string">mean : 样本数据的平均值</span></span><br><span class="line"><span class="string">std : 样本数据的标准差</span></span><br><span class="line"><span class="string">min : 样本数据的最小值</span></span><br><span class="line"><span class="string">25% : 样本数据25%的时候的值</span></span><br><span class="line"><span class="string">50% : 样本数据50%的时候的值</span></span><br><span class="line"><span class="string">75% : 样本数据75%的时候的值</span></span><br><span class="line"><span class="string">max : 样本数据的最大值</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>one</th>
      <th>two</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.083333</td>
      <td>-2.900000</td>
    </tr>
    <tr>
      <th>std</th>
      <td>3.493685</td>
      <td>2.262742</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.750000</td>
      <td>-4.500000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.075000</td>
      <td>-3.700000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.400000</td>
      <td>-2.900000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.250000</td>
      <td>-2.100000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.100000</td>
      <td>-1.300000</td>
    </tr>
  </tbody>
</table><br>&lt;/div&gt;</p>
<p>调用 describe 函数，观察frame2的数据基本信息</p>
<h4 id="1-6-6-任务六：分别看看泰坦尼克号数据集中-票价、父母子女-这列数据的基本统计数据，你能发现什么？"><a href="#1-6-6-任务六：分别看看泰坦尼克号数据集中-票价、父母子女-这列数据的基本统计数据，你能发现什么？" class="headerlink" title="1.6.6 任务六：分别看看泰坦尼克号数据集中 票价、父母子女 这列数据的基本统计数据，你能发现什么？"></a>1.6.6 任务六：分别看看泰坦尼克号数据集中 票价、父母子女 这列数据的基本统计数据，你能发现什么？</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">看看泰坦尼克号数据集中 票价 这列数据的基本统计数据</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<pre><code>&#39;\n看看泰坦尼克号数据集中 票价 这列数据的基本统计数据\n&#39;
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码</span></span><br><span class="line">train_chinese[<span class="string">&#x27;票价&#x27;</span>].describe()</span><br></pre></td></tr></table></figure>
<pre><code>count    891.000000
mean      32.204208
std       49.693429
min        0.000000
25%        7.910400
50%       14.454200
75%       31.000000
max      512.329200
Name: 票价, dtype: float64
</code></pre><p>【思考】从上面数据我们可以看出， 一共有891个票价数据， 平均值约为：32.20， 标准差约为49.69，说明票价波动特别大， 25%的人的票价是低于7.91的，50%的人的票价低于14.45，75%的人的票价低于31.00， 票价最大值约为512.33，最小值为0。<br>当然，答案只是我的想法，你还可以有更多想法，欢迎写在你的学习笔记中。</p>
<p><strong>多做几个组数据的统计，看看你能分析出什么？</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写下你的其他分析</span></span><br><span class="line">train_chinese[<span class="string">&#x27;父母子女个数&#x27;</span>].describe()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>count    891.000000
mean       0.381594
std        0.806057
min        0.000000
25%        0.000000
50%        0.000000
75%        0.000000
max        6.000000
Name: 父母子女个数, dtype: float64
</code></pre><p>【思考】有更多想法，欢迎写在你的学习笔记中。</p>
<p>【总结】本节中我们通过Pandas的一些内置函数对数据进行了初步统计查看，这个过程最重要的不是大家得掌握这些函数，而是看懂从这些函数出来的数据，构建自己的数据分析思维，这也是第一章最重要的点，希望大家学完第一章能对数据有个基本认识，了解自己在做什么，为什么这么做，后面的章节我们将开始对数据进行清洗，进一步分析。</p>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第一章：第一节数据载入及初步观察</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%80%E8%8A%82%E6%95%B0%E6%8D%AE%E8%BD%BD%E5%85%A5%E5%8F%8A%E5%88%9D%E6%AD%A5%E8%A7%82%E5%AF%9F-%E8%AF%BE%E7%A8%8B-checkpoint/</url>
    <content><![CDATA[<p><strong>复习</strong>:这门课程得主要目的是通过真实的数据，以实战的方式了解数据分析的流程和熟悉数据分析python的基本操作。知道了课程的目的之后，我们接下来我们要正式的开始数据分析的实战教学，完成kaggle上<a href="https://www.kaggle.com/c/titanic/overview">泰坦尼克的任务</a>，实战数据分析全流程。<br>这里有两份资料：<br>教材《Python for Data Analysis》和 baidu.com &amp;<br>google.com（善用搜索引擎）</p>
<h2 id="1-第一章：数据载入及初步观察"><a href="#1-第一章：数据载入及初步观察" class="headerlink" title="1 第一章：数据载入及初步观察"></a>1 第一章：数据载入及初步观察</h2><h3 id="1-1-载入数据"><a href="#1-1-载入数据" class="headerlink" title="1.1 载入数据"></a>1.1 载入数据</h3><p>数据集下载 <a href="https://www.kaggle.com/c/titanic/overview">https://www.kaggle.com/c/titanic/overview</a></p>
<h4 id="1-1-1-任务一：导入numpy和pandas"><a href="#1-1-1-任务一：导入numpy和pandas" class="headerlink" title="1.1.1 任务一：导入numpy和pandas"></a>1.1.1 任务一：导入numpy和pandas</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【提示】如果加载失败，学会如何在你的python环境下安装numpy和pandas这两个库</p>
<h4 id="1-1-2-任务二：载入数据"><a href="#1-1-2-任务二：载入数据" class="headerlink" title="1.1.2 任务二：载入数据"></a>1.1.2 任务二：载入数据</h4><p>(1) 使用相对路径载入数据<br>(2) 使用绝对路径载入数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.getcwd()</span><br><span class="line">test=pd.read_csv(<span class="string">&#x27;./titanic/test.csv&#x27;</span>)</span><br><span class="line">train=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">abs_path_test=os.path.abspath(<span class="string">&#x27;./titanic/test.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(abs_path_test)</span><br><span class="line">test=pd.read_csv(abs_path_test)</span><br><span class="line">abs_path_train=os.path.abspath(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(abs_path_train)</span><br><span class="line">train=pd.read_csv(abs_path_train)</span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<pre><code>/workspace/WuTeachingAI/hands-on-data-analysis/myself/titanic/test.csv
/workspace/WuTeachingAI/hands-on-data-analysis/myself/titanic/train.csv
</code></pre><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>


<p>【提示】相对路径载入报错时，尝试使用os.getcwd()查看当前工作目录。<br>【思考】知道数据加载的方法后，试试pd.read_csv()和pd.read_table()的不同，如果想让他们效果一样，需要怎么做？了解一下’.tsv’和’.csv’的不同，如何加载这两个数据集？<br>【总结】加载的数据是所有工作的第一步，我们的工作会接触到不同的数据格式（eg:.csv;.tsv;.xlsx）,但是加载的方法和思路都是一样的，在以后工作和做项目的过程中，遇到之前没有碰到的问题，要多多查资料吗，使用googel，了解业务逻辑，明白输入和输出是什么。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pd.read_csv() 和 pd.read_table() 本质上非常相似，主要区别在于默认的分隔符参数。</span></span><br><span class="line"><span class="comment"># 通过显式设置 `sep` 参数，可以让它们处理各种以不同字符分隔的文本文件。</span></span><br><span class="line"><span class="comment"># &#x27;.csv&#x27; 文件用逗号分隔，&#x27;.tsv&#x27; 文件用制表符分隔。选择合适的pandas读取函数或正确设置`sep`参数即可加载。</span></span><br></pre></td></tr></table></figure>
<h4 id="1-1-3-任务三：每1000行为一个数据模块，逐块读取"><a href="#1-1-3-任务三：每1000行为一个数据模块，逐块读取" class="headerlink" title="1.1.3 任务三：每1000行为一个数据模块，逐块读取"></a>1.1.3 任务三：每1000行为一个数据模块，逐块读取</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">chunker=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>,chunksize=<span class="number">1000</span>)</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> chunker:</span><br><span class="line">    <span class="built_in">print</span>(chunk)</span><br></pre></td></tr></table></figure>
<pre><code>     PassengerId  Survived  Pclass  \
0              1         0       3   
1              2         1       1   
2              3         1       3   
3              4         1       1   
4              5         0       3   
..           ...       ...     ...   
886          887         0       2   
887          888         1       1   
888          889         0       3   
889          890         1       1   
890          891         0       3   

                                                  Name     Sex   Age  SibSp  \
0                              Braund, Mr. Owen Harris    male  22.0      1   
1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   
2                               Heikkinen, Miss. Laina  female  26.0      0   
3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   
4                             Allen, Mr. William Henry    male  35.0      0   
..                                                 ...     ...   ...    ...   
886                              Montvila, Rev. Juozas    male  27.0      0   
887                       Graham, Miss. Margaret Edith  female  19.0      0   
888           Johnston, Miss. Catherine Helen &quot;Carrie&quot;  female   NaN      1   
889                              Behr, Mr. Karl Howell    male  26.0      0   
890                                Dooley, Mr. Patrick    male  32.0      0   

     Parch            Ticket     Fare Cabin Embarked  
0        0         A/5 21171   7.2500   NaN        S  
1        0          PC 17599  71.2833   C85        C  
2        0  STON/O2. 3101282   7.9250   NaN        S  
3        0            113803  53.1000  C123        S  
4        0            373450   8.0500   NaN        S  
..     ...               ...      ...   ...      ...  
886      0            211536  13.0000   NaN        S  
887      0            112053  30.0000   B42        S  
888      2        W./C. 6607  23.4500   NaN        S  
889      0            111369  30.0000  C148        C  
890      0            370376   7.7500   NaN        Q  

[891 rows x 12 columns]
</code></pre><p>【思考】什么是逐块读取？为什么要逐块读取呢？</p>
<p>【提示】大家可以chunker(数据块)是什么类型？用<code>for</code>循环打印出来出处具体的样子是什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **什么是逐块读取？**</span></span><br><span class="line"><span class="comment"># 逐块读取（Chunking）是指在读取大型数据集时，不一次性将整个文件加载到内存中，而是将文件分成若干个小的数据块（chunks），每次只加载和处理一个数据块。</span></span><br><span class="line"><span class="comment"># 在pandas中，可以通过在 `pd.read_csv()` 或类似的读取函数中设置 `chunksize` 参数来实现逐块读取。`chunksize` 定义了每个数据块包含的行数。</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># **为什么要逐块读取呢？**</span></span><br><span class="line"><span class="comment"># 1.  **处理内存不足的大文件**：</span></span><br><span class="line"><span class="comment">#     *   当数据集非常大，其大小超过了计算机可用内存时，一次性加载整个文件会导致内存溢出错误（MemoryError）。逐块读取允许我们分批处理数据，每次只在内存中保留一小部分数据，从而有效避免内存问题。</span></span><br><span class="line"><span class="comment"># 2.  **提高处理效率（特定场景下）**：</span></span><br><span class="line"><span class="comment">#     *   对于某些类型的操作，例如对数据进行迭代处理、过滤或聚合，如果不需要同时访问所有数据，逐块处理可以使得程序更快地开始处理数据，而不是等待整个大文件加载完毕。</span></span><br><span class="line"><span class="comment">#     *   可以边读取边处理，实现流式数据处理的效果。</span></span><br><span class="line"><span class="comment"># 3.  **数据清洗和预处理**：</span></span><br><span class="line"><span class="comment">#     *   在对大型原始数据进行初步的清洗、转换或特征工程时，可以逐块进行，将处理后的数据块追加到新的存储中，或者在每个块上计算统计量并逐步累积。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="1-1-4-任务四：将表头改成中文，索引改为乘客ID-对于某些英文资料，我们可以通过翻译来更直观的熟悉我们的数据"><a href="#1-1-4-任务四：将表头改成中文，索引改为乘客ID-对于某些英文资料，我们可以通过翻译来更直观的熟悉我们的数据" class="headerlink" title="1.1.4 任务四：将表头改成中文，索引改为乘客ID [对于某些英文资料，我们可以通过翻译来更直观的熟悉我们的数据]"></a>1.1.4 任务四：将表头改成中文，索引改为乘客ID [对于某些英文资料，我们可以通过翻译来更直观的熟悉我们的数据]</h4><p>PassengerId =&gt; 乘客ID<br>Survived    =&gt; 是否幸存<br>Pclass      =&gt; 乘客等级(1/2/3等舱位)<br>Name        =&gt; 乘客姓名<br>Sex         =&gt; 性别<br>Age         =&gt; 年龄<br>SibSp       =&gt; 堂兄弟/妹个数<br>Parch       =&gt; 父母与小孩个数<br>Ticket      =&gt; 船票信息<br>Fare        =&gt; 票价<br>Cabin       =&gt; 客舱<br>Embarked    =&gt; 登船港口             </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将&quot;乘客ID&quot;列作为行索引</span></span><br><span class="line">df=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>,names=[<span class="string">&#x27;乘客ID&#x27;</span>,<span class="string">&#x27;是否幸存&#x27;</span>,<span class="string">&#x27;仓位等级&#x27;</span>,<span class="string">&#x27;姓名&#x27;</span>,<span class="string">&#x27;性别&#x27;</span>,<span class="string">&#x27;年龄&#x27;</span>,<span class="string">&#x27;兄弟姐妹个数&#x27;</span>,<span class="string">&#x27;父母子女个数&#x27;</span>,<span class="string">&#x27;船票信息&#x27;</span>,<span class="string">&#x27;票价&#x27;</span>,<span class="string">&#x27;客舱&#x27;</span>,<span class="string">&#x27;登船港口&#x27;</span>],index_col=<span class="string">&#x27;乘客ID&#x27;</span>,header=<span class="number">0</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>是否幸存</th>
      <th>仓位等级</th>
      <th>姓名</th>
      <th>性别</th>
      <th>年龄</th>
      <th>兄弟姐妹个数</th>
      <th>父母子女个数</th>
      <th>船票信息</th>
      <th>票价</th>
      <th>客舱</th>
      <th>登船港口</th>
    </tr>
    <tr>
      <th>乘客ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
【思考】所谓将表头改为中文其中一个思路是：将英文列名表头替换成中文。还有其他的方法吗？

### 1.2 初步观察
导入数据后，你可能要对数据的整体结构和样例进行概览，比如说，数据大小、有多少列，各列都是什么格式的，是否包含null等

#### 1.2.1 任务一：查看数据的基本信息


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.info()</span><br><span class="line">df.describe()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

    <class 'pandas.core.frame.dataframe'>
    Index: 891 entries, 1 to 891
    Data columns (total 11 columns):
     #   Column  Non-Null Count  Dtype  
    ---  ------  --------------  -----  
     0   是否幸存    891 non-null    int64  
     1   仓位等级    891 non-null    int64  
     2   姓名      891 non-null    object 
     3   性别      891 non-null    object 
     4   年龄      714 non-null    float64
     5   兄弟姐妹个数  891 non-null    int64  
     6   父母子女个数  891 non-null    int64  
     7   船票信息    891 non-null    object 
     8   票价      891 non-null    float64
     9   客舱      204 non-null    object 
     10  登船港口    889 non-null    object 
    dtypes: float64(2), int64(4), object(5)
    memory usage: 83.5+ KB



<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>是否幸存</th>
      <th>仓位等级</th>
      <th>年龄</th>
      <th>兄弟姐妹个数</th>
      <th>父母子女个数</th>
      <th>票价</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>714.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.383838</td>
      <td>2.308642</td>
      <td>29.699118</td>
      <td>0.523008</td>
      <td>0.381594</td>
      <td>32.204208</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.486592</td>
      <td>0.836071</td>
      <td>14.526497</td>
      <td>1.102743</td>
      <td>0.806057</td>
      <td>49.693429</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>20.125000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>38.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>


<p>【提示】有多个函数可以这样做，你可以做一下总结</p>
<h4 id="1-2-2-任务二：观察表格前10行的数据和后15行的数据"><a href="#1-2-2-任务二：观察表格前10行的数据和后15行的数据" class="headerlink" title="1.2.2 任务二：观察表格前10行的数据和后15行的数据"></a>1.2.2 任务二：观察表格前10行的数据和后15行的数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.head(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>是否幸存</th>
      <th>仓位等级</th>
      <th>姓名</th>
      <th>性别</th>
      <th>年龄</th>
      <th>兄弟姐妹个数</th>
      <th>父母子女个数</th>
      <th>船票信息</th>
      <th>票价</th>
      <th>客舱</th>
      <th>登船港口</th>
    </tr>
    <tr>
      <th>乘客ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>3</td>
      <td>Moran, Mr. James</td>
      <td>male</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>330877</td>
      <td>8.4583</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>1</td>
      <td>McCarthy, Mr. Timothy J</td>
      <td>male</td>
      <td>54.0</td>
      <td>0</td>
      <td>0</td>
      <td>17463</td>
      <td>51.8625</td>
      <td>E46</td>
      <td>S</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0</td>
      <td>3</td>
      <td>Palsson, Master. Gosta Leonard</td>
      <td>male</td>
      <td>2.0</td>
      <td>3</td>
      <td>1</td>
      <td>349909</td>
      <td>21.0750</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1</td>
      <td>3</td>
      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>
      <td>female</td>
      <td>27.0</td>
      <td>0</td>
      <td>2</td>
      <td>347742</td>
      <td>11.1333</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1</td>
      <td>2</td>
      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>
      <td>female</td>
      <td>14.0</td>
      <td>1</td>
      <td>0</td>
      <td>237736</td>
      <td>30.0708</td>
      <td>NaN</td>
      <td>C</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1</td>
      <td>3</td>
      <td>Sandstrom, Miss. Marguerite Rut</td>
      <td>female</td>
      <td>4.0</td>
      <td>1</td>
      <td>1</td>
      <td>PP 9549</td>
      <td>16.7000</td>
      <td>G6</td>
      <td>S</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1</td>
      <td>1</td>
      <td>Bonnell, Miss. Elizabeth</td>
      <td>female</td>
      <td>58.0</td>
      <td>0</td>
      <td>0</td>
      <td>113783</td>
      <td>26.5500</td>
      <td>C103</td>
      <td>S</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0</td>
      <td>3</td>
      <td>Saundercock, Mr. William Henry</td>
      <td>male</td>
      <td>20.0</td>
      <td>0</td>
      <td>0</td>
      <td>A/5. 2151</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0</td>
      <td>3</td>
      <td>Andersson, Mr. Anders Johan</td>
      <td>male</td>
      <td>39.0</td>
      <td>1</td>
      <td>5</td>
      <td>347082</td>
      <td>31.2750</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0</td>
      <td>3</td>
      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>
      <td>female</td>
      <td>14.0</td>
      <td>0</td>
      <td>0</td>
      <td>350406</td>
      <td>7.8542</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.tail()</span><br></pre></td></tr></table></figure>
<h4 id="1-2-4-任务三：判断数据是否为空，为空的地方返回True，其余地方返回False"><a href="#1-2-4-任务三：判断数据是否为空，为空的地方返回True，其余地方返回False" class="headerlink" title="1.2.4 任务三：判断数据是否为空，为空的地方返回True，其余地方返回False"></a>1.2.4 任务三：判断数据是否为空，为空的地方返回True，其余地方返回False</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.isnull().head()</span><br></pre></td></tr></table></figure>
<p><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>是否幸存</th>
      <th>仓位等级</th>
      <th>姓名</th>
      <th>性别</th>
      <th>年龄</th>
      <th>兄弟姐妹个数</th>
      <th>父母子女个数</th>
      <th>船票信息</th>
      <th>票价</th>
      <th>客舱</th>
      <th>登船港口</th>
    </tr>
    <tr>
      <th>乘客ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
  </tbody>
</table><br>【总结】上面的操作都是数据分析中对于数据本身的观察</p>
<p>【思考】对于一个数据，还可以从哪些方面来观察？找找答案，这个将对下面的数据分析有很大的帮助</p>
<h3 id="1-3-保存数据"><a href="#1-3-保存数据" class="headerlink" title="1.3 保存数据"></a>1.3 保存数据</h3><h4 id="1-3-1-任务一：将你加载并做出改变的数据，在工作目录下保存为一个新文件train-chinese-csv"><a href="#1-3-1-任务一：将你加载并做出改变的数据，在工作目录下保存为一个新文件train-chinese-csv" class="headerlink" title="1.3.1 任务一：将你加载并做出改变的数据，在工作目录下保存为一个新文件train_chinese.csv"></a>1.3.1 任务一：将你加载并做出改变的数据，在工作目录下保存为一个新文件train_chinese.csv</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 注意：不同的操作系统保存下来可能会有乱码。大家可以加入`encoding=&#x27;GBK&#x27; 或者 ’encoding = ’utf-8‘‘`</span></span><br><span class="line">df.to_csv(<span class="string">&#x27;./titanic/train_chinese.csv&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>【总结】数据的加载以及入门，接下来就要接触数据本身的运算，我们将主要掌握numpy和pandas在工作和项目场景的运用。</p>
</class>]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第三章模型建立和评估---评价</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="第三章-模型搭建和评估-评估"><a href="#第三章-模型搭建和评估-评估" class="headerlink" title="第三章 模型搭建和评估-评估"></a>第三章 模型搭建和评估-评估</h2><p>根据之前的模型的建模，我们知道如何运用sklearn这个库来完成建模，以及我们知道了的数据集的划分等等操作。那么一个模型我们怎么知道它好不好用呢？以至于我们能不能放心的使用模型给我的结果呢？那么今天的学习的评估，就会很有帮助。</p>
<p>加载下面的库</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">6</span>)  <span class="comment"># 设置输出图片大小</span></span><br></pre></td></tr></table></figure>
<p><strong>任务：加载数据并分割测试集和训练集</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 一般先取出X和y后再切割，有些情况会使用到未切割的，这时候X和y就可以用,x是清洗好的数据，y是我们要预测的存活数据&#x27;Survived&#x27;</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;clear_data.csv&#x27;</span>)</span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">X = data</span><br><span class="line">y = train[<span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 对数据集进行切割</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 默认参数逻辑回归模型</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</code></pre><h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><ul>
<li>模型评估是为了知道模型的泛化能力。</li>
<li>交叉验证（cross-validation）是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。</li>
<li>在交叉验证中，数据被多次划分，并且需要训练多个模型。</li>
<li>最常用的交叉验证是 k 折交叉验证（k-fold cross-validation），其中 k 是由用户指定的数字，通常取 5 或 10。</li>
<li>准确率（precision）度量的是被预测为正例的样本中有多少是真正的正例</li>
<li>召回率（recall）度量的是正类样本中有多少被预测为正类</li>
<li>f-分数是准确率与召回率的调和平均</li>
</ul>
<p>【思考】：将上面的概念进一步的理解，大家可以做一下总结</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答：</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务一：交叉验证"><a href="#任务一：交叉验证" class="headerlink" title="任务一：交叉验证"></a>任务一：交叉验证</h4><ul>
<li>用10折交叉验证来评估之前的逻辑回归模型</li>
<li>计算交叉验证精度的平均值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提示：交叉验证</span></span><br><span class="line">Image(<span class="string">&#x27;Snipaste_2020-01-05_16-37-56.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_16_0.png" alt="第三章模型建立和评估---评价-课程_16_0"></p>
<h4 id="提示4"><a href="#提示4" class="headerlink" title="提示4"></a>提示4</h4><ul>
<li>交叉验证在sklearn中的模块为<code>sklearn.model_selection</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">lr = LogisticRegression(C=<span class="number">100</span>)</span><br><span class="line">scores = cross_val_score(lr, X_train, y_train, cv=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 平均交叉验证分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Average cross-validation score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(scores.mean()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Average cross-validation score: 0.78
</code></pre><h4 id="思考4"><a href="#思考4" class="headerlink" title="思考4"></a>思考4</h4><ul>
<li>k折越多的情况下会带来什么样的影响？</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 当 k 越大时：</span></span><br><span class="line"><span class="comment"># 1. 每次训练使用的数据更多，评估偏差（bias）降低</span></span><br><span class="line"><span class="comment"># 2. 每次测试集样本更少，评估方差（variance）增大</span></span><br><span class="line"><span class="comment"># 3. 需要训练 k 个模型，计算开销显著增加</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务二：混淆矩阵"><a href="#任务二：混淆矩阵" class="headerlink" title="任务二：混淆矩阵"></a>任务二：混淆矩阵</h4><ul>
<li>计算二分类问题的混淆矩阵</li>
<li>计算精确率、召回率以及f-分数</li>
</ul>
<p>【思考】什么是二分类问题的混淆矩阵，理解这个概念，知道它主要是运算到什么任务中的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 混淆矩阵（confusion matrix）是一个 2×2 的表格，用于二分类任务中展示模型预测结果与真实标签的对应关系：</span></span><br><span class="line"><span class="comment">#    - True Positive (TP)：真实为正类，预测也为正类</span></span><br><span class="line"><span class="comment">#    - False Positive (FP)：真实为负类，却被误预测为正类</span></span><br><span class="line"><span class="comment">#    - False Negative (FN)：真实为正类，却被误预测为负类</span></span><br><span class="line"><span class="comment">#    - True Negative (TN)：真实为负类，预测也为负类</span></span><br><span class="line"><span class="comment"># 通过混淆矩阵，可以进一步计算精确率（Precision）、召回率（Recall）、F1 分数等指标，</span></span><br><span class="line"><span class="comment"># 帮助我们评估模型在不同类型错误上的表现，常用于分类模型的性能评估和错误分析。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提示：混淆矩阵</span></span><br><span class="line">Image(<span class="string">&#x27;Snipaste_2020-01-05_16-38-26.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_27_0.png" alt="第三章模型建立和评估---评价-课程_27_0"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#提示：准确率 (Accuracy),精确度（Precision）,Recall,f-分数计算方法</span></span><br><span class="line">Image(<span class="string">&#x27;Snipaste_2020-01-05_16-39-27.png&#x27;</span>)</span><br><span class="line">​    </span><br></pre></td></tr></table></figure>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_28_0.png" alt="第三章模型建立和评估---评价-课程_28_0"></p>
<h4 id="提示5"><a href="#提示5" class="headerlink" title="提示5"></a>提示5</h4><ul>
<li>混淆矩阵的方法在sklearn中的<code>sklearn.metrics</code>模块</li>
<li>混淆矩阵需要输入真实标签和预测标签</li>
<li>精确率、召回率以及f-分数可使用<code>classification_report</code>模块</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lr = LogisticRegression(C=<span class="number">100</span>)</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 模型预测结果</span></span><br><span class="line">pred = lr.predict(X_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 混淆矩阵</span></span><br><span class="line">confusion_matrix(y_train, pred)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>array([[355,  57],
       [ 82, 174]])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="comment"># 精确率、召回率以及f1-score</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(y_train, pred))</span><br></pre></td></tr></table></figure>
<pre><code>              precision    recall  f1-score   support

           0       0.81      0.86      0.84       412
           1       0.75      0.68      0.71       256

    accuracy                           0.79       668
   macro avg       0.78      0.77      0.78       668
weighted avg       0.79      0.79      0.79       668
</code></pre><p>【思考】</p>
<ul>
<li>如果自己实现混淆矩阵的时候该注意什么问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 如果自己实现混淆矩阵，需要注意：</span></span><br><span class="line"><span class="comment"># 1. 明确行列含义：通常行是真实标签，列是预测标签，并保持一致。</span></span><br><span class="line"><span class="comment"># 2. 类别顺序要固定：最好指定 labels 列表，避免类别稀疏时错位。</span></span><br><span class="line"><span class="comment"># 3. 初始化大小为 n_classes×n_classes 的零矩阵。</span></span><br><span class="line"><span class="comment"># 4. 索引时使用整数或统一的类别映射，避免类型不一致。</span></span><br><span class="line"><span class="comment"># 5. 对每个样本累加到对应的 [真实, 预测] 单元格，最后矩阵元素之和应等于样本数。</span></span><br><span class="line"><span class="comment"># 6. 对于未出现的类别，矩阵对应行或列应保留 0。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务三：ROC曲线"><a href="#任务三：ROC曲线" class="headerlink" title="任务三：ROC曲线"></a>任务三：ROC曲线</h4><ul>
<li>绘制ROC曲线</li>
</ul>
<p>【思考】什么是ROC曲线，OCR曲线的存在是为了解决什么问题？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考</span></span><br><span class="line"><span class="comment"># ROC曲线（Receiver Operating Characteristic Curve）是一条以假正例率（FPR）为横坐标、</span></span><br><span class="line"><span class="comment"># 真正例率（TPR）为纵坐标绘制的曲线，展示模型在不同阈值下的分类性能变化。</span></span><br><span class="line"><span class="comment"># 它解决了单一阈值下评估不全面的问题，通过曲线下的面积（AUC）能够衡量模型整体区分正负样本的能力；</span></span><br><span class="line"><span class="comment"># 对类别不平衡更稳健，可在不同模型或参数设置间进行客观比较。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="提示6"><a href="#提示6" class="headerlink" title="提示6"></a>提示6</h4><ul>
<li>ROC曲线在sklearn中的模块为<code>sklearn.metrics</code></li>
<li>ROC曲线下面所包围的面积越大越好</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.decision_function(X_test))</span><br></pre></td></tr></table></figure>
<pre><code>[-1.7776276  -1.68901519 -2.9343385  -2.73339993 -0.7425476   0.1771919
  0.42300886 -0.95177507 -2.19297241 -2.09492243 -2.09876666 -2.24379328
 -0.72898893 -0.74448703  1.55206252  2.26736362 -3.0615053  -1.45551632
  1.82143942  1.10174703  2.80348253  2.20862227 -2.08595792 -1.98565326
 -2.62459231  2.61608127  2.52054836  0.46386814 -2.26805651 -1.89799476
 -4.40221097 -2.45118004 -2.11507984  0.25727282  1.56507901 -3.49922092
  0.09517543  3.1727335  -0.66659502 -2.16889122 -2.31738004 -0.75154631
  1.34173247 -0.68691348 -2.38317701 -1.48352807  3.30441868  0.37836543
  0.15120699 -2.39554116  0.71230509 -2.94049784  0.0526656  -0.12124772
  0.21937853 -0.95736671 -2.91315052  1.73227025 -2.30451919 -0.11949728
 -2.40406452 -1.23217853 -3.04709277 -2.51149884 -2.91275507  0.36741872
  1.88515182 -1.73344723  1.61180838 -2.64456699 -2.82671595 -1.32885535
 -1.89201447 -2.38194062  1.14830497  0.7324757   3.41575634 -0.04718518
  1.99047031  0.71098531 -2.5002286   2.11220527  1.35687779 -4.65208202
 -0.50164169 -2.21847127 -0.27744568 -2.1098023  -2.28203956 -2.24087733
  1.49913758 -0.46745632 -1.76590269 -3.13694507 -2.48969764 -2.52447108
 -0.31359417 -2.62456277  0.10812447 -3.22505518 -0.54301462 -1.31398633
 -2.45637232 -0.9392769  -1.99910791 -0.01952273  0.16386412  1.17043699
  0.83571934 -0.30892412 -2.56236834 -2.52630696 -2.15878988  3.38005162
 -1.63316112 -2.0470374   1.16802525  1.96428556 -0.85542758 -0.84711271
 -2.3923425  -2.27467461  1.27340371 -0.16738478  2.77379952 -0.91636487
  3.49337899  2.22265823 -1.03898765 -1.79576035  3.05405598 -1.72625544
 -2.08233698  0.14427761 -2.03826492 -1.87510703 -2.43040363  0.88364821
 -2.31722422  1.21479438 -2.19509856 -1.96948465  2.90456606  1.22909197
 -0.60993113 -2.40508898  1.79832298 -2.33619419 -1.76964851  0.54894164
  0.56920781 -1.65544357 -2.18783672 -2.51890544 -1.1167812   1.85506633
 -2.14366192  2.56003678  1.79741811  2.22038003 -0.93948297  2.11029939
  3.66773152  3.37255532 -1.62079149 -0.21922341 -2.93532548 -1.8851028
 -0.11223495 -0.89402373 -2.79168773  0.58319665 -1.20213471  2.11583429
 -1.78550619 -1.21648746 -2.91538781 -2.80005448 -2.74359191 -0.06775047
 -1.28645408 -1.17048578 -0.1176852  -1.59958242 -0.65901928 -2.40701243
  0.57575073 -3.0756839   1.53932753 -2.49031769 -3.03266822  0.30539932
 -0.05523861 -0.24431132 -2.36483723  3.25595248 -2.11664845 -1.97728592
 -2.04509461 -3.07727841 -1.11942703 -3.38920295 -2.59088459 -3.55978164
  0.22449105 -0.3214215   0.05735696  0.02061023 -3.01544378 -0.77973619
 -1.39798016 -3.10075724 -4.80621573 -3.01948006  3.44366918 -2.88193813
 -2.01992513 -0.09559774  0.91447527 -1.13270082 -2.45426968 -1.91415803
 -0.08403516]
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 计算ROC曲线的假正例率(FPR)、真正例率(TPR)和阈值</span></span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, lr.decision_function(X_test))</span><br><span class="line">plt.plot(fpr, tpr, label=<span class="string">&quot;ROC Curve&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;FPR&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;TPR (recall)&quot;</span>)</span><br><span class="line"><span class="comment"># 找到最接近于0的阈值</span></span><br><span class="line">close_zero = np.argmin(np.<span class="built_in">abs</span>(thresholds))</span><br><span class="line">plt.plot(fpr[close_zero], tpr[close_zero], <span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">10</span>, label=<span class="string">&quot;threshold zero&quot;</span>, fillstyle=<span class="string">&quot;none&quot;</span>, c=<span class="string">&#x27;k&#x27;</span>, mew=<span class="number">2</span>)</span><br><span class="line">plt.legend(loc=<span class="number">4</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0---%E8%AF%84%E4%BB%B7-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估---评价-课程_44_3.png" alt="第三章模型建立和评估---评价-课程_44_3"></p>
<h4 id="思考6"><a href="#思考6" class="headerlink" title="思考6"></a>思考6</h4><ul>
<li>对于多分类问题如何绘制ROC曲线</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【思考】你能从这条OCR曲线的到什么信息？这些信息可以做什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 从ROC曲线中可以得到以下信息：</span></span><br><span class="line"><span class="comment"># 1. 模型整体性能：曲线下的面积 (AUC - Area Under the Curve) 是一个常用的评估指标。</span></span><br><span class="line"><span class="comment">#    - AUC = 1：完美分类器。</span></span><br><span class="line"><span class="comment">#    - AUC = 0.5：随机分类器（无区分能力，ROC曲线接近对角线）。</span></span><br><span class="line"><span class="comment">#    - AUC &gt; 0.5：模型优于随机猜测。AUC越大，模型区分正负样本的能力越强。</span></span><br><span class="line"><span class="comment">#    - AUC &lt; 0.5：模型表现差于随机猜测（可能标签反了或者模型非常差）。</span></span><br><span class="line"><span class="comment"># 2. 不同阈值下的权衡：ROC曲线展示了在所有可能的分类阈值下，真正例率 (TPR) 与假正例率 (FPR) 之间的关系。</span></span><br><span class="line"><span class="comment">#    - 曲线上的每个点代表一个特定的阈值。</span></span><br><span class="line"><span class="comment">#    - 曲线越靠近左上角 (FPR低, TPR高)，说明模型在较低的假正例率下能达到较高的真正例率，性能越好。</span></span><br><span class="line"><span class="comment"># 3. 模型的区分能力：曲线的形状可以反映模型区分正负样本的能力。如果曲线显著高于对角线，说明模型具有较好的区分能力。</span></span><br><span class="line"><span class="comment"># 4. 阈值选择的依据：可以根据业务需求，在ROC曲线上选择一个合适的平衡点（即选择一个阈值）。</span></span><br><span class="line"><span class="comment">#    - 例如，如果更关注减少漏报（提高TPR），可以选择曲线上TPR较高的点，即使FPR可能略高。</span></span><br><span class="line"><span class="comment">#    - 如果更关注减少误报（降低FPR），可以选择曲线上FPR较低的点，即使TPR可能略低。</span></span><br><span class="line"><span class="comment">#    - 图中标记的 &quot;threshold zero&quot; 点通常是模型默认的分类阈值对应的性能点。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第一章：第一节数据载入及初步观察</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%BA%8C%E8%8A%82pandas%E5%9F%BA%E7%A1%80-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>数据分析的第一步，加载数据我们已经学习完毕了。当数据展现在我们面前的时候，我们所要做的第一步就是认识他，今天我们要学习的就是<strong>了解字段含义以及初步观察数据</strong>。</p>
<h2 id="1-第一章：数据载入及初步观察"><a href="#1-第一章：数据载入及初步观察" class="headerlink" title="1 第一章：数据载入及初步观察"></a>1 第一章：数据载入及初步观察</h2><h3 id="1-4-知道你的数据叫什么"><a href="#1-4-知道你的数据叫什么" class="headerlink" title="1.4 知道你的数据叫什么"></a>1.4 知道你的数据叫什么</h3><p>我们学习pandas的基础操作，那么上一节通过pandas加载之后的数据，其数据类型是什么呢？</p>
<p><strong>开始前导入numpy和pandas</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<h4 id="1-4-1-任务一：pandas中有两个数据类型DateFrame和Series，通过查找简单了解他们。然后自己写一个关于这两个数据类型的小例子🌰-开放题"><a href="#1-4-1-任务一：pandas中有两个数据类型DateFrame和Series，通过查找简单了解他们。然后自己写一个关于这两个数据类型的小例子🌰-开放题" class="headerlink" title="1.4.1 任务一：pandas中有两个数据类型DateFrame和Series，通过查找简单了解他们。然后自己写一个关于这两个数据类型的小例子🌰[开放题]"></a>1.4.1 任务一：pandas中有两个数据类型DateFrame和Series，通过查找简单了解他们。然后自己写一个关于这两个数据类型的小例子🌰[开放题]</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#我们举的例子</span></span><br><span class="line">sdata = &#123;<span class="string">&#x27;Ohio&#x27;</span>: <span class="number">35000</span>, <span class="string">&#x27;Texas&#x27;</span>: <span class="number">71000</span>, <span class="string">&#x27;Oregon&#x27;</span>: <span class="number">16000</span>, <span class="string">&#x27;Utah&#x27;</span>: <span class="number">5000</span>&#125;</span><br><span class="line">example_1 = pd.Series(sdata)</span><br><span class="line">example_1</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Ohio      35000
Texas     71000
Oregon    16000
Utah       5000
dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#我们举的例子</span></span><br><span class="line">data = &#123;<span class="string">&#x27;state&#x27;</span>: [<span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Ohio&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>, <span class="string">&#x27;Nevada&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2003</span>],<span class="string">&#x27;pop&#x27;</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>, <span class="number">3.2</span>]&#125;</span><br><span class="line">example_2 = pd.DataFrame(data)</span><br><span class="line">example_2</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>year</th>
      <th>pop</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Ohio</td>
      <td>2000</td>
      <td>1.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Ohio</td>
      <td>2001</td>
      <td>1.7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Ohio</td>
      <td>2002</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Nevada</td>
      <td>2001</td>
      <td>2.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Nevada</td>
      <td>2002</td>
      <td>2.9</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Nevada</td>
      <td>2003</td>
      <td>3.2</td>
    </tr>
  </tbody>
</table>
#### 1.4.2 任务二：根据上节课的方法载入"train.csv"文件

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df=pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>

也可以加载上一节课保存的"train_chinese.csv"文件。通过翻译版train_chinese.csv熟悉了这个数据集，然后我们对trian.csv来进行操作
#### 1.4.3 任务三：查看DataFrame数据的每列的名称


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.columns</span><br></pre></td></tr></table></figure>


    Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
           'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],
          dtype='object')

#### 1.4.4任务四：查看"Cabin"这列的所有值[有多种方法]


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[<span class="string">&#x27;Cabin&#x27;</span>].head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>


    0     NaN
    1     C85
    2     NaN
    3    C123
    4     NaN
    5     NaN
    6     E46
    7     NaN
    8     NaN
    9     NaN
    Name: Cabin, dtype: object


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.Cabin.values[:<span class="number">10</span>]</span><br><span class="line">df.Cabin.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>


    0     NaN
    1     C85
    2     NaN
    3    C123
    4     NaN
    5     NaN
    6     E46
    7     NaN
    8     NaN
    9     NaN
    Name: Cabin, dtype: object

#### 1.4.5 任务五：加载文件"test_1.csv"，然后对比"train.csv"，看看有哪些多出的列，然后将多出的列删除
经过我们的观察发现一个测试集test_1.csv有一列是多余的，我们需要将这个多余的列删去


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">test_1=pd.read_csv(<span class="string">&#x27;../第一单元项目集合/test_1.csv&#x27;</span>)</span><br><span class="line">test_1.head()</span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
      <th>a</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
      <td>100</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
      <td>100</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
      <td>100</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
      <td>100</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
      <td>100</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#test_1.columns</span></span><br><span class="line">test_1.drop(<span class="string">&#x27;Unnamed: 0&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">test_1.columns</span><br></pre></td></tr></table></figure>
<pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,
       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;, &#39;a&#39;],
      dtype=&#39;object&#39;)
</code></pre><p>【思考】还有其他的删除多余的列的方式吗？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 思考回答</span></span><br><span class="line"><span class="keyword">del</span> test_1[<span class="string">&#x27;Unnamed: 0&#x27;</span>]</span><br><span class="line">test_1.columns</span><br></pre></td></tr></table></figure>
<pre><code>Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;,
       &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;, &#39;a&#39;],
      dtype=&#39;object&#39;)
</code></pre><h4 id="1-4-6-任务六：-将-‘PassengerId’-’Name’-’Age’-’Ticket’-这几个列元素隐藏，只观察其他几个列元素"><a href="#1-4-6-任务六：-将-‘PassengerId’-’Name’-’Age’-’Ticket’-这几个列元素隐藏，只观察其他几个列元素" class="headerlink" title="1.4.6 任务六： 将[‘PassengerId’,’Name’,’Age’,’Ticket’]这几个列元素隐藏，只观察其他几个列元素"></a>1.4.6 任务六： 将[‘PassengerId’,’Name’,’Age’,’Ticket’]这几个列元素隐藏，只观察其他几个列元素</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.drop([<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Ticket&#x27;</span>], axis=<span class="number">1</span>).head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>8.4583</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>1</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>51.8625</td>
      <td>E46</td>
      <td>S</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>3</td>
      <td>1</td>
      <td>21.0750</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>0</td>
      <td>2</td>
      <td>11.1333</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1</td>
      <td>2</td>
      <td>female</td>
      <td>1</td>
      <td>0</td>
      <td>30.0708</td>
      <td>NaN</td>
      <td>C</td>
    </tr>
  </tbody>
</table>
【思考】对比任务五和任务六，是不是使用了不一样的方法(函数)，如果使用一样的函数如何完成上面的不同的要求呢？

【思考回答】

如果想要完全的删除你的数据结构，使用inplace=True，因为使用inplace就将原数据覆盖了，所以这里没有用

### 1.5 筛选的逻辑

表格数据中，最重要的一个功能就是要具有可筛选的能力，选出我所需要的信息，丢弃无用的信息。

下面我们还是用实战来学习pandas这个功能。

#### 1.5.1 任务一： 我们以"Age"为筛选条件，显示年龄在10岁以下的乘客信息。


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="built_in">print</span>((df[<span class="string">&#x27;Age&#x27;</span>]&lt;<span class="number">10</span>).head(<span class="number">2</span>))</span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>]&lt;<span class="number">10</span>].head(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

    0    False
    1    False
    Name: Age, dtype: bool

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>0</td>
      <td>3</td>
      <td>Palsson, Master. Gosta Leonard</td>
      <td>male</td>
      <td>2.0</td>
      <td>3</td>
      <td>1</td>
      <td>349909</td>
      <td>21.075</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11</td>
      <td>1</td>
      <td>3</td>
      <td>Sandstrom, Miss. Marguerite Rut</td>
      <td>female</td>
      <td>4.0</td>
      <td>1</td>
      <td>1</td>
      <td>PP 9549</td>
      <td>16.700</td>
      <td>G6</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
#### 1.5.2 任务二： 以"Age"为条件，将年龄在10岁以上和50岁以下的乘客信息显示出来，并将这个数据命名为midage


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage=df[(df[<span class="string">&#x27;Age&#x27;</span>]&gt;<span class="number">10</span>) &amp; (df[<span class="string">&#x27;Age&#x27;</span>]&lt;<span class="number">50</span>)]</span><br><span class="line">midage</span><br></pre></td></tr></table></figure>





【提示】了解pandas的条件筛选方式以及如何使用交集和并集操作

#### 1.5.3 任务三：将midage的数据中第100行的"Pclass"和"Sex"的数据显示出来


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage = midage.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(midage)</span><br><span class="line">midage.loc[<span class="number">1</span>][[<span class="string">&#x27;Pclass&#x27;</span>, <span class="string">&#x27;Sex&#x27;</span>]]</span><br></pre></td></tr></table></figure>

         PassengerId  Survived  Pclass  \
    0              1         0       3   
    1              2         1       1   
    2              3         1       3   
    3              4         1       1   
    4              5         0       3   
    ..           ...       ...     ...   
    571          886         0       3   
    572          887         0       2   
    573          888         1       1   
    574          890         1       1   
    575          891         0       3   

                                                      Name     Sex   Age  SibSp  \
    0                              Braund, Mr. Owen Harris    male  22.0      1   
    1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   
    2                               Heikkinen, Miss. Laina  female  26.0      0   
    3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   
    4                             Allen, Mr. William Henry    male  35.0      0   
    ..                                                 ...     ...   ...    ...   
    571               Rice, Mrs. William (Margaret Norton)  female  39.0      0   
    572                              Montvila, Rev. Juozas    male  27.0      0   
    573                       Graham, Miss. Margaret Edith  female  19.0      0   
    574                              Behr, Mr. Karl Howell    male  26.0      0   
    575                                Dooley, Mr. Patrick    male  32.0      0   

         Parch            Ticket     Fare Cabin Embarked  
    0        0         A/5 21171   7.2500   NaN        S  
    1        0          PC 17599  71.2833   C85        C  
    2        0  STON/O2. 3101282   7.9250   NaN        S  
    3        0            113803  53.1000  C123        S  
    4        0            373450   8.0500   NaN        S  
    ..     ...               ...      ...   ...      ...  
    571      5            382652  29.1250   NaN        Q  
    572      0            211536  13.0000   NaN        S  
    573      0            112053  30.0000   B42        S  
    574      0            111369  30.0000  C148        C  
    575      0            370376   7.7500   NaN        Q  

    [576 rows x 12 columns]



    Pclass         1
    Sex       female
    Name: 1, dtype: object



【提示】在抽取数据中，我们希望数据的相对顺序保持不变，用什么函数可以达到这个效果呢？

#### 1.5.4 任务四：使用loc方法将midage的数据中第100，105，108行的"Pclass"，"Name"和"Sex"的数据显示出来


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage.loc[[<span class="number">100</span>,<span class="number">105</span>,<span class="number">108</span>],[<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Name&#x27;</span>,<span class="string">&#x27;Sex&#x27;</span>]] </span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>100</th>
      <td>2</td>
      <td>Byles, Rev. Thomas Roussel Davids</td>
      <td>male</td>
    </tr>
    <tr>
      <th>105</th>
      <td>3</td>
      <td>Cribb, Mr. John Hatfield</td>
      <td>male</td>
    </tr>
    <tr>
      <th>108</th>
      <td>3</td>
      <td>Calic, Mr. Jovo</td>
      <td>male</td>
    </tr>
  </tbody>
</table>
#### 1.5.5 任务五：使用iloc方法将midage的数据中第100，105，108行的"Pclass"，"Name"和"Sex"的数据显示出来


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">midage.iloc[[<span class="number">100</span>,<span class="number">105</span>,<span class="number">108</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]] </span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>149</th>
      <td>2</td>
      <td>Byles, Rev. Thomas Roussel Davids</td>
      <td>male</td>
    </tr>
    <tr>
      <th>160</th>
      <td>3</td>
      <td>Cribb, Mr. John Hatfield</td>
      <td>male</td>
    </tr>
    <tr>
      <th>163</th>
      <td>3</td>
      <td>Calic, Mr. Jovo</td>
      <td>male</td>
    </tr>
  </tbody>
</table>


<p>【思考】对比<code>iloc</code>和<code>loc</code>的异同</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># *   当你需要根据**标签名称**（如行索引名或列名）来选取数据时，使用 `loc`。这使得代码更具可读性，因为你可以直接看到你正在操作的标签。</span></span><br><span class="line"><span class="comment"># *   当你需要根据**整数位置**来选取数据时（不关心标签名称，或者标签不是整数），使用 `iloc`。这在处理没有有意义标签的 DataFrame，或者需要进行与位置相关的操作时很有用。</span></span><br><span class="line"><span class="comment"># *   **注意**：如果 DataFrame 的索引是默认的整数索引 (0, 1, 2, ...)，那么 `loc` 和 `iloc` 在使用单个整数或整数切片进行行选择时，行为可能会相似，但这可能会导致混淆。</span></span><br><span class="line"><span class="comment">#     *   例如，如果 `df.index` 是 `[0, 1, 2, 5, 6]`：</span></span><br><span class="line"><span class="comment">#         *   `df.loc[0]` 会选择索引标签为 `0` 的行。</span></span><br><span class="line"><span class="comment">#         *   `df.iloc[0]` 也会选择第一行（即索引标签为 `0` 的行）。</span></span><br><span class="line"><span class="comment">#         *   `df.loc[3]` 会报错，因为没有索引标签为 `3`。</span></span><br><span class="line"><span class="comment">#         *   `df.iloc[3]` 会选择第四行（即索引标签为 `5` 的行）。</span></span><br><span class="line"><span class="comment"># *   为了避免混淆，最佳实践是：当你知道你正在使用标签时，明确使用 `loc`；当你知道你正在使用整数位置时，明确使用 `iloc`。</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第三章模型建立和评估--建模</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0--%E5%BB%BA%E6%A8%A1-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="第三章-模型搭建和评估—建模"><a href="#第三章-模型搭建和评估—建模" class="headerlink" title="第三章 模型搭建和评估—建模"></a>第三章 模型搭建和评估—建模</h2><p>经过前面的两章的知识点的学习，我可以对数数据的本身进行处理，比如数据本身的增删查补，还可以做必要的清洗工作。那么下面我们就要开始使用我们前面处理好的数据了。这一章我们要做的就是使用数据，我们做数据分析的目的也就是，运用我们的数据以及结合我的业务来得到某些我们需要知道的结果。那么分析的第一步就是建模，搭建一个预测模型或者其他模型；我们从这个模型的到结果之后，我们要分析我的模型是不是足够的可靠，那我就需要评估这个模型。今天我们学习建模，下一节我们学习评估。</p>
<p>我们拥有的泰坦尼克号的数据集，那么我们这次的目的就是，完成泰坦尼克号存活预测这个任务。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">6</span>)  <span class="comment"># 设置输出图片大小</span></span><br></pre></td></tr></table></figure>
<p>载入这些库，如果缺少某些库，请安装他们</p>
<p>【思考】这些库的作用是什么呢？你需要查一查</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考题回答</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Image 是 IPython.display 模块的一部分，用于在 Jupyter Notebook 或 IPython 环境中直接显示图像。支持从本地路径或网络 URL 加载图像，并控制显示格式（如宽度、高度、格式类型）</span></span><br><span class="line"><span class="string">seaborn 是一个基于 Matplotlib 的高级数据可视化库，专注于统计图形的绘制（如分布图、相关性图、分类图等），能快速生成美观且信息丰富的图表</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>&#39;\nImage 是 IPython.display 模块的一部分，用于在 Jupyter Notebook 或 IPython 环境中直接显示图像。支持从本地路径或网络 URL 加载图像，并控制显示格式（如宽度、高度、格式类型）\nseaborn 是一个基于 Matplotlib 的高级数据可视化库，专注于统计图形的绘制（如分布图、相关性图、分类图等），能快速生成美观且信息丰富的图表\n&#39;
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<p> <strong>载入我们提供清洗之后的数据(clear_data.csv)，大家也将原始数据载入（train.csv），说说他们有什么不同</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">train.shape</span><br></pre></td></tr></table></figure>
<pre><code>(891, 12)
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre><p>&lt;/style&gt;</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>





<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;clear_data.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Sex_female</th>
      <th>Sex_male</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>3</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>1</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>3</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>


<h3 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a>模型搭建</h3><ul>
<li>处理完前面的数据我们就得到建模数据，下一步是选择合适模型</li>
<li>在进行模型选择之前我们需要先知道数据集最终是进行<strong>监督学习</strong>还是<strong>无监督学习</strong></li>
<li>模型的选择一方面是通过我们的任务来决定的。</li>
<li>除了根据我们任务来选择模型外，还可以根据数据样本量以及特征的稀疏性来决定</li>
<li>刚开始我们总是先尝试使用一个基本的模型来作为其baseline，进而再训练其他模型做对比，最终选择泛化能力或性能比较好的模型</li>
</ul>
<p>这里我的建模，并不是从零开始，自己一个人完成完成所有代码的编译。我们这里使用一个机器学习最常用的一个库（sklearn）来完成我们的模型的搭建</p>
<p><strong>下面给出sklearn的算法选择路径，供大家参考</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sklearn模型算法选择路径图</span></span><br><span class="line">Image(<span class="string">&#x27;sklearn.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%B8%89%E7%AB%A0%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E5%92%8C%E8%AF%84%E4%BC%B0--%E5%BB%BA%E6%A8%A1-%E8%AF%BE%E7%A8%8B/第三章模型建立和评估--建模-课程_17_0.png" alt="第三章模型建立和评估--建模-课程_17_0"></p>
<p>【思考】数据集哪些差异会导致模型在拟合数据是发生变化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务一：切割训练集和测试集"><a href="#任务一：切割训练集和测试集" class="headerlink" title="任务一：切割训练集和测试集"></a>任务一：切割训练集和测试集</h4><p>这里使用留出法划分数据集</p>
<ul>
<li>将数据集分为自变量和因变量</li>
<li>按比例切割训练集和测试集(一般测试集的比例有30%、25%、20%、15%和10%)</li>
<li>使用分层抽样</li>
<li>设置随机种子以便结果能复现</li>
</ul>
<p>【思考】</p>
<ul>
<li>划分数据集的方法有哪些？</li>
<li>为什么使用分层抽样，这样的好处有什么？</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 划分数据集的方法有哪些？</span></span><br><span class="line"><span class="comment"># 1.  **留出法 (Hold-out Cross Validation)**：</span></span><br><span class="line"><span class="comment">#     *   直接将数据集D划分为两个互斥的集合：训练集S和测试集T。</span></span><br><span class="line"><span class="comment">#     *   例如，70%的数据用于训练，30%用于测试。</span></span><br><span class="line"><span class="comment">#     *   优点：简单、计算开销小。</span></span><br><span class="line"><span class="comment">#     *   缺点：划分具有随机性，单次划分的结果可能不够稳定和准确，尤其是在数据集较小时。训练集和测试集的样本比例会影响评估结果。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.  **交叉验证法 (Cross Validation)**：</span></span><br><span class="line"><span class="comment">#     *   **k折交叉验证 (k-Fold Cross Validation)**：</span></span><br><span class="line"><span class="comment">#         *   将数据集D划分为k个大小相似的互斥子集 D1, D2, ..., Dk。</span></span><br><span class="line"><span class="comment">#         *   每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集。</span></span><br><span class="line"><span class="comment">#         *   这样可以获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这k个测试结果的均值。</span></span><br><span class="line"><span class="comment">#         *   常用的k值为5或10。</span></span><br><span class="line"><span class="comment">#         *   优点：比留出法更稳定，更充分地利用了数据。</span></span><br><span class="line"><span class="comment">#         *   缺点：计算开销是k倍。</span></span><br><span class="line"><span class="comment">#     *   **留一法 (Leave-One-Out Cross Validation, LOOCV)**：</span></span><br><span class="line"><span class="comment">#         *   k折交叉验证的特例，当k等于样本数N时。</span></span><br><span class="line"><span class="comment">#         *   每次只留下一个样本作为测试集，其余N-1个样本作为训练集。</span></span><br><span class="line"><span class="comment">#         *   优点：评估结果通常被认为比较准确，因为几乎所有数据都用于训练。</span></span><br><span class="line"><span class="comment">#         *   缺点：计算开销非常大，尤其是在数据集很大时。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.  **自助法 (Bootstrapping)**：</span></span><br><span class="line"><span class="comment">#     *   以自助采样法为基础。给定包含m个样本的数据集D，对它进行采样产生数据集D&#x27;：每次随机从D中挑选一个样本，将其拷贝放入D&#x27;，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到。这个过程重复执行m次后，我们就得到了包含m个样本的数据集D&#x27;。</span></span><br><span class="line"><span class="comment">#     *   可以证明，初始数据集D中约有36.8%的样本未出现在采样数据集D&#x27;中。于是我们可将D&#x27;用作训练集，D\D&#x27;用作测试集。</span></span><br><span class="line"><span class="comment">#     *   优点：在数据集较小、难以有效划分训练/测试集时很有用；能从初始数据集中产生多个不同的训练集。</span></span><br><span class="line"><span class="comment">#     *   缺点：自助法产生的数据集改变了初始数据集的分布，会引入估计偏差。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为什么使用分层抽样，这样的好处有什么？</span></span><br><span class="line"><span class="comment"># **分层抽样 (Stratified Sampling)** 是一种抽样技术，它将总体（数据集）划分为若干个互不重叠的子群（称为“层”），然后从每个层中独立地进行简单随机抽样。在划分训练集和测试集时，特别是对于分类任务，通常是根据目标变量的类别进行分层。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># **好处：**</span></span><br><span class="line"><span class="comment"># 1.  **保持类别比例一致性**：</span></span><br><span class="line"><span class="comment">#     *   确保训练集和测试集中的各个类别的样本比例与原始数据集中各个类别的样本比例大致相同。</span></span><br><span class="line"><span class="comment">#     *   这对于类别不平衡的数据集尤为重要。如果进行纯随机抽样，可能会导致训练集或测试集中某些少数类别的样本过少，甚至没有，从而影响模型的训练效果和评估的可靠性。</span></span><br><span class="line"><span class="comment"># 2.  **提高模型的泛化能力和评估的准确性**：</span></span><br><span class="line"><span class="comment">#     *   由于训练集和测试集都较好地代表了原始数据的类别分布，模型在训练时能学习到各个类别的特征，评估时也能更准确地反映模型在所有类别上的表现。</span></span><br><span class="line"><span class="comment">#     *   避免了因随机划分导致训练集和测试集在类别分布上产生较大差异，从而使得模型评估结果更加稳定和可信。</span></span><br><span class="line"><span class="comment"># 3.  **减少抽样误差**：</span></span><br><span class="line"><span class="comment">#     *   相比于简单随机抽样，分层抽样通常能得到更具代表性的样本，从而减少因抽样带来的误差，使得基于样本的推断更加精确。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务提示1"><a href="#任务提示1" class="headerlink" title="任务提示1"></a>任务提示1</h4><ul>
<li>切割数据集是为了后续能评估模型泛化能力</li>
<li>sklearn中切割数据集的方法为<code>train_test_split</code></li>
<li>查看函数文档可以在jupyter noteboo里面使用<code>train_test_split?</code>后回车即可看到</li>
<li>分层和随机种子在参数里寻找</li>
</ul>
<p>要从clear_data.csv和train.csv中提取train_test_split()所需的参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment"># 一般先取出X和y后再切割，有些情况会使用到未切割的，这时候X和y就可以用,x是清洗好的数据，y是我们要预测的存活数据&#x27;Survived&#x27;</span></span><br><span class="line">X = data</span><br><span class="line">y = train[<span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line"><span class="comment"># 对数据集进行切割</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">X_train.shape, X_test.shape</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>((668, 11), (223, 11))
</code></pre><p>【思考】</p>
<ul>
<li>什么情况下切割数据集的时候不用进行随机选取</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 在以下情况下切割数据集时可能不需要或不适合进行随机选取：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.  **时间序列数据 (Time Series Data)**：</span></span><br><span class="line"><span class="comment">#     *   对于时间序列数据，数据的顺序至关重要，因为它包含了时间依赖性。随机打乱顺序会破坏这种依赖关系。</span></span><br><span class="line"><span class="comment">#     *   通常的做法是按时间顺序划分，例如，将较早的数据作为训练集，较晚的数据作为测试集（或验证集）。这更符合实际应用中用过去预测未来的场景。</span></span><br><span class="line"><span class="comment">#     *   例如，用前几年的股票数据训练模型，用最近一年的数据测试模型。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.  **数据已经预先排序或具有特定结构**：</span></span><br><span class="line"><span class="comment">#     *   如果数据集已经按照某种对分析有意义的顺序排列（例如，按地理区域、按实验批次等），并且你希望测试集来自与训练集不同的、特定的部分，那么可能需要按顺序或按特定规则划分，而不是随机划分。</span></span><br><span class="line"><span class="comment">#     *   例如，在一个全国性的调查数据中，你可能想用某些省份的数据做训练，用另一些省份的数据做测试，以检验模型的地域泛化能力。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.  **数据集非常大且分布均匀**：</span></span><br><span class="line"><span class="comment">#     *   当数据集非常庞大，并且可以合理假设数据是独立同分布 (i.i.d.) 且分布均匀时，简单地按顺序取一部分作为训练集，另一部分作为测试集，其效果可能与随机选取相差不大。随机选取的计算开销在这种情况下可能显得不必要。</span></span><br><span class="line"><span class="comment">#     *   然而，即使在这种情况下，随机选取通常仍然是更稳妥的做法，以避免潜在的未知偏差。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.  **特定的交叉验证策略**：</span></span><br><span class="line"><span class="comment">#     *   某些交叉验证方法本身就定义了非随机的划分方式。例如，在k折交叉验证中，虽然整体上数据被分成了k折，但每一折的选择是确定的（通常是按顺序分割）。留一法交叉验证更是每次只留一个特定的样本作为测试集。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.  **当需要完全复现特定的、非随机的划分结果时**：</span></span><br><span class="line"><span class="comment">#     *   如果之前的研究或实验使用了某种特定的非随机划分方式，为了比较或复现结果，也需要采用相同的划分方式。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.  **流式数据或在线学习场景**：</span></span><br><span class="line"><span class="comment">#     *   在数据持续不断流入的场景中，模型可能需要用新到达的数据进行测试或持续训练。这种情况下，测试集自然是最新的一部分数据，而不是从历史数据中随机抽取的。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务二：模型创建"><a href="#任务二：模型创建" class="headerlink" title="任务二：模型创建"></a>任务二：模型创建</h4><ul>
<li>创建基于线性模型的分类模型（逻辑回归）</li>
<li>创建基于树的分类模型（决策树、随机森林）</li>
<li>分别使用这些模型进行训练，分别的到训练集和测试集的得分</li>
<li>查看模型的参数，并更改参数值，观察模型变化</li>
</ul>
<h4 id="提示"><a href="#提示" class="headerlink" title="提示"></a>提示</h4><ul>
<li>逻辑回归不是回归模型而是分类模型，不要与<code>LinearRegression</code>混淆</li>
<li>随机森林其实是决策树集成为了降低决策树过拟合的情况</li>
<li>线性模型所在的模块为<code>sklearn.linear_model</code></li>
<li>树模型所在的模块为<code>sklearn.ensemble</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 默认参数逻辑回归模型</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 查看训练集和测试集score值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr.score(X_train, y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr.score(X_test, y_test)))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Training set score: 0.80
Testing set score: 0.79
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment"># 调整参数后的逻辑回归模型</span></span><br><span class="line">lr2 = LogisticRegression(C=<span class="number">100</span>)</span><br><span class="line">lr2.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr2.score(X_train, y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(lr2.score(X_test, y_test)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Training set score: 0.79
Testing set score: 0.78


/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认参数的随机森林分类模型</span></span><br><span class="line">rfc = RandomForestClassifier()</span><br><span class="line">rfc.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc.score(X_train, y_train)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Testing set score: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(rfc.score(X_test, y_test)))</span><br></pre></td></tr></table></figure>
<pre><code>Training set score: 1.00
Testing set score: 0.82
</code></pre><p>【思考】</p>
<ul>
<li>为什么线性模型可以进行分类任务，背后是怎么的数学关系</li>
<li>对于多分类问题，线性模型是怎么进行分类的</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment"># 为什么线性模型可以进行分类任务，背后是怎么的数学关系</span></span><br><span class="line"><span class="comment"># 线性模型（如逻辑回归 Logistic Regression，或者支持向量机 SVM 的线性核）之所以能用于分类任务，是因为它们通过以下方式将线性组合的输入特征映射到类别预测：</span></span><br><span class="line"><span class="comment"># 1.  **线性组合**：首先，模型计算输入特征的线性组合，形式通常为 `z = w_1*x_1 + w_2*x_2 + ... + w_n*x_n + b`，或者用向量表示为 `z = w^T * x + b`。</span></span><br><span class="line"><span class="comment">#     *   `x` 是输入特征向量。</span></span><br><span class="line"><span class="comment">#     *   `w` 是模型学习到的权重（或系数）。</span></span><br><span class="line"><span class="comment">#     *   `b` 是偏置项（或截距）。</span></span><br><span class="line"><span class="comment">#     这个 `z` 值可以看作是样本点到决策边界的某种度量。</span></span><br><span class="line"><span class="comment"># 2.  **决策函数/激活函数**：然后，这个线性组合的结果 `z` 会被传递给一个决策函数或激活函数，该函数将其转换为类别预测或类别概率。</span></span><br><span class="line"><span class="comment">#     *   **对于逻辑回归 (Logistic Regression)**：</span></span><br><span class="line"><span class="comment">#         *   它使用 Sigmoid (Logistic) 函数：`p = 1 / (1 + e^(-z))`。</span></span><br><span class="line"><span class="comment">#         *   Sigmoid 函数将任意实数值 `z` 映射到 (0, 1) 区间，这个输出 `p` 可以解释为样本属于正类（通常是类别1）的概率。</span></span><br><span class="line"><span class="comment">#         *   通过设定一个阈值（通常是0.5），如果 `p &gt; 0.5` (即 `z &gt; 0`)，则预测为正类；否则预测为负类。</span></span><br><span class="line"><span class="comment">#         *   因此，决策边界是 `z = 0`，即 `w^T * x + b = 0`，这是一个超平面。</span></span><br><span class="line"><span class="comment">#     *   **对于线性支持向量机 (Linear SVM)**：</span></span><br><span class="line"><span class="comment">#         *   它直接使用 `z` 的符号来决定类别。如果 `z &gt; 0`，预测为一类；如果 `z &lt; 0`，预测为另一类。</span></span><br><span class="line"><span class="comment">#         *   SVM 的目标是找到一个能最大化两类样本之间间隔（margin）的决策边界（超平面）。</span></span><br><span class="line"><span class="comment"># 总结来说，线性模型通过学习一个线性决策边界（直线、平面或超平面）来分隔不同类别的样本。它们首先计算一个线性得分，然后通过一个非线性函数（如Sigmoid）或直接根据得分的符号来做出分类决策。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于多分类问题，线性模型是怎么进行分类的</span></span><br><span class="line"><span class="comment"># 当类别数量大于两个时（即多分类问题），线性模型通常采用以下两种主要策略之一将问题转化为多个二分类问题：</span></span><br><span class="line"><span class="comment"># 1.  **一对余 (One-vs-Rest, OvR) 或 一对所有 (One-vs-All, OvA)**：</span></span><br><span class="line"><span class="comment">#     *   **原理**：如果有个 `K` 个类别，OvR 策略会训练 `K` 个独立的二分类器。</span></span><br><span class="line"><span class="comment">#     *   第 `i` 个分类器 (`i` 从 1 到 `K`) 会将类别 `i` 的样本视为正类，而将所有其他 `K-1` 个类别的样本视为负类。</span></span><br><span class="line"><span class="comment">#     *   **预测**：对于一个新的样本，它会被输入到所有 `K` 个分类器中。每个分类器都会输出一个分数或概率，表示该样本属于其对应“正类”的置信度。最终，样本被分配给那个给出最高置信度分数的类别。</span></span><br><span class="line"><span class="comment">#     *   **优点**：直观，实现相对简单，计算效率较高（只需要训练K个分类器）。</span></span><br><span class="line"><span class="comment">#     *   **缺点**：当类别数量很多时，每个二分类器的负类可能包含非常多样化的样本，可能导致类别不平衡问题。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.  **一对一 (One-vs-One, OvO)**：</span></span><br><span class="line"><span class="comment">#     *   **原理**：如果有个 `K` 个类别，OvO 策略会为每一对类别 `(i, j)` 训练一个二分类器，其中 `i != j`。总共需要训练 `K * (K-1) / 2` 个分类器。</span></span><br><span class="line"><span class="comment">#     *   每个分类器只负责区分两个特定的类别。</span></span><br><span class="line"><span class="comment">#     *   **预测**：对于一个新的样本，它会被输入到所有 `K * (K-1) / 2` 个分类器中。每个分类器都会对样本属于其两个类别中的哪一个进行投票。最终，样本被分配给获得最多投票的类别。</span></span><br><span class="line"><span class="comment">#     *   **优点**：每个分类器只需要处理两个类别的数据，通常训练速度更快，且对于某些对类别不平衡不敏感的算法（如SVM）可能表现更好。</span></span><br><span class="line"><span class="comment">#     *   **缺点**：当类别数量 `K` 很大时，需要训练的分类器数量会急剧增加，导致计算成本和存储成本较高。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># **在 scikit-learn 中**：</span></span><br><span class="line"><span class="comment"># *   `LogisticRegression` 默认使用 OvR 策略进行多分类 (可以通过 `multi_class` 参数设置为 `&#x27;multinomial&#x27;` 来使用 Softmax 回归，这是一种直接处理多分类的方法，但其基础仍然是线性的)。</span></span><br><span class="line"><span class="comment"># *   `LinearSVC` (线性支持向量机) 默认使用 OvR 策略。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="任务三：输出模型预测结果"><a href="#任务三：输出模型预测结果" class="headerlink" title="任务三：输出模型预测结果"></a>任务三：输出模型预测结果</h4><ul>
<li>输出模型预测分类标签</li>
<li>输出不同分类标签的预测概率</li>
</ul>
<h4 id="提示3"><a href="#提示3" class="headerlink" title="提示3"></a>提示3</h4><ul>
<li>一般监督模型在sklearn里面有个<code>predict</code>能输出预测标签，<code>predict_proba</code>则可以输出标签概率</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred = lr.predict(X_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([0, 1, 1, 1, 0, 0, 1, 0, 1, 1])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred_proba = lr.predict_proba(X_train)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">pred_proba[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.60887905, 0.39112095],
       [0.17668722, 0.82331278],
       [0.40624596, 0.59375404],
       [0.18896449, 0.81103551],
       [0.87984221, 0.12015779],
       [0.91385758, 0.08614242],
       [0.13282516, 0.86717484],
       [0.90555878, 0.09444122],
       [0.05280619, 0.94719381],
       [0.10934565, 0.89065435]])
</code></pre><p>【思考】</p>
<ul>
<li>预测标签的概率对我们有什么帮助</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第一节数据清洗及特征处理</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%80%E8%8A%82%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E5%8F%8A%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p>【回顾&amp;引言】前面一章的内容大家可以感觉到我们主要是对基础知识做一个梳理，让大家了解数据分析的一些操作，主要做了数据的各个角度的观察。那么在这里，我们主要是做数据分析的流程性学习，主要是包括了数据清洗以及数据的特征处理，数据重构以及数据可视化。这些内容是为数据分析最后的建模和模型评价做一个铺垫。</p>
<h4 id="开始之前，导入numpy、pandas包和数据"><a href="#开始之前，导入numpy、pandas包和数据" class="headerlink" title="开始之前，导入numpy、pandas包和数据"></a>开始之前，导入numpy、pandas包和数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载所需的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载数据train.csv</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;./titanic/train.csv&#x27;</span>)</span><br><span class="line">df.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
## 2 第二章：数据清洗及特征处理
我们拿到的数据通常是不干净的，所谓的不干净，就是数据中有缺失值，有一些异常点等，需要经过一定的处理才能继续做后面的分析或建模，所以拿到数据的第一步是进行数据清洗，本章我们将学习缺失值、重复值、字符串和数据转换等操作，将数据清洗成可以分析或建模的亚子。

### 2.1 缺失值观察与处理
我们拿到的数据经常会有很多缺失值，比如我们可以看到Cabin列存在NaN，那其他列还有没有缺失值，这些缺失值要怎么处理呢

#### 2.1.1 任务一：缺失值观察
(1) 请查看每个特征缺失值个数  
(2) 请查看Age， Cabin， Embarked列的数据
以上方式都有多种方式，所以大家多多益善


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure>

    <class 'pandas.core.frame.dataframe'>
    RangeIndex: 891 entries, 0 to 890
    Data columns (total 12 columns):
     #   Column       Non-Null Count  Dtype  
    ---  ------       --------------  -----  
     0   PassengerId  891 non-null    int64  
     1   Survived     891 non-null    int64  
     2   Pclass       891 non-null    int64  
     3   Name         891 non-null    object 
     4   Sex          891 non-null    object 
     5   Age          714 non-null    float64
     6   SibSp        891 non-null    int64  
     7   Parch        891 non-null    int64  
     8   Ticket       891 non-null    object 
     9   Fare         891 non-null    float64
     10  Cabin        204 non-null    object 
     11  Embarked     889 non-null    object 
    dtypes: float64(2), int64(5), object(5)
    memory usage: 83.7+ KB

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




    PassengerId      0
    Survived         0
    Pclass           0
    Name             0
    Sex              0
    Age            177
    SibSp            0
    Parch            0
    Ticket           0
    Fare             0
    Cabin          687
    Embarked         2
    dtype: int64




<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[[<span class="string">&#x27;Age&#x27;</span>,<span class="string">&#x27;Cabin&#x27;</span>,<span class="string">&#x27;Embarked&#x27;</span>]].head(<span class="number">3</span>)</span><br><span class="line"><span class="comment">#df[&#x27;Age&#x27;].head(3)</span></span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>22.0</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38.0</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>26.0</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
外层 [] 是 DataFrame 的索引操作符。
内层 [] 是 Python 原生的列表语法，用于传递多个列名。

#### 2.1.2 任务二：对缺失值进行处理
(1)处理缺失值一般有几种思路

(2) 请尝试对Age列的数据的缺失值进行处理

(3) 请尝试使用不同的方法直接对整张表的缺失值进行处理  

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#处理缺失值的一般思路：</span></span><br><span class="line"><span class="comment">#提醒：可使用的函数有---&gt;dropna函数与fillna函数</span></span><br><span class="line"><span class="comment">#print(df.head(3))</span></span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>]==<span class="literal">None</span>]=<span class="number">0</span></span><br><span class="line">df.head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>].isnull()]</span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>].isnull()] = <span class="number">0</span> </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[df[<span class="string">&#x27;Age&#x27;</span>] == np.nan] = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>【思考1】dropna和fillna有哪些参数，分别如何使用呢?  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#dropna() 是 Pandas 中用于删除包含缺失值（NaN 或 None）的行或列的函数。其核心作用是清理数据中的缺失值，适用于数据清洗阶段。</span></span><br><span class="line">df.dropna().head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0000</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#fillna() 是 Pandas 中用于填充缺失值（NaN 或 None）的核心函数，常用于数据清洗阶段。其核心作用是将缺失值替换为合理值，以便后续分析或建模。</span></span><br><span class="line">df.fillna(<span class="number">0</span>).head(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>0</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>0</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>



<p>【思考】检索空缺值用<code>np.nan</code>,<code>None</code>以及<code>.isnull()</code>哪个更好，这是为什么？如果其中某个方式无法找到缺失值，原因又是为什么？</p>
<p>【参考】<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html</a></p>
<p>【参考】<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html</a></p>
<h3 id="2-2-重复值观察与处理"><a href="#2-2-重复值观察与处理" class="headerlink" title="2.2 重复值观察与处理"></a>2.2 重复值观察与处理</h3><p>由于这样那样的原因，数据中会不会存在重复值呢，如果存在要怎样处理呢</p>
<h4 id="2-2-1-任务一：请查看数据中的重复值"><a href="#2-2-1-任务一：请查看数据中的重复值" class="headerlink" title="2.2.1 任务一：请查看数据中的重复值"></a>2.2.1 任务一：请查看数据中的重复值</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#df.duplicated()返回一个布尔序列 (Series)，标记每一行是否为重复行</span></span><br><span class="line">df[df.duplicated()]</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>17</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>26</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>28</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>29</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>859</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>863</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>868</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>878</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>888</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>176 rows × 12 columns</p>


#### 2.2.2 任务二：对重复值进行处理
(1)重复值有哪些处理方式呢？

(2)处理我们数据的重复值

方法多多益善


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#重复值有哪些处理方式：</span></span><br><span class="line"><span class="comment">#删除 DataFrame 中的重复行（完全相同的行只保留一次）。</span></span><br><span class="line">df = df.drop_duplicates()</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>


<h4 id="2-2-3-任务三：将前面清洗的数据保存为csv格式"><a href="#2-2-3-任务三：将前面清洗的数据保存为csv格式" class="headerlink" title="2.2.3 任务三：将前面清洗的数据保存为csv格式"></a>2.2.3 任务三：将前面清洗的数据保存为csv格式</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">df.to_csv(<span class="string">&#x27;test_clear.csv&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="2-3-特征观察与处理"><a href="#2-3-特征观察与处理" class="headerlink" title="2.3 特征观察与处理"></a>2.3 特征观察与处理</h3><p>我们对特征进行一下观察，可以把特征大概分为两大类：<br>数值型特征：Survived ，Pclass， Age ，SibSp， Parch， Fare，其中Survived， Pclass为离散型数值特征，Age，SibSp， Parch， Fare为连续型数值特征<br>文本型特征：Name， Sex， Cabin，Embarked， Ticket，其中Sex， Cabin， Embarked， Ticket为类别型文本特征，数值型特征一般可以直接用于模型的训练，但有时候为了模型的稳定性及鲁棒性会对连续变量进行离散化。文本型特征往往需要转换成数值型特征才能用于建模分析。</p>
<h4 id="2-3-1-任务一：对年龄进行分箱（离散化）处理"><a href="#2-3-1-任务一：对年龄进行分箱（离散化）处理" class="headerlink" title="2.3.1 任务一：对年龄进行分箱（离散化）处理"></a>2.3.1 任务一：对年龄进行分箱（离散化）处理</h4><p>(1) 分箱操作是什么？</p>
<p>(2) 将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示  </p>
<p>(3) 将连续变量Age划分为[0,5) [5,15) [15,30) [30,50) [50,80)五个年龄段，并分别用类别变量12345表示  </p>
<p>(4) 将连续变量Age按10% 30% 50% 70% 90%五个年龄段，并用分类变量12345表示</p>
<p>(5) 将上面的获得的数据分别进行保存，保存为csv格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#分箱操作是什么：</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">分箱操作（Binning）是数据预处理中的一种常用技术，主要用于将连续型数值转换为离散的区间（即“箱子”或“分组”）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示</span></span><br><span class="line">df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(df[<span class="string">&#x27;Age&#x27;</span>], <span class="number">5</span>,labels = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">df.head()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
      <th>AgeBand</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
      <td>3</td>
    </tr>
  </tbody>
</table>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将连续变量Age划分为(0,5] (5,15] (15,30] (30,50] (50,80]五个年龄段，并分别用类别变量12345表示</span></span><br><span class="line">df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.cut(df[<span class="string">&#x27;Age&#x27;</span>],[<span class="number">0</span>,<span class="number">5</span>,<span class="number">15</span>,<span class="number">30</span>,<span class="number">50</span>,<span class="number">80</span>],labels = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">df.head(<span class="number">3</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
      <th>AgeBand</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
      <td>3</td>
    </tr>
  </tbody>
</table>





<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将连续变量Age按10% 30% 50 70% 90%五个年龄段，并用分类变量12345表示</span></span><br><span class="line">df[<span class="string">&#x27;AgeBand&#x27;</span>] = pd.qcut(df[<span class="string">&#x27;Age&#x27;</span>],[<span class="number">0</span>,<span class="number">0.1</span>,<span class="number">0.3</span>,<span class="number">0.5</span>,<span class="number">0.7</span>,<span class="number">0.9</span>],labels = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
      <th>AgeBand</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
      <td>4</td>
    </tr>
  </tbody>
</table><br>【参考】<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html</a></p>
<p>【参考】<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html</a></p>
<h4 id="2-3-2-任务二：对文本变量进行转换"><a href="#2-3-2-任务二：对文本变量进行转换" class="headerlink" title="2.3.2 任务二：对文本变量进行转换"></a>2.3.2 任务二：对文本变量进行转换</h4><p>(1) 查看文本变量名及种类<br>(2) 将文本变量Sex， Cabin ，Embarked用数值变量12345表示<br>(3) 将文本变量Sex， Cabin， Embarked用one-hot编码表示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#方法一: value_counts</span></span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>].value_counts(),</span><br><span class="line">df[<span class="string">&#x27;Cabin&#x27;</span>].value_counts(),</span><br><span class="line">df[<span class="string">&#x27;Embarked&#x27;</span>].value_counts())</span><br></pre></td></tr></table></figure>
<pre><code>Sex
male      453
female    261
0           1
Name: count, dtype: int64 Cabin
B96 B98        4
G6             4
C23 C25 C27    4
F2             3
C22 C26        3
              ..
E36            1
D7             1
C118           1
C99            1
D37            1
Name: count, Length: 135, dtype: int64 Embarked
S    554
C    130
Q     28
0      1
Name: count, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>].unique()</span><br><span class="line">df[<span class="string">&#x27;Sex&#x27;</span>].nunique()</span><br></pre></td></tr></table></figure>
<pre><code>3
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#将类别文本转换为12345</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#方法一: replace</span></span><br><span class="line">df[<span class="string">&#x27;Sex_num&#x27;</span>] = df[<span class="string">&#x27;Sex&#x27;</span>].replace([<span class="string">&#x27;male&#x27;</span>,<span class="string">&#x27;female&#x27;</span>],[<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">df.head()</span><br><span class="line"><span class="comment">#方法二: map</span></span><br><span class="line">df[<span class="string">&#x27;Sex_num&#x27;</span>] = df[<span class="string">&#x27;Sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;male&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;female&#x27;</span>: <span class="number">2</span>&#125;)</span><br><span class="line">df.head()</span><br><span class="line"><span class="comment">#方法三: 使用sklearn.preprocessing的LabelEncoder</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> [<span class="string">&#x27;Cabin&#x27;</span>, <span class="string">&#x27;Ticket&#x27;</span>]:</span><br><span class="line">    lbl = LabelEncoder()  </span><br><span class="line">    label_dict = <span class="built_in">dict</span>(<span class="built_in">zip</span>(df[feat].unique(), <span class="built_in">range</span>(df[feat].nunique())))</span><br><span class="line">    <span class="comment">#print(label_dict)</span></span><br><span class="line">    df[feat + <span class="string">&quot;_labelEncode&quot;</span>] = df[feat].<span class="built_in">map</span>(label_dict)</span><br><span class="line">    df[feat + <span class="string">&quot;_labelEncode&quot;</span>] = lbl.fit_transform(df[feat].astype(<span class="built_in">str</span>))</span><br><span class="line"></span><br><span class="line">df.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>/tmp/ipykernel_1400/2627332835.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option(&#39;future.no_silent_downcasting&#39;, True)`
  df[&#39;Sex_num&#39;] = df[&#39;Sex&#39;].replace([&#39;male&#39;,&#39;female&#39;],[1,2])
</code></pre><p><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>...</th>
      <th>Age_66.0</th>
      <th>Age_70.0</th>
      <th>Age_70.5</th>
      <th>Age_71.0</th>
      <th>Age_74.0</th>
      <th>Age_80.0</th>
      <th>Embarked_0</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>...</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table></p>
<p>5 rows × 109 columns</p>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#将类别文本转换为one-hot编码</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#方法一: OneHotEncoder</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> [<span class="string">&quot;Age&quot;</span>, <span class="string">&quot;Embarked&quot;</span>]:</span><br><span class="line">    x = pd.get_dummies(df[<span class="string">&quot;Age&quot;</span>] // <span class="number">6</span>)</span><br><span class="line"><span class="comment">#     x = pd.get_dummies(pd.cut(df[&#x27;Age&#x27;],5))</span></span><br><span class="line">    x = pd.get_dummies(df[feat], prefix=feat)</span><br><span class="line">    df = pd.concat([df, x], axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#df[feat] = pd.get_dummies(df[feat], prefix=feat)</span></span><br><span class="line">    </span><br><span class="line">df.head()</span><br><span class="line">df.to_csv(<span class="string">&#x27;temp.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-3-3-任务三：从纯文本Name特征里提取出Titles的特征-所谓的Titles就是Mr-Miss-Mrs等"><a href="#2-3-3-任务三：从纯文本Name特征里提取出Titles的特征-所谓的Titles就是Mr-Miss-Mrs等" class="headerlink" title="2.3.3 任务三：从纯文本Name特征里提取出Titles的特征(所谓的Titles就是Mr,Miss,Mrs等)"></a>2.3.3 任务三：从纯文本Name特征里提取出Titles的特征(所谓的Titles就是Mr,Miss,Mrs等)</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#保存最终你完成的已经清理好的数据</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</class>]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第三节数据重构2</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%B8%89%E8%8A%82%E6%95%B0%E6%8D%AE%E9%87%8D%E6%9E%842-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>在前面我们已经学习了Pandas基础，第二章我们开始进入数据分析的业务部分，在第二章第一节的内容中，我们学习了<strong>数据的清洗</strong>，这一部分十分重要，只有数据变得相对干净，我们之后对数据的分析才可以更有力。而这一节，我们要做的是数据重构，数据重构依旧属于数据理解（准备）的范围。</p>
<h4 id="开始之前，导入numpy、pandas包和数据"><a href="#开始之前，导入numpy、pandas包和数据" class="headerlink" title="开始之前，导入numpy、pandas包和数据"></a>开始之前，导入numpy、pandas包和数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入基本库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 载入上一个任务人保存的文件中:result.csv，并查看这个文件</span></span><br><span class="line">text = pd.read_csv(<span class="string">&#x27;result.csv&#x27;</span>)</span><br><span class="line">text.head()</span><br></pre></td></tr></table></figure>
<p><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table></p>
<h1 id="2-第二章：数据重构"><a href="#2-第二章：数据重构" class="headerlink" title="2 第二章：数据重构"></a>2 第二章：数据重构</h1><h2 id="第一部分：数据聚合与运算"><a href="#第一部分：数据聚合与运算" class="headerlink" title="第一部分：数据聚合与运算"></a>第一部分：数据聚合与运算</h2><h3 id="2-6-数据运用"><a href="#2-6-数据运用" class="headerlink" title="2.6 数据运用"></a>2.6 数据运用</h3><h4 id="2-6-1-任务一：通过教材《Python-for-Data-Analysis》P303、Google-or-anything来学习了解GroupBy机制"><a href="#2-6-1-任务一：通过教材《Python-for-Data-Analysis》P303、Google-or-anything来学习了解GroupBy机制" class="headerlink" title="2.6.1 任务一：通过教材《Python for Data Analysis》P303、Google or anything来学习了解GroupBy机制"></a>2.6.1 任务一：通过教材《Python for Data Analysis》P303、Google or anything来学习了解GroupBy机制</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入心得</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">GroupBy机制是Pandas中用于数据分组与聚合的核心操作，其本质是遵循&quot;Split-Apply-Combine&quot;模式：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Split：按指定键（列、函数、数组等）将数据分割成多个子集</span></span><br><span class="line"><span class="string">Apply：对每个子集独立应用聚合函数（如mean/max）、转换函数（如标准化）或过滤操作</span></span><br><span class="line"><span class="string">Combine：将结果合并为新的数据结构</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h4 id="2-4-2：任务二：计算泰坦尼克号男性与女性的平均票价"><a href="#2-4-2：任务二：计算泰坦尼克号男性与女性的平均票价" class="headerlink" title="2.4.2：任务二：计算泰坦尼克号男性与女性的平均票价"></a>2.4.2：任务二：计算泰坦尼克号男性与女性的平均票价</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">df  = text[<span class="string">&#x27;Fare&#x27;</span>].groupby(text[<span class="string">&#x27;Sex&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(df.groups)</span><br><span class="line">means = df.mean()</span><br><span class="line">means</span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;female&#39;: [1, 2, 3, 8, 9, 10, 11, 14, 15, 18, 19, 22, 24, 25, 28, 31, 32, 38, 39, 40, 41, 43, 44, 47, 49, 52, 53, 56, 58, 61, 66, 68, 71, 79, 82, 84, 85, 88, 98, 100, 106, 109, 111, 113, 114, 119, 123, 128, 132, 133, 136, 140, 141, 142, 147, 151, 156, 161, 166, 167, 172, 177, 180, 184, 186, 190, 192, 194, 195, 198, 199, 205, 208, 211, 215, 216, 218, 229, 230, 233, 235, 237, 240, 241, 246, 247, 251, 254, 255, 256, 257, 258, 259, 264, 268, 269, 272, 274, 275, 276, ...], &#39;male&#39;: [0, 4, 5, 6, 7, 12, 13, 16, 17, 20, 21, 23, 26, 27, 29, 30, 33, 34, 35, 36, 37, 42, 45, 46, 48, 50, 51, 54, 55, 57, 59, 60, 62, 63, 64, 65, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 107, 108, 110, 112, 115, 116, 117, 118, 120, 121, 122, 124, 125, 126, 127, 129, 130, 131, 134, 135, 137, 138, 139, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, ...]&#125;

Sex
female    44.479818
male      25.523893
Name: Fare, dtype: float64
</code></pre><p>在了解GroupBy机制之后，运用这个机制完成一系列的操作，来达到我们的目的。</p>
<p>下面通过几个任务来熟悉GroupBy机制。</p>
<h4 id="2-4-3：任务三：统计泰坦尼克号中男女的存活人数"><a href="#2-4-3：任务三：统计泰坦尼克号中男女的存活人数" class="headerlink" title="2.4.3：任务三：统计泰坦尼克号中男女的存活人数"></a>2.4.3：任务三：统计泰坦尼克号中男女的存活人数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_sex = text[<span class="string">&#x27;Survived&#x27;</span>].groupby(text[<span class="string">&#x27;Sex&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line">survived_sex.head()</span><br></pre></td></tr></table></figure>
<pre><code>Sex
female    233
male      109
Name: Survived, dtype: int64
</code></pre><h4 id="2-4-4：任务四：计算客舱不同等级的存活人数"><a href="#2-4-4：任务四：计算客舱不同等级的存活人数" class="headerlink" title="2.4.4：任务四：计算客舱不同等级的存活人数"></a>2.4.4：任务四：计算客舱不同等级的存活人数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_pclass = text[<span class="string">&#x27;Survived&#x27;</span>].groupby(text[<span class="string">&#x27;Pclass&#x27;</span>])</span><br><span class="line">survived_pclass.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<pre><code>Pclass
1    136
2     87
3    119
Name: Survived, dtype: int64
</code></pre><p>【<strong>提示：</strong>】表中的存活那一栏，可以发现如果还活着记为1，死亡记为0</p>
<p>【<strong>思考</strong>】从数据分析的角度，上面的统计结果可以得出那些结论</p>
<p>【思考】从任务二到任务三中，这些运算可以通过agg()函数来同时计算。并且可以使用rename函数修改列名。你可以按照提示写出这个过程吗？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考心得</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">agg() 函数是 Pandas 中用于对分组后的数据 同时执行多个聚合操作 的核心工具，其全称为 Aggregate（聚合）。它允许你对不同列应用不同的聚合函数，并支持自定义函数，极大提升数据分析效率。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">text.groupby(<span class="string">&#x27;Sex&#x27;</span>).agg(&#123;<span class="string">&#x27;Fare&#x27;</span>: <span class="string">&#x27;mean&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>: <span class="string">&#x27;count&#x27;</span>&#125;).rename(columns=</span><br><span class="line">                            &#123;<span class="string">&#x27;Fare&#x27;</span>: <span class="string">&#x27;mean_fare&#x27;</span>, <span class="string">&#x27;Pclass&#x27;</span>: <span class="string">&#x27;count_pclass&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>
<p><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean_fare</th>
      <th>count_pclass</th>
    </tr>
    <tr>
      <th>Sex</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>female</th>
      <td>44.479818</td>
      <td>314</td>
    </tr>
    <tr>
      <th>male</th>
      <td>25.523893</td>
      <td>577</td>
    </tr>
  </tbody>
</table></p>
<h4 id="2-4-5：任务五：统计在不同等级的票中的不同年龄的船票花费的平均值"><a href="#2-4-5：任务五：统计在不同等级的票中的不同年龄的船票花费的平均值" class="headerlink" title="2.4.5：任务五：统计在不同等级的票中的不同年龄的船票花费的平均值"></a>2.4.5：任务五：统计在不同等级的票中的不同年龄的船票花费的平均值</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">temp=text.groupby([<span class="string">&#x27;Pclass&#x27;</span>,<span class="string">&#x27;Age&#x27;</span>])[<span class="string">&#x27;Fare&#x27;</span>]</span><br><span class="line">temp.groups</span><br><span class="line">temp.mean().head()</span><br></pre></td></tr></table></figure>
<pre><code>Pclass  Age  
1       0.92     151.5500
        2.00     151.5500
        4.00      81.8583
        11.00    120.0000
        14.00    120.0000
Name: Fare, dtype: float64
</code></pre><h4 id="2-4-6：任务六：将任务二和任务三的数据合并，并保存到sex-fare-survived-csv"><a href="#2-4-6：任务六：将任务二和任务三的数据合并，并保存到sex-fare-survived-csv" class="headerlink" title="2.4.6：任务六：将任务二和任务三的数据合并，并保存到sex_fare_survived.csv"></a>2.4.6：任务六：将任务二和任务三的数据合并，并保存到sex_fare_survived.csv</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">result = pd.merge(means,survived_sex,on=<span class="string">&#x27;Sex&#x27;</span>)</span><br><span class="line">result</span><br><span class="line">result.to_csv(<span class="string">&#x27;sex_fare_survived.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-4-7：任务七：得出不同年龄的总的存活人数，然后找出存活人数最多的年龄段，最后计算存活人数最高的存活率（存活人数-总人数）"><a href="#2-4-7：任务七：得出不同年龄的总的存活人数，然后找出存活人数最多的年龄段，最后计算存活人数最高的存活率（存活人数-总人数）" class="headerlink" title="2.4.7：任务七：得出不同年龄的总的存活人数，然后找出存活人数最多的年龄段，最后计算存活人数最高的存活率（存活人数/总人数）"></a>2.4.7：任务七：得出不同年龄的总的存活人数，然后找出存活人数最多的年龄段，最后计算存活人数最高的存活率（存活人数/总人数）</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_age = text[<span class="string">&#x27;Survived&#x27;</span>].groupby(text[<span class="string">&#x27;Age&#x27;</span>]).<span class="built_in">sum</span>()</span><br><span class="line">survived_age.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Age
0.42    1
0.67    1
0.75    2
0.83    2
0.92    1
Name: Survived, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line">survived_age[survived_age.values==survived_age.<span class="built_in">max</span>()]</span><br></pre></td></tr></table></figure>
<pre><code>Age
24.0    15
Name: Survived, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_<span class="built_in">sum</span> = text[<span class="string">&#x27;Survived&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(_<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure>
<pre><code>342
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sum of person:&quot;</span>+<span class="built_in">str</span>(_<span class="built_in">sum</span>))</span><br><span class="line"></span><br><span class="line">precetn =survived_age.<span class="built_in">max</span>()/_<span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最大存活率：&quot;</span>+<span class="built_in">str</span>(precetn))</span><br></pre></td></tr></table></figure>
<pre><code>sum of person:342
最大存活率：0.043859649122807015
</code></pre>]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第二节数据重构1</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E4%BA%8C%E8%8A%82%E6%95%B0%E6%8D%AE%E9%87%8D%E6%9E%841-%E8%AF%BE%E7%A8%8B/</url>
    <content><![CDATA[<p><strong>复习：</strong>在前面我们已经学习了Pandas基础，第二章我们开始进入数据分析的业务部分，在第二章第一节的内容中，我们学习了<strong>数据的清洗</strong>，这一部分十分重要，只有数据变得相对干净，我们之后对数据的分析才可以更有力。而这一节，我们要做的是数据重构，数据重构依旧属于数据理解（准备）的范围。</p>
<h4 id="开始之前，导入numpy、pandas包和数据"><a href="#开始之前，导入numpy、pandas包和数据" class="headerlink" title="开始之前，导入numpy、pandas包和数据"></a>开始之前，导入numpy、pandas包和数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入基本库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 载入data文件中的:train-left-up.csv</span></span><br><span class="line">text=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-left-up.csv&#x27;</span>)</span><br><span class="line">text.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
    </tr>
  </tbody>
</table>
# 2 第二章：数据重构


### 2.4 数据的合并

#### 2.4.1 任务一：将data文件夹里面的所有数据都载入，观察数据的之间的关系


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">text_left_up=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-left-up.csv&#x27;</span>)</span><br><span class="line">text_left_down=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-left-down.csv&#x27;</span>)</span><br><span class="line">text_right_up=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-right-up.csv&#x27;</span>)</span><br><span class="line">text_right_down=pd.read_csv(<span class="string">&#x27;../第二章项目集合/data/train-right-down.csv&#x27;</span>)</span><br><span class="line">text_left_up.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
    </tr>
  </tbody>
</table>
【提示】结合之前我们加载的train.csv数据，大致预测一下上面的数据是什么

#### 2.4.2：任务二：使用concat方法：将数据train-left-up.csv和train-right-up.csv横向合并为一张表，并保存这张表为result_up


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#pandas.concat 是 Pandas 中用于连接 Series 或 DataFrame 对象的核心方法，支持横向（列方向）或纵向（行方向）拼接</span></span><br><span class="line">list_up = [text_left_up,text_right_up]</span><br><span class="line">result_up = pd.concat(list_up,axis=<span class="number">1</span>)</span><br><span class="line">result_up.head()</span><br></pre></td></tr></table></figure>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>


<h4 id="2-4-3-任务三：使用concat方法：将train-left-down和train-right-down横向合并为一张表，并保存这张表为result-down。然后将上边的result-up和result-down纵向合并为result。"><a href="#2-4-3-任务三：使用concat方法：将train-left-down和train-right-down横向合并为一张表，并保存这张表为result-down。然后将上边的result-up和result-down纵向合并为result。" class="headerlink" title="2.4.3 任务三：使用concat方法：将train-left-down和train-right-down横向合并为一张表，并保存这张表为result_down。然后将上边的result_up和result_down纵向合并为result。"></a>2.4.3 任务三：使用concat方法：将train-left-down和train-right-down横向合并为一张表，并保存这张表为result_down。然后将上边的result_up和result_down纵向合并为result。</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">list_down=[text_left_down,text_right_down]</span><br><span class="line">result_down = pd.concat(list_down,axis=<span class="number">1</span>)</span><br><span class="line">result = pd.concat([result_up,result_down])</span><br><span class="line">result.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>



<h4 id="2-4-4-任务四：使用DataFrame自带的方法join方法和append：完成任务二和任务三的任务"><a href="#2-4-4-任务四：使用DataFrame自带的方法join方法和append：完成任务二和任务三的任务" class="headerlink" title="2.4.4 任务四：使用DataFrame自带的方法join方法和append：完成任务二和任务三的任务"></a>2.4.4 任务四：使用DataFrame自带的方法join方法和append：完成任务二和任务三的任务</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line">resul_up = text_left_up.join(text_right_up)</span><br><span class="line">result_down = text_left_down.join(text_right_down)</span><br><span class="line">result = result_up.append(result_down)</span><br><span class="line">result.head()</span><br></pre></td></tr></table></figure>
<h4 id="2-4-5-任务五：使用Panads的merge方法和DataFrame的append方法：完成任务二和任务三的任务"><a href="#2-4-5-任务五：使用Panads的merge方法和DataFrame的append方法：完成任务二和任务三的任务" class="headerlink" title="2.4.5 任务五：使用Panads的merge方法和DataFrame的append方法：完成任务二和任务三的任务"></a>2.4.5 任务五：使用Panads的merge方法和DataFrame的append方法：完成任务二和任务三的任务</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">该代码使用 pandas.merge 方法，以索引（index）为键，将两个 DataFrame (text_left_up 和 text_right_up) 横向合并。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">result_up = pd.merge(text_left_up,text_right_up,left_index=<span class="literal">True</span>,right_index=<span class="literal">True</span>)</span><br><span class="line">result_down = pd.merge(text_left_down,text_right_down,left_index=<span class="literal">True</span>,right_index=<span class="literal">True</span>)</span><br><span class="line">result = resul_up.append(result_down)</span><br><span class="line">result.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>【思考】对比merge、join以及concat的方法的不同以及相同。思考一下在任务四和任务五的情况下，为什么都要求使用DataFrame的append方法，如何只要求使用merge或者join可不可以完成任务四和任务五呢？</p>
<h4 id="2-4-6-任务六：完成的数据保存为result-csv"><a href="#2-4-6-任务六：完成的数据保存为result-csv" class="headerlink" title="2.4.6 任务六：完成的数据保存为result.csv"></a>2.4.6 任务六：完成的数据保存为result.csv</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">result.to_csv(<span class="string">&#x27;result.csv&#x27;</span>)</span><br><span class="line">result.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="2-5-换一种角度看数据"><a href="#2-5-换一种角度看数据" class="headerlink" title="2.5 换一种角度看数据"></a>2.5 换一种角度看数据</h3><h4 id="2-5-1-任务一：将我们的数据变为Series类型的数据"><a href="#2-5-1-任务一：将我们的数据变为Series类型的数据" class="headerlink" title="2.5.1 任务一：将我们的数据变为Series类型的数据"></a>2.5.1 任务一：将我们的数据变为Series类型的数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"><span class="comment">#text.stack() 是 Pandas 中用于将 DataFrame 的列旋转为行的方法</span></span><br><span class="line">text = pd.read_csv(<span class="string">&#x27;result.csv&#x27;</span>)</span><br><span class="line">unit_result=text.stack().head(<span class="number">20</span>)</span><br><span class="line">unit_result.head()</span><br></pre></td></tr></table></figure>
<pre><code>0  Unnamed: 0                           0
   PassengerId                          1
   Survived                             0
   Pclass                               3
   Name           Braund, Mr. Owen Harris
dtype: object
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#写入代码</span></span><br><span class="line"></span><br><span class="line">unit_result.to_csv(<span class="string">&#x27;unit_result.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析——第二章：第四节数据可视化</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/</url>
    <content><![CDATA[<p><strong>复习：</strong>回顾学习完第一章，我们对泰坦尼克号数据有了基本的了解，也学到了一些基本的统计方法，第二章中我们学习了数据的清理和重构，使得数据更加的易于理解；今天我们要学习的是第二章第三节：<strong>数据可视化</strong>，主要给大家介绍一下Python数据可视化库Matplotlib，在本章学习中，你也许会觉得数据很有趣。在打比赛的过程中，数据可视化可以让我们更好的看到每一个关键步骤的结果如何，可以用来优化方案，是一个很有用的技巧。</p>
<h1 id="2-第二章：数据可视化"><a href="#2-第二章：数据可视化" class="headerlink" title="2 第二章：数据可视化"></a>2 第二章：数据可视化</h1><h4 id="开始之前，导入numpy、pandas以及matplotlib包和数据"><a href="#开始之前，导入numpy、pandas以及matplotlib包和数据" class="headerlink" title="开始之前，导入numpy、pandas以及matplotlib包和数据"></a>开始之前，导入numpy、pandas以及matplotlib包和数据</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载所需的库</span></span><br><span class="line"><span class="comment"># 如果出现 ModuleNotFoundError: No module named &#x27;xxxx&#x27;</span></span><br><span class="line"><span class="comment"># 你只需要在终端/cmd下 pip install xxxx 即可</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#加载result.csv这个数据</span></span><br><span class="line">text = pd.read_csv(<span class="string">r&#x27;result.csv&#x27;</span>)</span><br><span class="line">text.head()</span><br></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>


<h3 id="2-7-如何让人一眼看懂你的数据？"><a href="#2-7-如何让人一眼看懂你的数据？" class="headerlink" title="2.7 如何让人一眼看懂你的数据？"></a>2.7 如何让人一眼看懂你的数据？</h3><p>《Python for Data Analysis》第九章</p>
<h4 id="2-7-1-任务一：跟着书本第九章，了解matplotlib，自己创建一个数据项，对其进行基本可视化"><a href="#2-7-1-任务一：跟着书本第九章，了解matplotlib，自己创建一个数据项，对其进行基本可视化" class="headerlink" title="2.7.1 任务一：跟着书本第九章，了解matplotlib，自己创建一个数据项，对其进行基本可视化"></a>2.7.1 任务一：跟着书本第九章，了解matplotlib，自己创建一个数据项，对其进行基本可视化</h4><p>【思考】最基本的可视化图案有哪些？分别适用于那些场景？（比如折线图适合可视化某个属性值随时间变化的走势）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考回答</span></span><br><span class="line"><span class="comment">#这一部分需要了解可视化图案的的逻辑，知道什么样的图案可以表达什么样的信号b</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="2-7-2-任务二：可视化展示泰坦尼克号数据集中男女中生存人数分布情况（用柱状图试试）。"><a href="#2-7-2-任务二：可视化展示泰坦尼克号数据集中男女中生存人数分布情况（用柱状图试试）。" class="headerlink" title="2.7.2 任务二：可视化展示泰坦尼克号数据集中男女中生存人数分布情况（用柱状图试试）。"></a>2.7.2 任务二：可视化展示泰坦尼克号数据集中男女中生存人数分布情况（用柱状图试试）。</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line">sex = text.groupby(<span class="string">&#x27;Sex&#x27;</span>)[<span class="string">&#x27;Survived&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">sex.plot.bar()</span><br><span class="line">plt.title(<span class="string">&#x27;survived_count&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>  <img src="./../../../../images/第二章：第四节数据可视化-课程 (copy" alt="第二章：第四节数据可视化-课程_10_0">/第二章：第四节数据可视化-课程_10_0.png)</p>
<p>【思考】计算出泰坦尼克号数据集中男女中死亡人数，并可视化展示？如何和男女生存人数可视化柱状图结合到一起？看到你的数据可视化，说说你的第一感受（比如：你一眼看出男生存活人数更多，那么性别可能会影响存活率）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考题回答</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="2-7-3-任务三：可视化展示泰坦尼克号数据集中男女中生存人与死亡人数的比例图（用柱状图试试）。"><a href="#2-7-3-任务三：可视化展示泰坦尼克号数据集中男女中生存人与死亡人数的比例图（用柱状图试试）。" class="headerlink" title="2.7.3 任务三：可视化展示泰坦尼克号数据集中男女中生存人与死亡人数的比例图（用柱状图试试）。"></a>2.7.3 任务三：可视化展示泰坦尼克号数据集中男女中生存人与死亡人数的比例图（用柱状图试试）。</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"><span class="comment"># 提示：计算男女中死亡人数 1表示生存，0表示死亡</span></span><br><span class="line">text.groupby([<span class="string">&#x27;Sex&#x27;</span>,<span class="string">&#x27;Survived&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].count().unstack().plot(kind=<span class="string">&#x27;bar&#x27;</span>,stacked=<span class="string">&#x27;True&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;survived_count&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Text(0, 0.5, &#39;count&#39;)
</code></pre><p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_14_1.png" alt="第二章：第四节数据可视化-课程_14_1"></p>
<p>【提示】男女这两个数据轴，存活和死亡人数按比例用柱状图表示</p>
<h4 id="2-7-4-任务四：可视化展示泰坦尼克号数据集中不同票价的人生存和死亡人数分布情况。（用折线图试试）（横轴是不同票价，纵轴是存活人数）"><a href="#2-7-4-任务四：可视化展示泰坦尼克号数据集中不同票价的人生存和死亡人数分布情况。（用折线图试试）（横轴是不同票价，纵轴是存活人数）" class="headerlink" title="2.7.4 任务四：可视化展示泰坦尼克号数据集中不同票价的人生存和死亡人数分布情况。（用折线图试试）（横轴是不同票价，纵轴是存活人数）"></a>2.7.4 任务四：可视化展示泰坦尼克号数据集中不同票价的人生存和死亡人数分布情况。（用折线图试试）（横轴是不同票价，纵轴是存活人数）</h4><p>【提示】对于这种统计性质的且用折线表示的数据，你可以考虑将数据排序或者不排序来分别表示。看看你能发现什么？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"><span class="comment"># 计算不同票价中生存与死亡人数 1表示生存，0表示死亡</span></span><br><span class="line"><span class="comment">#print(text.groupby([&#x27;Fare&#x27;])[&#x27;Survived&#x27;].value_counts())</span></span><br><span class="line">fare_sur = text.groupby([<span class="string">&#x27;Fare&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].value_counts().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">fare_sur</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Fare     Survived
8.0500   0           38
7.8958   0           37
13.0000  0           26
7.7500   0           22
26.0000  0           16
                     ..
6.9500   0            1
6.9750   0            1
         1            1
7.0458   0            1
7.1417   1            1
Name: count, Length: 330, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 排序后绘折线图</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">18</span>))</span><br><span class="line">fare_sur.plot(grid=<span class="literal">True</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>   <img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_19_0.png" alt="第二章：第四节数据可视化-课程_19_0"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写入代码</span></span><br><span class="line"><span class="comment"># 排序前绘折线图</span></span><br><span class="line">fare_sur1 = text.groupby([<span class="string">&#x27;Fare&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].value_counts()</span><br><span class="line">fare_sur1</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>, <span class="number">18</span>))</span><br><span class="line">fare_sur1.plot(grid=<span class="literal">True</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p> <img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_20_0.png" alt="第二章：第四节数据可视化-课程_20_0"></p>
<h4 id="2-7-5-任务五：可视化展示泰坦尼克号数据集中不同仓位等级的人生存和死亡人员的分布情况。（用柱状图试试）"><a href="#2-7-5-任务五：可视化展示泰坦尼克号数据集中不同仓位等级的人生存和死亡人员的分布情况。（用柱状图试试）" class="headerlink" title="2.7.5 任务五：可视化展示泰坦尼克号数据集中不同仓位等级的人生存和死亡人员的分布情况。（用柱状图试试）"></a>2.7.5 任务五：可视化展示泰坦尼克号数据集中不同仓位等级的人生存和死亡人员的分布情况。（用柱状图试试）</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"><span class="comment"># 1表示生存，0表示死亡</span></span><br><span class="line">pclass_sur = text.groupby([<span class="string">&#x27;Pclass&#x27;</span>])[<span class="string">&#x27;Survived&#x27;</span>].value_counts()</span><br><span class="line">pclass_sur</span><br></pre></td></tr></table></figure>
<pre><code>Pclass  Survived
1       1           136
        0            80
2       0            97
        1            87
3       0           372
        1           119
Name: count, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.countplot(x=<span class="string">&quot;Pclass&quot;</span>, hue=<span class="string">&quot;Survived&quot;</span>, data=text)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Axes: xlabel=&#39;Pclass&#39;, ylabel=&#39;count&#39;&gt;
</code></pre><p><img src="./../../../../images/第二章：第四节数据可视化-课程 (copy" alt="第二章：第四节数据可视化-课程_23_1">/第二章：第四节数据可视化-课程_23_1.png)</p>
<p>【思考】看到这个前面几个数据可视化，说说你的第一感受和你的总结</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#思考题回答</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="2-7-6-任务六：可视化展示泰坦尼克号数据集中不同年龄的人生存与死亡人数分布情况。-不限表达方式"><a href="#2-7-6-任务六：可视化展示泰坦尼克号数据集中不同年龄的人生存与死亡人数分布情况。-不限表达方式" class="headerlink" title="2.7.6 任务六：可视化展示泰坦尼克号数据集中不同年龄的人生存与死亡人数分布情况。(不限表达方式)"></a>2.7.6 任务六：可视化展示泰坦尼克号数据集中不同年龄的人生存与死亡人数分布情况。(不限表达方式)</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line">facet = sns.FacetGrid(text, hue=<span class="string">&quot;Survived&quot;</span>,aspect=<span class="number">3</span>)</span><br><span class="line">facet.<span class="built_in">map</span>(sns.kdeplot,<span class="string">&#x27;Age&#x27;</span>,shade= <span class="literal">True</span>)</span><br><span class="line">facet.<span class="built_in">set</span>(xlim=(<span class="number">0</span>, text[<span class="string">&#x27;Age&#x27;</span>].<span class="built_in">max</span>()))</span><br><span class="line">facet.add_legend()</span><br></pre></td></tr></table></figure>
<pre><code>/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/seaborn/axisgrid.py:854: FutureWarning: 

`shade` is now deprecated in favor of `fill`; setting `fill=True`.
This will become an error in seaborn v0.14.0; please update your code.

  func(*plot_args, **plot_kwargs)
/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/seaborn/axisgrid.py:854: FutureWarning: 

`shade` is now deprecated in favor of `fill`; setting `fill=True`.
This will become an error in seaborn v0.14.0; please update your code.

  func(*plot_args, **plot_kwargs)

&lt;seaborn.axisgrid.FacetGrid at 0x7f9c6bce1f50&gt;
</code></pre><p><img src="./../../../../images/第二章：第四节数据可视化-课程 (copy" alt="第二章：第四节数据可视化-课程_27_2">/第二章：第四节数据可视化-课程_27_2.png)</p>
<h4 id="2-7-7-任务七：可视化展示泰坦尼克号数据集中不同仓位等级的人年龄分布情况。（用折线图试试）"><a href="#2-7-7-任务七：可视化展示泰坦尼克号数据集中不同仓位等级的人年龄分布情况。（用折线图试试）" class="headerlink" title="2.7.7 任务七：可视化展示泰坦尼克号数据集中不同仓位等级的人年龄分布情况。（用折线图试试）"></a>2.7.7 任务七：可视化展示泰坦尼克号数据集中不同仓位等级的人年龄分布情况。（用折线图试试）</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#代码编写</span></span><br><span class="line"></span><br><span class="line">text.Age[text.Pclass == <span class="number">1</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">text.Age[text.Pclass == <span class="number">2</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">text.Age[text.Pclass == <span class="number">3</span>].plot(kind=<span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;age&quot;</span>)</span><br><span class="line">plt.legend((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),loc=<span class="string">&quot;best&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f9c69946e90&gt;
</code></pre><p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/kaggle/titanic/%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%AC%AC%E5%9B%9B%E8%8A%82%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-%E8%AF%BE%E7%A8%8B%20(copy)/第二章：第四节数据可视化-课程_29_1.png" alt="第二章：第四节数据可视化-课程_29_1"></p>
<p>【思考】上面所有可视化的例子做一个总体的分析，你看看你能不能有自己发现</p>
<p>【总结】到这里，我们的可视化就告一段落啦，如果你对数据可视化极其感兴趣，你还可以了解一下其他可视化模块，如：pyecharts，bokeh等。</p>
<p>如果你在工作中使用数据可视化，你必须知道数据可视化最大的作用不是炫酷，而是最快最直观的理解数据要表达什么，你觉得呢？</p>
]]></content>
      <categories>
        <category>kaggle</category>
        <category>titanic</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>实习日志</title>
    <url>/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/</url>
    <content><![CDATA[<h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>7.16 10：46</p>
<p>已经将mineru部署至服务器，完成pdf和扫描件的提取测试，但是mineru是没办法直接提取doc与docx的，能不能直接对doc与docx进行文本分块，或者先转换成pdf再提取（官方给出的解决方案：通过独立部署的LibreOffice服务先行转换为PDF格式，再进行后续解析操作。）</p>
<p>7.17 11：04</p>
<p>完成mineru脚本的编写，仅输出提取的md与image；实现调用多块gpu；实现数据并行，通过多卡同时处理多个输入来增加吞吐量；使用sglang框架</p>
<p>7.18 14：37</p>
<p>发现mineru提取的markdown文档是不带多级标题的，只有一级标题，所以不考虑文档结构分块；语义分块要调用embedding模型，而且文档里有很多表格，我感觉效果不一定会好；后续我想法是使用递归分块，表格在md文档中以html表格格式存储的，大量冗余信息，我想先对其进行预处理，转换成md表格的形式吧（用“ |”存储），然后再分块，或许效果会好一些，正在进行</p>
<p>还有一个就是libreoffice是部署在哪里，我没有找到诶</p>
<p>7.19 10：26</p>
<p>完成表格预处理的脚本编写，完成对md文档的预处理；完成递归分块，后续完成存入es数据库</p>
<p>7.21</p>
<p>完成简单地将分块结果存入elasticsearch（mapping只有content字段，使用http请求存的，没有用langchain-elasticsearch）后面要试试langchain-elasticsearch，去看看字段的处理</p>
<p>7.22</p>
<p>完成langchain-elasticsearch的bm25的检索测试，接下来尝试使用服务器的embedding模型进行测试，阅读项目文件，理清思路，具体内容见<a href="https://icnrn6ghqrgx.feishu.cn/wiki/MWZ9wVYRxixABqkMhjQcQPqTnfe">多模态 - PDF表格图片&amp;扫描件</a>，存入es与文件处理字段处理部分已经理清了，成功存入服务器的es</p>
<p>7.23</p>
<p>今天在把之前做的所有工作进行整合，编写一个完整的代码，实现生产的流程，遇到的主要问题有两个：1.我还是没有很看懂之前对字段的存储，和字段的结构2.我没有太理解pdf分块的部分在哪里，是没有吗，我看doc的rewrite_word是有文本分块的</p>
<p>感觉需要你给我讲一下，不然我后面不大知道该怎么处理，那我明天去把语义分块和其他的检索方案试一下吧，整合代码先稍微延后</p>
<p>7.24</p>
<p>使用docker的自定义网络，实现容器之间的通信，从而可以在repo容器中调用mineru，其他容器都在network_test下，我把mineru也启动到里面</p>
<p>成功在repo容器访问到mineru容器，完成pdf分块数据的批量写入elasticsearch并可以成功检索，后续完成调用mineru的fastapi接口（还没编完），继续完成代码整合（已经完成大部分，主要差mineru的部分，和一些衔接的代码）</p>
<p>7.25</p>
<p>完成通过接口使用mineru批量处理pdf文件</p>
<p>7.28</p>
<p>完成了代码整合，可以完成pdf整个流程的处理</p>
<p>7.29</p>
<p>补充了libreoffice的代码，实现了将doc，docx转换成pdf，统一处理流程；完成了数据标记web；后续计划：根据问题检索url，处理后存入zxj_test es数据库，再进行进一步检索产生数据集</p>
<p>7.30</p>
<p>完成扫描件的测试，文字公式图片皆可正常识别</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><h4 id="vscode连接远程服务器"><a href="#vscode连接远程服务器" class="headerlink" title="vscode连接远程服务器"></a>vscode连接远程服务器</h4><ol>
<li>输入 ssh root@10.117.128.50</li>
<li>输入密码 think123@</li>
</ol>
<h5 id="使用旧版remotessh"><a href="#使用旧版remotessh" class="headerlink" title="使用旧版remotessh"></a>使用旧版remotessh</h5><p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/image-20250708104452761.png" alt="image-20250708104452761"></p>
<blockquote>
<p>原因：可能因为内网，服务器那边没有进行更新，所以新版的remotessh无法连接</p>
<p>其他问题：可能由于上述原因，trae也无法连接，并且由于trae的远程连接插件无法更改版本，因此无法使用</p>
</blockquote>
<h5 id="虚拟环境创建"><a href="#虚拟环境创建" class="headerlink" title="虚拟环境创建"></a>虚拟环境创建</h5><p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/image-20250708104254347.png" alt="image-20250708104254347"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python3 -m venv .venv</span><br><span class="line"></span><br><span class="line">which python</span><br><span class="line"></span><br><span class="line">#激活虚拟环境</span><br><span class="line"> .venv\Scripts\activate</span><br><span class="line"> source .venv/bin/activate</span><br><span class="line"> </span><br><span class="line"> #停掉虚拟环境</span><br><span class="line"> deactivate</span><br></pre></td></tr></table></figure>
<h4 id="git连接远程仓库"><a href="#git连接远程仓库" class="headerlink" title="git连接远程仓库"></a>git连接远程仓库</h4><p>初始化仓库：<code>git init</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 添加所有文件到暂存区</span><br><span class="line">git add .</span><br><span class="line"></span><br><span class="line"># 提交更改</span><br><span class="line">git commit -m &quot;Initial commit&quot;</span><br><span class="line"></span><br><span class="line">#上传远程库</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th>目标</th>
<th>命令</th>
</tr>
</thead>
<tbody>
<tr>
<td>查看远程仓库</td>
<td><code>git remote -v</code></td>
</tr>
<tr>
<td>修改远程仓库地址</td>
<td><code>git remote set-url origin &lt;新地址&gt;</code></td>
</tr>
<tr>
<td>添加新远程仓库（不同名）</td>
<td><code>git remote add upstream &lt;新地址&gt;</code></td>
</tr>
<tr>
<td>删除远程仓库</td>
<td><code>git remote remove origin</code></td>
</tr>
<tr>
<td>添加第一个远程仓库</td>
<td><code>git remote add origin</code></td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/image-20250708151320868.png" alt="image-20250708151320868"></p>
<p>当前存在连接超时问题，可能是服务器连接的原因</p>
</blockquote>
<h4 id="mineru部署情况"><a href="#mineru部署情况" class="headerlink" title="mineru部署情况"></a>mineru部署情况</h4><p><img src="/2025/07/08/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/7.8/1a9954d6-31d7-404a-9419-cd9a87c9ee09.png" alt="1a9954d6-31d7-404a-9419-cd9a87c9ee09"></p>
<p>通过调整docker镜像源，可以拉取基础镜像了，但是遇到<code>RUN apt-get update &amp;&amp; apt-get install -y libgl1 &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*</code>第二部命令再次出现网络问题</p>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>python web——fastapi</title>
    <url>/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>FastAPI 是一个用于构建 API 的现代、快速（高性能）的 web 框架，使用 Python 并基于标准的 Python 类型提示。</p>
<p>关键特性:</p>
<ul>
<li><strong>快速</strong>：可与 <strong>NodeJS</strong> 和 <strong>Go</strong> 并肩的极高性能（归功于 Starlette 和 Pydantic）。<a href="https://fastapi.tiangolo.com/zh/#_11">最快的 Python web 框架之一</a>。</li>
<li><strong>高效编码</strong>：提高功能开发速度约 200％ 至 300％。*</li>
<li><strong>更少 bug</strong>：减少约 40％ 的人为（开发者）导致错误。*</li>
<li><strong>智能</strong>：极佳的编辑器支持。处处皆可自动补全，减少调试时间。</li>
<li><strong>简单</strong>：设计的易于使用和学习，阅读文档的时间更短。</li>
<li><strong>简短</strong>：使代码重复最小化。通过不同的参数声明实现丰富功能。bug 更少。</li>
<li><strong>健壮</strong>：生产可用级别的代码。还有自动生成的交互式文档。</li>
<li><strong>标准化</strong>：基于（并完全兼容）API 的相关开放标准：<a href="https://github.com/OAI/OpenAPI-Specification">OpenAPI</a> (以前被称为 Swagger) 和 <a href="https://json-schema.org/">JSON Schema</a>。</li>
</ul>
<h3 id="两个核心组件：Starlette-和-Pydantic"><a href="#两个核心组件：Starlette-和-Pydantic" class="headerlink" title="两个核心组件：Starlette 和 Pydantic"></a>两个核心组件：Starlette 和 Pydantic</h3><p>Starlette 负责web部分</p>
<p>Starlette 是 FastAPI 的底层 ASGI（异步服务器网关接口）框架，为 FastAPI 提供了异步编程能力和高性能的网络通信支持。</p>
<p>ASGI（<strong>Asynchronous Server Gateway Interface</strong> ）是一种用于连接 Python Web 服务器和应用程序框架的<strong>异步接口标准</strong> ，旨在支持现代 Web 协议（如 WebSocket、HTTP/2）和异步编程模型</p>
<p>Pydantic负责</p>
<p>Pydantic 负责 FastAPI 的数据验证、序列化和自动文档生成</p>
<h3 id="http协议"><a href="#http协议" class="headerlink" title="http协议"></a>http协议</h3><h4 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h4><p><strong>HTTP协议</strong> 是Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于万维网（WWW: World Wide Web）服务器与本地浏览器之间传输超文本的传送协议。HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。</p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/1.png" alt="1"></p>
<h4 id="二、http协议特性"><a href="#二、http协议特性" class="headerlink" title="二、http协议特性"></a>二、http协议特性</h4><p>（1）基于 TCP/IP 协议</p>
<p>http 协议是基于 <strong>TCP/IP 协议</strong>之上的应用层协议。</p>
<p>（2）基于请求 - 响应模式</p>
<p>HTTP 协议规定，请求从客户端发出，最后服务器端响应应该请求并返回。换句话说，肯定是先<strong>从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应</strong>。</p>
<p>（3）无状态保存</p>
<p>HTTP 是一种不保存状态，即无状态（stateless）协议。HTTP 协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。</p>
<p>使用 HTTP 协议，每当有新的请求发送时，就会有对应的新响应产生。协议本身并<strong>不保留之前一切的请求或响应报文的信息</strong>。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。</p>
<p>（4）短连接</p>
<p>HTTP 1.0 默认使用的是短连接。浏览器和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。 </p>
<p>HTTP 1.1 起，默认使用长连接。要使用长连接，客户端和服务器的 HTTP 首部的 Connection 都要设置为 keep - alive，才能支持长连接。 </p>
<p>HTTP 长连接，指的是复用 TCP 连接。多个 HTTP 请求可以复用同一个 TCP 连接，这就节省了 TCP 连接建立和断开的消耗。</p>
<h4 id="三、http请求协议与响应协议"><a href="#三、http请求协议与响应协议" class="headerlink" title="三、http请求协议与响应协议"></a>三、http请求协议与响应协议</h4><p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/2.png" alt="2"></p>
<blockquote>
<p>Socket（套接字）是计算机网络中用于实现进程间双向通信的端点抽象，它为应用层进程通过网络协议交换数据提供了统一的接口。具体来说，Socket 是应用层与 TCP/IP 协议族通信的中间软件抽象层，本质上是一组封装了复杂网络协议的接口，简化了开发者对底层通信细节的操作。</p>
<p>从功能上看，Socket 可以看作是网络通信的“电话插座”：两个设备（如客户端与服务器）通过 Socket 建立连接后，即可像电话通话一样进行数据交换，而端口号则类似于插座上的插孔，用于标识具体的通信进程，且不能被其他进程占用。此外，Socket 包含网络通信必需的五种核心信息，例如使用的协议（TCP/UDP）、本地与远程地址、端口等，构成了网络通信的基本操作单元。</p>
<p>总结而言，Socket 既是通信端点的逻辑概念，也是实现网络应用层交互的关键工具，其设计目标是屏蔽底层协议的复杂性，提供统一的编程接口。</p>
</blockquote>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/3.png" alt="3"></p>
<blockquote>
<p>GET ：请求参数通过 URL 的查询字符串（Query String）传递，数据暴露在地址栏中，例如：<a href="https://example.com">https://example.com</a> ?name=value</p>
<p>POST ：请求参数存储在请求体（Body）中传输，相对更安全，且支持传输非字符串数据（如文件、二进制等）</p>
<p>一个完整的URL包括：协议、ip、端口、路径、参数</p>
<p>例如：<a href="https://www.baidu.com/s?wd=yuan">https://www.baidu.com/s?wd=yuan</a> 其中https是协议，www.baidu.com 是IP，端口默认80，/s是路径，参数是wd=yuan</p>
<p>请求方式：get与post请求</p>
<ul>
<li>GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如EditBook?name=test1&amp;id=123456。POST方法是把提交的数据放在HTTP包的请求体中。</li>
<li>GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制</li>
</ul>
<p>响应状态码：状态码的职责是当客户端向服务器端发送请求时，返回的请求结果。借助状态码，用户可以知道服务器端是正常处理了请求，还是出现了问题。状态码如200 OK，以3位数字和原因组成。</p>
</blockquote>
<p>测试http协议格式：请求与响应</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#web应用程序：遵循http协议</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line">sock=socket.socket()</span><br><span class="line">sock.bind((<span class="string">&quot;127.0.0.1&quot;</span>,<span class="number">8080</span>))</span><br><span class="line">sock.listen(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    conn 表示新建立的套接字对象，用于在服务器和客户端之间进行数据传输。</span></span><br><span class="line"><span class="string">    addr 是一个元组，它包含了连接进来的客户端的 IP 地址和端口号。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    conn, addr = sock.accept()<span class="comment">#阻塞等待客户端连接</span></span><br><span class="line">    data=conn.recv(<span class="number">1024</span>)<span class="comment">#请求报文</span></span><br><span class="line">    <span class="comment"># data 是一个字节串，包含了客户端发送的请求信息。</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端发送的请求信息：\n&quot;</span>,data)</span><br><span class="line">    conn.send(<span class="string">b&quot;HTTP/1.1 200 ok\r\nserver:zxj\r\n\r\nhello world&quot;</span>)<span class="comment">#响应首行+响应头+响应体</span></span><br><span class="line">    conn.close()</span><br></pre></td></tr></table></figure>
<p>测试post请求：urlencoded格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 socket 连接</span></span><br><span class="line">client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">client.connect((<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">8080</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造 POST 请求报文</span></span><br><span class="line">path = <span class="string">&quot;/&quot;</span>  <span class="comment"># 目标路径</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;Host&quot;</span>: <span class="string">&quot;127.0.0.1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>,  <span class="comment"># 数据格式</span></span><br><span class="line">    <span class="string">&quot;Content-Length&quot;</span>: <span class="built_in">len</span>(<span class="string">&quot;username=admin&amp;password=123456&quot;</span>)  <span class="comment"># 数据长度</span></span><br><span class="line">&#125;</span><br><span class="line">body = <span class="string">&quot;username=admin&amp;password=123456&quot;</span>  <span class="comment"># 请求体（表单数据）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拼接请求报文</span></span><br><span class="line">request = <span class="string">f&quot;POST <span class="subst">&#123;path&#125;</span> HTTP/1.1\r\n&quot;</span></span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> headers.items():</span><br><span class="line">    request += <span class="string">f&quot;<span class="subst">&#123;k&#125;</span>: <span class="subst">&#123;v&#125;</span>\r\n&quot;</span></span><br><span class="line">request += <span class="string">&quot;\r\n&quot;</span>  <span class="comment"># 空行分隔头部与主体</span></span><br><span class="line">request += body</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送请求</span></span><br><span class="line">client.send(request.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接收响应</span></span><br><span class="line">response = client.recv(<span class="number">4096</span>)</span><br><span class="line"><span class="built_in">print</span>(response.decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">client.close()</span><br></pre></td></tr></table></figure>
<p>测试post请求：json格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义请求地址</span></span><br><span class="line">url = <span class="string">&quot;http://127.0.0.1:8080&quot;</span></span><br><span class="line"><span class="comment"># 定义 JSON 数据（字典格式）</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;username&quot;</span>: <span class="string">&quot;admin&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送 POST 请求</span></span><br><span class="line">response = requests.post(</span><br><span class="line">    url, </span><br><span class="line">    json=data  <span class="comment"># 使用 json 参数自动序列化字典并设置 Content-Type: application/json</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出响应结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;状态码:&quot;</span>, response.status_code)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;响应内容:&quot;</span>, response.text)  <span class="comment"># 使用 text 获取原始响应文本</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">客户端发送的请求信息：</span></span><br><span class="line"><span class="string"> b&#x27;POST / HTTP/1.1\r\nHost: 127.0.0.1:8080\r\nUser-Agent: python-requests/2.32.2\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nContent-Length: 43\r\nContent-Type: application/json\r\n\r\n&#123;&quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;123456&quot;&#125;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>通过 <code>json=data</code> 参数，<code>requests</code> 会自动将字典转换为 JSON 字符串，并设置请求头 <code>Content-Type: application/json</code>，无需手动调用 <code>json.dumps()</code> 或配置 headers </p>
<p>SSL 验证是指通过 SSL 证书验证网站身份并确保通信安全的过程。其核心目标是确认服务器的真实性、防止身份伪造，并建立加密连接以保护数据传输的安全性</p>
<p>HTTPS（HyperText Transfer Protocol Secure）是以安全为目标的 HTTP 通道，通过在 HTTP 基础上加入加密和身份认证机制，确保数据传输的隐私性、完整性和服务器身份的真实性</p>
<p>https=http+ssl</p>
<p>通过 <code>Content-Type</code>，服务器可识别请求体（Body）的格式（如 JSON、表单数据），客户端可解析响应数据的类型（如 HTML、图片）</p>
<p>例如：conn.send(b”HTTP/1.1 200 ok\r\nserver:zxj\r\n<strong>content-type:text/html</strong>\r\n\r\n</p><h1>hello world&lt;\h1&gt;”)<p></p>
<p>再例如：‘HTTP/1.1 200 ok\r\nserver:zxj\r\n<strong>content-type:application/json</strong>\r\n\r\n{“user_id”:zxj}’</p>
</h1></blockquote>
<h5 id="api接口"><a href="#api接口" class="headerlink" title="api接口"></a>api接口</h5><p>在开发web应用中，有两种应用模式：</p>
<p>1.前后端不分离：客户端看到的内容和所有页面效果都是有服务端提供出来的</p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/4.png" alt="4"></p>
<p>2.前后端分离：把前端的页面效果（html，css，js分离到另一个服务端，python服务端只需要返回数据即可）</p>
<p>前端形成一个独立的网站，服务端构成一个独立的网站</p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/5.png" alt="5"></p>
<p><strong>应用程序编程接口（Application Programming Interface，API接口）</strong>，就是应用程序对外提供了一个操作数据的入口，这个入口可以是一个函数或类方法，也可以是一个url地址或者一个网络地址。当客户端调用这个入口，应用程序则会执行对应代码操作，给客户端完成相对应的功能。</p>
<p>当然，api接口在工作中是比较常见的开发内容，有时候，我们会调用其他人编写的api接口，有时候，我们也需要提供api接口给其他人操作。由此就会带来一个问题，api接口往往都是一个函数、类方法、或者url或其他网络地址，不断是哪一种，当api接口编写过程中，我们都要考虑一个问题就是这个接口应该怎么编写？接口怎么写的更加容易维护和清晰，这就需要大家在调用或者编写api接口的时候要有一个明确的编写规范！！！</p>
<p>为了在团队内部形成共识，防止个人习惯差异引起的混乱，我们都需要找到一种大家都觉得很好的接口实现规范，而且这种规范能够让后端写的接口，用途一目了然，减少客户端和服务端双方之间的合作成本。</p>
<p>目前市面上大部分公司开发人员使用的接口实现规范主要有：restful、RPC。</p>
<p>REST全称是Representational State Transfer，中文意思是表述（编者注：通常译为表征）性状态转移。它首次出现在2000年Roy Fielding的博士论文中。</p>
<p>RESTful是一种专门为Web开发而定义API接口的设计风格，尤其适用于前后端分离的应用模式中。</p>
<p><strong>关键：面向资源开发</strong></p>
<p>这种风格的理念认为后端开发任务就是提供数据的，对外提供的是数据资源的访问接口，所以在定义接口时，客户端访问的URL路径就表示这种要操作的数据资源。</p>
<p>而<strong>对于数据资源分别使用POST、DELETE、GET、UPDATE等请求动作来表达对数据的增删查改</strong>。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>请求方法</th>
<th>请求地址</th>
<th>后端操作</th>
</tr>
</thead>
<tbody>
<tr>
<td>POST</td>
<td>/student/</td>
<td>增加学生</td>
</tr>
<tr>
<td>GET</td>
<td>/student/</td>
<td>获取所有学生</td>
</tr>
<tr>
<td>GET</td>
<td>/student/1</td>
<td>获取id为1的学生</td>
</tr>
<tr>
<td>PUT</td>
<td>/student/1</td>
<td>修改id为1的学生</td>
</tr>
<tr>
<td>DELETE</td>
<td>/student/1</td>
<td>删除id为1的学生</td>
</tr>
</tbody>
</table>
</div>
<p>restful规范是一种通用的规范，不限制语言和开发框架的使用。事实上，我们可以使用任何一门语言，任何一个框架都可以实现符合restful规范的API接口。</p>
<h3 id="fastapi快速开始"><a href="#fastapi快速开始" class="headerlink" title="fastapi快速开始"></a>fastapi快速开始</h3><h4 id="简单案例"><a href="#简单案例" class="headerlink" title="简单案例"></a>简单案例</h4><p>安装：<code>pip install fastapi</code></p>
<p>还需要一个ASGI服务器，生产环境使用Uvicorn：<code>pip install uvicorn</code></p>
<blockquote>
<p>ASGI（<strong>Asynchronous Server Gateway Interface</strong> ）是一种<strong>异步服务器网关接口</strong> ，为 Python Web 应用提供了标准接口，使其能够处理现代网络协议（如 WebSocket、HTTP/2 等）的异步请求。与传统的 WSGI 不同，ASGI 支持异步编程模型，允许单个请求处理多个事件（如长连接、双向通信），从而提升高并发场景下的性能</p>
<p>Uvicorn 是一个基于 ASGI 的高性能异步 Web 服务器，专为 Python 异步框架设计。</p>
<p>web应用程序=web框架+自己写的业务逻辑代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI<span class="comment">#fastapi类</span></span><br><span class="line"></span><br><span class="line">app= FastAPI()<span class="comment">#创建一个fastapi实例</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">home</span>():</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_id&quot;</span>:<span class="number">1001</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/shop&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">shop</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;shop_id&quot;</span>:<span class="number">1002</span>&#125;</span><br></pre></td></tr></table></figure>
<p>启动：<code>uvicorn &quot;04 fastapi_begin:app&quot; --reload</code></p>
<p>也可以：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(app=<span class="string">&quot;04 fastapi_begin:app&quot;</span>,port=<span class="number">8080</span>,reload=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>接口文档</p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/6.png" alt="6"></p>
<blockquote>
<p>修饰器（Decorator）是 Python 中一种动态修改函数或类行为的高级功能，本质上是一个函数或类，它<strong>接受目标函数或类作为参数，并返回包装后的新函数或类对象</strong>，从而在<strong>不修改原始代码</strong> 的前提下为对象添加额外功能</p>
</blockquote>
<h3 id="路径操作"><a href="#路径操作" class="headerlink" title="路径操作"></a>路径操作</h3><h4 id="路径操作修饰器"><a href="#路径操作修饰器" class="headerlink" title="路径操作修饰器"></a>路径操作修饰器</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.get()</span></span><br><span class="line"><span class="meta">@app.post()</span></span><br><span class="line"><span class="meta">@app.put()</span></span><br><span class="line"><span class="meta">@app.patch()</span></span><br><span class="line"><span class="meta">@app.delete()</span></span><br><span class="line"><span class="meta">@app.options()</span></span><br><span class="line"><span class="meta">@app.head()</span></span><br><span class="line"><span class="meta">@app.trace()</span></span><br></pre></td></tr></table></figure>
<p>路径操作修饰器参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tags为接口添加标签，用于在自动生成的文档</span></span><br><span class="line"><span class="string">summary为接口添加描述</span></span><br><span class="line"><span class="string">description为接口添加详细描述</span></span><br><span class="line"><span class="string">response_description为接口返回值描述</span></span><br><span class="line"><span class="string">deprecated为过时的接口</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/post&quot;</span>, </span></span></span><br><span class="line"><span class="params"><span class="meta">        tags=[<span class="string">&quot;这是post方法&quot;</span>],</span></span></span><br><span class="line"><span class="params"><span class="meta">        summary=<span class="string">&quot;这是post方法的描述&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">        description=<span class="string">&quot;这是post方法的详细描述&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">        response_description=<span class="string">&quot;这是post方法的返回值描述&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">        deprecated=<span class="literal">True</span>, <span class="comment"># 过时的接口</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        </span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br></pre></td></tr></table></figure>
<h4 id="include-router"><a href="#include-router" class="headerlink" title="include_router"></a>include_router</h4><p>文件路径如下</p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/7.png" alt="7"></p>
<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> apps.app01.shop <span class="keyword">import</span> shop</span><br><span class="line"><span class="keyword">from</span> apps.app02.user <span class="keyword">import</span> user</span><br><span class="line"></span><br><span class="line">app= FastAPI()</span><br><span class="line"></span><br><span class="line">app.include_router(shop,</span><br><span class="line">                 prefix=<span class="string">&quot;/shop&quot;</span>, <span class="comment"># 路由前缀</span></span><br><span class="line">                 tags=[<span class="string">&quot;购物中心接口&quot;</span>], <span class="comment"># 标签</span></span><br><span class="line">                 responses=&#123;<span class="number">200</span>: &#123;<span class="string">&quot;description&quot;</span>: <span class="string">&quot;成功&quot;</span>&#125;&#125; <span class="comment"># 响应描述</span></span><br><span class="line">                 )</span><br><span class="line">app.include_router(user,</span><br><span class="line">                 prefix=<span class="string">&quot;/user&quot;</span>, <span class="comment"># 路由前缀</span></span><br><span class="line">                 tags=[<span class="string">&quot;用户接口&quot;</span>], <span class="comment"># 标签</span></span><br><span class="line">                 responses=&#123;<span class="number">200</span>: &#123;<span class="string">&quot;description&quot;</span>: <span class="string">&quot;成功&quot;</span>&#125;&#125; <span class="comment"># 响应描述</span></span><br><span class="line">                 )</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(<span class="string">&quot;main:app&quot;</span>, port=<span class="number">8080</span>,  reload=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>shop.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"></span><br><span class="line">shop=APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="meta">@shop.get(<span class="params"><span class="string">&quot;/food&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shop_food</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;food&quot;</span>:<span class="string">&quot;shop food&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@shop.get(<span class="params"><span class="string">&quot;/drink&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shop_drink</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;drink&quot;</span>:<span class="string">&quot;shop drink&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>user.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"></span><br><span class="line">user=APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="meta">@user.post(<span class="params"><span class="string">&quot;/login&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">user_login</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user&quot;</span>:<span class="string">&quot;user login&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@user.post(<span class="params"><span class="string">&quot;/register&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">user_register</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user&quot;</span>:<span class="string">&quot;user register&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>include_router</code> 是 FastAPI 框架中用于整合路由的核心方法，其作用是将通过 <code>APIRouter</code> 定义的路由模块添加到主应用程序实例中，使这些路由在应用中生效。</p>
</blockquote>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/8.png" alt="8"></p>
<h3 id="请求与响应"><a href="#请求与响应" class="headerlink" title="请求与响应"></a>请求与响应</h3><h4 id="4-1-路径参数"><a href="#4-1-路径参数" class="headerlink" title="4.1 路径参数"></a>4.1 路径参数</h4><h5 id="（1）基本用法"><a href="#（1）基本用法" class="headerlink" title="（1）基本用法"></a>（1）基本用法</h5><p>以使用与 Python 格式化字符串相同的语法来声明路径”参数”或”变量”：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/user/&#123;user_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user</span>(<span class="params">user_id</span>):</span><br><span class="line">    <span class="built_in">print</span>(user_id, <span class="built_in">type</span>(user_id))</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_id&quot;</span>: user_id&#125;</span><br></pre></td></tr></table></figure>
<p>路径参数 <code>user_id</code> 的值将作为参数 <code>user_id</code> 传递给你的函数。</p>
<h5 id="（2）有类型的路径参数"><a href="#（2）有类型的路径参数" class="headerlink" title="（2）有类型的路径参数"></a>（2）有类型的路径参数</h5><p>你可以使用标准的 Python 类型标注为函数中的路径参数声明类型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/user/&#123;user_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user</span>(<span class="params">user_id: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(user_id, <span class="built_in">type</span>(user_id))</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_id&quot;</span>: user_id&#125;</span><br></pre></td></tr></table></figure>
<p>在这个例子中，<code>user_id</code> 被声明为 int 类型。</p>
<blockquote>
<p>这将为你的函数提供编辑器支持，包括错误检查、代码补全等等。</p>
</blockquote>
<h5 id="（3）注意顺序"><a href="#（3）注意顺序" class="headerlink" title="（3）注意顺序"></a>（3）注意顺序</h5><p>在创建路径操作时，你会发现有些情况下路径是固定的。</p>
<p>比如 <code>/users/me</code>，我们假设它用来获取关于当前用户的数据。</p>
<p>然后，你还可以使用路径 <code>/user/&#123;username&#125;</code> 来通过用户名获取关于特定用户的数据。</p>
<p>由于路径操作是<strong>按顺序依次运行</strong>的，你需要确保路径 /<code>user/me</code> 声明在路径 <code>/user/&#123;username&#125;</code> 之前。</p>
<p>如下</p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250516193934740.png" alt="image-20250516193934740"></p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250516201128482.png" alt="image-20250516201128482"></p>
<blockquote>
<p>路由（Routing）是指在网络中<strong>选择数据传输路径</strong>的过程，其核心目标是将数据从源点高效、可靠地传输到目的地</p>
<p>cURL 是一个开源的命令行工具和跨平台的库（libcurl），用于基于 URL 语法在网络协议下进行数据传输。它支持多种协议（如 HTTP、HTTPS、FTP、SMTP 等），能够实现文件上传、下载以及与 Web 服务器的交互，常被开发者用于 API 测试、数据传输等场景</p>
</blockquote>
<h4 id="4-2-查询参数（请求参数）"><a href="#4-2-查询参数（请求参数）" class="headerlink" title="4.2 查询参数（请求参数）"></a>4.2 查询参数（请求参数）</h4><p>路径函数中声明<strong>不属于路径参数的其他函数参数</strong>时，它们将被<strong>自动解释为查询字符串参数</strong>，就是 <code>url？</code>之后用 <code>&amp;</code> 分割的 <code>key-value 键值对</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app02.get(<span class="params"><span class="string">&quot;/jobs&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_jobs</span>(<span class="params">kind1: <span class="built_in">str</span>, kind2: <span class="built_in">str</span>, kind3: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="comment">#基于查询参数的值来执行不同的操作</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;kind1&quot;</span>: kind1,</span><br><span class="line">        <span class="string">&quot;kind2&quot;</span>: kind2,</span><br><span class="line">        <span class="string">&quot;kind3&quot;</span>: kind3</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250516201707589.png" alt="image-20250516201707589"></p>
<p>增加路径参数：kind1为路径参数</p>
<p>增加默认参数值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app02.get(<span class="params"><span class="string">&quot;/jobs/&#123;kind1&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_jobs</span>(<span class="params">kind1: <span class="built_in">str</span>, kind2: <span class="built_in">str</span>=<span class="string">&quot;None&quot;</span>, kind3: <span class="built_in">str</span>=<span class="string">&quot;None&quot;</span></span>):<span class="comment">#增加默认值，可选填</span></span><br><span class="line">    <span class="comment">#基于查询参数的值来执行不同的操作</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;kind1&quot;</span>: kind1,</span><br><span class="line">        <span class="string">&quot;kind2&quot;</span>: kind2,</span><br><span class="line">        <span class="string">&quot;kind3&quot;</span>: kind3</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>Request URL：</p>
<p><code>http://127.0.0.1:8080/app02/jobs/11?kind2=22&amp;kind3=33</code></p>
<p>自python3.5开始，PEP484为python引入了类型注解(type hints)，typing的主要作用有：</p>
<blockquote>
<p>1.类型检查，防止运行时出现参数、返回值类型不符。</p>
<p>2.作为开发文档附加说明，方便使用者调用时传入和返回参数类型。</p>
<p>3.模块加入不会影响程序的运行不会报正式的错误，pycharm支持typing检查错误时会出现黄色警告。</p>
</blockquote>
<p><code>type hints</code>主要是要指示函数的输入和输出的数据类型，数据类型在typing包中，基本类型有<code>str list dict</code>等等，</p>
<blockquote>
<p>Type Hints 是 Python 3.5 引入的功能，通过类型注解增强代码的可读性和可维护性。它允许开发者为变量、函数参数、返回值等指定预期的数据类型，从而帮助静态类型检查工具（如 <code>mypy</code>）捕获潜在错误，并提升 IDE 的智能提示能力。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">greet</span>(<span class="params">name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;Hello, <span class="subst">&#123;name&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>
<p>此处 <code>name: str</code> 表示参数需为字符串类型，<code>-&gt; str</code> 表示返回值类型为字符串 。</p>
</blockquote>
<p><code>Union</code>是当有多种可能的数据类型时使用，比如函数有可能根据不同情况有时返回str或返回list，那么就可以写成<code>Union[list, str]</code></p>
<blockquote>
<p>从 Python 3.10 起，<code>Union[X, Y]</code> 可简写为 <code>X | Y</code>。例如 <code>int | str</code> 等价于 <code>Union[int, str]</code> 。</p>
<p>再例如：<code>kind2:str|None=None</code></p>
</blockquote>
<p><code>Optional</code>是Union的一个简化，当数据类型中有可能是None时，比如有可能是str也有可能是None，则Optional[str]，相当于Union[str, None]</p>
<h4 id="4-3-请求体数据"><a href="#4-3-请求体数据" class="headerlink" title="4.3 请求体数据"></a>4.3 请求体数据</h4><p>当你需要将数据从客户端（例如浏览器）发送给 API 时，你将其作为「请求体」发送。请求体是客户端发送给 API 的数据。响应体是 API 发送给客户端的数据。</p>
<p>FastAPI 基于 <code>Pydantic</code> ，<code>Pydantic</code> 主要用来做类型强制检查（校验数据）。不符合类型要求就会抛出异常。</p>
<p>对于 API 服务，支持类型检查非常有用，会让服务更加健壮，也会加快开发速度，因为开发者再也不用自己写一行一行的做类型检查。</p>
<p>安装上手 <code>pip install pydantic</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel,Field,field_validator</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> date</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span>,<span class="type">Optional</span></span><br><span class="line"></span><br><span class="line">app03 = APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Address</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    province: <span class="built_in">str</span></span><br><span class="line">    city: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="comment">#正则表达式</span></span><br><span class="line">    <span class="comment">#username:str=Field(pattern=&quot;^[a-zA-Z0-9]&#123;3,10&#125;$&quot;,title=&quot;用户名&quot;,description=&quot;用户名长度在3-10之间，且只能包含字母和数字&quot;)</span></span><br><span class="line">    <span class="comment">#name: str|None = None</span></span><br><span class="line">    name:<span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span>=Field(default=<span class="number">0</span>,gt=<span class="number">0</span>,lt=<span class="number">100</span>)</span><br><span class="line">    birth:<span class="type">Union</span>[date,<span class="literal">None</span>] = <span class="literal">None</span></span><br><span class="line">    friends:<span class="built_in">list</span>[<span class="built_in">int</span>]=[]</span><br><span class="line">    description:<span class="type">Optional</span>[<span class="built_in">str</span>]=<span class="literal">None</span></span><br><span class="line">    <span class="comment">#嵌套</span></span><br><span class="line">    addr:Address|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    field_validator 的第一个参数必须是 cls，因为它是类方法 （classmethod），用于在验证字段时访问模型类的上下文。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">    @field_validator(<span class="params"><span class="string">&quot;name&quot;</span></span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name_must_alpha</span>(<span class="params">cls,value</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        value.isalpha() 会检查字符串是否只由字母组成，如果是则返回 True，否则返回 False。</span></span><br><span class="line"><span class="string">        如果返回 False，assert 触发，会抛出 AssertionError，并显示错误信息 &quot;name must be alpha&quot;。</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">assert</span> value.isalpha(), <span class="string">&quot;name must be alpha&quot;</span></span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="comment">#嵌套</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Data</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    data:<span class="built_in">list</span>[User]</span><br><span class="line"></span><br><span class="line"><span class="meta">@app03.post(<span class="params"><span class="string">&quot;/user&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">user</span>(<span class="params">user:User</span>):</span><br><span class="line">    <span class="built_in">print</span>(user,<span class="built_in">type</span>(user))</span><br><span class="line">    <span class="keyword">return</span> user</span><br><span class="line"></span><br><span class="line"><span class="meta">@app03.post(<span class="params"><span class="string">&quot;/data&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">data</span>(<span class="params">data:Data</span>):</span><br><span class="line">    <span class="built_in">print</span>(data,<span class="built_in">type</span>(data))</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>BaseModel</code>专门用于数据验证、数据转换和序列化。在定义数据结构时继承自 BaseModel，可以：</p>
<ul>
<li><strong>自动校验数据类型</strong>：根据类中字段的类型注解，自动校验输入数据是否符合预期类型。</li>
<li><strong>数据转换</strong>：可以自动将输入数据（例如 JSON 字符串）转换成相应的 Python 数据类型。</li>
<li><strong>序列化输出</strong>：支持将模型实例转换成 JSON、字典等格式，便于响应输出。</li>
</ul>
<p>在 Pydantic 中，<code>Field</code> 用于为模型字段提供额外的信息，比如设置默认值、描述信息、约束条件（例如长度、范围等）或别名。这可以帮助自动生成 OpenAPI 文档、增强验证或对字段进行更细粒度的控制。</p>
<p><code>field_validator</code> 是 Pydantic v2 中用于替代旧版 <code>@validator</code> 的新装饰器，专门用于为模型字段添加自定义验证逻辑。它通过更清晰的命名和更灵活的模式（如 <code>mode=&quot;before&quot;</code> 或 <code>mode=&quot;after&quot;</code>）提升代码可读性和验证逻辑的控制能力</p>
<p><code>field_validator</code>和<code>model_validator</code>区别</p>
<p><strong><code>field_validator</code></strong>专门针对<strong>单个字段</strong> 进行验证，适用于需要校验特定字段的规则（如长度、格式、类型约束）。例如验证用户名长度</p>
<p><strong><code>model_validator</code></strong>作用于<strong>整个模型实例</strong> ，适用于需要跨字段验证或全局逻辑的场景。例如检查两次密码是否一致</p>
</blockquote>
<h4 id="4-4-form表单数据"><a href="#4-4-form表单数据" class="headerlink" title="4.4 form表单数据"></a>4.4 form表单数据</h4><p>在 <code>OAuth2</code> 规范的一种使用方式（密码流）中，需要将用户名、密码作为表单字段发送，而不是 JSON。</p>
<p>FastAPI 可以使用 <strong>Form 组件</strong>来接收表单数据，需要先使用 <code>pip install python-multipart</code> 命令进行安装。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app04.post(<span class="params"><span class="string">&quot;/register&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">data</span>(<span class="params">username:<span class="built_in">str</span>=Form(<span class="params"></span>),password:<span class="built_in">str</span>=Form(<span class="params"></span>)</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;username: <span class="subst">&#123;username&#125;</span>, password: <span class="subst">&#123;password&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;username&quot;</span>: username,</span><br><span class="line">        <span class="string">&quot;password&quot;</span>: password</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>发送post请求：form表单数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 目标 URL</span></span><br><span class="line">url = <span class="string">&quot;http://127.0.0.1:8080/app04/register&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 表单数据（键值对）</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;username&quot;</span>: <span class="string">&quot;test_user&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;secure_password_123&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送 POST 请求</span></span><br><span class="line">response = requests.post(</span><br><span class="line">    url, </span><br><span class="line">    data=data</span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>通过 requests.post() 的 data 参数传递表单数据，该参数接受字典或字符串格式的数据。requests 会自动将其编码为 application/x-www-form-urlencoded 格式</p>
</blockquote>
<h4 id="4-5-文件上传"><a href="#4-5-文件上传" class="headerlink" title="4.5 文件上传"></a>4.5 文件上传</h4><p>导入必要库</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> File,UploadFile</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">app05 = APIRouter()</span><br></pre></td></tr></table></figure>
<p>通过字节上传</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app05.post(<span class="params"><span class="string">&quot;/file&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">file</span>(<span class="params">file: <span class="built_in">bytes</span> = File(<span class="params">...</span>)</span>):</span><br><span class="line">    <span class="comment">#适合小文件上传</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;filename&quot;</span>: <span class="string">&quot;file&quot;</span>,</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: <span class="built_in">len</span>(file)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>多文件上传</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app05.post(<span class="params"><span class="string">&quot;/files&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">files</span>(<span class="params">files: <span class="built_in">list</span>[<span class="built_in">bytes</span>] = File(<span class="params">...</span>)</span>):</span><br><span class="line">    <span class="comment">#多文件上传</span></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">len</span>(file))</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;filename&quot;</span>: <span class="string">&quot;files&quot;</span>,</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: <span class="built_in">len</span>(files)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>UploadFile上传，绝对路径</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app05.post(<span class="params"><span class="string">&quot;/uploadfile&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">upload_file</span>(<span class="params">file: UploadFile= File(<span class="params">...</span>)</span>):</span><br><span class="line">    <span class="comment">#适合大文件上传</span></span><br><span class="line">    <span class="comment"># 获取当前文件的绝对路径</span></span><br><span class="line">    base_dir = os.path.dirname(os.path.abspath(__file__))</span><br><span class="line">    <span class="built_in">print</span>(base_dir)</span><br><span class="line">    img_dir = os.path.join(base_dir, <span class="string">&quot;../imgs&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(img_dir)</span><br><span class="line">    <span class="comment"># 创建目录</span></span><br><span class="line">    path = os.path.join(img_dir, file.filename)</span><br><span class="line">    <span class="comment">#path=os.path.join(&quot;../imgs&quot;,file.filename)</span></span><br><span class="line">    <span class="built_in">print</span>(path)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;文件名:&quot;</span>, file.filename)</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> file.file:</span><br><span class="line">            f.write(chunk)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;filename&quot;</span>: file.filename</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>UploadFile是 FastAPI 提供的一个类，用于处理文件上传。与直接将文件内容读取为字节流（例如 bytes相比，UploadFile有以下优点：</p>
<ul>
<li><strong>内存优化</strong>：它采用了文件对象的方式处理上传文件，不必将整个文件内容一次性加载到内存中，适合处理大文件。</li>
<li><strong>异步支持</strong>：支持异步操作，可以用异步方式读取文件内容，提高性能。</li>
<li><strong>文件元数据</strong>：提供文件名、内容类型等元数据信息，通过属性 <code>filename</code>、<code>content_type</code> 获取。</li>
<li><strong>文件接口</strong>：通过 file 属性获取一个类文件对象，可以像操作普通文件一样读取或保存上传的文件。</li>
</ul>
</blockquote>
<h4 id="4-6-Request对象"><a href="#4-6-Request对象" class="headerlink" title="4.6 Request对象"></a>4.6 Request对象</h4><p>有些情况下我们希望能直接访问 Request 对象。例如我们在路径操作函数中想获取客户端的 IP 地址，需要在函数中声明 Request 类型的参数，FastAPI 就会自动传递 Request 对象给这个参数，我们就可以获取到 Request 对象及其属性信息，例如 header、url、cookie、session 等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@app06.post(<span class="params"><span class="string">&quot;/items&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">items</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;url:&quot;</span>, request.url)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端ip:&quot;</span>, request.client.host)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求头:&quot;</span>, request.headers)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端宿主&quot;</span>,request.headers.get(<span class="string">&quot;user-agent&quot;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;cookie:&quot;</span>, request.cookies)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;url&quot;</span>: request.url,</span><br><span class="line">        <span class="string">&quot;client_ip&quot;</span>: request.client.host,</span><br><span class="line">        <span class="string">&quot;headers&quot;</span>: request.headers,</span><br><span class="line">        <span class="string">&quot;user_agent&quot;</span>: request.headers.get(<span class="string">&quot;user-agent&quot;</span>),</span><br><span class="line">        <span class="string">&quot;cookies&quot;</span>: request.cookies</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="4-7请求静态文件"><a href="#4-7请求静态文件" class="headerlink" title="4.7请求静态文件"></a>4.7请求静态文件</h4><p>在 Web 开发中，需要请求很多静态资源文件（不是由服务器生成的文件），如 css/js 和图片文件等。</p>
<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi.staticfiles <span class="keyword">import</span> StaticFiles</span><br><span class="line">app.mount(<span class="string">&quot;/static&quot;</span>, StaticFiles(directory=<span class="string">&quot;statics&quot;</span>))<span class="comment">#静态文件目录</span></span><br></pre></td></tr></table></figure>
<p><img src="./../../../../images/fastapi/image-20250517143857442.png" alt="image-20250517143857442"></p>
<p><img src="./../../../../images/fastapi/image-20250517143914772.png" alt="image-20250517143914772"></p>
<blockquote>
<p><strong>静态网站</strong></p>
<p>完全由静态文件（HTML、CSS、JavaScript）组成，内容固定不变，所有页面在开发时已预生成，无需动态计算或数据库支持</p>
<p><strong>动态网站</strong></p>
<p>内容根据用户请求实时生成，通常依赖数据库和服务器端编程（如PHP、Python、Node.js），能提供个性化和交互功能</p>
<p><code>StaticFiles</code>是 FastAPI（实际来自 Starlette）提供的一个类，用于挂载和服务静态文件目录。<br>它的作用是让你可以通过 HTTP 路径直接访问服务器上的静态资源（如图片、CSS、JS 文件等）。</p>
<p><code>mount()</code>方法用于将一个完整的应用或静态文件目录挂载到主 FastAPI 应用的某个路径下。这样，访问指定路径时，请求会被转发到挂载的应用或目录。</p>
</blockquote>
<h4 id="4-8-响应模型相关参数"><a href="#4-8-响应模型相关参数" class="headerlink" title="4.8 响应模型相关参数"></a>4.8 响应模型相关参数</h4><h5 id="response-model"><a href="#response-model" class="headerlink" title="response_model"></a>response_model</h5><p><code>response_model</code>是 FastAPI 路由装饰器（如 <code>@app.post</code>、<code>@app.get</code> 等）中的一个参数，用于指定接口响应的数据模型。它的作用是：</p>
<ul>
<li><strong>自动校验和序列化</strong>：FastAPI 会根据你指定的 Pydantic 模型自动校验、过滤和格式化返回的数据。</li>
<li><strong>自动生成文档</strong>：接口文档会自动显示响应的数据结构。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UserIn</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    username: <span class="built_in">str</span></span><br><span class="line">    password: <span class="built_in">str</span></span><br><span class="line">    email: EmailStr</span><br><span class="line">    full_name: <span class="built_in">str</span>|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UserOut</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    username: <span class="built_in">str</span></span><br><span class="line">    email: EmailStr</span><br><span class="line">    full_name: <span class="built_in">str</span>|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app07.post(<span class="params"><span class="string">&quot;/user02&quot;</span>,response_model=UserOut</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_user</span>(<span class="params">user: UserIn</span>):</span><br><span class="line">    <span class="comment"># 这里可以进行一些处理，比如将用户信息存储到数据库中</span></span><br><span class="line">    <span class="keyword">return</span> user</span><br></pre></td></tr></table></figure>
<p>案例：</p>
<ul>
<li>注册功能</li>
<li>输入账号、密码、昵称、邮箱，注册成功后返回个人信息</li>
</ul>
<h5 id="response-model-exclude-unset-True"><a href="#response-model-exclude-unset-True" class="headerlink" title="response_model_exclude_unset=True"></a>response_model_exclude_unset=True</h5><p>通过上面的例子，我们学到了如何用 response_model 控制响应体结构，但是，如果它们实际上没有存储，则可能要从结果中忽略它们。例如，如果 model 在 NoSQL 数据库中具有很多可选属性，但是不想发送很长的 JSON 响应，其中包含默认值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Item</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name:<span class="built_in">str</span></span><br><span class="line">    description: <span class="built_in">str</span>|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line">    price: <span class="built_in">float</span></span><br><span class="line">    tax:<span class="built_in">float</span>=<span class="number">10.5</span></span><br><span class="line">    tags: <span class="built_in">list</span>[<span class="built_in">str</span>]|<span class="literal">None</span> = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#模拟数据库</span></span><br><span class="line">items=&#123;</span><br><span class="line">    <span class="string">&quot;item01&quot;</span>:Item(name=<span class="string">&quot;item01&quot;</span>,price=<span class="number">10.5</span>),</span><br><span class="line">    <span class="string">&quot;item02&quot;</span>:Item(name=<span class="string">&quot;item02&quot;</span>,description=<span class="string">&quot;item02&quot;</span>,price=<span class="number">20.5</span>,tax=<span class="number">20.5</span>,tags=[<span class="string">&quot;tag1&quot;</span>,<span class="string">&quot;tag2&quot;</span>]),</span><br><span class="line">    <span class="string">&quot;item03&quot;</span>:Item(name=<span class="string">&quot;item03&quot;</span>,description=<span class="string">&quot;item03&quot;</span>,price=<span class="number">30.5</span>,tax=<span class="number">30.5</span>,tags=[<span class="string">&quot;tag1&quot;</span>,<span class="string">&quot;tag2&quot;</span>]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app07.get(<span class="params"><span class="string">&quot;/items/&#123;item_id&#125;&quot;</span>,response_model=Item,response_model_exclude_unset=<span class="literal">True</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">read_item</span>(<span class="params">item_id: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">return</span> items[item_id]</span><br></pre></td></tr></table></figure>
<p>设置后返回为：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">item01</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;item01&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;price&quot;</span><span class="punctuation">:</span> <span class="number">10.5</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>当你设置 <code>response_model_exclude_unset=True</code> 时，返回的响应数据只包含<strong>被显式设置过的字段</strong>，没有被赋值的（即使用默认值且未传递的）字段不会出现在响应中。</p>
</blockquote>
<h5 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h5><p><strong>response_model_exclude_defaults </strong>作用：排除所有值为默认值的字段。</p>
<p><strong>response_model_exclude_none</strong> 作用：排除所有值为 <code>None</code> 的字段。</p>
<p><strong>response_model_include</strong> 作用：只返回指定字段</p>
<p><strong>response_model_exclude</strong> 作用：排除指定字段，不在响应中返回。</p>
<h3 id="jinja2模板"><a href="#jinja2模板" class="headerlink" title="jinja2模板"></a>jinja2模板</h3><p>要了解 jinja2，那么需要先理解模板的概念。模板在 Python 的 web 开发中广泛使用，它能够有效的将业务逻辑和页面逻辑分开，使代码可读性增强、并且更加容易理解和维护。</p>
<p>模板简单来说就是一个其中包涵占位变量表示动态的部分的文件，模板文件在经过动态赋值后，返回给用户。</p>
<p>jinja2 是 Flask 作者开发的一个模板系统，起初是仿 django 模板的一个模板引擎，为 Flask 提供模板支持，由于其灵活，快速和安全等优点被广泛使用。</p>
<p>在 jinja2 中，存在三种语法：</p>
<blockquote>
<ol>
<li>变量取值 <code>&#123;&#123; &#125;&#125;</code></li>
<li>控制结构 <code>&#123;% %&#125;</code></li>
</ol>
<p>应用于前后端不分离，模板html+数据库，返回动态网站</p>
</blockquote>
<h4 id="5-1-变量"><a href="#5-1-变量" class="headerlink" title="5.1 变量"></a>5.1 变量</h4><p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi.templating <span class="keyword">import</span> Jinja2Templates</span><br><span class="line"></span><br><span class="line">templates=Jinja2Templates(directory=<span class="string">&quot;templates&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/index&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="comment">#数据库</span></span><br><span class="line">    name=<span class="string">&quot;World&quot;</span></span><br><span class="line">    books=[<span class="string">&quot;Python&quot;</span>, <span class="string">&quot;Java&quot;</span>, <span class="string">&quot;C++&quot;</span>]</span><br><span class="line">    user=&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;Tom&quot;</span>, <span class="string">&quot;age&quot;</span>:<span class="number">18</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> templates.TemplateResponse(</span><br><span class="line">        <span class="string">&quot;index.html&quot;</span>,<span class="comment">#模板文件</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;request&quot;</span>: request,<span class="comment"># FastAPI需要一个request对象</span></span><br><span class="line">            <span class="string">&quot;name&quot;</span>: name,</span><br><span class="line">            <span class="string">&quot;books&quot;</span>: books,</span><br><span class="line">            <span class="string">&quot;user&quot;</span>: user</span><br><span class="line">        &#125;<span class="comment">#context上下文对象</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>index.html</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=<span class="string">&quot;en&quot;</span>&gt;</span><br><span class="line"></span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=<span class="string">&quot;UTF-8&quot;</span>&gt;</span><br><span class="line">    &lt;meta name=<span class="string">&quot;viewport&quot;</span> content=<span class="string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span><br><span class="line">    &lt;title&gt;Document&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line"></span><br><span class="line">&lt;body&gt;</span><br><span class="line">    &lt;h1&gt;Hello, &#123;&#123; name &#125;&#125;!&lt;/h1&gt;</span><br><span class="line">    &lt;p&gt;Your favorite books are:&lt;/p&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">        &#123;% <span class="keyword">for</span> book <span class="keyword">in</span> books %&#125;</span><br><span class="line">        &lt;li&gt;&#123;&#123; book &#125;&#125;&lt;/li&gt;</span><br><span class="line">        &#123;% endfor %&#125;</span><br><span class="line">    &lt;/ul&gt;</span><br><span class="line">    &lt;p&gt;姓名：&#123;&#123; user.name &#125;&#125;&lt;/p&gt;</span><br><span class="line">    &lt;p&gt;年龄：&#123;&#123; user.age &#125;&#125;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line"></span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250517200643492.png" alt="image-20250517200643492"></p>
<h4 id="5-2-过滤器"><a href="#5-2-过滤器" class="headerlink" title="5.2 过滤器"></a>5.2 过滤器</h4><p>变量可以通过“过滤器”进行修改，过滤器可以理解为是 jinja2 里面的内置函数和字符串处理函数。常用的过滤器有：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>过滤器名称</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>capitalize</td>
<td>把值的首字母转换成大写，其他字母转换为小写</td>
</tr>
<tr>
<td>lower</td>
<td>把值转换成小写形式</td>
</tr>
<tr>
<td>title</td>
<td>把值中每个单词的首字母都转换成大写</td>
</tr>
<tr>
<td>trim</td>
<td>把值的首尾空格去掉</td>
</tr>
<tr>
<td>striptags</td>
<td>渲染之前把值中所有的 HTML 标签都删掉</td>
</tr>
<tr>
<td>join</td>
<td>拼接多个值为字符串</td>
</tr>
<tr>
<td>round</td>
<td>默认对数字进行四舍五入，也可以用参数进行控制</td>
</tr>
<tr>
<td>safe</td>
<td>渲染时值不转义</td>
</tr>
</tbody>
</table>
</div>
<p>那么如何使用这些过滤器呢？只需要在变量后面使用管道 (|) 分割，多个过滤器可以链式调用，前一个过滤器的输出会作为后一个过滤器的输入。</p>
<p>例如：<code>&lt;h1&gt;Hello, &#123;&#123; name|upper &#125;&#125;!&lt;/h1&gt;</code>   <code>&lt;li&gt;&#123;&#123; book|title &#125;&#125;&lt;/li&gt;</code></p>
<h4 id="5-3-控制结构"><a href="#5-3-控制结构" class="headerlink" title="5.3 控制结构"></a>5.3 控制结构</h4><p>jinja2中的if语句类似与Python的if语句，它也具有单分支，多分支等多种结构，不同的是，条件语句不需要使用冒号结尾，而结束控制语句，需要使用endif关键字</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&lt;p&gt;影视区&lt;/p&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% if age &gt;= <span class="number">18</span> %<span class="punctuation">&#125;</span></span><br><span class="line">&lt;ul&gt;</span><br><span class="line">    &lt;li&gt;成人影片&lt;/li&gt;</span><br><span class="line">    &lt;li&gt;成人游戏&lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% else %<span class="punctuation">&#125;</span></span><br><span class="line">&lt;ul&gt;</span><br><span class="line">    &lt;li&gt;儿童影片&lt;/li&gt;</span><br><span class="line">    &lt;li&gt;儿童游戏&lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% endif %<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>jinja2中的for循环用于迭代Python的数据类型，包括列表、元组和字典。在jinja2中不存在while循环。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>% for book in books %<span class="punctuation">&#125;</span></span><br><span class="line">&lt;li&gt;<span class="punctuation">&#123;</span><span class="punctuation">&#123;</span> book|title <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span>&lt;/li&gt;</span><br><span class="line"><span class="punctuation">&#123;</span>% endfor %<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="ORM操作"><a href="#ORM操作" class="headerlink" title="ORM操作"></a>ORM操作</h3><p>在大型的 Web 开发中，我们肯定会用到数据库操作，那么 FastAPI 也支持数据库的开发，你可以用 PostgreSQL、MySQL、SQLite、Oracle 等。本文用 SQLite 为例。我们看下在 FastAPI 是如何操作设计数据库的。</p>
<p>FastAPI 是一个很优秀的框架，但是缺少一个合适的 ORM，官方代码里面使用的是 SQLAlchemy，Tortoise ORM 是受 Django 启发的易于使用的异步 ORM（对象关系映射器）。</p>
<p>Tortoise ORM 目前支持以下数据库：</p>
<ul>
<li>PostgreSQL &gt;= 9.4（使用 asyncpg）</li>
<li>SQLite（使用 aiosqlite）</li>
<li>MySQL/MariaDB（使用 aiomysql 或使用 asyncmy）</li>
</ul>
<p>安装：<code>pip install tortoise-orm</code></p>
<h4 id="6-1-创建模型"><a href="#6-1-创建模型" class="headerlink" title="6.1 创建模型"></a>6.1 创建模型</h4><p><strong>1. 一对一关系（One-to-One）</strong></p>
<ul>
<li><strong>定义</strong> ：一张表中的一条记录仅关联另一张表中的一条记录。</li>
<li><strong>示例</strong> ：用户表（User）与身份证信息表（IDCard），一个用户仅对应一张身份证信息。</li>
</ul>
<p><strong>2. 一对多关系（One-to-Many）</strong></p>
<ul>
<li><strong>定义</strong> ：一张表中的一条记录关联另一张表中的多条记录。</li>
<li><strong>示例</strong> ：班级表（Class）与学生表（Student），一个班级包含多个学生，但每个学生只能属于一个班级。</li>
</ul>
<p><strong>3. 多对多关系（Many-to-Many）</strong></p>
<ul>
<li><strong>定义</strong> ：两张表中的记录可以互相关联多条记录，通常通过中间表实现。</li>
<li><strong>示例</strong> ：学生表（Student）与课程表（Course），一个学生可选修多门课程，一门课程也可被多个学生选修。</li>
</ul>
<p><strong>4. 自引用关系（Self-Referencing）</strong></p>
<ul>
<li><strong>定义</strong> ：表内的记录通过字段关联自身，形成层级或树状结构。</li>
<li><strong>示例</strong> ：员工表（Employee），每个员工可能有直属上级（另一个员工）。</li>
</ul>
<p><strong>5. 继承关系（Inheritance）</strong></p>
<ul>
<li><strong>定义</strong> ：基于面向对象的继承概念，子表继承父表的字段和约束。</li>
<li><strong>示例</strong> ：用户表（User）作为基表，管理员表（Admin）和普通用户表（RegularUser）继承其字段（如用户名、密码）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tortoise.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tortoise <span class="keyword">import</span> fields</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Model 是所有数据模型的基类，通过继承 Model 可定义数据库表的结构。每个 Model 子类对应一张数据库表，其类属性定义了表的字段（列）及其约束。</span></span><br><span class="line"><span class="string">fields 提供了多种字段类型，用于定义数据库表的列及其约束。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> = fields.IntField(pk=<span class="literal">True</span>)<span class="comment">#该字段会被指定为模型的主键</span></span><br><span class="line">    name = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;姓名&quot;</span>)</span><br><span class="line">    pwd = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;密码&quot;</span>)</span><br><span class="line">    sno = fields.IntField(description=<span class="string">&quot;学号&quot;</span>)</span><br><span class="line">    <span class="comment">#一对多关系</span></span><br><span class="line">    Class_id = fields.ForeignKeyField(</span><br><span class="line">        <span class="string">&quot;models.Class&quot;</span>,<span class="comment">#关联的模型类</span></span><br><span class="line">        related_name=<span class="string">&quot;students&quot;</span>,<span class="comment">#反向查询时的名称</span></span><br><span class="line">        on_delete=fields.CASCADE,<span class="comment">#级联删除</span></span><br><span class="line">        description=<span class="string">&quot;班级&quot;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#多对多关系</span></span><br><span class="line">    Course_id = fields.ManyToManyField(</span><br><span class="line">        <span class="string">&quot;models.Course&quot;</span>,<span class="comment">#关联的模型类</span></span><br><span class="line">        related_name=<span class="string">&quot;students&quot;</span>,<span class="comment">#反向查询时的名称</span></span><br><span class="line">        description=<span class="string">&quot;课程&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Course</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> = fields.IntField(pk=<span class="literal">True</span>)</span><br><span class="line">    name = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;课程名称&quot;</span>)</span><br><span class="line">    teacher = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;授课老师&quot;</span>)</span><br><span class="line">    <span class="comment">#一对多关系</span></span><br><span class="line">    teacher_id = fields.ForeignKeyField(</span><br><span class="line">        <span class="string">&quot;models.Teacher&quot;</span>,<span class="comment">#关联的模型类</span></span><br><span class="line">        related_name=<span class="string">&quot;courses&quot;</span>,<span class="comment">#反向查询时的名称</span></span><br><span class="line">        on_delete=fields.CASCADE,<span class="comment">#级联删除</span></span><br><span class="line">        description=<span class="string">&quot;老师&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Class</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> = fields.IntField(pk=<span class="literal">True</span>)</span><br><span class="line">    name= fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;班级名称&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Teacher</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="built_in">id</span> =fields.IntField(pk=<span class="literal">True</span>)</span><br><span class="line">    name = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;老师姓名&quot;</span>)</span><br><span class="line">    pwd = fields.CharField(max_length=<span class="number">50</span>,description=<span class="string">&quot;密码&quot;</span>)</span><br><span class="line">    sno = fields.IntField(description=<span class="string">&quot;工号&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>ORM（Object Relational Mapping，对象关系映射）是一种程序设计技术，主要用于实现<strong>面向对象编程语言</strong> 与<strong>关系型数据库</strong> 之间的数据转换。其核心思想是通过对象模型与数据库表结构的映射，将数据库操作转化为面向对象的操作，从而简化开发流程并提升代码的可维护性</p>
<p>Tortoise ORM 是一款专为 Python 异步环境设计的轻量级对象关系映射（ORM）框架，其设计灵感来源于 Django ORM，但专注于异步编程场景，适用于 FastAPI、Sanic 等基于 <code>asyncio</code> 的现代 Web 框架。</p>
<p>关系型数据库与非关系型数据库</p>
<p><strong>关系型数据库</strong><br>以表格形式存储数据，数据按行和列组织，列代表属性（字段），行代表记录。例如，用户表可能包含 <code>id</code>、<code>name</code>、<code>email</code> 等列，每行对应一个用户记录。这种结构化设计支持严格的模式约束（Schema）17。</p>
<p><strong>典型代表</strong> ：MySQL、Oracle、PostgreSQL。</p>
<p><strong>非关系型数据库（NoSQL）</strong><br>采用非结构化或半结构化存储，常见的类型包括：</p>
<ul>
<li><p><strong>文档型</strong> （如 MongoDB）：以 JSON 或 BSON 格式存储数据。</p>
</li>
<li><p><strong>键值型</strong> （如 Redis）：通过键直接访问值。</p>
</li>
<li><p><strong>列存储</strong> （如 Cassandra）：按列而非行组织数据。</p>
</li>
<li><p><strong>图数据库</strong> </p>
<p>（如 Neo4j）：以节点和边表示数据关系</p>
</li>
</ul>
</blockquote>
<h4 id="6-2-aerich迁移工具"><a href="#6-2-aerich迁移工具" class="headerlink" title="6.2 aerich迁移工具"></a>6.2 aerich迁移工具</h4><p><strong>docker 安装 mysql</strong>：</p>
<p>拉取 MySQL 镜像：<code>docker pull mysql</code></p>
<p>运行 MySQL 容器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run --name fastapi -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql</span><br></pre></td></tr></table></figure>
<blockquote>
<p>-p表示端口映射<br>—restart=always表示容器退出时总是重启<br>—name表示容器命名<br>—privileged=true表示赋予容器权限修改宿主文件权利<br>-v /home/mysql/log:/var/log/mysql表示容器日志挂载到宿主机<br>-v /home/mysql/data:/var/lib/mysql表示容器存储文件挂载到宿主机<br>-v /home/mysql/conf/my.cnf:/etc/mysql/my.cnf表示容器配置文件挂载到宿主机<br>-e MYSQL_ROOT_PASSWORD=a12bCd3_W45pUq6表示设置mysql的root用户密码,建议用强密码<br>-d表示后台运行</p>
</blockquote>
<p>启动这个 MySQL 容器：<code>docker start fastapi</code></p>
<p>进入 MySQL 容器：<code>docker exec -it fastapi bash</code></p>
<blockquote>
<p>这条命令的作用是：</p>
<ul>
<li><code>docker exec</code>：在已运行的 Docker 容器中执行命令。</li>
<li><code>-it</code>：<code>-i</code> 表示交互式操作，<code>-t</code> 分配一个伪终端（让你像在终端一样操作）。</li>
<li><code>fastapi</code>：这是你要进入的容器名称（你的 MySQL 容器名）。</li>
<li><code>bash</code>：在容器内启动 bash shell。</li>
</ul>
<p>这条命令会让你进入名为 <code>fastapi</code> 的容器，并获得一个 bash 命令行界面，就像登录到一台 Linux 服务器一样，可以在里面执行各种命令（比如登录 MySQL、查看日志等）。</p>
</blockquote>
<p>登录 MySQL：<code>mysql -u root -p</code></p>
<p>从主机直接连接：<code>mysql -h 127.0.0.1 -P 3306 -u root -p</code></p>
<h5 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TORTOISE_ORM = &#123;</span><br><span class="line">    &quot;connections&quot;: &#123;</span><br><span class="line">        &quot;default&quot;: &#123;</span><br><span class="line">            &quot;engine&quot;:&#x27;tortoise.backends.mysql&#x27;,#选择数据库引擎，mysql</span><br><span class="line">            &quot;credentials&quot;: &#123;</span><br><span class="line">                &quot;host&quot;: &quot;localhost&quot;,#数据库地址</span><br><span class="line">                &quot;port&quot;: 3306,#数据库端口</span><br><span class="line">                &quot;user&quot;: &quot;root&quot;,#数据库用户名</span><br><span class="line">                &quot;password&quot;: &quot;root&quot;,#数据库密码</span><br><span class="line">                &quot;database&quot;: &quot;fastapi_db&quot;,#数据库名称</span><br><span class="line">                &#x27;charset&#x27;: &quot;utf8mb4&quot;,#数据库编码</span><br><span class="line">                &#x27;echo&#x27;: True,#是否打印sql语句</span><br><span class="line">                &#x27;minsize&#x27;: 1,#连接池最小连接数</span><br><span class="line">                &#x27;maxsize&#x27;: 5#连接池最大连接数</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;apps&quot;: &#123;</span><br><span class="line">        &quot;models&quot;: &#123;</span><br><span class="line">            #db.models是我们自己定义的模型类,models在db文件夹下</span><br><span class="line">            &quot;models&quot;: [&quot;db.models&quot;,&quot;aerich.models&quot;],</span><br><span class="line">            &quot;default_connection&quot;: &quot;default&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;use_tz&#x27;: False,#是否使用时区</span><br><span class="line">    &#x27;timezone&#x27;: &#x27;Asia/Shanghai&#x27;,#时区</span><br><span class="line">    &quot;generate_schemas&quot;: True,</span><br><span class="line">    &quot;add_exception_handlers&quot;: True</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="1-初始化配置，只需要使用一次"><a href="#1-初始化配置，只需要使用一次" class="headerlink" title="1.初始化配置，只需要使用一次"></a>1.初始化配置，只需要使用一次</h5><p>aerich 是一种 ORM 迁移工具，需要结合 tortoise 异步 orm 框架使用。安装 aerich</p>
<p><code>pip install aerich</code></p>
<p><code>aerich init -t settings.TORTOISE_ORM  # TORTOISE_ORM 配置的位置</code></p>
<blockquote>
<p>初始化完会在当前目录生成一个文件：pyproject.toml 和一个文件夹：migrations</p>
<ul>
<li>pyproject.toml：保存配置文件路径，低版本可能是 aerich.ini</li>
<li>migrations：存放迁移文件</li>
</ul>
</blockquote>
<h5 id="2-初始化数据库，一般情况下只用一次"><a href="#2-初始化数据库，一般情况下只用一次" class="headerlink" title="2.初始化数据库，一般情况下只用一次"></a>2.初始化数据库，一般情况下只用一次</h5><p><code>aerich init-db</code></p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250521105044582.png" alt="image-20250521105044582"></p>
<h5 id="3-更新模型并进行迁移"><a href="#3-更新模型并进行迁移" class="headerlink" title="3.更新模型并进行迁移"></a>3.更新模型并进行迁移</h5><p>修改model类，重新生成迁移文件</p>
<p><code>aerich migrate</code></p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250521111024194.png" alt="image-20250521111024194"></p>
<h5 id="4-重新执行迁移，写入数据库"><a href="#4-重新执行迁移，写入数据库" class="headerlink" title="4.重新执行迁移，写入数据库"></a>4.重新执行迁移，写入数据库</h5><p><code>aerich upgrade</code></p>
<p><img src="/2025/05/14/%E5%AD%A6%E4%B9%A0/python-web/fastapi/fastapi/image-20250521111131931.png" alt="image-20250521111131931"></p>
<h5 id="5-回到上一个版本"><a href="#5-回到上一个版本" class="headerlink" title="5.回到上一个版本"></a>5.回到上一个版本</h5><p><code>aerich downgrade</code></p>
<h5 id="6-查看历史迁移记录"><a href="#6-查看历史迁移记录" class="headerlink" title="6.查看历史迁移记录"></a>6.查看历史迁移记录</h5><p><code>aerich history</code></p>
<blockquote>
<p><code>register_tortoise</code> 是 Tortoise ORM 提供的一个工具函数，用于在 <strong>FastAPI</strong> 等异步框架中快速集成和管理 Tortoise ORM 的生命周期（如启动时初始化数据库连接，关闭时释放资源）。其核心作用是简化 Tortoise ORM 的配置和自动化管理，开发者只需一行代码即可完成复杂的初始化流程</p>
</blockquote>
<h4 id="6-3-ORM查询操作"><a href="#6-3-ORM查询操作" class="headerlink" title="6.3 ORM查询操作"></a>6.3 ORM查询操作</h4><p>api.stud</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> APIRouter</span><br><span class="line"><span class="comment">#导入数据库</span></span><br><span class="line"><span class="keyword">from</span> db.models <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">student_api=APIRouter()</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.get(<span class="params"><span class="string">&quot;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_students</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    #查询所有学生信息</span></span><br><span class="line"><span class="string">    students= await Student.all()#获取所有学生信息</span></span><br><span class="line"><span class="string">    for student in students:</span></span><br><span class="line"><span class="string">        print(student.id,student.name)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #过滤查询filter</span></span><br><span class="line"><span class="string">    students= await Student.filter(name__contains=&quot;张&quot;).all()</span></span><br><span class="line"><span class="string">    for student in students:</span></span><br><span class="line"><span class="string">        print(student.id,student.name)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #get学生信息</span></span><br><span class="line"><span class="string">    stu = await Student.get(id=1)</span></span><br><span class="line"><span class="string">    print(stu.id,stu.name)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #模糊查询</span></span><br><span class="line"><span class="string">    #最大值</span></span><br><span class="line"><span class="string">    stu =await Student.filter(sno__gt=1000).all()</span></span><br><span class="line"><span class="string">    #最小值</span></span><br><span class="line"><span class="string">    #stu = await Student.filter(sno__lt=1000).all()</span></span><br><span class="line"><span class="string">    #范围查询</span></span><br><span class="line"><span class="string">    #stu = await Student.filter(sno__range=(1000,2000)).all()</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    #values查询</span></span><br><span class="line"><span class="string">    stu = await Student.all().values(&quot;sno&quot;,&quot;name&quot;)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">&quot;获取所有学生信息&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.post(<span class="params"><span class="string">&quot;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_student</span>():</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">&quot;创建学生信息&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.get(<span class="params"><span class="string">&quot;/&#123;student_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_student</span>(<span class="params">student_id:<span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">f&quot;获取学生信息，ID：<span class="subst">&#123;student_id&#125;</span>&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@student_api.put(<span class="params"><span class="string">&quot;/&#123;student_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">update_student</span>(<span class="params">student_id:<span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">return</span>&#123;</span><br><span class="line">        <span class="string">&quot;操作&quot;</span>:<span class="string">f&quot;更新学生信息，ID：<span class="subst">&#123;student_id&#125;</span>&quot;</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在 FastAPI 和 Tortoise ORM 中，<code>async</code> 和 <code>await</code> 用于<strong>异步编程</strong>，主要原因如下：</p>
<ol>
<li><strong>异步 I/O 操作</strong><br>数据库查询（如 Student.all()）是耗时的 I/O 操作。使用 <code>async</code>/<code>await</code> 可以在等待数据库响应时，不阻塞主线程，提高应用的并发性能。</li>
<li><strong>FastAPI 支持异步路由</strong><br>FastAPI 支持异步（<code>async def</code>）的路由函数，这样可以充分利用 Python 的异步特性，提升 Web 服务的吞吐量。</li>
<li><strong>Tortoise ORM 的方法是异步的</strong><br>Tortoise ORM 的数据库操作方法（如 <code>.all()</code>、<code>.create()</code> 等）本身就是异步方法，必须用 <code>await</code> 调用，并且所在函数必须用 <code>async def</code> 声明。</li>
</ol>
</blockquote>
<h3 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h3><h4 id="端口查询"><a href="#端口查询" class="headerlink" title="端口查询"></a>端口查询</h4><p>查看所有端口占用情况：<code>netstat -ano</code></p>
<p>查询特定端口是否被占用：<code>netstat -ano | findstr 8080</code></p>
<p>使用 <code>taskkill</code> 命令强制结束进程：<code>taskkill /PID 进程ID /F</code></p>
<p>通过 PID 查找进程：<code>tasklist | findstr PID</code></p>
<h4 id="获取绝对路径"><a href="#获取绝对路径" class="headerlink" title="获取绝对路径"></a>获取绝对路径</h4><p>获取当前文件的绝对路径：<code>base_dir = os.path.dirname(os.path.abspath(__file__))</code></p>
<p>拼接路径：<code>img_dir = os.path.join(base_dir, &quot;../imgs&quot;)</code></p>
<h4 id="mysql部分指令"><a href="#mysql部分指令" class="headerlink" title="mysql部分指令"></a>mysql部分指令</h4><p><strong>查看数据库列表</strong>：<code>SHOW DATABASES;</code></p>
<p><strong>选择数据库</strong>：<code>USE 数据库名;</code></p>
<p><strong>删除数据库</strong>：<code>DROP DATABASE 数据库名;</code></p>
<p><strong>创建数据库</strong>：<code>CREATE DATABASE 数据库名;</code></p>
<p><strong>登录 MySQL</strong>：<code>mysql -u root -p</code></p>
<p><strong>退出</strong>：<code>exit</code></p>
<h4 id="docker部分指令"><a href="#docker部分指令" class="headerlink" title="docker部分指令"></a>docker部分指令</h4><p><strong>linux安装docker</strong>：<code>sudo apt-get update &amp;&amp; sudo apt-get install docker.io</code></p>
<p><strong>查看 Docker 版本信息</strong>：<code>docker version</code></p>
<p><strong>查看镜像</strong>：<code>docker images</code></p>
<p><strong>查看所有的容器</strong>：<code>docker ps -a</code> </p>
<blockquote>
<p><code>systemctl</code> 是 <strong>systemd</strong> 系统和服务管理器的核心工具，用于管理系统和服务的状态及配置。</p>
</blockquote>
<p><code>mysql-client</code> 是 MySQL 数据库的命令行客户端工具。它允许你通过命令行连接和操作 MySQL 数据库服务器，比如执行 SQL 查询、管理数据库和用户等。</p>
<p>常用命令格式如下：<code>mysql -h 主机地址 -P 端口号 -u 用户名 -p</code></p>
<p>你可以在终端输入以下命令来检查是否已安装 <code>mysql-client</code>：<code>mysql --version</code></p>
<p>可以使用以下命令安装：<code>sudo apt-get update  sudo apt-get install mysql-client</code></p>
<blockquote>
<p><code>sudo apt-get update</code> 这个命令的作用是<strong>更新本地软件包列表</strong>。</p>
</blockquote>
<p><strong>停止并删除容器</strong>：<code>docker stop fastapi  docker rm fastapi</code></p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>fastapi一个项目<a href="https://www.bilibili.com/video/BV1TSVPzkE7Y?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">FastAPI进阶_哔哩哔哩_bilibili</a></p>
<p>教程<a href="https://www.bilibili.com/video/BV1Ya4y1D7et/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">fastapi框架快速学习_哔哩哔哩_bilibili</a></p>
<p>fastapi相关知识的补充<a href="https://www.bilibili.com/video/BV1zJ7mzdEc8?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">Python 异步编程 - 搞明白 async, await (继续解释 yield)_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>python-web</category>
        <category>fastapi</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title>数字逻辑电路——CMOS逻辑门电路</title>
    <url>/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/</url>
    <content><![CDATA[<h1 id="数字逻辑电路——CMOS逻辑门电路"><a href="#数字逻辑电路——CMOS逻辑门电路" class="headerlink" title="数字逻辑电路——CMOS逻辑门电路"></a>数字逻辑电路——CMOS逻辑门电路</h1><h2 id="MOS管"><a href="#MOS管" class="headerlink" title="MOS管"></a>MOS管</h2><p>MOSFET全称金属-氧化物-半导体场效应三极管</p>
<p>从载流子极性来看，分为<strong>NMOS（电子型）管</strong>和<strong>PMOS（空穴型）管</strong>两种</p>
<p>按照导电机制的不同，MOS管又可以分为<strong>增强型</strong>和<strong>耗尽型</strong></p>
<p>因此MOSFET共有四种：E型NMOS管、D型NMOS管、E型PMOS管、D型PMOS管</p>
<h3 id="NMOS和PMOS区别"><a href="#NMOS和PMOS区别" class="headerlink" title="NMOS和PMOS区别"></a>NMOS和PMOS区别</h3><p>MOS管的管脚有三个：<strong>源极S（source）、栅极G（Gate）和漏极（Drain）</strong></p>
<p>MOS管有两种：<strong>一个是PMOS管，一个是NMOS管</strong>；PMOS管就是positive管，是积极的管，而NMOS管是negative管，是消极的管。积极的管就是顺应潮流，顺势而为；消极的管就是违背趋势，逆流而上。<br>很显然，电流从源极（输入端）到漏极（输出端），那就是顺势而为，因为源极就是源头嘛，因此这种管就是PMOS管；而电流要是从漏极（输入端）到源极（输出端），那就是逆流而上，是NMOS管。</p>
<p>判定是N沟道MOS还是P沟道MOS：<br><strong>箭头指向G极的是N沟道<br>箭头背向G极的是P沟道</strong></p>
<p>从导通特性上区分：</p>
<p>NMOS：当电压高于阈值电压<strong>可以导通</strong>；当电压低于阈值电压<strong>不能导通</strong></p>
<p>PMOS：当电压高于阈值电压<strong>不能导通</strong>；当电压低于阈值电压<strong>可以导通</strong></p>
<p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/22e26add55da2a09c803a6ed67ee4777.png" alt="22e26add55da2a09c803a6ed67ee4777"></p>
<h3 id="增强型和耗尽型的区别"><a href="#增强型和耗尽型的区别" class="headerlink" title="增强型和耗尽型的区别"></a>增强型和耗尽型的区别</h3><p>以<strong>NMOS管</strong>为例：</p>
<p>当$\ V<em>{GS}=0$时没有导电沟道，需要依靠$\ V</em>{GS}$的作用才能产生导电沟道，称为<strong>增强型FET</strong>。</p>
<p>当$\ V<em>{GS}=0$时有导电沟道，需要依靠$\ V</em>{GS}$的作用是削弱导电沟道，称为<strong>耗尽型FET</strong>。</p>
<h2 id="CMOS逻辑门电路"><a href="#CMOS逻辑门电路" class="headerlink" title="CMOS逻辑门电路"></a>CMOS逻辑门电路</h2><p>由<code>N</code>沟道和<code>P</code>沟道增强型<code>MOS</code>管组成的电路称为互补<code>MOS</code>或<code>CMOS</code>电路。</p>
<h3 id="非门"><a href="#非门" class="headerlink" title="非门"></a>非门</h3><p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/57F[QXP6AT6LH8KOVH4CIQ.png" alt="img"></p>
<h3 id="或门和或非门"><a href="#或门和或非门" class="headerlink" title="或门和或非门"></a>或门和或非门</h3><p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/4.png" alt="4"></p>
<p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/G%WO3]UHOQB5{DKEJ571A7.png" alt="img"></p>
<h3 id="与门和与非门"><a href="#与门和与非门" class="headerlink" title="与门和与非门"></a>与门和与非门</h3><p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/5.png" alt="5"></p>
<p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/7.png" alt="7"></p>
<h3 id="异或门和同或门"><a href="#异或门和同或门" class="headerlink" title="异或门和同或门"></a>异或门和同或门</h3><p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/1.png" alt="1"></p>
<p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/CMOS%E9%80%BB%E8%BE%91%E9%97%A8%E7%94%B5%E8%B7%AF/2.png" alt="2"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.bilibili.com/video/BV1nL411x7jH?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">【硬核科普】带你认识CPU第00期——什么是MOSFET_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV18M4y137Cr?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;spm_id_from=333.788.videopod.sections">【硬核科普】带你认识CPU第01期——什么是逻辑门_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/weixin_43491077/article/details/109721185">NMOS管与PMOS管的区别与总结_pmos和nmos的区别-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数字逻辑电路</category>
      </categories>
      <tags>
        <tag>数字逻辑电路</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——中缀表达式</title>
    <url>/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E4%B8%AD%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="数据结构——中缀表达式"><a href="#数据结构——中缀表达式" class="headerlink" title="数据结构——中缀表达式"></a>数据结构——中缀表达式</h1><h2 id="利用中缀表达式直接求值"><a href="#利用中缀表达式直接求值" class="headerlink" title="利用中缀表达式直接求值"></a>利用中缀表达式直接求值</h2><p>要实现中缀表达式直接求值，必须设置两个栈，一个栈用于存放操作数，记作 <code>OPND</code>； 另一个栈用于存放操作符，记作 <code>OPTR</code>。</p>
<p>中缀表达式求值算法步骤如下：</p>
<ol>
<li>初始化：操作符栈中放置一个元素 <code>@</code>。</li>
<li>依次读取中缀表达式中的每一个字符，对于不同类型的字符按以下情况处理：<ol>
<li>若读到的是操作数，则压入操作数栈，并读取下一个字符。</li>
<li>若读到的是操作符 <code>c</code>，则将操作符栈的栈顶元素 <code>pre_op</code>与之进行比较，会出现以下 3 种情况：<ul>
<li>若 <code>pre_op &lt; c</code>，则将 <code>c</code> 入栈，并读取下一个字符。</li>
<li>若 <code>pre_op = c</code>，则将 <code>pre_op</code> 出栈，并读取下一个字符。</li>
<li>若 <code>pre_op &gt; c</code>，则将 <code>pre_op</code> 出栈，并在操作数栈中退栈 2 次，依次得到操作数 <code>b</code> 和 <code>a</code>，然后进行 <code>a pre_op b</code> 运算，将运算结果压入操作数栈。</li>
</ul>
</li>
</ol>
</li>
<li>扫描完毕时，操作数栈中只有一个元素，即计算结果。</li>
</ol>
<p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E4%B8%AD%E7%BC%80%E8%A1%A8%E8%BE%BE%E5%BC%8F/IMG_20241026_164151.jpg" alt="IMG_20241026_164151"></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//中缀表达式，实数</span></span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">Expression_Eval2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	SeqStack&lt;<span class="type">char</span>, <span class="number">100</span>&gt; OPTR;</span><br><span class="line">	SeqStack&lt;<span class="type">double</span>, <span class="number">100</span>&gt; OPND;</span><br><span class="line">	OPTR.<span class="built_in">Push</span>(<span class="string">&#x27;@&#x27;</span>);</span><br><span class="line">	<span class="type">char</span> ch = <span class="built_in">getchar</span>();</span><br><span class="line">	<span class="keyword">while</span> (ch != <span class="string">&#x27;@&#x27;</span> || OPTR.<span class="built_in">Top</span>() != <span class="string">&#x27;@&#x27;</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (<span class="built_in">isdigit</span>(ch) || ch == <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">// 处理多位数和小数</span></span><br><span class="line">			string number;</span><br><span class="line">			<span class="keyword">while</span> (<span class="built_in">isdigit</span>(ch) || ch == <span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">			&#123;</span><br><span class="line">				number += ch;</span><br><span class="line">				ch = <span class="built_in">getchar</span>();</span><br><span class="line">			&#125;</span><br><span class="line">			OPND.<span class="built_in">Push</span>(<span class="built_in">stod</span>(number));</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			<span class="type">char</span> pre_op = OPTR.<span class="built_in">Top</span>();</span><br><span class="line">			<span class="keyword">switch</span> (<span class="built_in">Precede</span>(pre_op, ch))</span><br><span class="line">			&#123;</span><br><span class="line">			<span class="keyword">case</span> <span class="string">&#x27;&lt;&#x27;</span>:</span><br><span class="line">				OPTR.<span class="built_in">Push</span>(ch);</span><br><span class="line">				ch = <span class="built_in">getchar</span>();</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			<span class="keyword">case</span> <span class="string">&#x27;=&#x27;</span>:</span><br><span class="line">				OPTR.<span class="built_in">Pop</span>();</span><br><span class="line">				ch = <span class="built_in">getchar</span>();</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			<span class="keyword">case</span> <span class="string">&#x27;&gt;&#x27;</span>:</span><br><span class="line">				<span class="type">char</span> pre_op = OPTR.<span class="built_in">Pop</span>();</span><br><span class="line">				<span class="type">double</span> b = OPND.<span class="built_in">Pop</span>();</span><br><span class="line">				<span class="type">double</span> a = OPND.<span class="built_in">Pop</span>();</span><br><span class="line">				OPND.<span class="built_in">Push</span>(<span class="built_in">Operate</span>(a, pre_op, b));</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">			</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> OPND.<span class="built_in">Top</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>Precede(pre_op, ch)</code>为进行算符优先级比较的函数</p>
<p><code>Operate(a, pre_op, b)</code>为计算函数 </p>
<h2 id="利用后缀表达式求值"><a href="#利用后缀表达式求值" class="headerlink" title="利用后缀表达式求值"></a>利用后缀表达式求值</h2><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>后缀是指把操作符放在两个操作数的后面。采用后缀表示的算术表达式被称为<strong>后缀表达式</strong>或<strong>后缀算</strong>。<br>在后缀表达式中，<strong>完全按照操作符出现的先后顺序进行计算过程，不存在括号，也不存在优先级的差别</strong>。</p>
<p>将中缀表达式转换成等价的后缀表达式求值时，不需要再考虑操作符的优先级，只需从左到右扫描一边后缀表达式即可。只需设置一个OPND栈用于存放操作数</p>
<h3 id="先将中缀表达式转成后缀表达式"><a href="#先将中缀表达式转成后缀表达式" class="headerlink" title="先将中缀表达式转成后缀表达式"></a>先将中缀表达式转成后缀表达式</h3><p>把中缀表达式转换为后缀表达式算法的基本思路如下：</p>
<ol>
<li><p>初始化：操作符栈中放置一个元素 <code>@</code>。</p>
</li>
<li><p>依次读入中缀表达式中的每个字符</p>
<p>，对于不同类型的字符按不同情况进行处理：</p>
<ol>
<li>若读到的是操作数，则输出该操作数，并读取下一个字符。</li>
<li>若读到的是左括号 <code>(</code>，则把它压入 <code>OPTR</code> 栈中，并读取下一个字符。</li>
<li>若读到的是右括号 <code>)</code>，则表明括号内的中缀表达式已经扫描完毕，将 <code>OPTR</code> 栈从栈顶直到左括号之前的操作符依次出栈并输出，然后将左括号出栈，并读取下一个字符。</li>
<li>若读到的是操作符 <code>c</code>，则将操作符栈的栈顶元素 <code>pre_op</code>与之进行比较：<ul>
<li>若 <code>pre_op &lt; c</code>，则将 <code>c</code> 入栈，并读取下一个字符。</li>
<li>若 <code>pre_op &gt;= c</code>，则将 <code>pre_op</code> 出栈并输出。</li>
</ul>
</li>
<li>若读到的是结束符 <code>@</code>，则把栈中剩余的操作符依次出栈并输出，即可得到转换成的后缀表达式。</li>
</ol>
</li>
</ol>
<h2 id="后缀表达式求值"><a href="#后缀表达式求值" class="headerlink" title="后缀表达式求值"></a>后缀表达式求值</h2><p>后缀表达式求值算法的基本思路如下</p>
<ol>
<li><p>依次读入后缀表达式中的每个字符</p>
<p>，直至表达式结束。</p>
<ul>
<li>若读到的是操作数，则入 <code>OPND</code> 栈。</li>
<li>若读到的是操作符，则在 <code>OPND</code> 栈中退栈两个元素（先退出的是操作符右侧，后退出的是操作符左侧），然后用该操作符进行运算，并将运算结果压入 <code>OPND</code> 栈中。</li>
</ul>
</li>
<li><p><strong>后缀表达式扫描完毕时</strong>，若 <code>OPND</code> 栈中仅有一个元素，即为运算结果。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数字逻辑电路——数电实验1</title>
    <url>/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/</url>
    <content><![CDATA[<h1 id="实验1-门电路逻辑功能测试"><a href="#实验1-门电路逻辑功能测试" class="headerlink" title="实验1  门电路逻辑功能测试"></a>实验1  门电路逻辑功能测试</h1><h2 id="内容一：与非门和异或门逻辑功能的测试"><a href="#内容一：与非门和异或门逻辑功能的测试" class="headerlink" title="内容一：与非门和异或门逻辑功能的测试"></a>内容一：与非门和异或门逻辑功能的测试</h2><h3 id="74LS20双4输入与非门逻辑功能测试"><a href="#74LS20双4输入与非门逻辑功能测试" class="headerlink" title="74LS20双4输入与非门逻辑功能测试"></a>74LS20双4输入与非门逻辑功能测试</h3><p>74LS20功能：<strong>四输入双与非门</strong>，其内部结构及真值表如图</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/1ac35b0a8f06411f05cc80a49ec9c700.png" alt="1ac35b0a8f06411f05cc80a49ec9c700"></p>
<p>电路图如下</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/1.png" alt="1"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">A</th>
<th style="text-align:center">B</th>
<th style="text-align:center">C</th>
<th style="text-align:center">D</th>
<th style="text-align:center">Y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
</div>
<p>全1出0，有0出1</p>
<h3 id="74LS86四2输入异或门逻辑功能测试"><a href="#74LS86四2输入异或门逻辑功能测试" class="headerlink" title="74LS86四2输入异或门逻辑功能测试"></a>74LS86四2输入异或门逻辑功能测试</h3><p>74LS86功能：<strong>二输入端四异或门</strong>，其内部结构及真值表如图</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/a74b68814db1d802db338a7b636a523e.png" alt="a74b68814db1d802db338a7b636a523e"></p>
<p>电路图如下</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/6-1730557274344-12.png" alt="6"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">A</th>
<th style="text-align:center">B</th>
<th style="text-align:center">Y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
</div>
<h2 id="内容二：根据电路图写出逻辑关系表达式"><a href="#内容二：根据电路图写出逻辑关系表达式" class="headerlink" title="内容二：根据电路图写出逻辑关系表达式"></a>内容二：根据电路图写出逻辑关系表达式</h2><h3 id="用74LS00按图接线，将输入输出逻辑关系分别填入表中。"><a href="#用74LS00按图接线，将输入输出逻辑关系分别填入表中。" class="headerlink" title="用74LS00按图接线，将输入输出逻辑关系分别填入表中。"></a>用74LS00按图接线，将输入输出逻辑关系分别填入表中。</h3><p>74LS00功能：<strong>二输入端四与非门</strong>，其内部结构及真值表如图</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/4.png" alt="4"></p>
<p>题目如下</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/564.png" alt="564"></p>
<p>电路图如下</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/44.png" alt="44"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">A</th>
<th style="text-align:center">B</th>
<th style="text-align:center">Y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
</tbody>
</table>
</div>
<p>电路图如下</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/546.png" alt="546"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">A</th>
<th style="text-align:center">B</th>
<th style="text-align:center">Y</th>
<th style="text-align:center">Z</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
</div>
<h3 id="写出两个电路逻辑表达式"><a href="#写出两个电路逻辑表达式" class="headerlink" title="写出两个电路逻辑表达式"></a>写出两个电路逻辑表达式</h3><p>电路逻辑表达式为$\ \bar{A}B+\bar{B}A$</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/DSFDSG.png" alt="DSFDSG"></p>
<p>电路逻辑表达式为$\ Y=\bar{A}B+\bar{B}A$    $\ Z=AB$</p>
<h2 id="内容三：利用与非门控制输出"><a href="#内容三：利用与非门控制输出" class="headerlink" title="内容三：利用与非门控制输出"></a>内容三：利用与非门控制输出</h2><h3 id="用一片74LS00按图接线，S接任一电平开关，用示波器观察S对输出脉冲的控制作用"><a href="#用一片74LS00按图接线，S接任一电平开关，用示波器观察S对输出脉冲的控制作用" class="headerlink" title="用一片74LS00按图接线，S接任一电平开关，用示波器观察S对输出脉冲的控制作用"></a>用一片74LS00按图接线，S接任一电平开关，用示波器观察S对输出脉冲的控制作用</h3><h3 id="第一题"><a href="#第一题" class="headerlink" title="第一题"></a>第一题</h3><p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/4552.png" alt="4552"></p>
<p>电路图如下</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/456.png" alt="456"></p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/284.png" alt="284"></p>
<h3 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h3><p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/SAD.png" alt="SAD"></p>
<p>电路图如下</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/VX.png" alt="VX"></p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/GS.png" alt="GS"></p>
<h2 id="内容四：用与非门组成其它门电路并测试验证"><a href="#内容四：用与非门组成其它门电路并测试验证" class="headerlink" title="内容四：用与非门组成其它门电路并测试验证"></a>内容四：用与非门组成其它门电路并测试验证</h2><h3 id="第一题：组成或非门"><a href="#第一题：组成或非门" class="headerlink" title="第一题：组成或非门"></a>第一题：组成或非门</h3><p>用一片2输入端四与非门组成或非门</p>
<p>电路图如下</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/dsaf.png" alt="dsaf"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">A</th>
<th style="text-align:center">B</th>
<th style="text-align:center">Y</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
</div>
<h3 id="第二题：组成异或门"><a href="#第二题：组成异或门" class="headerlink" title="第二题：组成异或门"></a>第二题：组成异或门</h3><p>同内容二</p>
<h2 id="内容五：逻辑门传输延迟时间的测量"><a href="#内容五：逻辑门传输延迟时间的测量" class="headerlink" title="内容五：逻辑门传输延迟时间的测量"></a>内容五：逻辑门传输延迟时间的测量</h2><p>用六反相器（非门）按图接线，输入200KHz连续脉冲，用双踪示波器测量输入、输出相位差，计算每个门的平均传输延迟时间的值。</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/asdfa.png" alt="asdfa"></p>
<p>74LS04功能：<strong>六反相器</strong>，其内部结构及真值表如图</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/sad-1730613828885-37.png" alt="sad"></p>
<p>电路图如下</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/sads.png" alt="sads"></p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/afdga.png" alt="afdga"></p>
<h2 id="内容六：用基本门电路组装一个译码电路：将BCD8421码转换成格雷码"><a href="#内容六：用基本门电路组装一个译码电路：将BCD8421码转换成格雷码" class="headerlink" title="内容六：用基本门电路组装一个译码电路：将BCD8421码转换成格雷码"></a>内容六：用基本门电路组装一个译码电路：将BCD8421码转换成格雷码</h2><p>BCD8421码：二进制编码的十进制数，简称BCD码</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/t0131751fc49c1edcb4.png" alt="t0131751fc49c1edcb4"></p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/63d335349be6acd1189581d69870bd56.png" alt="63d335349be6acd1189581d69870bd56"></p>
<p>一位不产生进位的加法电路用<a href="https://so.csdn.net/so/search?q=异或门&amp;spm=1001.2101.3001.7020">异或门</a>就可以实现，下图左边为一个二进制-格雷码转换器器，右边为一个格雷码-二进制码转换器。</p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/353484a62261823731307a1969c8278e.png" alt="353484a62261823731307a1969c8278e"></p>
<p><img src="/2024/11/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF/%E6%95%B0%E7%94%B5%E5%AE%9E%E9%AA%8C1/sadsfdf.png" alt="sadsfdf"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://blog.csdn.net/qq_41628475/article/details/136149964">数字电路逻辑与设计实验一 门电路逻辑功能及测试_数电实验-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数字逻辑电路</category>
      </categories>
      <tags>
        <tag>数字逻辑电路</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——图</title>
    <url>/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/</url>
    <content><![CDATA[<h2 id="图的基本概念和术语"><a href="#图的基本概念和术语" class="headerlink" title="图的基本概念和术语"></a>图的基本概念和术语</h2><p>定义：一个图可以利用两个集合进行定义。第一个集合是点的集合,这些点在图术语中一般被称(Vertex);第二个集合是连接两个顶点的边(Edge)的集合。图的具体定义如下。 图是由顶点集合及顶点间的关系集合组成的一种数据结构:Graph = (V, E)</p>
<p>基本术语</p>
<ol>
<li><p>有向图</p>
</li>
<li><p>无向图</p>
</li>
<li><p>邻接点</p>
</li>
<li><p>顶点的度，入度与出度</p>
</li>
<li><p>权和网：</p>
<ul>
<li><strong>权 ：</strong> 某些图的每条边都可能赋予一个数值，这个数值称为权。</li>
<li><strong>网 ：</strong> 带有权的图称为网。</li>
</ul>
</li>
<li><p><strong>无向完全图：</strong> 任意两个顶点之间都有一条边的无向图。</p>
<p><strong>有向完全图：</strong> 任意两个顶点之间都有方向相反的两条边的有向图。</p>
</li>
</ol>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202190122603.png" alt="image-20241202190122603"></p>
<ol>
<li><p>路径与路径长度</p>
</li>
<li><p><strong>简单路径</strong>：若路径上经过的各顶点均不重复，则称这样的路径为简单路径。</p>
<p><strong>回路或环</strong>：若路径上的第一个顶点与最后一个顶点相同，则称这样的路径为回路或环。</p>
</li>
</ol>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202190704319.png" alt="image-20241202190704319"></p>
<ol>
<li><p><strong>连通图：</strong> 在无向图中，若任意两个顶点之间都存在路径，则称该图为连通图。</p>
<p><strong>连通分量：</strong> 非连通图的极大连通子图称为连通分量。也就是说，一个连通分量是一个连通的子图，且不能再扩大。</p>
</li>
<li><p><strong>强连通图：</strong> 在有向图中，若对于任意一对顶点 u 和 v，都存在一条从 u 到 v 和从 v 到 u 的路径，则称该图为强连通图。</p>
<p><strong>强连通分量：</strong> 非强连通图的极大强连通子图称为强连通分量。</p>
</li>
<li><p><strong>生成树：</strong> 一个连通图的生成树是包含图中所有顶点的极小连通子图。也就是说，生成树是一棵树，且包含图中的所有顶点。</p>
<p><strong>生成森林：</strong> 非连通图的每个连通分量分别可以得到一棵生成树，这些生成树的集合称为生成森林。</p>
</li>
</ol>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202191533963.png" alt="image-20241202191533963"></p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202191543162.png" alt="image-20241202191543162"></p>
<h2 id="图的储存结构"><a href="#图的储存结构" class="headerlink" title="图的储存结构"></a>图的储存结构</h2><h3 id="邻接矩阵"><a href="#邻接矩阵" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h3><p>邻接矩阵表示法的基本思想是引入两个数组：</p>
<ul>
<li>一个用于记录图中各个顶点信息的—维数组，称为顶点表；</li>
<li>另一个用于表示图中各个顶点之间关系的二维数组，称为邻接矩阵。</li>
</ul>
<p>设图G=(V, E)是具有n(n&gt;0)个顶点的图，则图G所对应的邻接矩阵A是一个n阶方阵</p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202192441396.png" alt="image-20241202192441396"></p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202192456777.png" alt="image-20241202192456777"></p>
<p>无向图的邻接矩阵可采用只存储上三角阵或下三角阵的压缩存储方法</p>
<hr>
<p>对于带权图，需要对邻接矩阵的元素值定义进行修改，让元素值表示相应顶点的权值</p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202192636345.png" alt="image-20241202192636345"></p>
<p>其中，∞可用计算机中的一个足够大的数代替，以与权重区分</p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241202193146935.png" alt="image-20241202193146935"></p>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>图类MGraph的定义</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 图的类型定义: 无向图、无向网、有向图、有向网</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">GraphType</span> &#123; undigraph, digraph, undinetwork, dinetwork &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeType</span> &#123; <span class="comment">// 本类型定义也适用于后面的邻接表结构</span></span><br><span class="line">    T head, tail;</span><br><span class="line">    <span class="type">int</span> cost;</span><br><span class="line">    <span class="built_in">EdgeType</span>(T h, T t, <span class="type">int</span> c) &#123;</span><br><span class="line">        head = h;</span><br><span class="line">        tail = t;</span><br><span class="line">        cost = c;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MGraph</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> vexnum, edgenum;</span><br><span class="line">    GraphType kind;</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; edges; <span class="comment">// 邻接矩阵</span></span><br><span class="line">    vector&lt;T&gt; vexs;            <span class="comment">// 顶点表</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>无向有权图的邻接矩阵构建</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">createAdjMatrix</span><span class="params">(vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; adjMatrix, <span class="type">const</span> vector&lt;tuple&lt;<span class="type">int</span>, <span class="type">int</span>, <span class="type">int</span>&gt;&gt;&amp; edges, <span class="type">int</span> numVertices)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化邻接矩阵为无穷大</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numVertices; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; numVertices; ++j) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i != j) adjMatrix[i][j] = INT_MAX; <span class="comment">// 没有边的地方设置为无穷大，当i=j的值为0</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 填充边的信息</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; edge : edges) &#123;</span><br><span class="line">        <span class="type">int</span> u = <span class="built_in">get</span>&lt;<span class="number">0</span>&gt;(edge);  <span class="comment">// 获取第一个元素</span></span><br><span class="line">        <span class="type">int</span> v = <span class="built_in">get</span>&lt;<span class="number">1</span>&gt;(edge);  <span class="comment">// 获取第二个元素</span></span><br><span class="line">        <span class="type">int</span> weight = <span class="built_in">get</span>&lt;<span class="number">2</span>&gt;(edge);  <span class="comment">// 获取第三个元素</span></span><br><span class="line">        adjMatrix[u][v] = weight;</span><br><span class="line">        adjMatrix[v][u] = weight;  <span class="comment">// 无向图</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="邻接表"><a href="#邻接表" class="headerlink" title="邻接表"></a>邻接表</h3><p>当一个图为稀疏图时（边数相对顶点较少），使用邻接矩阵法显然要浪费大量的存储空间，如下图所示：</p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/dc28a71607451fd5adeb57fadf14659b.png" alt="dc28a71607451fd5adeb57fadf14659b"></p>
<p>邻接表中存在两种结点:顶点表结点和边表结点，如下图所示。</p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/5257342f8b24df2a6af18a35e74af60b.png" alt="5257342f8b24df2a6af18a35e74af60b"></p>
<p>顶点表结点由顶点域(data)和指向第一条邻接边的指针(firstarc) 构成，边表(邻接表)结点由邻接点域(adjvex)和指向下一条邻接边的指针域(nextarc) 构成。</p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241205203225293.png" alt="image-20241205203225293"></p>
<h4 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h4><p>基于邻接表存储表示的图类ALGraph定义</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 边节点</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">EdgeNode</span> &#123;</span><br><span class="line">    <span class="type">int</span> adjvex;  <span class="comment">// 邻接点下标</span></span><br><span class="line">    EdgeNode* next; <span class="comment">// 指向下一个邻接点</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 顶点节点</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">VexNode</span> &#123;</span><br><span class="line">    T data;</span><br><span class="line">    EdgeNode* firstEdge;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 图的邻接表表示</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ALGraph</span> &#123;</span><br><span class="line">    vector&lt;VexNode&lt;T&gt;&gt; vex;  <span class="comment">// 顶点数组</span></span><br><span class="line">    <span class="type">int</span> vexnum, edgenum;  <span class="comment">// 顶点数和边数</span></span><br><span class="line">	GraphType kind;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>无向图的构建</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">ALGraph&lt;T&gt;::<span class="built_in">ALGraph</span>(GraphType t, T vexs[], <span class="type">int</span> n, <span class="type">int</span> e) &#123;</span><br><span class="line">    <span class="comment">// 参数表示图的类型, 参数vexs为存储各顶点值的数组, 参数n和e分别为顶点数和边数</span></span><br><span class="line">    vexnum = n;</span><br><span class="line">    edgenum = e;</span><br><span class="line">    kind = t;</span><br><span class="line">    adjlist.<span class="built_in">resize</span>(vexnum);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化顶点表</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; ++i) &#123;</span><br><span class="line">        adjlist[i].data = vexs[i];</span><br><span class="line">        adjlist[i].firstEdge = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 依次输入所有的边的信息</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; edgenum; j++) &#123;</span><br><span class="line">        <span class="type">int</span> va, vb;</span><br><span class="line">        cin &gt;&gt; va &gt;&gt; vb;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 产生第一个表结点</span></span><br><span class="line">        EdgeNode* p = <span class="keyword">new</span> EdgeNode;</span><br><span class="line">        p-&gt;adjvex = vb;</span><br><span class="line">        p-&gt;nextedge = adjlist[va].firstEdge;</span><br><span class="line">        adjlist[va].firstEdge = p;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 产生第二个表结点</span></span><br><span class="line">        p = <span class="keyword">new</span> EdgeNode;</span><br><span class="line">        p-&gt;adjvex = va;</span><br><span class="line">        p-&gt;nextedge = adjlist[vb].firstEdge;</span><br><span class="line">        adjlist[vb].firstEdge = p;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="图的遍历"><a href="#图的遍历" class="headerlink" title="图的遍历"></a>图的遍历</h2><p>为了防止已经访问过的结点重复访问的问题，提出了辅助数组 <code>visited[]</code></p>
<h3 id="深度优先遍历"><a href="#深度优先遍历" class="headerlink" title="深度优先遍历"></a>深度优先遍历</h3><p><strong>深度优先搜索类似于树的先序遍历。</strong></p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241205210048064.png" alt="image-20241205210048064"></p>
<p>算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> visited[MAX_VERTEX_NUM];	<span class="comment">//访问标记数组</span></span><br><span class="line"><span class="comment">/*从顶点出发，深度优先遍历图G*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFS</span><span class="params">(Graph G, <span class="type">int</span> v)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> w;</span><br><span class="line">	<span class="built_in">visit</span>(v);	<span class="comment">//访问顶点</span></span><br><span class="line">	visited[v] = TRUE;	<span class="comment">//设已访问标记</span></span><br><span class="line">	<span class="comment">//FirstNeighbor(G,v):求图G中顶点v的第一个邻接点，若有则返回顶点号，否则返回-1。</span></span><br><span class="line">	<span class="comment">//NextNeighbor(G,v,w):假设图G中顶点w是顶点v的一个邻接点，返回除w外顶点v</span></span><br><span class="line">	<span class="keyword">for</span>(w = <span class="built_in">FirstNeighbor</span>(G, v); w&gt;=<span class="number">0</span>; w=<span class="built_in">NextNeighor</span>(G, v, w))&#123;</span><br><span class="line">		<span class="keyword">if</span>(!visited[w])&#123;	<span class="comment">//w为u的尚未访问的邻接顶点</span></span><br><span class="line">			<span class="built_in">DFS</span>(G, w);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*对图进行深度优先遍历*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFSTraverse</span><span class="params">(MGraph G)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> v; </span><br><span class="line">	<span class="keyword">for</span>(v=<span class="number">0</span>; v&lt;G.vexnum; ++v)&#123;</span><br><span class="line">		visited[v] = FALSE;	<span class="comment">//初始化已访问标记数据</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span>(v=<span class="number">0</span>; v&lt;G.vexnum; ++v)&#123;	<span class="comment">//从v=0开始遍历</span></span><br><span class="line">		<span class="keyword">if</span>(!visited[v])&#123;</span><br><span class="line">			<span class="built_in">DFS</span>(G, v);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>DFS算法是一个递归算法，需要借助一个递归工作栈，故其空间复杂度为O(V)。</p>
<p>对于n个顶点e条边的图来说，邻接矩阵由于是二维数组，要查找每个顶点的邻接点需要访问矩阵中的所有元素，因此都需要O(V^2)的时间。而邻接表做存储结构时，找邻接点所需的时间取决于顶点和边的数量，所以是O(V＋E)。</p>
<h3 id="广度优先遍历"><a href="#广度优先遍历" class="headerlink" title="广度优先遍历"></a>广度优先遍历</h3><p><strong>图的广度优先遍历就类似于树的层序遍历</strong></p>
<p>算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*邻接矩阵的广度遍历算法*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFSTraverse</span><span class="params">(MGraph G)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> i, j;</span><br><span class="line">	Queue Q;</span><br><span class="line">	<span class="keyword">for</span>(i = <span class="number">0</span>; i&lt;G,numVertexes; i++)&#123;</span><br><span class="line">		visited[i] = FALSE;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">InitQueue</span>(&amp;Q);	<span class="comment">//初始化一辅助用的队列</span></span><br><span class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;G.numVertexes; i++)&#123;</span><br><span class="line">		<span class="comment">//若是未访问过就处理</span></span><br><span class="line">		<span class="keyword">if</span>(!visited[i])&#123;</span><br><span class="line">			vivited[i] = TRUE;	<span class="comment">//设置当前访问过</span></span><br><span class="line">			<span class="built_in">visit</span>(i);	<span class="comment">//访问顶点</span></span><br><span class="line">			<span class="built_in">EnQueue</span>(&amp;Q, i);	<span class="comment">//将此顶点入队列</span></span><br><span class="line">			<span class="comment">//若当前队列不为空</span></span><br><span class="line">			<span class="keyword">while</span>(!<span class="built_in">QueueEmpty</span>(Q))&#123;</span><br><span class="line">				<span class="built_in">DeQueue</span>(&amp;Q, &amp;i);	<span class="comment">//顶点i出队列</span></span><br><span class="line">				<span class="comment">//FirstNeighbor(G,v):求图G中顶点v的第一个邻接点，若有则返回顶点号，否则返回-1。</span></span><br><span class="line">				<span class="comment">//NextNeighbor(G,v,w):假设图G中顶点w是顶点v的一个邻接点，返回除w外顶点v</span></span><br><span class="line">				<span class="keyword">for</span>(j=<span class="built_in">FirstNeighbor</span>(G, i); j&gt;=<span class="number">0</span>; j=<span class="built_in">NextNeighbor</span>(G, i, j))&#123;</span><br><span class="line">					<span class="comment">//检验i的所有邻接点</span></span><br><span class="line">					<span class="keyword">if</span>(!visited[j])&#123;</span><br><span class="line">						<span class="built_in">visit</span>(j);	<span class="comment">//访问顶点j</span></span><br><span class="line">						visited[j] = TRUE;	<span class="comment">//访问标记</span></span><br><span class="line">						<span class="built_in">EnQueue</span>(Q, j);	<span class="comment">//顶点j入队列</span></span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>无论是邻接表还是邻接矩阵的存储方式，BFS算法都需要借助一个辅助队列Q, n个顶点均需入队一次，在最坏的情况下，空间复杂度为O(V)。<br>采用邻接表存储方式时，每个顶点均需搜索一次(或入队一次)，在搜索任一顶点的邻接点时，每条边至少访问一次，算法总的时间复杂度为O(V＋E)。采用邻接矩阵存储方式时，查找每个顶点的邻接点所需的时间为O(V)，故算法总的时间复杂度为O(V^2)。</p>
<blockquote>
<p>注意:图的邻接矩阵表示是唯一的，但对于邻接表来说，若边的输入次序不同，生成的邻接表也不同。因此，对于同样一个图，基于邻接矩阵的遍历所得到的DFS序列和BFS序列是唯一的，基于邻接表的遍历所得到的DFS序列和BFS序列是不唯一的。</p>
</blockquote>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>简单路径的搜索算法 dfs</p>
<p>二部图的判定算法</p>
<h2 id="最小生成树"><a href="#最小生成树" class="headerlink" title="最小生成树"></a>最小生成树</h2><p>生成树变成非连通图;若给它增加一条边，则会形成图中的一条回路。对于一个带权连通无向图G=(V,E)，生成树不同，其中边的权值之和最小的那棵生成树（构造连通网的最小代价生成树)，称为G的<strong>最小生成树(Minimum-Spanning-Tree,MST)</strong>。</p>
<h3 id="普里姆（Prim）算法"><a href="#普里姆（Prim）算法" class="headerlink" title="普里姆（Prim）算法"></a>普里姆（Prim）算法</h3><p><strong>从一个顶点出发，在保证不形成回路的前提下，每找到并添加一条最短的边，就把当前形成的连通分量当做一个整体或者一个点看待，然后重复“找最短的边并添加”的操作。</strong></p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/d0daac1cd8df11a443697ee6bc3fcf03.png" alt="d0daac1cd8df11a443697ee6bc3fcf03"></p>
<p>引入辅助数组<code>miniedges[]</code>，用于存放每个节点到节点v的边的权值，并每次挑选出权值最小的那个边所对应的节点加入生成树，辅助数组<code>miniedges[]</code>的数据类型如下</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Edge</span> &#123;</span><br><span class="line">    <span class="type">int</span> adjvex;  <span class="comment">// 与当前生成树连接的节点的编号</span></span><br><span class="line">    <span class="type">int</span> lowcost; <span class="comment">// 到当前生成树的最小边权值</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>若将某个数组元素<code>miniedges[i]</code>的 lowcost成员值设为0，则表示相应的顶点v,已加入到最小生成树中。</p>
<p>为便于算法在执行过程中读取任意两个顶点之间边的权值，对图宜采用<strong>邻接矩阵存储结构</strong>。</p>
<p>算法思路：</p>
<ol>
<li><p>初始化辅助数组，从节点v开始，将v的lowcost设为0，说明已经加入生成树</p>
</li>
<li><p>循环vexnum-1次，利用函数<code>MiniNum</code>找到权值最小的节点并输出</p>
<p>函数<code>MiniNum</code>循环vexnum次，找到当前所有节点中，<strong>未加入生成树的</strong>，lowcost最小的节点</p>
</li>
<li><p>更新辅助数组<code>miniedges[]</code>的每个节点的lowcost：循环vexnum次，如果通过当前节点k能找到比原先更小的边，更新该节点的lowcost；如果大，则保留原lowcost的值，更新后代表生成树节点的集合到未加入节点的集合的权值最小的vexnum条边</p>
</li>
</ol>
<p>时间复杂度：O(n^2)</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Prim</span><span class="params">(<span class="type">const</span> vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; graph, <span class="type">int</span> v, <span class="type">int</span> vexnum)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化 miniedges 数组</span></span><br><span class="line">    Edge* miniedges = <span class="keyword">new</span> Edge[vexnum];</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化 miniedges，每个节点到起始点v的边的权值</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        miniedges[i].adjvex = <span class="built_in">GetVexValue</span>(v);        <span class="comment">// 初始时节点的连接为起始节点v</span></span><br><span class="line">        miniedges[i].lowcost = <span class="built_in">GetEdgeValue</span>(graph, v, i);   <span class="comment">// 初始化每个节点到v的边权值</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    miniedges[v].lowcost = <span class="number">0</span>; <span class="comment">// 将起始节点v的lowcost设为0，表示已经加入生成树</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 循环执行，每次选取一个未加入生成树的权值最小的节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        <span class="comment">// 找到最小的lowcost</span></span><br><span class="line">        <span class="type">int</span> k = <span class="built_in">MiniNum</span>(miniedges, vexnum);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 输出当前加入生成树的边</span></span><br><span class="line">        cout &lt;&lt; miniedges[k].adjvex &lt;&lt; <span class="string">&quot; --&gt; &quot;</span> &lt;&lt; <span class="built_in">GetVexValue</span>(k) &lt;&lt; endl;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将选中的节点k加入生成树</span></span><br><span class="line">        miniedges[k].lowcost = <span class="number">0</span>; <span class="comment">// 表示节点k已加入生成树</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 更新与当前生成树连接的节点的lowcost（最小边权值）</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; vexnum; j++) &#123;</span><br><span class="line">            <span class="comment">// 如果通过当前节点k能找到比原先更小的边，更新该节点的lowcost</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">GetEdgeValue</span>(graph, k, j) &lt; miniedges[j].lowcost) &#123;</span><br><span class="line">                miniedges[j].adjvex = <span class="built_in">GetVexValue</span>(k);   <span class="comment">// 记录当前节点k</span></span><br><span class="line">                miniedges[j].lowcost = <span class="built_in">GetEdgeValue</span>(graph, k, j); <span class="comment">// 更新到生成树的最小边权值</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放动态分配的内存</span></span><br><span class="line">    <span class="keyword">delete</span>[] miniedges;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>函数<code>MiniNum</code>用于在数组miniedges中查找集合V-U中的具有最小权值的顶点,可以将它定义为私有成员函数</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 找到当前所有节点中，未加入生成树的，lowcost最小的节点</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">MiniNum</span><span class="params">(Edge miniedges[], <span class="type">int</span> vexnum)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> min = INT_MAX;</span><br><span class="line">    <span class="type">int</span> k = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (miniedges[i].lowcost != <span class="number">0</span> &amp;&amp; miniedges[i].lowcost &lt; min) &#123; <span class="comment">// 如果该节点未加入生成树</span></span><br><span class="line">            min = miniedges[i].lowcost;</span><br><span class="line">            k = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> k; <span class="comment">// 返回最小权值的节点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="克鲁斯卡尔（Kruskal）算法"><a href="#克鲁斯卡尔（Kruskal）算法" class="headerlink" title="克鲁斯卡尔（Kruskal）算法"></a>克鲁斯卡尔（Kruskal）算法</h3><p><strong>与Prim算法从顶点开始扩展最小生成树不同，Kruskal 算法是一种按权值的递增次序选择合适的边来构造最小生成树的方法。</strong></p>
<p>每次挑选为加入生成树的最小边，若不构成回路，则加入生成树，若构成则挑选下一个</p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/6b95ef2bc34f407c122e931cf06b11e6.png" alt="6b95ef2bc34f407c122e931cf06b11e6"></p>
<p>为提高算法执行过程中<strong>查找最小权值边的速度</strong>，可以采用一种排序算法(如堆排序算法)对边集数组中的边按权值进行排序。</p>
<p>接下来，Kruskal算法的关键问题就是<strong>如何判断所选取的边加入T中是否会产生回路</strong>，这里通过引入称为<strong>并查集</strong>的数据结构来解决</p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/fb9515df040633c09b3c136601c8dbd7-1743416415437-1.png" alt="fb9515df040633c09b3c136601c8dbd7"></p>
<p>在下面描述的Kruskal 算法实现中，首先利用私有成员 <code>GetGraph()函数</code><strong>将图的边按权值排好序后存入边集数组graph中</strong>，而<code>边集数组tree</code>则用于<strong>保存和返回算法所构造的最小生成树T</strong>。</p>
<p>算法思路：</p>
<ol>
<li>初始话数组<code>graph</code>，用于存放所有的边，并对其排序</li>
<li>并查集的使用利用<code>数组components</code>，先进行初始化，每个节点的祖先都是自己，也可以理解成每个节点都构成一个集合，后续并查集的过程即为集合合并的过程</li>
<li>循环直到找到最小生成树的所有边（vexnum - 1条），对于每条边，查找他的起点和终点节点的祖先，若是一个祖先则说明在同一集合，不能加入到生成树；若不是一个，则可以加入到<code>生成树数组tree</code>，并要修改节点的祖先，使他们集合合并</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">Kruskal</span>(vector&lt;EdgeType&gt; &amp;tree) &#123;</span><br><span class="line">    <span class="comment">// 创建一个图的边集合，用于存放所有的边</span></span><br><span class="line">    vector&lt;EdgeType&gt; graph;</span><br><span class="line">    <span class="comment">// GetGraph函数将图的所有边按权值从小到大存放到graph数组中</span></span><br><span class="line">    <span class="built_in">GetGraph</span>(graph);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化最小生成树数组，并且初始化并查集组件</span></span><br><span class="line">    tree.<span class="built_in">resize</span>(vexnum - <span class="number">1</span>);  <span class="comment">// 最小生成树包含的边数量是vexnum - 1</span></span><br><span class="line">    <span class="type">int</span> *components = <span class="keyword">new</span> <span class="type">int</span>[vexnum];  <span class="comment">// 记录每个节点所属的集合</span></span><br><span class="line">    <span class="comment">// 初始时，每个节点都属于自己的集合</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">        components[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> k = <span class="number">0</span>, j = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 循环直到找到最小生成树的所有边（vexnum - 1条）</span></span><br><span class="line">    <span class="keyword">while</span> (k &lt; vexnum - <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// 从排序好的边中选择一条边</span></span><br><span class="line">        <span class="type">int</span> h1 = graph[j].head;  <span class="comment">// 边的起点</span></span><br><span class="line">        <span class="type">int</span> t1 = graph[j].tail;  <span class="comment">// 边的终点</span></span><br><span class="line">        <span class="type">int</span> h2 = components[h1];  <span class="comment">// 获取起点所在的集合</span></span><br><span class="line">        <span class="type">int</span> t2 = components[t1];  <span class="comment">// 获取终点所在的集合</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果起点和终点属于不同的集合，则这条边可以加入最小生成树</span></span><br><span class="line">        <span class="keyword">if</span> (h2 != t2) &#123;</span><br><span class="line">            <span class="comment">// 将这条边加入最小生成树中</span></span><br><span class="line">            tree[k].head = h1;</span><br><span class="line">            tree[k].tail = t1;</span><br><span class="line">            tree[k].cost = graph[j].cost;  <span class="comment">// 边的权值</span></span><br><span class="line">            k++;  <span class="comment">// 记录已选择的边的数量</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 合并两个集合，统一编号</span></span><br><span class="line">            <span class="comment">// 将所有属于终点集合t2的顶点，集合编号更新为起点集合h2的编号</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; i++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (components[i] == t2) &#123;</span><br><span class="line">                    components[i] = h2;  <span class="comment">// 更新组件编号</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        j++;  <span class="comment">// 继续检查下一条边</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放动态分配的内存</span></span><br><span class="line">    <span class="keyword">delete</span>[] components;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>显然，Kruskal算法的效率与所选择的<strong>排序算法的效率</strong>以及<strong>并查集数据结构的实现效率</strong>有关。若采用第10章介绍的比较高效的<strong>堆排序算法</strong>排序，<strong>并查集采用树结构</strong>实现，则Kruskal算法的时间复杂度可达到O($\ elog_{2}{e}$)。相比 Prim 算法而言，Kruskal算法更适用于求解稀疏网(指边数较少的网)的最小生成树。</p>
<h2 id="最短路径"><a href="#最短路径" class="headerlink" title="最短路径"></a>最短路径</h2><p>在网图和非网图中，最短路径的含义是不同的。由于非网图它没有边上的权值，所谓的最短路径，其实就是指两顶点之间经过的边数最少的路径；而<strong>对于网图来说，最短路径，是指两顶点之间经过的边上权值之和最少的路径，并且我们称路径上的第一个顶点是源点，最后一个顶点是终点。</strong></p>
<p>求图的最短路径问题通常可分为两类。一类是求图中某顶点到其余各顶点的最短路径问题，也称为<strong>单源最短路径问题</strong>;另一类是求图中每对顶点之间的最短路径问题。</p>
<h3 id="迪杰斯特拉-Dijkstra-算法"><a href="#迪杰斯特拉-Dijkstra-算法" class="headerlink" title="迪杰斯特拉( Dijkstra )算法"></a>迪杰斯特拉( Dijkstra )算法</h3><p>Dijkstra算法用于构建单源点的最短路径—，即图中某个点到任何其他点的距离都是最短的。例如，构建地图应用时查找自己的坐标离某个地标的最短距离。可以用于有向图，但是不能存在负权值。</p>
<p><strong>通俗点说，迪杰斯特拉(Dijkstra)算法，它并不是一下子求出了$\ v_i$到$\ v_j$的最短路径，而是一步步求出它们之间顶点的最短路径，过程中都是基于已经求出的最短路径的基础上，求得更远顶点的最短路径，最终得到你要的结果。</strong></p>
<p>下面介绍 Dijkstra算法的具体实现。为便于在算法执行过程中快速地求得任意两个顶点之间边的权值，图的存储结构宜采用邻接矩阵方式。</p>
<p>为标识图中各顶点在算法执行过程中<strong>是否已求出最短路径</strong>，设置一个<code>一维数组s[]</code></p>
<p>为记录 Dijkstra算法所求出的从源点到各顶点的最短路径，引入<code>数组 path[]</code>, path[i]中保存了从源点到终点v,的最短路径上该顶点的<strong>前驱顶点的序号</strong>。算法结束时，可根据数组path[ ]找到源点到v,的最短路径上每个顶点的前驱顶点，并一直回溯至源点，从而推出从源点到v的最短路径。</p>
<p>为便于每次从V-S中选择当前离源点距离最短的顶点，需要引人一个<code>辅助数组dist[]</code>。它的每一个分量dist[i]表示当前所确定的从源点$\ v<em>0$,到终点$\ v</em>{i}$的最短路径.</p>
<p>算法思路：</p>
<ol>
<li>初始化，s[]所有值为0，s[0]设置为1，代表从$\ v<em>{0}$节点开始，path[]所有值设为0，path[0]设为-1，dist[]通过查找邻接矩阵，得到$\ v</em>{0}$到各个顶点的值</li>
<li>查找dist中最小的值，从该节点继续完成最小路径，将该节点对应s[]设为1</li>
<li>遍历尚未找到最短路径的节点，即s[]为0，dist[i] = Min{dist[i]，dist[j] +cost(j,i)}，选择是借用上一个最短路径的节点到达还是直接到达，更新dist的值</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Dijkstra算法：计算从起点start到其他所有节点的最短路径</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dijkstra</span><span class="params">(<span class="type">int</span> start, <span class="type">int</span> dist[], <span class="type">int</span> path[])</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = numVertices;  <span class="comment">// 获取图中节点的数量</span></span><br><span class="line">    <span class="type">bool</span> visited[n];  <span class="comment">// 访问标记数组，用于标记节点是否已经被访问</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化dist数组和path数组</span></span><br><span class="line">    <span class="comment">// dist[i] 表示从起点到节点i的最短距离</span></span><br><span class="line">    <span class="comment">// path[i] 表示从起点到节点i的最短路径的前驱节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">        visited[i] = <span class="literal">false</span>;  <span class="comment">// 初始时，所有节点均未被访问</span></span><br><span class="line">        dist[i] = adjMatrix[start][i];  <span class="comment">// dist数组初始化为起点到各节点的初始距离</span></span><br><span class="line">        <span class="keyword">if</span> (dist[i] != INT_MAX || i == start) &#123;  <span class="comment">// 如果有边（距离不为无穷大），或者是起点本身</span></span><br><span class="line">            path[i] = start;  <span class="comment">// 将路径的前驱节点设置为起点</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            path[i] = <span class="number">-1</span>;  <span class="comment">// 如果节点无法从起点到达，前驱节点为-1</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    dist[start] = <span class="number">0</span>;  <span class="comment">// 起点到起点的距离为0</span></span><br><span class="line">    visited[start] = <span class="literal">true</span>;  <span class="comment">// 标记起点为已访问</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进行n-1轮循环，逐步更新最短路径</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> count = <span class="number">0</span>; count &lt; n - <span class="number">1</span>; ++count) &#123;</span><br><span class="line">        <span class="type">int</span> min = INT_MAX, min_index;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到未访问的节点中距离最小的节点</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v = <span class="number">0</span>; v &lt; n; ++v) &#123;</span><br><span class="line">            <span class="comment">// 选择距离最小且未被访问的节点</span></span><br><span class="line">            <span class="keyword">if</span> (visited[v] == <span class="literal">false</span> &amp;&amp; dist[v] &lt;= min) &#123;</span><br><span class="line">                min = dist[v];  <span class="comment">// 更新最小距离</span></span><br><span class="line">                min_index = v;  <span class="comment">// 记录最小距离节点的索引</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        visited[min_index] = <span class="literal">true</span>;  <span class="comment">// 标记该节点为已访问</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 更新与该最小距离节点相邻的节点的距离</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v = <span class="number">0</span>; v &lt; n; ++v) &#123;</span><br><span class="line">            <span class="comment">// 如果v节点未被访问，并且从min_index到v有边，且经过min_index节点的路径更短</span></span><br><span class="line">            <span class="keyword">if</span> (!visited[v] &amp;&amp;  </span><br><span class="line">                dist[v] &gt; dist[min_index] + adjMatrix[min_index][v]) &#123;</span><br><span class="line">                dist[v] = dist[min_index] + adjMatrix[min_index][v];  <span class="comment">// 更新v的最短距离</span></span><br><span class="line">                path[v] = min_index;  <span class="comment">// 更新v的前驱节点</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241209092422699.png" alt="image-20241209092422699"></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 打印从源节点到目标节点v的路径</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintPath</span><span class="params">(<span class="type">const</span> vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; g, vector&lt;<span class="type">int</span>&gt; path, vector&lt;<span class="type">int</span>&gt; dist, <span class="type">int</span> v)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (dist[v] == INF) &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;节点 &quot;</span> &lt;&lt; v &lt;&lt; <span class="string">&quot; 无法到达&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 递归打印路径</span></span><br><span class="line">    <span class="keyword">if</span> (path[v] != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="built_in">PrintPath</span>(g, path, dist, path[v]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; v &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>时间复杂度O(n^2)</p>
<h3 id="弗洛伊德-Floyd-算法"><a href="#弗洛伊德-Floyd-算法" class="headerlink" title="弗洛伊德( Floyd )算法"></a>弗洛伊德( Floyd )算法</h3><p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/e00a2f6ecb05b16c2cae4adfb9da8698.png" alt="e00a2f6ecb05b16c2cae4adfb9da8698"></p>
<p>算法原理：递归</p>
<p>n阶数组D：用于保留每一步所求得的所有顶点对之间的当前最短路径长度</p>
<p>初始化：$\ D[i][j]=cost(i,j)$用邻接矩阵进行初始化</p>
<p>状态转移方程：$\ D^{k}[i][j]=min{D^{k-1}[i][j],D^{k-1}[i][k]+D^{k-1}[k][j]}$更新$v_i$到$v_j$的最短路径</p>
<p>path数组：用于存储最短路径，初始化若没有直接路径则$\ path[i][j]=-1$，若有则$\ path[i][j] = j$</p>
<p>算法思路：</p>
<p>初始化数组，遍历n*n次，即$v_i$到$v_j$和$v_j$到$v_i$都遍历一遍，通过状态转移方程更新D数组的值，若找到短的路径，则同时也更新path数组</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Floyd算法</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">Floyd</span>(<span class="type">int</span> path[][MAXV], <span class="type">int</span> D[][MAXV]) &#123;</span><br><span class="line">    <span class="comment">// 初始化距离矩阵D和路径矩阵path</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; vexnum; ++j) &#123;</span><br><span class="line">            D[i][j] = edges[i][j];</span><br><span class="line">            <span class="comment">//初始化path</span></span><br><span class="line">            <span class="keyword">if</span> (D[i][j] &lt; INF &amp;&amp; i != j)</span><br><span class="line">                path[i][j] = j;  <span class="comment">// 若i到j有直接路径，记录路径</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                path[i][j] = <span class="number">-1</span>; <span class="comment">// 否则路径不存在</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 核心Floyd-Warshall算法</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; vexnum; ++k) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vexnum; ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; vexnum; ++j) &#123;</span><br><span class="line">                <span class="keyword">if</span> (D[i][k] != INF &amp;&amp; D[k][j] != INF &amp;&amp; D[i][k] + D[k][j] &lt; D[i][j]) &#123;</span><br><span class="line">                    D[i][j] = D[i][k] + D[k][j];  <span class="comment">// 更新最短路径长度</span></span><br><span class="line">                    path[i][j] = path[i][k];      <span class="comment">// 更新路径</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>函数OutputPath用于输出保存于二维数组path中的所有路径以及保存于二维数组D中的路径长度</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">OutputPath</span><span class="params">(MGraph&lt;T&gt; &amp;G, <span class="type">int</span> path[][MAXV], <span class="type">int</span> D[][MAXV])</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 遍历所有顶点对，输出源点到目标点的最短路径及路径长度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; G.vexnum; ++i) &#123;      <span class="comment">// 遍历所有源点 i</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; G.vexnum; ++j) &#123;  <span class="comment">// 遍历所有目标点 j</span></span><br><span class="line">            <span class="keyword">if</span> (i != j) &#123; <span class="comment">// 排除自身到自身的情况</span></span><br><span class="line">                <span class="keyword">if</span> (D[i][j] == INF) &#123;  <span class="comment">// 若距离为无穷大，表示无路径</span></span><br><span class="line">                    std::cout &lt;&lt; <span class="string">&quot;Path from &quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; to &quot;</span> &lt;&lt; j &lt;&lt; <span class="string">&quot;: No path exists.\n&quot;</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;  <span class="comment">// 若存在路径</span></span><br><span class="line">                    std::cout &lt;&lt; <span class="string">&quot;Path from &quot;</span> &lt;&lt; i &lt;&lt; <span class="string">&quot; to &quot;</span> &lt;&lt; j &lt;&lt; <span class="string">&quot; (Length: &quot;</span> &lt;&lt; D[i][j] &lt;&lt; <span class="string">&quot;): &quot;</span>;</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">// 输出路径，使用 path 数组逐步跟踪中间节点</span></span><br><span class="line">                    <span class="type">int</span> temp = i;      <span class="comment">// 起始点</span></span><br><span class="line">                    std::cout &lt;&lt; temp; <span class="comment">// 输出源点</span></span><br><span class="line">                    <span class="keyword">while</span> (temp != j) &#123; <span class="comment">// 当未到达目标点时</span></span><br><span class="line">                        temp = path[temp][j];  <span class="comment">// 获取路径中的下一个节点</span></span><br><span class="line">                        std::cout &lt;&lt; <span class="string">&quot; -&gt; &quot;</span> &lt;&lt; temp; <span class="comment">// 输出中间节点或目标点</span></span><br><span class="line">                    &#125;</span><br><span class="line">                    std::cout &lt;&lt; std::endl; <span class="comment">// 换行</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="AOV网与拓扑排序"><a href="#AOV网与拓扑排序" class="headerlink" title="AOV网与拓扑排序"></a>AOV网与拓扑排序</h2><p><strong>有向无环图：不含环的有向图</strong></p>
<p><strong>AOV网</strong>：<strong>在一个表示工程的有向图中，用顶点表示活动，用弧表示活动之间的优先关系，这样的有向图为顶点表示活动的网</strong></p>
<p><strong>拓扑序列</strong>：<strong>设G=(V,E)是一个具有n个顶点的有向图，V中的顶点序列V, V2 ,..V n，满足若从顶点V到V;有一条路径，则在顶点序列中顶点V必在顶点V;之前。则我们称这样的顶点序列为一个拓扑序列。</strong></p>
<p><strong>拓扑排序</strong>：<strong>其实就是对一个有向图构造拓扑序列的过程</strong>。每个AOV网都有一个或多个拓扑排序序列。</p>
<p><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241215131046998.png" alt="image-20241215131046998"></p>
<p>对一个AOV网进行拓扑排序的算法有很多，下面介绍比较常用的一种方法的步骤:</p>
<p>①从AOV网中选择一个没有前驱的顶点并输出。<br>②从网中删除该顶点和所有以它为起点的有向边。<br>③重复①和②直到当前的AOV网为空或当前网中不存在无前驱的顶点为止。如果输出顶点数少了，哪怕是少了一个，也说明这个网存在环(回路)，不是AOV网。<br><img src="/2024/12/02/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%9B%BE/image-20241215131727207.png" alt="image-20241215131727207"></p>
<p>算法原理：dfs</p>
<p>对于AOV 网宜采用<strong>邻接表</strong>作为存储结构</p>
<p>数组indegree：用于存放各个顶点的入度</p>
<p>算法思路：</p>
<p>每次遍历数组indegree，查找入度为零的顶点，将其加入队列，再遍历邻接表，将遍历到的顶点的indegree值减一，并判断是否为零，若为零则加入队列</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 拓扑排序实现</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Graph::topologicalSort</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">indegree</span><span class="params">(V, <span class="number">0</span>)</span></span>; <span class="comment">// 入度数组</span></span><br><span class="line">    queue&lt;<span class="type">int</span>&gt; q;              <span class="comment">// 队列</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算所有顶点的入度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; V; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v : adj[i]) &#123;</span><br><span class="line">            indegree[v]++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将入度为0的顶点加入队列</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; V; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (indegree[i] == <span class="number">0</span>) &#123;</span><br><span class="line">            q.<span class="built_in">push</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> count = <span class="number">0</span>; <span class="comment">// 用于检测图是否存在环</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出拓扑排序</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;拓扑排序顺序为: &quot;</span>;</span><br><span class="line">    <span class="keyword">while</span> (!q.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="type">int</span> u = q.<span class="built_in">front</span>();</span><br><span class="line">        q.<span class="built_in">pop</span>();</span><br><span class="line">        cout &lt;&lt; u &lt;&lt; <span class="string">&quot; &quot;</span>; <span class="comment">// 输出顶点</span></span><br><span class="line">        count++;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 遍历该顶点的所有邻接点，并更新它们的入度</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> v : adj[u]) &#123;</span><br><span class="line">            indegree[v]--;</span><br><span class="line">            <span class="keyword">if</span> (indegree[v] == <span class="number">0</span>) &#123;</span><br><span class="line">                q.<span class="built_in">push</span>(v);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果没有输出所有顶点，说明存在环</span></span><br><span class="line">    <span class="keyword">if</span> (count != V) &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;图中存在环，无法进行拓扑排序！&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://blog.csdn.net/Real_Fool_/article/details/114141377">数据结构：图(Graph)【详解】_图数据结构-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1gT4y1v768/?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">数据结构-图-prim（普里姆）算法最小生成树（过程分析+手写代码）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV19S4y1Y7MT?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">数据结构-图-最小生成树-克鲁斯卡尔（Kruskal)算法-手画+过程分析+代码_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——循环队列</title>
    <url>/2024/10/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[<h1 id="数据结构——循环队列"><a href="#数据结构——循环队列" class="headerlink" title="数据结构——循环队列"></a>数据结构——循环队列</h1><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p><img src="/2024/10/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%BE%AA%E7%8E%AF%E9%98%9F%E5%88%97/IMG_20241015_235239-1729007863179-13.jpg" alt="IMG_20241015_235239"></p>
<p>头指针<code>front</code>指向的位置为队列头元素的前一个位置</p>
<p>尾指针<code>rear</code>指向的位置为队列尾元素</p>
<p>以上目的：为了区分队列是否为空或已满的判断条件</p>
<ul>
<li><strong>队列为空</strong>：当 <code>front</code> 和 <code>rear</code> 相等时，说明队列中没有元素，此时为空队列。</li>
<li><strong>队列已满</strong>：当 <code>(rear + 1) % MAXSIZE == front</code> 时，说明队列已满，因为<code>rear</code> 紧跟在 <code>front</code> 的前面，队列的最后一个位置不可用，否则会与空队列的情况冲突。</li>
</ul>
<p>注意事项：</p>
<p>由于判断队列满的条件需要 <code>front</code> 位置与 <code>rear + 1</code> 相等，意味着最多只能使用 <code>MAXSIZE - 1</code> 个元素的位置，这种策略用于避免空队列与满队列状态混淆。</p>
<p>若不做此区分，队空和队满的判断条件都是<code>(rear + 1) % MAXSIZE == front</code>，会发生混淆</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//循环队列</span><br><span class="line">const int MAXSIZE = 100;</span><br><span class="line">typedef struct &#123;</span><br><span class="line">	int data[MAXSIZE];</span><br><span class="line">	int front;</span><br><span class="line">	int rear;</span><br><span class="line">&#125;Queue;</span><br><span class="line"></span><br><span class="line">//初始化队列</span><br><span class="line">void InitQueue(Queue&amp; Q) &#123;</span><br><span class="line">	Q.front = 0;</span><br><span class="line">	Q.rear = 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//判断队列是否为空</span><br><span class="line">bool IsEmpty(Queue Q) &#123;</span><br><span class="line">	return Q.front == Q.rear;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//判断队列是否已满</span><br><span class="line">bool IsFull(Queue Q) &#123;</span><br><span class="line">	return (Q.rear + 1) % MAXSIZE == Q.front;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//入队</span><br><span class="line">void push(Queue&amp; Q, int x) &#123;</span><br><span class="line">	if (IsFull(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列已满&quot; &lt;&lt; endl;</span><br><span class="line">		return;</span><br><span class="line">	&#125;</span><br><span class="line">	//指针先向后移动，再赋值</span><br><span class="line">	Q.rear = (Q.rear + 1) % MAXSIZE;</span><br><span class="line">	Q.data[Q.rear] = x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//出队</span><br><span class="line">int pop(Queue&amp; Q) &#123;</span><br><span class="line">	if (IsEmpty(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	//指针先向后移动，再返回值</span><br><span class="line">	Q.front = (Q.front + 1) % MAXSIZE;</span><br><span class="line">	return Q.data[Q.front];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//获取队头元素</span><br><span class="line">int getFront(Queue Q) &#123;</span><br><span class="line">	if (IsEmpty(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	//指针向后移动，再返回值，front指针指向的是队头元素的前一个位置</span><br><span class="line">	return Q.data[(Q.front + 1) % MAXSIZE];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//获取队尾元素</span><br><span class="line">int getRear(Queue Q) &#123;</span><br><span class="line">	if (IsEmpty(Q)) &#123;</span><br><span class="line">		cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; endl;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">	//rear指针指向的是队尾元素</span><br><span class="line">	return Q.data[Q.rear];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//测试函数</span><br><span class="line">int main() &#123;</span><br><span class="line">	Queue Q;</span><br><span class="line">	InitQueue(Q);</span><br><span class="line">	push(Q, 1);</span><br><span class="line">	push(Q, 2);</span><br><span class="line">	push(Q, 3);</span><br><span class="line">	cout &lt;&lt; getFront(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; getRear(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; pop(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; getFront(Q) &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; getRear(Q) &lt;&lt; endl;</span><br><span class="line">	return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意事项：</p>
<p>入队逻辑：rear指针先向后移动一位，再赋值</p>
<p>出队逻辑：front指针先向后移动一位，再返回值，因为front指针指向的是队头元素的前一个位置</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.bilibili.com/video/BV1CC4y1m7Bu/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【队列&amp;循环队列】手动实现循环队列，掌握循环队列的每一处细节_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>实习七月复盘</title>
    <url>/2025/08/05/%E5%AE%9E%E4%B9%A0/%E6%99%A8%E6%99%9F%E6%99%BA%E6%8E%A7/%E6%97%A5%E5%BF%97/%E4%B8%83%E6%9C%88%E5%A4%8D%E7%9B%98/</url>
    <content><![CDATA[<h3 id="文件处理阶段"><a href="#文件处理阶段" class="headerlink" title="文件处理阶段"></a>文件处理阶段</h3><ol>
<li>使用libreoffice将doc，docx文件处理成pdf文件，方便后续使用mineru进行提取</li>
<li>完成mineru的docker本地部署；搭建fastapi服务，与项目容器构建自定义网络，方便后续服务调用；使用locust完成对mineru的并发性能测试，和吞吐量测试</li>
<li>对mineru提取的html格式的表格进行预处理工作，将其转化成md格式，方便后续分块，节省tokens</li>
</ol>
<h4 id="部分技术细节"><a href="#部分技术细节" class="headerlink" title="部分技术细节"></a>部分技术细节</h4><p><strong>mineru提取效果说明</strong></p>
<p>可以完整提取表格与图片，将图片以相对链接形式储存在images文件夹下；可以完成pdf与扫描件的提取，可以实现对图片中文字的识别；输出符合人类阅读顺序的文本，适用于单栏、多栏及复杂排版；删除页眉、页脚、脚注、页码等元素，确保语义连贯</p>
<p>目前问题：仍无法实现对多级标题的识别</p>
<p><strong>mineru的fastapi启动指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3 mineru-api --host 0.0.0.0 --port 30000 --dp-size 3 --enable-torch-compile</span><br></pre></td></tr></table></figure>
<blockquote>
<p>MinerU支持通过sglang的多GPU并行模式来提升推理速度。</p>
<ul>
<li>如果您有超过多张显卡，可以使用sglang的多卡并行模式来增加吞吐量：<code>--dp-size 2</code></li>
<li>同时您可以启用<code>torch.compile</code>来将推理速度加速约15%：<code>--enable-torch-compile</code></li>
</ul>
<p>注意设置环境变量<code>MINERU_MODEL_SOURCE=local CUDA_VISIBLE_DEVICES=1,2,3</code>保证模型本地加载与调用指定gpu</p>
</blockquote>
<p><strong>mineru容器启动指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d --name mineru-server --gpus all --shm-size 32g -p 30000:30000 --ipc=host -v /aisys/:/aisys/ --network network_test mineru-sglang:latest tail -f /dev/null</span><br><span class="line">docker start mineru-server</span><br></pre></td></tr></table></figure>
<p><strong>mineru三种后端模式测试</strong></p>
<p>pipeline (默认后端) ，vlm-sglang-engine，vlm-sglang-client</p>
<p>项目中使用的是vlm-sglang-engine，原因如下，pipeline应用场景更多是仅能cpu推理，解析速度大大落后与vlm模式，而我们gpu资源充足，自然不考虑；vlm-sglang-client应用场景更多是有SGLang服务器，这样客户端既可以不用安装sglang，同样不符合我们的条件</p>
<p><strong>mineru并发与吞吐量测试</strong></p>
<p><strong>测试场景</strong>：10页的pdf，50用户并发</p>
<p><strong>工具</strong>：locust</p>
<p><strong>测试结果</strong></p>
<p>对于推理模型的吞吐量，在3个gpu开启数据并行的情况下，平均每秒单个gpu处理tokens为1500左右</p>
<p>gpu状态如上:<strong>显存几乎打满 85–87 %</strong>,<strong>GPU 利用率 59–63 %</strong>,<strong>功耗 170–188 W / 350 W</strong></p>
<p>压测结果如下，选取部分指标</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>指标</th>
<th>数值</th>
<th>通俗解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>平均响应时间</strong></td>
<td><strong>241 秒</strong> ≈ <strong>4 分钟</strong></td>
<td>上传一个 PDF → 拿到解析结果，平均要等 4 分钟。</td>
</tr>
<tr>
<td><strong>中位数</strong></td>
<td><strong>215 秒</strong> ≈ <strong>3.6 分钟</strong></td>
<td>一半请求在 3.6 分钟内完成。</td>
</tr>
<tr>
<td><strong>95% 用户</strong></td>
<td><strong>361 秒</strong> ≈ <strong>6 分钟</strong></td>
<td>最慢的 5% 要等 6 分钟以上。</td>
</tr>
<tr>
<td><strong>吞吐量</strong></td>
<td><strong>0.18 req/s</strong></td>
<td>这台 MinerU <strong>每分钟只能处理约11 个 PDF</strong>。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="分块阶段"><a href="#分块阶段" class="headerlink" title="分块阶段"></a>分块阶段</h3><p>当前主流的分块方式共五种：固定长度分块，语义分块，递归分块，文档结构分块，llm分块。</p>
<p>最后项目我选择了递归分块，原因如下：</p>
<ol>
<li>mineru无法正确提取md文档结构，因此我舍弃了文档结构分块</li>
<li>测试了agentic chunk（其主要思想是，先进行初步分段，按照长度或递归，然后让大模型生成这一段的概要，将段与段合并生成块），但是测试下来，我们这个一个文档的内容同质化很严重，基本上都分到一块里了，我猜测语义分块也是这种效果，因此舍弃</li>
<li>我们的文档中存在大量表格，我在预处理阶段增加了对表格的首尾标记，使用递归分块可以更好的保留这些结构</li>
</ol>
<h3 id="检索阶段"><a href="#检索阶段" class="headerlink" title="检索阶段"></a>检索阶段</h3><p>基于langchain_elasticsearch完成了向量搜索，bm25，混合检索，模糊检索的检索函数的编写。</p>
<p>结果如下：</p>
<ol>
<li>混合检索elasticsearch需要付费使用</li>
<li>bm25的多字段搜索有三种模式且字段的权重可以调整，后续评估时调整进行测试</li>
<li>检索的效果需要后续进行rag评估时判定</li>
</ol>
<h3 id="elasticsearch相关"><a href="#elasticsearch相关" class="headerlink" title="elasticsearch相关"></a>elasticsearch相关</h3><p>完成对项目es模块的熟悉阅读；实现对elasticsearch的连接与字段的构建与存入。</p>
<p>关于字段的存储，我选取了report_name，report_url，page_content</p>
<h4 id="相关细节"><a href="#相关细节" class="headerlink" title="相关细节"></a>相关细节</h4><h5 id="阅读elasticsearch代码相关记录"><a href="#阅读elasticsearch代码相关记录" class="headerlink" title="阅读elasticsearch代码相关记录:"></a><strong>阅读elasticsearch代码相关记录:</strong></h5><ol>
<li><strong>embedding_model</strong>.select_embeddings_model:根据指定的模型名称加载</li>
<li><strong>make_es_vector_store</strong>：<ol>
<li>docs_url = pd.read_excel(‘docs_new.xlsx’)，从excel加载url并进行数据处理，保存筛选后的ur</li>
<li>完成文件加载测试：xizhang/retrival/docfile_test/test.py；</li>
<li>初始化es，使用elastic_search.load_es_index加载存储索引</li>
<li>完成测试elasticsearch连接与索引构建（索引名zxj_test）：/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_es_connect.py，/aisys/repo_dev/xizhang/retrival/elasticsearch_test/test_add_es.py</li>
<li>顺序批量处理文件：共16000多份，每十份为一批进行处理，使用download_pdf.py进行文件下载，使用，使用vector_base.rewrite_file对文件进行处理，这里可以修改代码，增加对mineru处理pdf的markdown文件的处理，返回Document对象列表；</li>
</ol>
</li>
<li><strong>elastic_search</strong></li>
</ol>
<p>重写了检索策略的函数，包括BM25，KNN，混合搜索</p>
<ol>
<li><p>elastic_retriever创建Elasticsearch检索器：根据搜索类型选择对应的查询函数，创建Elasticsearch检索器ElasticsearchRetriever.from_es_params</p>
</li>
<li><p><strong>retrievers</strong></p>
<ol>
<li>定义函数select_retriever，根据指定的名称选择并返回相应的检索器，目前只有bm25</li>
</ol>
</li>
</ol>
<h5 id="文档结构"><a href="#文档结构" class="headerlink" title="文档结构"></a>文档结构</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">doc = Document(</span><br><span class="line">            page_content=text_content,</span><br><span class="line">            metadata=&#123;</span><br><span class="line">                &quot;report_name&quot;: folder_name,</span><br><span class="line">                &quot;report_url&quot;: report_url,</span><br><span class="line">                &quot;chunk_id&quot;: chunk_id</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<h3 id="rag评估"><a href="#rag评估" class="headerlink" title="rag评估"></a>rag评估</h3><p>待补充</p>
<h3 id="后续优化思考"><a href="#后续优化思考" class="headerlink" title="后续优化思考"></a>后续优化思考</h3><ol>
<li>重排序部分我没有做过，不知道怎么做，也不知道效果会怎样（我感觉在我们这个场景应该提升有限，听你说也是这样）</li>
<li>如何存入数据库的部分，可能也是优化的点，比如可以尝试agentic rag这种，在存入数据库前再进行一步处理</li>
<li>还有一个点我比较好奇，我们项目在召回后是如何处理的，就是上下文拼接吗</li>
</ol>
]]></content>
      <categories>
        <category>实习</category>
        <category>晨晟智控</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——广义表</title>
    <url>/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="数据结构——广义表"><a href="#数据结构——广义表" class="headerlink" title="数据结构——广义表"></a>数据结构——广义表</h1><h2 id="广义表的定义和相关概念"><a href="#广义表的定义和相关概念" class="headerlink" title="广义表的定义和相关概念"></a>广义表的定义和相关概念</h2><p>广义表是线性表的推广，其中的元素可以是原子（即不可再分的基本数据项），也可以是子表。广义表的一些常用术语包括：</p>
<ul>
<li><strong>长度</strong>：广义表的长度是其顶层元素的个数。</li>
<li><strong>深度</strong>：广义表中元素嵌套的最大深度。</li>
<li><strong>表头</strong>：广义表中的第一个元素。</li>
<li><strong>表尾</strong>：去掉表头后剩下的部分。</li>
</ul>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><ul>
<li><strong>A = ()</strong></li>
<li><strong>B = (a, b, c)</strong>c)`</li>
<li><strong>C = (a, (b, c, d), e)</strong></li>
<li><strong>D = (a, b, (e, f, g))</strong></li>
<li><strong>E = ((a, b), c, (d, e, (f, g)))</strong></li>
<li><strong>F = ((), ((), ()))</strong></li>
</ul>
<p>下表展示了图片中的几个广义表的长度、深度、表头和表尾的具体值：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>广义表</th>
<th>长度</th>
<th>深度</th>
<th>表头</th>
<th>表尾</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>0</td>
<td>1</td>
<td>空</td>
<td>()</td>
</tr>
<tr>
<td>B</td>
<td>3</td>
<td>1</td>
<td>a</td>
<td>(b, c)</td>
</tr>
<tr>
<td>C</td>
<td>3</td>
<td>2</td>
<td>a</td>
<td>((b, c, d), e)</td>
</tr>
<tr>
<td>D</td>
<td>3</td>
<td>3</td>
<td>a</td>
<td>(b, (e, f, g))</td>
</tr>
<tr>
<td>E</td>
<td>4</td>
<td>3</td>
<td>(a, b)</td>
<td>(c, (d, e, (f, g)))</td>
</tr>
<tr>
<td>F</td>
<td>3</td>
<td>3</td>
<td>()</td>
<td>((), ((), ()))</td>
</tr>
</tbody>
</table>
</div>
<h2 id="广义表的存储结构"><a href="#广义表的存储结构" class="headerlink" title="广义表的存储结构"></a>广义表的存储结构</h2><p><img src="/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/IMG_20241021_153619-1729496219467-9.jpg" alt="IMG_20241021_153619"></p>
<p>由于广义表中的每个元素可能是原子或子表，因此在广义表的存储结构中存在两类结点：</p>
<ol>
<li><strong>原子节点</strong>：用于存储单个元素。</li>
<li><strong>子表节点</strong>：用于存储子表的指针。</li>
</ol>
<p>为了区分元素是原子还是子表，结构中还设置了一个标识域 <code>type</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">GListNodeType</span> &#123; ATOM, LIST &#125;; <span class="comment">// 结点类型：原子或子表</span></span><br></pre></td></tr></table></figure>
<p>当type值为1，说明存入原子的值；为2，说明存入子广义表的头指针</p>
<p>广义表定义如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">char</span> ElemType; <span class="comment">// 原子的类型定义为字符类型</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">GListNode</span> &#123;</span><br><span class="line">    GListNodeType type; <span class="comment">// 类型域，表示该节点是原子还是子表</span></span><br><span class="line">    <span class="keyword">union</span> &#123;</span><br><span class="line">        ElemType data; <span class="comment">// 如果是原子节点，则存储数据</span></span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">GListNode</span> *sublist; <span class="comment">// 如果是子表节点，则存储指向子表的指针</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">GListNode</span> *next; <span class="comment">// 指向下一个表节点的指针</span></span><br><span class="line">&#125; GListNode, *GList; <span class="comment">// GList 表示广义表的指针类型</span></span><br></pre></td></tr></table></figure>
<p><img src="/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/IMG_20241021_154058-1729496523052-14.jpg" alt="IMG_20241021_154058"></p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="求广义表长度"><a href="#求广义表长度" class="headerlink" title="求广义表长度"></a>求广义表长度</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 求广义表的长度</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">LengthGList</span><span class="params">(GList list)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> length = <span class="number">0</span>;</span><br><span class="line">    GList current = list;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        length++;</span><br><span class="line">        current = current-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> length;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="求广义表深度"><a href="#求广义表深度" class="headerlink" title="求广义表深度"></a>求广义表深度</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 求广义表的深度</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">DepthGList</span><span class="params">(GList list)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (list == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;  <span class="comment">// 空表深度为 1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> maxDepth = <span class="number">1</span>;</span><br><span class="line">    GList current = list;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;type == LIST) &#123;</span><br><span class="line">            <span class="type">int</span> sublistDepth = <span class="built_in">DepthGList</span>(current-&gt;value.sublist) + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (sublistDepth &gt; maxDepth) &#123;</span><br><span class="line">                maxDepth = sublistDepth;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        current = current-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> maxDepth;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="打印"><a href="#打印" class="headerlink" title="打印"></a>打印</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 打印广义表</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintGList</span><span class="params">(GList list)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (list == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;()&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;(&quot;</span>);</span><br><span class="line">    GList current = list;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;type == ATOM) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>, current-&gt;value.data);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (current-&gt;type == LIST) &#123;</span><br><span class="line">            <span class="built_in">PrintGList</span>(current-&gt;value.sublist);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;next != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;, &quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        current = current-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;)&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="线性表章节小结"><a href="#线性表章节小结" class="headerlink" title="线性表章节小结"></a>线性表章节小结</h1><p><img src="/2024/10/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E5%B9%BF%E4%B9%89%E8%A1%A8/IMG_20241021_155320.jpg" alt="IMG_20241021_155320"></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——查找</title>
    <url>/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/</url>
    <content><![CDATA[<h2 id="查找的概念"><a href="#查找的概念" class="headerlink" title="查找的概念"></a>查找的概念</h2><p><strong>查找(Searching)</strong> ：就是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素( 或记录)。</p>
<p><strong>查找表(Search Table)</strong> ：是由同一类型的数据元素(或记录)构成的集合。</p>
<p><strong>关键字(Key)</strong> ：数据元素中唯一标识该元素的某个数据项的值，使用基于关键字的查找，查找结果应该是唯一的。例如，在由一个学生元素构成的数据集合中，学生元素中“学号”这一数据项的值唯一地标识一名学生。</p>
<p><strong>静态查找表(Static Search Table)</strong> ：只作查找操作的查找表。<br><strong>动态查找表(Dynamic Search Table)</strong> ： 在查找过程中同时插入查找表中不存在的数据元素，或者从查找表中删除已经存在的某个数据元素。</p>
<p><strong>平均查找长度</strong> ：在查找过程中，一次查找的长度是指需要比较的关键字次数，而平均查找长度，则是所有查找过程中进行关键字的比较次数的平均值，其数学定义为$\ ASL=\sum_{i=1}^{n}P_iC_i$</p>
<p>式中，n是查找表的长度;P是查找第i个数据元素的概率，一般认为每个数据元素的查找概率相等，即P,= 1/n;C;是找到第i个数据元素所需进行的比较次数。平均查找长度是衡量查找算法效率的最主要的指标。</p>
<h2 id="顺序表查找"><a href="#顺序表查找" class="headerlink" title="顺序表查找"></a>顺序表查找</h2><h3 id="顺序查找"><a href="#顺序查找" class="headerlink" title="顺序查找"></a>顺序查找</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*有哨兵顺序查找*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Sequential_Search</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> n, <span class="type">int</span> key)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> i;</span><br><span class="line">	a[<span class="number">0</span>] = key;	<span class="comment">//设置a[0]为关键字，称之为“哨兵”</span></span><br><span class="line">	i = n;	<span class="comment">//循环从数组尾部开始</span></span><br><span class="line">	<span class="keyword">while</span>(a[i] != key)&#123;</span><br><span class="line">		i--;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> i;	<span class="comment">//返回0则说明查找失败</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这种在查找方向的尽头放置“哨兵”免去了在查找过程中每一次比较后都要判断查找位置是否越界的小技巧，看似与原先差别不大，但在总数据较多时，效率提高很大，是非常好的编码技巧。<br>上述顺序表查找时间复杂度是O (n) 。</p>
<h3 id="折半查找"><a href="#折半查找" class="headerlink" title="折半查找"></a>折半查找</h3><p>当查找表是有序表时，可采用折半查找的方法。</p>
<p>算法思路：</p>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215134842077.png" alt="image-20241215134842077"></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">Binary_Search</span><span class="params">(SeqList L, ElemType key)</span></span>&#123;</span><br><span class="line">	<span class="type">int</span> low = <span class="number">0</span>, high = L.length - <span class="number">1</span>, mid;</span><br><span class="line">	<span class="keyword">while</span>(low &lt;= high)&#123;</span><br><span class="line">		mid = (low + hight)/<span class="number">2</span>;	<span class="comment">//取中间位置</span></span><br><span class="line">		<span class="keyword">if</span>(L.elem[mid] == key)&#123;</span><br><span class="line">			<span class="keyword">return</span> mid;	<span class="comment">//查找成功返回所在位置</span></span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(L.elem[mid] &gt; key)&#123;</span><br><span class="line">			high = mid - <span class="number">1</span>;	<span class="comment">//从前半部分继续查找</span></span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			low = mid + <span class="number">1</span>;	<span class="comment">//从后半部分继续查找</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">-1</span>;	<span class="comment">//查找失败，返回-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215134858075.png" alt="image-20241215134858075"></p>
<p>折半查找的过程可用二叉树来描述，称为判定树。</p>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215135512761.png" alt="image-20241215135512761"></p>
<p>节点的树高代表该节点的查询次数</p>
<p>因此，长度为13的有序表进行折半查找的平均查找长度ASL=(1×1+2×2+3×4+4×6)/13 =41/13。</p>
<p>折半查找的时间复杂度为$\ O(\log_2n)$，平均情况下比顺序查找的效率高。</p>
<h3 id="分块查找"><a href="#分块查找" class="headerlink" title="分块查找"></a>分块查找</h3><p>为了减少索引项的个数，我们可以对数据集进行分块，使其分块有序，然后再对每一块建立一个索引项，从而减少索引项的个数。</p>
<p>分块有序，是把数据集的记录分成了若千块，并且这些块需要满足两个条件：</p>
<ul>
<li><p>块内无序：即每一块内的记录不要求有序。</p>
</li>
<li><p>块间有序：例如，要求第二块所有记录的关键字均要大于第一块中所有记录的关键字，第三块的所有记录的关键字均要大于第二块的所有记录关键字…因为只有块间有序，才有可能在查找时带来效率。</p>
</li>
</ul>
<p>对于分块有序的数据集，将每块对应一个索引项， 这种索引方法叫做分块索引。如下图所示，我们定义的分块索引的索引项结构分三个数据项：</p>
<ul>
<li><p>最大关键码：它存储每一块中的最大关键字，这样的好处就是可以使得在它之后的下一块中的最小关键字也能比这一块最大的关键字要大；</p>
</li>
<li><p>块长：存储了块中的记录个数，以便于循环时使用；</p>
</li>
<li>块首指针：用于指向块首数据元素的指针，便于开始对这一块中记录进行遍历。</li>
</ul>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/825a789b2d39804be6b9aede1bbc0ba1.png" alt="825a789b2d39804be6b9aede1bbc0ba1"></p>
<p>在分块索引表中查找，就是分两步进行:<br>1.在分块索引表中查找要查关键字所在的块。由于分块索引表是块间有序的，因此很容易利用折半、插值等算法得到结果。例如在上图的数据集中查找62，我们可以很快可以从左上角的索引表中由57&lt;62&lt;96得到62在第三个块中。<br>2.根据块首指针找到相应的块，并在块中顺序查找关键码。</p>
<h2 id="树表的查找"><a href="#树表的查找" class="headerlink" title="树表的查找"></a>树表的查找</h2><h3 id="二叉排序树"><a href="#二叉排序树" class="headerlink" title="二叉排序树"></a>二叉排序树</h3><p>二叉排序树(也称二叉查找树)或者是一棵空树，或者是具有下列特性的二叉树:</p>
<ol>
<li>若左子树非空，则<strong>左子树上所有结点的值均小于根结点的值</strong>。</li>
<li>若右子树非空，则<strong>右子树上所有结点的值均大于根结点的值</strong>。</li>
<li>左、右子树也分别是一棵二叉排序树。</li>
</ol>
<p>根据二叉排序树的定义，左子树结点值&lt;根结点值&lt;右子树结点值，所以对二叉排序树进行中序遍历，可以得到一个递增的有序序列。例如，下图所示二叉排序树的中序遍历序列为123468。</p>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/bec1d08d423a4860887667fb980dfbea.png" alt="bec1d08d423a4860887667fb980dfbea"></p>
<h4 id="二叉排序树的插入和建立"><a href="#二叉排序树的插入和建立" class="headerlink" title="二叉排序树的插入和建立"></a>二叉排序树的插入和建立</h4><p>在一棵二叉排序树中插入值为系的结点的步骤如下：</p>
<p>①若二叉排序树为空，则生成值为k的新结点s，同时将新结点s作为根结点插入。</p>
<p>②若k小于根结点的值,则在根的左子树中插入值为k的结点。</p>
<p>③若k大于根结点的值,则在根的右子树中插入值为k的结点。</p>
<p>④若k等于根结点的值，表明二叉排序树中已有此关键字，则无需插入。</p>
<p>二叉排序树插入算法</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"> <span class="comment">//构造函数</span></span><br><span class="line"> <span class="built_in">BiNode</span>(<span class="type">int</span> k) : <span class="built_in">key</span>(k), <span class="built_in">lchild</span>(<span class="literal">nullptr</span>), <span class="built_in">rchild</span>(<span class="literal">nullptr</span>) &#123;&#125;;</span><br><span class="line"><span class="comment">// 递归插入函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Insert</span><span class="params">(BiNode*&amp; ptr, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (ptr == <span class="literal">nullptr</span>) &#123; <span class="comment">// 如果当前指针为空，插入新节点</span></span><br><span class="line">            ptr = <span class="keyword">new</span> <span class="built_in">BiNode</span>(k);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (k &lt; ptr-&gt;key) &#123; </span><br><span class="line">            <span class="built_in">Insert</span>(ptr-&gt;lchild, k); <span class="comment">// 递归插入到左子树</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (k &gt; ptr-&gt;key) &#123;</span><br><span class="line">            <span class="built_in">Insert</span>(ptr-&gt;rchild, k); <span class="comment">// 递归插入到右子树</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果k等于当前节点值，则不插入（BST通常不允许重复值）</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 插入值到BST</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Insert</span><span class="params">(<span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">Insert</span>(root, k);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>二叉排序树的建立</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 构造函数：利用数组 a[] 和大小 n 建立二叉排序树</span></span><br><span class="line">    <span class="built_in">BiSortTree</span>(<span class="type">int</span> a[], <span class="type">int</span> n) &#123;</span><br><span class="line">        root = <span class="literal">nullptr</span>; <span class="comment">// 初始化根节点为空</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">            <span class="built_in">Insert</span>(root, a[i]); <span class="comment">// 插入数组中的每个元素</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215144119644.png" alt="image-20241215144119644"></p>
<h4 id="二叉排序树的查找过程"><a href="#二叉排序树的查找过程" class="headerlink" title="二叉排序树的查找过程"></a>二叉排序树的查找过程</h4><p>根据二叉排序树的定义，在二叉排序树中查找给定值k的过程如下:</p>
<p>①若二叉排序树为空，则表明查找失败，返回空指针;否则，若给定值k等于根结点的值,则表明查找成功,返回根结点。</p>
<p>②若给定值k小于根结点的值,则继续在根的左子树中查找。</p>
<p>③若给定值k大于根结点的值,则继续在根的右子树中查找。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 非递归查找函数</span></span><br><span class="line">   <span class="function">BiNode* <span class="title">Search2</span><span class="params">(BiNode* ptr, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">while</span> (ptr) &#123;</span><br><span class="line">           <span class="keyword">if</span> (k == ptr-&gt;key) <span class="comment">// 找到目标节点</span></span><br><span class="line">               <span class="keyword">return</span> ptr;</span><br><span class="line">           <span class="keyword">else</span> <span class="keyword">if</span> (k &lt; ptr-&gt;key) <span class="comment">// 查找左子树</span></span><br><span class="line">               ptr = ptr-&gt;lchild;</span><br><span class="line">           <span class="keyword">else</span>                  <span class="comment">// 查找右子树</span></span><br><span class="line">               ptr = ptr-&gt;rchild;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="literal">nullptr</span>; <span class="comment">// 未找到</span></span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>若二叉排序树是<strong>平衡的(即形态均匀)</strong>，则进行查找的时间复杂度为$\ O(log_2n)$;若退化为一棵单支树（最极端和最差的情况)，则其时间复杂度为$\ O(n)$。对于一般情况，其时间复杂度可以认为是$\ O(log_2n)$。</p>
<h4 id="二叉排序树的删除"><a href="#二叉排序树的删除" class="headerlink" title="二叉排序树的删除"></a>二叉排序树的删除</h4><p>二叉排序树的查找和插入都很简单，但是删除操作就要复杂一些，此时要删除的结点有三种情况：</p>
<ol>
<li>叶子结点；</li>
<li>仅有左或右子树的结点；</li>
<li>左右子树都有的结点；</li>
</ol>
<p>前两种情况都很简单，第一种只需删除该结点不需要做其他操作；第二种删除后需让被删除结点的直接后继接替它的位置；<strong>复杂就复杂在第三种，此时我们需要遍历得到被删除结点的直接前驱或者直接后继来接替它的位置，然后再删除</strong>。</p>
<p>第三种情况如下图所示：</p>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/1fa9d70c1f0ef1ab673061a9c2e39a08.png" alt="1fa9d70c1f0ef1ab673061a9c2e39a08"></p>
<p>代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">若二叉排序树T中存在关键字等于key的数据元素时，则删除该数据元素结点，</span></span><br><span class="line"><span class="comment">并返回TRUE;否则返回FALSE</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">DeleteBST</span><span class="params">(BiTree *T, <span class="type">int</span> key)</span></span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(!T)&#123;</span><br><span class="line">		<span class="keyword">return</span> FALSE; </span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		<span class="keyword">if</span>(key == T-&gt;data)&#123;</span><br><span class="line">			<span class="comment">//找到关键字等于key的数据元素</span></span><br><span class="line">			<span class="keyword">return</span> <span class="built_in">Delete</span>(T);</span><br><span class="line">		&#125;<span class="keyword">else</span> <span class="keyword">if</span>(key &lt; T -&gt; data)&#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="built_in">DeleteBST</span>(T -&gt; lchild, key);</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="built_in">DeleteBST</span>(T -&gt; rchild, key);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面是Delete()方法：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*从二叉排序树中删除结点p，并重接它的左或右子树。*/</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Delete</span><span class="params">(BiTree *p)</span></span>&#123;</span><br><span class="line">	BiTree q, s;</span><br><span class="line">	<span class="keyword">if</span>(p-&gt;rchild == <span class="literal">NULL</span>)&#123;</span><br><span class="line">		<span class="comment">//右子树为空则只需重接它的左子树</span></span><br><span class="line">		q = p;</span><br><span class="line">		p = p-&gt;lchild;</span><br><span class="line">		<span class="built_in">free</span>(q);</span><br><span class="line">	&#125;<span class="keyword">else</span> <span class="keyword">if</span>(p-&gt;lchild == <span class="literal">NULL</span>)&#123;</span><br><span class="line">		<span class="comment">//左子树为空则只需重接它的右子树</span></span><br><span class="line">		q = p;</span><br><span class="line">		p = p-&gt;rchild;</span><br><span class="line">		<span class="built_in">free</span>(q);</span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">		<span class="comment">//左右子树均不空</span></span><br><span class="line">		q = p;</span><br><span class="line">		s = p-&gt;lchild;	<span class="comment">//先转左</span></span><br><span class="line">		<span class="keyword">while</span>(s-&gt;rchild)&#123;<span class="comment">//然后向右到尽头，找待删结点的前驱</span></span><br><span class="line">			q = s;</span><br><span class="line">			s = s-&gt;rchild;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//此时s指向被删结点的直接前驱，p指向s的父母节点</span></span><br><span class="line">		p-&gt;data = s-&gt;data;	<span class="comment">//被删除结点的值替换成它的直接前驱的值</span></span><br><span class="line">		<span class="keyword">if</span>(q != p)&#123;</span><br><span class="line">			q-&gt;rchild = s-&gt;lchild;	<span class="comment">//重接q的右子树</span></span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			q-&gt;lchild = s-&gt;lchild;	<span class="comment">//重接q的左子树</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="built_in">pree</span>(s);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> TRUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>二叉排序树的查找性能取决于二叉排序树的形状</strong>。</p>
<p>例如{ 62 , 88 , 58 , 47 , 35 , 73 , 51 , 99 , 37 , 93 } {62,88,58,47,35,73,51,99,37,93}{62,88,58,47,35,73,51,99,37,93}这样的数组，我们可以构建如下左图的二叉排序树。但如果数组元素的次序是从小到大有序，如{35,37,47,51,58,62,73,88,93,99},则二叉排序树就成了极端的右斜树，如下面右图的二叉排序树：<br><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/f33a1ebf98e14082fb0df30072964e09.png" alt="f33a1ebf98e14082fb0df30072964e09"></p>
<p>也就是说，我们希望二叉排序树是比较平衡的，即其深度与完全二叉树相同，那么查找的时间复杂也就为$\ O(\log_2n)$，近似于折半查找。<br>不平衡的最坏情况就是像上面右图的斜树，查找时间复杂度为O(n)，这等同于顺序查找。<br>因此，如果我们希望对一个集合按二叉排序树查找，最好是把它构建成一棵<strong>平衡的二叉排序树</strong>。</p>
<h3 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h3><p><strong>平衡二叉树</strong>：<strong>是一种二叉排序树，其中每一个节点的左子树和右子树的高度差至多等于1。</strong></p>
<p>我们<strong>将二叉树上结点的左子树深度减去右子树深度的值称为平衡因子BF</strong></p>
<p>那么平衡二叉树上所有结点的平衡因子只可能是-1、0和1。只要二叉树上有一个结点的平衡因子的绝对值大于1，则该二叉树就是不平衡的。</p>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/a1f704e077a99af5d0e5491cfbd18b50.png" alt="a1f704e077a99af5d0e5491cfbd18b50"></p>
<h4 id="平衡二叉树的插入"><a href="#平衡二叉树的插入" class="headerlink" title="平衡二叉树的插入"></a>平衡二叉树的插入</h4><p>新结点插入后，若造成查找路径上的某个结点不再平衡，则需要做出相应的调整。可将调整的规律归纳为下列4种情况：</p>
<ol>
<li><strong>LL平衡旋转(右单旋转)</strong>:由于在结点A的左孩子(L)的左子树(L)上插入了新结点</li>
</ol>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/c1f0364ace56db6d49fe314233364370.png" alt="c1f0364ace56db6d49fe314233364370"></p>
<ol>
<li><strong>RR平衡旋转(左单旋转)</strong>:由于在结点A的右孩子(R)的右子树(R)上插入了 新结点</li>
</ol>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/741cd35f51fbb8eab58cd2dbb8988875.png" alt="741cd35f51fbb8eab58cd2dbb8988875"></p>
<ol>
<li><strong>LR平衡旋转(先左后右双旋转)</strong>:由于在A的左孩子(L)的右子树(R)上插入新结点</li>
</ol>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/53cabfa17150d6a0c98b467098d6379d.png" alt="53cabfa17150d6a0c98b467098d6379d"></p>
<ol>
<li><strong>RL平衡旋转(先右后左双旋转)</strong>:由于在A的右孩子(R)的左子树(L)上插入新结点</li>
</ol>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/fcb6dda8bd30d25a55cab887fb332c04.png" alt="fcb6dda8bd30d25a55cab887fb332c04"></p>
<p>举例</p>
<p><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/image-20241215152052099.png" alt="image-20241215152052099"></p>
<h3 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h3><p>B树，又称多路平衡查找树，B树中所有结点的孩子个数的最大值称为B树的阶，通常用m表示。<br><strong>B树是所有结点的平衡因子均等于0的多路平衡查找树。</strong></p>
<p>下图所示的B树中所有结点的最大孩子数m = 5，因此它是一棵5阶B树，在m mm阶B树中结点最多可以有m个孩子。可以借助该实例来分析上述性质：<br><img src="/2024/12/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%9F%A5%E6%89%BE/91938989f25f6c683f053d6b71647591.png" alt="91938989f25f6c683f053d6b71647591"></p>
<p><a href="https://www.bilibili.com/video/BV1JU411d7iY?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">B树(B-树) - 删除_哔哩哔哩_bilibili</a></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://blog.csdn.net/Real_Fool_/article/details/114359564">数据结构：查找(Search)【详解】_index.search返回什么结构-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——树和二叉树</title>
    <url>/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/</url>
    <content><![CDATA[<h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><h2 id="树的基本术语"><a href="#树的基本术语" class="headerlink" title="树的基本术语"></a>树的基本术语</h2><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/d72517fa6b39dc28ff37c0942cda4df1.png" alt="d72517fa6b39dc28ff37c0942cda4df1"></p>
<ol>
<li><p>结点的度和树的度</p>
<p>树中结点的最大度数称为<strong>树的度</strong>。如结点B的度为2,结点D的度为3,树的度为3。</p>
</li>
<li><p>孩子，双亲，兄弟结点</p>
</li>
<li><p>路径和路径长度</p>
<p>树中两个结点之间的<strong>路径</strong>是由这两个结点之间所经过的结点序列构成的,而<strong>路径长度</strong>是路径上所经过的边的个数。<br>注意:由于树中的分支是有向的,即从双亲指向孩子,所以树中的路径是从上向下的,同一双亲的两个孩子之间不存在路径。</p>
</li>
<li><p>子孙结点和祖先结点</p>
<p>根A到结点K的唯一路径上的任意结点,称为结点K的<strong>祖先</strong>。如结点B是结点K的祖先,而结点K是结点B的<strong>子孙</strong>。</p>
</li>
<li><p>结点的层次和树的高度</p>
<p><strong>结点的层次</strong>从树根开始定义,根结点为第1层,它的子结点为第2层,以此类推。</p>
</li>
<li><p>有序树和无序树</p>
<p>树中结点的各子树从左到右是有次序的,不能互换,称该树为<strong>有序树</strong>,否则称为<strong>无序树</strong>。</p>
</li>
<li><p>森林</p>
<p><strong>森林</strong>是m (m≥0)棵互不相交的树的集合。</p>
</li>
</ol>
<h2 id="树的存储结构"><a href="#树的存储结构" class="headerlink" title="树的存储结构"></a>树的存储结构</h2><h3 id="多叉链表表示法"><a href="#多叉链表表示法" class="headerlink" title="多叉链表表示法"></a>多叉链表表示法</h3><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/fasdfa.png" alt="fasdfa"></p>
<p>采用多叉链表表示法存储树，许多算法设计可以直接参照二叉树的二叉链表结构的算法。其优点是简单易学，缺点是存在许多指针域的浪费。设树中结点数是n，树的度是k，则共使用了n×k个指针域，而这其中只有n -1个非空指针城。</p>
<h3 id="孩子链表表示法"><a href="#孩子链表表示法" class="headerlink" title="孩子链表表示法"></a>孩子链表表示法</h3><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/safsafsxcx.png" alt="safsafsxcx"></p>
<p>当树的度较大时，CTree类可以减少多叉链表表示法的空间浪费。但是，当插入、删除结点时，却会涉及多个孩子链表的调整,还有可能造成存储空间的再分配，因此时间复杂度较大。在CTree类中，利用孩子链表可以方便、快捷地查找指定结点的孩子结点。但是，查找双亲结点则需遍历所有的孩子链表,因此效率就低得多了。</p>
<h3 id="双亲表示法"><a href="#双亲表示法" class="headerlink" title="双亲表示法"></a>双亲表示法</h3><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/sadfas.png" alt="sadfas"></p>
<p>在PTree类中，不仅利用结点的双亲指针域很容易找到其双亲结点，而且查找其所有祖先结点也非常便利、高效。若需要查找指定结点的孩子或子孙结点，则需遍历整个树的存储空间，效率就低得多了。</p>
<h3 id="孩子兄弟表示法"><a href="#孩子兄弟表示法" class="headerlink" title="孩子兄弟表示法"></a>孩子兄弟表示法</h3><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/dasfgae.png" alt="dasfgae"></p>
<p>因为孩子兄弟表示法建立起了树和二叉树之间的对应关系，所以常常将其称为树的二叉树表示法。相比树的其他存储结构，孩子兄弟表示法既简化了结构，又可以将许多二叉树的优秀算法移植到树结构的应用中来，因此具有很好的学习、应用价值。</p>
<h2 id="树的操作算法"><a href="#树的操作算法" class="headerlink" title="树的操作算法"></a>树的操作算法</h2><h3 id="构造算法"><a href="#构造算法" class="headerlink" title="构造算法"></a>构造算法</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 构造函数</span></span><br><span class="line">    <span class="built_in">CSTree</span>(vector&lt;pair&lt;T, T&gt;&gt;&amp; ps) &#123;</span><br><span class="line">        <span class="keyword">if</span> (ps.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            root = <span class="literal">nullptr</span>;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 创建根节点</span></span><br><span class="line">        root = <span class="keyword">new</span> <span class="built_in">CSNode</span>&lt;T&gt;(ps[<span class="number">0</span>].first);</span><br><span class="line">        root-&gt;firstchild = <span class="literal">nullptr</span>;</span><br><span class="line">        root-&gt;nextsibling = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 插入其他节点</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; ps.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="built_in">InsertNode</span>(ps[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 插入节点</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">InsertNode</span><span class="params">(pair&lt;T, T&gt;&amp; p)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 创建新节点</span></span><br><span class="line">        CSNode&lt;T&gt;* child = <span class="keyword">new</span> <span class="built_in">CSNode</span>&lt;T&gt;(p.second);</span><br><span class="line">        child-&gt;firstchild = <span class="literal">nullptr</span>;</span><br><span class="line">        child-&gt;nextsibling = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到父节点</span></span><br><span class="line">        CSNode&lt;T&gt;* parent = <span class="built_in">Search</span>(root, p.first);</span><br><span class="line">        <span class="keyword">if</span> (!parent) &#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;Parent node &quot;</span> &lt;&lt; p.first &lt;&lt; <span class="string">&quot; not found!&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 若父节点无子节点，将新节点作为第一个子节点</span></span><br><span class="line">        <span class="keyword">if</span> (parent-&gt;firstchild == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">            parent-&gt;firstchild = child;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 若父节点已有子节点，将新节点作为最后一个子节点</span></span><br><span class="line">            CSNode&lt;T&gt;* temp = parent-&gt;firstchild;</span><br><span class="line">            <span class="keyword">while</span> (temp-&gt;nextsibling != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                temp = temp-&gt;nextsibling;</span><br><span class="line">            &#125;</span><br><span class="line">            temp-&gt;nextsibling = child;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h3 id="计算树的高度"><a href="#计算树的高度" class="headerlink" title="计算树的高度"></a>计算树的高度</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计算指定节点子树的高度</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> CSTree&lt;T&gt;::<span class="built_in">Height</span>(CSNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">nullptr</span>)  <span class="comment">// 如果节点为空，返回高度 0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> maxheight = <span class="number">0</span>;  <span class="comment">// 初始化子树的最大高度为 0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历所有子节点</span></span><br><span class="line">    <span class="keyword">for</span> (CSNode&lt;T&gt;* child = p-&gt;firstchild; child != <span class="literal">nullptr</span>; child = child-&gt;nextsibling) &#123;</span><br><span class="line">        <span class="type">int</span> height = <span class="built_in">Height</span>(child);  <span class="comment">// 递归计算子节点的高度</span></span><br><span class="line">        <span class="keyword">if</span> (height &gt; maxheight)      <span class="comment">// 更新最大高度</span></span><br><span class="line">            maxheight = height;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> maxheight + <span class="number">1</span>;  <span class="comment">// 当前节点的高度为子树最大高度 + 1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 外部接口：计算整棵树的高度</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> CSTree&lt;T&gt;::<span class="built_in">Height</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Height</span>(root);  <span class="comment">// 从根节点开始计算高度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="计算所有结点的度"><a href="#计算所有结点的度" class="headerlink" title="计算所有结点的度"></a>计算所有结点的度</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计算指定节点的度并递归处理其子树</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> CSTree&lt;T&gt;::<span class="built_in">Degree</span>(CSNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">nullptr</span>)  <span class="comment">// 如果节点为空，直接返回</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    p-&gt;degree = <span class="number">0</span>;  <span class="comment">// 初始化节点的度为 0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历所有子节点，统计度</span></span><br><span class="line">    <span class="keyword">for</span> (CSNode&lt;T&gt;* child = p-&gt;firstchild; child != <span class="literal">nullptr</span>; child = child-&gt;nextsibling) &#123;</span><br><span class="line">        p-&gt;degree++;  <span class="comment">// 子节点存在则度加 1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Degree</span>(p-&gt;firstchild);    <span class="comment">// 递归处理子节点的度</span></span><br><span class="line">    <span class="built_in">Degree</span>(p-&gt;nextsibling);   <span class="comment">// 递归处理兄弟节点的度</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 外部接口：计算整棵树的所有节点的度</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> CSTree&lt;T&gt;::<span class="built_in">Degree</span>() &#123;</span><br><span class="line">    <span class="built_in">Degree</span>(root);  <span class="comment">// 从根节点开始计算度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h1><h2 id="特殊的二叉树"><a href="#特殊的二叉树" class="headerlink" title="特殊的二叉树"></a>特殊的二叉树</h2><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/3ca44306b6c5f97c3544f5d091be9ac4.png" alt="3ca44306b6c5f97c3544f5d091be9ac4"></p>
<p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/a99ebdd407f8c2508597d85c610c44a7.png" alt="a99ebdd407f8c2508597d85c610c44a7"></p>
<h2 id="二叉树的性质"><a href="#二叉树的性质" class="headerlink" title="二叉树的性质"></a>二叉树的性质</h2><p>非空二叉树上的叶子结点数等于度为2的结点数加1，即$\ n{_0}=n{_1}+1$</p>
<p>因为二叉树中所有节点的度只能是 0、1、2，所以节点总数 $\ n=n{_0}+n{_1}+n{_2}$</p>
<p>其次考虑二叉树的分支总数。将二叉树的分支总数记作 m。<br>因为所有的分支是由度为 1 和度为 2 的节点发出的，所以$m=n{_1}+2×n{_2}$</p>
<p>最后，由树的性质 1，可得 $n=m+1$，即$n{_0}+n{_1}+n{_2}=n{_1}+2×n{_2}+1$</p>
<h2 id="二叉树的存储结构"><a href="#二叉树的存储结构" class="headerlink" title="二叉树的存储结构"></a>二叉树的存储结构</h2><h3 id="顺序结构"><a href="#顺序结构" class="headerlink" title="顺序结构"></a>顺序结构</h3><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/afdfa.png" alt="afdfa"></p>
<p>当二叉树单分支节点较多，高度变化较大时，空间浪费现象惊人</p>
<h3 id="链式结构"><a href="#链式结构" class="headerlink" title="链式结构"></a>链式结构</h3><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/adsfgad.png" alt="adsfgad"></p>
<h2 id="二叉树的遍历"><a href="#二叉树的遍历" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h2><p>前序遍历：根左右</p>
<p>中序遍历：左根右</p>
<p>后序遍历：左右根</p>
<p>先序遍历算法如下</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> BiTree&lt;T&gt;::<span class="built_in">PreOrder</span>(BiNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span>;             <span class="comment">// ① 若二叉树为空，则遍历结束</span></span><br><span class="line">    cout &lt;&lt; p-&gt;data;        <span class="comment">// ② 访问当前结点</span></span><br><span class="line">    <span class="built_in">PreOrder</span>(p-&gt;lchild);    <span class="comment">// ③ 先序遍历当前结点的左子树</span></span><br><span class="line">    <span class="built_in">PreOrder</span>(p-&gt;rchild);    <span class="comment">// ④ 先序遍历当前结点的右子树</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> BiTree&lt;T&gt;::<span class="built_in">PreOrder</span>() &#123;</span><br><span class="line">    <span class="built_in">PreOrder</span>(root);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>层序遍历：利用队列</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> BiTree&lt;T&gt;::<span class="built_in">LevelOrder</span>() &#123;</span><br><span class="line">    <span class="keyword">if</span> (root == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span>;             <span class="comment">// ① 若二叉树为空，则遍历结束</span></span><br><span class="line"></span><br><span class="line">    LinkQueue&lt;BiNode&lt;T&gt;*&gt; Q;    <span class="comment">// 定义一个队列存储节点指针</span></span><br><span class="line">    Q.<span class="built_in">EnQueue</span>(root);            <span class="comment">// ② 将根指针加入指针队列</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!Q.<span class="built_in">Empty</span>()) &#123;        <span class="comment">// ③ 若指针队列不空，则循环</span></span><br><span class="line">        BiNode&lt;T&gt;* p = Q.<span class="built_in">DeQueue</span>();   <span class="comment">// ④ 出队列，得到当前指针 p</span></span><br><span class="line">        cout &lt;&lt; p-&gt;data;              <span class="comment">// ④ 访问当前结点</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// ⑤ 若当前结点有左孩子，则左孩子地址进指针队列</span></span><br><span class="line">        <span class="keyword">if</span> (p-&gt;lchild != <span class="literal">NULL</span>)</span><br><span class="line">            Q.<span class="built_in">EnQueue</span>(p-&gt;lchild);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ⑤ 若当前结点有右孩子，则右孩子地址进指针队列</span></span><br><span class="line">        <span class="keyword">if</span> (p-&gt;rchild != <span class="literal">NULL</span>)</span><br><span class="line">            Q.<span class="built_in">EnQueue</span>(p-&gt;rchild);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二叉树的构造算法"><a href="#二叉树的构造算法" class="headerlink" title="二叉树的构造算法"></a>二叉树的构造算法</h2><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/sADF.png" alt="sADF"></p>
<p>先序序列是<code>abdecf</code>，带空指针标记的先序序列是<code>abd**e**cf ***</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinNode&lt;T&gt;* BinTree&lt;T&gt;::<span class="built_in">CreateByPre</span>(vector&lt;T&gt;&amp; pre, <span class="type">int</span>&amp; i) &#123;</span><br><span class="line">    T e = pre[i]; <span class="comment">// 提取当前数据</span></span><br><span class="line">    i++;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="string">&#x27;*&#x27;</span>) <span class="comment">// 若是特殊数据，返回空指针</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建新结点</span></span><br><span class="line">    BinNode&lt;T&gt;* p = <span class="keyword">new</span> BinNode&lt;T&gt;;</span><br><span class="line">    p-&gt;data = e;</span><br><span class="line">    <span class="comment">// 创建左子树</span></span><br><span class="line">    p-&gt;lchild = <span class="built_in">CreateByPre</span>(pre, i);</span><br><span class="line">    <span class="comment">// 创建右子树</span></span><br><span class="line">    p-&gt;rchild = <span class="built_in">CreateByPre</span>(pre, i);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinTree&lt;T&gt;::<span class="built_in">BinTree</span>(vector&lt;T&gt;&amp; pre) &#123;</span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>; <span class="comment">// 向量 pre 的下标变量</span></span><br><span class="line">    root = <span class="built_in">CreateByPre</span>(pre, i); <span class="comment">// 从先序序列构造二叉树</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二叉树的其他操作算法"><a href="#二叉树的其他操作算法" class="headerlink" title="二叉树的其他操作算法"></a>二叉树的其他操作算法</h2><h3 id="计算结点数"><a href="#计算结点数" class="headerlink" title="计算结点数"></a>计算结点数</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Count</span>(BiNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// 当前节点为空，返回 0</span></span><br><span class="line">    <span class="type">int</span> left = <span class="built_in">Count</span>(p-&gt;lchild);  <span class="comment">// 统计左子树节点数</span></span><br><span class="line">    <span class="type">int</span> right = <span class="built_in">Count</span>(p-&gt;rchild); <span class="comment">// 统计右子树节点数</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> + left + right;      <span class="comment">// 当前节点总数 = 左子树 + 右子树 + 当前节点</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Count</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Count</span>(root); <span class="comment">// 从根节点开始统计</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="计算高度"><a href="#计算高度" class="headerlink" title="计算高度"></a>计算高度</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Height</span>(BiNode&lt;T&gt;* p) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// 空节点高度为 0</span></span><br><span class="line">    <span class="type">int</span> left = <span class="built_in">Height</span>(p-&gt;lchild);  <span class="comment">// 左子树高度</span></span><br><span class="line">    <span class="type">int</span> right = <span class="built_in">Height</span>(p-&gt;rchild); <span class="comment">// 右子树高度</span></span><br><span class="line">    <span class="keyword">return</span> (left &gt; right ? left : right) + <span class="number">1</span>; <span class="comment">// 树高度为左右子树最大高度 + 1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">int</span> BiTree&lt;T&gt;::<span class="built_in">Height</span>() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Height</span>(root); <span class="comment">// 从根节点开始计算树高度</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="查找结点"><a href="#查找结点" class="headerlink" title="查找结点"></a>查找结点</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinNode&lt;T&gt;* BiTree&lt;T&gt;::<span class="built_in">Search</span>(BinNode&lt;T&gt;* p, T e) &#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;  <span class="comment">// 查找失败</span></span><br><span class="line">    <span class="keyword">if</span> (p-&gt;data == e)</span><br><span class="line">        <span class="keyword">return</span> p;     <span class="comment">// 查找成功，返回节点指针</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在左子树中递归查找</span></span><br><span class="line">    BinNode&lt;T&gt;* q = <span class="built_in">Search</span>(p-&gt;lchild, e);</span><br><span class="line">    <span class="keyword">if</span> (q != <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> q; <span class="comment">// 若在左子树中找到，返回结果</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在右子树中递归查找</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Search</span>(p-&gt;rchild, e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line">BinNode&lt;T&gt;* BiTree&lt;T&gt;::<span class="built_in">Search</span>(T e) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Search</span>(root, e); <span class="comment">// 从根节点开始查找</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="线索二叉树"><a href="#线索二叉树" class="headerlink" title="线索二叉树"></a>线索二叉树</h2><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/asfafs.png" alt="asfafs"></p>
<h1 id="哈夫曼树"><a href="#哈夫曼树" class="headerlink" title="哈夫曼树"></a>哈夫曼树</h1><p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/wqqwr.png" alt="wqqwr"></p>
<p><img src="/2024/11/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A0%91%E5%92%8C%E4%BA%8C%E5%8F%89%E6%A0%91/qetqt.png" alt="qetqt"></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://blog.csdn.net/Real_Fool_/article/details/113930623">数据结构：树(Tree)【详解】_数据结构 树-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——矩阵压缩</title>
    <url>/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/</url>
    <content><![CDATA[<h1 id="数据结构——矩阵压缩"><a href="#数据结构——矩阵压缩" class="headerlink" title="数据结构——矩阵压缩"></a>数据结构——矩阵压缩</h1><h2 id="特殊矩阵的压缩"><a href="#特殊矩阵的压缩" class="headerlink" title="特殊矩阵的压缩"></a>特殊矩阵的压缩</h2><h3 id="对称矩阵"><a href="#对称矩阵" class="headerlink" title="对称矩阵"></a>对称矩阵</h3><p>关键点：</p>
<ul>
<li>是选择上三角行主序存储还是下三角列主序存储</li>
<li>组的下标是从1开始还是0开始存储</li>
</ul>
<p><img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019163345497.png" alt="image-20241019163345497"></p>
<p><img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019163357393.png" alt="image-20241019163357393"></p>
<h3 id="三件矩阵"><a href="#三件矩阵" class="headerlink" title="三件矩阵"></a>三件矩阵</h3><p>注意点：</p>
<ul>
<li><p>理解下三角列序和下三角行序的差异，后者是计算<code>a[i][j]</code>后面的元素数量和，再用总数减去后面，得到前面元素数量；前者是直接计算<code>a[i][j]</code>前面元素数量</p>
</li>
<li><p>一位数组空间为<code>n(n+1)/2+1</code>，数组最后一位为0</p>
</li>
</ul>
<p><img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019162703259.png" alt="image-20241019162703259"></p>
<p><img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019162719970.png" alt="image-20241019162719970"></p>
<h3 id="对角矩阵"><a href="#对角矩阵" class="headerlink" title="对角矩阵"></a>对角矩阵</h3><p><img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/image-20241019163805806.png" alt="image-20241019163805806"></p>
<h2 id="稀疏矩阵的压缩存储"><a href="#稀疏矩阵的压缩存储" class="headerlink" title="稀疏矩阵的压缩存储"></a>稀疏矩阵的压缩存储</h2><h3 id="三元组表"><a href="#三元组表" class="headerlink" title="三元组表"></a>三元组表</h3><p><img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_164539.jpg" alt="IMG_20241019_164539"></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 用于表示稀疏矩阵中非零元素的结构体</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Triplet</span> &#123;</span><br><span class="line">    <span class="type">int</span> row;</span><br><span class="line">    <span class="type">int</span> col;</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于表示稀疏矩阵的类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SparseMatrix</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> rows;</span><br><span class="line">    <span class="type">int</span> cols;</span><br><span class="line">    vector&lt;Triplet&gt; triplets; </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 构造函数，用于初始化矩阵的维度</span></span><br><span class="line">    <span class="built_in">SparseMatrix</span>(<span class="type">int</span> rows, <span class="type">int</span> cols) : <span class="built_in">rows</span>(rows), <span class="built_in">cols</span>(cols) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加非零元素到矩阵的方法</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">add_element</span><span class="params">(<span class="type">int</span> row, <span class="type">int</span> col, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (value != <span class="number">0</span>) &#123;</span><br><span class="line">            triplets.<span class="built_in">push_back</span>(&#123; row, col, value &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 以三元组形式显示稀疏矩阵的方法</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">display</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; triplet : triplets) &#123;</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;行: &quot;</span> &lt;&lt; triplet.row &lt;&lt; <span class="string">&quot;, 列: &quot;</span> &lt;&lt; triplet.col &lt;&lt; <span class="string">&quot;, 值: &quot;</span> &lt;&lt; triplet.value &lt;&lt; endl;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将稀疏矩阵转换为密集矩阵表示的方法</span></span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">to_dense</span>() <span class="type">const</span> &#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">dense_matrix</span>(rows, <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(cols, <span class="number">0</span>));</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; triplet : triplets) &#123;</span><br><span class="line">            dense_matrix[triplet.row][triplet.col] = triplet.value;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dense_matrix;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="朴素转置"><a href="#朴素转置" class="headerlink" title="朴素转置"></a>朴素转置</h4><p><img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_181951.jpg" alt="IMG_20241019_181951"></p>
<p>因为矩阵A的列是矩阵B的行，所以以此遍历A的列，将其存入新的三元组顺序表</p>
<p>不能直接交换i和j的值的原因：因为三元组表是行优先顺序，如果直接交换就是列优先</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;Triplet&gt; <span class="title">transposeTripletMatrix</span><span class="params">(<span class="type">const</span> vector&lt;Triplet&gt;&amp; tripletMatrix)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取原始三元组矩阵的行数、列数和非零元素个数信息</span></span><br><span class="line">    <span class="type">int</span> rows = tripletMatrix[<span class="number">0</span>].row;</span><br><span class="line">    <span class="type">int</span> cols = tripletMatrix[<span class="number">0</span>].col;</span><br><span class="line">    <span class="type">int</span> numNonZero = tripletMatrix[<span class="number">0</span>].value;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建转置矩阵的三元组顺序表</span></span><br><span class="line">    vector&lt;Triplet&gt; transposedMatrix;</span><br><span class="line">    transposedMatrix.<span class="built_in">push_back</span>(&#123;cols, rows, numNonZero&#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过列的顺序插入非零元素到转置矩阵中</span></span><br><span class="line">    <span class="keyword">if</span> (numNonZero &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> col = <span class="number">0</span>; col &lt; cols; ++col) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= numNonZero; ++i) &#123;</span><br><span class="line">                <span class="keyword">if</span> (tripletMatrix[i].col == col) &#123;</span><br><span class="line">                    transposedMatrix.<span class="built_in">push_back</span>(&#123;tripletMatrix[i].col, tripletMatrix[i].row, tripletMatrix[i].value&#125;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transposedMatrix;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="快速转置"><a href="#快速转置" class="headerlink" title="快速转置"></a>快速转置</h4><p><img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_235512.jpg" alt="IMG_20241019_235512"></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;Triplet&gt; <span class="title">fastTransposeTripletMatrix</span><span class="params">(<span class="type">const</span> vector&lt;Triplet&gt;&amp; tripletMatrix)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取原始三元组矩阵的行数、列数和非零元素个数信息</span></span><br><span class="line">    <span class="type">int</span> rows = tripletMatrix[<span class="number">0</span>].row;</span><br><span class="line">    <span class="type">int</span> cols = tripletMatrix[<span class="number">0</span>].col;</span><br><span class="line">    <span class="type">int</span> numNonZero = tripletMatrix[<span class="number">0</span>].value;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建转置矩阵的三元组顺序表</span></span><br><span class="line">    <span class="function">vector&lt;Triplet&gt; <span class="title">transposedMatrix</span><span class="params">(numNonZero + <span class="number">1</span>)</span></span>;</span><br><span class="line">    transposedMatrix[<span class="number">0</span>] = &#123;cols, rows, numNonZero&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (numNonZero &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 初始化每一列中非零元素的个数和位置</span></span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">count</span><span class="params">(cols, <span class="number">0</span>)</span></span>;</span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">index</span><span class="params">(cols + <span class="number">1</span>, <span class="number">2</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 统计每一列中非零元素的个数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= numNonZero; ++i) &#123;</span><br><span class="line">            count[tripletMatrix[i].col]++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算每一列在转置矩阵中的起始位置</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; cols; ++i) &#123;</span><br><span class="line">            index[i + <span class="number">1</span>] = index[i] + count[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 填充转置矩阵的三元组顺序表</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= numNonZero; ++i) &#123;</span><br><span class="line">            <span class="type">int</span> col = tripletMatrix[i].col;</span><br><span class="line">            <span class="type">int</span> pos = index[col];</span><br><span class="line">            transposedMatrix[pos] = &#123;tripletMatrix[i].col, tripletMatrix[i].row, tripletMatrix[i].value&#125;;</span><br><span class="line">            index[col]++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> transposedMatrix;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="十字链表"><a href="#十字链表" class="headerlink" title="十字链表"></a>十字链表</h3><p><img src="/2024/10/19/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%9F%A9%E9%98%B5%E5%8E%8B%E7%BC%A9/IMG_20241019_170755.jpg" alt="IMG_20241019_170755"></p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>类中定义了两个链表数组，用于存储每一行和每一列的头节点指针</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 节点定义</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">OLNode</span> &#123;</span><br><span class="line">    <span class="type">int</span> row;         <span class="comment">// 行号</span></span><br><span class="line">    <span class="type">int</span> col;         <span class="comment">// 列号</span></span><br><span class="line">    <span class="type">int</span> value;       <span class="comment">// 元素值</span></span><br><span class="line">    OLNode* right;   <span class="comment">// 指向右边的节点</span></span><br><span class="line">    OLNode* down;    <span class="comment">// 指向下面的节点</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">OLNode</span>(<span class="type">int</span> r, <span class="type">int</span> c, <span class="type">int</span> val) : <span class="built_in">row</span>(r), <span class="built_in">col</span>(c), <span class="built_in">value</span>(val), <span class="built_in">right</span>(<span class="literal">nullptr</span>), <span class="built_in">down</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 十字链表类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OrthogonalList</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">int</span> rows, cols;</span><br><span class="line">    vector&lt;OLNode*&gt; row_heads; <span class="comment">// 行头链表数组</span></span><br><span class="line">    vector&lt;OLNode*&gt; col_heads; <span class="comment">// 列头链表数组</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h4><p><code>row_heads.resize(rows, nullptr);</code> 是用于调整 <code>row_heads</code> 向量的大小，使其包含 <code>rows</code> 个元素，并将每个元素初始化为 <code>nullptr</code>。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">OrthogonalList</span>(<span class="type">int</span> rows, <span class="type">int</span> cols) : <span class="built_in">rows</span>(rows), <span class="built_in">cols</span>(cols) &#123;</span><br><span class="line">        row_heads.<span class="built_in">resize</span>(rows, <span class="literal">nullptr</span>);</span><br><span class="line">        col_heads.<span class="built_in">resize</span>(cols, <span class="literal">nullptr</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="插入函数"><a href="#插入函数" class="headerlink" title="插入函数"></a>插入函数</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 插入元素</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(<span class="type">int</span> r, <span class="type">int</span> c, <span class="type">int</span> value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (value == <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查是否已存在节点，若存在则更新值</span></span><br><span class="line">    OLNode* current = row_heads[r];</span><br><span class="line">    <span class="keyword">while</span> (current &amp;&amp; current-&gt;col &lt; c) &#123;</span><br><span class="line">        current = current-&gt;right;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (current &amp;&amp; current-&gt;col == c) &#123;</span><br><span class="line">        current-&gt;value = value; <span class="comment">// 更新已有节点的值</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OLNode* newNode = <span class="keyword">new</span> <span class="built_in">OLNode</span>(r, c, value);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 插入到行链表中</span></span><br><span class="line">    <span class="keyword">if</span> (!row_heads[r]) &#123;</span><br><span class="line">        <span class="comment">//如果该行没有头节点，则成为该行头节点</span></span><br><span class="line">        row_heads[r] = newNode;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        current = row_heads[r];</span><br><span class="line">        OLNode* prev = <span class="literal">nullptr</span>;</span><br><span class="line">        <span class="comment">//current向下遍历，直到遍历到该行链表的最后一个，或者到达插入的列的位置</span></span><br><span class="line">        <span class="comment">//注意，该插入方式如果遇到该位置已有节点存在的情况，会用新节点覆盖旧节点</span></span><br><span class="line">        <span class="keyword">while</span> (current &amp;&amp; current-&gt;col &lt; c) &#123;</span><br><span class="line">            prev = current;</span><br><span class="line">            current = current-&gt;right;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//若prev存在，则说明头节点不为零，若为空则说明插在链表最前面</span></span><br><span class="line">        <span class="keyword">if</span> (prev) &#123;</span><br><span class="line">            prev-&gt;right = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            row_heads[r] = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        newNode-&gt;right = current;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 插入到列链表中</span></span><br><span class="line">    <span class="keyword">if</span> (!col_heads[c]) &#123;</span><br><span class="line">        col_heads[c] = newNode;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        current = col_heads[c];</span><br><span class="line">        OLNode* prev = <span class="literal">nullptr</span>;</span><br><span class="line">        <span class="keyword">while</span> (current &amp;&amp; current-&gt;row &lt; r) &#123;</span><br><span class="line">            prev = current;</span><br><span class="line">            current = current-&gt;down;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (prev) &#123;</span><br><span class="line">            prev-&gt;down = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            col_heads[c] = newNode;</span><br><span class="line">        &#125;</span><br><span class="line">        newNode-&gt;down = current;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="打印函数"><a href="#打印函数" class="headerlink" title="打印函数"></a>打印函数</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">   <span class="comment">// 打印矩阵</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; rows; ++i) &#123;</span><br><span class="line">            OLNode* current = row_heads[i];</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; cols; ++j) &#123;</span><br><span class="line">                <span class="keyword">if</span> (current &amp;&amp; current-&gt;col == j) &#123;</span><br><span class="line">                    cout &lt;&lt; current-&gt;value &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">                    current = current-&gt;right;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    cout &lt;&lt; <span class="string">&quot;0 &quot;</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            cout &lt;&lt; endl;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.bilibili.com/video/BV1WM411A7YQ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【数据结构】特殊矩阵的压缩存储/对称矩阵/三角矩阵/对角矩阵（含经典题讲解）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1a8yKYXELM/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【每个人都听得懂的】稀疏矩阵的快速转置算法_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——类模板</title>
    <url>/2024/10/24/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%B1%BB%E6%A8%A1%E6%9D%BF/</url>
    <content><![CDATA[<h1 id="数据结构——类模板"><a href="#数据结构——类模板" class="headerlink" title="数据结构——类模板"></a>数据结构——类模板</h1><h2 id="类模板"><a href="#类模板" class="headerlink" title="类模板"></a>类模板</h2><p>类模板是一种用于创建通用类的机制，它可以让程序员编写一次类，然后让它适用于<strong>多种数据类型</strong>，在实际编程中非常实用。</p>
<p>优点：使用类模板时，可以为同一个类使用不同的数据类型，这使得代码更加灵活。例如，一个通用的栈类模板可以用于<code>int</code>、<code>double</code>、<code>char</code>等不同类型，而不需要为每种类型分别定义栈类。</p>
<h3 id="定义方式"><a href="#定义方式" class="headerlink" title="定义方式"></a>定义方式</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyStack</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 构造函数、析构函数、入栈、出栈等函数</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    T* data;</span><br><span class="line">    <span class="type">int</span> top;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><code>template</code> 关键字用于声明类模板</p>
<h3 id="函数声明与定义"><a href="#函数声明与定义" class="headerlink" title="函数声明与定义"></a>函数声明与定义</h3><h4 id="类内定义"><a href="#类内定义" class="headerlink" title="类内定义"></a>类内定义</h4><p>如果是在类内进行函数定义，则不需添加<code>template&lt;&gt;</code>，如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 类模板</span><br><span class="line">template &lt;class T1,class T2&gt;</span><br><span class="line">class Data &#123;</span><br><span class="line">private:</span><br><span class="line">	T1 a;</span><br><span class="line">	T2 b;</span><br><span class="line">public:</span><br><span class="line">	Data(T1 a, T2 b)&#123;</span><br><span class="line">		this-&gt;a = a;</span><br><span class="line">		this-&gt;b = b;</span><br><span class="line">		cout &lt;&lt; &quot;Data的有参构造&quot; &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line">	void showData()</span><br><span class="line">	&#123;</span><br><span class="line">		cout &lt;&lt; a &lt;&lt; &quot; &quot; &lt;&lt; b &lt;&lt;endl;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="类外定义"><a href="#类外定义" class="headerlink" title="类外定义"></a>类外定义</h4><p>如果成员函数在类外定义</p>
<ul>
<li>在每个成员函数前必须添加<code>template&lt;&gt;</code>。</li>
<li>作用域需要添加<code>&lt;&gt;</code>修饰。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T1</span>,<span class="keyword">class</span> <span class="title class_">T2</span>&gt;</span><br><span class="line"><span class="type">void</span> Data&lt;T1,T2&gt;::<span class="built_in">showData</span>()</span><br><span class="line">&#123;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="友元函数"><a href="#友元函数" class="headerlink" title="友元函数"></a>友元函数</h4><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//类内声明</span></span><br><span class="line"><span class="function"><span class="keyword">friend</span> <span class="type">void</span> <span class="title">MyPrint</span><span class="params">(Data&lt;T3, T4&gt; &amp;ob)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//类外定义</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T3,<span class="keyword">typename</span> T4&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MyPrint</span><span class="params">(Data&lt;T3, T4&gt; &amp;ob)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	cout &lt;&lt; <span class="string">&quot;函数模板友元：&quot;</span> &lt;&lt; ob.a &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; ob.b &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="模板类分文件书写问题"><a href="#模板类分文件书写问题" class="headerlink" title="模板类分文件书写问题"></a>模板类分文件书写问题</h3><h4 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h4><p>将类的声明和成员函数的定义全部写在一个.h文件中，如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _DATA_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _DATA_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 类模板</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T1</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Data</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	T1 a;</span><br><span class="line">	T2 b;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">showData</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T1</span>, <span class="keyword">class</span> <span class="title class_">T2</span>&gt;</span><br><span class="line"><span class="type">void</span> Data&lt;T1, T2&gt;::<span class="built_in">showData</span>()</span><br><span class="line">&#123;</span><br><span class="line">	cout &lt;&lt; a &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; b &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// !_DATA_H_</span></span></span><br></pre></td></tr></table></figure>
<h4 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h4><p>若将函数的定义写在.cpp文件中，main.cpp中调用时，一定要同时include”.h”和“.cpp”文件，否则编译错误</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//main.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;Data.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;Data.cpp&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">// 类模板实例化对象</span></span><br><span class="line">	</span><br><span class="line">	<span class="function">Data&lt;<span class="type">int</span>, <span class="type">char</span>&gt; <span class="title">ob2</span><span class="params">(<span class="number">100</span>,<span class="string">&#x27;A&#x27;</span>)</span></span>;</span><br><span class="line">	ob<span class="number">2.</span><span class="built_in">showData</span>();</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://blog.csdn.net/Long_xu/article/details/131500484">【035】深入理解C++类模板（最全讲解）：从基础到实战-CSDN博客</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——模式匹配KMP</title>
    <url>/2024/10/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D-KMP/</url>
    <content><![CDATA[<h1 id="数据结构——模式匹配KMP"><a href="#数据结构——模式匹配KMP" class="headerlink" title="数据结构——模式匹配KMP"></a>数据结构——模式匹配KMP</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>以前因为惰性，没有记录学习笔记的习惯，但我决定抛弃过去，从现在出发，既要有摒弃过去的决心，又要有继续前进的勇气，悟以往之不谏，知来者之可追。</p>
<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><p>对于字符串s，查找是否有子串t，并用字符串m替换</p>
<h2 id="暴力解法——BF"><a href="#暴力解法——BF" class="headerlink" title="暴力解法——BF"></a>暴力解法——BF</h2><p>具体操作步骤如下：</p>
<ol>
<li>从文本的第一个字符开始，与模式的第一个字符进行逐一比较。</li>
<li>如果模式的每个字符都与文本中的相应字符匹配，则匹配成功，返回当前匹配的位置。</li>
<li>如果某个字符不匹配，则从文本的下一个字符开始重新进行比较。</li>
<li>重复步骤1-3，直到找到匹配或文本搜索完毕。</li>
</ol>
<p>由于每次比较都要逐一对齐模式串和文本，最坏情况下的时间复杂度是 <strong>O(m * n)</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//编写替换函数</span></span><br><span class="line"><span class="function">string <span class="title">replace</span><span class="params">(string&amp; s, string&amp; t,string&amp; m, <span class="type">int</span> start)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> len1 = s.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len2 = m.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len3 = t.<span class="built_in">length</span>();</span><br><span class="line">	string temp;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; start; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		temp += s[i];</span><br><span class="line">	&#125;</span><br><span class="line">	temp += m;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = start + len3; i &lt; len1; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		temp += s[i];</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> temp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFmatching</span><span class="params">(string &amp;s, string &amp;t, string &amp;m)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> i = <span class="number">0</span>;</span><br><span class="line">	<span class="type">int</span> j = <span class="number">0</span>;</span><br><span class="line">	<span class="type">int</span> len1 = s.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span>  len2 = t.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len3 = m.<span class="built_in">length</span>();</span><br><span class="line">	<span class="keyword">while</span> (i &lt; len1)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (s[i] == t[j])</span><br><span class="line">		&#123;</span><br><span class="line">			i++;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">		&#123;</span><br><span class="line">			i = i - j + <span class="number">1</span>;</span><br><span class="line">			j = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> (j &gt;= len2)</span><br><span class="line">		&#123;</span><br><span class="line">			s = <span class="built_in">replace</span>(s, t, m, i - j);</span><br><span class="line">			len1 = s.<span class="built_in">length</span>(); <span class="comment">// 更新字符串的长度</span></span><br><span class="line">			i = i - j + len3;</span><br><span class="line">			j = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a>KMP算法</h2><h3 id="前缀和后缀"><a href="#前缀和后缀" class="headerlink" title="前缀和后缀"></a>前缀和后缀</h3><p>前缀：从字符串的 <strong>第一个字符</strong> 开始的连续子串。前缀的长度可以从0到字符串的总长度减1。注意，前缀不包括整个字符串本身。</p>
<p>后缀：从字符串的 <strong>最后一个字符</strong> 开始的连续子串。与前缀类似，后缀的长度也可以从0到字符串的总长度减1。后缀不包括整个字符串本身。</p>
<p>二者意义：简单来说，就是当前匹配的后缀与前缀相同时，便可以跳过前缀的比较，直接开始后面的比较，而next数组则记录的是最长的既是前缀又是后缀的公共子串的长度，同样也是回溯的位置</p>
<h3 id="next数组的生成"><a href="#next数组的生成" class="headerlink" title="next数组的生成"></a>next数组的生成</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">getnext</span><span class="params">(string&amp; t)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> len = t.<span class="built_in">length</span>();</span><br><span class="line">	<span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">next</span><span class="params">(len, <span class="number">0</span>)</span></span>;</span><br><span class="line">	<span class="type">int</span> i= <span class="number">0</span>;<span class="comment">//后缀</span></span><br><span class="line">	<span class="type">int</span> j = <span class="number">0</span>;<span class="comment">//前缀末尾的位置，也是前缀的长度</span></span><br><span class="line">	next[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; len; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">while</span> (j &gt; <span class="number">0</span> &amp;&amp; t[i] != t[j])</span><br><span class="line">		&#123;</span><br><span class="line">			j = next[j - <span class="number">1</span>];</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (t[i] == t[j])</span><br><span class="line">		&#123;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		next[i] = j;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>利用后缀指针i和前缀指针j，在后缀指针不断向后遍历的过程中：</p>
<ul>
<li>如果可以匹配，则前缀指针i向后移动一位</li>
<li>如果不可以匹配，则前缀指针向前回溯</li>
</ul>
<h3 id="KMP算法的匹配"><a href="#KMP算法的匹配" class="headerlink" title="KMP算法的匹配"></a>KMP算法的匹配</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">KMPmatching</span><span class="params">(string&amp; s, string&amp; t, string&amp; m)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	vector&lt;<span class="type">int</span>&gt; next = <span class="built_in">getnext</span>(t);</span><br><span class="line">	<span class="type">int</span> len1 = s.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len2 = t.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> len3 = m.<span class="built_in">length</span>();</span><br><span class="line">	<span class="type">int</span> i = <span class="number">0</span>,j = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">while</span> (i &lt; len1) &#123;</span><br><span class="line">		<span class="keyword">if</span> (s[i] == t[j]) &#123;</span><br><span class="line">			i++;</span><br><span class="line">			j++;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="keyword">if</span> (j != <span class="number">0</span>) &#123;</span><br><span class="line">				j = next[j - <span class="number">1</span>];<span class="comment">//向前回溯</span></span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span> &#123;</span><br><span class="line">				i++;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 完成匹配后进行替换</span></span><br><span class="line">		<span class="keyword">if</span> (j == len2) &#123;</span><br><span class="line">			s = <span class="built_in">replace</span>(s, t, m, i - j);</span><br><span class="line">			len1 = s.<span class="built_in">length</span>(); <span class="comment">// 更新字符串的长度</span></span><br><span class="line">			i = i - j + m.<span class="built_in">length</span>(); <span class="comment">// 从替换后的新位置继续查找</span></span><br><span class="line">			j = <span class="number">0</span>; <span class="comment">// 重置 j 以重新开始匹配</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h3><p>注意更新<code>s</code>字符串的长度，每次替换后，<code>s</code>字符串都会变化，需要进行更新，否则运行是会造成溢出</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.bilibili.com/video/BV1PD4y1o7nd?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">帮你把KMP算法学个通透！（理论篇）_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1M5411j7Xx?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">帮你把KMP算法学个通透！（求next数组代码篇）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——线性表</title>
    <url>/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%BA%BF%E6%80%A7%E8%A1%A8/</url>
    <content><![CDATA[<h1 id="数据结构——线性表"><a href="#数据结构——线性表" class="headerlink" title="数据结构——线性表"></a>数据结构——线性表</h1><h2 id="线性表的定义"><a href="#线性表的定义" class="headerlink" title="线性表的定义"></a>线性表的定义</h2><p><strong>线性表（List）：零个或多个数据元素的有限序列。</strong></p>
<p><img src="/2024/10/26/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E7%BA%BF%E6%80%A7%E8%A1%A8/c8b3abeb72098a922a9ac4f6ff62f563.png" alt="c8b3abeb72098a922a9ac4f6ff62f563"></p>
<h3 id="顺序存储结构"><a href="#顺序存储结构" class="headerlink" title="顺序存储结构"></a>顺序存储结构</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> SEQLIST_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SEQLIST_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 模板类定义，表示顺序表</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="type">int</span> MaxSize&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SeqList</span> &#123;</span><br><span class="line">    T data[MaxSize];  <span class="comment">// 存储顺序表数据的数组</span></span><br><span class="line">    <span class="type">int</span> length;       <span class="comment">// 顺序表的长度</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<h3 id="链式存储结构"><a href="#链式存储结构" class="headerlink" title="链式存储结构"></a>链式存储结构</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> LINKLIST_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LINKLIST_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">    T data;</span><br><span class="line">    Node&lt;T&gt;* next;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinkList</span> &#123;</span><br><span class="line">    Node&lt;T&gt;* head;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// LINKLIST_H</span></span></span><br></pre></td></tr></table></figure>
<h2 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h2><p><a href="https://www.runoob.com/data-structures/merge-sort.html#:~:text=归并排序（Merge sort）是建立在归并操作上的一种有效、稳定的排序算法，该算法是采用分治法 (Divide,and Conquer）的一个非常典型的应用。 将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。 若将两个有序表合并成一个有序表，称为二路归并。">归并排序 | 菜鸟教程</a></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 友元函数：合并两个有序顺序表</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>, <span class="type">int</span> MaxSize1, <span class="type">int</span> MaxSize2&gt;</span><br><span class="line"><span class="function">SeqList&lt;T, MaxSize1 + MaxSize2&gt; <span class="title">Merge</span><span class="params">(<span class="type">const</span> SeqList&lt;T, MaxSize1&gt;&amp; list1, <span class="type">const</span> SeqList&lt;T, MaxSize2&gt;&amp; list2)</span> </span>&#123;</span><br><span class="line">    SeqList&lt;T, MaxSize1 + MaxSize2&gt; MergedList;  <span class="comment">// 创建一个新的顺序表</span></span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, n = <span class="number">0</span>;                    <span class="comment">// 定义三个指针，分别表示 list1、list2 和合并表的当前索引</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取两个顺序表的长度</span></span><br><span class="line">    <span class="type">int</span> length1 = list<span class="number">1.l</span>ength;</span><br><span class="line">    <span class="type">int</span> length2 = list<span class="number">2.l</span>ength;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 合并两个有序顺序表</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; length1 &amp;&amp; j &lt; length2) &#123;</span><br><span class="line">        <span class="keyword">if</span> (list<span class="number">1.</span>data[i] &lt;= list<span class="number">2.</span>data[j]) &#123;</span><br><span class="line">            MergedList.data[n++] = list<span class="number">1.</span>data[i++];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            MergedList.data[n++] = list<span class="number">2.</span>data[j++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将 list1 中剩余的元素插入到 MergedList 中</span></span><br><span class="line">    <span class="keyword">while</span> (i &lt; length1) &#123;</span><br><span class="line">        MergedList.data[n++] = list<span class="number">1.</span>data[i++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将 list2 中剩余的元素插入到 MergedList 中</span></span><br><span class="line">    <span class="keyword">while</span> (j &lt; length2) &#123;</span><br><span class="line">        MergedList.data[n++] = list<span class="number">2.</span>data[j++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    MergedList.length = n;  <span class="comment">// 设置合并后的顺序表长度</span></span><br><span class="line">    <span class="keyword">return</span> MergedList;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>最优化方法——期末复习</title>
    <url>/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/</url>
    <content><![CDATA[<p><a href="https://www.bilibili.com/video/BV1uP411K7Hf?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">最优化理论与方法-对偶线性规划（例题分析）_哔哩哔哩_bilibili</a></p>
<h3 id="复习笔记"><a href="#复习笔记" class="headerlink" title="复习笔记"></a>复习笔记</h3><p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120458.jpg" alt="IMG_20250624_120458"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120516.jpg" alt="IMG_20250624_120516"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120523.jpg" alt="IMG_20250624_120523"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120527.jpg" alt="IMG_20250624_120527"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120534.jpg" alt="IMG_20250624_120534"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120539.jpg" alt="IMG_20250624_120539"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120546.jpg" alt="IMG_20250624_120546"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120550.jpg" alt="IMG_20250624_120550"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120557.jpg" alt="IMG_20250624_120557"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120600.jpg" alt="IMG_20250624_120600"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120611.jpg" alt="IMG_20250624_120611"></p>
<p><img src="/2025/06/18/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%80%E4%BC%98%E5%8C%96/%E6%9C%80%E4%BC%98%E5%8C%96%E6%9C%9F%E6%9C%AB/IMG_20250624_120607.jpg" alt="IMG_20250624_120607"></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>最优化方法</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>最优化方法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——决策树</title>
    <url>/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><h3 id="什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？"><a href="#什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？" class="headerlink" title="什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？"></a>什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/hw_h_82p6lenbyhkws867e413c0614d3.png" alt="hw_h_82p6lenbyhkws867e413c0614d3"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153252.jpg" alt="IMG_20250329_153252"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153259.jpg" alt="IMG_20250329_153259"></p>
<h3 id="什么是交叉验证法？有什么用途？"><a href="#什么是交叉验证法？有什么用途？" class="headerlink" title="什么是交叉验证法？有什么用途？"></a>什么是交叉验证法？有什么用途？</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153307.jpg" alt="IMG_20250329_153307"></p>
<h3 id="什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？"><a href="#什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？" class="headerlink" title="什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？"></a>什么是过拟合（overfitting）？什么情况下可能发生过拟合？采取什么措施有助于消除过拟合？</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/IMG_20250329_153310.jpg" alt="IMG_20250329_153310"></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构——课设</title>
    <url>/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/</url>
    <content><![CDATA[<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><ol>
<li>编程实现希尔、快速、堆排序、归并排序算法。要求随机产生10000个数据存入磁盘文件，然后读入数据文件，分别采用不同的排序方法进行排序，并将结果存入文件中。</li>
<li>N（N&gt;10）个居民区之间需要铺设煤气管道。假设任意两个居民区之间都可以铺设煤气管道，但代价不同。要求事先将任意两个居民区之间铺设煤气管道的代价存入磁盘文件中。设计一个最佳方案使得这N个居民区之间铺设煤气管道所需代价最小，并将结果以图形方式在屏幕上输出。</li>
</ol>
<h1 id="题目一"><a href="#题目一" class="headerlink" title="题目一"></a>题目一</h1><h2 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h2><p><strong>希尔排序</strong>：希尔排序是一种基于插入排序的排序算法，通过按一定步长将待排序的元素分组，对每组内的元素进行插入排序，不断缩小步长，最终实现整体排序。希尔排序的时间复杂度依赖于步长的选择，最坏情况下时间复杂度为O(n^2)，最好的情况下接近O(nlogn)。</p>
<p><strong>快速排序</strong>：快速排序是一种分治法思想的排序算法，选择一个基准元素，将待排序的数组分为左右两部分，左侧部分的元素都小于基准元素，右侧部分的元素都大于基准元素，然后分别对左右两部分进行递归排序。时间复杂度为O(nlogn)，最坏情况下为O(n^2)。</p>
<p><strong>堆排序</strong>：堆排序是一种选择排序的改进算法，利用堆数据结构（通常是大顶堆或小顶堆）来找到最大值或最小值，并将其移到数组的末尾，然后调整堆。时间复杂度为O(nlogn)，适合大数据量排序。</p>
<p><strong>归并排序</strong>：归并排序是一种分治法的排序算法，它将待排序的数组分为两部分，分别排序后再合并。时间复杂度为O(nlogn)，且具有稳定性。</p>
<h2 id="程序结构"><a href="#程序结构" class="headerlink" title="程序结构"></a>程序结构</h2><ol>
<li><strong>数据生成</strong>：程序首先生成10000个随机数并将其存储到文件 <code>data.txt</code> 中。</li>
<li><p><strong>排序算法实现</strong>：实现了四种排序算法：希尔排序、快速排序、堆排序和归并排序。</p>
</li>
<li><p><strong>文件操作</strong>：程序从文件中读取数据，然后使用不同的排序算法对数据进行排序，并将排序结果保存到文件中。</p>
</li>
</ol>
<h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p>程序组成</p>
<p><img src="/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/sadf.png" alt="sadf"></p>
<p>生成数据</p>
<p><img src="/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/sadffac.png" alt="sadffac"></p>
<p>排序结果<img src="/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/dasfxc.png" alt="dasfxc"></p>
<h2 id="收获与体会"><a href="#收获与体会" class="headerlink" title="收获与体会"></a>收获与体会</h2><ul>
<li>实践了不同排序算法的实现，加深了对算法效率和适用场景的理解。</li>
<li>学会了如何操作文件进行数据存储和读取，增强了文件输入输出的处理能力。</li>
</ul>
<h1 id="题目二"><a href="#题目二" class="headerlink" title="题目二"></a>题目二</h1><h2 id="算法思想描述"><a href="#算法思想描述" class="headerlink" title="算法思想描述"></a>算法思想描述</h2><p>本题使用了<strong>Kruskal算法</strong>来求解最小生成树。Kruskal算法是一种典型的贪心算法，步骤如下：</p>
<ol>
<li>先将所有的边按照权重排序。</li>
<li>从最小的边开始，逐步加入到生成树中，若加入该边不会形成环，就加入生成树，否则跳过该边。</li>
<li>使用并查集（Union-Find）数据结构来判定是否会形成环。</li>
</ol>
<p>该算法通过选择最小权重的边逐步构建最小生成树，保证了铺设煤气管道的总代价最小。</p>
<h2 id="程序结构-1"><a href="#程序结构-1" class="headerlink" title="程序结构"></a>程序结构</h2><ol>
<li><strong>文件读取</strong>：程序读取包含代价矩阵和节点坐标的文件 <code>costs.txt</code>，并根据这些信息构建图。</li>
<li><strong>并查集实现</strong>：实现了一个并查集数据结构来判断是否形成环。</li>
<li><strong>图形显示</strong>：利用图形库绘制了居民区的分布、各居民区之间的煤气管道代价以及最终的最小生成树。</li>
</ol>
<h2 id="测试结果-1"><a href="#测试结果-1" class="headerlink" title="测试结果"></a>测试结果</h2><p>通过程序实现，成功展示了根据最小生成树算法铺设的煤气管道图形，并显示了连接每个居民区的最小代价路径。图形显示了所有居民区和最小生成树路径的直观效果，确保了程序的正确性和可视化。</p>
<p><img src="/2025/02/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8A/Data%20Structure/%E8%AF%BE%E8%AE%BE/asdf.png" alt="asdf"></p>
<h2 id="收获与体会-1"><a href="#收获与体会-1" class="headerlink" title="收获与体会"></a>收获与体会</h2><ul>
<li>通过实现Kruskal算法，深入理解了最小生成树问题以及并查集的使用。</li>
<li>掌握了如何通过图形库展示算法结果，增加了对图论问题的兴趣。</li>
<li>通过实践提高了编程技巧，特别是在图形和图论方面的应用。</li>
</ul>
]]></content>
      <categories>
        <category>大二上</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>大学</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——期末复习（上）</title>
    <url>/2025/06/14/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    <content><![CDATA[<h3 id="SVM支持向量机"><a href="#SVM支持向量机" class="headerlink" title="SVM支持向量机"></a>SVM支持向量机</h3><h4 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h4><h5 id="1"><a href="#1" class="headerlink" title="1"></a>1</h5><p>关于核化软间隔支持向量机，推导目标函数的原始问题转换为对偶问题的过程、KKT条件、预测函数。</p>
<p><strong>原始问题</strong></p>
<p>软间隔SVM的目标函数为：</p>
<script type="math/tex; mode=display">
\min_{\mathbf{w}, b, \xi} \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n \xi_i</script><p>约束条件：</p>
<script type="math/tex; mode=display">
y_i (\mathbf{w}^T \phi(\mathbf{x}_i) + b) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad i=1,\dots,n</script><p>其中 $C&gt;0$ 是惩罚参数，$\xi_i$ 是松弛变量，$\phi(\cdot)$ 是特征映射。</p>
<p><strong>转化为对偶问题</strong></p>
<ol>
<li><p><strong>构造拉格朗日函数</strong>：</p>
<script type="math/tex; mode=display">
\mathcal{L}(\mathbf{w}, b, \xi, \boldsymbol{\alpha}, \boldsymbol{\beta}) = \frac{1}{2} \|\mathbf{w}\|^2 + C \sum_{i=1}^n \xi_i - \sum_{i=1}^n \alpha_i \left[y_i (\mathbf{w}^T \phi(\mathbf{x}_i) + b) - 1 + \xi_i\right] - \sum_{i=1}^n \beta_i \xi_i</script><p>其中 $\alpha_i \geq 0, \beta_i \geq 0$ 是拉格朗日乘子。</p>
</li>
<li><p><strong>对原始变量求偏导并令其为零</strong>：</p>
</li>
</ol>
<ul>
<li>对 $\mathbf{w}$ 求导：<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}}{\partial \mathbf{w}} = \mathbf{w} - \sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i) = 0 \quad \Rightarrow \mathbf{w} = \sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i)</script></li>
<li>对 $b$ 求导：<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}}{\partial b} = -\sum_{i=1}^n \alpha_i y_i = 0 \quad \Rightarrow \sum_{i=1}^n \alpha_i y_i = 0</script></li>
<li>对 $\xi_i$ 求导：<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}}{\partial \xi_i} = C - \alpha_i - \beta_i = 0 \quad \Rightarrow \beta_i = C - \alpha_i</script></li>
</ul>
<ol>
<li><p><strong>代入拉格朗日函数消去原始变量</strong>：<br>将 $\mathbf{w}$ 和 $\beta_i$ 代入 $\mathcal{L}$，得到对偶目标函数：</p>
<script type="math/tex; mode=display">
\max_{\boldsymbol{\alpha}} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j \phi(\mathbf{x}_i)^T \phi(\mathbf{x}_j)</script><p>约束条件：</p>
<script type="math/tex; mode=display">
0 \leq \alpha_i \leq C, \quad \sum_{i=1}^n \alpha_i y_i = 0</script></li>
<li><p><strong>引入核函数</strong>：<br>用核函数 $K(\mathbf{x}_i, \mathbf{x}_j) = \phi(\mathbf{x}_i)^T \phi(\mathbf{x}_j)$ 替换内积，得到最终对偶问题：</p>
<script type="math/tex; mode=display">
\max_{\boldsymbol{\alpha}} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(\mathbf{x}_i, \mathbf{x}_j)</script><p>约束条件不变。</p>
</li>
</ol>
<p><strong>KKT条件</strong></p>
<ul>
<li><strong>原始可行性</strong>：$y_i (\mathbf{w}^T \phi(\mathbf{x}_i) + b) \geq 1 - \xi_i, \quad \xi_i \geq 0$</li>
<li><strong>对偶可行性</strong>：$\alpha_i \geq 0, \quad \beta_i = C - \alpha_i \geq 0$</li>
<li><strong>互补松弛性</strong>：$\alpha_i [y_i (\mathbf{w}^T \phi(\mathbf{x}_i) + b) - 1 + \xi_i] = 0, \quad \beta_i \xi_i = 0$</li>
<li><strong>梯度为零条件</strong>：已通过偏导数消去原始变量。</li>
</ul>
<p><strong>预测函数</strong></p>
<p>测试样本 $\mathbf{x}$ 的预测函数为：</p>
<script type="math/tex; mode=display">
f(\mathbf{x}) = \text{sign} \left( \sum_{i=1}^n \alpha_i y_i K(\mathbf{x}_i, \mathbf{x}) + b \right)</script><p>其中 $b$ 可通过任一支持向量（满足 $0 &lt; \alpha_i &lt; C$）计算：</p>
<script type="math/tex; mode=display">
b = y_i - \sum_{j=1}^n \alpha_j y_j K(\mathbf{x}_j, \mathbf{x}_i)</script><h5 id="2"><a href="#2" class="headerlink" title="2"></a>2</h5>]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——支持向量机</title>
    <url>/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>下面我将为你详细解释KKT（Karush-Kuhn-Tucker）条件。KKT条件是优化理论中用于求解带约束非线性规划问题的一组必要条件，广泛应用于支持向量机（SVM）等机器学习算法中。我会使用内联数学公式（如 <script type="math/tex">f(\mathbf{x})</script>）来展示相关表达式。</p>
<hr>
<h3 id="1-优化问题的一般形式"><a href="#1-优化问题的一般形式" class="headerlink" title="1. 优化问题的一般形式"></a>1. 优化问题的一般形式</h3><p>我们考虑一个带有约束的优化问题，数学形式如下：</p>
<ul>
<li>目标：<script type="math/tex">\min_{\mathbf{x}} f(\mathbf{x})</script></li>
<li>不等式约束：<script type="math/tex">g_i(\mathbf{x}) \leq 0</script>，其中 <script type="math/tex">i = 1, 2, \dots, m</script></li>
<li>等式约束：<script type="math/tex">h_j(\mathbf{x}) = 0</script>，其中 <script type="math/tex">j = 1, 2, \dots, p</script></li>
</ul>
<p>这里：</p>
<ul>
<li><script type="math/tex">f(\mathbf{x})</script> 是目标函数，通常是我们希望最小化的函数。</li>
<li><script type="math/tex">g_i(\mathbf{x}) \leq 0</script> 表示 <script type="math/tex">m</script> 个不等式约束。</li>
<li><script type="math/tex">h_j(\mathbf{x}) = 0</script> 表示 <script type="math/tex">p</script> 个等式约束。</li>
</ul>
<p>KKT条件的目标是找到满足这些约束的局部最优解 <script type="math/tex">\mathbf{x}</script>。</p>
<hr>
<h3 id="2-拉格朗日函数"><a href="#2-拉格朗日函数" class="headerlink" title="2. 拉格朗日函数"></a>2. 拉格朗日函数</h3><p>为了引入KKT条件，我们首先定义拉格朗日函数：</p>
<script type="math/tex; mode=display">\mathcal{L}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = f(\mathbf{x}) + \sum_{i=1}^{m} \lambda_i g_i(\mathbf{x}) + \sum_{j=1}^{p} \mu_j h_j(\mathbf{x})</script><p>其中：</p>
<ul>
<li><script type="math/tex">\boldsymbol{\lambda} = (\lambda_1, \lambda_2, \dots, \lambda_m)</script> 是与不等式约束 <script type="math/tex">g_i(\mathbf{x}) \leq 0</script> 对应的拉格朗日乘子。</li>
<li><script type="math/tex">\boldsymbol{\mu} = (\mu_1, \mu_2, \dots, \mu_p)</script> 是与等式约束 <script type="math/tex">h_j(\mathbf{x}) = 0</script> 对应的拉格朗日乘子。</li>
</ul>
<p>拉格朗日函数将目标函数和约束条件结合在一起，通过引入乘子 <script type="math/tex">\lambda_i</script> 和 <script type="math/tex">\mu_j</script> 来平衡约束对优化的影响。</p>
<hr>
<h3 id="3-KKT条件的组成部分"><a href="#3-KKT条件的组成部分" class="headerlink" title="3. KKT条件的组成部分"></a>3. KKT条件的组成部分</h3><p>KKT条件由以下四个部分组成，只有当某些正则性条件（如Slater条件）满足时，局部最优解 <script type="math/tex">\mathbf{x}</script> 才会同时满足这些条件。以下是具体的KKT条件：</p>
<h4 id="3-1-梯度条件（Stationarity）"><a href="#3-1-梯度条件（Stationarity）" class="headerlink" title="3.1 梯度条件（Stationarity）"></a>3.1 梯度条件（Stationarity）</h4><p>拉格朗日函数对 <script type="math/tex">\mathbf{x}</script> 的梯度必须为零，即：</p>
<script type="math/tex; mode=display">\nabla_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = \nabla f(\mathbf{x}) + \sum_{i=1}^{m} \lambda_i \nabla g_i(\mathbf{x}) + \sum_{j=1}^{p} \mu_j \nabla h_j(\mathbf{x}) = 0</script><p>这意味着在最优解处，目标函数的梯度可以通过约束函数梯度的线性组合来表示。</p>
<h4 id="3-2-原始可行性（Primal-Feasibility）"><a href="#3-2-原始可行性（Primal-Feasibility）" class="headerlink" title="3.2 原始可行性（Primal Feasibility）"></a>3.2 原始可行性（Primal Feasibility）</h4><p>解 <script type="math/tex">\mathbf{x}</script> 必须满足原始问题的所有约束：</p>
<ul>
<li>不等式约束：<script type="math/tex">g_i(\mathbf{x}) \leq 0</script>，其中 <script type="math/tex">i = 1, 2, \dots, m</script></li>
<li>等式约束：<script type="math/tex">h_j(\mathbf{x}) = 0</script>，其中 <script type="math/tex">j = 1, 2, \dots, p</script></li>
</ul>
<p>这确保了解仍在问题的可行域内。</p>
<h4 id="3-3-对偶可行性（Dual-Feasibility）"><a href="#3-3-对偶可行性（Dual-Feasibility）" class="headerlink" title="3.3 对偶可行性（Dual Feasibility）"></a>3.3 对偶可行性（Dual Feasibility）</h4><p>对于不等式约束对应的拉格朗日乘子，必须满足：</p>
<script type="math/tex; mode=display">\lambda_i \geq 0$$，其中 $$i = 1, 2, \dots, m</script><p>这表明不等式约束的乘子非负，反映了约束对优化方向的影响。</p>
<h4 id="3-4-互补松弛条件（Complementary-Slackness）"><a href="#3-4-互补松弛条件（Complementary-Slackness）" class="headerlink" title="3.4 互补松弛条件（Complementary Slackness）"></a>3.4 互补松弛条件（Complementary Slackness）</h4><p>对于每个不等式约束，乘子与约束函数的乘积必须为零：</p>
<script type="math/tex; mode=display">\lambda_i g_i(\mathbf{x}) = 0$$，其中 $$i = 1, 2, \dots, m</script><p>这意味着：</p>
<ul>
<li>如果某个约束不“紧”（即 <script type="math/tex">g_i(\mathbf{x}) < 0</script>），则对应的乘子 <script type="math/tex">\lambda_i = 0</script>。</li>
<li>如果 <script type="math/tex">\lambda_i > 0</script>，则该约束必须是“紧”的（即 <script type="math/tex">g_i(\mathbf{x}) = 0</script>）。</li>
</ul>
<hr>
<h3 id="4-KKT条件的意义"><a href="#4-KKT条件的意义" class="headerlink" title="4. KKT条件的意义"></a>4. KKT条件的意义</h3><ul>
<li><strong>梯度条件</strong>：表明最优解处目标函数的改变方向被约束完全平衡。</li>
<li><strong>原始可行性</strong>：确保解满足所有约束条件。</li>
<li><strong>对偶可行性</strong>：限制拉格朗日乘子的符号，保证优化方向的合理性。</li>
<li><strong>互补松弛条件</strong>：揭示哪些约束在最优解处起作用（紧约束），哪些不起作用。</li>
</ul>
<hr>
<h3 id="5-KKT条件在SVM中的应用示例"><a href="#5-KKT条件在SVM中的应用示例" class="headerlink" title="5. KKT条件在SVM中的应用示例"></a>5. KKT条件在SVM中的应用示例</h3><p>KKT条件在支持向量机（SVM）中尤为重要。SVM的原始优化问题为：</p>
<ul>
<li>目标：<script type="math/tex">\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2</script></li>
<li>约束：<script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1</script>，其中 <script type="math/tex">i = 1, 2, \dots, n</script></li>
</ul>
<p>将其改写为标准形式的不等式约束：<script type="math/tex">1 - y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \leq 0</script>。</p>
<p>拉格朗日函数为：</p>
<script type="math/tex; mode=display">\mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha}) = \frac{1}{2} \|\mathbf{w}\|^2 + \sum_{i=1}^{n} \alpha_i \left[ 1 - y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \right]</script><p>应用KKT条件：</p>
<ol>
<li><strong>梯度条件</strong>：<ul>
<li>对 <script type="math/tex">\mathbf{w}</script>：<script type="math/tex">\nabla_{\mathbf{w}} \mathcal{L} = \mathbf{w} - \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i = 0</script></li>
<li>对 <script type="math/tex">b</script>：<script type="math/tex">\frac{\partial \mathcal{L}}{\partial b} = -\sum_{i=1}^{n} \alpha_i y_i = 0</script></li>
</ul>
</li>
<li><strong>原始可行性</strong>：<script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1</script></li>
<li><strong>对偶可行性</strong>：<script type="math/tex">\alpha_i \geq 0</script></li>
<li><strong>互补松弛条件</strong>：<script type="math/tex">\alpha_i \left[ y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 \right] = 0</script></li>
</ol>
<p>这些条件帮助我们识别支持向量（<script type="math/tex">\alpha_i > 0</script> 的点）并求解最优的 <script type="math/tex">\mathbf{w}</script> 和 <script type="math/tex">b</script>。</p>
<hr>
<h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h3><p>KKT条件是求解带约束优化问题的核心工具，它通过梯度条件、原始可行性、对偶可行性和互补松弛条件，确保了解既是最优的，又满足所有约束。在机器学习中，KKT条件为SVM等算法提供了理论支持，是理解和实现这些模型的关键。</p>
<h3 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h3><h4 id="关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）"><a href="#关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）" class="headerlink" title="关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）"></a>关于支持向量机，推导目标函数的原始问题转换为对偶问题的过程和条件。（使用拉格朗日乘子法）</h4><p><img src="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/IMG_20250416_164811.jpg" alt="IMG_20250416_164811"></p>
<p>下面我们将推导支持向量机（SVM）中目标函数从原始问题转换为对偶问题的过程和条件，使用拉格朗日乘子法。我们将一步步展开，确保推导清晰且完整。</p>
<hr>
<h3 id="1-原始问题"><a href="#1-原始问题" class="headerlink" title="1. 原始问题"></a>1. 原始问题</h3><p>支持向量机（SVM）的目标是找到一个超平面，能够最大化到最近数据点的间隔。对于线性可分的情况，原始优化问题可以定义为：</p>
<ul>
<li><p><strong>目标函数</strong>：  </p>
<script type="math/tex; mode=display">\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2</script></li>
<li><p><strong>约束条件</strong>：  </p>
<script type="math/tex; mode=display">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1, \quad i = 1, 2, \dots, n</script></li>
</ul>
<p>其中：</p>
<ul>
<li><script type="math/tex">\mathbf{w}</script> 是超平面的法向量；</li>
<li><script type="math/tex">b</script> 是超平面的截距；</li>
<li><script type="math/tex">\mathbf{x}_i</script> 是训练样本，<script type="math/tex">y_i \in \{-1, 1\}</script> 是对应的类别标签；</li>
<li><script type="math/tex">\|\mathbf{w}\|^2</script> 表示法向量的平方范数，目标是最小化它以最大化间隔；</li>
<li>约束条件确保所有样本点被正确分类，并且到超平面的归一化距离至少为 1。</li>
</ul>
<hr>
<h3 id="2-引入拉格朗日乘子法"><a href="#2-引入拉格朗日乘子法" class="headerlink" title="2. 引入拉格朗日乘子法"></a>2. 引入拉格朗日乘子法</h3><p>由于这是一个带不等式约束的优化问题，我们使用拉格朗日乘子法将其转换为无约束形式。引入拉格朗日乘子 <script type="math/tex">\boldsymbol{\alpha} = (\alpha_1, \alpha_2, \dots, \alpha_n)</script>，其中 <script type="math/tex">\alpha_i \geq 0</script>，构造拉格朗日函数：</p>
<script type="math/tex; mode=display">\mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha}) = \frac{1}{2} \|\mathbf{w}\|^2 - \sum_{i=1}^{n} \alpha_i \left[ y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 \right]</script><ul>
<li>第一项 <script type="math/tex">\frac{1}{2} \|\mathbf{w}\|^2</script> 是原始目标函数；</li>
<li>第二项 <script type="math/tex">-\sum_{i=1}^{n} \alpha_i \left[ y_i (\mathbf{w} \cdot \mathbf{x}_i + b) - 1 \right]</script> 将约束条件引入，由于是 <script type="math/tex">\geq</script> 不等式，乘子 <script type="math/tex">\alpha_i \geq 0</script>。</li>
</ul>
<p>我们的目标是通过拉格朗日函数，将原始问题转换为对偶问题。</p>
<hr>
<h3 id="3-转换为对偶问题"><a href="#3-转换为对偶问题" class="headerlink" title="3. 转换为对偶问题"></a>3. 转换为对偶问题</h3><p>对偶问题的核心思想是：先对 <script type="math/tex">\mathbf{w}</script> 和 <script type="math/tex">b</script> 求拉格朗日函数的极小值，然后对 <script type="math/tex">\boldsymbol{\alpha}</script> 求极大值。即：</p>
<script type="math/tex; mode=display">\max_{\boldsymbol{\alpha} \geq 0} \min_{\mathbf{w}, b} \mathcal{L}(\mathbf{w}, b, \boldsymbol{\alpha})</script><h4 id="3-1-对-mathbf-w-和-b-求偏导"><a href="#3-1-对-mathbf-w-和-b-求偏导" class="headerlink" title="3.1 对 \mathbf{w} 和 b 求偏导"></a>3.1 对 <script type="math/tex">\mathbf{w}</script> 和 <script type="math/tex">b</script> 求偏导</h4><p>为了找到 <script type="math/tex">\mathcal{L}</script> 关于 <script type="math/tex">\mathbf{w}</script> 和 <script type="math/tex">b</script> 的极小值，分别求偏导并令其为零：</p>
<ul>
<li><p>对 <script type="math/tex">\mathbf{w}</script> 求偏导：  </p>
<script type="math/tex; mode=display">\frac{\partial \mathcal{L}}{\partial \mathbf{w}} = \mathbf{w} - \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i = 0</script><p>解得：  </p>
<script type="math/tex; mode=display">\mathbf{w} = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i</script></li>
<li><p>对 <script type="math/tex">b</script> 求偏导：  </p>
<script type="math/tex; mode=display">\frac{\partial \mathcal{L}}{\partial b} = -\sum_{i=1}^{n} \alpha_i y_i = 0</script><p>解得：  </p>
<script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i = 0</script></li>
</ul>
<p>这两个结果是后续推导的关键。</p>
<h4 id="3-2-代入拉格朗日函数"><a href="#3-2-代入拉格朗日函数" class="headerlink" title="3.2 代入拉格朗日函数"></a>3.2 代入拉格朗日函数</h4><p>将 <script type="math/tex">\mathbf{w} = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i</script> 代入拉格朗日函数，并利用 <script type="math/tex">\sum_{i=1}^{n} \alpha_i y_i = 0</script> 简化：</p>
<script type="math/tex; mode=display">\mathcal{L} = \frac{1}{2} \left\| \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \right\|^2 - \sum_{i=1}^{n} \alpha_i \left[ y_i \left( \left( \sum_{j=1}^{n} \alpha_j y_j \mathbf{x}_j \right) \cdot \mathbf{x}_i + b \right) - 1 \right]</script><ul>
<li><p>计算第一项：  </p>
<script type="math/tex; mode=display">\left\| \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i \right\|^2 = \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)</script></li>
<li><p>计算第二项中的内积部分：  </p>
<script type="math/tex; mode=display">y_i \left( \sum_{j=1}^{n} \alpha_j y_j \mathbf{x}_j \right) \cdot \mathbf{x}_i = y_i \sum_{j=1}^{n} \alpha_j y_j (\mathbf{x}_j \cdot \mathbf{x}_i)</script><p>所以：  </p>
<script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i \left( \sum_{j=1}^{n} \alpha_j y_j (\mathbf{x}_j \cdot \mathbf{x}_i) \right) = \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j)</script></li>
<li><p>考虑 <script type="math/tex">b</script> 项：  </p>
<script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i b = b \sum_{i=1}^{n} \alpha_i y_i = 0 \quad (\text{因为} \sum_{i=1}^{n} \alpha_i y_i = 0)</script></li>
</ul>
<p>代入后，拉格朗日函数变为：  </p>
<script type="math/tex; mode=display">\mathcal{L} = \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) - \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) + \sum_{i=1}^{n} \alpha_i</script><p>化简：  </p>
<script type="math/tex; mode=display">\mathcal{L} = -\frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) + \sum_{i=1}^{n} \alpha_i</script><h4 id="3-3-对偶优化问题"><a href="#3-3-对偶优化问题" class="headerlink" title="3.3 对偶优化问题"></a>3.3 对偶优化问题</h4><p>于是，对偶问题是：  </p>
<script type="math/tex; mode=display">\max_{\boldsymbol{\alpha}} \left[ \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) \right]</script><ul>
<li><strong>约束条件</strong>：  <script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i = 0</script><script type="math/tex; mode=display">\alpha_i \geq 0, \quad i = 1, 2, \dots, n</script></li>
</ul>
<p>为了与标准优化形式一致，常将其写为最小化问题：  </p>
<script type="math/tex; mode=display">\min_{\boldsymbol{\alpha}} \left[ \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) - \sum_{i=1}^{n} \alpha_i \right]</script><ul>
<li><strong>约束条件不变</strong>：  <script type="math/tex; mode=display">\sum_{i=1}^{n} \alpha_i y_i = 0</script><script type="math/tex; mode=display">\alpha_i \geq 0</script></li>
</ul>
<hr>
<h3 id="4-转换的条件"><a href="#4-转换的条件" class="headerlink" title="4. 转换的条件"></a>4. 转换的条件</h3><p>原始问题与对偶问题之间的关系由<strong>强对偶性</strong>保证。在SVM中：</p>
<ul>
<li>目标函数 <script type="math/tex">\frac{1}{2} \|\mathbf{w}\|^2</script> 是凸函数（二次函数）；</li>
<li>约束条件 <script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1</script> 是线性不等式；</li>
<li>对于线性可分数据，Slater条件满足（存在可行解使约束严格成立）。</li>
</ul>
<p>因此，强对偶性成立，原始问题的最优解可以通过对偶问题求解得到。</p>
<p>此外：</p>
<ul>
<li>最优的 <script type="math/tex">\boldsymbol{\alpha}</script> 通过对偶问题求解；</li>
<li><script type="math/tex">\mathbf{w} = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i</script>；</li>
<li>对于支持向量（<script type="math/tex">\alpha_i > 0</script> 的样本），<script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) = 1</script>，可据此解出 <script type="math/tex">b</script>。</li>
</ul>
<hr>
<h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h3><ul>
<li><p><strong>原始问题</strong>：  </p>
<script type="math/tex; mode=display">\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2</script><p>受约束：<script type="math/tex">y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1</script></p>
</li>
<li><p><strong>对偶问题</strong>：  </p>
<script type="math/tex; mode=display">\max_{\boldsymbol{\alpha}} \left[ \sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j (\mathbf{x}_i \cdot \mathbf{x}_j) \right]</script><p>受约束：<script type="math/tex">\sum_{i=1}^{n} \alpha_i y_i = 0</script>，<script type="math/tex">\alpha_i \geq 0</script></p>
</li>
<li><p><strong>转换条件</strong>：<br>通过拉格朗日乘子法，基于凸优化和强对偶性完成转换。对偶形式不仅便于求解，还为引入核函数奠定了基础。</p>
</li>
</ul>
<p>以上就是SVM目标函数从原始问题到对偶问题的推导过程和条件。</p>
<h4 id="2-已知训练数据集中正例点x1-2-3-，x2-3-3-，x3-3-2-，负例点x4-1-2-，-x5-2-1-，x6-3-1-，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。"><a href="#2-已知训练数据集中正例点x1-2-3-，x2-3-3-，x3-3-2-，负例点x4-1-2-，-x5-2-1-，x6-3-1-，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。" class="headerlink" title="2.已知训练数据集中正例点x1=(2,3)，x2=(3,3)，x3=(3,2)，负例点x4=(1,2)，    x5=(2,1)，x6=(3,1)，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。"></a>2.已知训练数据集中正例点x1=(2,3)，x2=(3,3)，x3=(3,2)，负例点x4=(1,2)，    x5=(2,1)，x6=(3,1)，训练线性SVM分类器。求最大间隔分类超平面和分类决策函数，并画出分类超平面、间隔边界以及支持向量。</h4><p><img src="/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/IMG_20250416_164804-1744793466526-4.jpg" alt="IMG_20250416_164804"></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——期末复习（查漏补缺）</title>
    <url>/2025/06/10/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA%EF%BC%89/</url>
    <content><![CDATA[<h3 id="高斯核（RBF核）中-σ²-的作用及其对模型的影响"><a href="#高斯核（RBF核）中-σ²-的作用及其对模型的影响" class="headerlink" title="高斯核（RBF核）中 σ² 的作用及其对模型的影响"></a>高斯核（RBF核）中 σ² 的作用及其对模型的影响</h3><p>高斯核（RBF核）的形式为：</p>
<script type="math/tex; mode=display">
K(x, x') = \exp\left(-\frac{\|x - x'\|^2}{2\sigma^2}\right)</script><p>其中 $ |x - x’| $ 是两个样本点之间的欧氏距离，$ \sigma^2 $ 是高斯核的方差参数，控制核函数的“宽度”或“局部性”。</p>
<p><strong>1. σ² 的几何意义：核函数的“影响范围”</strong></p>
<ul>
<li><p><strong>σ² 较小时</strong>：<br>分母较小，指数项中的 $ \frac{|x - x’|^2}{2\sigma^2} $ 会更大，导致指数函数值快速衰减。<br><strong>结果</strong>：只有当 $ x $ 和 $ x’ $ 非常接近时，核函数值才接近1；稍远一点的距离会导致核函数值迅速趋近于0。<br><strong>直观理解</strong>：模型只关注局部区域内的样本点，决策边界会围绕每个样本点“弯曲”，形成复杂的非线性形状。</p>
</li>
<li><p><strong>σ² 较大时</strong>：<br>分母较大，指数项中的 $ \frac{|x - x’|^2}{2\sigma^2} $ 会更小，指数函数值衰减缓慢。<br><strong>结果</strong>：即使 $ x $ 和 $ x’ $ 相距较远，核函数值仍可能较大。<br><strong>直观理解</strong>：模型会考虑更大范围的样本点，决策边界更平滑，接近线性分隔。</p>
</li>
</ul>
<p><strong>2. σ² 如何影响模型的复杂度</strong></p>
<ul>
<li><p><strong>σ² 小 → 局部敏感，高复杂度</strong>：  </p>
<ul>
<li>每个样本点的影响范围有限，模型需要“记住”每个局部区域的细节。  </li>
<li>决策边界会围绕每个样本点剧烈弯曲，甚至形成孤立的环形区域（如图1）。  </li>
<li>容易过拟合：模型过度适应训练数据的噪声和细节。</li>
</ul>
</li>
<li><p><strong>σ² 大 → 全局平滑，低复杂度</strong>：  </p>
<ul>
<li>样本点的影响范围扩大，模型倾向于用简单的全局模式区分数据。  </li>
<li>决策边界接近线性（如图2），可能无法捕捉数据中的非线性结构。  </li>
<li>容易欠拟合：模型无法拟合数据中的局部特征。</li>
</ul>
</li>
</ul>
<p><strong>3. 数学与直观示例</strong></p>
<p>假设两个样本点 $ x_1 $ 和 $ x_2 $ 距离为 $ d $，核函数值 $ K(x_1, x_2) $ 随 $ \sigma^2 $ 的变化如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>$ \sigma^2 $</th>
<th>$ d = 1 $</th>
<th>$ d = 2 $</th>
<th>$ d = 3 $</th>
</tr>
</thead>
<tbody>
<tr>
<td>$ \sigma^2 = 0.1 $</td>
<td>$ \exp(-5) \approx 0.0067 $</td>
<td>$ \exp(-20) \approx 2.06 \times 10^{-9} $</td>
<td>$ \exp(-45) \approx 2.87 \times 10^{-20} $</td>
</tr>
<tr>
<td>$ \sigma^2 = 1 $</td>
<td>$ \exp(-0.5) \approx 0.6065 $</td>
<td>$ \exp(-2) \approx 0.1353 $</td>
<td>$ \exp(-4.5) \approx 0.0111 $</td>
</tr>
<tr>
<td>$ \sigma^2 = 10 $</td>
<td>$ \exp(-0.05) \approx 0.9512 $</td>
<td>$ \exp(-0.2) \approx 0.8187 $</td>
<td>$ \exp(-0.45) \approx 0.6376 $</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><strong>σ² 小（如 0.1）</strong>：距离稍大的样本点之间几乎无关联，模型仅依赖极邻近的点做决策。  </li>
<li><strong>σ² 大（如 10）</strong>：即使距离较远的样本点仍有显著关联，模型决策边界更平滑。</li>
</ul>
<h3 id="为什么使用高斯核之前要归一化"><a href="#为什么使用高斯核之前要归一化" class="headerlink" title="为什么使用高斯核之前要归一化"></a>为什么使用高斯核之前要归一化</h3><p>在使用高斯核（RBF核）之前对数据进行归一化，是机器学习中至关重要的预处理步骤。其核心原因是<strong>高斯核对特征的尺度（scale）极度敏感</strong>，而归一化能消除特征间尺度差异带来的负面影响。以下是详细解释：</p>
<ol>
<li><strong>高斯核的本质依赖距离计算</strong></li>
</ol>
<p>高斯核的公式为：</p>
<script type="math/tex; mode=display">
K(x, x') = \exp\left(-\frac{\|x - x'\|^2}{2\sigma^2}\right)</script><p>其中 $|x - x’|$ 是两个样本点之间的欧氏距离。<br><strong>问题</strong>：欧氏距离的计算受特征尺度影响极大。例如：</p>
<ul>
<li>假设特征A的取值范围是 [0,1]，特征B的取值范围是 [0,1000]。</li>
<li>此时特征B的差异会主导距离计算（如 $ (0.5)^2 + (500)^2 \approx 250000 $），特征A的贡献几乎被忽略。</li>
</ul>
<p><strong>结果</strong>：模型决策边界会过度依赖尺度大的特征，导致性能下降。</p>
<ol>
<li><strong>归一化消除特征尺度差异</strong></li>
</ol>
<p>归一化（如标准化或最小-最大缩放）将所有特征调整到相似的数值范围（如 [0,1] 或均值为0、方差为1）。<br><strong>效果</strong>：</p>
<ul>
<li><strong>公平比较特征</strong>：每个特征对距离的贡献权重均衡。</li>
<li><strong>防止“大尺度特征主导”</strong>：避免模型因某些特征数值过大而忽略其他重要特征。</li>
</ul>
<p><strong>示例</strong>：<br>假设两个样本：  </p>
<ul>
<li>未归一化：$ x_1 = [1, 100], x_2 = [2, 200] $，距离为 $ \sqrt{(1)^2 + (100)^2} \approx 100.005 $。  </li>
<li>归一化后（假设缩放到 [0,1]）：$ x_1 = [0.1, 0.1], x_2 = [0.2, 0.2] $，距离为 $ \sqrt{(0.1)^2 + (0.1)^2} \approx 0.141 $。<br>此时两个特征的贡献比例从 1:100 变为 1:1。</li>
</ul>
<ol>
<li><strong>高斯核参数 σ² 的有效性依赖归一化</strong></li>
</ol>
<p>高斯核的参数 σ²（或 γ = 1/σ²）决定了核函数的“局部性”（即模型关注局部还是全局模式）。  </p>
<ul>
<li><strong>未归一化时</strong>：σ² 的选择必须同时适应不同尺度的特征，导致参数调优困难。<ul>
<li>例如：若某特征尺度极大，需要极小的 σ² 才能捕捉其局部变化，但这可能使其他小尺度特征的核函数失效。</li>
</ul>
</li>
<li><strong>归一化后</strong>：所有特征尺度一致，σ² 的调参只需关注数据整体分布，而非单个特征的尺度。</li>
</ul>
<h3 id="SVM的Hinge损失函数"><a href="#SVM的Hinge损失函数" class="headerlink" title="SVM的Hinge损失函数"></a>SVM的Hinge损失函数</h3><p>Hinge损失函数是支持向量机（SVM）中用于分类任务的核心损失函数，其核心思想是<strong>最大化分类间隔</strong>，同时惩罚分类错误或置信度不足的样本。以下是详细解析：</p>
<p><strong>1. 数学定义</strong></p>
<p>对于二分类问题，假设真实标签 $ y \in {+1, -1} $，模型输出 $ f(x) = w^T x + b $，则 <strong>Hinge损失</strong> 的定义为：</p>
<script type="math/tex; mode=display">
\mathcal{L}(y, f(x)) = \max(0, 1 - y \cdot f(x))</script><ul>
<li><strong>关键含义</strong>：<ul>
<li>当 $ y \cdot f(x) \geq 1 $：样本被正确分类且置信度足够（位于间隔边界外），损失为0。</li>
<li>当 $ y \cdot f(x) &lt; 1 $：样本位于间隔内或被错误分类，损失随 $ y \cdot f(x) $ 线性增长。</li>
</ul>
</li>
</ul>
<p><strong>2. 几何意义：最大化间隔</strong></p>
<p>Hinge损失的设计与SVM的<strong>硬间隔（Hard Margin）</strong>和<strong>软间隔（Soft Margin）</strong>目标直接相关：</p>
<ul>
<li><strong>硬间隔</strong>：要求所有样本严格满足 $ y_i (w^T x_i + b) \geq 1 $，即完全线性可分。</li>
<li><strong>软间隔</strong>：允许部分样本违反间隔约束，通过Hinge损失将约束转化为优化目标：<script type="math/tex; mode=display">
\min_{w,b} \left( \frac{1}{2} \|w\|^2 + C \sum_{i=1}^n \max(0, 1 - y_i (w^T x_i + b)) \right)</script><ul>
<li><strong>第一项</strong> $ \frac{1}{2} |w|^2 $：最大化间隔（间隔宽度与 $ |w| $ 成反比）。</li>
<li><strong>第二项</strong> Hinge损失：惩罚违反间隔约束的样本，$ C $ 控制惩罚强度。</li>
</ul>
</li>
</ul>
<h3 id="为什么树的数量增加不会导致过拟合？"><a href="#为什么树的数量增加不会导致过拟合？" class="headerlink" title="为什么树的数量增加不会导致过拟合？"></a>为什么树的数量增加不会导致过拟合？</h3><p><strong>核心原因</strong>：随机森林通过<strong>集成学习</strong>和<strong>多样性机制</strong>抑制了单棵决策树的过拟合风险。具体来说：</p>
<ol>
<li><p><strong>Bagging（自助聚合）机制</strong>：<br>每棵树的训练数据是通过有放回采样（Bootstrap）得到的子集，这意味着每棵树看到的数据略有不同，减少了对训练数据的“记忆”依赖。</p>
</li>
<li><p><strong>特征随机选择</strong>：<br>每次分裂节点时，仅从随机选择的特征子集中挑选最优特征，进一步降低了各树之间的相关性。</p>
</li>
<li><p><strong>投票/平均机制</strong>：<br>多棵树的预测结果通过投票（分类）或平均（回归）结合，高方差的个体树被平滑，整体模型的泛化能力增强。</p>
</li>
<li><p><strong>收敛性保证</strong>：<br>随着树的数量增加，模型性能逐渐收敛到一个稳定值。即使继续增加树的数量，也不会显著提升训练集性能，更不会过拟合。</p>
</li>
</ol>
<h3 id="欧式距离的特性分析"><a href="#欧式距离的特性分析" class="headerlink" title="欧式距离的特性分析"></a>欧式距离的特性分析</h3><p><strong>欧式距离</strong>（Euclidean Distance）是衡量欧几里得空间中两点之间直线距离的常用方法，其公式为：</p>
<script type="math/tex; mode=display">
d(x, y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}</script><p>以下是对其特性的详细分析：</p>
<p><strong>A. 旋转不变性</strong>  </p>
<p><strong>正确</strong>  </p>
<ul>
<li><strong>定义</strong>：若坐标系旋转，两点间的欧式距离保持不变。  </li>
<li><strong>原因</strong>：旋转是刚性变换（rigid transformation），仅改变点的坐标表示，但不改变几何距离。  </li>
<li><strong>示例</strong>：在二维平面中，将坐标系旋转θ角度，两点 $(x_1, y_1)$ 和 $(x_2, y_2)$ 的旋转后坐标分别为：<script type="math/tex; mode=display">
(x_1', y_1') = (x_1\cos\theta - y_1\sin\theta, x_1\sin\theta + y_1\cos\theta)</script><script type="math/tex; mode=display">
(x_2', y_2') = (x_2\cos\theta - y_2\sin\theta, x_2\sin\theta + y_2\cos\theta)</script>计算旋转后的距离仍等于原始距离。</li>
</ul>
<p><strong>B. 尺度缩放不变性</strong>  </p>
<p><strong>错误</strong>  </p>
<ul>
<li><strong>定义</strong>：若对坐标轴进行非均匀或均匀缩放，欧式距离会发生变化。  </li>
<li><strong>反例</strong>：假设对某维特征缩放 $k$ 倍（如将 $x_i$ 变为 $k x_i$），则距离变为原来的 $k$ 倍。  </li>
<li><strong>结论</strong>：欧式距离<strong>依赖于特征的绝对尺度</strong>，不具备缩放不变性。</li>
</ul>
<p><strong>C. 不受量纲影响的特性</strong>  </p>
<p><strong>错误</strong>  </p>
<ul>
<li><strong>定义</strong>：若不同特征的量纲不同（如身高[m]与体重[kg]），欧式距离的计算会因量纲差异而失真。  </li>
<li><strong>反例</strong>：  <ul>
<li>点A：(1.8m, 70kg)，点B：(1.7m, 65kg)  </li>
<li>若不标准化，身高差（0.1m）与体重差（5kg）的贡献会被直接相加，但两者量纲不同，结果无实际意义。  </li>
</ul>
</li>
<li><strong>解决方法</strong>：需通过标准化（如Z-score归一化）消除量纲影响。</li>
</ul>
<h3 id="下列哪个不属于特征提取"><a href="#下列哪个不属于特征提取" class="headerlink" title="下列哪个不属于特征提取"></a>下列哪个不属于特征提取</h3><p><strong>答案：D. 主成分分析</strong></p>
<p><strong>解析：</strong></p>
<p>在文本分类的特征选择中，常用的方法包括：</p>
<ul>
<li><strong>A. 卡方检验值</strong>：通过统计检验评估特征与类别的相关性，属于过滤式特征选择方法。</li>
<li><strong>B. 互信息</strong>：基于信息论，衡量特征与类别的依赖关系，属于无监督或半监督的特征选择方法。</li>
<li><strong>C. 信息增益</strong>：基于熵的指标，评估特征对分类的贡献，常用于决策树等算法中的特征选择。</li>
</ul>
<p>而 <strong>D. 主成分分析（PCA）</strong> 是一种 <strong>降维技术</strong>，通过线性变换将高维数据映射到低维空间，其核心目标是保留数据的主要方差，而非直接选择原始特征。它属于 <strong>特征提取</strong>（Feature Extraction）而非传统意义上的 <strong>特征选择</strong>（Feature Selection）。因此，主成分分析不属于常用的文本分类特征选择算法。</p>
<h3 id="ridge回归和lasso回归"><a href="#ridge回归和lasso回归" class="headerlink" title="ridge回归和lasso回归"></a>ridge回归和lasso回归</h3><p>Ridge回归（岭回归）和Lasso回归（套索回归）是两种常用的<strong>正则化线性回归方法</strong>，主要用于解决线性回归中的<strong>过拟合问题</strong>和<strong>特征选择问题</strong>。它们的核心思想是在损失函数中添加正则化项（惩罚项），从而限制模型参数的大小，提升模型的泛化能力。</p>
<p><strong>1. Ridge回归（岭回归）</strong></p>
<p><strong>目标函数</strong></p>
<script type="math/tex; mode=display">
\min_{\mathbf{w}} \left\{ \sum_{i=1}^n (y_i - \mathbf{w}^T \mathbf{x}_i)^2 + \lambda \|\mathbf{w}\|_2^2 \right\}</script><ul>
<li>第一项是普通线性回归的均方误差（MSE）。</li>
<li>第二项是L2正则化项（权重平方的和），$\lambda \geq 0$ 是正则化系数，控制惩罚强度。</li>
</ul>
<p><strong>特点</strong></p>
<ul>
<li><strong>L2正则化</strong>：通过缩小权重系数（但不会完全置零）来减少模型复杂度。</li>
<li><strong>解决多重共线性</strong>：当特征之间存在高度相关性时，Ridge回归能稳定回归系数。</li>
<li><strong>唯一解</strong>：目标函数是凸函数，且严格凸，因此有唯一最优解。</li>
<li><strong>计算效率高</strong>：可以通过解析解（闭式解）求解：<script type="math/tex; mode=display">
\mathbf{w}_{\text{Ridge}} = (\mathbf{X}^T \mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{X}^T \mathbf{y}</script></li>
</ul>
<p><strong>应用场景</strong></p>
<ul>
<li>特征维度较低，但存在多重共线性。</li>
<li>需要保留所有特征，但希望抑制其影响（如基因数据分析）。</li>
</ul>
<p><strong>2. Lasso回归（套索回归）</strong></p>
<p><strong>目标函数</strong></p>
<script type="math/tex; mode=display">
\min_{\mathbf{w}} \left\{ \sum_{i=1}^n (y_i - \mathbf{w}^T \mathbf{x}_i)^2 + \lambda \|\mathbf{w}\|_1 \right\}</script><ul>
<li>第一项是均方误差。</li>
<li>第二项是L1正则化项（权重绝对值的和），$\lambda \geq 0$ 是正则化系数。</li>
</ul>
<p><strong>特点</strong></p>
<ul>
<li><strong>L1正则化</strong>：强制部分权重系数为零，实现特征选择。</li>
<li><strong>稀疏模型</strong>：适用于高维数据（如文本分类、基因数据），自动筛选关键特征。</li>
<li><strong>非唯一解</strong>：目标函数是凸函数，但可能有多个解（当特征高度相关时）。</li>
<li><strong>计算复杂度较高</strong>：通常需要迭代优化算法（如坐标下降法、近端梯度下降）。</li>
</ul>
<p><strong>应用场景</strong></p>
<ul>
<li>特征维度极高（如万维以上），需降维。</li>
<li>需要可解释性强的模型（如金融风控中的关键特征筛选）。</li>
</ul>
<p><strong>3. 总结</strong></p>
<ul>
<li><strong>Ridge回归</strong>：适合特征较少且需要稳定系数的场景。</li>
<li><strong>Lasso回归</strong>：适合高维数据和特征选择场景。</li>
<li><strong>实际选择</strong>：<ul>
<li>如果特征数量远大于样本数量（$p \gg n$），优先使用Lasso。</li>
<li>如果特征间存在强相关性，优先使用Ridge或弹性网络。</li>
</ul>
</li>
</ul>
<p>通过调整正则化系数 $\lambda$，可以控制模型的复杂度与泛化能力。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——神经网络</title>
    <url>/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h3><h4 id="类别不均衡指的是什么？有哪些解决方案。"><a href="#类别不均衡指的是什么？有哪些解决方案。" class="headerlink" title="类别不均衡指的是什么？有哪些解决方案。"></a>类别不均衡指的是什么？有哪些解决方案。</h4><p><strong>类别不均衡（Class Imbalance）</strong> 是指分类任务中不同类别样本的数量差异显著，例如：  </p>
<ul>
<li><strong>多数类（Majority Class）</strong>：样本数量多（如正常交易占99%）。  </li>
<li><strong>少数类（Minority Class）</strong>：样本数量极少（如欺诈交易仅占1%）。  </li>
</ul>
<p>这种问题会导致模型倾向于预测多数类，严重降低少数类的预测性能（如漏检欺诈行为）。以下是详细解释和解决方案：</p>
<p><strong>1. 类别不均衡的影响</strong></p>
<ul>
<li><strong>模型偏差</strong>：模型过度关注多数类，忽略少数类（如将所有样本预测为多数类，准确率虚高）。  </li>
<li><strong>评估指标失效</strong>：准确率（Accuracy）失去意义（例如：99% 的样本是多数类，模型只需预测多数类即可达到 99% 准确率）。  </li>
</ul>
<p><strong>2. 解决方案</strong></p>
<p><strong>2.1 数据层面调整</strong></p>
<ul>
<li><p><strong>过采样（Oversampling）</strong>  </p>
<ul>
<li><strong>复制少数类样本</strong>：直接复制少数类数据（可能导致过拟合）。  </li>
<li><strong>生成合成样本</strong>：使用 <strong>SMOTE</strong>（Synthetic Minority Over-sampling Technique）生成新样本（通过插值法）。  </li>
<li><strong>改进版算法</strong>：如 <strong>ADASYN</strong>（自适应合成采样），根据样本分布动态生成数据。  </li>
</ul>
</li>
<li><p><strong>欠采样（Undersampling）</strong>  </p>
<ul>
<li><strong>随机删除多数类样本</strong>：减少多数类数量，但可能丢失重要信息。  </li>
<li><strong>选择性欠采样</strong>：保留多数类中更具代表性的样本（如 <strong>Tomek Links</strong> 或 <strong>Cluster Centroids</strong>）。  </li>
</ul>
</li>
<li><p><strong>混合采样</strong><br>结合过采样和欠采样（如先过采样少数类，再欠采样多数类）。</p>
</li>
</ul>
<p><strong>2.2 算法层面调整</strong></p>
<ul>
<li><p><strong>调整类别权重（Class Weight）</strong>  </p>
<ul>
<li>为少数类分配更高的权重（如 <code>class_weight=&#39;balanced&#39;</code>），让模型更关注少数类。  </li>
<li>公式：<br>[<br>\text{权重} = \frac{\text{多数类样本数}}{\text{少数类样本数}}<br>]</li>
</ul>
</li>
<li><p><strong>集成学习（Ensemble Methods）</strong>  </p>
<ul>
<li><strong>EasyEnsemble</strong>：从多数类中随机采样多个子集，分别与少数类结合训练多个模型，集成结果。  </li>
<li><strong>BalanceCascade</strong>：逐步筛选多数类样本，避免冗余信息。  </li>
<li><strong>RUSBoost</strong>：结合欠采样和提升算法（Boosting）。  </li>
</ul>
</li>
<li><p><strong>改进损失函数</strong>  </p>
<ul>
<li><strong>Focal Loss</strong>：降低易分类样本的权重，聚焦于难分类的少数类样本。  </li>
<li><strong>Cost-sensitive Learning</strong>：为不同类别分配不同的误分类代价。  </li>
</ul>
</li>
</ul>
<p><strong>2.3 评估指标调整</strong></p>
<ul>
<li><strong>避免使用准确率（Accuracy）</strong>，改用以下指标：  <ul>
<li><strong>F1-Score</strong>：精确率（Precision）和召回率（Recall）的调和平均。  </li>
<li><strong>AUC-ROC 曲线</strong>：衡量分类器在不同阈值下的整体性能。  </li>
<li><strong>精确率-召回率曲线（PR Curve）</strong>：关注少数类的识别能力。  </li>
<li><strong>平衡准确率（Balanced Accuracy）</strong>：计算每个类别的召回率的平均值。  </li>
</ul>
</li>
</ul>
<p><strong>2.4 高级技术</strong></p>
<ul>
<li><p><strong>异常检测（Anomaly Detection）</strong><br>将少数类视为异常，使用 One-Class SVM 或孤立森林（Isolation Forest）检测。  </p>
</li>
<li><p><strong>生成对抗网络（GAN）</strong><br>使用 GAN 生成高质量的少数类样本（如医疗数据中的罕见病样本）。  </p>
</li>
<li><p><strong>阈值调整</strong><br>根据业务需求调整分类阈值（如将欺诈检测的阈值从 0.5 降低到 0.3）。  </p>
</li>
</ul>
<p><strong>3. 实际应用建议</strong></p>
<ul>
<li><strong>场景举例</strong>：  <ul>
<li><strong>欺诈检测</strong>：少数类（欺诈）样本极少，需使用 SMOTE + 集成学习。  </li>
<li><strong>医疗诊断</strong>：罕见病识别可尝试 GAN 生成数据或异常检测。  </li>
</ul>
</li>
<li><strong>工具库</strong>：  <ul>
<li>Python 的 <code>imbalanced-learn</code>（提供 SMOTE、EasyEnsemble 等）。  </li>
<li>TensorFlow/PyTorch 中的 <code>class_weight</code> 参数。  </li>
</ul>
</li>
</ul>
<p><strong>总结</strong></p>
<p>类别不均衡的核心是让模型“看到”足够的少数类信息，同时选择合适的评估指标。根据数据特点和业务需求，灵活组合数据采样、算法改进和评估方法，才能有效提升模型对少数类的识别能力。</p>
<h4 id="关于误差逆传播BP算法，详细推导E-k对w-hj的导数和对v-ih的导数。"><a href="#关于误差逆传播BP算法，详细推导E-k对w-hj的导数和对v-ih的导数。" class="headerlink" title="关于误差逆传播BP算法，详细推导E_k对w_hj的导数和对v_ih的导数。"></a>关于误差逆传播BP算法，详细推导E_k对w_hj的导数和对v_ih的导数。</h4><p>以下是误差逆传播（Backpropagation, BP）算法中误差 ( E<em>k ) 对权重 ( w</em>{hj} )（输出层权重）和 ( v_{ih} )（隐藏层权重）的详细导数推导过程：</p>
<p><strong>符号定义</strong></p>
<ul>
<li><strong>输入层节点</strong>：( $x_i$ )（( i = 1, 2, $\dots, n $)）  </li>
<li><strong>隐藏层节点</strong>：( $b_h$ )（( h = 1, 2, $\dots, q $)）  </li>
<li><strong>输出层节点</strong>：( $y_j$ )（( j = 1, 2,$ \dots, l $)）  </li>
<li><strong>隐藏层到输出层的权重</strong>：( $w_{hj}$ )（从隐藏层节点 ( h ) 到输出层节点 ( j )）  </li>
<li><strong>输入层到隐藏层的权重</strong>：( $v_{ih}$ )（从输入层节点 ( i ) 到隐藏层节点 ( h )）  </li>
<li><strong>激活函数</strong>：假设为 Sigmoid 函数 ($ f(x) = \frac{1}{1 + e^{-x}} $)，其导数为 ($ f’(x) = f(x)(1 - f(x)) $)  </li>
<li><strong>损失函数</strong>：均方误差 ($ E<em>k = \frac{1}{2} \sum</em>{j=1}^l (y_j - \hat{y}_j)^2 $)，其中 ( $\hat{y}_j $) 是真实标签。</li>
</ul>
<p><strong>1. 计算 ( $\frac{\partial E<em>k}{\partial w</em>{hj}} $)（输出层权重的梯度）</strong></p>
<p><strong>步骤分解</strong>：  </p>
<ol>
<li><p><strong>输出层输入</strong>：<br>[<br>$net<em>j = \sum</em>{h=1}^q w_{hj} b_h$<br>]<br>输出层节点的激活值为 ( $y_j = f(net_j)$ )。</p>
</li>
<li><p><strong>损失函数对 ( net_j ) 的导数</strong>：<br>[<br>$\frac{\partial E_k}{\partial net_j} = \frac{\partial E_k}{\partial y_j} \cdot \frac{\partial y_j}{\partial net_j}$<br>]</p>
<ul>
<li>( $\frac{\partial E_k}{\partial y_j} = (y_j - \hat{y}_j)$ )（均方误差导数）  </li>
<li>( $\frac{\partial y_j}{\partial net_j} = f’(net_j) = y_j (1 - y_j) $)（Sigmoid 导数）<br>因此：<br>[<br>$\frac{\partial E_k}{\partial net_j} = (y_j - \hat{y}_j) \cdot y_j (1 - y_j)$<br>]</li>
</ul>
</li>
<li><p><strong>损失函数对 ( w_{hj} ) 的导数</strong>：<br>[<br>$\frac{\partial E<em>k}{\partial w</em>{hj}} = \frac{\partial E<em>k}{\partial net_j} \cdot \frac{\partial net_j}{\partial w</em>{hj}}$<br>]</p>
<ul>
<li>( $\frac{\partial net<em>j}{\partial w</em>{hj}} = b<em>h$ )（因为 ( $net_j = \sum w</em>{hj} b<em>h $)）<br>因此：<br>[<br>$\frac{\partial E_k}{\partial w</em>{hj}} = (y_j - \hat{y}_j) \cdot y_j (1 - y_j) \cdot b_h$<br>]</li>
</ul>
</li>
</ol>
<p><strong>2. 计算 ( $\frac{\partial E<em>k}{\partial v</em>{ih}} $)（隐藏层权重的梯度）</strong></p>
<p><strong>步骤分解</strong>：  </p>
<ol>
<li><p><strong>隐藏层输入</strong>：<br>[<br>$net<em>h = \sum</em>{i=1}^n v_{ih} x_i$<br>]<br>隐藏层节点的激活值为 ($ b_h = f(net_h) $)。</p>
</li>
<li><p><strong>损失函数对 ( net_h ) 的导数</strong>：<br>需要将误差从输出层反向传播到隐藏层：<br>[<br>$\frac{\partial E<em>k}{\partial net_h} = \sum</em>{j=1}^l \left( \frac{\partial E_k}{\partial net_j} \cdot \frac{\partial net_j}{\partial b_h} \right) \cdot \frac{\partial b_h}{\partial net_h}$<br>]</p>
<ul>
<li>($ \frac{\partial net<em>j}{\partial b_h} = w</em>{hj} $)（输出层输入依赖于隐藏层输出 ( b_h )）  </li>
<li>($ \frac{\partial b<em>h}{\partial net_h} = f’(net_h) = b_h (1 - b_h) $)<br>因此：<br>[<br>$\frac{\partial E_k}{\partial net_h} = \left( \sum</em>{j=1}^l \frac{\partial E<em>k}{\partial net_j} \cdot w</em>{hj} \right) \cdot b_h (1 - b_h)$<br>]</li>
</ul>
</li>
<li><p><strong>损失函数对 ( v_{ih} ) 的导数</strong>：<br>[<br>$\frac{\partial E<em>k}{\partial v</em>{ih}} = \frac{\partial E<em>k}{\partial net_h} \cdot \frac{\partial net_h}{\partial v</em>{ih}}$<br>]</p>
<ul>
<li>($ \frac{\partial net<em>h}{\partial v</em>{ih}} = x<em>i $)（因为 ($ net_h = \sum v</em>{ih} x<em>i $）<br>因此：<br>[<br>$\frac{\partial E_k}{\partial v</em>{ih}} = \left( \sum<em>{j=1}^l \frac{\partial E_k}{\partial net_j} \cdot w</em>{hj} \right) \cdot b_h (1 - b_h) \cdot x_i$<br>]</li>
</ul>
</li>
</ol>
<p><strong>3. 最终梯度公式</strong></p>
<ul>
<li><p><strong>输出层权重梯度</strong>：<br>[<br>$\frac{\partial E<em>k}{\partial w</em>{hj}} = \delta_j \cdot b_h, \quad \text{其中 } \delta_j = (y_j - \hat{y}_j) \cdot y_j (1 - y_j)$<br>]</p>
</li>
<li><p><strong>隐藏层权重梯度</strong>：<br>[<br>$\frac{\partial E<em>k}{\partial v</em>{ih}} = \delta<em>h \cdot x_i, \quad \text{其中 } \delta_h = \left( \sum</em>{j=1}^l \delta<em>j \cdot w</em>{hj} \right) \cdot b_h (1 - b_h)$<br>]</p>
</li>
</ul>
<p><strong>4. 参数更新规则</strong></p>
<p>使用梯度下降法更新权重：  </p>
<ol>
<li><p><strong>输出层权重更新</strong>：<br>[<br>$w<em>{hj} \leftarrow w</em>{hj} - \eta \cdot \frac{\partial E<em>k}{\partial w</em>{hj}}$<br>]</p>
</li>
<li><p><strong>隐藏层权重更新</strong>：<br>[<br>$v<em>{ih} \leftarrow v</em>{ih} - \eta \cdot \frac{\partial E<em>k}{\partial v</em>{ih}}$<br>]<br>其中，( $\eta $) 是学习率。</p>
</li>
</ol>
<p><strong>关键点总结</strong></p>
<ol>
<li><strong>链式法则</strong>：通过逐层反向传播误差，将全局误差分解为对每个权重的局部梯度。  </li>
<li><strong>敏感度（Delta）</strong>：  <ul>
<li>输出层：($ \delta_j = (y_j - \hat{y}_j) \cdot f’(net_j)$ )  </li>
<li>隐藏层：($ \delta<em>h = \left( \sum \delta_j w</em>{hj} \right) \cdot f’(net_h)$ )  </li>
</ul>
</li>
<li><strong>高效性</strong>：通过存储中间结果（如 ( \delta_j )），避免重复计算，降低时间复杂度。</li>
</ol>
<p>如果需要进一步解释具体步骤或示例，请随时告诉我！ 😊</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.bilibili.com/video/BV1oY411N7Xz/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">[5分钟深度学习] #01 梯度下降算法_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1zV4y1R7B4/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">反向传播算法可视化展示_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——线性模型</title>
    <url>/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200047048.png" alt="image-20250320200047048"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200109835.png" alt="image-20250320200109835"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/image-20250320200139754.png" alt="image-20250320200139754"></p>
<h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><h3 id="1、何为正则化？其功能是什么？如何理解L1和L2正则化？"><a href="#1、何为正则化？其功能是什么？如何理解L1和L2正则化？" class="headerlink" title="1、何为正则化？其功能是什么？如何理解L1和L2正则化？"></a>1、何为正则化？其功能是什么？如何理解L1和L2正则化？</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250320_170100.jpg" alt="IMG_20250320_170100"></p>
<h3 id="2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。"><a href="#2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。" class="headerlink" title="2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。"></a>2、什么是偏差与方差？简要说明偏差、方差与过拟合、欠拟合的关系。</h3><div class="table-container">
<table>
<thead>
<tr>
<th>现象</th>
<th>偏差</th>
<th>方差</th>
<th>典型原因</th>
<th>解决方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>欠拟合</td>
<td>高</td>
<td>低</td>
<td>模型过于简单（如线性模型拟合非线性数据）</td>
<td>增加特征、使用更复杂模型、减少正则化</td>
</tr>
<tr>
<td>过拟合</td>
<td>低</td>
<td>高</td>
<td>模型过于复杂（如深度树模型拟合噪声）</td>
<td>增加数据、正则化、简化模型、早停法</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250320_181442.jpg" alt="IMG_20250320_181442"></p>
<h3 id="3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）"><a href="#3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）" class="headerlink" title="3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）"></a>3、公式推导：最小二乘法、多元线性回归与岭回归、逻辑回归（极大似然法）</h3><p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163937.jpg" alt="IMG_20250321_163937"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163941.jpg" alt="IMG_20250321_163941"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163944.jpg" alt="IMG_20250321_163944"></p>
<p><img src="/2025/03/20/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/IMG_20250321_163948.jpg" alt="IMG_20250321_163948"></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.bilibili.com/video/BV1Z44y147xA/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">“L1和L2正则化”直观理解(之一)，从拉格朗日乘数法角度进行理解_哔哩哔哩_bilibili</a></p>
<p>超级棒的公式证明，对我帮助很大</p>
<p><a href="https://www.bilibili.com/video/BV1Mh411e7VU?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=3&amp;spm_id_from=333.788.videopod.episodes">https://www.bilibili.com/video/BV1Mh411e7VU?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11&amp;p=3&amp;spm_id_from=333.788.videopod.episodes</a></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——期末复习（下）</title>
    <url>/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
    <content><![CDATA[<h2 id="期末复习"><a href="#期末复习" class="headerlink" title="期末复习"></a>期末复习</h2><h3 id="方差与偏差"><a href="#方差与偏差" class="headerlink" title="方差与偏差"></a>方差与偏差</h3><p>方差（Variance）和偏差（Bias）是机器学习中衡量模型性能的两个核心概念，它们共同构成了<strong>偏差-方差权衡</strong>（Bias-Variance Tradeoff）的基础框架。以下是两者的定义与区别：</p>
<p><strong>1. 偏差（Bias）</strong></p>
<ul>
<li><strong>定义</strong>：偏差是指模型预测的期望值与真实值之间的差异。它反映了模型本身的拟合能力，即是否能够准确捕捉数据中的规律。</li>
</ul>
<p><strong>2. 方差（Variance）</strong></p>
<ul>
<li><strong>定义</strong>：方差是指模型在不同训练数据集下预测结果的波动程度。它衡量了模型对训练数据中噪声或微小变化的敏感性。</li>
</ul>
<p><strong>3. 如何降低偏差与方差</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>目标</strong></th>
<th><strong>方法</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>降低偏差</strong></td>
<td>增加模型复杂度（如更多特征、更深的神经网络）、减少正则化强度</td>
<td>使用多项式回归替代线性回归</td>
</tr>
<tr>
<td><strong>降低方差</strong></td>
<td>增加训练数据、引入正则化（L1/L2）、使用集成方法（如 Bagging、Boosting）</td>
<td>随机森林（Bagging）降低决策树的方差</td>
</tr>
</tbody>
</table>
</div>
<p><strong>4. 总结</strong></p>
<ul>
<li><strong>偏差</strong>关注模型是否能准确拟合数据（<strong>学习能力</strong>），而<strong>方差</strong>关注模型对数据波动的稳定性（<strong>泛化能力</strong>）。</li>
<li>实际应用中需通过交叉验证、正则化或集成学习等技术平衡两者的关系。</li>
</ul>
<h3 id="监督学习与无监督学习"><a href="#监督学习与无监督学习" class="headerlink" title="监督学习与无监督学习"></a>监督学习与无监督学习</h3><p>以下是关于监督学习与无监督学习的核心区别总结：</p>
<p><strong>1. 监督学习（Supervised Learning）</strong></p>
<p><strong>任务类型</strong>：  </p>
<ul>
<li><strong>分类（Classification）</strong>：预测离散类别标签（如垃圾邮件/非垃圾邮件）。  </li>
<li><strong>回归（Regression）</strong>：预测连续数值标签（如房价预测）。  </li>
</ul>
<p><strong>特点</strong>：  </p>
<ul>
<li>需要<strong>带标签的样本</strong>（Labeled Data），即每个训练样本都有明确的输入 $ x $ 和输出 $ y $。  </li>
<li>模型通过学习输入与标签之间的映射关系进行预测。  </li>
</ul>
<p><strong>2. 无监督学习（Unsupervised Learning）</strong></p>
<p><strong>任务类型</strong>：  </p>
<ul>
<li><strong>聚类（Clustering）</strong>：将样本划分为具有相似特征的群体（如客户分群）。  </li>
<li><strong>降维（Dimensionality Reduction）</strong>：压缩数据维度同时保留关键信息（如PCA）。  </li>
</ul>
<p><strong>特点</strong>：  </p>
<ul>
<li>仅需<strong>无标签的样本</strong>（Unlabeled Data），无需预先定义输出目标。  </li>
<li>模型自主挖掘数据内在结构或分布规律。  </li>
</ul>
<h3 id="贝叶斯分类"><a href="#贝叶斯分类" class="headerlink" title="贝叶斯分类"></a>贝叶斯分类</h3><h4 id="贝叶斯分类器"><a href="#贝叶斯分类器" class="headerlink" title="贝叶斯分类器"></a>贝叶斯分类器</h4><h5 id="贝叶斯决策论"><a href="#贝叶斯决策论" class="headerlink" title="贝叶斯决策论"></a>贝叶斯决策论</h5><p>本质思想：寻找合适的参数使得「当前的样本情况发生的概率」最大。</p>
<p>又由于假设每一个样本相互独立（概率条件理想的情况下），因此可以用连乘的形式表示上述概率，当然由于概率较小导致连乘容易出现浮点数精度损失，因此尝尝采用取对数的方式来避免「下溢」问题。也就是所谓的「对数似然估计」方法。</p>
<p>在已知样本特征 $ \mathbf{x} $ 的条件下，选择分类结果 $ c_i $，使得分类的期望损失（Risk）最小<strong>。</strong></p>
<p><strong>(1) 损失函数 $ \lambda_{ij} $</strong></p>
<ul>
<li><strong>定义</strong>：$ \lambda_{ij} $ 是将真实类别为 $ c_j $ 的样本误分类为 $ c_i $ 所产生的损失。<ul>
<li>例如：<ul>
<li>在医学诊断中，若 $ c_1 $ 表示“患病”，$ c_2 $ 表示“未患病”：<ul>
<li>$ \lambda_{21} $：将实际患病（$ c_1 $）误判为未患病（$ c_2 $）的损失（可能更高）。</li>
<li>$ \lambda_{12} $：将实际未患病（$ c_2 $）误判为患病（$ c_1 $）的损失（可能较低）。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>(2) 条件风险（单个样本的期望损失）</strong></p>
<p>对于给定样本 $ \mathbf{x} $，若将其分类为 $ c_i $，则其<strong>条件风险</strong>为：</p>
<script type="math/tex; mode=display">
R(c_i | \mathbf{x}) = \sum_{j=1}^N \lambda_{ij} P(c_j | \mathbf{x})</script><ul>
<li><strong>含义</strong>：在已知 $ \mathbf{x} $ 的情况下，分类为 $ c_i $ 的平均损失。</li>
<li><strong>推导</strong>：<ul>
<li>$ P(c_j | \mathbf{x}) $：样本 $ \mathbf{x} $ 真实属于 $ c_j $ 的后验概率。</li>
<li>$ \lambda<em>{ij} $：若真实类别是 $ c_j $，但被分到 $ c_i $，则产生损失 $ \lambda</em>{ij} $。</li>
<li>因此，总期望损失是所有可能真实类别的加权和（权重为后验概率）。</li>
</ul>
</li>
</ul>
<p><strong>(3) 总体风险</strong></p>
<p>对于整个数据集，分类器 $ h(\mathbf{x}) $ 的<strong>总体风险</strong>为：</p>
<script type="math/tex; mode=display">
R(h) = \mathbb{E}_{\mathbf{x}}[R(h(\mathbf{x}) | \mathbf{x})] = \int R(h(\mathbf{x}) | \mathbf{x}) p(\mathbf{x}) d\mathbf{x}</script><ul>
<li><strong>含义</strong>：所有样本的平均条件风险。h为分类器（模型）</li>
<li><strong>目标</strong>：找到使 $ R(h) $ 最小的分类器 $ h(\mathbf{x}) $。</li>
</ul>
<h5 id="贝叶斯决策规则"><a href="#贝叶斯决策规则" class="headerlink" title="贝叶斯决策规则"></a><strong>贝叶斯决策规则</strong></h5><p>根据上述定义，贝叶斯决策论的分类规则是：</p>
<blockquote>
<p><strong>对于样本 $ \mathbf{x} $，选择使其条件风险 $ R(c_i | \mathbf{x}) $ 最小的类别 $ c_i $ 作为预测结果。</strong></p>
</blockquote>
<p>即：</p>
<script type="math/tex; mode=display">
h^*(\mathbf{x}) = \arg\min_{c_i} R(c_i | \mathbf{x}) = \arg\min_{c_i} \sum_{j=1}^N \lambda_{ij} P(c_j | \mathbf{x})</script><h5 id="特殊情况：0-1-损失函数"><a href="#特殊情况：0-1-损失函数" class="headerlink" title="特殊情况：0-1 损失函数"></a><strong>特殊情况：0-1 损失函数</strong></h5><p>当所有误分类的损失相同（即 $ \lambda<em>{ij} = 1 $ 对于 $ i \neq j $，$ \lambda</em>{ii} = 0 $）<strong>0-1 损失函数</strong>：</p>
<script type="math/tex; mode=display">
\lambda_{ij} = 
\begin{cases}
0, & \text{if } i = j \\
1, & \text{otherwise}
\end{cases}</script><p>此时条件风险简化为：</p>
<script type="math/tex; mode=display">
R(c_i | \mathbf{x}) = \sum_{j \neq i} P(c_j | \mathbf{x}) = 1 - P(c_i | \mathbf{x})</script><p>原因：概率之和为 1：$ \sum<em>{j=1}^N P(c_j | \mathbf{x}) = 1 $，因此 $ \sum</em>{j \neq i} P(c_j | \mathbf{x}) = 1 - P(c_i | \mathbf{x}) $。</p>
<p>此时，最小化风险等价于<strong>最大化后验概率</strong>，即：</p>
<script type="math/tex; mode=display">
h^*(\mathbf{x}) = \arg\max_{c_i} P(c_i | \mathbf{x})</script><p>这正是传统贝叶斯分类器的决策规则。</p>
<blockquote>
<p>即在x样本的情况下，分类正确的概率最大</p>
</blockquote>
<h4 id="后验概率与先验概率"><a href="#后验概率与先验概率" class="headerlink" title="后验概率与先验概率"></a>后验概率与先验概率</h4><h5 id="后验概率"><a href="#后验概率" class="headerlink" title="后验概率"></a>后验概率</h5><p>后验概率（Posterior Probability）是贝叶斯理论中的核心概念，指的是<strong>在观察到新证据（数据）后，对事件发生概率的修正</strong> 。<br>其本质是：</p>
<blockquote>
<p><strong>“已知结果（数据），反推原因（类别或参数）的概率”</strong> 。 </p>
</blockquote>
<p>已知结果（数据）B，反推最可能的原因A（后验概率 <em>P</em>(<em>A</em>∣<em>B</em>) ）</p>
<h5 id="先验概率（Prior-Probability）"><a href="#先验概率（Prior-Probability）" class="headerlink" title="先验概率（Prior Probability）"></a><strong>先验概率（Prior Probability）</strong></h5><p>先验概率是贝叶斯统计中的核心概念，指的是在<strong>观察到新数据之前</strong>，对某一事件或假设的概率估计。它是基于<strong>已有知识、经验或假设</strong>得出的初始概率，后续会通过新数据更新为更准确的<strong>后验概率</strong>。</p>
<p><strong>1. 核心定义</strong></p>
<ul>
<li><p><strong>数学表达</strong>：  </p>
<script type="math/tex; mode=display">
P(A)</script><ul>
<li>$ P(A) $：事件 $ A $ 的先验概率。</li>
<li>例如：$ A $ 表示“某人患有某种疾病”，则 $ P(A) $ 是该疾病的已知发病率（在未进行检测前的概率）。</li>
</ul>
</li>
<li><p><strong>与后验概率的区别</strong>：  </p>
<ul>
<li><strong>先验概率</strong>：$ P(A) $，在无新数据时的概率。  </li>
<li><strong>后验概率</strong>：$ P(A|B) $，在观察到数据 $ B $ 后更新的概率（通过贝叶斯定理计算）。</li>
</ul>
</li>
</ul>
<p><strong>2. 直观理解</strong></p>
<p><strong>(1) 类比：医学诊断</strong></p>
<ul>
<li><strong>先验概率</strong>：某种疾病的已知发病率（如 1%）。  </li>
<li><strong>新数据</strong>：患者接受检测，结果为阳性。  </li>
<li><strong>后验概率</strong>：结合发病率和检测结果，计算实际患病的概率（如 8.7%，参考贝叶斯定理的经典医学测试案例）。</li>
</ul>
<h4 id="生成式模型和判别式模型"><a href="#生成式模型和判别式模型" class="headerlink" title="生成式模型和判别式模型"></a>生成式模型和判别式模型</h4><h5 id="核心区别"><a href="#核心区别" class="headerlink" title="核心区别"></a><strong>核心区别</strong></h5><div class="table-container">
<table>
<thead>
<tr>
<th><strong>模型类型</strong></th>
<th><strong>建模目标</strong></th>
<th><strong>数学表达</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>判别式模型</strong></td>
<td>直接建模 $ P(c</td>
<td>\mathbf{x}) $</td>
<td>$ P(c</td>
<td>\mathbf{x}) $</td>
</tr>
<tr>
<td><strong>生成式模型</strong></td>
<td>先建模联合概率 $ P(\mathbf{x}, c) $，再推导 $ P(c</td>
<td>\mathbf{x}) $</td>
<td>$ P(c</td>
<td>\mathbf{x}) = \frac{P(\mathbf{x}</td>
<td>c)P(c)}{P(\mathbf{x})} $</td>
</tr>
</tbody>
</table>
</div>
<h5 id="详细解释"><a href="#详细解释" class="headerlink" title="详细解释"></a><strong>详细解释</strong></h5><p><strong>1. 判别式模型（Discriminative Model）</strong></p>
<ul>
<li><strong>目标</strong>：直接学习从输入 $ \mathbf{x} $ 到标签 $ c $ 的映射关系。</li>
<li><strong>数学本质</strong>：建模条件概率 $ P(c|\mathbf{x}) $，即“已知特征 $ \mathbf{x} $，预测类别 $ c $”。</li>
<li><strong>特点</strong>：<ul>
<li>不关心数据本身的分布，只关注分类边界。</li>
<li>例如：逻辑回归、支持向量机（SVM）、神经网络等。</li>
</ul>
</li>
</ul>
<p><strong>2. 生成式模型（Generative Model）</strong></p>
<ul>
<li><p><strong>目标</strong>：先学习数据的生成过程，即联合概率 $ P(\mathbf{x}, c) $，再通过贝叶斯定理推导条件概率 $ P(c|\mathbf{x}) $。</p>
</li>
<li><p><strong>数学步骤</strong>：</p>
<ol>
<li>建模 $ P(\mathbf{x}|c) $（特征在类别 $ c $ 下的分布）和 $ P(c) $（类别先验）。</li>
<li>根据贝叶斯定理计算后验概率：<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(\mathbf{x}|c)P(c)}{P(\mathbf{x})}</script></li>
<li>选择使 $ P(c|\mathbf{x}) $ 最大的类别作为预测结果。</li>
</ol>
</li>
</ul>
<h5 id="示例：二分类问题"><a href="#示例：二分类问题" class="headerlink" title="示例：二分类问题"></a><strong>示例：二分类问题</strong></h5><p>假设我们要判断一封邮件是否为垃圾邮件（$ c=spam $ 或 $ ham $）。</p>
<p><strong>判别式模型（逻辑回归）</strong></p>
<p>直接建模：</p>
<script type="math/tex; mode=display">
P(spam|\mathbf{x}) = \frac{1}{1 + e^{-(w^T \mathbf{x} + b)}}</script><p>若 $ P(spam|\mathbf{x}) &gt; 0.5 $，则判定为垃圾邮件。</p>
<p><strong>生成式模型（朴素贝叶斯）</strong></p>
<ol>
<li>建模联合概率：<script type="math/tex; mode=display">
P(\mathbf{x}, spam) = P(spam) \prod_{i} P(word_i|spam)</script><script type="math/tex; mode=display">
P(\mathbf{x}, ham) = P(ham) \prod_{i} P(word_i|ham)</script></li>
<li>计算后验概率：<script type="math/tex; mode=display">
P(spam|\mathbf{x}) = \frac{P(\mathbf{x}|spam)P(spam)}{P(\mathbf{x})}</script><script type="math/tex; mode=display">
P(ham|\mathbf{x}) = \frac{P(\mathbf{x}|ham)P(ham)}{P(\mathbf{x})}</script></li>
<li>选择概率更大的类别。</li>
</ol>
<h4 id="生成式模型的建模思路"><a href="#生成式模型的建模思路" class="headerlink" title="生成式模型的建模思路"></a>生成式模型的建模思路</h4><p>根据概率论的基本定义：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(\mathbf{x}, c)}{P(\mathbf{x})}</script><ul>
<li><strong>含义</strong>：<ul>
<li>$ P(\mathbf{x}, c) $：联合概率，表示特征 $ \mathbf{x} $ 和类别 $ c $ 同时发生的概率。</li>
<li>$ P(\mathbf{x}) $：边缘概率（证据），表示特征 $ \mathbf{x} $ 出现的概率，用于归一化。</li>
</ul>
</li>
</ul>
<p>根据贝叶斯定理，联合概率 $ P(\mathbf{x}, c) $ 可以分解为：</p>
<script type="math/tex; mode=display">
P(\mathbf{x}, c) = P(c) \cdot P(\mathbf{x}|c)</script><p>其中：</p>
<ul>
<li>$ P(c) $：类先验概率（Prior Probability），表示类别 $ c $ 在数据中的整体占比。</li>
<li>$ P(\mathbf{x}|c) $：似然度（Likelihood），表示在类别 $ c $ 下，特征 $ \mathbf{x} $ 出现的概率。</li>
</ul>
<p>将上述分解代入条件概率公式，得到：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(c) \cdot P(\mathbf{x}|c)}{P(\mathbf{x})}</script><p>产生问题：</p>
<p>在贝叶斯分类中，需要计算联合概率 <em>P</em>(<strong>x</strong>∣<em>c</em>) ，即在类别 <em>c</em> 下，特征向量 <strong>x</strong>=(<em>x</em>1,<em>x</em>2,…,<em>x**d</em>) 的条件概率。<br>若直接建模联合概率，需估计 <em>d</em> 个特征的所有可能组合的概率。例如：</p>
<ul>
<li>若每个特征有 <em>k</em> 个取值，类别数为 <em>K</em> ，则需要估计 <em>K</em>⋅<em>k**d</em> 个参数。</li>
<li>当特征维度 <em>d</em> 很大时（如文本分类中成千上万的词汇），参数数量呈指数级增长，导致计算不可行（<strong>维度灾难</strong> ）。</li>
</ul>
<p>举例：</p>
<ul>
<li><strong>低维空间</strong> ：假设只有 2 个特征（如“免费”和“中奖”），每个特征取值为 0 或 1，则特征空间共有 22=4 个可能的组合（即四个格子）。<ul>
<li>如果有 100 封邮件，每个格子平均有 25 封邮件（数据较密集）。</li>
</ul>
</li>
<li><strong>高维空间</strong> ：<br>当特征维度增加到 <em>d</em>=10,000 时，特征空间的组合数是 210,000 ，远大于宇宙中原子的数量（约 1080 ）。<ul>
<li>即使有 100 万封邮件，每个组合几乎都是空的（数据极度稀疏）。</li>
</ul>
</li>
</ul>
<p><strong>结果</strong> ：<br>在高维空间中，训练数据无法覆盖所有可能的特征组合，导致模型无法可靠估计联合概率 <em>P</em>(x∣c) 。</p>
<p>因此产生<strong>属性条件独立性假设</strong></p>
<h4 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h4><p>朴素贝叶斯分类器的核心思想是通过<strong>贝叶斯定理</strong>和<strong>属性条件独立性假设</strong>来简化计算，从而高效地进行分类。</p>
<h5 id="属性条件独立性假设"><a href="#属性条件独立性假设" class="headerlink" title="属性条件独立性假设"></a>属性条件独立性假设</h5><p>朴素贝叶斯的核心假设是：<strong>在已知类别 $ c $ 的条件下，所有属性（特征）之间相互独立</strong>。<br>因此，联合概率 $ P(\mathbf{x}|c) $ 可以分解为各属性独立概率的乘积：</p>
<script type="math/tex; mode=display">
P(\mathbf{x}|c) = \prod_{i=1}^d P(x_i|c)</script><p>其中 $ d $ 是特征的数量，$ x_i $ 是第 $ i $ 个特征的取值。</p>
<p>将此代入贝叶斯公式：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(c) \cdot \prod_{i=1}^d P(x_i|c)}{P(\mathbf{x})}</script><h5 id="为何可以忽略-P-mathbf-x"><a href="#为何可以忽略-P-mathbf-x" class="headerlink" title="为何可以忽略 $ P(\mathbf{x}) $?"></a><strong>为何可以忽略 $ P(\mathbf{x}) $?</strong></h5><p>在分类任务中，我们的目标是比较不同类别 $ c $ 的后验概率 $ P(c|\mathbf{x}) $，并选择最大值。由于 $ P(\mathbf{x}) $ 对所有类别来说是相同的常量（与类别无关），因此在最大化过程中可以忽略：</p>
<script type="math/tex; mode=display">
\arg\max_{c} P(c|\mathbf{x}) = \arg\max_{c} \left[ \frac{P(c) \cdot \prod_{i=1}^d P(x_i|c)}{P(\mathbf{x})} \right] = \arg\max_{c} \left[ P(c) \cdot \prod_{i=1}^d P(x_i|c) \right]</script><p>这就是公式中 $ P(\mathbf{x}) $ 被省略的原因。</p>
<blockquote>
<p>在比较的过程中，分母相同，可以忽略</p>
</blockquote>
<h5 id="朴素贝叶斯的最终决策规则"><a href="#朴素贝叶斯的最终决策规则" class="headerlink" title="朴素贝叶斯的最终决策规则"></a><strong>朴素贝叶斯的最终决策规则</strong></h5><p>简化后的决策规则为：</p>
<script type="math/tex; mode=display">
h_{nb}(\mathbf{x}) = \arg\max_{c} \left[ P(c) \cdot \prod_{i=1}^d P(x_i|c) \right]</script><p>即：</p>
<ul>
<li>计算每个类别的先验概率 $ P(c) $。</li>
<li>计算每个特征在该类别下的条件概率 $ P(x_i|c) $。</li>
<li>将这些概率相乘，选择乘积最大的类别作为预测结果。</li>
</ul>
<h5 id="类先验概率-P-c-的估计方法"><a href="#类先验概率-P-c-的估计方法" class="headerlink" title="类先验概率 $ P(c) $ 的估计方法"></a><strong>类先验概率 $ P(c) $ 的估计方法</strong></h5><p>基于<strong>大数定律</strong></p>
<script type="math/tex; mode=display">
P(c) = \frac{|D_c|}{|D|}</script><ul>
<li><p><strong>符号含义</strong>：</p>
<ul>
<li>$ D $：训练集，包含所有样本。</li>
<li>$ D_c $：训练集中类别为 $ c $ 的样本子集。</li>
<li>$ |D_c| $：类别 $ c $ 的样本数量。</li>
<li>$ |D| $：训练集总样本数量。</li>
</ul>
</li>
<li><p><strong>直观解释</strong>：<br>类先验概率等于该类别样本数占总样本数的比例。</p>
</li>
</ul>
<h5 id="条件概率-P-x-i-c-的估计方法"><a href="#条件概率-P-x-i-c-的估计方法" class="headerlink" title="条件概率 $ P(x_i | c) $ 的估计方法"></a><strong>条件概率 $ P(x_i | c) $ 的估计方法</strong></h5><p>在生成式模型（如朴素贝叶斯分类器）中，<strong>条件概率 $ P(x_i | c) $</strong> 表示在类别 $ c $ 下，第 $ i $ 个属性取值为 $ x_i $ 的概率。根据属性类型（离散或连续），其估计方法不同：</p>
<p><strong>1. 离散属性的条件概率估计</strong></p>
<p><strong>公式</strong>：</p>
<script type="math/tex; mode=display">
P(x_i | c) = \frac{|D_{c,x_i}|}{|D_c|}</script><ul>
<li><strong>符号含义</strong>：<ul>
<li>$ D_c $：训练集中类别为 $ c $ 的样本集合。</li>
<li>$ D_{c,x_i} $：$ D_c $ 中第 $ i $ 个属性取值为 $ x_i $ 的样本子集。</li>
<li>$ |D<em>{c,x_i}| $：$ D</em>{c,x_i} $ 的样本数量。</li>
<li>$ |D_c| $：类别 $ c $ 的总样本数量。</li>
</ul>
</li>
</ul>
<p><strong>直观解释</strong>：</p>
<ul>
<li>在类别 $ c $ 的样本中，统计第 $ i $ 个属性取值为 $ x_i $ 的频率，作为 $ P(x_i | c) $ 的估计。</li>
<li><strong>示例</strong>：<br>若类别 $ c=spam $（垃圾邮件）有 200 封，其中 150 封包含“免费”一词，则：<script type="math/tex; mode=display">
P(\text{“免费”} | spam) = \frac{150}{200} = 0.75</script></li>
</ul>
<p><strong>注意事项</strong>：</p>
<ul>
<li><strong>零概率问题</strong>：若某属性值在类别 $ c $ 中未出现，则 $ P(x_i | c) = 0 $，可能导致后续计算失效。<br><strong>解决方案</strong>：使用<strong>拉普拉斯平滑（Laplace Smoothing）</strong>，将公式改为：<script type="math/tex; mode=display">
P(x_i | c) = \frac{|D_{c,x_i}| + 1}{|D_c| + K}</script>其中 $ K $ 是该属性的取值总数。</li>
</ul>
<p><strong>2. 连续属性的条件概率估计</strong></p>
<p><strong>假设</strong>：属性服从正态分布（高斯分布）</p>
<script type="math/tex; mode=display">
p(x_i | c) = \frac{1}{\sqrt{2\pi}\sigma_{c,i}} \exp\left( -\frac{(x_i - \mu_{c,i})^2}{2\sigma_{c,i}^2} \right)</script><ul>
<li><strong>符号含义</strong>：<ul>
<li>$ \mu_{c,i} $：类别 $ c $ 在第 $ i $ 个属性上的均值。</li>
<li>$ \sigma_{c,i}^2 $：类别 $ c $ 在第 $ i $ 个属性上的方差。</li>
</ul>
</li>
</ul>
<p><strong>直观解释</strong>：</p>
<ul>
<li>假设在类别 $ c $ 下，属性 $ x<em>i $ 服从均值为 $ \mu</em>{c,i} $、方差为 $ \sigma_{c,i}^2 $ 的正态分布。</li>
<li><strong>示例</strong>：<br>若类别 $ c=spam $ 的“字数”属性均值 $ \mu<em>{spam, \text{字数}} = 500 $，方差 $ \sigma</em>{spam, \text{字数}}^2 = 100 $，则：<script type="math/tex; mode=display">
p(600 | spam) = \frac{1}{\sqrt{2\pi \cdot 100}} \exp\left( -\frac{(600 - 500)^2}{2 \cdot 100} \right) \approx 0.004</script></li>
</ul>
<p><strong>注意事项</strong>：</p>
<ul>
<li><strong>分布假设</strong>：若实际数据不符合正态分布，需调整假设（如使用核密度估计、对数变换等）。</li>
<li><strong>参数估计</strong>：均值和方差通过训练数据计算：<script type="math/tex; mode=display">
\mu_{c,i} = \frac{1}{|D_c|} \sum_{x \in D_c} x_i, \quad \sigma_{c,i}^2 = \frac{1}{|D_c|} \sum_{x \in D_c} (x_i - \mu_{c,i})^2</script></li>
</ul>
<h4 id="半朴素贝叶斯分类器"><a href="#半朴素贝叶斯分类器" class="headerlink" title="半朴素贝叶斯分类器"></a>半朴素贝叶斯分类器</h4><p>半朴素贝叶斯分类器是对传统<strong>朴素贝叶斯</strong>的改进，它在保留计算效率的同时，<strong>适当引入部分属性间的依赖关系</strong>，从而在分类性能和计算复杂度之间取得平衡。</p>
<h5 id="独依赖估计（ODE）方法"><a href="#独依赖估计（ODE）方法" class="headerlink" title="独依赖估计（ODE）方法"></a><strong>独依赖估计（ODE）方法</strong></h5><p><strong>(1) 定义</strong></p>
<p>独依赖估计（One-Dependent Estimator, ODE）是半朴素贝叶斯的一种实现方式，其核心假设是：</p>
<blockquote>
<p><strong>每个属性 $ x_i $ 在类别 $ c $ 之外最多依赖于一个其他属性（称为父属性 $ pa_i $）</strong>。</p>
</blockquote>
<p>数学表达式为：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) \propto P(c) \prod_{i=1}^d P(x_i | c, pa_i)</script><p>其中：</p>
<ul>
<li>$ pa_i $：属性 $ x_i $ 的父属性（依赖的单一属性）。</li>
<li>$ P(x_i | c, pa_i) $：在类别 $ c $ 和父属性 $ pa_i $ 下，属性 $ x_i $ 的条件概率。</li>
</ul>
<p><strong>(2) 直观理解</strong></p>
<ul>
<li>每个属性 $ x_i $ 的分布不仅受类别 $ c $ 影响，还受其父属性 $ pa_i $ 的影响。</li>
<li>例如，在文本分类中，若属性 $ x_1 $ 是“免费”，$ x_2 $ 是“中奖”，可设定 $ pa_2 = x_1 $，表示“中奖”在类别和“免费”的共同作用下出现。</li>
</ul>
<h5 id="超父独依赖估计（SPODE）"><a href="#超父独依赖估计（SPODE）" class="headerlink" title="超父独依赖估计（SPODE）"></a><strong>超父独依赖估计（SPODE）</strong></h5><p>超父独依赖估计（Super Parent One-Dependent Estimator, SPODE）是<strong>半朴素贝叶斯分类器</strong>的一种扩展，其核心思想是：</p>
<blockquote>
<p><strong>所有属性都依赖于同一个“超父”属性 $ x_i $</strong>，从而在保留部分依赖关系的同时避免完全联合概率的计算。</p>
</blockquote>
<p><strong>(1) 贝叶斯定理展开</strong></p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) = \frac{P(\mathbf{x}, c)}{P(\mathbf{x})}</script><p>其中：</p>
<ul>
<li>$ P(\mathbf{x}, c) $：联合概率，表示特征 $ \mathbf{x} $ 和类别 $ c $ 同时发生的概率。</li>
<li>$ P(\mathbf{x}) $：证据（归一化因子）。</li>
</ul>
<p><strong>(2) 引入“超父”属性 $ x_i $</strong></p>
<p>假设所有属性 $ x_j (j \neq i) $ 在类别 $ c $ 下仅依赖于 $ x_i $，则：</p>
<script type="math/tex; mode=display">
P(\mathbf{x}, c) = P(c, x_i) \cdot P(x_1, \dots, x_{i-1}, x_{i+1}, \dots, x_d | c, x_i)</script><p>进一步分解为：</p>
<script type="math/tex; mode=display">
P(\mathbf{x}, c) = P(c, x_i) \cdot \prod_{j \neq i} P(x_j | c, x_i)</script><p><strong>(3) 最终形式</strong></p>
<p>由于 $ P(\mathbf{x}) $ 对所有类别相同，可忽略，最终决策规则为：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) \propto P(c, x_i) \cdot \prod_{j=1}^d P(x_j | c, x_i)</script><p>其中：</p>
<ul>
<li>$ P(c, x_i) $：类别 $ c $ 和属性 $ x_i $ 的联合概率。</li>
<li>$ P(x_j | c, x_i) $：在类别 $ c $ 和 $ x_i $ 的条件下，属性 $ x_j $ 的概率。</li>
</ul>
<h5 id="树增强朴素贝叶斯（TAN-Tree-Augmented-Naive-Bayes）"><a href="#树增强朴素贝叶斯（TAN-Tree-Augmented-Naive-Bayes）" class="headerlink" title="树增强朴素贝叶斯（TAN: Tree-Augmented Naive Bayes）"></a><strong>树增强朴素贝叶斯（TAN: Tree-Augmented Naive Bayes）</strong></h5><p><strong>TAN</strong>（Tree-Augmented Naive Bayes）是<strong>半朴素贝叶斯分类器</strong>的一种扩展，旨在通过引入属性间的<strong>树状依赖关系</strong>，在保留计算效率的同时，显著提升分类性能。它结合了<strong>贝叶斯网络</strong>的建模能力和<strong>生成式模型</strong>的概率推理优势。</p>
<p><strong>1. 核心思想</strong></p>
<p>TAN 的核心假设是：</p>
<blockquote>
<p><strong>所有属性（特征）在类别 $ c $ 的基础上，形成一个以属性为节点的树状依赖结构</strong>，即每个属性最多依赖一个其他属性（父属性），且整个依赖图是一棵无环的树。</p>
</blockquote>
<p><strong>数学表达</strong>：</p>
<script type="math/tex; mode=display">
P(c|\mathbf{x}) \propto P(c) \cdot \prod_{i=1}^d P(x_i | c, pa_i)</script><p>其中：</p>
<ul>
<li>$ pa_i $：属性 $ x_i $ 的父属性（依赖的单一属性）。</li>
<li>$ P(x_i | c, pa_i) $：在类别 $ c $ 和父属性 $ pa_i $ 的条件下，属性 $ x_i $ 的条件概率。</li>
</ul>
<p><strong>2. TAN 的构建步骤</strong></p>
<p>TAN 通过以下步骤构建属性间的依赖结构：</p>
<p><strong>(1) 计算互信息（Mutual Information）</strong></p>
<p>互信息衡量两个属性之间的相关性：</p>
<script type="math/tex; mode=display">
I(x_i, x_j) = \sum_{x_i, x_j} P(x_i, x_j) \log \frac{P(x_i, x_j)}{P(x_i)P(x_j)}</script><ul>
<li><strong>含义</strong>：互信息越大，两个属性之间的依赖关系越强。</li>
</ul>
<p><strong>(2) 构建带权图</strong></p>
<ul>
<li>将所有属性视为图中的节点。</li>
<li>每对属性间的边权重设为互信息 $ I(x_i, x_j) $。</li>
</ul>
<p><strong>(3) 最大带权生成树（Maximum Weight Spanning Tree, MWST）</strong></p>
<p>使用克鲁斯卡尔（Kruskal）算法或普里姆（Prim）算法，选择一棵连接所有属性节点的树，使得：</p>
<ul>
<li>树的边权重（互信息）总和最大。</li>
<li>树中无环。</li>
</ul>
<p><strong>(4) 确定依赖方向</strong></p>
<ul>
<li>随机选择一个根节点（或根据领域知识指定）。</li>
<li>从根节点出发，确定每条边的方向（父属性 → 子属性）。</li>
</ul>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250605223036362.png" alt="image-20250605223036362"></p>
<h4 id="贝叶斯网"><a href="#贝叶斯网" class="headerlink" title="贝叶斯网"></a>贝叶斯网</h4><p>待学习</p>
<h4 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a>EM算法</h4><p>EM算法（Expectation-Maximization Algorithm）是一种<strong>迭代优化算法</strong>，用于处理<strong>含有隐变量</strong>（Hidden Variables）或<strong>缺失数据</strong>的概率模型参数估计问题。它的核心思想是通过交替执行<strong>期望（E）步</strong>和<strong>最大化（M）步</strong>，逐步逼近模型参数的最大似然估计。</p>
<h5 id="1-核心思想：解决隐变量问题"><a href="#1-核心思想：解决隐变量问题" class="headerlink" title="1. 核心思想：解决隐变量问题"></a><strong>1. 核心思想：解决隐变量问题</strong></h5><p><strong>(1) 什么是隐变量？</strong></p>
<p>隐变量（Latent Variables）是模型中<strong>不可观测但影响观测数据</strong>的变量。例如：</p>
<ul>
<li><strong>混合高斯模型（GMM）</strong>：每个样本属于哪个高斯分布是隐变量。</li>
<li><strong>聚类任务</strong>：样本所属的聚类标签是隐变量。</li>
</ul>
<p><strong>(2) 问题挑战</strong></p>
<p>当存在隐变量时，直接最大化似然函数变得困难。例如：</p>
<script type="math/tex; mode=display">
\log P(\mathbf{x}|\theta) = \log \sum_z P(\mathbf{x}, z|\theta)</script><p>其中 $ z $ 是隐变量，$ \theta $ 是模型参数。由于对数中包含求和，直接求导无法分离参数。</p>
<p><strong>(3) EM算法的解决方案</strong></p>
<p>EM算法通过以下步骤迭代求解：</p>
<ol>
<li><strong>E步（期望）</strong>：用当前参数估计隐变量的后验分布（即“责任”分配）。</li>
<li><strong>M步（最大化）</strong>：基于隐变量的后验分布，最大化期望似然函数以更新参数。</li>
</ol>
<h5 id="2-算法流程"><a href="#2-算法流程" class="headerlink" title="2. 算法流程"></a><strong>2. 算法流程</strong></h5><p><strong>(1) 初始化参数</strong></p>
<p>选择初始参数 $ \theta^{(0)} $，例如随机初始化或通过启发式方法设定。</p>
<p><strong>(2) E步：计算隐变量后验分布</strong></p>
<p>给定当前参数 $ \theta^{(t)} $，计算隐变量 $ z $ 的后验概率：</p>
<script type="math/tex; mode=display">
Q^{(t)}(z) = P(z|\mathbf{x}, \theta^{(t)})</script><p>这一步为每个样本分配隐变量的概率分布（如样本属于某个聚类的概率）。</p>
<p><strong>(3) M步：最大化期望似然</strong></p>
<p>基于 $ Q^{(t)}(z) $，构造期望似然函数并最大化：</p>
<script type="math/tex; mode=display">
\theta^{(t+1)} = \arg\max_{\theta} \sum_z Q^{(t)}(z) \log P(\mathbf{x}, z|\theta)</script><p>这一步更新参数 $ \theta $，使得期望似然最大。</p>
<p><strong>(4) 收敛判断</strong></p>
<p>重复E步和M步直到参数收敛（如 $ |\theta^{(t+1)} - \theta^{(t)}| &lt; \epsilon $）或达到最大迭代次数。</p>
<h5 id="3-示例：混合高斯模型（GMM）"><a href="#3-示例：混合高斯模型（GMM）" class="headerlink" title="3. 示例：混合高斯模型（GMM）"></a><strong>3. 示例：混合高斯模型（GMM）</strong></h5><p>假设数据由多个高斯分布生成，但不知道每个样本属于哪个分布。</p>
<p><strong>(1) 模型定义</strong></p>
<ul>
<li>观测变量 $ x_i \in \mathbb{R}^d $：第 $ i $ 个样本。</li>
<li>隐变量 $ z_i \in {1, …, K} $：样本 $ x_i $ 所属的高斯分布。</li>
<li>参数 $ \theta = {\mu<em>k, \Sigma_k, \pi_k}</em>{k=1}^K $：<ul>
<li>$ \mu_k $：第 $ k $ 个高斯分布的均值。</li>
<li>$ \Sigma_k $：第 $ k $ 个高斯分布的协方差矩阵。</li>
<li>$ \pi_k $：第 $ k $ 个高斯分布的权重（先验概率）。</li>
</ul>
</li>
</ul>
<p><strong>(2) E步：计算责任分配</strong></p>
<p>对于每个样本 $ x_i $ 和类别 $ k $，计算责任（responsibility）：</p>
<script type="math/tex; mode=display">
\gamma_{ik}^{(t)} = P(z_i=k|x_i, \theta^{(t)}) = \frac{\pi_k^{(t)} \mathcal{N}(x_i|\mu_k^{(t)}, \Sigma_k^{(t)})}{\sum_{j=1}^K \pi_j^{(t)} \mathcal{N}(x_i|\mu_j^{(t)}, \Sigma_j^{(t)})}</script><p>含义：在当前参数下，样本 $ x_i $ 属于类别 $ k $ 的概率。</p>
<p><strong>(3) M步：更新参数</strong></p>
<p>根据责任 $ \gamma_{ik} $ 更新参数：</p>
<ul>
<li><strong>均值更新</strong>：<script type="math/tex; mode=display">
\mu_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)} x_i}{\sum_{i=1}^N \gamma_{ik}^{(t)}}</script></li>
<li><strong>协方差更新</strong>：<script type="math/tex; mode=display">
\Sigma_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)} (x_i - \mu_k^{(t+1)})(x_i - \mu_k^{(t+1)})^T}{\sum_{i=1}^N \gamma_{ik}^{(t)}}</script></li>
<li><strong>权重更新</strong>：<script type="math/tex; mode=display">
\pi_k^{(t+1)} = \frac{\sum_{i=1}^N \gamma_{ik}^{(t)}}{N}</script></li>
</ul>
<p><strong>(4) 迭代终止</strong></p>
<p>当参数变化小于阈值或达到最大迭代次数时停止。</p>
<h4 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h4><h5 id="1"><a href="#1" class="headerlink" title="1"></a>1</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143758565.png" alt="image-20250606143758565"></p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606143819352.png" alt="image-20250606143819352"></p>
<h5 id="2"><a href="#2" class="headerlink" title="2"></a>2</h5><p>已知观测数据-67，-48，6，8，14，16，23，24，28，29，41，49，56，60，75，试估计两个分量的高斯混合模型的5个参数。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150830535.png" alt="image-20250606150830535"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化观测数据</span></span><br><span class="line">data = np.array([-<span class="number">67</span>, -<span class="number">48</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">41</span>, <span class="number">49</span>, <span class="number">56</span>, <span class="number">60</span>,</span><br><span class="line">                 <span class="number">75</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类</span></span><br><span class="line">gmmModel = GaussianMixture(n_components=<span class="number">2</span>)</span><br><span class="line">gmmModel.fit(data)</span><br><span class="line">labels = gmmModel.predict(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels =&quot;</span>, labels)</span><br><span class="line">labels = [<span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(labels)):</span><br><span class="line">    <span class="keyword">if</span> labels[i] == <span class="number">0</span>:</span><br><span class="line">        plt.scatter(i, data.take(i), s=<span class="number">15</span>, c=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> labels[i] == <span class="number">1</span>:</span><br><span class="line">        plt.scatter(i, data.take(i), s=<span class="number">15</span>, c=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Gaussian Mixture Model&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;means =&quot;</span>, gmmModel.means_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;covariances =&quot;</span>, gmmModel.covariances_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights = &quot;</span>, gmmModel.weights_.reshape(<span class="number">1</span>, -<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606150906475.png" alt="image-20250606150906475"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># means = [[ 32.98489643 -57.51107027]]</span></span><br><span class="line"><span class="comment"># covariances = [[429.45764867  90.24987882]]</span></span><br><span class="line"><span class="comment"># weights =  [[0.86682762 0.13317238]]</span></span><br></pre></td></tr></table></figure>
<h5 id="3"><a href="#3" class="headerlink" title="3"></a>3</h5><p>简要阐述下EM算法的原理，并给出EM算法对高斯混合模型GMM进行求解的具体过程。</p>
<h6 id="EM算法的原理"><a href="#EM算法的原理" class="headerlink" title="EM算法的原理"></a>EM算法的原理</h6><p>EM算法（期望最大化算法）是一种用于含有隐变量的概率模型参数估计的迭代优化方法。其核心思想是通过交替执行两个步骤来最大化观测数据的似然函数：</p>
<ol>
<li><strong>E步（期望步）</strong>：计算隐变量的后验期望（即责任），给定当前参数估计。</li>
<li><strong>M步（最大化步）</strong>：基于责任，最大化完全数据的期望似然函数以更新参数。</li>
</ol>
<p>EM算法通过不断优化似然函数的下界，最终收敛到局部最优解。以下具体阐述EM算法对高斯混合模型（GMM）的求解过程。</p>
<h6 id="EM算法对GMM的具体求解过程"><a href="#EM算法对GMM的具体求解过程" class="headerlink" title="EM算法对GMM的具体求解过程"></a><strong>EM算法对GMM的具体求解过程</strong></h6><p><strong>1. GMM模型定义</strong></p>
<p>GMM假设数据由 $ K $ 个高斯分布线性组合生成，其概率密度函数为：</p>
<script type="math/tex; mode=display">
p(\mathbf{x}|\theta) = \sum_{k=1}^K \alpha_k \cdot \mathcal{N}(\mathbf{x}|\mu_k, \Sigma_k)</script><p>其中：</p>
<ul>
<li>$ \alpha<em>k $：第 $ k $ 个高斯分布的权重（$ \sum</em>{k=1}^K \alpha_k = 1 $）。</li>
<li>$ \mu_k $：第 $ k $ 个高斯分布的均值向量。</li>
<li>$ \Sigma_k $：第 $ k $ 个高斯分布的协方差矩阵。</li>
<li>$ \theta = {\alpha<em>k, \mu_k, \Sigma_k}</em>{k=1}^K $：模型参数。</li>
</ul>
<p>隐变量 $ z_i \in {1,\dots,K} $ 表示样本 $ \mathbf{x}_i $ 的类别标签（未知）。</p>
<p><strong>2. EM算法步骤</strong></p>
<p><strong>(1) 初始化参数</strong></p>
<p>随机或通过K-means初始化：</p>
<ul>
<li>每个高斯分布的均值 $ \mu_k^{(0)} $、协方差 $ \Sigma_k^{(0)} $、权重 $ \alpha_k^{(0)} $。</li>
</ul>
<p><strong>(2) 迭代优化（E步与M步）</strong></p>
<p><strong>E步：计算责任（后验概率）</strong><br>对每个样本 $\mathbf{x}_i$ 和每个簇 $ k $，计算其属于第 $ k $ 个高斯分布的后验概率</p>
<script type="math/tex; mode=display">
\gamma(z_{ik}) = \frac{\alpha_k \cdot \mathcal{N}(\mathbf{x}_i | \mu_k, \Sigma_k)}{\sum_{j=1}^K \alpha_j \cdot \mathcal{N}(\mathbf{x}_i | \mu_j, \Sigma_j)}</script><p>此概率表示在当前参数下，样本 $ \mathbf{x}_i $ 属于第 $ k $ 个高斯分布的“责任”。</p>
<p><strong>M步：更新参数</strong><br>基于责任 $ \gamma(z_{ik}) $，最大化完全数据似然函数的期望，更新参数：</p>
<ul>
<li><strong>权重更新</strong>：<script type="math/tex; mode=display">
\alpha_k^{(new)} = \frac{1}{N} \sum_{i=1}^N \gamma(z_{ik})</script></li>
<li><strong>均值更新</strong>：<script type="math/tex; mode=display">
\mu_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) \mathbf{x}_i}{\sum_{i=1}^N \gamma(z_{ik})}</script></li>
<li><strong>协方差更新</strong>：<script type="math/tex; mode=display">
\Sigma_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) (\mathbf{x}_i - \mu_k^{(new)})(\mathbf{x}_i - \mu_k^{(new)})^\top}{\sum_{i=1}^N \gamma(z_{ik})}</script>若为单变量高斯分布，则更新方差：<script type="math/tex; mode=display">
\sigma_k^{(new)} = \frac{\sum_{i=1}^N \gamma(z_{ik}) (x_i - \mu_k^{(new)})^2}{\sum_{i=1}^N \gamma(z_{ik})}</script></li>
</ul>
<p><strong>(3) 收敛判断</strong></p>
<p>计算对数似然函数：</p>
<script type="math/tex; mode=display">
\log p(\mathbf{X}|\theta) = \sum_{i=1}^N \log \left( \sum_{k=1}^K \alpha_k \cdot \mathcal{N}(\mathbf{x}_i|\mu_k, \Sigma_k) \right)</script><p>若对数似然的变化量小于阈值或达到最大迭代次数，则停止；否则重复E步和M步。。</p>
<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://www.bilibili.com/video/BV1RT411G7jJ/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">[5分钟学算法] #06 EM算法 你到底是哪个班级的_哔哩哔哩_bilibili</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/396007256">《统计学习方法_第二版》学习笔记第九章 - 知乎</a></p>
<h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><h4 id="个体与集成"><a href="#个体与集成" class="headerlink" title="个体与集成"></a>个体与集成</h4><h5 id="集成学习的基本概念"><a href="#集成学习的基本概念" class="headerlink" title="集成学习的基本概念"></a><strong>集成学习的基本概念</strong></h5><p>集成学习（Ensemble Learning）通过构建并结合<strong>多个学习器（基模型）</strong>来完成学习任务，其核心思想是“<strong>优而不同</strong>”，即<strong>通过多个弱学习器的协作提升整体性能</strong>，通常能获得比单一学习器更优的泛化能力 。 </p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606154731476.png" alt="image-20250606154731476"> </p>
<p>在上图的集成模型中，若个体学习器都属于同一类别，例如都是决策树或都是神经网络，则称该集成为同质的（homogeneous）;若个体学习器包含多种类型的学习算法，例如既有决策树又有神经网络，则称该集成为异质的（heterogenous）。</p>
<blockquote>
<p><strong>同质集成</strong>：个体学习器称为“基学习器”（base learner），对应的学习算法为“基学习算法”（base learning algorithm）。 </p>
<p><strong>异质集成</strong>：个体学习器称为“组件学习器”（component learner）或直称为“个体学习器”。</p>
</blockquote>
<p>集成学习的两个重要概念：<strong>准确性</strong>和<strong>多样性</strong>（diversity）。准确性指的是个体学习器不能太差，要有一定的准确度；多样性则是个体学习器之间的输出要具有差异性。</p>
<p>通过下面的这三个例子可以很容易看出这一点，准确度较高，差异度也较高，可以较好地提升集成性能。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606155939884.png" alt="image-20250606155939884"></p>
<p><strong>集成策略</strong>：如何结合多个基模型的预测结果，例如：  </p>
<ul>
<li><strong>投票法</strong>（Voting）：多数投票（硬投票）或概率加权（软投票）。  </li>
<li><strong>加权平均法</strong>：对基模型的输出赋予不同权重 。  </li>
<li><strong>Stacking</strong>：用元模型（Meta-Model）学习基模型的输出作为新特征 。</li>
</ul>
<h5 id="基于投票法的集成个体学习器的收敛性保证："><a href="#基于投票法的集成个体学习器的收敛性保证：" class="headerlink" title="基于投票法的集成个体学习器的收敛性保证："></a><strong>基于投票法的集成个体学习器的收敛性保证</strong>：</h5><p><strong>公式解析</strong></p>
<script type="math/tex; mode=display">
P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) = \sum_{k=0}^{\lfloor T/2 \rfloor} \binom{T}{k} (1-\epsilon)^k \epsilon^{T-k} \leq \exp\left(-\frac{1}{2} T (1 - 2\epsilon)^2\right)</script><p><strong>1. 公式含义</strong></p>
<ul>
<li><strong>$H(\boldsymbol{x})$</strong>：集成学习器的最终预测结果（如多数投票结果）。</li>
<li><strong>$f(\boldsymbol{x})$</strong>：真实标记。</li>
<li><strong>$\epsilon$</strong>：单个弱学习器的错误率（即 $P(h_t(\boldsymbol{x}) \neq f(\boldsymbol{x}))$），默认小于0.5。</li>
<li><strong>$T$</strong>：基学习器的数量。</li>
<li><strong>左边</strong>：集成学习器预测错误的概率（即至少有超过 $T/2$ 个基学习器预测错误的概率）。</li>
<li><strong>右边</strong>：对左边概率的指数级上限估计。</li>
</ul>
<p><strong>2. 推导思路</strong></p>
<ul>
<li>假设每个基学习器独立且错误率为 $\epsilon$，则错误次数服从<strong>二项分布</strong> $B(T, \epsilon)$。</li>
<li>集成错误的条件是“超过半数基学习器错误”，即错误次数 $k \leq \lfloor T/2 \rfloor$。</li>
</ul>
<p><strong>两个基本结论</strong></p>
<p><strong>1. 收敛速率随个体学习器数量 $T$ 指数下降</strong></p>
<ul>
<li><strong>数学体现</strong>：错误概率的上界是 $\exp(-cT)$ 形式，其中 $c = \frac{1}{2}(1 - 2\epsilon)^2$。</li>
</ul>
<p><strong>2. $\epsilon = 0.5$ 的个体学习器对收敛没有作用</strong></p>
<ul>
<li><strong>数学原因</strong>：当 $\epsilon = 0.5$ 时，$(1 - 2\epsilon)^2 = 0$，指数项变为 0，错误概率上界为 $\exp(0) = 1$，即错误概率无法降低。</li>
</ul>
<p>根据个体学习器的<strong>生成方式</strong>，目前集成学习可分为两类，代表作如下：</p>
<ol>
<li>个体学习器直接存在强依赖关系，必须串行生成的序列化方法：<strong>Boosting</strong>；</li>
<li>个体学习器间不存在强依赖关系，可以同时生成的并行化方法：<strong>Bagging</strong> 和 <strong>随机森林 (Random Forest)</strong>。</li>
</ol>
<h4 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a><strong>Boosting</strong></h4><p>Boosting是一种<strong>串行</strong>的工作机制，即<strong>个体学习器的训练存在依赖关系</strong>，必须一步一步序列化进行。</p>
<p>其<strong>基本思想</strong>是：<strong>增加前一个基学习器在训练过程中预测错误样本的权重，使得后续基学习器更加关注这些打标错误的训练样本，尽可能纠正这些错误，然后基于调整后的样本分布训练下一个基学习器</strong>，如此重复，一直向下串行直至产生需要的T个基学习器，Boosting最终对这T个学习器进行加权结合，产生学习器委员会。</p>
<p>Boosting族算法最著名、使用最为广泛的就是<strong>AdaBoost</strong>，因此下面主要是对AdaBoost算法进行介绍。</p>
<p>AdaBoost使用的是<strong>指数损失函数</strong>，因此AdaBoost的权值与样本分布的更新都是围绕着最小化指数损失函数进行的。</p>
<blockquote>
<p>看到这里回想一下之前的机器学习算法，<strong>不难发现机器学习的大部分带参模型只是改变了最优化目标中的损失函数</strong>：如果是Square loss，那就是最小二乘了；如果是Hinge Loss，那就是著名的SVM了；如果是log-Loss，那就是Logistic Regression了。</p>
</blockquote>
<h5 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h5><h5 id="公式解析"><a href="#公式解析" class="headerlink" title="公式解析"></a><strong>公式解析</strong></h5><script type="math/tex; mode=display">
H(\boldsymbol{x}) = \sum_{t=1}^T \alpha_t h_t(\boldsymbol{x})</script><script type="math/tex; mode=display">
\ell_{\exp}(H | \mathcal{D}) = \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}} \left[ e^{-f(\boldsymbol{x}) H(\boldsymbol{x})} \right]</script><p><strong>1. 符号含义</strong></p>
<ul>
<li><strong>$H(\boldsymbol{x})$</strong>：最终集成模型的预测结果，是 $T$ 个基学习器 $h_t(\boldsymbol{x})$ 的加权和。</li>
<li><strong>$\alpha_t$</strong>：第 $t$ 个基学习器的权重，表示其在集成中的重要性。</li>
<li><strong>$h_t(\boldsymbol{x})$</strong>：第 $t$ 个基学习器（如决策树、感知机等）。</li>
<li><strong>$f(\boldsymbol{x})$</strong>：真实标签，通常取值为 ${-1, +1}$（二分类问题）。</li>
<li><strong>$\mathcal{D}$</strong>：训练数据分布。</li>
<li><strong>$\ell_{\exp}$</strong>：指数损失函数（Exponential Loss）。</li>
</ul>
<p><strong>2. 指数损失函数的意义</strong></p>
<p>指数损失函数的形式为：</p>
<script type="math/tex; mode=display">
\ell_{\exp}(H | \mathcal{D}) = \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}} \left[ e^{-f(\boldsymbol{x}) H(\boldsymbol{x})} \right]</script><ul>
<li><strong>直观解释</strong>：<ul>
<li>当 $H(\boldsymbol{x})$ 与 $f(\boldsymbol{x})$ 同号时（预测正确），指数项 $e^{-f(\boldsymbol{x}) H(\boldsymbol{x})}$ 接近 0，损失小。</li>
<li>当 $H(\boldsymbol{x})$ 与 $f(\boldsymbol{x})$ 异号时（预测错误），指数项趋近于正无穷，损失极大。</li>
<li>因此，该损失函数对错误样本的惩罚非常严格，迫使模型优先修正错误。</li>
</ul>
</li>
</ul>
<h5 id="AdaBoost的优化目标"><a href="#AdaBoost的优化目标" class="headerlink" title="AdaBoost的优化目标"></a><strong>AdaBoost的优化目标</strong></h5><p>AdaBoost的目标是选择基学习器 $h_t$ 和权重 $\alpha_t$，使得集成模型 $H(\boldsymbol{x})$ 能够<strong>最小化指数损失函数</strong>：</p>
<script type="math/tex; mode=display">
\min_{\alpha_1, h_1, \dots, \alpha_T, h_T} \mathbb{E}_{\boldsymbol{x} \sim \mathcal{D}} \left[ e^{-f(\boldsymbol{x}) \sum_{t=1}^T \alpha_t h_t(\boldsymbol{x})} \right]</script><p><strong>优化策略</strong></p>
<p>AdaBoost采用<strong>前向分步算法（Forward Stagewise Algorithm）</strong>，逐轮迭代优化：</p>
<ol>
<li><strong>初始化样本权重</strong>：初始时所有样本权重相等。</li>
<li><strong>训练基学习器 $h_t$</strong>：在当前样本权重分布下，训练一个弱学习器 $h_t$。</li>
<li><strong>计算权重 $\alpha_t$</strong>：根据 $h_t$ 的错误率 $\epsilon_t$ 计算其权重：<script type="math/tex; mode=display">
\alpha_t = \frac{1}{2} \ln \left( \frac{1 - \epsilon_t}{\epsilon_t} \right)</script></li>
<li><strong>更新样本权重</strong>：提高被 $h_t$ 错分类样本的权重，降低正确分类样本的权重。</li>
<li><strong>重复步骤 2-4</strong>，直到训练完成 $T$ 轮。</li>
</ol>
<h5 id="示例：二分类问题-1"><a href="#示例：二分类问题-1" class="headerlink" title="示例：二分类问题"></a><strong>示例：二分类问题</strong></h5><p>假设一个二分类任务，真实标签 $f(\boldsymbol{x}) \in {-1, +1}$，集成模型预测值 $H(\boldsymbol{x}) = \sum_{t=1}^T \alpha_t h_t(\boldsymbol{x})$：</p>
<ul>
<li>若 $H(\boldsymbol{x}) &gt; 0$，预测为 $+1$；</li>
<li>若 $H(\boldsymbol{x}) &lt; 0$，预测为 $-1$。</li>
</ul>
<p>此时，指数损失函数的值反映了模型对错误样本的惩罚程度：</p>
<ul>
<li>正确预测时，$e^{-f(\boldsymbol{x}) H(\boldsymbol{x})} \approx 0$；</li>
<li>错误预测时，$e^{-f(\boldsymbol{x}) H(\boldsymbol{x})} \gg 1$。</li>
</ul>
<h5 id="AdaBoost的算法流程"><a href="#AdaBoost的算法流程" class="headerlink" title="AdaBoost的算法流程"></a>AdaBoost的算法流程</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606172851748.png" alt="image-20250606172851748"></p>
<h5 id="重赋权法与重采样法"><a href="#重赋权法与重采样法" class="headerlink" title="重赋权法与重采样法"></a>重赋权法与重采样法</h5><p>在集成学习中，<strong>Boosting 算法的核心在于动态调整样本权重</strong> ，以逐步聚焦难分类样本。Boosting 主要通过两种方法实现样本权重的更新：<strong>重赋权法（re-weighting）</strong> 和 <strong>重采样法（re-sampling）</strong> 。</p>
<blockquote>
<p><strong>重赋权法</strong> : 对每个样本附加一个权重，这时涉及到样本属性与标签的计算，都需要乘上一个权值。 <strong>重采样法</strong> : 对于一些无法接受带权样本的及学习算法，适合用“重采样法”进行处理。方法大致过程是，根据各个样本的权重，对训练数据进行重采样，初始时样本权重一样，每个样本被采样到的概率一致，每次从N个原始的训练样本中按照权重有放回采样N个样本作为训练集，然后计算训练集错误率，然后调整权重，重复采样，集成多个基学习器。</p>
</blockquote>
<p>从偏差-方差分解来看：Boosting算法主要关注于降低偏差，每轮的迭代都关注于训练过程中预测错误的样本，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成学习器。</p>
<h5 id="拓展：Gradient-Boosting"><a href="#拓展：Gradient-Boosting" class="headerlink" title="拓展：Gradient Boosting"></a>拓展：Gradient Boosting</h5><p>任务分为分类，回归，聚类，降维等，而分类中还分为二分类和多分类</p>
<p>从AdaBoost的算法流程来看，标准的AdaBoost只适用于二分类问题。</p>
<p>通过改造AdaBoost对样本分类的限制和损失函数，可以实现多分类或回归问题，这样改造出来的算法框架成为<strong>Gradient Boosting</strong></p>
<h6 id="GBDT（Gradient-Boosting-Decision-Tree）与XGBoost"><a href="#GBDT（Gradient-Boosting-Decision-Tree）与XGBoost" class="headerlink" title="GBDT（Gradient Boosting Decision Tree）与XGBoost"></a><strong>GBDT（Gradient Boosting Decision Tree）与XGBoost</strong></h6><p><strong>1. GBDT 的核心思想</strong></p>
<p>GBDT 是基于<strong>梯度提升（Gradient Boosting）</strong>框架的集成学习方法，其特点包括：</p>
<ul>
<li><strong>基学习器</strong>：使用<strong>CART（分类与回归树）</strong>作为个体学习器。</li>
<li><strong>损失函数</strong>：<ul>
<li><strong>回归问题</strong>：平方损失（Squared Loss）：<script type="math/tex; mode=display">
\text{err}(H_t(\boldsymbol{x}), f(\boldsymbol{x})) = (H_t(\boldsymbol{x}) - f(\boldsymbol{x}))^2</script></li>
<li><strong>二分类问题</strong>：对数似然损失（Log-Likelihood Loss，类似逻辑回归）：<script type="math/tex; mode=display">
\text{err}(H_t(\boldsymbol{x}), f(\boldsymbol{x})) = \log(1 + \exp(-f(\boldsymbol{x}) H_t(\boldsymbol{x})))</script></li>
<li><strong>多分类问题</strong>：扩展为多分类对数损失。</li>
</ul>
</li>
</ul>
<p><strong>2. XGBoost 的定位</strong></p>
<p>XGBoost（eXtreme Gradient Boosting）是 GBDT 的一种<strong>高效实现和改进</strong>，类似于 LIBSVM 对 SVM 的优化关系。其核心目标是：</p>
<ul>
<li><strong>提升训练速度</strong>：通过<strong>并行计算</strong>、<strong>内存优化</strong>等工程技巧。</li>
<li><strong>增强模型性能</strong>：引入<strong>正则化项</strong>、<strong>缺失值处理</strong>、<strong>自适应学习率</strong>等改进。</li>
</ul>
<blockquote>
<p>XGBoost即eXtremeGradient Boosting的缩写，XGBoost与GBDT的关系可以类比为<br>LIBSVM和SVM的关系，即XGBoOst是GBDT的一种高效实现和改进。</p>
<p>它并非一个全新的算法框架，而是对标准 GBDT 进行了<strong>大量的工程优化和算法增强</strong>。</p>
</blockquote>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606175536310.png" alt="image-20250606175536310"></p>
<h4 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h4><p>Bagging是一种<strong>并行式</strong>的集成学习方法，即<strong>基学习器的训练之间没有前后顺序可以同时进行</strong></p>
<p>Bagging使用<strong>“有放回”采样的方式选取训练集</strong>，对于包含m个样本的训练集，进行m次有放回的随机采样操作，从而得到m个样本的采样集，这样训练集中有<strong>接近36.8%</strong>的样本没有被采到，可用作验证集来对泛化性能进行“包外估计”(out-of-bag estimate)。</p>
<p>按照相同的方式重复进行，我们就可以采集到T个包含m个样本的数据集，从而训练出<strong>T个基学习器</strong>，最终对<strong>这T个基学习器的输出进行结合</strong>。</p>
<h5 id="Bagging与Boosting的差异"><a href="#Bagging与Boosting的差异" class="headerlink" title="Bagging与Boosting的差异"></a>Bagging与Boosting的差异</h5><p>Boosting算法一大特点是串行，这样诚然可以降低模型的偏差，增强拟合能力，但是当数据过大时，一大缺点就是会降低学习效率</p>
<p>Bagging作为并行式的集成学习方法，通过综合多个基学习器的结果，可以增加学习效率</p>
<p>二者差异性：</p>
<p>1.对目标的拟合程度：Boosting对目标有更好的拟合能力（偏差小）；Bagging则偏差相对大一些</p>
<p>2.运行效率：由于并行的特点，Bagging的运行效率是大于Boosting的</p>
<p>3.泛化能力：由于Bagging每个学习器不会受其他学习器的影响，泛化能力（方差大）相对于Boosting</p>
<p>更好</p>
<h5 id="Bagging的算法流程"><a href="#Bagging的算法流程" class="headerlink" title="Bagging的算法流程"></a>Bagging的算法流程</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606182733022.png" alt="image-20250606182733022"></p>
<p>可以看出Bagging主要通过<strong>样本的扰动</strong>来增加基学习器之间的多样性，因此Bagging的基学习器应为那些对训练集十分敏感的不稳定学习算法，例如：神经网络与决策树等。</p>
<p>从偏差-方差分解来看，Bagging算法主要关注于降低方差，即通过多次重复训练提高稳定性。</p>
<p>不同于AdaBoost的是，Bagging可以十分简单地移植到多分类、回归等问题。总的说起来则是：<strong>AdaBoost关注于降低偏差，而Bagging关注于降低方差。</strong></p>
<h5 id="自助采样法（Bootstrap-Sampling）"><a href="#自助采样法（Bootstrap-Sampling）" class="headerlink" title="自助采样法（Bootstrap Sampling）"></a>自助采样法（Bootstrap Sampling）</h5><p>在机器学习中，<strong>自助采样法（Bootstrap Sampling）</strong> 是 Bagging 算法的核心技术之一。其核心思想是从原始数据集中有放回地随机抽取样本，形成新的训练子集。这一过程的一个重要数学性质是：当样本量 $n$ 趋近于无穷大时，每个样本在 Bootstrap 样本集中<strong>未被抽中</strong>的概率趋近于 $\frac{1}{e} \approx 36.6\%$。以下是详细解析：</p>
<p><strong>1. 公式推导</strong></p>
<p>假设我们从 $n$ 个样本中<strong>有放回地</strong>抽取 $n$ 次，形成一个 Bootstrap 样本集。对于任意一个特定样本（如第 $i$ 个样本），它在某次抽样中<strong>未被选中</strong>的概率为：</p>
<script type="math/tex; mode=display">
1 - \frac{1}{n}</script><p>因此，它在整个 $n$ 次抽样中<strong>从未被选中</strong>的概率为：</p>
<script type="math/tex; mode=display">
\left(1 - \frac{1}{n}\right)^n</script><p>当 $n \to \infty$ 时，该概率的极限为：</p>
<script type="math/tex; mode=display">
\lim_{n \to \infty} \left(1 - \frac{1}{n}\right)^n = \frac{1}{e} \approx 0.3679 \quad (\text{即 } 36.6\%)</script><p>在每次 Bootstrap 采样中，约有 <strong>36.6% 的样本未被选中</strong> ，这些样本称为 <strong>Out-of-Bag（OOB，包外估计）样本</strong> 。</p>
<p><strong>2. OOB 样本的应用</strong></p>
<p>在 Bagging 算法中，OOB 样本具有以下重要作用：</p>
<ol>
<li><strong>无偏验证</strong>：<br>每个基学习器的训练数据不包含其对应的 OOB 样本，因此可以用这些样本直接评估模型性能（即 OOB 误差），无需额外的交叉验证。</li>
<li><strong>特征重要性评估</strong>：<br>在随机森林中，通过比较 OOB 样本在打乱某个特征后的预测误差变化，可以衡量该特征的重要性。</li>
</ol>
<p><strong>3. 与其他采样方法的对比</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>采样方法</strong></th>
<th><strong>是否放回</strong></th>
<th><strong>样本覆盖范围</strong></th>
<th><strong>典型应用场景</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Bootstrap 采样</strong></td>
<td>是</td>
<td>约 63.4% 样本被重复使用</td>
<td>Bagging、随机森林</td>
</tr>
<tr>
<td><strong>简单随机采样</strong></td>
<td>否</td>
<td>所有样本唯一出现</td>
<td>传统交叉验证</td>
</tr>
</tbody>
</table>
</div>
<h5 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h5><p>随机森林（Random Forest）是Bagging的一个拓展体，它的基学习器固定为<strong>决策树</strong>，多棵树也就组成了森林，而<strong>“随机”则在于选择划分属性的随机</strong>，随机森林在训练基学习器时，也采用有放回采样的方式添加样本扰动，同时它还引入了一种<strong>属性扰动</strong>，即在基决策树的训练过程中，在选择划分属性时，RF先从候选属性集中随机挑选出一个包含K个属性的子集，再从这个子集中选择最优划分属性 。</p>
<p>这样随机森林中基学习器的<strong>多样性不仅来自样本扰动，还来自属性扰动</strong>，从而进一步提升了基学习器之间的差异度。相比决策树的Bagging集成，随机森林的起始性能较差（由于属性扰动，基决策树的准确度有所下降），但随着基学习器数目的增多，随机森林往往会收敛到更低的泛化误差。同时不同于Bagging中决策树从所有属性集中选择最优划分属性，<strong>随机森林只在属性集的一个子集中选择划分属性，因此训练效率更高</strong>。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606184958951.png" alt="image-20250606184958951"></p>
<h4 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h4><p>在集成学习中，结合策略是将多个基学习器的输出整合为最终预测结果的关键步骤。以下是针对回归和分类问题的不同结合策略及其核心要点：</p>
<p><strong>定义</strong>：在训练好多个基学习器后，如何将其输出组合成集成模型的最终输出。</p>
<h5 id="1-平均法（回归问题）"><a href="#1-平均法（回归问题）" class="headerlink" title="1.平均法（回归问题）"></a><strong>1.平均法（回归问题）</strong></h5><ol>
<li><p><strong>简单平均法（Simple Averaging）</strong>  </p>
<ul>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
H(x) = \frac{1}{T} \sum_{i=1}^{T} h_i(x)</script></li>
<li><strong>特点</strong>：  <ul>
<li>直接对所有基学习器的预测结果取算术平均。  </li>
<li>计算简单，适合基学习器性能相近的场景。  </li>
<li>若部分基学习器表现较差，可能拖累整体性能。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>加权平均法（Weighted Averaging）</strong>  </p>
<ul>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
H(x) = \sum_{i=1}^{T} w_i h_i(x)</script>其中，$ w<em>i \geq 0 $ 且 $ \sum</em>{i=1}^{T} w_i = 1 $。  </li>
<li><strong>特点</strong>：  <ul>
<li>通过权重 $ w_i $ 调节各基学习器的贡献，灵活性更高。  </li>
<li>适用于基学习器性能差异较大的情况，可提升鲁棒性。  </li>
<li>权重可通过验证集性能（如RMSE、MAE）或优化算法（如梯度下降）确定。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h5 id="2-投票法（分类问题）"><a href="#2-投票法（分类问题）" class="headerlink" title="2.投票法（分类问题）"></a><strong>2.投票法（分类问题）</strong></h5><ol>
<li><p><strong>简单投票法（Majority Voting）</strong>  </p>
<ul>
<li><strong>原理</strong>：<br>每个基学习器对样本进行分类投票，最终结果由得票最多的类别决定。  </li>
<li><strong>公式</strong>（二分类示例）：  <script type="math/tex; mode=display">
H(x) = 
\begin{cases} 
1 & \text{若} \sum_{i=1}^{T} I(h_i(x) = 1) > T/2 \\
0 & \text{否则}
\end{cases}</script>其中，$ I(\cdot) $ 为指示函数。  </li>
<li><strong>特点</strong>：  <ul>
<li>简单高效，适合基学习器性能相近的场景。  </li>
<li>对异常分类器的鲁棒性较弱。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>加权投票法（Weighted Voting）</strong>  </p>
<ul>
<li><strong>原理</strong>：<br>给不同基学习器分配权重，最终结果由加权票数最高的类别决定。  </li>
<li><strong>公式</strong>（二分类示例）：  <script type="math/tex; mode=display">
H(x) = 
\begin{cases} 
1 & \text{若} \sum_{i=1}^{T} w_i I(h_i(x) = 1) > 0.5 \sum_{i=1}^{T} w_i \\
0 & \text{否则}
\end{cases}</script></li>
<li><strong>特点</strong>：  <ul>
<li>权重可根据基学习器的验证集准确率或领域知识设定。  </li>
<li>更适合处理性能差异较大的基学习器。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>绝对多数投票法（majority voting）提供了拒绝选项，这在可靠性要求很高的学习任务中是一个很好的机制。同时，对于分类任务，各个基学习器的输出值有两种类型，分别为类标记和类概率。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250606195241433.png" alt="image-20250606195241433"></p>
<p>一些在产生类别标记的同时也生成置信度的学习器，置信度可转化为类概率使用，<strong>一般基于类概率进行结合往往比基于类标记进行结合的效果更好</strong>，需要注意的是对于异质集成，其类概率不能直接进行比较，此时需要将类概率转化为类标记输出，然后再投票。</p>
<h5 id="3-学习法（Stacking）"><a href="#3-学习法（Stacking）" class="headerlink" title="3.学习法（Stacking）"></a><strong>3.学习法（Stacking）</strong></h5><p><strong>学习法</strong>是一种更高级的结合策略，其核心思想是通过训练一个<strong>次级学习器（Meta-Learner）</strong> 来动态融合多个基学习器的输出。其中，<strong>Stacking（堆叠泛化）</strong> 是学习法的典型代表，它通过将基学习器的预测结果作为新特征，进一步训练一个次级模型，最终实现更优的泛化性能。</p>
<p><strong>Stacking 的基本原理</strong></p>
<p><strong>步骤概述</strong>：  </p>
<ul>
<li><strong>训练基学习器</strong>：使用原始数据训练 $ T $ 个基学习器（如决策树、SVM、神经网络等）。  </li>
<li><strong>生成新特征</strong>：对于每个样本，将 $ T $ 个基学习器的输出（预测结果）作为该样本的新特征，形成一个 $ m \times T $ 的数据集（$ m $ 为样本数量）。  </li>
<li><strong>训练次级学习器</strong>：使用新数据集（基学习器输出 + 真实标签）训练一个次级学习器（如逻辑回归、梯度提升树等），该学习器负责融合基学习器的预测结果。  </li>
</ul>
<p><strong>Stacking 的优势</strong></p>
<ol>
<li><strong>动态权重分配</strong>：<br>次级学习器可以自动学习基学习器的权重，无需人工设定。例如，若某个基学习器表现优异，次级学习器会赋予其更高的权重。  </li>
<li><strong>异质模型融合</strong>：<br>可以混合不同类型的基学习器（如线性模型与树模型），充分利用各自的特性。  </li>
<li><strong>提升泛化能力</strong>：<br>次级学习器通过学习基学习器的输出模式，能够捕捉更复杂的决策边界。</li>
</ol>
<p><strong>Stacking 的实现细节</strong></p>
<ol>
<li><p><strong>数据划分</strong>：  </p>
<ul>
<li>通常需将原始数据分为两部分：  <ul>
<li><strong>训练集</strong>：用于训练基学习器。  </li>
<li><strong>验证集</strong>：用于生成基学习器的输出（避免过拟合）。  </li>
</ul>
</li>
<li>或采用交叉验证（如 $ k $-折）生成基学习器的预测结果，确保次级学习器的训练数据不被污染。</li>
</ul>
</li>
<li><p><strong>基学习器输出类型</strong>：  </p>
<ul>
<li><strong>分类任务</strong>：基学习器输出类概率（Soft Voting），而非类别标签（Hard Voting）。例如，逻辑回归输出 $ P(c_j | x) $，随机森林输出节点样本的类别分布。  </li>
<li><strong>回归任务</strong>：基学习器直接输出预测值（如线性回归的 $\hat{y}$）。</li>
</ul>
</li>
<li><p><strong>次级学习器选择</strong>：  </p>
<ul>
<li><strong>多响应线性回归（MLR）</strong>：适用于基学习器输出可加权平均的情况，计算简单且鲁棒。  <script type="math/tex; mode=display">
H(x) = \sum_{i=1}^{T} w_i h_i(x)</script></li>
<li><strong>复杂模型</strong>：如梯度提升树、神经网络，可捕捉基学习器输出之间的非线性关系。  </li>
</ul>
</li>
</ol>
<h4 id="多样性"><a href="#多样性" class="headerlink" title="多样性"></a>多样性</h4><p>在集成学习中，<strong>多样性增强（Diversity Enhancement）</strong> 是提升模型性能的关键策略。通过引入多样性，可以降低基学习器之间的相关性，从而减少误差传递和过拟合风险。以下是四种常见的多样性增强方法及其核心要点：</p>
<p><strong>1. 数据样本扰动（Data Perturbation）</strong></p>
<p><strong>原理</strong>：通过修改训练数据的分布或采样方式，使每个基学习器看到不同的数据子集。  </p>
<p><strong>实现方式</strong>：  </p>
<ul>
<li><strong>Bagging（如随机森林）</strong>：  <ul>
<li>随机有放回地采样（Bootstrap），生成多个不同的训练集。  </li>
<li>对输入扰动敏感的基学习器（如决策树、神经网络）效果显著。  </li>
</ul>
</li>
<li><strong>示例</strong>：  <ul>
<li>决策树对数据扰动敏感，Bagging 可有效提升其泛化能力。  </li>
<li>线性模型（如线性回归、SVM）对数据扰动不敏感，Bagging 效果有限。  </li>
</ul>
</li>
</ul>
<p><strong>2. 输入属性扰动（Input Attribute Perturbation）</strong></p>
<p><strong>原理</strong>：通过改变输入特征的表示或选择，增加基学习器间的差异。  </p>
<p><strong>实现方式</strong>：  </p>
<ul>
<li><strong>特征子集采样</strong>：每次随机选择部分特征进行训练（如随机森林中的列扰动）。  </li>
<li><strong>特征变换</strong>：对特征进行缩放、旋转或加噪声等操作。  </li>
<li><strong>适用场景</strong>：  <ul>
<li>数据包含大量冗余属性时，可大幅加速训练并提升多样性。  </li>
<li>对高维数据（如图像、文本）尤其有效。  </li>
</ul>
</li>
</ul>
<p><strong>3. 输出属性扰动（Output Attribute Perturbation）</strong></p>
<p><strong>原理</strong>：通过修改训练样本的标签，间接影响基学习器的学习过程。  </p>
<p><strong>实现方式</strong>：  </p>
<ul>
<li><strong>随机翻转标签</strong>：对部分样本的标记进行随机更改（需谨慎使用，避免干扰模型）。  </li>
<li><strong>Dropout（神经网络）</strong>：  <ul>
<li>在训练过程中随机“关闭”部分神经元，强制网络学习更鲁棒的特征。  </li>
<li>类似于对输出属性的随机扰动，可提升模型泛化能力。  </li>
</ul>
</li>
</ul>
<p><strong>4. 算法参数扰动（Algorithm Parameter Perturbation）</strong></p>
<p><strong>原理</strong>：通过调整基学习器的超参数，生成不同的模型行为。  </p>
<p><strong>实现方式</strong>：  </p>
<ul>
<li><strong>正则化方法</strong>：L1/L2 正则化（如 Ridge、Lasso）限制模型复杂度，降低过拟合风险。 </li>
<li><strong>随机初始化</strong>：  神经网络的随机权重初始化可能导致收敛到不同局部最优解。  </li>
</ul>
<h4 id="作业-1"><a href="#作业-1" class="headerlink" title="作业"></a>作业</h4><h5 id="1-1"><a href="#1-1" class="headerlink" title="1"></a>1</h5><p>集成学习中常见的两种方法是什么？请分别介绍它们的原理和特点。集成学习相比于单个模型有什么优势和应用场景？</p>
<p><strong>集成学习常见方法、原理、特点及优势</strong></p>
<p><strong>常见方法</strong>：Bagging 和 Boosting<br><strong>原理与特点</strong>：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>方法</strong></th>
<th><strong>原理</strong></th>
<th><strong>特点</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Bagging</strong></td>
<td>1. <strong>自助采样</strong>：从训练集有放回抽取多个子集<br>2. <strong>并行训练</strong>基模型<br>3. <strong>聚合预测</strong>（投票/平均）</td>
<td>- 降低方差<br>- 适合高方差模型（如未剪枝决策树）<br>- 并行化，训练快<br>- 代表：随机森林</td>
</tr>
<tr>
<td><strong>Boosting</strong></td>
<td>1. <strong>顺序训练</strong>：后一个模型修正前一个模型的错误<br>2. <strong>加权困难样本</strong><br>3. <strong>加权组合</strong>模型</td>
<td>- 降低偏差<br>- 需弱学习器（如树桩）<br>- 易过拟合（需正则化）<br>- 代表：AdaBoost, GBDT, XGBoost</td>
</tr>
</tbody>
</table>
</div>
<p><strong>集成学习的优势</strong>：  </p>
<ul>
<li><strong>提升泛化能力</strong>：降低过拟合（Bagging）或欠拟合（Boosting）风险  </li>
<li><strong>增强鲁棒性</strong>：减少异常值/噪声影响（如投票机制）  </li>
<li><strong>突破性能上限</strong>：组合多个弱模型达到强模型效果  </li>
</ul>
<p><strong>应用场景</strong>：  </p>
<ul>
<li><strong>分类任务</strong>：医疗诊断（整合多模型减少误诊）  </li>
<li><strong>回归任务</strong>：房价预测（融合不同树模型提升精度）  </li>
<li><strong>不平衡数据</strong>：Boosting 加权少数类样本  </li>
<li><strong>高维数据</strong>：随机森林自动特征选择  </li>
</ul>
<h5 id="2-1"><a href="#2-1" class="headerlink" title="2"></a>2</h5><p>如果在完全相同的训练集上训练了五个不同的模型，并且它们都达到了95%的准确率，是否还有机会通过结合这些模型来获得更好的结果？如果可以，该怎么做？如果不行，为什么？</p>
<p><strong>模型结合提升性能的可能性与方法</strong></p>
<p><strong>是否可能提升</strong>：<strong>是</strong>，但需满足条件：<strong>模型错误不相关</strong>（即犯错样本不同）。  </p>
<p><strong>如何实现</strong>：  </p>
<ol>
<li><strong>投票法（分类）</strong>：  <ul>
<li>多数投票：5个模型对样本 (x) 的预测为 ([A, A, B, A, C]) → 最终输出 (A)  </li>
<li><strong>关键要求</strong>：模型存在<strong>多样性</strong>（如使用SVM、决策树等不同算法）  </li>
</ul>
</li>
<li><strong>加权平均（回归）</strong>：  <ul>
<li>若模型精度不同，分配权重：$ y_{\text{final}} = w_1 y_1 + w_2 y_2 + \dots + w_5 y_5$</li>
<li>权重可通过验证集性能确定  </li>
</ul>
</li>
</ol>
<p><strong>若无法提升的情况</strong>：  </p>
<ul>
<li><strong>原因</strong>：模型高度相关（如相同算法、相同特征、相同超参）  </li>
<li><strong>数学解释</strong>：误差相关性 $rho \approx 1$ 时，集成误差 $\approx$单一模型误差  </li>
</ul>
<h5 id="3-1"><a href="#3-1" class="headerlink" title="3"></a>3</h5><p>是否可以通过在多个服务器上并行来加速随机森林的训练？AdaBoost集成呢？为什么？</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>算法</strong></th>
<th><strong>是否支持并行</strong></th>
<th><strong>原因</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>随机森林</strong></td>
<td>✅ <strong>是</strong></td>
<td>1. 树之间独立训练<br>2. 可分布式分配Bootstrap样本到不同服务器<br>3. 特征分裂也可并行（如选特征子集）</td>
</tr>
<tr>
<td><strong>AdaBoost</strong></td>
<td>❌ <strong>否</strong></td>
<td>1. 模型必须<strong>顺序训练</strong>：后一个模型依赖前一个模型的样本权重更新<br>2. 无法解耦迭代过程</td>
</tr>
</tbody>
</table>
</div>
<h3 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h3><h4 id="聚类任务"><a href="#聚类任务" class="headerlink" title="聚类任务"></a><strong>聚类任务</strong></h4><blockquote>
<p>我们之前学习的分类/回归任务都属于 有监督学习 需要我们提供样本与标签</p>
<p>而马上要学习的聚类任务和后续学习的降维则属于 无监督学习 仅需提供样本</p>
</blockquote>
<p>聚类是一种经典的<strong>无监督学习</strong>(unsupervised learning)方法，<strong>无监督学习的目标是通过对无标记训练样本的学习，发掘和揭示数据集本身潜在的结构与规律</strong>，即不依赖于训练数据集的类标记信息。</p>
<p>聚类试图将数据集中的样本划分为若干个通常是不相交的子集,<strong>每个子集称为一个“簇”( cluster)</strong>。通过这样的划分,每簇可能对应于一些潜在的概念(类别),如“浅色瓜”“深色瓜”,“有籽瓜”“无籽瓜”,甚至“本地瓜”“外地瓜”等;需说明的是,这些概念对聚类算法而言事先是未知的,聚类过程仅能自动形成簇结构, <strong>簇所对应的概念语义需由使用者来把握和命名</strong>。</p>
<p>直观上来说，聚类是将相似的样本聚在一起，从而形成一个<strong>类簇（cluster）</strong>。涉及两个问题</p>
<ul>
<li>如何<strong>度量相似性</strong>（similarity measure），这便是<strong>距离度量</strong>(distance measure)，在生活中我们说差别小则相似，对应到多维样本，每个样本可以对应于高维空间中的一个数据点，若它们的距离相近，我们便可以称它们相似。</li>
<li>如何<strong>评价聚类结果</strong>，这便是<strong>性能度量</strong>(validity index)</li>
</ul>
<h4 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h4><h5 id="连续-离散有序"><a href="#连续-离散有序" class="headerlink" title="连续/离散有序"></a>连续/离散有序</h5><p><strong>明可夫斯基距离（Minkowski Distance）</strong></p>
<p>明可夫斯基距离是一组常用的<strong>连续型距离度量</strong>，通过调整参数 $ p $ 可以统一表示多种距离形式，是欧氏距离和曼哈顿距离的推广。</p>
<p><strong>1. 公式定义</strong></p>
<p>对于两个 $ n $ 维向量 $ \boldsymbol{x}<em>i = (x</em>{i1}, x<em>{i2}, \dots, x</em>{in}) $ 和 $ \boldsymbol{x}<em>j = (x</em>{j1}, x<em>{j2}, \dots, x</em>{jn}) $，明可夫斯基距离的计算公式为：</p>
<script type="math/tex; mode=display">
\text{dist}_{\text{mk}}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \left( \sum_{u=1}^{n} |x_{iu} - x_{ju}|^p \right)^{\frac{1}{p}}</script><p>其中，$ p \geq 1 $ 是一个可调节的参数。</p>
<p><strong>2. 特殊情况</strong></p>
<ul>
<li><p><strong>当 $ p = 2 $</strong>：退化为<strong>欧氏距离（Euclidean Distance）</strong>  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{ed}}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \sqrt{\sum_{u=1}^{n} |x_{iu} - x_{ju}|^2}</script><ul>
<li><strong>几何意义</strong>：两点之间的直线距离。  </li>
<li><strong>适用场景</strong>：大多数机器学习算法（如KNN、PCA）默认使用欧氏距离。</li>
</ul>
</li>
<li><p><strong>当 $ p = 1 $</strong>：退化为<strong>曼哈顿距离（Manhattan Distance）</strong>  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{man}}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \sum_{u=1}^{n} |x_{iu} - x_{ju}|</script><ul>
<li><strong>几何意义</strong>：沿坐标轴移动的总距离（如棋盘格路径）。  </li>
<li><strong>适用场景</strong>：高维稀疏数据（如文本特征）、计算资源受限的场景。</li>
</ul>
</li>
<li><p><strong>当 $ p \to \infty $</strong>：退化为<strong>切比雪夫距离（Chebyshev Distance）</strong>  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{che}}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \max_{u} |x_{iu} - x_{ju}|</script><ul>
<li><strong>几何意义</strong>：各维度差值的最大值。  </li>
<li><strong>适用场景</strong>：关注最坏情况下的误差（如游戏AI路径规划）。</li>
</ul>
</li>
</ul>
<p><strong>3. 参数 $ p $ 的影响</strong></p>
<ul>
<li><strong>$ p $ 越小</strong>：距离计算越关注较小的维度差异（如曼哈顿距离对单个维度的扰动更敏感）。  </li>
<li><strong>$ p $ 越大</strong>：距离计算越关注较大的维度差异（如切比雪夫距离仅关注最大差值）。  </li>
<li><strong>选择依据</strong>：  <ul>
<li>数据分布是否均匀：若某些维度差异显著，可增大 $ p $。  </li>
<li>算法需求：如KNN中，高维数据可能更适合曼哈顿距离（缓解“维度灾难”）。</li>
</ul>
</li>
</ul>
<h5 id="离散无序"><a href="#离散无序" class="headerlink" title="离散无序"></a>离散无序</h5><p>我们知道属性分为两种：<strong>连续属性</strong>(continuous attribute)和<strong>离散属性</strong>（catergorical attribute有限个取值）。对于连续值的属性，一般都可以被学习器所用，有时会根据具体的情形作相应的预处理，例如：归一化等；而对于离散值的属性，需要作下面进一步的处理：</p>
<blockquote>
<p>若属性值之间<strong>存在序关系</strong>(ordinal attribute)，则可以将其转化为连续值，例如：身高属性“高”“中等”“矮”，可转化为{1, 0.5, 0}。 </p>
<p>若属性值之间<strong>不存在序关系</strong>(non-ordinal attribute)，则通常将其转化为向量的形式，例如：性别属性“男”“女”，可转化为{（1,0）,（0,1）}。</p>
</blockquote>
<p><strong>连续属性和存在序关系的离散属性都可以直接参与计算</strong>，而不存在序关系的<strong>无序属性，我们一般采用VDM（Value Difference Metric）进行距离的计算</strong></p>
<p>VDM 是一种专门用于<strong>离散无序属性</strong>的距离度量方法，通过统计信息量化不同类别间的差异。其核心思想是：<strong>若两个类别的样本在目标变量上的分布差异越大，则它们的距离越大</strong>。</p>
<p><strong>1. 公式解析</strong></p>
<script type="math/tex; mode=display">
\text{VDM}_p(a, b) = \sum_{i=1}^{k} \left| \frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}} \right|^p</script><ul>
<li><strong>符号含义</strong>：  <ul>
<li>$ a, b $：两个不同的类别值（如性别“男”和“女”）。  </li>
<li>$ m_{u,a,i} $：在属性 $ u $ 的第 $ i $ 个取值下，类别 $ a $ 的样本数量。  </li>
<li>$ m_{u,a} $：类别 $ a $ 的总样本数量。  </li>
<li>$ k $：属性 $ u $ 的不同取值数目（如颜色属性有红、蓝、绿三种取值，则 $ k=3 $）。  </li>
<li>$ p $：距离幂指数（通常取 $ p=1 $ 或 $ p=2 $）。</li>
</ul>
</li>
</ul>
<p><strong>2. 核心思想</strong></p>
<ul>
<li><strong>统计分布差异</strong>：<br>对于每个属性取值 $ i $，计算类别 $ a $ 和 $ b $ 的样本比例差异：  <script type="math/tex; mode=display">
\left| \frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}} \right|</script>该值越大，说明两个类别在该取值上的分布差异越大。  </li>
<li><strong>加权求和</strong>：<br>将所有属性取值的差异按 $ p $ 次方加权求和，得到最终的距离。</li>
</ul>
<p><strong>3. 示例说明</strong></p>
<p>假设我们有一个“颜色”属性（红、蓝、绿），目标变量是“是否购买商品”（0/1）。统计结果如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>颜色</th>
<th>购买（1）</th>
<th>不购买（0）</th>
<th>总计</th>
</tr>
</thead>
<tbody>
<tr>
<td>红</td>
<td>10</td>
<td>5</td>
<td>15</td>
</tr>
<tr>
<td>蓝</td>
<td>8</td>
<td>12</td>
<td>20</td>
</tr>
<tr>
<td>绿</td>
<td>3</td>
<td>7</td>
<td>10</td>
</tr>
</tbody>
</table>
</div>
<p>计算“红”与“蓝”之间的 VDM 距离（$ p=1 $）：</p>
<ol>
<li>计算每个颜色在购买/不购买的比例：  <ul>
<li>红：$ P(1) = 10/15 \approx 0.67 $，$ P(0) = 5/15 \approx 0.33 $  </li>
<li>蓝：$ P(1) = 8/20 = 0.4 $，$ P(0) = 12/20 = 0.6 $  </li>
</ul>
</li>
<li>计算差异并求和：  <script type="math/tex; mode=display">
\text{VDM}_1(\text{红}, \text{蓝}) = |0.67 - 0.4| + |0.33 - 0.6| = 0.27 + 0.27 = 0.54</script></li>
</ol>
<h4 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h4><p>于聚类算法不依赖于样本的真实类标，就不能像监督学习的分类那般，通过计算分对分错（即精确度或错误率）来评价学习器的好坏或作为学习过程中的优化目标。</p>
<p>直观上看,我们希望<strong>“物以类聚”</strong>,即同一簇的样本尽可能彼此相似,不同簇的样本尽可能不同换言之,聚类结果的<strong>“簇内相似度”( intra-cluster similarity)高且“簇间相似度” inter-cluster similarity)低</strong></p>
<p><strong>聚类性能度量有两类</strong></p>
<ul>
<li>“外部指标”(external index)：所谓外部指标就是已经有一个“参考模型”存在了，将当前模型与参考模型的比对结果作为指标。</li>
<li>“内部指标”( internal index)：所谓内部指标就是仅仅考虑当前模型的聚类结果。</li>
</ul>
<h5 id="外部指标"><a href="#外部指标" class="headerlink" title="外部指标"></a>外部指标</h5><p><strong>1.基本概念</strong></p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607110103570.png" alt="image-20250607110103570"></p>
<p>显然，$ a + b + c + d = \frac{m(m-1)}{2} $ 。</p>
<p><strong>2. 常用外部指标</strong></p>
<p><strong>（1）Jaccard系数（JC）</strong></p>
<script type="math/tex; mode=display">
\text{JC} = \frac{a}{a + b + c}</script><ul>
<li><strong>含义</strong>：衡量两个划分的重叠程度，仅考虑正确匹配（$ a $）与矛盾情况（$ b + c $）。  </li>
<li><strong>范围</strong>：$ [0, 1] $，值越大越好。  </li>
<li><strong>特点</strong>：对称性差，对噪声敏感 。</li>
</ul>
<p><strong>（2）Fowlkes-Mallows指数（FMI）</strong></p>
<script type="math/tex; mode=display">
\text{FMI} = \sqrt{\frac{a}{a + b} \cdot \frac{a}{a + c}}</script><ul>
<li><strong>含义</strong>：结合查准率（$ \frac{a}{a + c} $）和查全率（$ \frac{a}{a + b} $），反映正确匹配的综合能力。  </li>
<li><strong>范围</strong>：$ [0, 1] $，值越大越好。  </li>
<li><strong>特点</strong>：平衡性较好，适合小样本 。</li>
</ul>
<p><strong>（3）Rand指数（RI）</strong></p>
<script type="math/tex; mode=display">
\text{RI} = \frac{2(a + d)}{m(m - 1)}</script><ul>
<li><strong>含义</strong>：同时考虑正确匹配（$ a + d $）与总样本对数，适用于大规模数据。  </li>
<li><strong>范围</strong>：$ [0, 1] $，值越大越好。  </li>
<li><strong>特点</strong>：计算简单，但对噪声较鲁棒 。</li>
</ul>
<p><strong>常用指标</strong></p>
<ul>
<li><p><strong>调整兰德指数（Adjusted Rand Index, ARI）</strong>  </p>
<ul>
<li><strong>定义</strong>：衡量聚类结果与真实标签的匹配程度，调整随机聚类的影响，取值范围 [-1, 1]，值越大越好。  </li>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
\text{ARI} = \frac{\text{RI} - \mathbb{E}[\text{RI}]}{\max(\text{RI}) - \mathbb{E}[\text{RI}]}</script>其中 RI 是兰德指数（匹配样本对的比例）。</li>
</ul>
</li>
<li><p><strong>归一化互信息（Normalized Mutual Information, NMI）</strong>  </p>
<ul>
<li><strong>定义</strong>：衡量聚类结果与真实标签的信息共享程度，值越大越好。  </li>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
\text{NMI} = \frac{I(C; K)}{\sqrt{H(C) H(K)}}</script>其中 $ I(C; K) $ 是互信息，$ H(C) $ 和 $ H(K) $ 是熵。</li>
</ul>
</li>
<li><p><strong>Fowlkes-Mallows 指数（FMI）</strong>  </p>
<ul>
<li><strong>定义</strong>：基于聚类结果与真实标签的 TP、FP、TN、FN 计算，值越大越好。  </li>
<li><strong>公式</strong>：  <script type="math/tex; mode=display">
\text{FMI} = \sqrt{\frac{\text{TP}}{\text{TP} + \text{FP}} \cdot \frac{\text{TP}}{\text{TP} + \text{FN}}}</script></li>
</ul>
</li>
</ul>
<p><strong>优点</strong></p>
<ul>
<li>在有真实标签时，能更客观地评估聚类效果。</li>
<li>适用于验证聚类结果的业务意义（如客户分群是否符合预期）。</li>
</ul>
<p><strong>局限性</strong></p>
<ul>
<li>需要真实标签，不适用于纯无监督任务。</li>
<li>对标签噪声敏感（如标签错误会误导 $ K $ 的选择）。</li>
</ul>
<p><strong>3. 应用示例</strong></p>
<p>假设一个包含4个样本的数据集，参考标签为 ${A, A, B, B}$，聚类结果为 ${C, C, D, D}$：</p>
<ul>
<li><strong>计算样本对</strong>：  <ul>
<li>$ a = 2 $（样本1-2同簇，参考与聚类均同类）。  </li>
<li>$ b = 0 $（参考同类但聚类不同类）。  </li>
<li>$ c = 0 $（参考不同类但聚类同类）。  </li>
<li>$ d = 2 $（参考不同类且聚类不同类）。  </li>
</ul>
</li>
<li><strong>指标结果</strong>：  <ul>
<li>JC = $ \frac{2}{2+0+0} = 1 $（完美匹配）。  </li>
<li>FMI = $ \sqrt{\frac{2}{2+0} \cdot \frac{2}{2+0}} = 1 $。  </li>
<li>RI = $ \frac{2(2+2)}{4 \times 3} = \frac{8}{12} \approx 0.67 $。</li>
</ul>
</li>
</ul>
<h5 id="内部指标"><a href="#内部指标" class="headerlink" title="内部指标"></a>内部指标</h5><p>内部指标不依赖任何外部参考模型，直接通过<strong>簇内紧凑性</strong>和<strong>簇间分离性</strong>评估聚类结果。其核心思想是：</p>
<ul>
<li><strong>簇内高内聚</strong>：同一簇的样本尽可能相似（距离小）。  </li>
<li><strong>簇间低耦合</strong>：不同簇的样本尽可能不同（距离大）。</li>
</ul>
<p><strong>1. 基本定义</strong></p>
<p>设聚类结果为 $ C = {C_1, C_2, \dots, C_k} $，定义以下四个关键距离：</p>
<p><strong>（1）簇内平均距离（avg(C)）</strong></p>
<script type="math/tex; mode=display">
\text{avg}(C) = \frac{2}{|C|(|C| - 1)} \sum_{1 \leq i < j \leq |C|} \text{dist}(\boldsymbol{x}_i, \boldsymbol{x}_j)</script><ul>
<li><strong>含义</strong>：簇内所有样本对的平均距离。  </li>
<li><strong>目标</strong>：越小越好，表示簇内样本更紧密。</li>
</ul>
<p><strong>（2）簇内最大距离（diam(C)）</strong></p>
<script type="math/tex; mode=display">
\text{diam}(C) = \max_{1 \leq i < j \leq |C|} \text{dist}(\boldsymbol{x}_i, \boldsymbol{x}_j)</script><ul>
<li><strong>含义</strong>：簇内最远的两个样本之间的距离。  </li>
<li><strong>目标</strong>：越小越好，避免簇内存在离群点。</li>
</ul>
<p><strong>（3）簇间最小距离（$ d_{\min}(C_i, C_j) $）</strong></p>
<script type="math/tex; mode=display">
d_{\min}(C_i, C_j) = \min_{\boldsymbol{x}_i \in C_i, \boldsymbol{x}_j \in C_j} \text{dist}(\boldsymbol{x}_i, \boldsymbol{x}_j)</script><ul>
<li><strong>含义</strong>：簇 $ C_i $ 和 $ C_j $ 之间最近的两个样本的距离。  </li>
<li><strong>目标</strong>：越大越好，表示簇间分离度高。</li>
</ul>
<p><strong>（4）簇中心距离（$ d_{\text{cen}}(C_i, C_j) $）</strong></p>
<script type="math/tex; mode=display">
d_{\text{cen}}(C_i, C_j) = \text{dist}(\boldsymbol{\mu}_i, \boldsymbol{\mu}_j)</script><ul>
<li><strong>含义</strong>：簇 $ C_i $ 和 $ C_j $ 的中心点（均值向量）之间的距离。  </li>
<li><strong>目标</strong>：越大越好，表示簇中心相隔较远。</li>
</ul>
<p><strong>2. 常用内部指标</strong></p>
<p><strong>1. DB指数（Davies-Bouldin Index, DBI）</strong></p>
<ul>
<li><p><strong>公式</strong>：  </p>
<script type="math/tex; mode=display">
\text{DBI} = \frac{1}{k} \sum_{i=1}^{k} \max_{j \neq i} \left( \frac{\text{avg}(C_i) + \text{avg}(C_j)}{d_{\text{cen}}(\mu_i, \mu_j)} \right)</script><ul>
<li><strong>符号含义</strong>：  <ul>
<li>$ k $：簇的数量。  </li>
<li>$ \text{avg}(C_i) $：簇 $ C_i $ 内部样本的平均距离。  </li>
<li>$ d_{\text{cen}}(\mu_i, \mu_j) $：簇 $ C_i $ 和 $ C_j $ 的中心点（均值向量）之间的距离。  </li>
</ul>
</li>
<li><strong>目标</strong>：越小越好。  </li>
<li><strong>核心思想</strong>：对于每个簇 $ C<em>i $，找到与其“最竞争”的簇 $ C_j $（即 $ \frac{\text{avg}(C_i) + \text{avg}(C_j)}{d</em>{\text{cen}}(\mu_i, \mu_j)} $ 最大的簇），并取所有簇的平均值。  </li>
</ul>
</li>
<li><p><strong>示例</strong>：<br>若簇 $ C_1 $ 和 $ C_2 $ 的平均距离分别为 2 和 3，中心距离为 5，则它们的比值为 $ \frac{2+3}{5} = 1 $。若这是 $ C_1 $ 的最大比值，则 $ C_1 $ 对 DBI 的贡献为 1。最终 DBI 是所有簇贡献的平均值。  </p>
</li>
</ul>
<p><strong>2. Dunn指数（Dunn Index, DI）</strong></p>
<ul>
<li><p><strong>公式</strong>：  </p>
<script type="math/tex; mode=display">
\text{DI} = \min_{1 \leq i \leq k} \left\{ \frac{\min_{j \neq i} d_{\min}(C_i, C_j)}{\max_{1 \leq l \leq k} \text{diam}(C_l)} \right\}</script><ul>
<li><strong>符号含义</strong>：  <ul>
<li>$ d_{\min}(C_i, C_j) $：簇 $ C_i $ 和 $ C_j $ 之间的最小距离（最近样本对的距离）。  </li>
<li>$ \text{diam}(C_l) $：簇 $ C_l $ 内的最大距离（最远样本对的距离）。  </li>
</ul>
</li>
<li><strong>目标</strong>：越大越好。  </li>
<li><strong>核心思想</strong>：  <ul>
<li>分子：所有簇对之间的最小距离中的最小值（即最“脆弱”的簇间分离度）。  </li>
<li>分母：所有簇中的最大直径（最“松散”的簇内紧凑度）。  </li>
<li>指数越大，表示簇间分离度高且簇内紧凑。  </li>
</ul>
</li>
</ul>
</li>
<li><p><strong>示例</strong>：<br>假设簇对 $ (C_1, C_2) $ 的最小距离为 5，簇 $ C_3 $ 的最大直径为 10，则 DI 为 $ \frac{5}{10} = 0.5 $。  </p>
</li>
</ul>
<p><strong>3. 轮廓系数（Silhouette Coefficient）</strong></p>
<ul>
<li><p><strong>单一样本的轮廓系数</strong>：  </p>
<script type="math/tex; mode=display">
s = \frac{b - a}{\max(a, b)}</script><ul>
<li><strong>符号含义</strong>：  <ul>
<li>$ a $：样本到同簇其他样本的平均距离（簇内凝聚度）。  </li>
<li>$ b $：样本到最近簇中样本的平均距离（簇间分离度）。  </li>
</ul>
</li>
<li><strong>取值范围</strong>：$ [-1, 1] $，越接近 1 表示聚类效果越好。  </li>
<li><strong>核心思想</strong>：  <ul>
<li>若 $ a &lt; b $（同簇紧密，异簇疏远），则 $ s &gt; 0 $，样本分类合理。  </li>
<li>若 $ a &gt; b $（同簇松散，异簇更近），则 $ s &lt; 0 $，样本可能被错误分类。  </li>
</ul>
</li>
</ul>
</li>
<li><p><strong>整体轮廓系数</strong>：所有样本轮廓系数的平均值。  </p>
</li>
<li><p><strong>示例</strong>：<br>若某样本 $ a = 2 $，$ b = 5 $，则 $ s = \frac{5-2}{5} = 0.6 $，表明该样本分类合理。  </p>
</li>
</ul>
<p><strong>4.肘部法则（Elbow Method）</strong></p>
<p>肘部法则是一种<strong>经验性方法</strong>，常用于确定K-means等聚类算法的最优簇数（$ K $）。其核心思想是通过观察误差平方和（SSE, Sum of Squared Errors）随 $ K $ 值变化的趋势，寻找“肘部点”（即 SSE 下降速度明显减缓的拐点），从而选择最优的 $ K $ 值</p>
<ul>
<li><p><strong>SSE（误差平方和）</strong>：衡量每个样本到其所属簇中心的距离平方和，公式为：</p>
<script type="math/tex; mode=display">
\text{SSE} = \sum_{i=1}^n \|x_i - \mu_{c_i}\|^2</script><p>其中 $ x<em>i $ 是样本点，$ \mu</em>{c_i} $ 是其所属簇中心。</p>
</li>
<li><p><strong>趋势分析</strong>：</p>
<ul>
<li>当 $ K $ 增大时，SSE 会不断减小（因为簇越多，每个簇的样本越密集）。</li>
<li>但当 $ K $ 增加到某个值后，SSE 的下降速度会显著放缓，形成“肘部”形状。</li>
</ul>
</li>
<li><p><strong>肘部点的意义</strong>：<br>肘部点对应的 $ K $ 值是<strong>模型复杂度</strong>（簇数）与<strong>聚类效果</strong>（SSE）之间的平衡点。</p>
</li>
</ul>
<p><strong>指标对比与选择</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>指标</strong></th>
<th><strong>计算方式</strong></th>
<th><strong>目标</strong></th>
<th><strong>适用场景</strong></th>
<th><strong>局限性</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>DBI</td>
<td>簇内平均距离与簇中心距离的比值</td>
<td>越小越好</td>
<td>球形簇，需指定 $ k $</td>
<td>对离群点敏感</td>
</tr>
<tr>
<td>Dunn指数</td>
<td>簇间最小距离与簇内最大直径的比值</td>
<td>越大越好</td>
<td>强调簇间分离与簇内紧凑</td>
<td>计算复杂，受离群点影响</td>
</tr>
<tr>
<td>轮廓系数</td>
<td>样本到同簇/异簇的平均距离差</td>
<td>越接近 1 越好</td>
<td>快速评估，适合 K-Means</td>
<td>对非球形簇不敏感</td>
</tr>
</tbody>
</table>
</div>
<h4 id="原型聚类与kmeans"><a href="#原型聚类与kmeans" class="headerlink" title="原型聚类与kmeans"></a>原型聚类与kmeans</h4><h5 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h5><p>原型聚类即“<strong>基于原型的聚类</strong>”（prototype-based clustering），原型表示模板的意思，就是通过参考一个模板向量或模板分布的方式来完成聚类的过程，通常情形下算法先对原型进行初始化,然后对原型进行迭代更新求解。采用不同的原型表、不同的求解方式,将产生不同的算法。</p>
<p>常见的K-Means便是基于簇中心（原型向量）来实现聚类，混合高斯聚类则是基于簇分布（概率模型）来实现聚类。</p>
<h5 id="K-Means-聚类算法详解"><a href="#K-Means-聚类算法详解" class="headerlink" title="K-Means 聚类算法详解"></a><strong>K-Means 聚类算法详解</strong></h5><p><strong>目标函数</strong>：最小化所有样本到其所属簇中心的平方距离之和：  </p>
<script type="math/tex; mode=display">
E = \sum_{i=1}^{k} \sum_{\boldsymbol{x} \in C_i} \|\boldsymbol{x} - \boldsymbol{\mu}_i\|_2^2</script><p>其中，$ \boldsymbol{\mu}<em>i = \frac{1}{|C_i|} \sum</em>{\boldsymbol{x} \in C_i} \boldsymbol{x} $ 是簇 $ C_i $ 的均值向量。</p>
<p><strong>算法步骤</strong></p>
<ol>
<li><strong>初始化簇中心</strong>：随机选择 $ k $ 个样本作为初始簇中心。  <ul>
<li><strong>改进方法</strong>：K-Means++ 算法可提升初始中心的质量。  </li>
</ul>
</li>
<li><strong>分配样本到最近簇</strong>：对每个样本 $ \boldsymbol{x} $，计算其到所有簇中心的距离，将其分配到距离最近的簇 $ C_i $。  </li>
<li><strong>更新簇中心</strong>：重新计算每个簇的均值向量 $ \boldsymbol{\mu}_i $。  </li>
<li><strong>迭代终止条件</strong>：  <ul>
<li>达到预设的最大迭代次数；  </li>
<li>簇中心不再显著变化（如变化幅度小于阈值 $ \epsilon $）；  </li>
<li>样本分配不再改变。</li>
</ul>
</li>
</ol>
<p><strong>如何选择 $ k $ 值？</strong></p>
<ul>
<li><strong>肘部法则（Elbow Method）</strong>：绘制 $ k $ 与误差 $ E $ 的关系曲线，选择误差下降显著变缓的 $ k $ 值。  </li>
<li><strong>轮廓系数（Silhouette Coefficient）</strong>：计算每个样本的轮廓系数，选择平均轮廓系数最大的 $ k $。  </li>
</ul>
<h5 id="K-Means的算法流程"><a href="#K-Means的算法流程" class="headerlink" title="K-Means的算法流程"></a>K-Means的算法流程</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607114743211.png" alt="image-20250607114743211"></p>
<h5 id="K-means"><a href="#K-means" class="headerlink" title="K-means++"></a>K-means++</h5><p>此法相对于 K-means 做出了一个小的改进。在一开始选择 k 个聚类中心时，并不是随机初始化 k 个，而是首先随机出 1 个，然后循环 k−1<em>k</em>−1 次选择剩下的 k-1 个聚类中心。选择的规则是：每次选择最不可能成为新的聚类中心的样本，或者是到所有聚类中心的最小距离最大的样本。</p>
<h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a><strong>优势</strong></h5><p><strong>避免不良初始化</strong> ：传统K-means随机初始化可能导致中心过于集中，而K-means++通过“最大化最小距离”策略，使初始中心分布更均匀。</p>
<h5 id="Bisecting-K-means"><a href="#Bisecting-K-means" class="headerlink" title="Bisecting K-means"></a>Bisecting K-means</h5><p>此法叫做二分 K-means 算法。具体的，在一开始将所有的样本划分为一个簇，然后每次选择一个误差最大的簇进行二分裂，不断分裂直到收敛。这种方法不能使得 Loss 最小，但是可以作为 K-means 算法的一个预热，比如可以通过这种方法得到一个相对合理的簇中心，然后再利用 K-means 算法进行聚类。</p>
<h5 id="优势-1"><a href="#优势-1" class="headerlink" title="优势"></a><strong>优势</strong></h5><p><strong>降低计算复杂度</strong> ：每次仅对一个簇进行二分，时间复杂度为 <em>O</em>(<em>k</em>⋅<em>m</em>⋅<em>n</em>) ，适合大规模数据。</p>
<p><strong>提供合理初始中心</strong> ：可作为传统K-means的预处理，减少随机初始化的影响。</p>
<h5 id="LVQ（学习向量量化）"><a href="#LVQ（学习向量量化）" class="headerlink" title="LVQ（学习向量量化）"></a><strong>LVQ（学习向量量化）</strong></h5><p><strong>核心思想</strong>：<br>LVQ 是一种<strong>有监督的原型聚类算法</strong>，结合了神经网络与向量量化技术。它通过维护一组<strong>原型向量</strong>（Prototype Vectors）来代表不同类别，并利用这些原型对数据进行分类或聚类。与 K-Means 类似，LVQ 会为每个簇分配一个原型向量，但其更新规则受类别标签的指导，因此更适用于分类任务 。</p>
<p><strong>算法特点</strong>：  </p>
<ul>
<li><strong>有监督学习</strong>：需要已知类别标签来调整原型向量，使同类样本更接近对应原型，异类样本远离原型。  </li>
<li><strong>拓扑结构建模</strong>：通过原型向量捕捉数据的局部特征，类似于自组织映射（SOM），但更具针对性。  </li>
<li><strong>硬聚类</strong>：每个样本最终被分配到最近的原型对应的类别，不提供概率输出 。</li>
</ul>
<h5 id="高斯混合聚类（Gaussian-Mixture-Model-GMM）"><a href="#高斯混合聚类（Gaussian-Mixture-Model-GMM）" class="headerlink" title="高斯混合聚类（Gaussian Mixture Model, GMM）"></a><strong>高斯混合聚类（Gaussian Mixture Model, GMM）</strong></h5><p> 一句话概述算法：高斯混合聚类算法是一种概率模型，假设数据由多个高斯分布混合而成，通过迭代优化参数以拟合数据分布，常用于无监督学习中的聚类任务。</p>
<p>算法过程：</p>
<p>初始化参数： 随机初始化每个分量的均值、协方差矩阵和混合系数。</p>
<p>E 步（Expectation）： 对每个数据点，计算它属于每个分量的后验概率，即计算每个分量的权重。</p>
<p>M 步（Maximization）： 使用E步计算得到的后验概率，更新每个分量的均值、协方差矩阵和混合系数。</p>
<p>迭代： 重复执行E步和M步，直到模型参数收敛或达到预定的迭代次数。</p>
<p>GMM的优点包括对各种形状和方向的聚类簇建模能力，以及对数据分布的灵活性。它在许多领域，如模式识别、图像处理和自然语言处理等，都有广泛的应用。<br><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250611180451162.png" alt="image-20250611180451162"></p>
<p>以下是高斯混合聚类（GMM）算法的详细步骤及EM算法中E步与M步的解释：</p>
<p><strong>算法流程解析</strong></p>
<p><strong>输入</strong>：样本集 $ D = {x_1, x_2, \dots, x_m} $，混合成分个数 $ k $。<br><strong>输出</strong>：簇划分 $ C = {C_1, C_2, \dots, C_k} $。</p>
<p><strong>步骤详解</strong></p>
<ol>
<li><p><strong>初始化模型参数</strong><br>随机初始化或通过K-means初步估计以下参数：</p>
<ul>
<li><strong>混合系数</strong> $ \alpha<em>i $（满足 $ \sum</em>{i=1}^k \alpha_i = 1 $）。</li>
<li><strong>均值向量</strong> $ \mu_i $。</li>
<li><strong>协方差矩阵</strong> $ \Sigma_i $。</li>
</ul>
</li>
<li><p><strong>迭代优化参数（EM循环）</strong><br>重复以下步骤直到收敛（如对数似然变化小于阈值）：</p>
<ul>
<li><p><strong>E步（期望步）</strong>：<br>对每个样本 $ x<em>j $，计算其由第 $ i $ 个高斯分布生成的<strong>后验概率</strong>（责任度 $ \gamma</em>{ji} $）：</p>
<script type="math/tex; mode=display">
\gamma_{ji} = p(z_j = i | x_j) = \frac{\alpha_i \mathcal{N}(x_j | \mu_i, \Sigma_i)}{\sum_{l=1}^k \alpha_l \mathcal{N}(x_j | \mu_l, \Sigma_l)}</script><p>其中 $ \mathcal{N}(x | \mu, \Sigma) $ 是高斯分布的概率密度函数。</p>
</li>
<li><p><strong>M步（最大化步）</strong>：<br>根据当前的责任度 $ \gamma_{ji} $，更新模型参数：</p>
<ol>
<li><strong>新均值向量</strong>：<script type="math/tex; mode=display">
\mu_i' = \frac{\sum_{j=1}^m \gamma_{ji} x_j}{\sum_{j=1}^m \gamma_{ji}}</script></li>
<li><strong>新协方差矩阵</strong>：<script type="math/tex; mode=display">
\Sigma_i' = \frac{\sum_{j=1}^m \gamma_{ji} (x_j - \mu_i')(x_j - \mu_i')^\top}{\sum_{j=1}^m \gamma_{ji}}</script></li>
<li><strong>新混合系数</strong>：<script type="math/tex; mode=display">
\alpha_i' = \frac{\sum_{j=1}^m \gamma_{ji}}{m}</script></li>
</ol>
</li>
</ul>
</li>
<li><p><strong>簇划分</strong>  </p>
<ul>
<li>初始化空簇 $ C_i = \varnothing $。</li>
<li>对每个样本 $ x<em>j $，计算其属于各簇的后验概率 $ \lambda_j = \arg\max_i \gamma</em>{ji} $。</li>
<li>将 $ x<em>j $ 分配到簇 $ C</em>{\lambda_j} $ 中。</li>
</ul>
</li>
</ol>
<p><strong>E步与M步的核心作用</strong></p>
<p><strong>E步（期望步）</strong></p>
<ul>
<li><strong>目标</strong>：基于当前参数 $ (\alpha<em>i, \mu_i, \Sigma_i) $，计算每个样本 $ x_j $ 属于各高斯分布的<strong>责任度</strong> $ \gamma</em>{ji} $。</li>
<li><strong>意义</strong>：<ul>
<li>责任度反映了在当前模型下，样本 $ x_j $ 由第 $ i $ 个高斯分布生成的概率。</li>
<li><strong>软分配</strong>：允许样本部分属于多个簇，而非硬划分。</li>
</ul>
</li>
</ul>
<p><strong>M步（最大化步）</strong></p>
<ul>
<li><strong>目标</strong>：根据责任度 $ \gamma_{ji} $，重新估计模型参数 $ (\alpha_i’, \mu_i’, \Sigma_i’) $，以最大化数据的对数似然。</li>
<li><strong>关键公式</strong>：<ul>
<li><strong>均值更新</strong>：加权平均样本点，权重为责任度。</li>
<li><strong>协方差更新</strong>：加权样本点的方差，反映簇内数据分布。</li>
<li><strong>混合系数更新</strong>：各簇样本的“有效数量”占总样本的比例。</li>
</ul>
</li>
</ul>
<h4 id="参考资料-1"><a href="#参考资料-1" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://blog.csdn.net/smileyan9/article/details/135398479">西瓜书读书笔记整理（九） —— 第九章 聚类_西瓜书笔记第9章-CSDN博客</a></p>
<h4 id="密度聚类与DBSCAN"><a href="#密度聚类与DBSCAN" class="headerlink" title="密度聚类与DBSCAN"></a>密度聚类与DBSCAN</h4><blockquote>
<p>若样本分布为同心的两个环，kmeans则无法做到良好的聚类效果，因此引出密度聚类</p>
</blockquote>
<p>密度聚类是一种基于<strong>样本分布密集程度</strong>的无监督学习方法，其核心思想是：<strong>将高密度区域划分为同一簇，低密度区域视为噪声或边界</strong>。</p>
<p>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是密度聚类的典型代表，通过两个关键参数 $ \epsilon $ 和 $ MinPts $ 描述样本分布的紧密性。</p>
<h5 id="1-核心概念"><a href="#1-核心概念" class="headerlink" title="1. 核心概念"></a><strong>1. 核心概念</strong></h5><ol>
<li><strong>$ \epsilon $-邻域</strong>  <ul>
<li>定义：与样本 $ x $ 距离不超过 $ \epsilon $ 的所有样本集合。  </li>
<li>作用：衡量样本周围的局部密度。  </li>
</ul>
</li>
<li><strong>核心对象（Core Object）</strong>  <ul>
<li>定义：若样本 $ x $ 的 $ \epsilon $-邻域内包含至少 $ MinPts $ 个样本，则 $ x $ 是核心对象。  </li>
<li>作用：作为簇的生长起点，确保簇的最小密度要求。  </li>
</ul>
</li>
<li><strong>密度直达（Directly Density-Reachable）</strong>  <ul>
<li>定义：若样本 $ x_j $ 位于核心对象 $ x_i $ 的 $ \epsilon $-邻域内，则称 $ x_i $ 可密度直达 $ x_j $。  </li>
<li>作用：建立核心对象与邻近样本的直接连接。  </li>
</ul>
</li>
<li><strong>密度可达（Density-Reachable）</strong>  <ul>
<li>定义：若存在样本序列 $ x<em>i, p_1, p_2, \dots, p_n, x_j $，其中 $ p_i $ 密度直达 $ p</em>{i+1} $，则称 $ x_i $ 可密度可达 $ x_j $。  </li>
<li>作用：通过链式传递扩展簇的范围。  </li>
</ul>
</li>
<li><strong>密度相连（Density-Connected）</strong>  <ul>
<li>定义：若样本 $ x_i $ 和 $ x_j $ 均可密度可达某个公共样本 $ x_k $，则称 $ x_i $ 和 $ x_j $ 密度相连。  </li>
<li>作用：确保簇的连通性，避免碎片化。  </li>
</ul>
</li>
</ol>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124326529.png" alt="image-20250607124326529"></p>
<p><strong>DBSCN定义的簇</strong></p>
<ul>
<li>定义：最大密度相连的样本集合为一个簇</li>
<li>有两个性质：1.连接性：同一个簇内任意两样本，必然密度相连2.最大性：密度可达的两个样本必<br>定属于同一个簇</li>
</ul>
<h5 id="2-DBSCAN-算法流程"><a href="#2-DBSCAN-算法流程" class="headerlink" title="2. DBSCAN 算法流程"></a><strong>2. DBSCAN 算法流程</strong></h5><p>简单来理解DBSCAN：<strong>找出一个核心对象所有密度可达的样本集合形成簇</strong>。首先从数据集中任选一个核心对象A，找出所有A密度可达的样本集合，将这些样本形成一个密度相连的类簇，直到所有的核心对象都遍历完。DBSCAN算法的流程如下图所示：</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607124446432.png" alt="image-20250607124446432"></p>
<h5 id="3-参数选择与影响"><a href="#3-参数选择与影响" class="headerlink" title="3. 参数选择与影响"></a><strong>3. 参数选择与影响</strong></h5><ul>
<li><p><strong>$ \epsilon $（邻域半径）</strong>：  </p>
<ul>
<li>过小：可能导致多数样本被标记为噪声，簇数量增加。  </li>
<li>过大：可能导致不同簇合并，簇数量减少。  </li>
<li><strong>选择方法</strong>：通过<strong>K-Distance图</strong>（排序后的第 $ k $ 近邻距离）观察“拐点”。  </li>
</ul>
</li>
<li><p><strong>$ MinPts $（最小样本数）</strong>：  </p>
<ul>
<li>控制簇的最小密度阈值。  </li>
<li>通常取 $ d+1 $（$ d $ 为特征维度），避免在高维空间中误判噪声。  </li>
</ul>
</li>
</ul>
<h4 id="层次聚类与AGNES"><a href="#层次聚类与AGNES" class="headerlink" title="层次聚类与AGNES"></a>层次聚类与AGNES</h4><p>层次聚类是一种通过构建<strong>树状结构（Dendrogram）</strong>将数据划分为不同层次的聚类方法。其核心思想是：  </p>
<ul>
<li><strong>凝聚型（Agglomerative）</strong>：从每个样本作为一个独立簇开始，逐步合并最相似的簇，直到达到预设的簇数或形成一个唯一簇。  </li>
<li><strong>分裂型（Divisive）</strong>：与凝聚型相反，从整个数据集作为一个簇开始，逐步分裂为更小的簇。  </li>
</ul>
<p>本节重点介绍<strong>AGNES（Agglomerative Nesting）</strong>，一种经典的自底向上的层次聚类算法。</p>
<h5 id="1-AGNES-算法流程"><a href="#1-AGNES-算法流程" class="headerlink" title="1. AGNES 算法流程"></a><strong>1. AGNES 算法流程</strong></h5><ol>
<li><strong>初始化</strong>：每个样本作为一个独立簇。  </li>
<li><strong>迭代合并</strong>：  <ul>
<li>计算所有簇对之间的距离。  </li>
<li>合并距离最近的两个簇。  </li>
</ul>
</li>
<li><strong>终止条件</strong>：  <ul>
<li>达到预设的簇数 $ k $；  </li>
<li>所有簇之间的距离大于阈值。  </li>
</ul>
</li>
</ol>
<h5 id="2-簇间距离的定义"><a href="#2-簇间距离的定义" class="headerlink" title="2. 簇间距离的定义"></a><strong>2. 簇间距离的定义</strong></h5><p>AGNES 的关键在于如何定义<strong>簇间距离</strong>，常见的三种方法如下：</p>
<p><strong>（1）最小距离（Single Linkage）</strong></p>
<script type="math/tex; mode=display">
d_{\min}(C_i, C_j) = \min_{\boldsymbol{x} \in C_i, \boldsymbol{z} \in C_j} \text{dist}(\boldsymbol{x}, \boldsymbol{z})</script><ul>
<li><strong>含义</strong>：两个簇之间最近的两个样本的距离。  </li>
</ul>
<p><strong>（2）最大距离（Complete Linkage）</strong></p>
<script type="math/tex; mode=display">
d_{\max}(C_i, C_j) = \max_{\boldsymbol{x} \in C_i, \boldsymbol{z} \in C_j} \text{dist}(\boldsymbol{x}, \boldsymbol{z})</script><ul>
<li><strong>含义</strong>：两个簇之间最远的两个样本的距离。    </li>
</ul>
<p><strong>（3）平均距离（Average Linkage）</strong></p>
<script type="math/tex; mode=display">
d_{\text{avg}}(C_i, C_j) = \frac{1}{|C_i| |C_j|} \sum_{\boldsymbol{x} \in C_i} \sum_{\boldsymbol{z} \in C_j} \text{dist}(\boldsymbol{x}, \boldsymbol{z})</script><ul>
<li><strong>含义</strong>：两个簇所有样本对距离的平均值。  </li>
</ul>
<h5 id="层次聚类法的算法流程如下所示："><a href="#层次聚类法的算法流程如下所示：" class="headerlink" title="层次聚类法的算法流程如下所示："></a>层次聚类法的算法流程如下所示：</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125338029.png" alt="image-20250607125338029"></p>
<h4 id="作业-2"><a href="#作业-2" class="headerlink" title="作业"></a>作业</h4><h5 id="1-2"><a href="#1-2" class="headerlink" title="1"></a>1</h5><p>假设任务是将下面8个点聚类成3个簇：A1(2,10), A2(2,5), A3(8,4), B1(5,8), B2(7,5), B3(6,4), C1(1,2), C3(4,9)，距离函数是欧式距离。假设初始选择A1，B1，C1分别作为每个聚类的中心，用Kmeans算法给出计算过程。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125506436.png" alt="image-20250607125506436"></p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607125606040.png" alt="image-20250607125606040"></p>
<h5 id="2-2"><a href="#2-2" class="headerlink" title="2"></a>2</h5><p>Kmeans初始类簇中心如何选取？K值如何确定？请简要阐述。</p>
<p><strong>一、初始类簇中心的选取 (如何选好的起始点？)</strong></p>
<p>传统K-means随机选择初始中心点，容易导致结果不稳定（多次运行结果不同）或陷入局部最优（效果差）。改进方法主要有：</p>
<ol>
<li><strong>K-means++ (最常用且推荐)：</strong><ul>
<li><strong>核心思想：</strong> 让初始中心点彼此尽量远离。</li>
<li><strong>步骤：</strong><ol>
<li>随机选择<strong>第一个</strong>中心点。</li>
<li>计算每个数据点到<strong>当前已选中心点</strong>的最短距离（即离最近中心的距离）。</li>
<li>以<strong>与这个最短距离平方成正比</strong>的概率，随机选择下一个中心点（距离越大的点，被选中的概率越大）。</li>
<li>重复步骤2和3，直到选出K个中心点。</li>
</ol>
</li>
<li><strong>优点：</strong> 显著提高聚类质量和稳定性，计算开销增加不大。</li>
</ul>
</li>
<li><strong>多次运行+选取最优：</strong><ul>
<li>独立运行K-means算法多次（每次随机初始化）。</li>
<li>每次运行完成后，计算所有数据点与其所属簇中心的距离平方和（SSE, Sum of Squared Errors）。</li>
<li>选择SSE最小的那次运行结果作为最终结果。</li>
<li><strong>优点：</strong> 简单，增加找到更好解的机会。</li>
<li><strong>缺点：</strong> 计算开销随运行次数增加。</li>
</ul>
</li>
<li><strong>基于样本密度/距离：</strong><ul>
<li>选择数据空间中样本密度高的区域点作为中心。</li>
<li>或选择相互之间距离较远的点作为中心（类似K-means++的思想，但实现方式可能不同）。</li>
</ul>
</li>
</ol>
<p><strong>二、K值（簇数量）的确定 (如何知道分几类？)</strong></p>
<p>K值通常需要预先指定，但没有绝对正确的答案。常用方法基于评估不同K值下聚类结果的“质量”，寻找拐点或最优值：</p>
<ol>
<li><strong>肘部法则：</strong><ul>
<li><strong>核心思想：</strong> 随着K增大，簇内样本聚合更紧密，簇内平方和误差（SSE）会下降，但下降幅度会逐渐变缓。找到SSE下降速率发生显著变化的“肘点”。</li>
<li><strong>做法：</strong> 计算不同K值（如K=1, 2, 3, …, max）对应的SSE。绘制<code>K值 - SSE</code>曲线图。观察曲线，寻找SSE下降幅度突然变得平缓的那个K值（形如手臂的“肘关节”）。</li>
<li><strong>优点：</strong> 直观。</li>
<li><strong>缺点：</strong> “肘点”有时不明显或不存在，需要主观判断。</li>
</ul>
</li>
<li><strong>轮廓系数：</strong><ul>
<li><strong>核心思想：</strong> 综合衡量一个样本与其自身簇的紧密度(<code>a</code>)和与其他簇的分离度(<code>b</code>)。</li>
<li><strong>计算：</strong> 对于每个样本i：<ul>
<li><code>a(i)</code> = i 到同簇内所有其他点的平均距离（簇内不相似度）。</li>
<li><code>b(i)</code> = i 到所有<strong>其他簇</strong>中点的平均距离的最小值（最近邻簇的不相似度）。</li>
<li>样本i的轮廓系数：<code>s(i) = (b(i) - a(i)) / max(a(i), b(i))</code>。值在[-1, 1]之间。</li>
</ul>
</li>
<li><strong>整体评估：</strong> 计算所有样本轮廓系数的平均值，作为该K值下聚类的整体轮廓系数。</li>
<li><strong>选择K：</strong> 尝试不同K值，选择<strong>平均轮廓系数最大</strong>对应的K值。轮廓系数越接近1，表示聚类效果越好（簇内紧凑，簇间分离）。</li>
<li><strong>优点：</strong> 量化评估，结果在[-1, 1]之间有界。</li>
<li><strong>缺点：</strong> 计算量较大，尤其对于大数据集。</li>
</ul>
</li>
</ol>
<h4 id="参考资料-2"><a href="#参考资料-2" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://cloud.tencent.com.cn/developer/article/1802143">《机器学习》— 第九章 聚类-腾讯云开发者社区-腾讯云</a></p>
<h3 id="降维与度量学习"><a href="#降维与度量学习" class="headerlink" title="降维与度量学习"></a>降维与度量学习</h3><h4 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h4><p>k近邻算法简称<strong>kNN（k-Nearest Neighbor）</strong>，是一种经典的监督学习方法，是数据挖掘十大算法之一。其工作机制十分简单：给定某个测试样本，kNN基于某种<strong>距离度量</strong>在训练集中找出与其距离最近的k个带有真实标记的训练样本，然后基于这k个邻居的真实标记来进行预测，类似于集成学习中的基学习器结合策略：分类任务采用投票法，回归任务则采用平均法。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607150256290.png" alt="image-20250607150256290"></p>
<p><strong>核心思想</strong></p>
<p>1NN 分类器通过将测试样本 $ \boldsymbol{x} $ 分配到其最近邻样本 $ \boldsymbol{z} $ 的类别来完成预测。其错误概率取决于两个关键因素：</p>
<ul>
<li><strong>$ \boldsymbol{x} $ 的真实类别</strong>：$ P(c | \boldsymbol{x}) $，即给定 $ \boldsymbol{x} $ 属于类别 $ c $ 的概率。  </li>
<li><strong>$ \boldsymbol{z} $ 的类别</strong>：$ P(c | \boldsymbol{z}) $，即 $ \boldsymbol{z} $ 属于类别 $ c $ 的概率。</li>
</ul>
<p><strong>错误概率公式</strong></p>
<p>若测试样本 $ \boldsymbol{x} $ 的最近邻为 $ \boldsymbol{z} $，则 1NN 分类器出错的概率为：</p>
<script type="math/tex; mode=display">
P(\text{err}) = 1 - P(\text{correct}) = 1 - \sum_{c \in \mathcal{C}} P(c | \boldsymbol{x}) P(c | \boldsymbol{z})</script><p>其中：</p>
<ul>
<li>$ \mathcal{C} $ 是所有可能的类别集合。  </li>
<li>$ P(c | \boldsymbol{x}) $：$ \boldsymbol{x} $ 属于类别 $ c $ 的条件概率。  </li>
<li>$ P(c | \boldsymbol{z}) $：$ \boldsymbol{z} $ 属于类别 $ c $ 的条件概率。</li>
</ul>
<p>通过证明可以发现一个令人震惊的结论：<strong>最近邻分类器的错误率不超过贝叶斯最优分类器错误率的两倍</strong>。 </p>
<p>对于距离度量，<strong>不同的度量方法得到的k个近邻不尽相同，从而对最终的投票结果产生了影响</strong>，因此选择一个合适的距离度量方法也十分重要。</p>
<p>在上一篇聚类算法中，在度量样本相似性时介绍了常用的几种距离计算方法，包括<strong>闵可夫斯基距离，曼哈顿距离，VDM</strong>等。在实际应用中，<strong>kNN的距离度量函数一般根据样本的特性来选择合适的距离度量，同时应对数据进行去量纲/归一化处理来消除大量纲属性的强权政治影响</strong>。 </p>
<h4 id="低维嵌入"><a href="#低维嵌入" class="headerlink" title="低维嵌入"></a>低维嵌入</h4><p><strong>使用knn的前提是样本空间的密度要一定大，但是这个条件在现实中很难满足，因此引出降维操作</strong></p>
<blockquote>
<p>kNN的重要假设: 任意测试样本  附近任意小的  距离范围内总能找到一个训练样本，即训练样本的采样密度足够大，或称为 <strong>“密采样”( dense sample)</strong> 。然而，这个假设在现实任务中通常很难满足</p>
</blockquote>
<p>样本的<strong>特征数</strong>也称为<strong>维数</strong>（dimensionality），当维数非常大时，也就是通常所说的“<strong>维数灾难</strong>”(curse of dimensionality)，具体表现在：在高维情形下，<strong>数据样本变得十分稀疏</strong>，因为此时要满足训练样本为“<strong>密采样</strong>”的总体样本数目是一个触不可及的天文数字。<strong>训练样本的稀疏使得其代表总体分布的能力大大减弱，从而消减了学习器的泛化能力</strong>；同时当维数很高时，<strong>计算距离也变得十分复杂</strong>，甚至连计算内积都不再容易</p>
<p>缓解维数灾难的一个重要途径就是<strong>降维（dimension reduction），即通过某种数学变换将原始高维空间转变到一个低维的子空间</strong>。在这个子空间中，样本的密度将大幅提高，同时距离计算也变得容易。这</p>
<p>时也许会有疑问，降维之后不是会丢失原始数据的一部分信息吗？</p>
<p>实际上，在很多实际问题中，虽然训练数据是高维的，但是与学习任务相关也许仅仅是其中的一个低维子空间，也称为一个<strong>低维嵌入</strong>，例如：数据属性中存在噪声属性、相似属性或冗余属性等，<strong>对高维数据进行降维能在一定程度上达到提炼低维优质属性或降噪的效果</strong>。</p>
<h4 id="MDS算法"><a href="#MDS算法" class="headerlink" title="MDS算法"></a><strong>MDS算法</strong></h4><p>MDS（Multidimensional Scaling，多维尺度分析）是一种经典的<strong>降维技术</strong>，其核心目标是将高维数据映射到低维空间（如二维或三维），同时<strong>尽可能保留原始数据中样本点之间的距离关系</strong>。以下是其核心原理与应用要点：</p>
<p><strong>1. 核心思想</strong></p>
<ul>
<li><strong>输入</strong>：一个样本点之间的距离矩阵 $ D $（如欧氏距离、余弦距离等）。  </li>
<li><strong>输出</strong>：低维空间中样本点的坐标矩阵 $ Z $，使得低维空间中的距离与原始距离尽可能一致 。  </li>
<li><strong>关键假设</strong>：高维数据的内在结构可通过样本间的距离关系描述，降维后需最小化这种关系的失真。</li>
</ul>
<p><strong>2. 算法步骤</strong></p>
<p>MDS 的核心是通过<strong>矩阵分解</strong>从距离矩阵推导低维坐标：</p>
<ol>
<li><p><strong>构建距离矩阵 $ D $</strong>：<br>对于 $ r $ 个样本，计算两两之间的距离，形成 $ r \times r $ 的矩阵 $ D $，其中 $ D_{ij} $ 表示样本 $ i $ 和 $ j $ 的距离 。</p>
</li>
<li><p><strong>双中心化（Double Centering）</strong>：<br>构造矩阵 $ B = -\frac{1}{2} H D^{(2)} H $，其中 $ D^{(2)} $ 是距离的平方矩阵，$ H = I - \frac{1}{r} \mathbf{1} \mathbf{1}^\top $ 是中心化矩阵 。</p>
</li>
<li><p><strong>特征值分解</strong>：<br>对 $ B $ 进行特征值分解，得到 $ B = V \Lambda V^\top $，其中 $ \Lambda $ 是按降序排列的特征值对角矩阵，$ V $ 是对应的特征向量矩阵 。</p>
</li>
<li><p><strong>构造低维坐标</strong>：<br>选择前 $ d’ $ 个最大特征值（$ d’ $ 为目标维度）和对应的特征向量，计算低维坐标矩阵：  </p>
<script type="math/tex; mode=display">
Z = \Lambda^{1/2} V^\top</script><p>其中 $ \Lambda^{1/2} $ 是特征值矩阵的平方根 。</p>
</li>
</ol>
<p><strong>3. 关键特性</strong></p>
<ul>
<li><strong>保留距离关系</strong>：MDS 直接优化低维空间中的距离与原始距离的一致性，适用于需精确保留样本相似性的场景（如生物信息学中的基因关系分析）。  </li>
<li><strong>非线性适应性</strong>：与 PCA 不同，MDS 不要求数据线性分布，更适合处理非线性结构（如环形、流形数据）。  </li>
<li><strong>灵活性</strong>：支持任意距离度量（如自定义的相似性指标），而 PCA 仅适用于欧氏距离 。</li>
</ul>
<h4 id="线性降维方法"><a href="#线性降维方法" class="headerlink" title="线性降维方法"></a><strong>线性降维方法</strong></h4><p>线性降维通过<strong>线性变换</strong>将高维数据 $ \mathbf{X} \in \mathbb{R}^{d \times m} $ 投影到低维空间 $ \mathbf{Z} \in \mathbb{R}^{d’ \times m} $（$ d’ \leq d $），保留数据的主要信息。其数学表达为：</p>
<script type="math/tex; mode=display">
\mathbf{Z} = \mathbf{W}^\top \mathbf{X}</script><ul>
<li><strong>变换矩阵 $ \mathbf{W} \in \mathbb{R}^{d \times d’} $</strong>：<br>每一列是正交的基向量，构成低维子空间的坐标系。  </li>
<li><p><strong>目标</strong>：选择 $ \mathbf{W} $ 使得低维表示 $ \mathbf{Z} $ 最大化保留原始数据的信息（如方差、距离等）。</p>
</li>
<li><p><strong>MDS</strong>：<br>直接以<strong>保留高维空间中样本点之间的距离关系</strong>为目标。降维后的低维空间需尽可能保持原始样本两两之间的距离（如欧氏距离、自定义相似性距离）。  </p>
<ul>
<li><strong>示例</strong>：在基因数据分析中，MDS可确保基因表达相似的样本在低维空间中仍紧密分布。  </li>
</ul>
</li>
<li><p><strong>其他线性方法（如PCA、LDA）</strong>：  </p>
<ul>
<li><strong>PCA</strong>：最大化数据在低维空间的方差，强调保留全局结构而非具体距离。  </li>
<li><strong>LDA</strong>：在监督学习中最大化类间分离度，忽略类内距离。  </li>
</ul>
</li>
</ul>
<h4 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h4><p>不同于MDS采用距离保持的方法，主成分分析（Principal Component Analysis ,PCA）是一种经典的<strong>无监督降维算法</strong> ，其核心目标是通过线性变换将高维数据映射到低维空间，同时保留数据的<strong>最大方差信息</strong> （即信息损失最小）</p>
<p>直接通过一个<strong>线性变换</strong>，将原始空间中的样本<strong>投影</strong>到新的低维空间中。</p>
<p>简单来理解这一过程便是：<strong>PCA采用一组新的基（向量）来表示样本点，其中每一个基向量都是原始空间基向量的线性组合，通过使用尽可能少的新基向量来表出样本，从而达到降维的目的。</strong></p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607155733314.png" alt="image-20250607155733314"></p>
<p>假设使用d’个新基向量来表示原来样本，实质上是将样本投影到一个由d’个基向量确定的一个<strong>超平面</strong>上（<strong>即舍弃了一些维度</strong>），要用一个超平面对空间中所有高维样本进行恰当的表达，最理想的情形是：<strong>若这些样本点都能在超平面上表出且这些表出在超平面上都能够很好地分散开来</strong>。但是一般使用较原空间低一些维度的超平面来做到这两点十分不容易，因此我们退一步海阔天空，要求这个超平面应具有如下两个性质：</p>
<blockquote>
<p><strong>最近重构性</strong>：样本点到超平面的距离足够近，即尽可能在超平面附近；</p>
<p><strong>最大可分性</strong>：样本点在超平面上的投影尽可能地分散开来，即投影后的坐标具有区分性。</p>
</blockquote>
<p>这里十分神奇的是：<strong>最近重构性与最大可分性虽然从不同的出发点来定义优化问题中的目标函数，但最终这两种特性得到了完全相同的优化问题</strong>：</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607165159235.png" alt="image-20250607165159235"></p>
<h5 id="协方差矩阵与优化求解"><a href="#协方差矩阵与优化求解" class="headerlink" title="协方差矩阵与优化求解"></a><strong>协方差矩阵与优化求解</strong></h5><p>若数据已<strong>中心化</strong>（均值为零），则 $ \mathbf{X} \mathbf{X}^\top $ 是<strong>样本协方差矩阵</strong>的 $ m $ 倍。此时，PCA的优化问题转化为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
& \underset{\mathbf{W}}{\text{maximize}}
& & \text{tr}\left( \mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W} \right) \\
& \text{subject to}
& & \mathbf{W}^\top \mathbf{W} = \mathbf{I}
\end{aligned}</script><p>通过拉格朗日乘数法，该问题的解为 $ \mathbf{X} \mathbf{X}^\top $ 的前 $ d’ $ 个最大特征值对应的特征向量</p>
<h5 id="PCA的数学推导"><a href="#PCA的数学推导" class="headerlink" title="PCA的数学推导"></a><strong>PCA的数学推导</strong></h5><ul>
<li><p><strong>优化目标</strong>：  </p>
<script type="math/tex; mode=display">
\max_{\mathbf{W}} \quad \text{tr}\left( \mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W} \right) \quad \text{s.t.} \quad \mathbf{W}^\top \mathbf{W} = \mathbf{I}</script><p>其中，$ \mathbf{X} \in \mathbb{R}^{d \times m} $ 是中心化后的数据矩阵（均值为零）。</p>
</li>
<li><p><strong>拉格朗日乘数法</strong>：<br>引入拉格朗日乘子 $ \Lambda $，构造拉格朗日函数：</p>
<script type="math/tex; mode=display">
\mathcal{L}(\mathbf{W}, \Lambda) = \text{tr}\left( \mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W} \right) - \text{tr}\left( \Lambda (\mathbf{W}^\top \mathbf{W} - \mathbf{I}) \right)</script><p>对 $ \mathbf{W} $ 求导并令导数为零，得到：</p>
<script type="math/tex; mode=display">
\mathbf{X} \mathbf{X}^\top \mathbf{W} = \Lambda \mathbf{W}</script><p>即 $ \mathbf{X} \mathbf{X}^\top $ 的特征向量 $ \mathbf{w}_i $ 满足：</p>
<script type="math/tex; mode=display">
\mathbf{X} \mathbf{X}^\top \mathbf{w}_i = \lambda_i \mathbf{w}_i</script></li>
</ul>
<h5 id="PCA特征向量选择"><a href="#PCA特征向量选择" class="headerlink" title="PCA特征向量选择"></a>PCA特征向量选择</h5><p><strong>1. 核心问题</strong></p>
<p>在PCA中，我们希望找到一个 $ d’ \times d $ 的变换矩阵 $ \mathbf{W} $，其列向量是协方差矩阵 $ \mathbf{X} \mathbf{X}^\top $ 的特征向量，且满足正交约束 $ \mathbf{W}^\top \mathbf{W} = \mathbf{I} $。关键问题是：<strong>如何从 $ d $ 个特征向量中选择 $ d’ $ 个最优的？</strong></p>
<p><strong>2. 数学推导</strong></p>
<ol>
<li><p><strong>特征值分解</strong>：<br>协方差矩阵 $ \mathbf{X} \mathbf{X}^\top \in \mathbb{R}^{d \times d} $ 可分解为：</p>
<script type="math/tex; mode=display">
\mathbf{X} \mathbf{X}^\top \mathbf{W} = \mathbf{W} \boldsymbol{\Lambda}</script><p>其中，$ \boldsymbol{\Lambda} = \text{diag}(\lambda_1, \lambda_2, \dots, \lambda_d) $ 是特征值对角矩阵，$ \mathbf{W} $ 是特征向量矩阵。</p>
</li>
<li><p><strong>优化目标转化</strong>：<br>PCA的目标是最大化 $ \text{tr}(\mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W}) $。利用特征值分解，可得：</p>
<script type="math/tex; mode=display">
\mathbf{W}^\top \mathbf{X} \mathbf{X}^\top \mathbf{W} = \mathbf{W}^\top (\mathbf{W} \boldsymbol{\Lambda}) = \boldsymbol{\Lambda}</script><p>因此，优化目标变为：</p>
<script type="math/tex; mode=display">
\max_{\mathbf{W}} \quad \text{tr}(\boldsymbol{\Lambda}) = \sum_{i=1}^{d'} \lambda_i</script><p>即选择 $ d’ $ 个最大的特征值 $ \lambda_i $ 对应的特征向量组成 $ \mathbf{W} $。</p>
</li>
</ol>
<p><strong>3. 特征向量选择策略</strong></p>
<ul>
<li><strong>按特征值排序</strong>：<br>特征值 $ \lambda_i $ 表示数据沿特征向量 $ \mathbf{w}_i $ 方向的方差。选择前 $ d’ $ 个最大特征值对应的特征向量，可保留最多信息。  </li>
<li><strong>正交性保证</strong>：<br>特征向量矩阵 $ \mathbf{W} $ 的列自动满足 $ \mathbf{W}^\top \mathbf{W} = \mathbf{I} $，无需额外正交化。</li>
</ul>
<h5 id="PCA算法的整个流程如下图所示："><a href="#PCA算法的整个流程如下图所示：" class="headerlink" title="PCA算法的整个流程如下图所示："></a>PCA算法的整个流程如下图所示：</h5><p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607170020467.png" alt="image-20250607170020467"></p>
<h4 id="核化线性降维"><a href="#核化线性降维" class="headerlink" title="核化线性降维"></a><strong>核化线性降维</strong></h4><p>待学习</p>
<h4 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h4><p><strong>流形学习（manifold learning）</strong>是一种借助拓扑流形概念的降维方法，流形是指在<strong>局部与欧式空间同胚的空间</strong>，即在局部与欧式空间具有相同的性质，能用欧氏距离计算样本之间的距离。这样即使高维空间的分布十分复杂，但是在局部上依然满足欧式空间的性质，基于流形学习的降维正是这种 <strong>“邻域保持”</strong> 的思想。其中 <strong>等度量映射（Isomap）试图在降维前后保持邻域内样本之间的距离，而局部线性嵌入（LLE）则是保持邻域内样本之间的线性关系</strong> 。</p>
<h5 id="等度量映射Isomap"><a href="#等度量映射Isomap" class="headerlink" title="等度量映射Isomap"></a>等度量映射Isomap</h5><p>等度量映射的基本出发点是：高维空间中的直线距离具有误导性，因为有时高维空间中的直线距离在低维空间中是不可达的。<strong>因此利用流形在局部上与欧式空间同胚的性质，可以使用近邻距离来逼近测地线距离</strong>，即对于一个样本点，它与近邻内的样本点之间是可达的，且距离使用欧式距离计算，这样整个样本空间就形成了一张近邻图，高维空间中两个样本之间的距离就转为最短路径问题。可采用著名的<strong>Dijkstra算法</strong>或<strong>Floyd算法</strong>计算最短距离，得到高维空间中任意两点之间的距离后便可以使用 MDS 算法来其计算低维空间中的坐标。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171119645.png" alt="image-20250607171119645"></p>
<p>Isomap算法流程如下图：</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607171258284.png" alt="image-20250607171258284"></p>
<p>对于近邻图的构建，常用的有两种方法：<strong>一种是指定近邻点个数</strong>，像kNN一样选取k个最近的邻居；<strong>另一种是指定邻域半径</strong>，距离小于该阈值的被认为是它的近邻点。但两种方法均会出现下面的问题：</p>
<blockquote>
<p>若<strong>邻域范围指定过大，则会造成“短路问题”</strong>，即本身距离很远却成了近邻，将距离近的那些样本扼杀在摇篮。</p>
<p>若<strong>邻域范围指定过小，则会造成“断路问题”</strong>，即有些样本点无法可达了，整个世界村被划分为互不可达的小部落。</p>
</blockquote>
<h5 id="局部线性嵌入"><a href="#局部线性嵌入" class="headerlink" title="局部线性嵌入"></a>局部线性嵌入</h5><p>待学习</p>
<h4 id="度量学习"><a href="#度量学习" class="headerlink" title="度量学习"></a>度量学习</h4><p><strong>1. 核心思想</strong></p>
<p>度量学习（Metric Learning）的核心目标是<strong>学习一个合理的距离度量</strong>，使得相似样本距离更近，不相似样本距离更远。传统欧式距离（Euclidean Distance）虽然简单，但其固定权重无法反映不同特征的实际重要性。因此，我们引入<strong>加权欧式距离</strong>，通过可调节的参数（权重）优化距离计算。</p>
<p><strong>2. 欧式距离与加权欧式距离</strong></p>
<ul>
<li><p><strong>标准欧式距离</strong>：  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{ed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) = \|\boldsymbol{x}_i - \boldsymbol{x}_j\|_2^2 = \sum_{k=1}^d (\boldsymbol{x}_{i,k} - \boldsymbol{x}_{j,k})^2</script><p>每个特征维度对距离的贡献相同，未考虑特征的重要性差异。</p>
</li>
<li><p><strong>加权欧式距离</strong>：  </p>
<script type="math/tex; mode=display">
\text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) = (\boldsymbol{x}_i - \boldsymbol{x}_j)^\top \mathbf{W} (\boldsymbol{x}_i - \boldsymbol{x}_j)</script><p>其中，$ \mathbf{W} = \text{diag}(\boldsymbol{w}) $ 是对角权重矩阵，$ w_k \geq 0 $ 表示第 $ k $ 个特征的权重。<br>展开后为：</p>
<script type="math/tex; mode=display">
\text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) = \sum_{k=1}^d w_k (\boldsymbol{x}_{i,k} - \boldsymbol{x}_{j,k})^2</script></li>
</ul>
<p><strong>3. 权重的作用</strong></p>
<ul>
<li><strong>特征重要性调节</strong>：  <ul>
<li>高权重 $ w_k $：强调第 $ k $ 维特征对距离的影响（如图像的颜色通道比位置更重要）。  </li>
<li>低权重 $ w_k $：弱化噪声或冗余特征的影响。  </li>
</ul>
</li>
<li><strong>几何意义</strong>：<br>加权欧式距离相当于在各特征维度上进行缩放，将数据映射到一个新的空间，使得关键特征的差异更显著。</li>
</ul>
<p><strong>4. 度量学习的目标</strong></p>
<p>通过学习最优权重 $ \boldsymbol{w} $，使以下目标成立：</p>
<ul>
<li><strong>相似样本</strong>：加权距离小（$ \text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) \to 0 $）。  </li>
<li><strong>不相似样本</strong>：加权距离大（$ \text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) \to \infty $）。  </li>
</ul>
<p>典型优化问题形式：</p>
<script type="math/tex; mode=display">
\min_{\boldsymbol{w}} \quad \sum_{(\boldsymbol{x}_i, \boldsymbol{x}_j) \in S} \text{dist}_{\text{wed}}^2(\boldsymbol{x}_i, \boldsymbol{x}_j) + \lambda \|\boldsymbol{w}\|_2^2</script><p>其中，$ S $ 是相似样本对集合，$ \lambda $ 是正则化项防止过拟合。</p>
<blockquote>
<p>总结来说，</p>
<ul>
<li><strong>降维是将原高维空间嵌入到一个合适的低维子空间中，接着在低维空间中进行学习任务</strong></li>
<li><strong>度量学习则是试图去学习出一个 *距离度量* 来等效降维的效果</strong></li>
</ul>
</blockquote>
<h5 id="LMNN（Large-Margin-Nearest-Neighbors）详解"><a href="#LMNN（Large-Margin-Nearest-Neighbors）详解" class="headerlink" title="LMNN（Large Margin Nearest Neighbors）详解"></a><strong>LMNN（Large Margin Nearest Neighbors）详解</strong></h5><p><strong>1. 核心思想</strong></p>
<p>LMNN 是一种<strong>监督度量学习方法</strong>，其目标是通过学习一个线性变换矩阵 $ \mathbf{M} $，使<strong>同类样本在变换后的空间中更紧密</strong>，<strong>不同类样本被推开</strong>，从而提升KNN等基于距离的算法性能。其核心是引入<strong>最大边距（Large Margin）</strong>的概念，类似于SVM的分类边界。</p>
<p><strong>2. 损失函数</strong></p>
<p>LMNN 的优化目标由两部分组成：</p>
<ul>
<li><p><strong>Pull Loss（拉力损失）</strong>：<br>使同类样本对的距离尽可能小，公式为：</p>
<script type="math/tex; mode=display">
\varepsilon_{\text{pull}}(\mathbf{L}) = \sum_{j \sim i} \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2</script><p>其中，$ j \sim i $ 表示与样本 $ i $ 同类的最近邻样本。</p>
</li>
<li><p><strong>Push Loss（推力损失）</strong>：<br>使不同类样本对的距离至少保持一个固定边距 $ \xi_{ijl} $，公式为：</p>
<script type="math/tex; mode=display">
\varepsilon_{\text{push}}(\mathbf{L}) = \sum_{i,j,l} (1 - y_{il}) \left[1 + \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2 - \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_l)\|^2\right]_+</script><p>其中，$ y<em>{il} = 1 $ 表示样本 $ i $ 和 $ l $ 属于同一类，否则为0；$ [\cdot]</em>+ $ 表示取正值部分。</p>
</li>
<li><p><strong>总损失函数</strong>：  </p>
<script type="math/tex; mode=display">
\varepsilon(\mathbf{L}) = (1 - \mu) \varepsilon_{\text{pull}}(\mathbf{L}) + \mu \varepsilon_{\text{push}}(\mathbf{L})</script><p>参数 $ \mu \in [0, 1] $ 控制两类损失的权重。</p>
</li>
</ul>
<p><strong>3. 优化问题</strong></p>
<p>LMNN 的目标是最小化总损失函数，同时满足以下约束：</p>
<script type="math/tex; mode=display">
\begin{aligned}
& \min_{\mathbf{M}, \boldsymbol{\xi}} \quad (1 - \mu) \sum_{i,j \sim i} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j) + \mu \sum_{i,j \sim i,l} (1 - y_{il}) \xi_{ijl} \\
& \text{s.t.} \quad (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_l)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_l) - (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)^\top \mathbf{M} (\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j) \geq 1 - \xi_{ijl}, \\
& \quad \quad \quad \xi_{ijl} \geq 0, \quad \mathbf{M} \succeq 0.
\end{aligned}</script><ul>
<li><strong>约束（1）</strong>：确保不同类样本对的距离比同类样本对大至少 $ 1 - \xi_{ijl} $。  </li>
<li><strong>约束（2）</strong>：松弛变量 $ \xi_{ijl} \geq 0 $ 允许部分样本对违反约束。  </li>
<li><strong>约束（3）</strong>：$ \mathbf{M} $ 必须是半正定矩阵，保证距离的非负性和三角不等式。</li>
</ul>
<h4 id="作业-3"><a href="#作业-3" class="headerlink" title="作业"></a>作业</h4><h5 id="1-3"><a href="#1-3" class="headerlink" title="1"></a>1</h5><p>数据降维有哪些常用的方法？阐述主成分分析（PCA）算法的计算流程，并讨论PCA 降维之后的维度如何确定？</p>
<p><strong>（1）常用数据降维方法</strong></p>
<ol>
<li><strong>主成分分析（PCA）</strong>：通过线性变换保留最大方差方向，适用于去噪和压缩数据 。  </li>
<li><strong>线性判别分析（LDA）</strong>：在监督学习中最大化类间分离度，适用于分类任务 。  </li>
</ol>
<p><strong>（2）主成分分析（PCA）的计算流程</strong></p>
<ol>
<li><strong>数据标准化</strong>：对原始数据去均值、方差归一化，消除量纲影响 。  </li>
<li><strong>计算协方差矩阵</strong>：  <script type="math/tex; mode=display">
\mathbf{\Sigma} = \frac{1}{m} \mathbf{X} \mathbf{X}^\top</script>其中 $ \mathbf{X} $ 是中心化后的数据矩阵 。  </li>
<li><strong>特征值分解</strong>：对协方差矩阵进行特征值分解，得到特征值 $ \lambda_i $ 和单位正交特征向量 $ \mathbf{w}_i $ 。  </li>
<li><strong>选择主成分</strong>：按特征值大小排序，选择前 $ d’ $ 个最大特征值对应的特征向量构成变换矩阵 $ \mathbf{W} = [\mathbf{w}<em>1, \mathbf{w}_2, \dots, \mathbf{w}</em>{d’}] $。  </li>
<li><strong>降维投影</strong>：计算低维表示 $ \mathbf{Z} = \mathbf{W}^\top \mathbf{X} $，其中 $ \mathbf{Z} \in \mathbb{R}^{d’ \times m} $ 。</li>
</ol>
<p><strong>（3）PCA降维后维度的确定</strong></p>
<ul>
<li><strong>累积方差贡献率</strong>：选择前 $ d’ $ 个主成分，使累计方差占比达到阈值（如95%）。  </li>
<li><strong>肘部法则（Elbow Method）</strong>：绘制特征值随维度变化的曲线，选择“拐点”作为 $ d’ $。  </li>
</ul>
<h5 id="2-3"><a href="#2-3" class="headerlink" title="2"></a>2</h5><p>度量学习的目标是什么？LMNN算法中三元组损失是什么？如何计算？</p>
<p><strong>（1）度量学习的目标</strong></p>
<p>度量学习旨在学习一个合理的距离度量，使得：</p>
<ul>
<li><strong>相似样本</strong>：距离尽可能小（如同类样本）。  </li>
<li><strong>不相似样本</strong>：距离尽可能大（如异类样本）。<br>典型应用包括推荐系统（优化用户-商品相似性）、图像检索（提升匹配精度）和生物识别（增强类间可分性）。</li>
</ul>
<p><strong>（2）LMNN中的三元组损失</strong></p>
<p>LMNN（Large Margin Nearest Neighbor）是一种监督度量学习方法，其核心思想是通过优化距离度量来提升KNN的分类性能。虽然LMNN本身主要使用对比损失（Contrastive Loss），但三元组损失（Triplet Loss）是深度度量学习中常见的损失函数，其计算方式如下：<strong>三元组损失的定义</strong></p>
<p>三元组损失基于锚点（Anchor）、正例（Positive）和负例（Negative）三个样本，目标是使锚点与正例的距离小于锚点与负例的距离，公式为：</p>
<script type="math/tex; mode=display">
\mathcal{L} = \sum_{i,j,l} \max\left(0, \|\mathbf{z}_i - \mathbf{z}_j\|^2 - \|\mathbf{z}_i - \mathbf{z}_l\|^2 + m\right)</script><ul>
<li>$ \mathbf{z}_i $：锚点样本的嵌入表示。  </li>
<li>$ \mathbf{z}_j $：与锚点同类的正例样本。  </li>
<li>$ \mathbf{z}_l $：与锚点不同类的负例样本。  </li>
<li>$ m $：预设的边界值（Margin），控制正负样本距离的最小差距 。</li>
</ul>
<p><strong>LMNN的损失函数</strong></p>
<p>LMNN 的损失函数包含两部分：</p>
<ol>
<li><strong>拉力损失（Pull Loss）</strong>：最小化同类样本对的距离：  <script type="math/tex; mode=display">
\varepsilon_{\text{pull}} = \sum_{i,j \sim i} \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2</script></li>
<li><strong>推力损失（Push Loss）</strong>：最大化异类样本对的距离：  <script type="math/tex; mode=display">
\varepsilon_{\text{push}} = \sum_{i,j \sim i,l} (1 - y_{il}) \left[1 + \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_j)\|^2 - \|\mathbf{L}(\bar{\boldsymbol{x}}_i - \bar{\boldsymbol{x}}_l)\|^2\right]_+</script>其中 $ \mathbf{L} $ 是线性变换矩阵，$ y<em>{il} $ 表示样本对是否同类，$ [\cdot]</em>+ $ 表示取正值部分 。</li>
</ol>
<p><strong>优化目标</strong></p>
<p>LMNN 的总损失为拉力和推力损失的加权和：</p>
<script type="math/tex; mode=display">
\varepsilon(\mathbf{L}) = (1 - \mu) \varepsilon_{\text{pull}} + \mu \varepsilon_{\text{push}}</script><p>参数 $ \mu \in [0, 1] $ 平衡两类损失的权重，最终通过优化 $ \mathbf{L} $ 得到最优距离度量 。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607175825520.png" alt="image-20250607175825520"></p>
<h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>监督学习解决现实问题有哪些难点?<br>1.标记数据获取成本高：在许多领域如医疗，获取标记数据是昂贵且耗时的。<br>2.未标记数据大量存在且易得：相对而言，未标记数据大量存在且容易获取。<br>3.提升模型的泛化能力：通过利用未标记数据，可以增强模型的泛化能力。<br>举例：在医疗领域，获取医生标记的诊断数据非常昂贵，但有大量未标记的病人记录。<br>半监督学习可以帮助利用这些未标记数据，提高疾病预测模型的准确性。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607181345721.png" alt="image-20250607181345721">半监督学习结合了有监督学习和无监督学习，半监督学习使用<strong>少量的标记数据</strong>和<strong>大量的未标记数据</strong>来训练模型，主要目标是提升模型在未标记数据上的表现。</p>
<h5 id="基于生成模型的方法"><a href="#基于生成模型的方法" class="headerlink" title="基于生成模型的方法"></a>基于生成模型的方法</h5><p>假设所有数据（无论是否有标记）都是由一个<strong>潜在的模型</strong>“生成”的。那么无标记的数据可以帮助更准确的估计潜在模型的参数。<br>比如右图中可以看到数据可以由两个高斯分布近似，则无监督的数据可以被用来更好得做高斯分布的参数估计</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183201926.png" alt="image-20250607183201926"></p>
<h5 id="半监督SVM"><a href="#半监督SVM" class="headerlink" title="半监督SVM"></a><strong>半监督SVM</strong></h5><p>监督学习中的SVM试图找到一个划分超平面，使得两侧支持向量之间的间隔最大，即 <strong>最大划分间隔</strong> 思想。对于半监督SVM (Semi-Supervised Support Vector Machine, S3VM) 则考虑超平面在能将两类标记样本分隔的同时，<strong>穿过数据低密度的区域</strong>。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607183349866.png" alt="image-20250607183349866"></p>
<h6 id="TSVM-Transductive-Support-Vector-Machine"><a href="#TSVM-Transductive-Support-Vector-Machine" class="headerlink" title="TSVM(Transductive Support Vector Machine)"></a>TSVM(Transductive Support Vector Machine)</h6><p><strong>1. 核心思想</strong></p>
<p>TSVM 是一种<strong>半监督学习方法</strong>，通过结合有标记数据 $ D_l $ 和未标记数据 $ D_u $，利用伪标签（Pseudo-labels）和迭代优化策略，最大化分类超平面的间隔。其损失函数需同时考虑：</p>
<ul>
<li><strong>有标记样本</strong>：最小化分类错误（Hinge Loss）。  </li>
<li><strong>未标记样本</strong>：通过伪标签引入约束，逐步调整超平面。</li>
</ul>
<p><strong>2. 损失函数推导</strong></p>
<p>TSVM 的目标是找到一个超平面 $ \boldsymbol{w}^\top \boldsymbol{x} + b = 0 $，使得：</p>
<ol>
<li><strong>有标记样本</strong>的分类误差最小。  </li>
<li><strong>未标记样本</strong>的伪标签与超平面预测结果一致。  </li>
</ol>
<p><strong>标准SVM的损失函数</strong>为：</p>
<script type="math/tex; mode=display">
\min_{\boldsymbol{w}, b, \xi} \quad \frac{1}{2} \|\boldsymbol{w}\|^2 + C \sum_{i=1}^l \xi_i</script><p>其中，$ \xi_i $ 是松弛变量，表示样本 $ (\boldsymbol{x}_i, y_i) $ 的分类误差。</p>
<p><strong>TSVM的扩展</strong>：<br>引入未标记样本 $ D_u $ 的伪标签 $ \hat{y}_j $（$ j = l+1, \dots, l+u $），并赋予其较小的惩罚系数 $ C_u $（初始阶段 $ C_u \ll C_l $）：</p>
<script type="math/tex; mode=display">
\min_{\boldsymbol{w}, b, \xi} \quad \frac{1}{2} \|\boldsymbol{w}\|^2 + C_l \sum_{i=1}^l \xi_i + C_u \sum_{j=l+1}^{l+u} \xi_j</script><p>其中：</p>
<ul>
<li>$ C_l $：有标记样本的惩罚系数。  </li>
<li>$ C_u $：未标记样本的惩罚系数，初始值很小，逐步增大以增强伪标签的影响。</li>
</ul>
<p><strong>3. 迭代优化流程</strong></p>
<ol>
<li><p><strong>初始化</strong>：  </p>
<ul>
<li>用有标记数据 $ D_l $ 训练初始 SVM，得到 $ \boldsymbol{w}_0, b_0 $。  </li>
<li>对未标记数据 $ D_u $ 预测伪标签 $ \hat{y}_j = \text{sign}(\boldsymbol{w}_0^\top \boldsymbol{x}_j + b_0) $。  </li>
</ul>
</li>
<li><p><strong>伪标签调整</strong>：  </p>
<ul>
<li>若存在冲突（如 $ \hat{y}_i \hat{y}_j &lt; 0 $ 且 $ \xi_i + \xi_j &gt; 2 $），翻转其中一个伪标签（如 $ \hat{y}_i \leftarrow -\hat{y}_i $）。  </li>
<li>重新求解优化问题，更新 $ \boldsymbol{w}, b $。  </li>
</ul>
</li>
<li><p><strong>参数调整</strong>：  </p>
<ul>
<li>逐步增大 $ C_u $（如 $ C_u \leftarrow \min{2C_u, C_l} $），增强未标记样本的影响。  </li>
</ul>
</li>
</ol>
<p><strong>4. 关键数学细节</strong></p>
<ul>
<li><p><strong>Hinge Loss</strong>：<br>对每个样本 $ (\boldsymbol{x}_i, y_i) $，损失为：</p>
<script type="math/tex; mode=display">
\xi_i = \max\left(0, 1 - y_i (\boldsymbol{w}^\top \boldsymbol{x}_i + b)\right)</script><p>未标记样本的伪标签 $ \hat{y}_j $ 同样代入此公式，但惩罚系数为 $ C_u $。  </p>
</li>
<li><p><strong>正则化项</strong>：<br>$ \frac{1}{2} |\boldsymbol{w}|^2 $ 确保超平面的泛化能力，防止过拟合。  </p>
</li>
<li><p><strong>伪标签翻转条件</strong>：<br>当两个未标记样本 $ i, j $ 满足：</p>
<script type="math/tex; mode=display">
\hat{y}_i \hat{y}_j < 0 \quad \text{且} \quad \xi_i > 0, \xi_j > 0, \quad \xi_i + \xi_j > 2</script><p>表示它们被错误分类且距离超平面较近，需翻转其中一个标签以减少冲突。</p>
</li>
</ul>
<h5 id="图半监督学习"><a href="#图半监督学习" class="headerlink" title="图半监督学习"></a><strong>图半监督学习</strong></h5><p>给定一个数据集，我们可将其映射为一个图，数据集中每个样本对应于图结点，若两个样本之间的相似度很高(或相关性很强)，则对应的结点之间存在一条边，边的“强度”(strength) 正比于样本之间的相似度(或相关性)。</p>
<p>可将有标记样本所对应的结点想象为染过色，标记样本所对应的结点尚未染色。半监督学习就对应于“颜色”在图上扩散或传播的过程。由于个图对应了一个矩阵，我们就能基于矩阵运算来进行半监督学习算法的推导与分析。</p>
<p><img src="/2025/06/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%EF%BC%88%E4%B8%8B%EF%BC%89/image-20250607184534217.png" alt="image-20250607184534217"></p>
<p><strong>图半监督学习中的能量函数推导详解</strong></p>
<p><strong>1. 图结构与亲和矩阵</strong></p>
<p>给定有标记数据集 $ D<em>l = {(\boldsymbol{x}_1, y_1), (\boldsymbol{x}_2, y_2), \dots, (\boldsymbol{x}_l, y_l)} $ 和未标记数据集 $ D_u = {\boldsymbol{x}</em>{l+1}, \boldsymbol{x}<em>{l+2}, \dots, \boldsymbol{x}</em>{l+u}} $，构建图 $ G = (V, E) $：</p>
<ul>
<li><strong>结点集</strong>：$ V = {\boldsymbol{x}<em>1, \dots, \boldsymbol{x}_l, \boldsymbol{x}</em>{l+1}, \dots, \boldsymbol{x}_{l+u}} $，包含所有样本。  </li>
<li><strong>边集</strong>：通过亲和矩阵 $ \mathbf{W} $ 表示，元素定义为：<script type="math/tex; mode=display">
(\mathbf{W})_{ij} = 
\begin{cases}
\exp\left(-\frac{\|\boldsymbol{x}_i - \boldsymbol{x}_j\|^2}{2\sigma^2}\right), & i \neq j \\
0, & \text{otherwise}
\end{cases}</script>其中，$ \sigma $ 是高斯核的带宽参数，控制邻接关系的敏感性。</li>
</ul>
<p><strong>2. 能量函数的定义与推导</strong></p>
<p>假设分类模型的输出标记为 $ f(\boldsymbol{x}_i) $（取值为类别标签，如 $ \pm 1 $），定义能量函数 $ E(f) $ 为：</p>
<script type="math/tex; mode=display">
E(f) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} (f(\boldsymbol{x}_i) - f(\boldsymbol{x}_j))^2</script><p>其中 $ m = l + u $ 是总样本数。</p>
<p><strong>3. 能量函数的展开与简化</strong></p>
<ol>
<li><strong>展开平方项</strong><script type="math/tex; mode=display">
E(f) = \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} \left[ f^2(\boldsymbol{x}_i) - 2 f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) + f^2(\boldsymbol{x}_j) \right]</script></li>
<li><strong>利用对称性简化</strong><br>由于 $ \mathbf{W} $ 是对称矩阵（$(\mathbf{W})<em>{ij} = (\mathbf{W})</em>{ji}$），可交换求和顺序：<script type="math/tex; mode=display">
\sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_j) = \sum_{j=1}^m \sum_{i=1}^m (\mathbf{W})_{ji} f^2(\boldsymbol{x}_j) = \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_i)</script>因此，能量函数变为<script type="math/tex; mode=display">
E(f) = \frac{1}{2} \left( 2 \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f^2(\boldsymbol{x}_i) - 2 \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) \right)</script></li>
<li><strong>引入度矩阵</strong><br>定义度矩阵 $ \mathbf{D} $ 为对角矩阵，其对角线元素为：<script type="math/tex; mode=display">
d_i = \sum_{j=1}^m (\mathbf{W})_{ij}</script>最终能量函数可表示为：<script type="math/tex; mode=display">
E(f) = \sum_{i=1}^m d_i f^2(\boldsymbol{x}_i) - \sum_{i=1}^m \sum_{j=1}^m (\mathbf{W})_{ij} f(\boldsymbol{x}_i) f(\boldsymbol{x}_j) = \boldsymbol{f}^\top (\mathbf{D} - \mathbf{W}) \boldsymbol{f}</script>其中，$ \boldsymbol{f} = [f(\boldsymbol{x}_1), f(\boldsymbol{x}_2), \dots, f(\boldsymbol{x}_m)]^\top $。</li>
</ol>
<p><strong>图半监督学习方法推导详解</strong></p>
<p><strong>1. 分块矩阵表示</strong></p>
<p>将亲和矩阵 $ \mathbf{W} $ 和度矩阵 $ \mathbf{D} $ 按有标记数据（前 $ l $ 行列）和未标记数据（后 $ u $ 行列）分块：</p>
<script type="math/tex; mode=display">
\mathbf{W} = 
\begin{bmatrix}
\mathbf{W}_{ll} & \mathbf{W}_{lu} \\
\mathbf{W}_{ul} & \mathbf{W}_{uu}
\end{bmatrix}, \quad
\mathbf{D} = 
\begin{bmatrix}
\mathbf{D}_{ll} & \mathbf{0}_{lu} \\
\mathbf{0}_{ul} & \mathbf{D}_{uu}
\end{bmatrix}</script><p>其中：</p>
<ul>
<li>$ \mathbf{W}_{ll} $：有标记数据间的亲和度。  </li>
<li>$ \mathbf{W}_{lu} $：有标记与未标记数据间的亲和度。  </li>
<li>$ \mathbf{W}_{uu} $：未标记数据间的亲和度。  </li>
<li>$ \mathbf{D}<em>{ll}, \mathbf{D}</em>{uu} $：对应子图的度矩阵。</li>
</ul>
<p><strong>2. 能量函数的分块展开</strong></p>
<p>能量函数 $ E(f) = \boldsymbol{f}^\top (\mathbf{D} - \mathbf{W}) \boldsymbol{f} $ 可展开为</p>
<p>展开后得到：</p>
<script type="math/tex; mode=display">
E(f) = \boldsymbol{f}_l^\top (\mathbf{D}_{ll} - \mathbf{W}_{ll}) \boldsymbol{f}_l - 2 \boldsymbol{f}_u^\top \mathbf{W}_{ul} \boldsymbol{f}_l + \boldsymbol{f}_u^\top (\mathbf{D}_{uu} - \mathbf{W}_{uu}) \boldsymbol{f}_u</script><p><strong>3. 对未标记数据 $ \boldsymbol{f}_u $ 求偏微分</strong></p>
<p>目标是最小化 $ E(f) $，对 $ \boldsymbol{f}_u $ 求偏导并令其为零：</p>
<script type="math/tex; mode=display">
\frac{\partial E(f)}{\partial \boldsymbol{f}_u} = -2 \mathbf{W}_{ul} \boldsymbol{f}_l + 2 (\mathbf{D}_{uu} - \mathbf{W}_{uu}) \boldsymbol{f}_u = 0</script><p>解得：</p>
<script type="math/tex; mode=display">
\boldsymbol{f}_u = (\mathbf{D}_{uu} - \mathbf{W}_{uu})^{-1} \mathbf{W}_{ul} \boldsymbol{f}_l</script><h4 id="协同训练"><a href="#协同训练" class="headerlink" title="协同训练"></a>协同训练</h4><p>协同训练（Co-training）是一种经典的<strong>半监督学习方法</strong>，由Blum和Mitchell于1998年首次提出，主要用于处理<strong>多视图数据</strong>（Multi-view Data）。其核心思想是通过多个分类器的协作，利用少量标记数据和大量未标记数据提升模型性能。以下是详细解析：</p>
<p><strong>1. 核心思想与假设</strong></p>
<p><strong>（1）多视图数据</strong></p>
<ul>
<li><strong>定义</strong>：每个样本可被划分为多个<strong>充分冗余且条件独立</strong>的视图（View）。  <ul>
<li><strong>充分冗余</strong>：每个视图本身包含足够信息，可独立完成学习任务。  </li>
<li><strong>条件独立性</strong>：在给定类别标签的条件下，不同视图的特征相互独立。<br>例如，网页数据可划分为“文本内容”和“超链接结构”两个视图，它们共同描述网页内容。</li>
</ul>
</li>
</ul>
<p><strong>（2）协作机制</strong></p>
<ul>
<li><strong>双分类器设计</strong>：使用两个分类器 $ h_1 $ 和 $ h_2 $，分别基于视图 $ V_1 $ 和 $ V_2 $ 进行训练。  </li>
<li><strong>伪标签生成</strong>：分类器 $ h_1 $ 对未标记数据的高置信度预测结果会被 $ h_2 $ 使用，反之亦然，形成迭代优化。  </li>
<li><strong>目标</strong>：通过分类器间的互补性，逐步扩展标记数据集，提升模型泛化能力。</li>
</ul>
<p><strong>2. 算法流程</strong></p>
<ol>
<li><strong>初始化阶段</strong>：  <ul>
<li>使用少量标记数据 $ D_l $，分别训练分类器 $ h_1 $（基于视图 $ V_1 $）和 $ h_2 $（基于视图 $ V_2 $）。  </li>
</ul>
</li>
<li><strong>伪标签生成</strong>：  <ul>
<li>对未标记数据 $ D_u $，$ h_1 $ 预测视图 $ V_1 $ 的伪标签，$ h_2 $ 预测视图 $ V_2 $ 的伪标签。  </li>
<li>选择置信度高于阈值的样本加入训练集（如 $ h_1 $ 的预测结果用于更新 $ h_2 $ 的训练数据，反之亦然）。  </li>
</ul>
</li>
<li><strong>迭代优化</strong>：  <ul>
<li>重复伪标签生成和模型训练，直到未标记数据耗尽或模型收敛。</li>
</ul>
</li>
</ol>
<p><strong>3. 核心优势</strong></p>
<ul>
<li><strong>减少对标注数据的依赖</strong>：仅需少量标记数据即可训练高性能模型，尤其适合标注成本高的场景（如医疗影像分析）。  </li>
<li><strong>提升模型鲁棒性</strong>：分类器间的协作可纠正彼此的错误，降低单一模型过拟合风险。  </li>
<li><strong>多视图互补性</strong>：不同视图的信息融合能捕捉更全面的特征（如图像的RGB通道与纹理特征）。</li>
</ul>
<h4 id="作业-4"><a href="#作业-4" class="headerlink" title="作业"></a>作业</h4><h5 id="1-4"><a href="#1-4" class="headerlink" title="1"></a>1</h5><p>什么是半监督学习？请简要描述其基本思想。半监督学习相比于监督学习和无监督学习有什么优势和应用场景？</p>
<p><strong>（1）定义与基本思想</strong>  </p>
<p>半监督学习（Semi-Supervised Learning）是结合<strong>监督学习</strong>（利用标记数据）和<strong>无监督学习</strong>（利用未标记数据）的机器学习方法，其核心思想是通过少量标记数据与大量未标记数据的联合训练，提升模型的泛化能力和鲁棒性。  </p>
<ul>
<li><strong>监督学习</strong>：依赖大量人工标注数据（如分类、回归）。  </li>
<li><strong>无监督学习</strong>：仅利用数据分布规律（如聚类、降维）。  </li>
<li><strong>半监督学习</strong>：在标记数据稀缺时，通过未标记数据挖掘潜在结构，降低标注成本 。</li>
</ul>
<p><strong>（2）优势</strong>  </p>
<ul>
<li><strong>减少标注依赖</strong>：仅需少量标记数据即可训练高性能模型，适用于标注成本高的场景（如医疗影像分析）。  </li>
<li><strong>提升模型性能</strong>：利用未标记数据增强数据多样性，缓解过拟合风险。  </li>
<li><strong>平衡效率与精度</strong>：在资源有限时，兼顾监督学习的准确性与无监督学习的高效性 。</li>
</ul>
<p><strong>（3）应用场景</strong>  </p>
<ul>
<li><strong>医学诊断</strong>：利用少量标注的病理图像和大量未标注数据训练疾病预测模型。  </li>
<li><strong>推荐系统</strong>：结合用户行为（有标记）与商品属性（未标记）优化排序模型。  </li>
<li><strong>自然语言处理</strong>：通过预训练模型（如GPT）的“预训练+微调”框架，减少人工标注需求 。</li>
</ul>
<h5 id="2-4"><a href="#2-4" class="headerlink" title="2"></a>2</h5><p>协同训练算法的作用是什么？请简述算法主要流程和所需条件。</p>
<p><strong>（1）作用与核心思想</strong>  </p>
<p>协同训练是一种典型的半监督学习方法，适用于<strong>多视图数据</strong>（Multi-view Data）。其核心思想是通过多个分类器的协作，利用未标记数据扩展训练集，最终提升模型性能。  </p>
<ul>
<li><strong>多视图条件</strong>：  <ul>
<li><strong>充分冗余</strong>：每个视图本身包含足够信息，可独立完成任务。  </li>
<li><strong>条件独立性</strong>：在给定类别标签的条件下，不同视图的特征相互独立 。</li>
</ul>
</li>
</ul>
<p><strong>（2）算法流程</strong>  </p>
<ol>
<li><strong>初始化阶段</strong>：  <ul>
<li>使用少量标记数据 $ D_l $，分别训练两个分类器 $ h_1 $（基于视图 $ V_1 $）和 $ h_2 $（基于视图 $ V_2 $）。  </li>
</ul>
</li>
<li><strong>伪标签生成</strong>：  <ul>
<li>对未标记数据 $ D_u $，$ h_1 $ 预测 $ V_2 $ 的伪标签，$ h_2 $ 预测 $ V_1 $ 的伪标签。  </li>
<li>选择置信度高于阈值的样本加入训练集（如 $ h_1 $ 的预测结果用于更新 $ h_2 $ 的训练数据，反之亦然）。  </li>
</ul>
</li>
<li><strong>迭代优化</strong>：  <ul>
<li>重复伪标签生成和模型训练，直到未标记数据耗尽或模型收敛 。</li>
</ul>
</li>
</ol>
<p><strong>（3）所需条件</strong>  </p>
<ul>
<li><strong>多视图划分</strong>：数据需满足“充分冗余”和“条件独立性”（如图像的RGB通道与纹理特征）。  </li>
<li><strong>分类器多样性</strong>：选择差异较大的分类器（如SVM + 决策树），增强互补性。  </li>
<li><strong>伪标签可靠性</strong>：初始模型需有一定性能，避免错误伪标签污染训练集 。</li>
</ul>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论期末笔记汇总</title>
    <url>/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h3 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h3><p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175733.jpg" alt="IMG_20250627_175733"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175736.jpg" alt="IMG_20250627_175736"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175740.jpg" alt="IMG_20250627_175740"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175743.jpg" alt="IMG_20250627_175743"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175748.jpg" alt="IMG_20250627_175748"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175752.jpg" alt="IMG_20250627_175752"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175755.jpg" alt="IMG_20250627_175755"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%A6%82%E7%8E%87%E8%AE%BA/%E6%A6%82%E7%8E%87%E8%AE%BA%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0/IMG_20250627_175759.jpg" alt="IMG_20250627_175759"></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>概率论</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>概率论</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——知识查漏补缺</title>
    <url>/2025/03/08/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h2 id="pip与conda区别"><a href="#pip与conda区别" class="headerlink" title="pip与conda区别"></a>pip与conda区别</h2><p><code>pip</code> 和 <code>conda</code> 都是用来安装和管理 Python 包的工具，但它们的工作方式和适用场景有所不同。以下是它们的主要区别：</p>
<h3 id="1-包管理的范围"><a href="#1-包管理的范围" class="headerlink" title="1. 包管理的范围"></a>1. <strong>包管理的范围</strong></h3><ul>
<li><code>pip</code>：是 Python 官方的包管理工具，只用于安装 Python 包。它从 Python 包索引 (PyPI) 中获取包并安装。这意味着它只能安装 Python 包，不能直接处理其他类型的依赖（如系统库、C 库等）。</li>
<li><code>conda</code>：是一个跨平台的包和环境管理工具，它不仅可以安装 Python 包，还可以安装其他语言（如 R、Java、C++ 等）以及非 Python 依赖（如系统库）。<code>conda</code> 能够管理整个环境（包括 Python 版本和库），并解决与系统库之间的依赖关系。</li>
</ul>
<h3 id="2-依赖管理"><a href="#2-依赖管理" class="headerlink" title="2. 依赖管理"></a>2. <strong>依赖管理</strong></h3><ul>
<li><code>pip</code>：在安装包时，<code>pip</code> 仅会安装 Python 包及其 Python 依赖，而不处理系统级依赖。如果一个包依赖于特定的 C 库或其他非 Python 包，<code>pip</code> 不会自动解决这些问题，这可能导致一些复杂的兼容性问题。</li>
<li><code>conda</code>：会同时处理 Python 包和非 Python 包的依赖。它会在安装时自动解决所有依赖，包括操作系统库、C 库等。因此，<code>conda</code> 在依赖关系处理上比 <code>pip</code> 更强大。</li>
</ul>
<h3 id="3-包来源"><a href="#3-包来源" class="headerlink" title="3. 包来源"></a>3. <strong>包来源</strong></h3><ul>
<li><code>pip</code>：通过 PyPI（Python Package Index）来下载和安装包，PyPI 是一个包含大多数 Python 包的中央库。</li>
<li><code>conda</code>：使用 Anaconda 仓库或其他 conda 仓库。Anaconda 仓库提供了大量的科学计算、数据分析相关的包，而不仅限于 Python 包。conda 还支持安装一些没有在 PyPI 上的包。</li>
</ul>
<h3 id="4-环境管理"><a href="#4-环境管理" class="headerlink" title="4. 环境管理"></a>4. <strong>环境管理</strong></h3><ul>
<li><code>pip</code>：本身不提供环境管理功能，但可以与 <code>virtualenv</code> 或 <code>venv</code> 等工具结合使用来创建虚拟环境。这些虚拟环境允许你为不同项目隔离依赖。</li>
<li><code>conda</code>：内置环境管理功能，可以通过 <code>conda create</code> 命令直接创建隔离的环境，支持不同版本的 Python 以及其他软件的管理。<code>conda</code> 环境的管理比 <code>pip + virtualenv</code> 更加方便和高效。</li>
</ul>
<h3 id="5-安装速度"><a href="#5-安装速度" class="headerlink" title="5. 安装速度"></a>5. <strong>安装速度</strong></h3><ul>
<li><code>pip</code>：通常只安装 Python 包。对于某些包，特别是需要从源代码编译的包，安装可能会比较慢，尤其是在没有预编译二进制文件的情况下。</li>
<li><code>conda</code>：由于它使用的是预编译的二进制包，安装速度通常更快，尤其是对于依赖项繁多的包（如 <code>numpy</code>、<code>scipy</code> 等）。它无需从源代码编译，直接安装预编译的版本。</li>
</ul>
<h3 id="6-跨平台支持"><a href="#6-跨平台支持" class="headerlink" title="6. 跨平台支持"></a>6. <strong>跨平台支持</strong></h3><ul>
<li><code>pip</code>：支持所有操作系统，但在一些操作系统（尤其是 Windows）上，安装某些包时可能会遇到编译问题，尤其是 C 扩展包。</li>
<li><code>conda</code>：同样支持多平台，并且在 Windows 系统上安装一些复杂的包（如 <code>numpy</code>、<code>pandas</code> 等）时，比 <code>pip</code> 更加稳定和方便，因为它会自动提供适合平台的预编译二进制文件。</li>
</ul>
<h3 id="7-包版本冲突"><a href="#7-包版本冲突" class="headerlink" title="7. 包版本冲突"></a>7. <strong>包版本冲突</strong></h3><ul>
<li><code>pip</code>：虽然可以安装特定版本的包，但如果项目中的多个包有不同的依赖版本，<code>pip</code> 并不能很好地解决这些版本冲突，需要手动处理依赖版本。</li>
<li><code>conda</code>：在安装时，<code>conda</code> 会自动解析所有的依赖关系，确保包和其依赖的版本兼容，从而减少版本冲突。</li>
</ul>
<h3 id="8-包更新"><a href="#8-包更新" class="headerlink" title="8. 包更新"></a>8. <strong>包更新</strong></h3><ul>
<li><strong><code>pip</code></strong>：更新包的方式通常是直接运行 <code>pip install --upgrade &lt;package&gt;</code>，但是它会仅更新 Python 包本身，不会考虑系统级的依赖。</li>
<li><strong><code>conda</code></strong>：更新包时，<code>conda</code> 会同时考虑包的 Python 依赖和系统库依赖，可以更全面地管理包更新。</li>
</ul>
<h3 id="总结对比表："><a href="#总结对比表：" class="headerlink" title="总结对比表："></a>总结对比表：</h3><div class="table-container">
<table>
<thead>
<tr>
<th>特性</th>
<th><code>pip</code></th>
<th><code>conda</code></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>包管理范围</strong></td>
<td>只管理 Python 包</td>
<td>管理 Python 包和其他非 Python 包</td>
</tr>
<tr>
<td><strong>依赖关系管理</strong></td>
<td>只处理 Python 依赖</td>
<td>处理 Python 和非 Python 依赖</td>
</tr>
<tr>
<td><strong>包来源</strong></td>
<td>PyPI</td>
<td>Anaconda 仓库等</td>
</tr>
<tr>
<td><strong>环境管理</strong></td>
<td>需配合 <code>virtualenv</code> 使用</td>
<td>内建环境管理</td>
</tr>
<tr>
<td><strong>安装速度</strong></td>
<td>慢（尤其是需要编译的包）</td>
<td>快（使用预编译二进制包）</td>
</tr>
<tr>
<td><strong>跨平台支持</strong></td>
<td>跨平台支持良好</td>
<td>更好的 Windows 支持</td>
</tr>
<tr>
<td><strong>版本冲突处理</strong></td>
<td>手动解决版本冲突</td>
<td>自动解决版本冲突</td>
</tr>
</tbody>
</table>
</div>
<h3 id="什么时候使用-pip，什么时候使用-conda？"><a href="#什么时候使用-pip，什么时候使用-conda？" class="headerlink" title="什么时候使用 pip，什么时候使用 conda？"></a>什么时候使用 <code>pip</code>，什么时候使用 <code>conda</code>？</h3><ul>
<li>如果你已经在使用 Anaconda 或 Miniconda，并且需要安装 Python 包及其相关依赖，<code>conda</code> 是更好的选择，因为它可以自动解决依赖并更好地管理环境。</li>
<li>如果你没有使用 Anaconda 或只需要安装纯粹的 Python 包，<code>pip</code> 更为轻量和直接。</li>
</ul>
<p>在实际使用中，有时你会发现两者可以结合使用：可以用 <code>conda</code> 安装 Python 环境和一些复杂的依赖，再用 <code>pip</code> 安装一些不在 Anaconda 仓库中的包。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——上机作业2</title>
    <url>/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A2/</url>
    <content><![CDATA[<h3 id="实验1：变量输出与机器数分析"><a href="#实验1：变量输出与机器数分析" class="headerlink" title="实验1：变量输出与机器数分析"></a><strong>实验1：变量输出与机器数分析</strong></h3><h4 id="1-1-运行代码并分析输出"><a href="#1-1-运行代码并分析输出" class="headerlink" title="1.1 运行代码并分析输出"></a><strong>1.1 运行代码并分析输出</strong></h4><p><strong>源代码</strong>：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> x = <span class="number">-1</span>;</span><br><span class="line">    <span class="type">unsigned</span> u = <span class="number">2147483648</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;x = %u = %d.\n&quot;</span>, x, x);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;u = %u = %d.\n&quot;</span>, u, u);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>编译与运行</strong>：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -o test1 test1.c</span><br><span class="line">./test1</span><br></pre></td></tr></table></figure></p>
<p><strong>输出结果</strong>（假设32位系统）：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x = 4294967295 = -1.</span><br><span class="line">u = 2147483648 = -2147483648.</span><br></pre></td></tr></table></figure></p>
<p><strong>结果分析</strong>：</p>
<ul>
<li><strong><code>x = %u</code></strong>：<br><code>x</code> 是 <code>int</code> 类型的 <code>-1</code>，二进制补码为 <code>0xFFFFFFFF</code>。用 <code>%u</code>（无符号）解释时，<code>0xFFFFFFFF</code> 对应 <code>4294967295</code>。</li>
<li><strong><code>x = %d</code></strong>：<br>正常输出 <code>-1</code>。</li>
<li><strong><code>u = %u</code></strong>：<br><code>u</code> 是 <code>unsigned</code> 类型的 <code>2147483648</code>（即 <code>0x80000000</code>），直接输出为 <code>2147483648</code>。</li>
<li><strong><code>u = %d</code></strong>：<br>用 <code>%d</code>（有符号）解释 <code>0x80000000</code>，最高位为1，表示负数，结果为 <code>-2147483648</code>。</li>
</ul>
<hr>
<h4 id="1-2-反汇编分析机器数"><a href="#1-2-反汇编分析机器数" class="headerlink" title="1.2 反汇编分析机器数"></a><strong>1.2 反汇编分析机器数</strong></h4><p><strong>步骤</strong>：</p>
<ol>
<li>生成目标文件：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -c test1.c -o test1.o</span><br></pre></td></tr></table></figure></li>
<li>反汇编查看变量赋值：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">objdump -d -M intel test1.o</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>关键汇编代码</strong>（简化）：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov DWORD PTR [rbp-4], 0xffffffff   ; x = -1 (机器数 0xFFFFFFFF)</span><br><span class="line">mov DWORD PTR [rbp-8], 0x80000000   ; u = 2147483648 (机器数 0x80000000)</span><br></pre></td></tr></table></figure></p>
<p><strong>变量机器数总结</strong>：<br>| 变量 | 机器数（十六进制） |<br>| —— | ————————— |<br>| x    | 0xFFFFFFFF         |<br>| u    | 0x80000000         |</p>
<hr>
<h3 id="实验2：表达式结果与反汇编分析"><a href="#实验2：表达式结果与反汇编分析" class="headerlink" title="实验2：表达式结果与反汇编分析"></a><strong>实验2：表达式结果与反汇编分析</strong></h3><h4 id="2-1-验证表达式结果"><a href="#2-1-验证表达式结果" class="headerlink" title="2.1 验证表达式结果"></a><strong>2.1 验证表达式结果</strong></h4><p><strong>源代码</strong>：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;-1 &lt; 0\t\t -&gt; %d\n&quot;</span>, (<span class="number">-1</span> &lt; <span class="number">0</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;-1 &lt; 0U\t -&gt; %d\n&quot;</span>, (<span class="number">-1</span> &lt; <span class="number">0U</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;2147483647 &gt; -2147483647 - 1\t -&gt; %d\n&quot;</span>, (<span class="number">2147483647</span> &gt; <span class="number">-2147483647</span> - <span class="number">1</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;2147483647U &gt; -2147483647 - 1\t -&gt; %d\n&quot;</span>, (<span class="number">2147483647U</span> &gt; <span class="number">-2147483647</span> - <span class="number">1</span>));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>编译与运行</strong>：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -o test2 test2.c</span><br><span class="line">./test2</span><br></pre></td></tr></table></figure></p>
<p><strong>输出结果</strong>：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-1 &lt; 0           -&gt; 1</span><br><span class="line">-1 &lt; 0U          -&gt; 0</span><br><span class="line">2147483647 &gt; -2147483647 - 1  -&gt; 1</span><br><span class="line">2147483647U &gt; -2147483647 - 1 -&gt; 0</span><br></pre></td></tr></table></figure></p>
<p><strong>结果分析</strong>：</p>
<ol>
<li><strong><code>-1 &lt; 0</code></strong>：<br>有符号比较，<code>-1</code> 小于 <code>0</code>，结果为真（<code>1</code>）。</li>
<li><strong><code>-1 &lt; 0U</code></strong>：<br><code>0U</code> 是无符号，<code>-1</code> 被转换为无符号数 <code>0xFFFFFFFF</code>（4294967295），远大于 <code>0U</code>，结果为假（<code>0</code>）。</li>
<li><strong><code>2147483647 &gt; -2147483647 - 1</code></strong>：<br>右侧表达式 <code>-2147483647 - 1</code> 等于 <code>-2147483648</code>（<code>INT_MIN</code>），有符号比较，<code>2147483647</code>（<code>INT_MAX</code>）大于 <code>INT_MIN</code>，结果为真（<code>1</code>）。</li>
<li><strong><code>2147483647U &gt; -2147483647 - 1</code></strong>：<br>左侧是无符号，右侧 <code>INT_MIN</code> 被转换为无符号数 <code>0x80000000</code>（2147483648），比较 <code>2147483647</code> 和 <code>2147483648</code>，结果为假（<code>0</code>）。</li>
</ol>
<hr>
<h4 id="2-2-反汇编分析表达式"><a href="#2-2-反汇编分析表达式" class="headerlink" title="2.2 反汇编分析表达式"></a><strong>2.2 反汇编分析表达式</strong></h4><p><strong>步骤</strong>：</p>
<ol>
<li>生成目标文件：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -c test2.c -o test2.o</span><br></pre></td></tr></table></figure></li>
<li>反汇编查看比较指令：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">objdump -d -M intel test2.o</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>关键汇编代码</strong>（以 <code>-1 &lt; 0U</code> 为例）：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov DWORD PTR [rbp-4], 0xffffffff   ; -1 的机器数</span><br><span class="line">cmp DWORD PTR [rbp-4], 0            ; 比较时，-1 被视为无符号数 4294967295</span><br><span class="line">setb al                             ; 设置结果（0 表示假）</span><br></pre></td></tr></table></figure></p>
<p><strong>总结</strong>：</p>
<ul>
<li>类型转换规则决定了比较结果。</li>
<li>反汇编显示编译器如何处理有符号与无符号的隐式转换。</li>
</ul>
<hr>
<h3 id="实验报告建议"><a href="#实验报告建议" class="headerlink" title="实验报告建议"></a><strong>实验报告建议</strong></h3><ol>
<li><strong>源代码与输出结果</strong>：附上代码及运行结果。</li>
<li><strong>反汇编截图</strong>：展示变量赋值和表达式比较的汇编代码。</li>
<li><strong>分析</strong>：<ul>
<li>解释类型转换对输出的影响。</li>
<li>说明反汇编中机器数与表达式比较的底层实现。</li>
</ul>
</li>
</ol>
<p>如果需要更详细的反汇编代码或具体步骤解释，请随时告知！</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——绪论</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[<h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><p><img src="/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%AA%E8%AE%BA/QQ20250320-191604.png" alt="QQ20250320-191604"></p>
<h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h3><p><a href="https://blog.csdn.net/lhxez6868/article/details/108150777">准确度(accuracy)、精确率（precision)、召回率（recall）、F1值 谈谈我的看法_recall f1-CSDN博客</a></p>
<p>南瓜书在线阅读：<a href="https://datawhalechina.github.io/pumpkin-book/#/">https://datawhalechina.github.io/pumpkin-book/#/</a></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——上机作业1</title>
    <url>/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A1/</url>
    <content><![CDATA[<h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>安装vmware虚拟机</p>
<p>安装ubuntu</p>
<h2 id="在Ubuntu终端里编写C语言程序"><a href="#在Ubuntu终端里编写C语言程序" class="headerlink" title="在Ubuntu终端里编写C语言程序"></a>在Ubuntu终端里编写C语言程序</h2><p> 打开终端：ctrl+alt+t</p>
<p>新建文件：<strong>vim hello.c</strong></p>
<p>输入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#define DISPLAY &quot;hello c!&quot;</span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">  printf(&quot;%s\n&quot;, DISPLAY);</span><br><span class="line">  return 0;</span><br><span class="line">&#125;</span><br><span class="line">ZZ（*说明：ZZ当前文件进行快速保存操作*）</span><br></pre></td></tr></table></figure>
<p>退出编译模式：shift+：</p>
<p>输入：w保存q退出</p>
<p><strong>预编译(Preprocessing)</strong></p>
<p><em>对各种预处理指令（#include #define #ifdef 等#开始的代码行）进行处理，删除注释和多余的空白字符，生成一份新的代码</em></p>
<p>输入：<strong>gcc -E hello.c -o hello.i</strong></p>
<ol>
<li><strong>命令分解</strong></li>
</ol>
<ul>
<li><strong><code>gcc</code></strong> ：GNU Compiler Collection（GCC）的编译器命令。</li>
<li><strong><code>-E</code></strong> ：选项表示 <strong>仅执行预处理阶段</strong> ，不进行编译、汇编和链接。</li>
<li><strong><code>hello.c</code></strong> ：输入的C语言源文件。</li>
<li><strong><code>-o hello.i</code></strong> ：指定预处理后的输出文件名为 <code>hello.i</code>（<code>.i</code> 是预处理文件的默认后缀）。</li>
</ul>
<p><strong>2. 预处理阶段的作用</strong></p>
<p>预处理是编译过程的第一个阶段，主要处理以下内容：</p>
<ol>
<li>头文件展开 <ul>
<li>将 <code>#include &lt;stdio.h&gt;</code> 等指令替换为对应头文件的实际内容。</li>
</ul>
</li>
<li>宏展开 <ul>
<li>替换 <code>#define PI 3.14</code> 等宏定义。</li>
</ul>
</li>
<li>条件编译 <ul>
<li>处理 <code>#ifdef</code>, <code>#ifndef</code>, <code>#endif</code> 等条件编译指令。</li>
</ul>
</li>
<li>删除注释 <ul>
<li>移除代码中的注释（<code>//</code> 或 <code>/* */</code>）。</li>
</ul>
</li>
</ol>
<p><strong>编译(Compilation)</strong></p>
<p><em>对代码进行语法、语义分析和错误判断，生成汇编代码文件</em></p>
<p><strong>gcc -S hello.i -o hello.s</strong></p>
<p><strong>编译阶段的作用</strong></p>
<p>在编译流程中，<code>-S</code> 选项对应 <strong>编译阶段</strong> ，主要完成以下任务：</p>
<ol>
<li><strong>语法分析</strong> ：检查代码是否符合C语言语法规则。</li>
<li><strong>中间代码生成</strong> ：将预处理后的代码转换为中间表示（如抽象语法树）。</li>
<li><strong>优化</strong> ：根据优化选项（如 <code>-O2</code>）对代码进行优化。</li>
<li><strong>生成汇编代码</strong> ：将优化后的中间代码转换为目标平台的汇编指令（如x86-64汇编）。</li>
</ol>
<p><strong>汇编(Assembly)</strong></p>
<p><strong>gcc -c hello.s -o hello.o</strong></p>
<p><strong>汇编阶段的作用</strong></p>
<p>该命令执行 <strong>汇编阶段</strong> ，将人类可读的汇编代码（如 <code>mov</code>, <code>call</code> 等指令）转换为 <strong>二进制机器码</strong> ，生成目标文件（<code>.o</code>）。<br>目标文件包含：</p>
<ul>
<li>机器指令（二进制代码）。</li>
<li>符号表（函数名、变量名等）。</li>
<li>未解析的引用（如外部函数 <code>printf</code> 的地址）。</li>
</ul>
<p><strong>链接(Linking/Build)</strong></p>
<p><strong>gcc hello.o -o hello</strong></p>
<p><strong>链接阶段的作用</strong></p>
<p>链接器（<code>ld</code>）完成以下任务：</p>
<ol>
<li>合并代码和数据 <ul>
<li>将 <code>hello.o</code> 中的机器码与标准库（如 <code>stdio.h</code> 中的 <code>printf</code>）的二进制代码合并。</li>
</ul>
</li>
<li>解析符号引用 <ul>
<li>解决外部符号（如 <code>printf</code>）的地址，确保所有函数和全局变量正确关联。</li>
</ul>
</li>
<li>生成可执行文件格式 <ul>
<li>创建符合操作系统要求的可执行文件（如Linux的ELF格式）。</li>
</ul>
</li>
</ol>
<p><strong>程序运行</strong></p>
<p><strong>./hello</strong></p>
<h2 id="手动安装VMware-tools"><a href="#手动安装VMware-tools" class="headerlink" title="手动安装VMware tools"></a>手动安装VMware tools</h2><p><a href="https://www.bilibili.com/video/BV1F6DzY2Ep9/?vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">手动安装VMware Tools（提示VMware Tools 不再随旧版客户机操作系统的 VMware Workstation 一起提供的解决办法）_哔哩哔哩_bilibili</a></p>
<p><strong>在线安装</strong></p>
<p>如果方法一不行，可以试试方法二，我是通过方法二进行安装的。</p>
<p>首先更新系统已安装的软件源，以确保是最新的，在终端输入命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br></pre></td></tr></table></figure>
<p>然后再输入命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install open-vm-tools-desktop</span><br></pre></td></tr></table></figure>
<p>完成后运行upgrade命令，来升级系统中已安装的软件包(命令后面的 -y可以跳过确认询问)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt upgrade -y</span><br></pre></td></tr></table></figure>
<p>完成后进行重启，重启过后，点击菜单栏查看，变成重新安装就是成功了。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——上机作业3</title>
    <url>/2025/03/31/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E4%B8%8A%E6%9C%BA%E4%BD%9C%E4%B8%9A3/</url>
    <content><![CDATA[<p>以下是针对表1和表2中所有函数的实现和验证分析，严格按照约束条件和操作符数量限制设计：</p>
<hr>
<h3 id="表1-位操作函数实现"><a href="#表1-位操作函数实现" class="headerlink" title="表1 位操作函数实现"></a><strong>表1 位操作函数实现</strong></h3><h4 id="1-lsbZero-将x的最低有效位清零"><a href="#1-lsbZero-将x的最低有效位清零" class="headerlink" title="1. lsbZero (将x的最低有效位清零)"></a><strong>1. lsbZero (将x的最低有效位清零)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">lsbZero</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> x &amp; (~<span class="number">1</span>);  <span class="comment">// 操作符: &amp; ~ 1 (共3个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x = 0x05 (0b101)</code> → <code>0x04 (0b100)</code></p>
<hr>
<h4 id="2-byteNot-将x的第n个字节取反"><a href="#2-byteNot-将x的第n个字节取反" class="headerlink" title="2. byteNot (将x的第n个字节取反)"></a><strong>2. byteNot (将x的第n个字节取反)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">byteNot</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = <span class="number">0xFF</span> &lt;&lt; (n &lt;&lt; <span class="number">3</span>);  <span class="comment">// 构造字节掩码</span></span><br><span class="line">    <span class="keyword">return</span> x ^ mask;               <span class="comment">// 操作符: &lt;&lt; &lt;&lt; 3 &lt;&lt; 8 (共6个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x = 0x12345678, n=1</code> → <code>0x1234A978</code>（第1字节 <code>0x56</code> 取反为 <code>0xA9</code>）</p>
<hr>
<h4 id="3-byteXor-比较x和y的第n个字节"><a href="#3-byteXor-比较x和y的第n个字节" class="headerlink" title="3. byteXor (比较x和y的第n个字节)"></a><strong>3. byteXor (比较x和y的第n个字节)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">byteXor</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> shift = n &lt;&lt; <span class="number">3</span>;</span><br><span class="line">    <span class="type">int</span> x_byte = (x &gt;&gt; shift) &amp; <span class="number">0xFF</span>;</span><br><span class="line">    <span class="type">int</span> y_byte = (y &gt;&gt; shift) &amp; <span class="number">0xFF</span>;</span><br><span class="line">    <span class="keyword">return</span> !!(x_byte ^ y_byte);  <span class="comment">// 操作符: &lt;&lt; &gt;&gt; &amp; ^ !! (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0x12345678, y=0x12745678, n=2</code> → <code>1</code>（第2字节 <code>0x34</code> vs <code>0x74</code>）</p>
<hr>
<h4 id="4-logicalAnd-模拟x-amp-amp-y"><a href="#4-logicalAnd-模拟x-amp-amp-y" class="headerlink" title="4. logicalAnd (模拟x &amp;&amp; y)"></a><strong>4. logicalAnd (模拟x &amp;&amp; y)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">logicalAnd</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (!!x) &amp; (!!y);  <span class="comment">// 操作符: !! &amp; (共2个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0, y=5</code> → <code>0</code>；<code>x=1, y=2</code> → <code>1</code></p>
<hr>
<h4 id="5-logicalOr-模拟x-y"><a href="#5-logicalOr-模拟x-y" class="headerlink" title="5. logicalOr (模拟x || y)"></a><strong>5. logicalOr (模拟x || y)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">logicalOr</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (!!x) | (!!y);  <span class="comment">// 操作符: !! | (共2个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0, y=0</code> → <code>0</code>；<code>x=0, y=1</code> → <code>1</code></p>
<hr>
<h4 id="6-rotateLeft-循环左移n位"><a href="#6-rotateLeft-循环左移n位" class="headerlink" title="6. rotateLeft (循环左移n位)"></a><strong>6. rotateLeft (循环左移n位)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">rotateLeft</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = (<span class="number">0xFF</span> &lt;&lt; <span class="number">24</span>) &gt;&gt; (<span class="number">32</span> - n);  <span class="comment">// 构造高位掩码</span></span><br><span class="line">    <span class="keyword">return</span> (x &lt;&lt; n) | ((x &gt;&gt; (<span class="number">32</span> - n)) &amp; mask);  <span class="comment">// 操作符: &lt;&lt; &gt;&gt; | &amp; (共25个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0x12345678, n=4</code> → <code>0x23456781</code>（左移4位，高位循环到低位）</p>
<hr>
<h4 id="7-parityCheck-奇偶校验"><a href="#7-parityCheck-奇偶校验" class="headerlink" title="7. parityCheck (奇偶校验)"></a><strong>7. parityCheck (奇偶校验)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">parityCheck</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">16</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">8</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">4</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">2</span>;</span><br><span class="line">    x ^= x &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> x &amp; <span class="number">1</span>;  <span class="comment">// 操作符: ^ &gt;&gt; &amp; (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0b1010</code> → <code>0</code>（2个1，偶数）；<code>x=0b101</code> → <code>1</code>（奇数）</p>
<hr>
<h3 id="表2-补码运算函数实现"><a href="#表2-补码运算函数实现" class="headerlink" title="表2 补码运算函数实现"></a><strong>表2 补码运算函数实现</strong></h3><h4 id="8-mul2OK-判断2-x是否溢出"><a href="#8-mul2OK-判断2-x是否溢出" class="headerlink" title="8. mul2OK (判断2*x是否溢出)"></a><strong>8. mul2OK (判断2*x是否溢出)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mul2OK</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> sign = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> result = x &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> !(((result &gt;&gt; <span class="number">31</span>) ^ sign) &amp; (!!(x ^ (x &lt;&lt; <span class="number">1</span>))));  <span class="comment">// 操作符: &gt;&gt; &lt;&lt; ^ &amp; !! (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0x40000000</code> → <code>0</code>（溢出）；<code>x=0x3FFFFFFF</code> → <code>1</code></p>
<hr>
<h4 id="9-mult3div2-计算-x-3-2"><a href="#9-mult3div2-计算-x-3-2" class="headerlink" title="9. mult3div2 (计算(x*3)/2)"></a><strong>9. mult3div2 (计算(x*3)/2)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mult3div2</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> temp = x + x + x;</span><br><span class="line">    <span class="type">int</span> sign = temp &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> (temp + (temp &gt;&gt; <span class="number">31</span> &amp; <span class="number">1</span>)) &gt;&gt; <span class="number">1</span>;  <span class="comment">// 操作符: + &gt;&gt; &amp; (共12个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=-3</code> → <code>(-9)/2 = -4</code>（向零取整）</p>
<hr>
<h4 id="10-subOK-判断x-y是否溢出"><a href="#10-subOK-判断x-y是否溢出" class="headerlink" title="10. subOK (判断x - y是否溢出)"></a><strong>10. subOK (判断x - y是否溢出)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">subOK</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="type">int</span> sub = x + (~y + <span class="number">1</span>);</span><br><span class="line">    <span class="type">int</span> x_sign = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> y_sign = (~y + <span class="number">1</span>) &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> sub_sign = sub &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> !((~(x_sign ^ y_sign)) &amp; (x_sign ^ sub_sign));  <span class="comment">// 操作符: ~ ^ + &gt;&gt; &amp; (共20个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=0x80000000, y=1</code> → <code>0</code>（溢出）</p>
<hr>
<h4 id="11-absVal-求绝对值"><a href="#11-absVal-求绝对值" class="headerlink" title="11. absVal (求绝对值)"></a><strong>11. absVal (求绝对值)</strong></h4><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">absVal</span><span class="params">(<span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="type">int</span> mask = x &gt;&gt; <span class="number">31</span>;</span><br><span class="line">    <span class="keyword">return</span> (x + mask) ^ mask;  <span class="comment">// 操作符: &gt;&gt; + ^ (共10个)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>验证</strong>：<br><code>x=-5</code> → <code>5</code>；<code>x=3</code> → <code>3</code></p>
<hr>
<h3 id="验证方法"><a href="#验证方法" class="headerlink" title="验证方法"></a><strong>验证方法</strong></h3><ol>
<li><strong>编写测试代码</strong>：为每个函数设计边界值（如0、最大值、最小值）。</li>
<li><strong>反汇编分析</strong>：使用 <code>objdump -d</code> 检查生成的机器码是否符合操作符限制。</li>
<li><strong>覆盖率测试</strong>：确保所有分支条件被触发（如正负数、溢出情况）。</li>
</ol>
<hr>
<h3 id="关键技巧"><a href="#关键技巧" class="headerlink" title="关键技巧"></a><strong>关键技巧</strong></h3><ul>
<li><strong>位掩码</strong>：使用 <code>0xFF</code>、<code>0x80000000</code> 等构造特定模式。</li>
<li><strong>符号位操作</strong>：通过 <code>x &gt;&gt; 31</code> 提取符号位。</li>
<li><strong>逻辑运算替代</strong>：用 <code>!!x</code> 将非零值转换为1，用 <code>x ^ (x &gt;&gt; 31)</code> 处理绝对值。</li>
</ul>
<p>如果需要具体函数的详细推导或测试用例，可进一步说明！</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——期末复习</title>
    <url>/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<h3 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h3><p><strong>时钟频率（f）</strong> ：单位时间内完成的时钟周期数，单位为赫兹（Hz）。<br>例如：800MHz 表示每秒完成 800×106 个周期。</p>
<p><strong>时钟周期（T）</strong> ：完成一个时钟周期所需的时间，单位为秒（s）。<br>例如：800MHz 的时钟周期为 <em>T</em>=800×1061​s=1.25ns （纳秒）。</p>
<p><strong>CPI</strong>（<strong>Cycles Per Instruction</strong>，每条指令所需的时钟周期数）是衡量计算机体系结构性能的关键指标之一，用于描述<strong>CPU执行一条指令平均需要多少个时钟周期</strong>。它直接影响程序的执行速度和系统性能。</p>
<ul>
<li><strong>CPI</strong> 表示每条指令执行所需的平均时钟周期数，计算公式为：<script type="math/tex; mode=display">
\text{CPI} = \frac{\text{总时钟周期数}}{\text{总指令数}}</script></li>
<li><strong>执行时间</strong> 与 CPI 的关系：<script type="math/tex; mode=display">
\text{执行时间} = \text{指令数} \times \text{CPI} \times \text{时钟周期时间}</script>其中，时钟周期时间 = 1 / 时钟频率。</li>
</ul>
<p><strong>MIPS（Million Instructions Per Second）</strong> 是衡量计算机处理器性能的一个经典指标，表示 <strong>每秒执行的百万条指令数</strong>，用于量化 CPU 的指令处理能力。其核心思想是：<strong>数值越大，性能越强</strong>，但需注意其局限性。</p>
<ul>
<li><strong>MIPS</strong> = 指令数 / (执行时间 × 10⁶)  </li>
<li>或通过 <strong>时钟频率</strong> 和 <strong>CPI（Cycles Per Instruction）</strong> 计算：  <script type="math/tex; mode=display">
\text{MIPS} = \frac{\text{时钟频率（Hz）}}{\text{CPI} \times 10^6}</script></li>
</ul>
<p><strong>举例</strong>：  </p>
<ul>
<li>若 CPU 主频为 <strong>2 GHz</strong>（2×10⁹ Hz），平均 CPI=4，则：  <script type="math/tex; mode=display">
\text{MIPS} = \frac{2 \times 10^9}{4 \times 10^6} = 500 \text{ MIPS}</script></li>
</ul>
<p>数量级：</p>
<p>G，吉，十的九次方</p>
<p>n，纳，十的负九次方</p>
<p><strong>m（milli，毫）的数量级是 10−3 （千分之一）</strong> 。</p>
<h3 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h3><h4 id="补码"><a href="#补码" class="headerlink" title="补码"></a>补码</h4><p><strong>1. 补码的定义</strong></p>
<p>补码（Two’s Complement）是计算机中表示有符号整数的标准方法，其核心作用是将减法运算转化为加法运算，从而简化硬件设计。</p>
<p><strong>2. 如何求一个数的补码？</strong></p>
<p>以 <strong>8位二进制</strong> 为例：</p>
<ul>
<li><p><strong>正数</strong>：补码 = 原码（符号位为0，其余位直接表示数值）。<br>例如：<code>+5</code> 的补码是 <code>00000101</code>。</p>
</li>
<li><p><strong>负数</strong>：补码 = 原码的符号位不变，其余位取反（反码），然后末位加1。<br>例如：求 <code>-5</code> 的补码：</p>
<ol>
<li>原码：<code>10000101</code>（符号位为1，其余位为5的二进制）。</li>
<li>取反（符号位保留）：<code>11111010</code>（反码）。</li>
<li>加1：<code>11111010 + 1 = 11111011</code>（补码）。</li>
</ol>
</li>
</ul>
<p><strong>3. 数学原理：模运算</strong></p>
<p>补码的本质是基于 <strong>模（Modulo）运算</strong>。  </p>
<ul>
<li>对于 <strong>n位二进制数</strong>，其模为 $2^n$。  </li>
<li>负数的补码表示为：  <script type="math/tex; mode=display">
-x \equiv 2^n - x \ (\text{mod} \ 2^n)</script>例如，8位二进制数的模是 $2^8 = 256$，因此：<br>$-5$ 的补码 = $256 - 5 = 251$，二进制表示为 <code>11111011</code>。</li>
</ul>
<p><strong>4. 为什么“取反 + 1”有效？</strong></p>
<ul>
<li><strong>取反</strong>：相当于将数值部分取反（即 $x \rightarrow (2^{n-1} - 1 - x)$）。</li>
<li><strong>加1</strong>：最终得到 $2^n - x$，即补码的数学定义。</li>
</ul>
<p>以 <code>-5</code> 为例（8位）：</p>
<ol>
<li>原码：<code>10000101</code>（符号位为1，数值部分为5）。</li>
<li>取反：<code>11111010</code>（数值部分取反，符号位保留）。</li>
<li>加1：<code>11111010 + 1 = 11111011</code>，即 $251 = 256 - 5$。</li>
</ol>
<p><strong>5. 补码的优势</strong></p>
<ul>
<li><strong>唯一零表示</strong>：补码中只有 <strong>一个零</strong>（<code>00000000</code>），而原码和反码存在 <code>+0</code> 和 <code>-0</code> 的问题。</li>
<li><strong>加减统一</strong>：所有加减运算均通过加法器完成，无需单独的减法器。<br>例如：<code>5 - 3 = 5 + (-3)</code>，直接通过补码相加即可。</li>
<li><strong>溢出自动处理</strong>：超过范围的高位会自然丢弃（模运算特性）。</li>
</ul>
<p><strong>6. 特殊情况：最小负数</strong></p>
<p>对于 <strong>n位补码</strong>，能表示的范围是：  </p>
<script type="math/tex; mode=display">
[-2^{n-1}, \ 2^{n-1} - 1]</script><ul>
<li>例如，8位补码范围是：<code>-128</code>（<code>10000000</code>）到 <code>+127</code>（<code>01111111</code>）。</li>
<li><strong>最小负数（-128）</strong> 没有对应的正数（因为 $+128$ 超出范围），其补码直接定义为 <code>10000000</code>，无法通过“取反 + 1”从原码推导（因为原码中不存在 <code>+128</code>）。</li>
</ul>
<h4 id="移码（Offset-Binary）详解"><a href="#移码（Offset-Binary）详解" class="headerlink" title="移码（Offset Binary）详解"></a><strong>移码（Offset Binary）详解</strong></h4><p><strong>1. 移码的定义</strong></p>
<p>移码是一种<strong>带偏移量的编码方式</strong>，主要用于表示<strong>浮点数的阶码</strong>（Exponent）。其核心思想是将真值（实际数值）加上一个固定的偏移量（Bias），使得所有数值映射到<strong>非负数范围</strong>，从而简化比较和运算。</p>
<p><strong>公式</strong>：  </p>
<script type="math/tex; mode=display">
\text{移码} = \text{真值} + \text{偏移量}</script><p><strong>2. 移码的核心作用</strong></p>
<ul>
<li><p><strong>简化比较</strong>：<br>移码将负数范围映射到正数范围，使得可以直接通过<strong>无符号整数比较</strong>来判断阶码的大小。  </p>
<ul>
<li>例如：<br>在浮点数中，阶码 $-3$ 和 $+2$ 的移码分别为 $125$ 和 $130$（偏移量为127），直接比较 $125 &lt; 130$ 即可得出 $-3 &lt; +2$。</li>
</ul>
</li>
<li><p><strong>消除负数表示</strong>：<br>移码将负数转换为正数表示，避免了补码中负数符号位的影响。</p>
</li>
</ul>
<p><strong>3. 偏移量的选择</strong></p>
<p>偏移量通常为 $2^{n-1}$ 或 $2^{n-1}-1$（$n$ 为位数）：</p>
<ul>
<li><strong>单精度浮点数（32位）</strong>：偏移量为 $127$（即 $2^7 - 1$）。  </li>
<li><strong>双精度浮点数（64位）</strong>：偏移量为 $1023$（即 $2^{10} - 1$）。</li>
</ul>
<p><strong>4. 移码与补码的关系</strong></p>
<ul>
<li><p><strong>符号位取反</strong>：<br>移码可以看作是<strong>补码的符号位取反</strong>。例如：  </p>
<ul>
<li>补码 <code>10000000</code>（$-128$）的移码为 <code>00000000</code>（$-128 + 128 = 0$）。  </li>
<li>补码 <code>00000000</code>（$0$）的移码为 <code>10000000</code>（$0 + 128 = 128$）。</li>
</ul>
</li>
<li><p><strong>本质区别</strong>：  </p>
<ul>
<li><strong>补码</strong>：用于定点数的加减运算，支持负数和正数的统一处理。  </li>
<li><strong>移码</strong>：用于浮点数阶码的表示，便于直接比较大小。</li>
</ul>
</li>
</ul>
<p><strong>5. 移码的应用场景</strong></p>
<ul>
<li><strong>IEEE 754浮点数标准</strong>：<br>移码用于表示浮点数的阶码（Exponent），使得阶码可以直接按无符号整数比较。  <ul>
<li><strong>单精度（32位）</strong>：<br>阶码占8位，偏移量为127。<br>真值 $E$ 的移码为 $E + 127$。  </li>
<li><strong>双精度（64位）</strong>：<br>阶码占11位，偏移量为1023。<br>真值 $E$ 的移码为 $E + 1023$。</li>
</ul>
</li>
</ul>
<h4 id="浮点数表示"><a href="#浮点数表示" class="headerlink" title="浮点数表示"></a>浮点数表示</h4><p><a href="https://www.bilibili.com/video/BV1VK4y1f7o6?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】2-4.浮点数(上)_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1Le4y137gU/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【计算机知识】定点数与浮点数（2）浮点数法表示方法！_哔哩哔哩_bilibili</a></p>
<h4 id="进制转换"><a href="#进制转换" class="headerlink" title="进制转换"></a>进制转换</h4><p><a href="https://www.bilibili.com/video/BV1ke411T7Qr?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【计算机基础】进制转换(3) 小数部分如何进行转换？_哔哩哔哩_bilibili</a></p>
<h4 id="整数加减"><a href="#整数加减" class="headerlink" title="整数加减"></a>整数加减</h4><h4 id="浮点数加减"><a href="#浮点数加减" class="headerlink" title="浮点数加减"></a>浮点数加减</h4><p><a href="https://www.bilibili.com/video/BV1894y1C7br/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">浮点数加减法运算 白中英计算机组成原理期末速成_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1ue4y1s71Z/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">(自用)计算机组成原理 题型三 浮点数加减法运算题_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1ej411J71a/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">浮点运算（浮点数加减运算）计算机组成原理（看了包会）_哔哩哔哩_bilibili</a></p>
<p>ieee</p>
<p><a href="https://www.bilibili.com/video/BV1nwTXz7EVi/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">计算机组成原理期末复习（5分钟）：IEEE754浮点数加减计算！_哔哩哔哩_bilibili</a></p>
<h4 id="位数"><a href="#位数" class="headerlink" title="位数"></a>位数</h4><p>short 16位</p>
<h3 id="第三章-程序的转换与机器级表示"><a href="#第三章-程序的转换与机器级表示" class="headerlink" title="第三章 程序的转换与机器级表示"></a><strong>第三章 程序的转换与机器级表示</strong></h3><h4 id="结构体与联合体"><a href="#结构体与联合体" class="headerlink" title="结构体与联合体"></a>结构体与联合体</h4><p><a href="https://www.bilibili.com/video/BV1754y1Y7Ut?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-9.结构体与联合体_哔哩哔哩_bilibili</a></p>
<h4 id="数组的分配和访问"><a href="#数组的分配和访问" class="headerlink" title="数组的分配和访问"></a>数组的分配和访问</h4><p><a href="https://www.bilibili.com/video/BV1ho4y1d7J6?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-8.数组的分配和访问_哔哩哔哩_bilibili</a></p>
<h4 id="过程调用"><a href="#过程调用" class="headerlink" title="过程调用"></a>过程调用</h4><p><a href="https://www.bilibili.com/video/BV1By4y1x7Yh/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">C程序在内存中的栈_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV19X4y1P7Pn?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-7. 过程（函数调用）_哔哩哔哩_bilibili</a></p>
<h4 id="AT-amp-T格式"><a href="#AT-amp-T格式" class="headerlink" title="AT&amp;T格式"></a>AT&amp;T格式</h4><p>AT&amp;T格式是汇编语言中的一种语法风格，主要用于x86/x64架构的汇编代码编写。它与Intel格式并列为最常见的两种汇编语法，两者在语法细节上有显著差异。以下是AT&amp;T格式的核心特点、示例及常见用途：</p>
<p><strong>主要特点</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>特性</th>
<th>AT&amp;T格式语法</th>
<th>对比Intel格式语法</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>寄存器</strong></td>
<td>前缀 <code>%</code>（如 <code>%eax</code>）</td>
<td>无前缀（如 <code>eax</code>）</td>
</tr>
<tr>
<td><strong>立即数</strong></td>
<td>前缀 <code>$</code>（如 <code>$0x10</code>）</td>
<td>直接使用数值（如 <code>10</code>）</td>
</tr>
<tr>
<td><strong>操作数顺序</strong></td>
<td>源操作数在前，目标在后</td>
<td>目标在前，源在后</td>
</tr>
<tr>
<td><strong>内存寻址</strong></td>
<td><code>offset(base, index, scale)</code></td>
<td><code>[base + index*scale + offset]</code></td>
</tr>
<tr>
<td><strong>指令后缀</strong></td>
<td>通过后缀标明操作数大小（如 <code>l</code> 表示32位）</td>
<td>无后缀，由操作数推断</td>
</tr>
</tbody>
</table>
</div>
<h4 id="寄存器种类"><a href="#寄存器种类" class="headerlink" title="寄存器种类"></a>寄存器种类</h4><ul>
<li>8 个通用寄存器，其中<ul>
<li><code>EAX, EBX, ECX, EDX</code> 均为 32 位寄存器</li>
<li><code>AX, BX, CX, DX</code> 均为 16 位寄存器</li>
<li><code>AH, BH, CH, DH</code> 均为高 8 位寄存器</li>
<li><code>AL, BL, CL, DL</code> 均为低 8 位寄存器</li>
</ul>
</li>
<li>2 个专用寄存器</li>
<li>6 个段寄存器</li>
</ul>
<h4 id="操作数寻址方式"><a href="#操作数寻址方式" class="headerlink" title="操作数寻址方式"></a>操作数寻址方式</h4><p><strong>1. 基础内存寻址模式</strong></p>
<p><strong>(1) 直接寻址（Direct Addressing）</strong> cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc              </p>
<ul>
<li><strong>语法</strong>：<code>offset</code>（AT&amp;T格式）或 <code>[offset]</code>（Intel格式）。</li>
<li><strong>用途</strong>：直接访问全局变量或静态数据。</li>
<li><strong>示例</strong>：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl var(%rip), %eax  # AT&amp;T格式（RIP相对寻址，64位模式推荐）</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov eax, [var]        # Intel格式（32位模式）</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>(2) 寄存器间接寻址（Register Indirect Addressing）</strong></p>
<ul>
<li><strong>语法</strong>：<code>(base_register)</code> 或 <code>[base_register]</code></li>
<li><strong>用途</strong>：指针解引用。</li>
<li><strong>示例</strong>：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl (%eax), %ebx     # 将EAX指向的内存值传入EBX</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov ebx, [eax]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>(3) 基址寻址（Base Addressing）</strong></p>
<ul>
<li><strong>语法</strong>：<code>offset(base_register)</code> 或 <code>[base_register + offset]</code></li>
<li><strong>用途</strong>：访问栈帧中的局部变量或结构体成员。</li>
<li><strong>示例</strong>：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl 8(%ebp), %ecx    # 从栈帧偏移8处读取数据到ECX</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov ecx, [ebp + 8]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>(4) 变址寻址（Indexed Addressing）比例寻址</strong></p>
<ul>
<li><strong>语法</strong>：<code>array(, index_register, scale)</code> 或 <code>[array + index_register*scale]</code></li>
<li><strong>用途</strong>：数组元素访问。</li>
<li><p><strong>示例</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl array(,%eax,4), %edx  # 数组array + EAX*4位置的值传入EDX（数组索引）</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edx, [array + eax*4]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>2. 组合寻址模式</strong></p>
<p><strong>(1) 基址 + 变址（Base + Index）</strong></p>
<ul>
<li><strong>语法</strong>：<code>(base_register, index_register)</code> 或 <code>[base_register + index_register]</code></li>
<li><strong>用途</strong>：访问二维数组或动态分配的数组。</li>
<li><p><strong>示例</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl (%ebx, %esi), %edi  # 将EBX + ESI指向的内存值传入EDI</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edi, [ebx + esi]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>(2) 基址 + 比例变址（Base + Index*Scale）</strong></p>
<ul>
<li><strong>语法</strong>：<code>(base_register, index_register, scale)</code> 或 <code>[base_register + index_register*scale]</code></li>
<li><strong>用途</strong>：按元素大小（scale）访问数组。</li>
<li><strong>示例</strong>：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl (%ebx, %esi, 4), %edi  # 将EBX + ESI*4指向的内存值传入EDI（4字节元素）</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edi, [ebx + esi*4]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>(3) 基址 + 比例变址 + 偏移（Base + Index*Scale + Offset）</strong></p>
<ul>
<li><strong>语法</strong>：<code>offset(base_register, index_register, scale)</code> 或 <code>[base_register + index_register*scale + offset]</code></li>
<li><strong>用途</strong>：访问结构体数组或复杂数据结构。</li>
<li><strong>示例</strong>：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl 12(%ebx, %esi, 8), %edi  # 结构体数组中第ESI个元素的偏移12处数据传入EDI</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mov edi, [ebx + esi*8 + 12]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>3.总结</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>寻址模式</th>
<th>AT&amp;T格式语法</th>
<th>Intel格式语法</th>
</tr>
</thead>
<tbody>
<tr>
<td>直接寻址</td>
<td><code>var(%rip)</code></td>
<td><code>[rip + var]</code>（64位）或 <code>var</code></td>
</tr>
<tr>
<td>寄存器间接寻址</td>
<td><code>(%eax)</code></td>
<td><code>[eax]</code></td>
</tr>
<tr>
<td>基址寻址</td>
<td><code>8(%ebp)</code></td>
<td><code>[ebp + 8]</code></td>
</tr>
<tr>
<td>变址寻址</td>
<td><code>array(,%eax,4)</code></td>
<td><code>[array + eax*4]</code></td>
</tr>
<tr>
<td>基址+比例变址</td>
<td><code>(%ebx, %esi, 4)</code></td>
<td><code>[ebx + esi*4]</code></td>
</tr>
<tr>
<td>基址+比例变址+偏移</td>
<td><code>12(%ebx, %esi, 8)</code></td>
<td><code>[ebx + esi*8 + 12]</code></td>
</tr>
</tbody>
</table>
</div>
<h4 id="指令后缀"><a href="#指令后缀" class="headerlink" title="指令后缀"></a>指令后缀</h4><p>在 AT&amp;T 汇编格式中，<strong>指令后缀</strong>（如 <code>b</code>、<code>w</code>、<code>l</code>、<code>q</code>）用于明确操作数的大小，确保汇编器正确生成机器码。判断后缀的核心规则是：<strong>根据操作数的大小选择对应的后缀</strong>，尤其是寄存器的位数或内存操作数的显式指定。以下是详细说明：</p>
<p><strong>后缀与操作数大小的对应关系</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>后缀</th>
<th>操作数大小</th>
<th>示例寄存器/操作数</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>b</code></td>
<td>byte（8位）</td>
<td><code>%al</code>, <code>$0x10</code>, <code>12(%ebp)</code>（需显式指定）</td>
</tr>
<tr>
<td><code>w</code></td>
<td>word（16位）</td>
<td><code>%ax</code>, <code>%bx</code>, <code>12(%ebp)</code>（需显式指定）</td>
</tr>
<tr>
<td><code>l</code></td>
<td>long（32位）</td>
<td><code>%eax</code>, <code>%ebx</code>, <code>12(%ebp)</code>（需显式指定）</td>
</tr>
<tr>
<td><code>q</code></td>
<td>quad（64位）</td>
<td><code>%rax</code>, <code>%rbx</code>, <code>12(%ebp)</code>（需显式指定）</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p><strong>立即数默认为32位</strong></p>
</blockquote>
<h4 id="判断“指针”与“临时变量"><a href="#判断“指针”与“临时变量" class="headerlink" title="判断“指针”与“临时变量"></a>判断“指针”与“临时变量</h4><p><strong>（1）<code>%edx</code>：临时变量</strong></p>
<ul>
<li><strong>特征</strong>：直接从寄存器 <code>%edx</code> 读取数据，不涉及内存地址的间接访问。</li>
<li><strong>对应C语言</strong>：<br>如果 <code>%edx</code> 存储的是某个局部变量或计算结果（如 <code>temp = a + b</code>），则对应<strong>临时变量</strong>。  </li>
</ul>
<p><strong>（2）<code>(%ecx)</code>：指针</strong></p>
<ul>
<li><strong>特征</strong>：<code>%ecx</code> 中存储的是内存地址，<code>(%ecx)</code> 表示解引用该地址（类似C语言的 <code>*ptr</code>）。  </li>
<li><strong>对应C语言</strong>：<br>如果 <code>%ecx</code> 存储的是一个指针变量（如 <code>int *ptr</code>），则 <code>(%ecx)</code> 对应<strong>指针解引用</strong>。  </li>
</ul>
<p><strong>关键结论</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>操作数</th>
<th>类型</th>
<th>判断依据</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>%edx</code></td>
<td>临时变量</td>
<td>直接从寄存器读取数据，无间接内存访问（无括号）。</td>
</tr>
<tr>
<td><code>(%ecx)</code></td>
<td>指针</td>
<td>使用括号 <code>(%ecx)</code> 表示解引用内存地址（类似C语言的 <code>*ptr</code>）。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>常见模式对比</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>汇编指令</th>
<th>C语言对应操作</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>movl %eax, (%ebx)</code></td>
<td><code>*ptr = temp;</code></td>
<td><code>%ebx</code> 是指针（存储地址），<code>%eax</code> 是临时变量。</td>
</tr>
<tr>
<td><code>movl (%ebx), %eax</code></td>
<td><code>temp = *ptr;</code></td>
<td>从指针 <code>ptr</code> 读取值到临时变量 <code>temp</code>。</td>
</tr>
<tr>
<td><code>movl $0x1, %eax</code></td>
<td><code>temp = 1;</code></td>
<td><code>%eax</code> 是临时变量，直接赋值。</td>
</tr>
</tbody>
</table>
</div>
<h4 id="汇编语言中M的作用"><a href="#汇编语言中M的作用" class="headerlink" title="汇编语言中M的作用"></a>汇编语言中M的作用</h4><p>在汇编语言中，<strong>M</strong> 通常表示 <strong>内存（Memory）</strong>，用于指示操作数来自内存地址。在你的问题中，<code>M[R[eax]]</code> 的含义是：</p>
<p><strong><code>M</code> 的作用</strong></p>
<ul>
<li><strong><code>M[地址]</code></strong> 表示从 <strong>内存地址为 <code>地址</code> 的位置读取数据</strong>。</li>
<li><strong><code>R[eax]</code></strong> 表示寄存器 <code>EAX</code> 的值（即 <code>EAX</code> 中存储的内容）。</li>
<li>因此，<code>M[R[eax]]</code> 的含义是：<blockquote>
<p><strong>以 <code>EAX</code> 寄存器的值作为内存地址，从该地址读取数据</strong>。</p>
</blockquote>
</li>
</ul>
<p><strong> AT&amp;T 汇编中的等价写法</strong></p>
<p>在 AT&amp;T 汇编语法中，<code>M[R[eax]]</code> 对应的写法是：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">addl (%eax), %edx</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>含义</strong>：<ul>
<li><code>(%eax)</code>：以 <code>EAX</code> 的值为内存地址，读取该地址的内容（默认是 4 字节，即 32 位）。</li>
<li><code>addl</code>：执行 32 位加法。</li>
<li><code>%edx</code>：目标寄存器，存储结果。</li>
</ul>
</li>
</ul>
<p><strong>关键点总结</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>R</code></td>
<td>寄存器（Register）</td>
<td><code>R[eax]</code> → <code>EAX</code> 的值</td>
</tr>
<tr>
<td><code>M</code></td>
<td>内存（Memory）</td>
<td><code>M[地址]</code> → 从地址读取数据</td>
</tr>
<tr>
<td><code>()</code></td>
<td>AT&amp;T 汇编中表示内存寻址</td>
<td><code>(%eax)</code> → 等价于 <code>M[R[eax]]</code></td>
</tr>
</tbody>
</table>
</div>
<h4 id="常见AT-amp-T格式汇编指令"><a href="#常见AT-amp-T格式汇编指令" class="headerlink" title="常见AT&amp;T格式汇编指令"></a>常见AT&amp;T格式汇编指令</h4><div class="table-container">
<table>
<thead>
<tr>
<th>指令类型</th>
<th>操作目的</th>
<th>影响标志位</th>
<th>典型用途</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>addl</code></td>
<td>加法</td>
<td>OF, SF, ZF, CF</td>
<td>数值运算、地址偏移</td>
</tr>
<tr>
<td><code>subl</code></td>
<td>减法</td>
<td>OF, SF, ZF, CF</td>
<td>数值运算、条件判断</td>
</tr>
<tr>
<td><code>orl</code></td>
<td>按位或</td>
<td>OF=0, SF, ZF, CF=0</td>
<td>位掩码操作</td>
</tr>
<tr>
<td><code>testl</code></td>
<td>按位与测试</td>
<td>OF=0, SF, ZF, CF=0</td>
<td>条件判断（如检查位是否设置）</td>
</tr>
<tr>
<td><code>imull</code></td>
<td>有符号乘法</td>
<td>OF, CF</td>
<td>数值运算</td>
</tr>
<tr>
<td><code>leal</code></td>
<td>地址计算</td>
<td>无影响</td>
<td>高效数组索引计算</td>
</tr>
<tr>
<td><code>decl</code></td>
<td>递减</td>
<td>OF, SF, ZF, CF</td>
<td>循环计数、边界检查</td>
</tr>
</tbody>
</table>
</div>
<p><strong><code>sall</code>（Shift Arithmetic Left）—— 左移指令</strong></p>
<p><strong>功能</strong></p>
<ul>
<li><strong>作用</strong> ：将操作数的二进制位 <strong>向左移动</strong> 指定的位数，低位补0。</li>
<li><strong>效果</strong> ：相当于将操作数乘以 2<em>n</em> （n 为移动的位数）。</li>
</ul>
<p><strong><code>and</code>（Logical AND）—— 逻辑与指令</strong></p>
<p><strong>功能</strong></p>
<ul>
<li><strong>作用</strong> ：对两个操作数进行 <strong>按位与运算</strong> ，结果写入目标操作数。</li>
<li><strong>效果</strong> ：只有对应位都为1时，结果位才为1。</li>
</ul>
<p><code>shrl</code> 是 <strong>逻辑右移指令</strong> （Shift Right Logical），用于对操作数进行 <strong>无符号右移</strong> ，即高位补 0，低位移出。</p>
<p><code>leal</code> 是 <strong>加载有效地址（Load Effective Address）</strong> 的指令，其功能是 <strong>计算内存地址并存储到目标寄存器</strong> ，但 <strong>不会访问内存</strong> 。它常用于 <strong>地址计算</strong> 和 <strong>高效算术运算</strong> </p>
<h4 id="标志位"><a href="#标志位" class="headerlink" title="标志位"></a>标志位</h4><p>以下是 <strong>x86/x64 架构中常见的四个状态标志位</strong>（OF、SF、ZF、CF）的详细说明及其判断方法：</p>
<p><strong>1. 标志位概述</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>标志</th>
<th>全称</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CF</strong></td>
<td>Carry Flag</td>
<td><strong>无符号溢出标志</strong>：表示无符号数运算是否产生进位或借位。</td>
</tr>
<tr>
<td><strong>ZF</strong></td>
<td>Zero Flag</td>
<td><strong>零标志</strong>：表示运算结果是否为零。</td>
</tr>
<tr>
<td><strong>SF</strong></td>
<td>Sign Flag</td>
<td><strong>符号标志</strong>：表示运算结果的最高位（符号位）是否为1（负数）。</td>
</tr>
<tr>
<td><strong>OF</strong></td>
<td>Overflow Flag</td>
<td><strong>溢出标志</strong>：表示有符号数运算是否溢出（结果超出数据类型表示范围）。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>2. 判断方法详解</strong></p>
<p><strong>(1) 进位标志（CF）</strong></p>
<ul>
<li><strong>用途</strong>：判断 <strong>无符号数运算</strong> 是否溢出。</li>
<li><strong>判断规则</strong>：<ul>
<li><strong>加法</strong>：若结果最高位（最高有效位）发生进位（超过数据类型的最大值），CF=1。</li>
<li><strong>减法</strong>：若结果需要借位（被减数 &lt; 减数），CF=1。</li>
</ul>
</li>
</ul>
<p><strong>(2) 零标志（ZF）</strong></p>
<ul>
<li><strong>用途</strong>：判断运算结果是否为零。</li>
<li><strong>判断规则</strong>：<ul>
<li><strong>结果为0</strong> → ZF=1</li>
<li><strong>结果非0</strong> → ZF=0</li>
</ul>
</li>
</ul>
<p><strong>(3) 符号标志（SF）</strong></p>
<ul>
<li><strong>用途</strong>：表示运算结果的符号（正/负）。</li>
<li><strong>判断规则</strong>：<ul>
<li><strong>结果最高位为1</strong>（负数）→ SF=1</li>
<li><strong>结果最高位为0</strong>（正数）→ SF=0</li>
</ul>
</li>
</ul>
<p><strong>(4) 溢出标志（OF）</strong></p>
<ul>
<li><strong>用途</strong>：判断 <strong>有符号数运算</strong> 是否溢出。</li>
<li><strong>判断规则</strong>：<ul>
<li><strong>溢出条件</strong>：两个正数相加结果为负，或两个负数相加结果为正 → OF=1。</li>
<li><strong>无溢出</strong>：其他情况 → OF=0。</li>
</ul>
</li>
</ul>
<h4 id="栈帧布局和参数偏移计算规则"><a href="#栈帧布局和参数偏移计算规则" class="headerlink" title="栈帧布局和参数偏移计算规则"></a>栈帧布局和参数偏移计算规则</h4><p><a href="https://www.bilibili.com/video/BV1sV411b7c1/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】3-3.栈与数据传送指令_哔哩哔哩_bilibili</a></p>
<p><strong>1. 参数压栈顺序</strong></p>
<p>C语言默认使用 <strong><code>cdecl</code> 调用约定</strong>，参数<strong>从右到左</strong>压入栈中。例如，函数调用 <code>operate(x, y, z, k)</code> 的压栈顺序为：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">push k;     <span class="comment">// 第四个参数（最右边）</span></span><br><span class="line">push z;     <span class="comment">// 第三个参数</span></span><br><span class="line">push y;     <span class="comment">// 第二个参数</span></span><br><span class="line">push x;     <span class="comment">// 第一个参数（最左边）</span></span><br><span class="line">call operate;</span><br></pre></td></tr></table></figure><br>栈中参数布局（高地址 → 低地址）：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">高地址</span><br><span class="line">| k  (参数4) | ← 栈顶（ESP）</span><br><span class="line">| z  (参数3) |</span><br><span class="line">| y  (参数2) |</span><br><span class="line">| x  (参数1) |</span><br><span class="line">| 返回地址   |</span><br><span class="line">低地址</span><br></pre></td></tr></table></figure></p>
<p><strong>2. 栈帧建立过程</strong></p>
<p>进入函数 <code>operate</code> 后，通过以下指令建立栈帧：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pushl %ebp        ; 保存旧的EBP（栈帧基址）</span><br><span class="line">movl %esp, %ebp   ; 将当前栈顶（ESP）赋值给EBP，作为新栈帧的基址</span><br></pre></td></tr></table></figure><br>此时栈帧布局如下：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">高地址</span><br><span class="line">| k  (参数4) | ← EBP + 20</span><br><span class="line">| z  (参数3) | ← EBP + 16</span><br><span class="line">| y  (参数2) | ← EBP + 12</span><br><span class="line">| x  (参数1) | ← EBP + 8</span><br><span class="line">| 返回地址   | ← EBP + 4</span><br><span class="line">| 旧 EBP     | ← EBP</span><br><span class="line">低地址</span><br></pre></td></tr></table></figure></p>
<p><strong>3. 参数地址的计算逻辑</strong></p>
<ul>
<li><strong><code>EBP + 4</code></strong>：返回地址（由 <code>call</code> 指令自动压栈）。  </li>
<li><strong><code>EBP + 8</code></strong>：第一个参数（<code>x</code>）。  </li>
<li><strong><code>EBP + 12</code></strong>：第二个参数（<code>y</code>）。  </li>
<li><strong><code>EBP + 16</code></strong>：第三个参数（<code>z</code>）。  </li>
<li><strong><code>EBP + 20</code></strong>：第四个参数（<code>k</code>）。  </li>
</ul>
<p><strong>原因</strong>：  </p>
<ol>
<li><strong>参数顺序</strong>：参数从右到左压栈，导致第一个参数（<code>x</code>）位于栈的最低地址（<code>EBP + 8</code>），而第四个参数（<code>k</code>）位于最高地址（<code>EBP + 20</code>）。  </li>
<li><strong>偏移计算</strong>：每个参数占用4字节（32位系统中 <code>int</code> 和指针大小），因此偏移量依次递增4。  </li>
<li><strong>栈帧基址</strong>：<code>EBP</code> 指向旧的 <code>EBP</code> 值，其上方是返回地址（<code>EBP + 4</code>），再上方是参数。</li>
</ol>
<h4 id="汇编语言表示程序函数的过程调用"><a href="#汇编语言表示程序函数的过程调用" class="headerlink" title="汇编语言表示程序函数的过程调用"></a>汇编语言表示程序函数的过程调用</h4><p><a href="https://www.bilibili.com/video/BV1Nt4y1G728/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">超硬核！408考研重点！汇编语言表示程序函数的过程调用！23王道计算机组成原理指令系统_哔哩哔哩_bilibili</a></p>
<h4 id="反汇编"><a href="#反汇编" class="headerlink" title="反汇编"></a>反汇编</h4><p>反汇编代码是将二进制机器码（如可执行文件、内存转储）转换为 <strong>人类可读的汇编指令</strong> 的结果。它是逆向工程、漏洞分析、调试等领域的核心工具。以下是详细说明：</p>
<p><strong>1. 反汇编代码的定义</strong></p>
<ul>
<li><strong>本质</strong>：将机器码（二进制/十六进制）转换为对应的汇编指令。</li>
<li><strong>作用</strong>：帮助开发者理解程序逻辑、分析恶意软件、调试崩溃原因或研究编译器优化。</li>
</ul>
<p><strong>2. 反汇编代码的典型格式</strong></p>
<p>反汇编代码通常包含以下部分：<br>| <strong>字段</strong>                  | <strong>说明</strong>                                           | <strong>示例</strong>                     |<br>| ————————————- | ————————————————————————— | —————————————— |<br>| <strong>地址（Address）</strong>       | 指令在内存中的地址（十六进制）。                   | <code>0x804838c</code>                  |<br>| <strong>机器码（Opcode）</strong>      | 对应的原始十六进制机器码（机器指令的二进制表示）。 | <code>74 08</code>                      |<br>| <strong>汇编指令（Mnemonic）</strong>  | 汇编助记符（如 <code>mov</code>, <code>jmp</code>, <code>call</code>）及操作数。    | <code>je 0x8048396</code>               |<br>| <strong>注释（Comment, 可选）</strong> | 开发者添加的注释（某些工具会自动生成符号信息）。   | <code>; if (eax == 0) goto label</code> |</p>
<p><strong>示例反汇编代码（AT&amp;T格式）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0804838c &lt;main&gt;:</span><br><span class="line">804838c:    74 08                   je     8048396 &lt;main+0xa&gt;</span><br><span class="line">804838e:    b8 00 00 00 00          mov    $0x0, %eax</span><br><span class="line">8048393:    e9 0e 00 00 00          jmp    80483a6 &lt;main+0x1a&gt;</span><br></pre></td></tr></table></figure>
<h4 id="大端小端"><a href="#大端小端" class="headerlink" title="大端小端"></a>大端小端</h4><p><strong>小端方式（Little-Endian）</strong> 是一种 <strong>数据在内存中的存储顺序</strong>，其核心特点是：</p>
<blockquote>
<p><strong>数据的低位字节（LSB, Least Significant Byte）存储在内存的低地址处，高位字节（MSB, Most Significant Byte）存储在高地址处</strong>。</p>
</blockquote>
<p><strong>1. 小端 vs 大端</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>小端（Little-Endian）</strong></th>
<th><strong>大端（Big-Endian）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>存储顺序</strong></td>
<td>低位字节在前（低地址），高位在后</td>
<td>高位字节在前（低地址），低位在后</td>
</tr>
<tr>
<td><strong>示例</strong></td>
<td><code>0x12345678</code> → 存储为 <code>78 56 34 12</code></td>
<td><code>0x12345678</code> → 存储为 <code>12 34 56 78</code></td>
</tr>
<tr>
<td><strong>常见平台</strong></td>
<td>x86/x64 架构（Intel/AMD 处理器）</td>
<td>ARM（部分模式）、网络协议（TCP/IP）</td>
</tr>
</tbody>
</table>
</div>
<p><strong>2. 小端方式的直观理解</strong></p>
<p><strong>示例：32位整数 <code>0x12345678</code></strong></p>
<ul>
<li><strong>内存地址分配</strong>：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">地址 →    0x1000    0x1001    0x1002    0x1003</span><br><span class="line">         +---------+---------+---------+---------+</span><br><span class="line">         |  0x78   |  0x56   |  0x34   |  0x12   |</span><br><span class="line">         +---------+---------+---------+---------+</span><br></pre></td></tr></table></figure></li>
<li><strong>解释</strong>：<ul>
<li>数据的最低位字节 <code>0x78</code> 存储在最低地址 <code>0x1000</code>。</li>
<li>高位字节 <code>0x12</code> 存储在最高地址 <code>0x1003</code>。</li>
</ul>
</li>
</ul>
<h4 id="转移目标地址的计算"><a href="#转移目标地址的计算" class="headerlink" title="转移目标地址的计算"></a>转移目标地址的计算</h4><p>在 IA-32（x86）架构中，<strong>转移目标地址的计算</strong>依赖于 <strong>指令的长度</strong> 和 <strong>相对偏移量（Displacement）</strong>。以下是详细分析：</p>
<p><strong>1. 转移指令的基本原理</strong></p>
<ul>
<li><strong>相对跳转（Relative Jump）</strong>：转移目标地址 = <strong>下一条指令地址</strong> + <strong>偏移量</strong>。</li>
<li><strong>偏移量</strong>：有符号的 8 位、16 位或 32 位整数，表示从 <strong>下一条指令地址</strong> 开始的偏移（正向或负向）。</li>
<li><strong>小端方式（Little-Endian）</strong>：多字节偏移量需按小端方式存储（低位字节在前）。</li>
</ul>
<p><strong>2. 示例：<code>call</code> 指令的地址计算</strong></p>
<p><strong>(1) 已知条件</strong></p>
<ul>
<li><strong>指令地址</strong>：<code>0x804838e</code>（<code>call</code> 指令的起始地址）。</li>
<li><strong>机器码</strong>：<code>E8 1E 00 00 00</code>。<ul>
<li><code>E8</code> 是 <code>call</code> 的操作码。</li>
<li><code>1E 00 00 00</code> 是偏移量（小端方式存储）。</li>
</ul>
</li>
</ul>
<p><strong>(2) 计算步骤</strong></p>
<ol>
<li><strong>确定指令长度</strong>：<ul>
<li><code>call</code> 指令占 <strong>5 字节</strong>（1 字节操作码 + 4 字节偏移量）。</li>
</ul>
</li>
<li><strong>计算下一条指令地址</strong>：<ul>
<li>下一条指令地址 = 当前指令地址 + 指令长度<br>= <code>0x804838e + 5 = 0x8048393</code>。</li>
</ul>
</li>
<li><strong>解析偏移量</strong>：<ul>
<li>偏移量字段为 <code>1E 00 00 00</code>（小端方式）→ 转换为大端顺序为 <code>0x0000001E</code>（十进制 30）。</li>
</ul>
</li>
<li><strong>计算转移目标地址</strong>：<ul>
<li>转移目标地址 = 下一条指令地址 + 偏移量<br>= <code>0x8048393 + 0x1E = 0x80483B1</code>。</li>
</ul>
</li>
</ol>
<p><strong>3. 核心公式</strong></p>
<script type="math/tex; mode=display">
\text{目标地址} = (\text{当前指令地址} + \text{指令长度}) + \text{偏移量}</script><ul>
<li><strong>当前指令地址</strong>：指令的起始地址（如 <code>0x804838e</code>）。</li>
<li><strong>指令长度</strong>：由操作码和操作数决定（如 <code>call</code> 占 5 字节）。</li>
<li><strong>偏移量</strong>：从指令的操作数中提取并转换为有符号整数。</li>
</ul>
<p><strong>9. 其他指令示例</strong></p>
<p><strong>(1) <code>je</code> 指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">804838c:    74 08                   je     0x8048396</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>当前地址</strong>：<code>0x804838c</code>。</li>
<li><strong>指令长度</strong>：2 字节。</li>
<li><strong>偏移量</strong>：<code>0x08</code>（单字节，无需反转）。</li>
<li><strong>目标地址</strong>：<code>0x804838c + 2 + 0x08 = 0x8048396</code>。</li>
</ul>
<p><strong>(2) <code>jmp</code> 指令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">80483a4:    E9 F6 FF FF FF          jmp    0x804839f</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>当前地址</strong>：<code>0x80483a4</code>。</li>
<li><strong>指令长度</strong>：5 字节。</li>
<li><strong>偏移量</strong>：<code>F6 FF FF FF</code>（小端）→ 补码为 <code>-10</code>（十进制）。</li>
<li><strong>目标地址</strong>：<code>0x80483a4 + 5 + (-10) = 0x804839f</code>。</li>
</ul>
<h4 id="计算下一条指令地址"><a href="#计算下一条指令地址" class="headerlink" title="计算下一条指令地址"></a><strong>计算下一条指令地址</strong></h4><p>下一条指令地址=当前指令地址+当前指令长度</p>
<h3 id="第四章-程序的链接"><a href="#第四章-程序的链接" class="headerlink" title="第四章 程序的链接"></a>第四章 程序的链接</h3><h4 id="重定位"><a href="#重定位" class="headerlink" title="重定位"></a>重定位</h4><p><a href="https://www.bilibili.com/video/BV1JL411L7ku?spm_id_from=333.788.videopod.sections&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】7-6. 重定位_哔哩哔哩_bilibili</a></p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p><a href="https://www.bilibili.com/video/BV1oe411n72U/?spm_id_from=333.337.search-card.all.click">3分钟彻底理解链接器_哔哩哔哩_bilibili</a></p>
<p><a href="https://blog.csdn.net/gzxb1995/article/details/105088502">计算机系统基础摘记——程序的链接_引入链接的好处是什么-CSDN博客</a></p>
<p><a href="https://www.bilibili.com/video/BV1oS4y1T7Uf?spm_id_from=333.788.player.switch&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">【CSAPP-深入理解计算机系统】7-5. 静态库的解析过程_哔哩哔哩_bilibili</a></p>
<h3 id="其他-1"><a href="#其他-1" class="headerlink" title="其他"></a>其他</h3><p>gdb调试</p>
<p><a href="https://www.bilibili.com/video/BV1Sg41167B1/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">一分钟学会GDB程序调试_哔哩哔哩_bilibili</a></p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://www.bilibili.com/video/BV17K4y1N7Q2?spm_id_from=333.788.videopod.episodes&amp;vd_source=bacf29bd4bb51f2ecf08a1ac7c7d8f11">深入理解计算机系统合集（周更中）_哔哩哔哩_bilibili</a></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——Python常用库</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84Python%E5%B8%B8%E7%94%A8%E5%BA%93/</url>
    <content><![CDATA[<h2 id="Python常用库"><a href="#Python常用库" class="headerlink" title="Python常用库"></a>Python常用库</h2><h3 id="1-Numpy"><a href="#1-Numpy" class="headerlink" title="1. Numpy"></a>1. Numpy</h3><p>numpy（Numerical Python的简称）是高性能科学计算和数据分析的基础包。其部分功能如下：</p>
<p>ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。 用于对整组数据进行快速运算的标准数学函数（无需编写循环）。 用于读写磁盘数据的工具以及用于操作内存映射文件的工具。 线性代数、随机数生成以及傅里叶变换功能。 用于集成由C、C++、Fortran等语言编写的代码的工具。</p>
<h3 id="2-Pandas"><a href="#2-Pandas" class="headerlink" title="2. Pandas"></a>2. Pandas</h3><p>pandas是python第三方库，提供高性能易用数据类型和分析工具 pandas基于numpy实现，常与numpy和matplotlib一同使用 pandas中有两大核心数据结构：Series（一维数据） 和 DataFrame（多特征数据,既有行索引,又有列索引）</p>
<h3 id="3-PIL"><a href="#3-PIL" class="headerlink" title="3. PIL"></a>3. PIL</h3><p>PIL库是一个具有强大图像处理能力的第三方库 在命令行下的安装方法：pip install pillow 在使用过程中的引入方法：from PIL import Image Image 是 PIL 库中代表一个图像的类（对象） 图像是一个由像素组成的二维矩阵，每个元素是一个RGB值</p>
<h3 id="4-Matplotlib"><a href="#4-Matplotlib" class="headerlink" title="4. Matplotlib"></a>4. Matplotlib</h3><p>Matplotlib库由各种可视化类构成，内部结构复杂。 受Matlab启发，matplotlib.pylot是绘制各类可视化图形的命令字库，相当于快捷方式。</p>
<h3 id="5-scikit-learn"><a href="#5-scikit-learn" class="headerlink" title="5. scikit-learn"></a>5. scikit-learn</h3><p><code>scikit-learn</code>（简称 <code>sklearn</code>）是一个开源的 Python 库，广泛应用于机器学习任务，提供了丰富的工具和算法，能够帮助数据科学家和机器学习工程师高效地进行数据预处理、模型训练、评估和优化。它基于 <code>NumPy</code>、<code>SciPy</code> 和 <code>matplotlib</code>，具有以下主要特点和功能：</p>
<h4 id="主要功能："><a href="#主要功能：" class="headerlink" title="主要功能："></a><strong>主要功能</strong>：</h4><ul>
<li><strong>分类 (Classification)</strong> ：用于预测数据点所属的类别（如垃圾邮件分类、疾病预测等）。</li>
<li><strong>回归 (Regression)</strong> ：用于预测连续的数值（如房价预测、股票价格预测等）。</li>
<li><strong>聚类 (Clustering)</strong> ：将数据点分为不同的簇或组（如客户细分、图像分割等）。</li>
<li><strong>降维 (Dimensionality Reduction)</strong> ：减少数据的维度，常用于数据压缩和可视化。</li>
<li><strong>模型评估 (Model Evaluation)</strong> ：提供评估工具，如交叉验证、准确率、F1 分数等。</li>
<li><strong>数据预处理 (Data Preprocessing)</strong> ：包括标准化、归一化、缺失值处理、编码等。</li>
<li><strong>超参数调优 (Hyperparameter Tuning)</strong> ：通过网格搜索（GridSearchCV）和随机搜索（RandomizedSearchCV）来优化模型超参数。</li>
</ul>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——课后答案</title>
    <url>/2025/03/12/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E8%AF%BE%E5%90%8E%E4%B9%A0%E9%A2%98%E5%8F%82%E8%80%83%E7%AD%94%E6%A1%88/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a><a href="#说明">说明</a></h2><h1 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h1><h2 id="版本信息"><a href="#版本信息" class="headerlink" title="版本信息"></a>版本信息</h2><p>书名：《计算机系统基础（第二版）》 袁春风</p>
<p>整理日期：2019-10-27 </p>
<p>整理人：李加其（幽弥狂）</p>
<p>内容：课后习题参考答案 </p>
<p>联系方式：13812991101</p>
<p>邮箱：1768478912@qq.com</p>
<p>QQ:1768478912</p>
<p>版本：v1.0</p>
<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><p>1、如果有侵权或者其他问题欢迎联系我。</p>
<p>2、参考书目为<a href="https://github.com/JackeyLea/NJUCS中README.md文件中列出的参考书目。">https://github.com/JackeyLea/NJUCS中README.md文件中列出的参考书目。</a></p>
<p>3、红色字体为重要内容，比如曾作为课后习题、考试考过等等。</p>
<p>4、括号里的P**表示在书本的第几页。</p>
<h1 id="第一部分-系统概述和可执行目标文件的生成"><a href="#第一部分-系统概述和可执行目标文件的生成" class="headerlink" title="第一部分 系统概述和可执行目标文件的生成"></a>第一部分 系统概述和可执行目标文件的生成</h1><h2 id="第一章计算机系统概述"><a href="#第一章计算机系统概述" class="headerlink" title="第一章计算机系统概述"></a>第一章计算机系统概述</h2><p>1、见《计算机系统基础习题解答与教学指导》</p>
<p>2、简单回答下列问题。</p>
<p>（1）冯·诺依曼计算机由哪几部分组成？各部分的功能是什么？</p>
<pre><code>控制器：用于控制主动执行指令；

运算器：用于执行指令；

存储器：存放数据和指令；

输入输出设备：通过输入输出设备使用计算机；
</code></pre><p>（2）什么是“存储程序”工作方式？</p>
<pre><code>必须将事先编好的程序和原始数据送人主存后才开能执行程序，一旦程序被启动执行，计算机能在必须操作人员干预的情况下自动完成逐条指令取出和执行任务。（P3）
</code></pre><p>（3）一条指令的执行过程包含哪几个阶段？</p>
<pre><code>程序的执行就是指令的执行过程。

阶段：
取指令、取数、传数、ALU运算阶段。（P6）
</code></pre><p>（4）计算机系统的层次结构如何划分？</p>
<pre><code>电路设计、数字设计、ISA、汇编程序、编译程序、应用程序、操作系统（P18 图1.11）
</code></pre><p>（5）计算机系统的用户可分哪几类？每类用户工作在哪个层次？</p>
<pre><code>   用户有四种：

   最终用户：应用程序级

   系统管理员：操作系统

   应用程序员：编译程序

   系统程序员：汇编程序和ISA之间
</code></pre><p>（6）程序的 CPI 与哪些因素有关？</p>
<pre><code>总时钟周期数、指令条数（P20）
</code></pre><p>（7）为什么说性能指标 MIPS 不能很好地反映计算机的性能？</p>
<pre><code>MIPS反映了机器执行定点指令的速度。首先，不同机器的指令集是不同的，而且指令的功能也是不同的，也许在机器1上一条指令完成的功能机器2需要多条指令。其次，不同机器的CPI和时钟周期也是不同的，因此同一条指令在不同的机器上所用的时间也不同。（P20 最后一段）
</code></pre><p>3、略</p>
<p>4、略</p>
<p>5、题目略</p>
<p>仿照图1.3</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>主存地址</th>
<th>主存单元地址</th>
<th>内容说明（Ii表示第i条指令）</th>
<th>指令的符号表示</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1110 0111</td>
<td>I1：R[0]←M[7]；op=1110；取数操作</td>
<td>load r0,7#</td>
</tr>
<tr>
<td>1</td>
<td>0000 0100</td>
<td>I2：R[1]←R[0]；op=0000；传送操作</td>
<td>mov r1,r0</td>
</tr>
<tr>
<td>2</td>
<td>1110 0101</td>
<td>I3：R[0]←M[6]；op=1110；取数操作</td>
<td>load r0,6#</td>
</tr>
<tr>
<td>3</td>
<td>0010 0001</td>
<td>I4：R[0]←R[0]-R[1]；op=0010；减操作</td>
<td>sub r0,r1</td>
</tr>
<tr>
<td>4</td>
<td>0011 0001</td>
<td>I5：R[0]←R[0]*R[1]；op=0011；乘操作</td>
<td>mul r0,r1</td>
</tr>
<tr>
<td>5</td>
<td>1111 1000</td>
<td>I6：M[8]←R[0]；op=1111；存数操作</td>
<td>store 8#,r0</td>
</tr>
<tr>
<td>6</td>
<td>0001 0000</td>
<td>操作数x，值为16</td>
<td></td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>0010 0001</td>
<td>操作数y，值为33</td>
<td></td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>0000 0000</td>
<td>结果z，初始值为0</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>仿照图1.5 </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>I1:1110 0111</th>
<th>I2：0000 0100</th>
<th>I3：1110 0101</th>
<th>I4：0010 0001</th>
<th>I5：0011 0001</th>
<th>I6：1111 1000</th>
</tr>
</thead>
<tbody>
<tr>
<td>取指令</td>
<td>IR←M[0000]</td>
<td>IR←M[0001]</td>
<td>IR←M[0010]</td>
<td>IR←M[0011]</td>
<td>IR←M[0100]</td>
<td>IR←M[0101]</td>
</tr>
<tr>
<td>指令译码</td>
<td>op=1110，取数</td>
<td>op=0000，传送</td>
<td>op=1110，取数</td>
<td>op=0010，减</td>
<td>op=0011，乘</td>
<td>op=1111，存数</td>
</tr>
<tr>
<td>PC增量</td>
<td>PC←0000+1</td>
<td>PC←0001+1</td>
<td>PC←0010+1</td>
<td>PC←0011+1</td>
<td>PC←0100+1</td>
<td>PC←0101+1</td>
</tr>
<tr>
<td>取数并执行</td>
<td>MDR←M[0110]</td>
<td>A←R[0]、mov</td>
<td>MDR←M[0101]</td>
<td>A←R[0]、B←R[1]、sub</td>
<td>A←R[0]、B←R[1]、mul</td>
<td>MDR←R[0]</td>
</tr>
<tr>
<td>送结果</td>
<td>R[0]←MDR</td>
<td>R[1]←F</td>
<td>R[0]←MDR</td>
<td>R[0]←F</td>
<td>R[0]←F</td>
<td>M[1000]←MDR</td>
</tr>
<tr>
<td>执行结果</td>
<td>R[0]=33</td>
<td>R[1]=33</td>
<td>R[0]=16</td>
<td>R[0]=16-33=-17</td>
<td>R[0]=-17×33</td>
<td>M[8]=-561</td>
</tr>
</tbody>
</table>
</div>
<p>6、若有两个基准测试程序P1和P2在机器M1和M2上运行，假定M1和M2的价格分别是5000元和8000元，下表给出了P1和P2在M1和M2上所花的时间和指令条数。</p>
<table>
    <tr>
        <th rowspan="2">程序</th>
        <th colspan="2">M1</th>
        <th colspan="2">M2</th>
    </tr>
    <tr>
        <td>指令条数</td>
        <td>执行时间(ms)</td>
        <td>指令条数</td>
        <td>执行时间(ms)</td>
    </tr>
    <tr>
        <td>P1</td>
        <td>200×10^6</td>
        <td>10000</td>
        <td>150×10^6</td>
        <td>5000</td>
    </tr>
    <tr>
        <td>P2</td>
        <td>300×10^3</td>
        <td>3</td>
        <td>420×10^3</td>
        <td>6</td>
    </tr>
</table>

<p>请回答下列问题：</p>
<p>（1）对于P1，哪台机器的速度快？快多少？对于P2呢？</p>
<pre><code>对于P1，M2比M1快一倍；对于P2，M1比M2快一倍。
</code></pre><p>（2）在M1上执行P1和P2的速度分别是多少MIPS？在M2上的执行速度又各是多少？从执行速度来看，对于P2，哪台机器的速度快？快多少？</p>
<pre><code>对于M1，P1的速度为：200M/10=20MIPS；P2为300k/0.003=100MIPS。

对于M2，P1的速度为：150M/5=30MIPS；P2为420k/0.006=70MIPS。

从执行速度来看，对于P2，因为100/70=1.43倍，所以M1比M2快0.43倍。
</code></pre><p>（3）假定M1和M2的时钟频率各是800MHz和1.2GHz，则在M1和M2上执行P1时的平均时钟周期数CPI各是多少？ </p>
<pre><code>在M1上执行P1时的平均时钟周期数CPI为：10×800M/(200×106)=40。

在M2上执行P1时的平均时钟周期数CPI为：5×1.2G/(150×106)=40。
</code></pre><p>（4）如果某个用户需要大量使用程序P1，并且该用户主要关心系统的响应时间而不是吞吐率，那么，该用户需要大批购进机器时，应该选择M1还是M2？为什么？（提示：从性价比上考虑）</p>
<pre><code>考虑运行P1时M1和M2的性价比，因为该用户主要关心系统的响应时间，所以性价比中的性能应考虑执行时间，其性能为执行时间的倒数。故性价比R为：

R=1/(执行时间×价格)

R越大说明性价比越高，也即，“执行时间×价格”的值越小，则性价比越高。

因为10×5000 &gt; 5×8000，所以，M2的性价比高。应选择M2。
</code></pre><p>（5）如果另一个用户也需要购进大批机器，但该用户使用P1和P2一样多，主要关心的也是响应时间，那么，应该选择M1还是M2？为什么？</p>
<pre><code>P1和P2需要同等考虑，性能有多种方式：执行时间总和、算术平均、几何平均。

若用算术平均方式，则：因为 (10+0.003)/2×5000 &gt; (5+0.006)/2×8000，所以M2的性价比高，应选择M2。

若用几何平均方式，则：因为sqrt(10×0.003) ×5000 &lt; sqrt(5×0.006) ×8000，所以M1的性价比高，应选择M1。
</code></pre><p>7．若机器M1和M2具有相同的指令集，其时钟频率分别为1GHz和1.5GHz。在指令集中有五种不同类型的指令A~E。下表给出了在M1和M2上每类指令的平均时钟周期数CPI。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>机器</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr>
<td>M1</td>
<td>1</td>
<td>2</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>M2</td>
<td>2</td>
<td>2</td>
<td>4</td>
<td>5</td>
<td>6</td>
</tr>
</tbody>
</table>
</div>
<p>请回答下列问题：<br>（1）M1和M2的峰值MIPS各是多少？</p>
<pre><code>M1上可以选择一段都是A类指令组成的程序，其峰值MIPS为1000MIPS。
M2上可以选择一段A和B类指令组成的程序，其峰值MIPS为1500/2=750MIPS。
</code></pre><p>（2）假定某程序P的指令序列中，五类指令具有完全相同的指令条数，则程序P在M1和M2上运行时，哪台机器更快？快多少？在M1和M2上执行程序P时的平均时钟周期数CPI各是多少？</p>
<pre><code>5类指令具有完全相同的指令条数，所以各占20%。
在M1和M2上执行程序P时的平均时钟周期数CPI分别为：
    M1：20%×(1+2+2+3+4)= 0.2×12 = 2.4
    M2：20%×(2+2+4+5+6)= 0.2×19 = 3.8
假设程序P的指令条数为N，则在M1和M2上的执行时间分别为：
    M1：2.4× N×1/1G = 2.4N (ns)
    M2：3.8×N×1/1.5G = 2.53 N (ns)
M1执行P的速度更快，每条指令平均快0.13ns，也即M1比M2快0.13/2.53×100%≈5%。
</code></pre><p>8．假设同一套指令集用不同的方法设计了两种机器M1和M2。机器M1的时钟周期为0.8ns，机器M2的时钟周期为1.2ns。某个程序P在机器M1上运行时的CPI为4，在M2上的CPI为2。对于程序P来说，哪台机器的执行速度更快？快多少？</p>
<pre><code>假设程序P的指令条数为N，则在M1和M2上的执行时间分别为：
    M1：4 N×0.8 = 3.2N (ns)
    M2：2 N×1.2 = 2.4 N (ns)  
所以，M2执行P的速度更快，每条指令平均快0.8ns，比M1快0.8/3.2×100%=25%。
</code></pre><p>9．假设某机器M的时钟频率为4GHz，用户程序P在M上的指令条数为8×109，其CPI为1.25，则P在M上的执行时间是多少？若在机器M上从程序P开始启动到执行结束所需的时间是4秒，则P占用的CPU时间的百分比是多少？</p>
<pre><code>程序P在M上的执行时间为：1.25×8××1/4G = 2.5 s，
从启动P执行开始到执行结束的总时间为4秒，
其中2.5秒是P在CPU上真正的执行时间，
其他时间可能执行操作系统程序或其他用户程序。
程序P占用的CPU时间的百分比为：2.5/4 = 62.5%。
</code></pre><p>10．假定某编译器对某段高级语言程序编译生成两种不同的指令序列S1和S2，在时钟频率为500MHz的机器M上运行，目标指令序列中用到的指令类型有A、B、C和D四类。四类指令在M上的CPI和两个指令序列所用的各类指令条数如下表所示。<br>| | A    | B    | C    | D |<br>|—| —-|—-|—-|—-|<br>各指令的CPI    1    2    3    4<br>S1的指令条数    5    2    2    1<br>S2的指令条数    1    1    1    5</p>
<p>请问：S1和S2各有多少条指令？CPI各为多少？所含的时钟周期数各为多少？执行时间各为多少？</p>
<pre><code>S1有10条指令，CPI为 (5×1+2×2+2×3+1×4)/10=1.9, 所含的时钟周期数为10×1.9=19，执行时间为19/500M = 38ns。
S2有8条指令，CPI为 (1×1+1×2+1×3+5×4)/8 =3.25, 所含的时钟周期数为8×3.25=26，执行时间为26/500M = 52ns。 
</code></pre><p>10．假定机器M的时钟频率为1.2GHz，某程序P在机器M上的执行时间为12秒钟。对P优化时，将其所有的乘4指令都换成了一条左移2位的指令，得到优化后的程序P’。已知在M上乘法指令的CPI为5，左移指令的CPI为2，P的执行时间是P’执行时间的1.2倍，则P中有多少条乘法指令被替换成了左移指令被执行？<br>参考答案：<br>显然，P’的执行时间为10秒，因此，P比P’多花了2秒钟，因此，执行时被换成左移指令的乘法指令的条数为1.2G×2/(5–2) = 800M。</p>
<h2 id="第二章计算机系统基本功能和基本组成"><a href="#第二章计算机系统基本功能和基本组成" class="headerlink" title="第二章计算机系统基本功能和基本组成"></a>第二章计算机系统基本功能和基本组成</h2><p>1、见习题解答。</p>
<p>2、简单回答下列问题。</p>
<p>（1）为什么计算机内部采用二进制表示信息？既然计算机内部所有信息都用二进制表示，为什么还要用到十六进制或八进制数？</p>
<p>制造两个稳定状态的元器件比多个稳定状态的元器件要容易，两个稳定状态对应高低电平，正好可以用0/1表示；二进制编码规则简单，可用开关电路实现；方便通过逻辑电路实现算术运算。<br>二进制硬件容易理解，但是不方便书写和阅读。</p>
<p>（2）常用的定点数编码方式有哪几种？ 通常它们各自用来表示什么？</p>
<p>原码：用定点原码表示浮点数的尾数部分；</p>
<p>补码：带符号整数；</p>
<p>反码：</p>
<p>移码：</p>
<p>（3）为什么计算机中大多用补码表示带符号整数？</p>
<p>（4）在浮点数的基和位数一定的情况下，浮点数的表数范围和表数精度分别由什么决定？两者如何相互制约？</p>
<p>（5）为什么要对浮点数进行规格化？有哪两种规格化操作？</p>
<p>（6）为什么有些计算机中除了用二进制外还用 BCD 码来表示数值数据？</p>
<p>（7）为什么计算机处理汉字时会涉及到不同的编码（如，输入码、内码、字模码）？说明这些编码中哪些是用二进制编码，哪些不是用二进制编码，为什么？</p>
<p>3．实现下列各数的转换。<br>（1）(25.8125)10= (?)2= (?) 8= (?) 16</p>
<p>（2）(101101.011)2 = (?)10= (?) 8= (?) 16= (?) 8421</p>
<p>（3）(0101 1001 0110.0011)8421 = (?)10= (?) 2= (?) 16</p>
<p>（4）(4E.C)16 = (?)10= (?) 2</p>
<p>参考答案：</p>
<p>（1）    (25.8125)10 = (1 1001.1101)2 = (31.64) 8 = (19.D) 16</p>
<p>（2）(101101.011)2 = (45.375)10 = (55.3) 8 = (2D.6) 16 = (0100 0101.0011 0111 0101) 8421</p>
<p>（3）(0101 1001 0110.0011)8421 = (596.3)10 = (1001010100.01001100110011…) 2 = (254.4CCC…) 16</p>
<p>（4）(4E.C)16 = (78.75)10 = (0100 1110.11) 2</p>
<p>4． 假定机器数为8位（1位符号，7位数值），写出下列各二进制数的原码和补码表示。<br>+0.1001，–0.1001，+1.0，–1.0，+0.010100，–0.010100，+0，–0</p>
<p>参考答案：<br>| 原码 | 补码 |<br>|——- |——-|<br>|+0.1001：            0.1001000            0.1001000<br>–0.1001：            1.1001000            1.0111000<br>+1.0：                溢出                溢出<br>–1.0：                溢出                1.0000000<br>+0.010100：            0.0101000            0.0101000<br>–0.010100：            1.0101000            1.1011000<br>+0：                0.0000000            0.0000000<br>–0：                1.0000000            0.0000000</p>
<p>5． 假定机器数为8位（1位符号，7位数值），写出下列各二进制数的补码和移码表示。<br>+1001，–1001，+1，–1，+10100，–10100，+0，–0<br>参考答案：<br>移码                  补码<br>+1001：                10001001            00001001<br>–1001：                01110111                11110111<br>+1：                10000001            00000001<br>–1：                011111111            11111111<br>+10100：            10010100            00010100<br>–10100：            01101100                11101100<br>+0：                10000000            00000000<br>–0：                10000000            00000000</p>
<p>6． 已知 [x]补，求x<br>（1）[x]补=1.1100111           （2）[x]补=10000000<br>（3）[x]补=0.1010010          （4）[x]补=11010011<br>参考答案：<br>（1）[x]补=1.1100111           x = –0.0011001B<br>（2）[x]补=10000000              x = –10000000B = –128<br>（3）[x]补=0.1010010             x = +0.101001B<br>（4）[x]补=11010011             x = – 101101B = – 45</p>
<p>7．假定一台32位字长的机器中带符号整数用补码表示，浮点数用IEEE 754标准表示，寄存器R1和R2的内容分别为R1：0000108BH，R2：8080108BH。不同指令对寄存器进行不同的操作，因而，不同指令执行时寄存器内容对应的真值不同。假定执行下列运算指令时，操作数为寄存器R1和R2的内容，则R1和R2中操作数的真值分别为多少？<br>（1）无符号数加法指令<br>（2）带符号整数乘法指令<br>（3）单精度浮点数减法指令<br>参考答案：<br>    R1     = 0000108BH = 0000 0000 0000 0000 0001 0000 1000 1011b<br>    R2    = 8080108BH = 1000 0000 1000 0000 0001 0000 1000 1011b<br>（1）对于无符号数加法指令，R1和R2中是操作数的无符号数表示，因此，其真值分别为R1：108BH, R2：8080108BH。<br>（2）对于带符号整数乘法指令，R1和R2中是操作数的带符号整数补码表示，由最高位可知， R1为正数， R2为负数。R1的真值为+108BH, R2的真值为–(0111 1111 0111 1111 1110 1111 0111  0100b + 1b) = –7F7FEF75H。<br>（3）对于单精度浮点数减法指令，R1和R2中是操作数的IEEE754单精度浮点数表示。在IEEE 754 标准中，单精度浮点数的位数为32位，其中包含1位符号位，8位阶码，23位尾数。<br>由R1中的内容可知，其符号位为0，表示其为正数，阶码为0000 0000，尾数部分为000 0000 0001 0000 1000 1011，故其为非规格化浮点数，指数为–126，尾数中没有隐藏的1，用十六进制表示尾数为+0.002116H，故R1表示的真值为+0.002116H × 10-126。<br>由R2中的内容可知，其符号位为1，表示其为负数，阶码为0000 0001， 尾数部分为000 0000 0001 0000 1000 1011，故其为规格化浮点数，指数为1–127 = –126，尾数中有隐藏的1，用十六进制表示尾数为–1.002116H，故R2表示的真值为–1.002116H × 10-126</p>
<p>8．假定机器M的字长为32位，用补码表示带符号整数。下表第一列给出了在机器M上执行的C语言程序中的关系表达式，请参照已有的表栏内容完成表中后三栏内容的填写。<br>关系表达式    运算类型    结果    说明<br>0 == 0U<br>–1 &lt; 0<br>–1 &lt; 0U<br>2147483647 &gt; –2147483647 – 1<br>2147483647U &gt; –2147483647 – 1<br>2147483647 &gt; (int) 2147483648U<br>–1 &gt; –2<br>(unsigned) –1 &gt; –2    无符号整数<br>有符号整数<br>无符号整数<br>有符号整数<br>无符号整数<br>有符号整数<br>有符号整数<br>无符号整数    1<br>1<br>0<br>1<br>0<br>1<br>1<br>1    00…0B = 00…0B<br>11…1B (–1) &lt; 00…0B (0)<br>11…1B (232–1) &gt; 00…0B(0)<br>011…1B (231–1) &gt; 100…0B (–231)<br>011…1B (231–1) &lt; 100…0B(231)<br>011…1B (231–1) &gt; 100…0B (–231)<br>11…1B (–1) &gt; 11…10B (–2)<br>11…1B (232–1) &gt; 11…10B (232–2)</p>
<p>9．以下是一个C语言程序，用来计算一个数组a中每个元素的和。当参数len为0时，返回值应该是0，但是在机器上执行时，却发生了存储器访问异常。请问这是什么原因造成的，并说明程序应该如何修改。<br>       1    float sum_elements(float a[], unsigned len)<br>    2    {<br>    3        int     i;<br>    4        float  result = 0;<br>    5<br>    6        for    (i = 0; i &lt;= len–1; i++)<br>    7            result += a[i];<br>    8        return result;<br>    9    }</p>
<p>参考答案：<br>参数len的类型是unsigned，所以，当len=0时，执行len-1的结果为11…1，是最大可表示的无符号数，因而，任何无符号数都比它小，使得循环体被不断执行，引起数组元素的访问越界，发生存储器访问异常。<br>    只要将len声明为int型，或循环的测试条件改为i&lt;len。</p>
<ol>
<li>设某浮点数格式为：</li>
</ol>
<p>其中，移码的偏置常数为16，补码采用一位符号位，基数为4。<br>（1）用这种格式表示下列十进制数：+1.7，–0.12，+19，–1/8。<br>（2）写出该格式浮点数的表示范围，并与12位定点补码整数表示范围比较。<br>参考答案：（假定采用0舍1入法进行舍入）<br>（1） +1.7 = +1.1011001B = 0.011011B× 41, 故阶码为1 +16 = 17 = 10001B, 尾数为+0.011011的补码， 即0.011011，所以+1.7表示为0 10001 011011。</p>
<pre><code>–0.12 = – 0.000111101B = – 0.011111B × 4–1, 故阶码为 –1 + 16 =15 = 01111B, 尾数为– 0.011111的补码，即1.100001, 所以–0.12表示为1 01111 100001。

+19 = +10011B = 0.010011B× 43，故阶码为3 + 16 = 19 = 10011B, 尾数为0.010011，所以+19表示为0 10011 010011。

–1/8 = – 0.125 = – 0.001B = – 0.100000 × 4–1，阶码为 –1 + 16 = 15 = 01111B，尾数为– 0.100000的补码，即1.100000，所以–1/8表示为1 01111 100000。
</code></pre><p>（2）该格式浮点数表示的范围如下。<br>    正数最大值：0.111111B × 411111，即：0.333× 415  （≈230 ≈109）<br>    正数最小值：0.000001B × 400000，即：0.001× 4–16  （≈2–34≈10–10）<br>    负数最大值：–0.000001B × 400000，即：–0.001× 4–16<br>    负数最小值：–1.000000B × 411111，即：–1.000× 415<br>    因此，该格式浮点数的数量级在10–10～109之间。<br>12位定点补码整数的表示范围为：–211～+(211–1)，即：–2048～2047<br>由此可见，定点数和浮点数的表示范围相差非常大。</p>
<ol>
<li>下列几种情况所能表示的数的范围是什么？<br>（1）16位无符号整数<br>（2）16位原码定点小数<br>（3）16位补码定点小数<br>（4）16位补码定点整数<br>（5）下述格式的浮点数（基数为2，移码的偏置常数为128）</li>
</ol>
<pre><code>参考答案：
</code></pre><p>（1）无符号整数：0～216–1。<br>（2）原码定点小数：–(1–2–15) ～ + (1–2–15)。<br>（3）补码定点小数：–1 ～ + (1–2–15)。<br>（4）补码定点整数：–32768 ～ +32767。<br>（5）浮点数：负数：– (1–2–7)×2+127 ～ –2–7×2–128。<br>正数：+2–135 ～ (1–2–7) ×2+127。</p>
<ol>
<li><p>以IEEE 754单精度浮点数格式表示下列十进制数。<br>+1.75，+19，–1/8，258<br>参考答案：<br>+1.75 = +1.11B = 1.11B × 20, 故阶码为0+127=01111111B, 数符为0，尾数为1.110…0，小数点前为隐藏位，所以+1.7表示为0 01111111 110 0000 0000 0000 0000 0000，用十六进制表示为3FE00000H。</p>
<p>+19 = +10011B = +1.0011B × 24，故阶码为4+127 = 10000011B, 数符为0，尾数为1.00110…0，所以+19表示为0 10000011 001 1000 0000 0000 0000 0000，用十六进制表示为41980000H。</p>
<p>–1/8 = – 0.125 = – 0.001B = – 1.0 × 2–3，阶码为–3+127 = 01111100B，数符为1，尾数为1.0…0，所以–1/8表示为1 01111100 000 0000 0000 0000 0000 0000，用十六进制表示为BE000000H。</p>
</li>
</ol>
<p>258=100000010B=1.0000001B × 28, 故阶码为8+127=10000111B, 数符为0，尾数为1.0000001，所以258表示为0 10000111 000 0001 0000 0000 0000 0000，用十六进制表示为43810000H。</p>
<p>13．设一个变量的值为4098，要求分别用32位补码整数和IEEE 754单精度浮点格式表示该变量（结果用十六进制表示），并说明哪段二进制序列在两种表示中完全相同，为什么会相同？<br>参考答案：<br>4098 = +1 0000 0000 0010B = +1. 0000 0000 001 × 212<br>    32位2-补码形式为：0000 0000 0000 0000 0001 0000 0000 0010 （00001002H）<br>    IEEE754单精度格式为：0 10001011 0000 0000 0010 0000 0000 000 （45801000H）<br>    粗体部分为除隐藏位外的有效数字，因此，在两种表示中是相同的序列。</p>
<p>14．设一个变量的值为–2147483647，要求分别用32位补码整数和IEEE754单精度浮点格式表示该变量（结果用十六进制表示），并说明哪种表示其值完全精确，哪种表示的是近似值。<br>参考答案：<br>–2147483647 = –111 1111 1111 1111 1111 1111 1111 1111B<br>= –1.11 1111 1111 1111 1111 1111 1111 1111 × 230<br>    32位2-补码形式为：1000 0000 0000 0000 0000 0000 0000 0001 （80000001H）<br>    IEEE 754单精度格式为：1 10011101 1111 1111 1111 1111 1111 111 （CEFFFFFFH）<br>    32位2-补码形式能表示精确的值，而浮点数表示的是近似值，低位被截断</p>
<p>15．下表给出了有关IEEE 754浮点格式表示中一些重要数据的取值，表中已经有最大规格化数的相应内容，要求填入其他浮点数的相应内容。（注：表中a代表一个在1到10之间的正纯小数）<br>项目    阶码    尾数    单精度    双精度<br>            以2的幂次表示的值    以10的幂次表示的值    以2的幂次表示的值    以10的幂次表示的值<br>0<br>1<br>最大规格化数<br>最小规格化数<br>最大非规格化数<br>最小非规格化数<br>+∞<br>NaN    00000000<br>01111111<br>11111110<br>00000001<br>00000000<br>00000000<br>11111111<br>11111111    0….00<br>0….00<br>1…11<br>0….00<br>1…11<br>0…01<br>0….00<br>非全0    0<br>1<br>(2–2–23)×2127<br>1.0×2–126<br>(1–2–23)×2–126<br>2–23×2–126=2–149<br>–<br>–    0<br>1<br>a×1038<br>a×10–38<br>a×10–38<br>a×10–44<br>–<br>–    0<br>1<br>(2–2–52)×21023<br>1.0×2–1022<br>(1–2–52)×2–1022<br>2–52×2–1022<br>–<br>–    0<br>1<br>a×10308<br>a×10–308<br>a×10–308<br>a×10–?<br>–<br>–</p>
<p>16．已知下列字符编码：A=100 0001，a=110 0001，0=011 0000，求E、e、f、7、G、Z、5的7位ACSII码和第一位前加入奇校验位后的8位编码。<br>参考答案：<br>    E的ASCII码为 ‘A’ + (‘E’ – ‘A’) = 100 0001 + 100 = 100 0101, 奇校验位P = 0，第一位前加入奇校验位后的8位编码是0 100 0101。<br>    e的ASCII码为‘a’+ (‘e’ – ‘a’) = 110 0001 + 100 = 110 0101， 奇校验位P = 1, 第一位前加入奇校验位后的8位编码是1 110 0101。<br>    f的ASCII码为‘a’+ (‘f’ – ‘a’) = 110 0001 + 101 = 110 0110, 奇校验位P = 1, 第一位前    加入奇校验位后的8位编码是 1 110 0110。<br>    7的ASCII码为‘0’+ (7 - 0)  = 011 0000 + 111 = 011 0111,奇校验位P = 0, 第一位前加入奇校验位后的8位编码是0 011 0111。<br>    G的ASCII码为‘A’+ (‘G’ – ‘A’) = 100 0001 + 0110 = 100 0111, 奇校验位P = 1, 第一位前加入奇校验位后的8位编码是1 100 0111。<br>    Z的ASCII码为‘A’+(‘Z’ – ‘A’) = 100 0001 + 11001 = 101 1010, 奇校验位P = 1, 第一位前加入奇校验位后的8位编码是 1 101 1010。<br>    5的ASCII码为‘0’+(5 – 0) = 011 0000 + 101 = 011 0101， 奇校验位P = 1, 第一位前加入奇校验位后的8位编码是 1 011 0101。</p>
<p>17．假定在一个程序中定义了变量x、y和i，其中，x和y是float型变量（用IEEE754单精度浮点数表示），i是16位short型变量（用补码表示）。程序执行到某一时刻，x = –0.125、y=7.5、i=100，它们都被写到了主存（按字节编址），其地址分别是100，108和112。请分别画出在大端机器和小端机器上变量x、y和i在内存的存放位置。<br>参考答案：<br>–0.125 = –0.001B = –1.0 × 2-3<br>x在机器内部的机器数为：1 01111100 00…0 (BE00 0000H)<br>7.5= +111.1B= +1.111 × 22<br>y在机器内部的机器数为：0 10000001 11100…0 (40F0 0000H)<br>100=64+32+4=1100100B<br>i在机器内部表示的机器数为：0000 0000 0110 0100（0064H）<br>大端机                          小端机<br>地址    内容                             内容<br>100        BEH                            00H<br>            101        00H                                00H<br>            102        00H                                00H<br>            103        00H                                BEH<br>            108        40H                                00H<br>            109        F0H                                00H<br>            110        00H                                F0H<br>            111        00H                                40H<br>            112        00H                                64H<br>            113        64H                                00H</p>
<p>18．假定某计算机的总线采用奇校验，每8位数据有一位校验位，若在32位数据线上传输的信息是8F 3C AB 96H，则对应的4个校验位应为什么？若接受方收到的数据信息和校验位分别为87 3C AB 96H和0101B，则说明发生了什么情况，并给出验证过程。<br>    参考答案：<br>    传输信息8F 3C AB 96H展开为1000 1111 0011 1100 1010 1011 1001 0110，每8位有一个奇校验位，因此，总线上发送方送出的4个校验位应该分别为0、1、0、1。<br>    接受方的数据信息为87 3C AB 96H，展开后为1000 0111 0011 1100 1010 1011 1001 0110；接收到的校验位分别为0、1、0、1。在接受方进行校验判断如下：<br>    根据接收到的数据信息计算出4个奇校验位分别为1、1、0、1，将该4位校验位分别和接收到的4位校验位进行异或，得到1、0、0、0，说明数据信息的第一个字节发生传输错误。对照传输前、后的数据信息，第一字节8FH变成了87H，说明确实发生了传输错误，验证正确。</p>
<p>19．写出16位数据的SEC码。假定数据为0101 0001 0100 0110，说明SEC码如何正确检测数据位5的错误。<br>    参考答案：<br>对于16位数据， 可以如下插入校验位：<br>    M16 M15 M14 M13 M12 P5 M11 M10 M9 M8 M7 M6 M5 P4 M4 M3 M2 P3 M1 P2 P1<br>    其中Mi是原信息数据， Pi是加入的校验位， 对于各个校验位的值可以如下计算<br>    P1 = M1⊕M2⊕M3⊕M4⊕M5⊕M7⊕M9⊕M11⊕M12⊕M14⊕M16 = 1<br>    P2 = M1⊕M3⊕M4⊕M6⊕M7⊕M10⊕M11⊕M13⊕M14 = 1<br>    P3 = M2⊕M3⊕M4⊕M8⊕M9⊕M10⊕M11⊕M15⊕M16 = 0<br>    P4 = M5⊕M6⊕M7⊕M8⊕M9⊕M10⊕M11 = 0<br>    P5 = M12⊕M13⊕M14⊕M15⊕M16 = 0<br>    所以此时P5 P4 P3 P2 P1 = 00011，第五位数据出错时，数据字变为：0101 0001 0101 0110，P5’P4’P3’P2’P1’= 01010，故障字 =  00011⊕01010 = 01001，说明码字第9位出错，即M5出错。</p>
<p>20．假设要传送的数据信息为：100011，若约定的生成多项式为：G(x)= x3+1，则校验码为多少？假定在接收端接收到的数据信息为100010，说明如何正确检测其错误，写出检测过程。</p>
<p>参考答案：<br>原数据信息为100011，对应的报文多项式为M(x) = x5 + x + 1, 生成多项式的位数为4位， 所以在原数据信息后面添加3个0，变为M’(x) = x3M(x) = x8 + x4 + x3, 用M(x)去模2除G(x)，得到的余数为111， 所以得到CRC码为100011 111。</p>
<pre><code>检测时， 用接收到的CRC码去模2除生成多项式1001，若得到的余数为0，则表明正确，否则说明传输时发生了错误。此题中接收到的CRC码为100010 111（即数据100010加检验位111），显然，用100010 111 模2除 1001，得到余数为001，不为0，说明传输时发生错误。
</code></pre>]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础——知识点</title>
    <url>/2025/04/16/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
    <content><![CDATA[<h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h2><p>在这张图片中，表格列出了 <code>x</code> 和 <code>y</code> 的十六进制值，并且要求用 C 语言中的位运算符对它们进行操作。接下来，我将对每个表达式进行详细的计算和解释。</p>
<p>在表格中，要求使用 C 语言中的不同位运算符来计算 <code>x</code> 和 <code>y</code> 之间的结果。位运算符包括：</p>
<ol>
<li><code>&amp;</code>（位与）</li>
<li><code>|</code>（位或）</li>
<li><code>^</code>（位异或）</li>
<li><code>~</code>（位取反）</li>
<li><code>&lt;&lt;</code>（左移）</li>
<li><code>&gt;&gt;</code>（右移）</li>
<li><code>!</code>（逻辑非）</li>
</ol>
<h3 id="计算步骤："><a href="#计算步骤：" class="headerlink" title="计算步骤："></a>计算步骤：</h3><ol>
<li><strong>位与运算 <code>x &amp; y</code></strong>： 位与运算会比较 <code>x</code> 和 <code>y</code> 的每一位，只有当对应位都为 1 时，结果才为 1，否则为 0。</li>
<li><strong>位或运算 <code>x | y</code></strong>： 位或运算会比较 <code>x</code> 和 <code>y</code> 的每一位，只要对应位有一个为 1，结果就为 1。</li>
<li><strong>位异或运算 <code>x ^ y</code></strong>： 位异或运算会比较 <code>x</code> 和 <code>y</code> 的每一位，当两者相同时，结果为 0；当两者不同时，结果为 1。</li>
<li><strong>位取反运算 <code>~x</code> 和 <code>~y</code></strong>： 位取反运算会将 <code>x</code> 或 <code>y</code> 的每一位都反转，0 变 1，1 变 0。</li>
<li><strong>左移运算 <code>x &lt;&lt; y</code></strong>： 左移运算会将 <code>x</code> 的二进制位向左移动 <code>y</code> 位，并在右边补 0。</li>
<li><strong>右移运算 <code>x &gt;&gt; y</code></strong>： 右移运算会将 <code>x</code> 的二进制位向右移动 <code>y</code> 位，符号位（对于负数来说是 1）保持不变。</li>
<li><strong>逻辑非运算 <code>!x</code></strong>： 逻辑非运算对 <code>x</code> 进行布尔值判断，如果 <code>x</code> 为 0，则结果为 1，否则为 0。</li>
</ol>
<h2 id="十六进制（Hexadecimal-H）和二进制（Binary-b）之间的直接关系"><a href="#十六进制（Hexadecimal-H）和二进制（Binary-b）之间的直接关系" class="headerlink" title="十六进制（Hexadecimal, H）和二进制（Binary, b）之间的直接关系"></a>十六进制（Hexadecimal, H）和二进制（Binary, b）之间的直接关系</h2><p><strong>核心原理:</strong> 每一个十六进制数字正好对应 4 个二进制位。这是因为 16=24。</p>
<p>我们可以将十六进制数 <code>8080 108B</code> H 中的每一位数字，分别转换为它对应的4位二进制数：</p>
<ol>
<li><strong><code>8</code></strong> H = <strong><code>1000</code></strong> b</li>
<li><strong><code>0</code></strong> H = <strong><code>0000</code></strong> b</li>
<li><strong><code>8</code></strong> H = <strong><code>1000</code></strong> b</li>
<li><strong><code>0</code></strong> H = <strong><code>0000</code></strong> b</li>
<li><strong><code>1</code></strong> H = <strong><code>0001</code></strong> b</li>
<li><strong><code>0</code></strong> H = <strong><code>0000</code></strong> b</li>
<li><strong><code>8</code></strong> H = <strong><code>1000</code></strong> b</li>
<li><strong><code>B</code></strong> H (B 代表十进制的 11) = <strong><code>1011</code></strong> b</li>
</ol>
<p><strong>组合:</strong> 现在，按照原始十六进制数的顺序，把这些4位的二进制数组合起来：</p>
<p><code>1000</code> (来自<code>8</code>) + <code>0000</code> (来自<code>0</code>) + <code>1000</code> (来自<code>8</code>) + <code>0000</code> (来自<code>0</code>) + <code>0001</code> (来自<code>1</code>) + <code>0000</code> (来自<code>0</code>) + <code>1000</code> (来自<code>8</code>) + <code>1011</code> (来自<code>B</code>)</p>
<p>结果: 将它们连接在一起就得到：</p>
<p>1000 0000 1000 0000 0001 0000 1000 1011 b</p>
<p><strong>所以，<code>8080 108B</code> H 等于 <code>1000 0000 1000 0000 0001 0000 1000 1011</code> b 是因为每个十六进制位都可以独立地、直接地转换为一个4位的二进制表示，然后按顺序拼接起来。</strong></p>
<h2 id="指令决定了如何解释寄存器中的二进制位串"><a href="#指令决定了如何解释寄存器中的二进制位串" class="headerlink" title="指令决定了如何解释寄存器中的二进制位串"></a>指令决定了如何解释寄存器中的二进制位串</h2><p>好的，我们来详细解释一下为什么在不同的指令下，寄存器 R1 和 R2 的内容 <code>0000 108B</code> H 和 <code>8080 108B</code> H 会对应不同的真值。核心原因在于，<strong>指令决定了如何解释寄存器中的二进制位串</strong>。</p>
<p><strong>（1）无符号数加法指令 (Unsigned Addition)</strong></p>
<ul>
<li><strong>解释规则:</strong> 当执行无符号数指令时，计算机会将寄存器中的 <strong>所有32位</strong> 都视为表示数值大小（magnitude）的部分，没有单独的符号位。数值就是这个32位二进制数直接转换成的十进制（或十六进制）值。</li>
</ul>
<p><strong>（2）带符号整数乘法指令 (Signed Integer Multiplication)</strong></p>
<ul>
<li><p>解释规则:</p>
<p> 当执行带符号整数指令时，计算机会使用</p>
<p>补码 (Two’s Complement)</p>
<p> 来表示整数。</p>
<ul>
<li><strong>最高位 (MSB, Most Significant Bit)</strong> 是符号位：<code>0</code> 代表正数或零，<code>1</code> 代表负数。</li>
<li><strong>正数:</strong> 其补码、原码、反码相同，数值就是除去符号位后的二进制值。</li>
<li><strong>负数:</strong> 其真值需要通过补码转换回原码来确定其绝对值。转换方法是：<strong>对补码再次求补（符号位不变，数值位按位取反，末位加1；或者全部位按位取反，末位加1）得到原码的绝对值</strong>。</li>
</ul>
</li>
</ul>
<p><strong>（3）单精度浮点数减法指令 (Single-Precision Floating-Point Subtraction)</strong></p>
<ul>
<li><p>解释规则:</p>
<p> 当执行浮点数指令时，计算机会按照 </p>
<p>IEEE 754 单精度 (32位)</p>
<p> 标准来解释寄存器中的位。格式如下：</p>
<ul>
<li><strong>符号位 (Sign, S):</strong> 1位 (第31位)。<code>0</code> 为正，<code>1</code> 为负。</li>
<li><strong>阶码 (Exponent, E):</strong> 8位 (第30-23位)。存储的是 <code>e + bias</code>，其中 <code>e</code> 是实际指数，<code>bias</code> (偏移量) 对于单精度是 <strong>127</strong>。</li>
<li><strong>尾数 (Mantissa/Fraction, F):</strong> 23位 (第22-0位)。表示小数部分。对于规格化数，实际尾数是 <code>1.F</code>（有一个隐藏的1）。</li>
<li><strong>数值公式 (规格化):</strong> Value=(−1)S×(1.F)2×2(E−127)</li>
<li><strong>特殊情况:</strong> 需要注意 E=0 (表示0或非规格化数) 和 E=255 (表示无穷大或NaN)。</li>
</ul>
</li>
</ul>
<h2 id="补码的基本规则"><a href="#补码的基本规则" class="headerlink" title="补码的基本规则"></a>补码的基本规则</h2><p>在开始计算之前，我们先了解补码的基本规则：</p>
<ol>
<li><p><strong>符号位</strong>：</p>
<ul>
<li>补码的最高位（最左边的位）是符号位。</li>
<li>符号位为 <strong>0</strong> 表示正数或零，符号位为 <strong>1</strong> 表示负数。</li>
</ul>
</li>
<li><p><strong>正数的补码</strong>：</p>
<ul>
<li>如果符号位是 0，补码与原码相同，直接按照二进制数值解释即可。</li>
</ul>
</li>
<li><p><strong>负数的补码</strong>：</p>
<ul>
<li>如果符号位是 1，表示负数。要得到原码（即实际的数值），需要对数值部分取反（0 变 1，1 变 0），然后加 1。</li>
<li>最后在结果前加上负号。</li>
</ul>
</li>
<li><p><strong>小数部分的处理</strong>：</p>
<ul>
<li>如果补码表示包含小数点，符号位在小数点左边，数值部分在小数点右边，按照二进制小数计算。</li>
</ul>
</li>
</ol>
<h2 id="是的，在-C-语言中，0U-后面的-U-确实表示无符号的意思。具体来说："><a href="#是的，在-C-语言中，0U-后面的-U-确实表示无符号的意思。具体来说：" class="headerlink" title="是的，在 C 语言中，0U 后面的 U 确实表示无符号的意思。具体来说："></a>是的，在 C 语言中，<code>0U</code> 后面的 <code>U</code> 确实表示无符号的意思。具体来说：</h2><ul>
<li><strong><code>0</code> 本身</strong>：这是一个整数常量，默认情况下是有符号整数类型（<code>signed int</code>）。</li>
<li><strong><code>0U</code> 的含义</strong>：当在 <code>0</code> 后面加上 <code>U</code> 后缀时，它就变成了一个无符号整数常量（<code>unsigned int</code>）。<code>U</code> 后缀明确指定了这个数字是无符号类型。</li>
</ul>
<h3 id="C-语言中整数常量的后缀规则"><a href="#C-语言中整数常量的后缀规则" class="headerlink" title="C 语言中整数常量的后缀规则"></a>C 语言中整数常量的后缀规则</h3><p>在 C 语言中，可以通过后缀来指定整数常量的类型：</p>
<ul>
<li><strong>无后缀</strong>：表示默认的有符号整数（<code>int</code>）。</li>
<li><strong><code>U</code> 或 <code>u</code></strong>：表示无符号整数（<code>unsigned int</code>）。</li>
<li><strong><code>L</code> 或 <code>l</code></strong>：表示长整型（<code>long int</code>）。</li>
<li><strong><code>UL</code> 或 <code>ul</code></strong>：表示无符号长整型（<code>unsigned long int</code>）。</li>
</ul>
<h3 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h3><ul>
<li><code>0</code>：有符号整数，值是 0。</li>
<li><code>0U</code>：无符号整数，值仍然是 0，但它的类型是 <code>unsigned int</code>。</li>
</ul>
<h3 id="为什么这很重要？"><a href="#为什么这很重要？" class="headerlink" title="为什么这很重要？"></a>为什么这很重要？</h3><p>无符号类型和有符号类型的区别在某些情况下会影响程序的行为，比如比较运算：</p>
<ul>
<li>如果比较两个无符号整数，或者两个有符号整数，直接按数值比较即可。</li>
<li>如果一个是有符号整数，另一个是无符号整数，C 语言会将有符号整数转换为无符号整数后再比较。这可能导致意外结果，例如负数在转换为无符号整数时变成一个很大的正数。</li>
</ul>
<p>总之，<code>U</code> 后缀的作用就是告诉编译器，这个整数常量是无符号的。所以你的理解是对的，后面带 <code>U</code> 就是无符号的意思！</p>
<h2 id="让我们来分析这个问题：为什么在表达式-unsigned-1-gt-2-中，-1-被转换为无符号整数，而-2-也被按无符号数处理。"><a href="#让我们来分析这个问题：为什么在表达式-unsigned-1-gt-2-中，-1-被转换为无符号整数，而-2-也被按无符号数处理。" class="headerlink" title="让我们来分析这个问题：为什么在表达式 (unsigned) -1 &gt; -2 中，-1 被转换为无符号整数，而 -2 也被按无符号数处理。"></a>让我们来分析这个问题：为什么在表达式 <code>(unsigned) -1 &gt; -2</code> 中，<code>-1</code> 被转换为无符号整数，而 <code>-2</code> 也被按无符号数处理。</h2><h3 id="1-表达式-unsigned-1-的含义"><a href="#1-表达式-unsigned-1-的含义" class="headerlink" title="1. 表达式 (unsigned) -1 的含义"></a>1. 表达式 <code>(unsigned) -1</code> 的含义</h3><ul>
<li><strong>(unsigned)</strong> 是一个强制类型转换，表示将后面的值 <code>-1</code> 从有符号整数（<code>int</code>）转换为无符号整数（<code>unsigned int</code>）。</li>
<li>在计算机中，整数通常以补码形式存储。以 32 位为例：<ul>
<li>有符号整数 <code>-1</code> 的补码是 <code>1111...1111</code>（32 位全 1）。</li>
<li>当将其强制转换为无符号整数时，这串二进制位被重新解释为一个正数。</li>
<li><code>1111...1111</code> 作为无符号整数的值是 (2^{32} - 1 = 4294967295)。</li>
</ul>
</li>
<li>所以，<code>(unsigned) -1</code> 的结果是 <code>4294967295</code>。</li>
</ul>
<h3 id="2-比较中的-2-为什么按无符号数处理"><a href="#2-比较中的-2-为什么按无符号数处理" class="headerlink" title="2. 比较中的 -2 为什么按无符号数处理"></a>2. 比较中的 <code>-2</code> 为什么按无符号数处理</h3><ul>
<li>在表达式 <code>(unsigned) -1 &gt; -2</code> 中，<code>-2</code> 默认是一个有符号整数（<code>int</code>），其补码表示为 <code>1111...1110</code>（32 位中最后一位是 0）。</li>
<li>当一个无符号整数（<code>(unsigned) -1</code>）与一个有符号整数（<code>-2</code>）进行比较时，C 语言会执行<strong>隐式类型转换</strong>，以确保两个操作数的类型一致。</li>
<li>根据 C 语言的规则：<ul>
<li>如果一个操作数是无符号整数，另一个是有符号整数，有符号整数会被转换为无符号整数。</li>
</ul>
</li>
<li>因此，<code>-2</code> 会被隐式转换为无符号整数：<ul>
<li><code>1111...1110</code> 作为无符号整数的值是 (2^{32} - 2 = 4294967294)。</li>
</ul>
</li>
</ul>
<h3 id="3-比较的过程"><a href="#3-比较的过程" class="headerlink" title="3. 比较的过程"></a>3. 比较的过程</h3><ul>
<li>现在，表达式 <code>(unsigned) -1 &gt; -2</code> 变成了：<ul>
<li><code>(unsigned) -1 = 4294967295</code>（无符号整数）。</li>
<li><code>-2</code> 被转换为 <code>4294967294</code>（无符号整数）。</li>
</ul>
</li>
<li>比较 <code>4294967295 &gt; 4294967294</code>，显然成立，结果为真（<code>1</code>）。</li>
</ul>
<h3 id="4-为什么-2-被按无符号数处理"><a href="#4-为什么-2-被按无符号数处理" class="headerlink" title="4. 为什么 -2 被按无符号数处理"></a>4. 为什么 <code>-2</code> 被按无符号数处理</h3><ul>
<li><code>-2</code> 被按无符号数处理的原因在于 C 语言的<strong>类型转换规则</strong>：<ul>
<li>当有符号整数与无符号整数进行运算或比较时，有符号整数会被自动转换为无符号整数。</li>
<li>这种转换基于补码的二进制表示，直接将补码重新解释为无符号值，而不改变位模式。</li>
</ul>
</li>
<li>在这个例子中：<ul>
<li><code>(unsigned) -1</code> 强制指定了无符号类型。</li>
<li><code>-2</code> 由于与无符号数比较，被隐式转换成了无符号数。</li>
</ul>
</li>
</ul>
<h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h3><ul>
<li><strong>(unsigned) -1</strong> 将 <code>-1</code> 显式转换为无符号整数，结果是 <code>4294967295</code>。</li>
<li><strong>-2</strong> 在比较中被隐式转换为无符号整数，结果是 <code>4294967294</code>。</li>
<li>这种行为是 C 语言类型转换规则的结果：为了保证比较时类型一致，<code>-2</code> 被按无符号数处理。</li>
</ul>
<p>这种机制虽然确保了类型一致性，但在处理负数时可能导致意外结果，因此在使用无符号类型时需要特别注意。希望这个解释清晰地回答了你的问题！</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>大学</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机系统基础期末笔记汇总</title>
    <url>/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<h3 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h3><p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165933.jpg" alt="IMG_20250706_165933"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165925.jpg" alt="IMG_20250706_165925"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165919.jpg" alt="IMG_20250706_165919"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165914.jpg" alt="IMG_20250706_165914"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165903.jpg" alt="IMG_20250706_165903"></p>
<p><img src="/2025/06/09/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%9C%9F%E6%9C%AB%E7%AC%94%E8%AE%B0%E6%B1%87%E6%80%BB/IMG_20250706_165909.jpg" alt="IMG_20250706_165909"></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>计算机系统基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>大学</tag>
        <tag>Ubuntu</tag>
        <tag>计算机系统基础</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2025/08/07/college/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p><a href="https://zh.d2l.ai/index.html">《动手学深度学习》 — 动手学深度学习 2.0.0 documentation</a></p>
<p><a href="https://courses.d2l.ai/zh-v2/">课程安排 - 动手学深度学习课程</a></p>
]]></content>
  </entry>
  <entry>
    <title>机器学习——第二次上机——数据预处理基础</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h1 id="机器学习数据预处理基础"><a href="#机器学习数据预处理基础" class="headerlink" title="机器学习数据预处理基础"></a>机器学习数据预处理基础</h1><h1 id="1-One-Hot编码"><a href="#1-One-Hot编码" class="headerlink" title="1. One-Hot编码"></a>1. One-Hot编码</h1><h2 id="任务介绍"><a href="#任务介绍" class="headerlink" title="任务介绍"></a>任务介绍</h2><ul>
<li>使用Pandas中的value_counts()函数，查看data中的特征User continent的取值类型， 并打印输出的内容；</li>
<li>使用pandas中的get<em>dummies()函数对data中的特征User continent进行One-Hot编码，参数prefix为User continent</em>；</li>
<li>将编码后的结果保存在encode_uc中，并输出变量的前5行内容。</li>
</ul>
<h2 id="预期实验结果"><a href="#预期实验结果" class="headerlink" title="预期实验结果"></a>预期实验结果</h2><p><img src="https://ai-studio-static-online.cdn.bcebos.com/bac5b83fc21a435fabddd64a5ab463600c7d80dc00e44fd6ae1715ae25355db6" alt><br><img src="https://ai-studio-static-online.cdn.bcebos.com/2f183364e29348079537f8ad38d9489004d4498e9b5d483fa9432f2bae06654e" alt></p>
<blockquote>
<p>补全代码;</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># value_counts() 函数统计并输出 &quot;User continent&quot; 列中各大陆出现的次数</span></span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;User continent&#x27;</span>].value_counts())</span><br><span class="line"><span class="comment"># 使用 get_dummies() 对 &quot;User continent&quot; 列进行 One-Hot 编码</span></span><br><span class="line"><span class="comment"># One-hot编码是一种将类别变量转换为多个二进制特征列的技术，</span></span><br><span class="line"><span class="comment"># 每个类别对应一列，如果该行数据属于该类别则取值为1，否则为0</span></span><br><span class="line">encode_uc = pd.get_dummies(data[<span class="string">&#x27;User continent&#x27;</span>], prefix=<span class="string">&#x27;User continent_&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(encode_uc)</span><br></pre></td></tr></table></figure>
<p>​    User continent<br>​    North America    296<br>​    Europe           118<br>​    Oceania           41<br>​    Asia              36<br>​    Africa             7<br>​    South America      6<br>​    Name: count, dtype: int64<br>​         User continent<strong>Africa  User continent</strong>Asia  User continent<strong>Europe  \<br>​    0                     False                 False                   False<br>​    1                     False                 False                   False<br>​    2                     False                 False                   False<br>​    3                     False                 False                    True<br>​    4                     False                 False                   False<br>​    ..                      …                   …                     …<br>​    499                   False                 False                    True<br>​    500                   False                 False                   False<br>​    501                   False                 False                   False<br>​    502                   False                 False                   False<br>​    503                   False                 False                   False<br>​<br>​         User continent</strong>North America  User continent<strong>Oceania  \<br>​    0                             True                    False<br>​    1                             True                    False<br>​    2                             True                    False<br>​    3                            False                    False<br>​    4                             True                    False<br>​    ..                             …                      …<br>​    499                          False                    False<br>​    500                           True                    False<br>​    501                           True                    False<br>​    502                           True                    False<br>​    503                           True                    False<br>​<br>​         User continent</strong>South America<br>​    0                            False<br>​    1                            False<br>​    2                            False<br>​    3                            False<br>​    4                            False<br>​    ..                             …<br>​    499                          False<br>​    500                          False<br>​    501                          False<br>​    502                          False<br>​    503                          False<br>​<br>​    [504 rows x 6 columns]<br>​    </p>
<h1 id="2-缺失值填补"><a href="#2-缺失值填补" class="headerlink" title="2. 缺失值填补"></a>2. 缺失值填补</h1><h2 id="任务介绍-1"><a href="#任务介绍-1" class="headerlink" title="任务介绍"></a>任务介绍</h2><ul>
<li>使用pandas中的value_counts()函数打印输出data中的特征Traveler type的取值统计信息， 并查看其是否含有缺失值；</li>
<li>如果存在缺失值，将特征Traveler type在其他样本中取值频数最多的值保存在变量freq_v中，并使用freq_v进行缺失值填充；</li>
<li>再次打印输出特征Traveler type的取值统计信息。</li>
</ul>
<h2 id="预期实验结果-1"><a href="#预期实验结果-1" class="headerlink" title="预期实验结果"></a>预期实验结果</h2><p><img src="https://ai-studio-static-online.cdn.bcebos.com/573d921570d34dc08c44f863ee8732f8d5816c88af7b467aa8cae7a2ce188129" alt></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># value_counts(dropna=False) 会包括缺失值（NaN）在内</span></span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;Traveler type&#x27;</span>].value_counts(dropna=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># idxmax()会获取频数最多的取值</span></span><br><span class="line">freq_v = data[<span class="string">&#x27;Traveler type&#x27;</span>].value_counts().idxmax()</span><br><span class="line"></span><br><span class="line"><span class="comment"># freq_v会替代缺失值</span></span><br><span class="line">data[<span class="string">&#x27;Traveler type&#x27;</span>] = data[<span class="string">&#x27;Traveler type&#x27;</span>].fillna(freq_v)</span><br><span class="line"></span><br><span class="line"><span class="comment">### 打印</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">u&#x27;缺失值填充完之后：&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;Traveler type&#x27;</span>].value_counts(dropna=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure>
<h1 id="3-特征标准化"><a href="#3-特征标准化" class="headerlink" title="3. 特征标准化"></a>3. 特征标准化</h1><h2 id="任务1"><a href="#任务1" class="headerlink" title="任务1:"></a>任务1:</h2><ul>
<li>使用sklearn中preprocessing模块下的StandardScaler()函数对data的特征Score进行Z-score标准化；</li>
<li>将特征取值的均值保存在变量score_mean中，并打印；</li>
<li>将特征取值的方差保存在变量score_var中，并打印。</li>
</ul>
<h2 id="预期实验结果-2"><a href="#预期实验结果-2" class="headerlink" title="预期实验结果"></a>预期实验结果</h2><p><img src="/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/fa64d89b-3dc9-4b07-b27f-210b56e583ed-1741258230441-1.png" alt="fa64d89b-3dc9-4b07-b27f-210b56e583ed"></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="comment"># sklearn是一个用于机器学习的Python库，提供了各种分类、回归、聚类算法，</span></span><br><span class="line"><span class="comment"># 包括支持向量机、随机森林、梯度提升等。它还包含了用于数据预处理、特征提取和模型选择的工具。</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment">## 创建Z-score对象</span></span><br><span class="line"><span class="comment">## Z-score标准化是一种将数据转换为均值为0，标准差为1的标准正态分布的方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 初始化StandardScaler对象，用于执行Z-score标准化</span></span><br><span class="line">std_scaler = StandardScaler()</span><br><span class="line"></span><br><span class="line"><span class="comment">## Score特征标准化，使用fit_transform()方法</span></span><br><span class="line"><span class="comment"># fit_transform() 会先计算出该特征的均值和标准差，然后进行标准化</span></span><br><span class="line">normal_df = std_scaler.fit_transform(data[[<span class="string">&#x27;Score&#x27;</span>]])  </span><br><span class="line"></span><br><span class="line"><span class="comment">## 均值</span></span><br><span class="line"><span class="comment"># StandardScaler 会自动计算并存储 &#x27;Score&#x27; 列的均值，这个值在标准化过程中用来进行数据转换</span></span><br><span class="line">score_mean = std_scaler.mean_</span><br><span class="line"></span><br><span class="line"><span class="comment">## 方差</span></span><br><span class="line"><span class="comment"># 方差也是 StandardScaler 会计算的一个参数，表示数据的离散程度</span></span><br><span class="line">score_var = std_scaler.var_</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印</span></span><br><span class="line"><span class="built_in">print</span> (score_mean)</span><br><span class="line"><span class="built_in">print</span> (score_var)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印前五行内容</span></span><br><span class="line">normal_df[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p>​    [4.12301587]<br>​    [1.01264487]<br>​    </p>
<p>​    array([[ 0.87149149],<br>​           [-1.11598231],<br>​           [ 0.87149149],<br>​           [-0.12224541],<br>​           [-0.12224541]])</p>
<h2 id="任务2："><a href="#任务2：" class="headerlink" title="任务2："></a>任务2：</h2><ul>
<li>自定义函数min_max()实现MinMax标准化，输入参数data为要进行标准化的数据，输出为标准化后的数据。</li>
<li>使自定义的min_max()函数对data的特征Score进行MinMax标准化，输出结果保存在score_transformed中，并打印变量的前5行内容</li>
</ul>
<h2 id="预期结果"><a href="#预期结果" class="headerlink" title="预期结果"></a>预期结果</h2><p><img src="https://ai-studio-static-online.cdn.bcebos.com/98a830f8c5594920883029b03ae2882f516aef4a6af244ff93061ef21aa09836" alt></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">min_max</span>(<span class="params">data</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 最小值</span></span><br><span class="line">    data_min = data.<span class="built_in">min</span>()</span><br><span class="line">    <span class="comment">## 最大值</span></span><br><span class="line">    data_max = data.<span class="built_in">max</span>()</span><br><span class="line">    <span class="comment">## 最大值与最小值之间的差值</span></span><br><span class="line">    data_range=data_max-data_min</span><br><span class="line">    <span class="comment">## 根据MinMax标准化的定义实现</span></span><br><span class="line">    <span class="comment">#MinMax 标准化（最小-最大标准化）是一种数据预处理方法，</span></span><br><span class="line">    <span class="comment"># 旨在将数据的所有特征（列）缩放到一个指定的范围，通常是 [0, 1]。</span></span><br><span class="line">    <span class="comment"># 这种标准化方法将原始数据通过线性变换映射到新的范围。</span></span><br><span class="line">    new_data = (data-data_min)/data_range<span class="comment"># MinMax标准化公式： (x - min) / (max - min)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 返回结果</span></span><br><span class="line">    <span class="keyword">return</span> new_data</span><br><span class="line"></span><br><span class="line"><span class="comment">## 调用min_max()函数</span></span><br><span class="line">score_transformed = min_max(data[<span class="string">&#x27;Score&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印变量的前5行内容</span></span><br><span class="line">score_transformed.head()</span><br></pre></td></tr></table></figure>
<p>​    0    1.00<br>​    1    0.50<br>​    2    1.00<br>​    3    0.75<br>​    4    0.75<br>​    Name: Score, dtype: float64</p>
<h2 id="任务3："><a href="#任务3：" class="headerlink" title="任务3："></a>任务3：</h2><ul>
<li>自定义logistic()函数，输入参数为要进行标准化的数据，输出结果为经过标准化后的数据；</li>
<li>使用自定义函数对data的特征Member years进行Logsitic标准化，结果保存在member_transformed中，并输出变量的前5行内容。</li>
</ul>
<h2 id="预期结果："><a href="#预期结果：" class="headerlink" title="预期结果："></a>预期结果：</h2><p><img src="https://ai-studio-static-online.cdn.bcebos.com/22fd81b1a5614b418f88cbe90bf7f99ba6c553820c2542be80f1a90421779026" alt></p>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ogistic 标准化（Logistic Normalization）是一个将数据转换为 (0, 1) 范围的过程，</span></span><br><span class="line"><span class="comment"># 通常使用 Logistic 函数（也称为 Sigmoid 函数）。</span></span><br><span class="line"><span class="comment"># 它是一种非线性转换方法，常用于神经网络和其他需要将数据映射到概率范围的场景。</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">logistic</span>(<span class="params">data</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    <span class="keyword">import</span> warnings</span><br><span class="line">    warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 计算 1 + e^(-x)</span></span><br><span class="line">    denominator = <span class="number">1</span>+ np.exp(-data)<span class="comment"># 使用 np.exp() 计算 e^(-x)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">## 实现logistic标准化</span></span><br><span class="line">    new_data = <span class="number">1</span>/denominator</span><br><span class="line">    <span class="comment">## 返回结果</span></span><br><span class="line">    <span class="keyword">return</span> new_data</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对特征Member years进行logsitic标准化</span></span><br><span class="line">member_transformed = logistic(data[<span class="string">&#x27;Member years&#x27;</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印内容</span></span><br><span class="line">member_transformed.head()</span><br></pre></td></tr></table></figure>
<p>​    0    0.999877<br>​    1    0.952574<br>​    2    0.880797<br>​    3    0.997527<br>​    4    0.999089<br>​    Name: Member years, dtype: float64</p>
<h1 id="4-特征离散化"><a href="#4-特征离散化" class="headerlink" title="4. 特征离散化"></a>4. 特征离散化</h1><h2 id="任务介绍-2"><a href="#任务介绍-2" class="headerlink" title="任务介绍"></a>任务介绍</h2><ul>
<li>使用Pandas的qcut()函数对data中的特征Member years进行等频离散化，结果保存在bins中；</li>
<li>使用pd.value_counts()函数统计categorical对象bins的取值信息。</li>
</ul>
<h2 id="预期结果-1"><a href="#预期结果-1" class="headerlink" title="预期结果"></a>预期结果</h2><p><img src="https://ai-studio-static-online.cdn.bcebos.com/a4729a315ee6483687f3a819d01d905b025fa5f90da04f3e893a7a80ce5e5107" alt></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 返回bins</span></span><br><span class="line"><span class="comment"># q=4 表示将数据分成 4 个区间</span></span><br><span class="line">bins = pd.qcut(data[<span class="string">&#x27;Member years&#x27;</span>], q=<span class="number">4</span>, labels=[<span class="string">&quot;(-1806.001, 2.0]&quot;</span>, <span class="string">&quot;(2.0, 4.0]&quot;</span>, <span class="string">&quot;(4.0, 6.0]&quot;</span>, <span class="string">&quot;(6.0, 13.0]&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## 统计取值信息</span></span><br><span class="line"><span class="comment"># 使用value_counts()函数统计bins中每个类别的数量，得到离散化后的各个类别的分布情况</span></span><br><span class="line">value_counts = pd.value_counts(bins)  </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(value_counts)</span><br></pre></td></tr></table></figure>
<p>​    Member years<br>​    (-1806.001, 2.0]    156<br>​    (6.0, 13.0]         124<br>​    (2.0, 4.0]          123<br>​    (4.0, 6.0]          101<br>​    Name: count, dtype: int64<br>​    </p>
<h1 id="5-离群值检测"><a href="#5-离群值检测" class="headerlink" title="5. 离群值检测"></a>5. 离群值检测</h1><h2 id="任务介绍-3"><a href="#任务介绍-3" class="headerlink" title="任务介绍"></a>任务介绍</h2><ul>
<li>使用拉依达准则对data的特征Member years进行离群值检测；</li>
<li>如果存在离群值，输出离群值的个数outlier_num，并将包含离群值的数据记录保存在变量outeliers中，并打印变量内容。</li>
</ul>
<h2 id="预期结果-2"><a href="#预期结果-2" class="headerlink" title="预期结果"></a>预期结果</h2><p><img src="https://ai-studio-static-online.cdn.bcebos.com/40e316267fc542339a74291e8438e340109ece96fc2a439591b75414e12085d2" alt></p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取csv文件到DataFrame</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;user_review.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取&#x27;Member years&#x27;这一列</span></span><br><span class="line">member_data = data[[<span class="string">&#x27;Member years&#x27;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">拉伊达准则</span></span><br><span class="line"><span class="string">计算四分位数（Q1 和 Q3）：计算Member years特征的第25百分位数（Q1）和第75百分位数（Q3）。</span></span><br><span class="line"><span class="string">计算IQR（Interquartile Range）：IQR = Q3 - Q1。</span></span><br><span class="line"><span class="string">判断离群值：低于 Q1 - 1.5 * IQR 或高于 Q3 + 1.5 * IQR 的数据点视为离群值。</span></span><br><span class="line"><span class="string">统计离群值的个数，并提取包含离群值的记录。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算四分位数</span></span><br><span class="line">Q1 = member_data[<span class="string">&#x27;Member years&#x27;</span>].quantile(<span class="number">0.25</span>)  <span class="comment"># 第25百分位数</span></span><br><span class="line">Q3 = member_data[<span class="string">&#x27;Member years&#x27;</span>].quantile(<span class="number">0.75</span>)  <span class="comment"># 第75百分位数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算IQR（四分位间距）</span></span><br><span class="line">IQR = Q3 - Q1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写出过滤条件：低于 Q1 - 1.5 * IQR 或 高于 Q3 + 1.5 * IQR 的值为离群值</span></span><br><span class="line">outlier_judge = (member_data[<span class="string">&#x27;Member years&#x27;</span>] &lt; (Q1 - <span class="number">1.5</span> * IQR)) | (member_data[<span class="string">&#x27;Member years&#x27;</span>] &gt; (Q3 + <span class="number">1.5</span> * IQR))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计离群值的个数</span></span><br><span class="line">outlier_num = outlier_judge.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取包含离群值的样本记录</span></span><br><span class="line">outliers = data[outlier_judge]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印离群值记录</span></span><br><span class="line"><span class="built_in">print</span>(outliers)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​        User country User continent  Member years Traveler type  \<br>​    75           USA  North America         -1806          Solo<br>​    143          USA  North America            13       Couples<br>​<br>​                                 Hotel name  Hotel stars  Nr. rooms  Score<br>​    75   Treasure Island- TI Hotel &amp; Casino          4.0       2884      5<br>​    143                      Caesars Palace          5.0       3348      4<br>​    </p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机3——线性回归（医疗保险费预测）</title>
    <url>/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><h2 id="任务1-一元线性回归"><a href="#任务1-一元线性回归" class="headerlink" title="任务1. 一元线性回归"></a>任务1. 一元线性回归</h2><h3 id="任务介绍："><a href="#任务介绍：" class="headerlink" title="任务介绍："></a>任务介绍：</h3><ul>
<li>自定义一元回归函数MyLinearRegression()，输入参数为x和y的数组xArr和yArr，输出为参数w1和w0，利用最小二乘法求得参数;</li>
<li>使用美国医疗保险费数据insurance.csv中的输入特征age和目标特征charges，输入MyLinearRegression()函数，得到回归参数值w1和w0，并保留到小数点后两位;</li>
<li>调用sklearn的LinearRegression()函数，比较其运行结果与上述自定义函数MyLinearRegression()的输出结果是否一致。</li>
<li>利用age与charges绘制真实样本点，利用w1与w0计算预测值，再绘制age与预测值的点图，观察真实样本点与预测点之间的拟合程度。</li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line">age = insurance[<span class="string">&#x27;age&#x27;</span>].values</span><br><span class="line">charges = insurance[<span class="string">&#x27;charges&#x27;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 定义一元线性回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># x均值, y均值计算</span></span><br><span class="line">    mean_x = xArr.mean()</span><br><span class="line">    mean_y = yArr.mean()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># w0, w1计算，公式</span></span><br><span class="line">    numerator = np.<span class="built_in">sum</span>((xArr - mean_x) * (yArr - mean_y))</span><br><span class="line">    denominator = np.<span class="built_in">sum</span>((xArr - mean_x)**<span class="number">2</span>)</span><br><span class="line">    w1 = numerator / denominator</span><br><span class="line">    w0 = mean_y - w1 * mean_x</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(w0,<span class="number">2</span>), <span class="built_in">round</span>(w1,<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型训练，得到参数值&quot;</span>)</span><br><span class="line">w0, w1 = MyLinearRegression(age, charges)</span><br><span class="line"><span class="built_in">print</span>(w1,<span class="string">&#x27;\n&#x27;</span>, w0)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sklearn的训练结果&quot;</span>)</span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment">#线性回归模型训练</span></span><br><span class="line">lr.fit(age.reshape(-<span class="number">1</span>, <span class="number">1</span>), charges)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.coef_[<span class="number">0</span>],<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.intercept_,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 观察真实样本点与预测点之间的拟合程度</span></span><br><span class="line">plt.scatter(age, charges, marker=<span class="string">&#x27;.&#x27;</span>)  <span class="comment"># 画样本点，随机散点</span></span><br><span class="line"><span class="comment"># 利用w1与w0计算预测值，绘制预测点</span></span><br><span class="line">plt.scatter(age, w1 * age + w0, marker=<span class="string">&#x27;+&#x27;</span>)  <span class="comment"># 画预测点，形成直线</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>模型训练，得到参数值
257.72 
 3165.89
sklearn的训练结果
257.72
3165.89
</code></pre><p><img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/main_2_1.png" alt="png"></p>
<h3 id="最小二乘法求解公式"><a href="#最小二乘法求解公式" class="headerlink" title="最小二乘法求解公式"></a><strong>最小二乘法求解公式</strong></h3><p><strong>目标</strong>：最小化预测值与真实值的平方误差之和：</p>
<script type="math/tex; mode=display">\min_{w_0, w_1} \sum_{i=1}^n (y_i - \hat{y}_i)^2</script><p><strong>闭式解（Normal Equation）</strong>：  </p>
<ol>
<li><p><strong>斜率 ( w_1 )</strong>：  </p>
<script type="math/tex; mode=display">w_1 = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}</script><p>其中 (\bar{x}) 和 (\bar{y}) 分别是 (x) 和 (y) 的均值。</p>
</li>
<li><p><strong>截距 ( w_0 )</strong>：  </p>
<script type="math/tex; mode=display">w_0 = \bar{y} - w_1 \bar{x}</script></li>
</ol>
<p>round(w0, 2) 和 round(w1, 2) 的作用是对线性回归模型的参数进行四舍五入处理，保留两位小数。</p>
<p>这段代码使用 <code>scikit-learn</code> 的 <code>LinearRegression</code> 类实现线性回归，并输出模型参数。以下是逐行解释：</p>
<h3 id="1-创建线性回归模型实例"><a href="#1-创建线性回归模型实例" class="headerlink" title="1. 创建线性回归模型实例"></a>1. <strong>创建线性回归模型实例</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr = LinearRegression()</span><br></pre></td></tr></table></figure>
<ul>
<li><code>LinearRegression()</code> 是 <code>scikit-learn</code> 中用于线性回归的类。</li>
<li><code>lr</code> 是该类的一个实例，后续通过它调用模型训练、预测等方法。<h3 id="2-模型训练"><a href="#2-模型训练" class="headerlink" title="2. 模型训练"></a>2. <strong>模型训练</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr.fit(age.reshape(-<span class="number">1</span>, <span class="number">1</span>), charges)</span><br></pre></td></tr></table></figure></li>
<li><strong>作用</strong>：用输入数据 <code>age</code>（特征）和 <code>charges</code>（目标值）训练线性回归模型。</li>
<li><strong>关键细节</strong>：<ul>
<li><code>age</code> 是一维数组（形状如 <code>(n,)</code>），但 <code>scikit-learn</code> 要求输入特征为二维数组（形状如 <code>(n, 1)</code>）。</li>
<li><code>age.reshape(-1, 1)</code> 将一维数组转换为二维列向量（<code>n</code> 行 1 列），确保输入格式正确。</li>
<li><code>charges</code> 是目标值的一维数组，无需调整形状。<h3 id="3-输出模型参数"><a href="#3-输出模型参数" class="headerlink" title="3. 输出模型参数"></a>3. <strong>输出模型参数</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.coef_[<span class="number">0</span>], <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">round</span>(lr.intercept_, <span class="number">2</span>))</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><strong><code>lr.coef_</code></strong>：<ul>
<li>存储模型的回归系数（即 <code>w1</code>，特征权重）。</li>
<li>对于一元线性回归，<code>coef_</code> 是一个包含单个元素的数组（如 <code>[w1]</code>），因此用 <code>coef_[0]</code> 提取数值。</li>
</ul>
</li>
<li><strong><code>lr.intercept_</code></strong>：<ul>
<li>存储模型的截距项（即 <code>w0</code>）。</li>
<li>直接通过 <code>intercept_</code> 访问，无需索引。</li>
</ul>
</li>
<li><strong><code>round(..., 2)</code></strong>：将参数四舍五入保留两位小数，便于与自定义函数结果对比。</li>
</ul>
<h2 id="任务2-多元线性回归"><a href="#任务2-多元线性回归" class="headerlink" title="任务2. 多元线性回归"></a>任务2. 多元线性回归</h2><h3 id="任务介绍：-1"><a href="#任务介绍：-1" class="headerlink" title="任务介绍："></a>任务介绍：</h3><ul>
<li>自定义多元线性回归函数MyLinearRegression2()，输入参数为X和y的数组xArr和yArr，输出为参数ws，利用最小二乘法求得参数;</li>
<li>使用美国医疗保险费数据insurance.csv中的输入特征age、bmi和children，目标特征charges，根据MyLinearRegression2()函数，得到回归参数值ws；注意判断（X^T X）^{-1}是否为满秩，如果满秩，则引入正则项，参数为alpha，目标函数变为岭回归问题。</li>
<li>为了得到模型的截距，需要在矩阵X最后增加一列，并且该列所有行的值均为1。</li>
<li>调用sklearn的LinearRegression()函数，比较其运行结果与上述自定义函数MyLinearRegression2()的输出结果是否一致。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg, column_stack, ones, array</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># 定义多元线性回归函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression2</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用mat将Array转换为矩阵</span></span><br><span class="line">    xMat = np.asmatrix(xArr)</span><br><span class="line">    yMat = np.asmatrix(yArr).T  <span class="comment"># 转换为列向量</span></span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    <span class="comment"># 通过调用linalg计算行列式来判定协方差矩阵是否可逆</span></span><br><span class="line">    <span class="keyword">if</span> linalg.det(xTx) &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>( <span class="string">&quot;singular matrix, can&#x27;t do inverse&quot;</span>)</span><br><span class="line">        <span class="comment"># 引入正则项，即 岭回归</span></span><br><span class="line">        alpha = <span class="number">0.1</span></span><br><span class="line">        <span class="comment"># 添加岭回归正则项（单位矩阵大小为特征数+1）</span></span><br><span class="line">        xTx  += alpha * np.eye(xMat.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算参数向量</span></span><br><span class="line">    <span class="comment"># 计算参数并转为一维数组</span></span><br><span class="line">    ws = xTx.I * (xMat.T * yMat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练，得到参数值</span></span><br><span class="line">X = insurance[[<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;bmi&#x27;</span>, <span class="string">&#x27;children&#x27;</span>]].values</span><br><span class="line"><span class="comment"># 调用column_stack函数在矩阵X后增加一列，并且该列所有行的值均为1</span></span><br><span class="line"><span class="comment"># 添加截距列（全1）</span></span><br><span class="line">X = column_stack((X, ones(X.shape[<span class="number">0</span>])))</span><br><span class="line">y = insurance[<span class="string">&#x27;charges&#x27;</span>]</span><br><span class="line">ws = MyLinearRegression2(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;自定义的训练结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ws)</span><br><span class="line"><span class="comment"># sklearn的训练结果</span></span><br><span class="line">lr = LinearRegression(fit_intercept=<span class="literal">False</span>)  <span class="comment"># 关键：禁用自动截距</span></span><br><span class="line"><span class="comment">#线性回归模型训练</span></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;sklearn的训练结果&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(lr.coef_)</span><br><span class="line"><span class="built_in">print</span>(lr.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>自定义的训练结果
[[  239.99447429]
 [  332.0833645 ]
 [  542.86465225]
 [-6916.24334779]]
sklearn的训练结果
[  239.99447429   332.0833645    542.86465225 -6916.24334779]
0.0
</code></pre><h2 id="任务3-线性回归应用：预测医疗费用"><a href="#任务3-线性回归应用：预测医疗费用" class="headerlink" title="任务3. 线性回归应用：预测医疗费用"></a>任务3. 线性回归应用：预测医疗费用</h2><h3 id="任务介绍"><a href="#任务介绍" class="headerlink" title="任务介绍"></a>任务介绍</h3><ul>
<li>对insurance.csv中的名义型特征进行One-Hot编码，得到了数据变量insurance</li>
<li>请使用自定义的多元回归函数MyLinearRegression2()得到回归模型参数ws和预测值y_pred，并计算R2分数</li>
<li>比较使用sklearn进行模型训练和模型评价R2分数的结果</li>
</ul>
<p>复用上一节实验中实现的代码，可以复制粘贴代替下面的代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model, metrics</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array, mean, ones</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用get_dummies函数对非数值型特征进行 one-hot 编码处理，以便于运算</span></span><br><span class="line">insurance = pd.read_csv(<span class="string">&#x27;insurance.csv&#x27;</span>)</span><br><span class="line">insurance = pd.get_dummies(insurance, drop_first=<span class="literal">True</span>)  <span class="comment"># One-Hot编码</span></span><br><span class="line"><span class="built_in">print</span>(insurance.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从insurance中获取X与y</span></span><br><span class="line">X = insurance.drop([<span class="string">&#x27;charges&#x27;</span>], axis=<span class="number">1</span>).values.astype(np.float64)</span><br><span class="line">y = insurance[<span class="string">&#x27;charges&#x27;</span>].values.astype(np.float64)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个特征与y的关系进行可视化，观察与y的相关性</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">1</span>]):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">6</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.scatter(array(X)[:,i],y,s=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">MyLinearRegression2</span>(<span class="params">xArr, yArr</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用mat将Array转换为矩阵</span></span><br><span class="line">    xMat = np.asmatrix(xArr)</span><br><span class="line">    yMat = np.asmatrix(yArr).T  <span class="comment"># 转换为列向量</span></span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    <span class="comment"># 通过调用linalg计算行列式来判定协方差矩阵是否可逆</span></span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(xTx) &lt; <span class="number">1e-8</span>:</span><br><span class="line">        <span class="built_in">print</span>( <span class="string">&quot;singular matrix, can&#x27;t do inverse&quot;</span>)</span><br><span class="line">        <span class="comment"># 引入正则项，即 岭回归</span></span><br><span class="line">        alpha = <span class="number">0.1</span></span><br><span class="line">        <span class="comment"># 添加岭回归正则项（单位矩阵大小为特征数+1）</span></span><br><span class="line">        xTx  += alpha * np.eye(xMat.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算参数向量</span></span><br><span class="line">    <span class="comment"># 计算参数并转为一维数组</span></span><br><span class="line">    ws = xTx.I * (xMat.T * yMat)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据X、y和自定义函数MyLinearRegression2()训练模型参数ws，并计算X的预测值y_pred</span></span><br><span class="line">ws = MyLinearRegression2(X, y)</span><br><span class="line">y_pred = X.dot(ws)</span><br><span class="line">y_pred = array(y_pred).reshape(y_pred.shape[<span class="number">0</span>],) <span class="comment"># 将矩阵转换为一行多列的array格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用metrics中的r2_score函数根据y和y_pred计算决定系数score</span></span><br><span class="line">score = metrics.r2_score(y, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sklearn模型训练与预测</span></span><br><span class="line">lr = linear_model.LinearRegression(fit_intercept=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="comment"># 计算X的预测值y_pred_sk与R2分数score_sk</span></span><br><span class="line">y_pred_sk = lr.predict(X)              <span class="comment"># 使用训练好的sklearn模型进行预测</span></span><br><span class="line">score_sk = metrics.r2_score(y, y_pred_sk)  <span class="comment"># 计算决定系数R²</span></span><br><span class="line"><span class="built_in">print</span>(score_sk)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请直接运行处结果，然后提交作业，该运行结果会自动一同提交上去</span></span><br></pre></td></tr></table></figure>
<pre><code>(1338, 9)
</code></pre><p><img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%88%E5%8C%BB%E7%96%97%E4%BF%9D%E9%99%A9%E8%B4%B9%E9%A2%84%E6%B5%8B%EF%BC%89/main_9_1.png" alt="png"></p>
<pre><code>0.7235368166092777
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——第二次上机——波士顿房价预测任务（线性回归、岭回归实现）</title>
    <url>/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%EF%BC%88%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0%EF%BC%89/</url>
    <content><![CDATA[<h1 id="波士顿房价预测任务（线性回归、岭回归实现）"><a href="#波士顿房价预测任务（线性回归、岭回归实现）" class="headerlink" title="波士顿房价预测任务（线性回归、岭回归实现）"></a>波士顿房价预测任务（线性回归、岭回归实现）</h1><p>包括数据准备、模型训练、模型评估与选择、性能度量、参数选择</p>
<h2 id="问题背景与数据集介绍"><a href="#问题背景与数据集介绍" class="headerlink" title="问题背景与数据集介绍"></a>问题背景与数据集介绍</h2><p>波士顿房价预测是一个经典的机器学习任务，类似于程序员世界的“Hello World”。和大家对房价的普遍认知相同，波士顿地区的房价受诸多因素影响。美国某经济杂志登出波士顿房价数据集，该数据集包含506条观测信息，统计了13种可能影响房价的因素（输入变量）和该类型房屋的均价（输出变量），其中每条观测信息包含城镇犯罪率、一氧化氮浓度、住宅平均房间数、到中心区域的加权距离以及自住房平均房价等关于波士顿周边或者城镇房价的描述，期望通过分析影响波士顿房价的因素来构建房价预测模型。相关属性描述如下图所示，其中最后一项就是想要预测的房屋均价。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/be005522b4c441ba89ee7a2ad8277f7c8706457a7a8e4b5f84f92591a32b701d" alt></p>
<p>观测数据的示例如下图所示。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/46fb2e80de2047ff8af2c16819a9e3f5114533f01e3c44c697cfdd66be7bf22f" alt></p>
<p>对于预测问题，可以根据预测输出的类型是连续的实数值，还是离散的标签，区分为回归任务和分类任务。因为房价是一个连续值，所以房价预测显然是一个回归任务。本次实验要求大家调用sklearn 的线性回归、岭回归模型来实现。</p>
<h3 id="实现过程："><a href="#实现过程：" class="headerlink" title="实现过程："></a>实现过程：</h3><ol>
<li>数据准备：导入数据、特征可视化</li>
<li>数据预处理：数据集划分、数据标准化处理</li>
<li>模型训练：线性回归、岭回归</li>
<li>模型评估与选择、参数选择</li>
</ol>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line"><span class="built_in">print</span>(boston.DESCR)</span><br></pre></td></tr></table></figure>
<h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><p>通过观察不同属性与房价之间的关系，分析影响房价的主要因素。</p>
<p>boston.data 存储的是所有样本的属性值，boston.target 存储的是所有样本的房价。下段程序所展示的13幅图中，横坐标是该属性的取值，纵坐标是房价值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入matplotlib库中的pyplot模块，用于绘制图表</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表的大小，figsize指定了图表的宽度和高度，单位是英寸</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历波士顿数据集的13个特征</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>):</span><br><span class="line">    <span class="comment"># 创建一个2行7列的子图，并在当前子图中绘制散点图</span></span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">7</span>, i + <span class="number">1</span>)  <span class="comment"># 2行7列的第i+1个子图</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 绘制散点图：x轴是第i个特征，y轴是目标值（房价中位数），s指定点的大小</span></span><br><span class="line">    plt.scatter(boston.data[:, i], boston.target, s=<span class="number">20</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置当前子图的标题，显示当前特征的名称</span></span><br><span class="line">    plt.title(boston.feature_names[i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存当前图表为PNG格式的图片，文件名为img.png</span></span><br><span class="line">plt.savefig(<span class="string">&#x27;img.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示绘制的所有子图</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p> <img src="/2025/03/06/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA2%E2%80%94%E2%80%94%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%EF%BC%88%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%81%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0%EF%BC%89/img.png" alt="img"></p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="任务1：数据集划分"><a href="#任务1：数据集划分" class="headerlink" title="任务1：数据集划分"></a>任务1：数据集划分</h3><p>调用sklearn.model_selection中的train_test_split()函数，把boston数据集分为训练集和测试集，划分比例是4:1。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 加载波士顿房价数据集</span></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据集划分为训练集和测试集，test_size=0.2 表示测试集占20%，即训练集占80%</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>
<h3 id="结果："><a href="#结果：" class="headerlink" title="结果："></a>结果：</h3><ul>
<li><strong><code>X_train</code></strong>：训练集的特征数据，形状为 <code>(404, 13)</code>，即 80% 的数据（506 * 0.8 = 404 个样本），每个样本有 13 个特征。</li>
<li><strong><code>X_test</code></strong>：测试集的特征数据，形状为 <code>(102, 13)</code>，即 20% 的数据（506 * 0.2 = 102 个样本）。</li>
<li><strong><code>y_train</code></strong>：训练集的目标值，形状为 <code>(404,)</code>，即对应训练集的 404 个房价中位数。</li>
<li><strong><code>y_test</code></strong>：测试集的目标值，形状为 <code>(102,)</code>，即对应测试集的 102 个房价中位数。</li>
</ul>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><ul>
<li><code>train_test_split()</code> 将数据集（包括特征和目标值）按照指定的比例随机划分为训练集和测试集。划分后的数据将用于模型的训练和评估，确保模型评估时使用的数据不会在训练过程中被“看见”。</li>
<li><code>test_size=0.2</code> 表示将 20% 的数据作为测试集，80% 的数据作为训练集。</li>
<li><code>random_state=42</code> 确保每次划分数据集时能得到一致的结果，保证实验的可复现性。</li>
</ul>
<h3 id="任务2：数据标准化处理："><a href="#任务2：数据标准化处理：" class="headerlink" title="任务2：数据标准化处理："></a>任务2：数据标准化处理：</h3><h4 id="1-Z-score标准化"><a href="#1-Z-score标准化" class="headerlink" title="1. Z-score标准化"></a>1. Z-score标准化</h4><p>首先使用StandardScaler()函数初始化对属性值的标准化器，然后调用fit_transform()方法对训练数据进行Z-score标准化，再将这个标准化器调用transform()方法用于测试数据的标准化。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment"># 初始化对属性值的标准化器</span></span><br><span class="line">ss_X = StandardScaler()</span><br><span class="line"><span class="comment"># ss_X调用fit_transform()和transform()方法对训练数据和测试数据进行标准化</span></span><br><span class="line"><span class="comment"># 对训练数据进行标准化，fit_transform() 方法会计算训练数据的均值和标准差，并应用到训练数据</span></span><br><span class="line"><span class="comment"># 训练数据X_train会被标准化为均值0，标准差1</span></span><br><span class="line">X_train = ss_X.fit_transform(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对测试数据进行标准化，使用transform()方法来使用训练数据的均值和标准差来标准化测试数据</span></span><br><span class="line"><span class="comment"># 注意：测试数据不能再用fit_transform()，否则会使用测试数据的统计量，导致数据泄露</span></span><br><span class="line">X_test = ss_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p><strong>Z-score 标准化</strong>的过程是将数据转换为均值为0，标准差为1的分布。<code>StandardScaler()</code> 是 <code>scikit-learn</code> 提供的标准化工具，它通过去掉均值并除以标准差来实现这一标准化。</p>
<h4 id="代码解释："><a href="#代码解释：" class="headerlink" title="代码解释："></a>代码解释：</h4><p><strong>对训练数据进行标准化</strong>：<br>   <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train = ss_X.fit_transform(X_train)</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>fit()</code>：计算训练数据的均值和标准差。</li>
<li><code>transform()</code>：使用训练数据的均值和标准差将数据标准化。</li>
<li><code>fit_transform()</code>：这两个操作结合在一起，计算并转换训练数据，使其均值为0，标准差为1。</li>
</ul>
<p><strong>对测试数据进行标准化</strong>：<br>   <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_test = ss_X.transform(X_test)</span><br></pre></td></tr></table></figure></p>
<ul>
<li>对测试数据应用 <code>transform()</code> 方法时，不会重新计算均值和标准差，而是使用在训练数据上计算得到的均值和标准差对测试数据进行转换。</li>
<li>这确保了测试数据的标准化是基于训练数据的统计信息，而不是测试数据本身的统计信息。</li>
</ul>
<h4 id="2-MinMax标准化"><a href="#2-MinMax标准化" class="headerlink" title="2. MinMax标准化"></a>2. MinMax标准化</h4><p>首先使用StandardScaler()函数初始化对属性值的标准化器，然后调用fit_transform()方法对训练数据进行Z-score标准化，再将这个标准化器调用transform()方法用于测试数据的标准化。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="comment"># 初始化对属性值的标准化器</span></span><br><span class="line">mm_X = MinMaxScaler()</span><br><span class="line"><span class="comment"># mm_X调用fit_transform()和transform()方法对训练数据和测试数据进行MinMax标准化</span></span><br><span class="line">X_train1 = mm_X.fit_transform(X_train)</span><br><span class="line">X_test1 = mm_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p>在 <strong>MinMax 标准化</strong>（也称为 <strong>归一化</strong>）中，数据将被缩放到指定的最小值和最大值之间，通常是将数据缩放到 <code>[0, 1]</code> 范围内。这对于那些对特征的绝对范围敏感的算法非常有效。</p>
<p><code>MinMaxScaler</code> 是 <code>scikit-learn</code> 提供的一个标准化工具，它会将每个特征缩放到一个指定的范围内，默认情况下是 <code>[0, 1]</code>。</p>
<h3 id="代码解释：-1"><a href="#代码解释：-1" class="headerlink" title="代码解释："></a>代码解释：</h3><p><strong>对训练数据进行 MinMax 标准化</strong>：<br>   <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_train1 = mm_X.fit_transform(X_train)</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>fit_transform()</code> 方法会计算训练数据的最小值和最大值，并将数据缩放到 <code>[0, 1]</code> 范围内。<ul>
<li><strong><code>fit()</code></strong>：计算训练数据的最小值和最大值。</li>
<li><strong><code>transform()</code></strong>：根据计算出的最小值和最大值，进行数据的转换。</li>
<li><code>fit_transform()</code> 是这两个操作的组合，直接返回标准化后的训练数据。</li>
</ul>
</li>
</ul>
<p><strong>对测试数据进行 MinMax 标准化</strong>：<br>   <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_test1 = mm_X.transform(X_test)</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>transform()</code> 方法会使用训练数据上的最小值和最大值来转换测试数据。</li>
<li><strong>注意</strong>：<code>transform()</code> 仅仅使用训练数据的统计量（即最小值和最大值）来对测试数据进行标准化，避免了数据泄露问题。如果对测试数据使用 <code>fit_transform()</code>，就会导致模型从测试数据中学习统计量，破坏了训练和测试数据的独立性。</li>
</ul>
<p><strong>MinMax 标准化</strong>是一种常用的数据预处理方法，尤其适用于特征的取值范围差异较大时。它将每个特征的最小值映射到 0，最大值映射到 1，其他值则在该区间内按比例进行缩放。这样做的好处是避免了某些特征因数值范围较大而在训练模型时占据主导地位，尤其是对于需要计算距离或内积的模型，如 KNN、SVM 等，使用 MinMax 标准化后的数据会使模型训练更加稳定。</p>
<h2 id="模型训练与评估"><a href="#模型训练与评估" class="headerlink" title="模型训练与评估"></a>模型训练与评估</h2><h3 id="任务3-1：线性回归模型训练"><a href="#任务3-1：线性回归模型训练" class="headerlink" title="任务3.1：线性回归模型训练"></a>任务3.1：线性回归模型训练</h3><p>调用sklearn.linear_model中的LinearRegression()函数，对训练集(X_train,y_train)进行模型训练，并预测测试集X_test的房价lr_y_predict。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="comment"># 初始化线性回归模型</span></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment"># 线性回归模型训练</span></span><br><span class="line">lr.fit(X_train, y_train)  <span class="comment"># 使用训练集数据训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">lr_y_predict = lr.predict(X_test)  <span class="comment"># 使用训练好的模型对测试集数据进行预测</span></span><br></pre></td></tr></table></figure>
<h3 id="代码解释：-2"><a href="#代码解释：-2" class="headerlink" title="代码解释："></a>代码解释：</h3><p><strong>训练模型</strong>：<br>   <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr.fit(X_train, y_train)</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>fit()</code> 方法会使用训练集数据 <code>(X_train, y_train)</code> 来训练线性回归模型。训练过程就是计算线性回归模型的系数（权重）和截距，以使预测值最接近真实目标值。</li>
</ul>
<p><strong>预测房价</strong>：<br>   <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lr_y_predict = lr.predict(X_test)</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>predict()</code> 方法会使用已经训练好的模型来对测试集 <code>X_test</code> 进行预测，返回预测的房价（即预测值 <code>lr_y_predict</code>）。模型根据训练时学到的关系来预测测试集中的每个样本的房价。</li>
</ul>
<h3 id="任务3-2：线性回归模型评估"><a href="#任务3-2：线性回归模型评估" class="headerlink" title="任务3.2：线性回归模型评估"></a>任务3.2：线性回归模型评估</h3><p>回归模型常用的三种评价指标：（1）R方分数（决定系数）、（2）MSE均方误差、以及（3）MAE平均绝对误差。</p>
<p>方法一：调用sklearn.metrics中的相关函数，计算测试结果lr_y_predict与真实结果y_test之间的误差或精度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score,mean_squared_error,mean_absolute_error</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;the value of R-squared of LR is&#x27;</span>,r2_score(y_test,lr_y_predict))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;the MSE of LR is&#x27;</span>,mean_squared_error(y_test,lr_y_predict))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;the MAE of LR is&#x27;</span>,mean_absolute_error(y_test,lr_y_predict))</span><br></pre></td></tr></table></figure>
<pre><code>the value of R-squared of LR is 0.7250808093832966
the MSE of LR is 23.56944609104811
the MAE of LR is 3.302381007591344
</code></pre><p>方法二：自己编写函数，计算上述指标。本实验要求学生至少完成MSE均方误差的计算，并打印输出结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 计算R²（决定系数）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_r2</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># R² = 1 - (SS_res / SS_tot)</span></span><br><span class="line">    ss_res = ((y_true - y_pred) ** <span class="number">2</span>).<span class="built_in">sum</span>()  <span class="comment"># 残差平方和</span></span><br><span class="line">    ss_tot = ((y_true - y_true.mean()) ** <span class="number">2</span>).<span class="built_in">sum</span>()  <span class="comment"># 总平方和</span></span><br><span class="line">    r2_score = <span class="number">1</span> - (ss_res / ss_tot)  <span class="comment"># 决定系数</span></span><br><span class="line">    <span class="keyword">return</span> r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算MSE（均方误差）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_mse</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    mse = mean_squared_error(y_true, y_pred)</span><br><span class="line">    <span class="keyword">return</span> mse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算MAE（平均绝对误差）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_mae</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    mae = mean_absolute_error(y_true, y_pred)</span><br><span class="line">    <span class="keyword">return</span> mae</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">r2 = calculate_r2(y_test, lr_y_predict)  <span class="comment"># R²</span></span><br><span class="line">mse = calculate_mse(y_test, lr_y_predict)  <span class="comment"># MSE</span></span><br><span class="line">mae = calculate_mae(y_test, lr_y_predict)  <span class="comment"># MAE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;R² (决定系数): <span class="subst">&#123;r2&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;MSE (均方误差): <span class="subst">&#123;mse&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;MAE (平均绝对误差): <span class="subst">&#123;mae&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>R² (决定系数): 0.7250808093832966
MSE (均方误差): 23.56944609104811
MAE (平均绝对误差): 3.302381007591344
</code></pre><p>下面是 <strong>R²（决定系数）</strong>、<strong>MSE（均方误差）</strong> 和 <strong>MAE（平均绝对误差）</strong> 的计算公式：</p>
<h3 id="1-R²（决定系数）-计算公式："><a href="#1-R²（决定系数）-计算公式：" class="headerlink" title="1. R²（决定系数） 计算公式："></a>1. <strong>R²（决定系数）</strong> 计算公式：</h3><p>R² 衡量模型对目标变量变化的解释程度。它的取值范围为 0 到 1，越接近 1，表示模型越能解释数据的变异性。</p>
<p>公式:</p>
<script type="math/tex; mode=display">
R^2=1-\frac{\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2}</script><ul>
<li>( $y_i $)：实际值（真实的目标值）。</li>
<li>( $\hat{y}_i$ )：预测值（模型预测的目标值）。</li>
<li>( $\bar{y}$ )：实际值的均值（ $\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i$ ）。</li>
<li>( $n$ )：样本数。</li>
</ul>
<h4 id="解释："><a href="#解释：" class="headerlink" title="解释："></a>解释：</h4><ul>
<li>分子部分是 <strong>残差平方和（RSS）</strong>，衡量预测值与真实值之间的差异。</li>
<li>分母部分是 <strong>总平方和（TSS）</strong>，衡量真实值与均值之间的差异。</li>
<li>R² 越接近 1，表示模型的拟合度越好。</li>
</ul>
<h3 id="2-MSE（均方误差）-计算公式："><a href="#2-MSE（均方误差）-计算公式：" class="headerlink" title="2. MSE（均方误差） 计算公式："></a>2. <strong>MSE（均方误差）</strong> 计算公式：</h3><p>MSE 衡量预测值与真实值之间差异的平方和的平均值，是一种常用的回归模型评估指标。</p>
<p>公式：</p>
<script type="math/tex; mode=display">
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2</script><ul>
<li>( $y_i$ )：实际值。</li>
<li>( $\hat{y}_i$)：预测值。</li>
<li>( $n$ )：样本数。</li>
</ul>
<h4 id="解释：-1"><a href="#解释：-1" class="headerlink" title="解释："></a>解释：</h4><ul>
<li>MSE 是实际值与预测值之间差异的平方和的平均值，越小表示模型的预测误差越小。</li>
</ul>
<h3 id="3-MAE（平均绝对误差）-计算公式："><a href="#3-MAE（平均绝对误差）-计算公式：" class="headerlink" title="3. MAE（平均绝对误差） 计算公式："></a>3. <strong>MAE（平均绝对误差）</strong> 计算公式：</h3><p>MAE 衡量预测值与真实值之间差异的绝对值的平均值，也是一种常用的回归模型评估指标。</p>
<p>公式：</p>
<script type="math/tex; mode=display">
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|</script><ul>
<li>( $y_i$ )：实际值。</li>
<li>( $\hat{y}_i$ )：预测值。</li>
<li>( $n$ )：样本数。</li>
</ul>
<h4 id="解释：-2"><a href="#解释：-2" class="headerlink" title="解释："></a>解释：</h4><ul>
<li>MAE 是实际值与预测值之间差异的绝对值的平均值，越小表示模型的预测性能越好。</li>
</ul>
<h3 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a>总结：</h3><ul>
<li><strong>R²（决定系数）</strong>：度量模型拟合优度，越接近 1 表示模型越好。</li>
<li><strong>MSE（均方误差）</strong>：越小，表示模型的预测误差越小。</li>
<li><strong>MAE（平均绝对误差）</strong>：越小，表示模型在预测时的绝对误差越小。</li>
</ul>
<h3 id="任务3-3：岭回归模型训练"><a href="#任务3-3：岭回归模型训练" class="headerlink" title="任务3.3：岭回归模型训练"></a>任务3.3：岭回归模型训练</h3><p>调用sklearn.linear_model中的Ridge()函数(参数设置为5)，对训练集(X_train,y_train)进行模型训练，并预测测试集X_test的房价rd_y_predict。</p>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">rd = Ridge(alpha=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#岭回归模型训练</span></span><br><span class="line">rd.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># 输出训练后的模型系数（回归系数）</span></span><br><span class="line"><span class="built_in">print</span>(rd.coef_)</span><br><span class="line"><span class="comment">#模型测试</span></span><br><span class="line">rd_y_predict = rd.predict(X_test)</span><br></pre></td></tr></table></figure>
<pre><code>[-0.89921997  1.17687007  0.06847273  0.58380163 -2.09273127  2.39227753
  0.15081088 -3.06269707  2.53630955 -1.8549535  -2.24256957  0.89722135
 -3.79040179]
</code></pre><h3 id="岭回归（Ridge-Regression）"><a href="#岭回归（Ridge-Regression）" class="headerlink" title="岭回归（Ridge Regression）"></a>岭回归（Ridge Regression）</h3><p><strong>岭回归</strong>（Ridge Regression），又称 <strong>L2 正则化回归</strong>，是一种扩展了普通最小二乘回归（OLS）的回归模型。其核心思想是在最小化 <strong>残差平方和</strong>（即普通最小二乘回归的目标函数）的同时，加入一个 <strong>正则化项</strong>，用于惩罚模型的复杂性，避免过拟合。</p>
<h3 id="岭回归的公式"><a href="#岭回归的公式" class="headerlink" title="岭回归的公式"></a>岭回归的公式</h3><p>岭回归的目标函数为：</p>
<script type="math/tex; mode=display">
\text{minimize} \quad \left( \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 + \alpha \sum_{j=1}^{p} \beta_j^2 \right)</script><p>其中：</p>
<ul>
<li>( $y_i$ )：实际观测值。</li>
<li>( $\hat{y}_i$ )：模型预测值。</li>
<li>( $\beta_j$ )：模型的回归系数。</li>
<li>( $\alpha$ )：正则化强度（超参数），控制正则化项的权重。</li>
</ul>
<h3 id="关键点："><a href="#关键点：" class="headerlink" title="关键点："></a>关键点：</h3><ol>
<li><strong>残差平方和</strong>：普通最小二乘回归的目标函数是最小化预测值和真实值之间的差异平方和：$\sum_{i=1}^{n} (y_i - \hat{y}_i)^2$</li>
<li><strong>L2 正则化</strong>：岭回归在最小化残差平方和的同时，加上一个正则化项$\ \alpha \sum_{j=1}^{p} \beta_j^2 $，用来限制回归系数的大小。这个正则化项惩罚过大的系数，使得系数趋向于 0，但不会完全为 0（与 Lasso 回归不同，Lasso 是 L1 正则化，会使部分系数变为 0）。<ul>
<li>$\alpha $：是岭回归的正则化参数，控制惩罚项的强度。较大的 ( \alpha ) 值会增加正则化的惩罚，使模型的系数变得较小，从而减少过拟合。</li>
</ul>
</li>
</ol>
<h3 id="岭回归的作用"><a href="#岭回归的作用" class="headerlink" title="岭回归的作用"></a>岭回归的作用</h3><ul>
<li><strong>防止过拟合</strong>：在普通的最小二乘回归中，若特征非常多，模型可能会在训练数据上表现得非常好，但却在测试数据上表现得较差（过拟合）。通过在回归系数上施加惩罚，岭回归减少了模型的复杂度，从而帮助防止过拟合。</li>
<li><strong>适应多重共线性</strong>：当特征之间存在强烈的相关性时（即多重共线性），普通的最小二乘回归可能无法得出稳定的回归系数。岭回归通过正则化项使得模型更稳定，避免共线性问题带来的不稳定性。</li>
</ul>
<h3 id="岭回归与普通最小二乘回归的区别"><a href="#岭回归与普通最小二乘回归的区别" class="headerlink" title="岭回归与普通最小二乘回归的区别"></a>岭回归与普通最小二乘回归的区别</h3><ul>
<li><strong>普通最小二乘回归</strong>：最小化残差平方和，没有对回归系数施加任何惩罚。因此，模型会根据训练数据的噪声来拟合训练数据，可能导致过拟合。</li>
<li><strong>岭回归</strong>：最小化残差平方和，并加上正则化项，控制回归系数的大小，防止模型复杂度过高，减少过拟合。</li>
</ul>
<h3 id="岭回归的超参数-alpha"><a href="#岭回归的超参数-alpha" class="headerlink" title="岭回归的超参数 ( $\alpha$ )"></a>岭回归的超参数 ( $\alpha$ )</h3><ul>
<li><strong>( $\alpha$ )</strong>：是岭回归中的超参数，控制正则化项的强度。<ul>
<li>当 ( \alpha = 0 ) 时，岭回归退化为普通的最小二乘回归。</li>
<li>当 ( \alpha ) 较大时，模型的回归系数被更多地惩罚，减少了过拟合的风险，但也可能导致欠拟合（即模型对数据的拟合能力不足）。</li>
</ul>
</li>
</ul>
<h3 id="任务3-4：岭回归模型评估"><a href="#任务3-4：岭回归模型评估" class="headerlink" title="任务3.4：岭回归模型评估"></a>任务3.4：岭回归模型评估</h3><p>与线性回归一样，岭回归模型有两种方法计算评价指标，这里调用sklearn.metrics来实现。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score,mean_squared_error,mean_absolute_error</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;the value of R-squared of Ridge is&#x27;</span>,r2_score(y_test,rd_y_predict ))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;the MSE of Ridge is&#x27;</span>,mean_squared_error(y_test,rd_y_predict))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;the MAE of Ridge is&#x27;</span>,mean_absolute_error(y_test,rd_y_predict))</span><br></pre></td></tr></table></figure>
<pre><code>the value of R-squared of Ridge is 0.7279447933421523
the MSE of Ridge is 23.323910246960786
the MAE of Ridge is 3.2535718613670053
</code></pre><h2 id="参数选择"><a href="#参数选择" class="headerlink" title="参数选择"></a>参数选择</h2><h3 id="任务4：运用交叉验证选择模型参数"><a href="#任务4：运用交叉验证选择模型参数" class="headerlink" title="任务4：运用交叉验证选择模型参数"></a>任务4：运用交叉验证选择模型参数</h3><p>岭回归模型参数是正则化参数alpha，前面把它设置为5。为了选择最优参数，对训练集进行10次10折交叉验证。具体地，参数选择在[0,10]范围内，以1为步长，进行选择。</p>
<ol>
<li>总共进行11次实验（不同alpha值），每次实验将训练数据随机分成10份，重复10次；</li>
<li>每一次划分，任意9份做训练，剩余1份测试，共执行10次，测试结果取平均；</li>
<li>再将所有划分的结果再取平均，作为这一次alpha取值的分数；</li>
<li>比较不同alpha取值的交叉验证模型分数，来选择其中表现最好的（分数最高的）模型的alpha值；</li>
<li>用上述选择的alpha值对训练数据重新训练模型，再测试评估。</li>
</ol>
<blockquote>
<p>补全代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cv_score_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>):</span><br><span class="line">    <span class="comment"># alpha 取不同值</span></span><br><span class="line">    rd = Ridge(alpha=i)</span><br><span class="line">    avg_score_cross = []</span><br><span class="line">    <span class="comment"># 进行10次随机划分</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        <span class="comment">#调用KFold()实现10折划分</span></span><br><span class="line">        kf = KFold(n_splits=<span class="number">10</span>, shuffle=<span class="literal">True</span>, random_state=j)</span><br><span class="line">        <span class="comment">#调用cross_val_score()计算训练集本次10折划分的分数</span></span><br><span class="line">        score_cross = cross_val_score(rd, X_train, y_train, cv=kf, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>)</span><br><span class="line">        avg_score_cross.append(np.mean(score_cross))</span><br><span class="line">    cv_score_list.append(np.mean(avg_score_cross))</span><br><span class="line"></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">11</span>), cv_score_list)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># cv_score_list中找到分数最大的模型所对应的alpha取值</span></span><br><span class="line">index = np.argmax(cv_score_list)</span><br><span class="line">rd = Ridge(alpha=index)</span><br><span class="line"><span class="comment">#岭回归模型训练</span></span><br><span class="line">rd.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#模型测试</span></span><br><span class="line">rd_y_predict = rd.predict(X_test)</span><br><span class="line"><span class="comment"># 打印模型评估结果</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, mean_absolute_error</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Best Alpha: <span class="subst">&#123;index&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Squared Error: <span class="subst">&#123;mean_squared_error(y_test, rd_y_predict)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Mean Absolute Error: <span class="subst">&#123;mean_absolute_error(y_test, rd_y_predict)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Best Alpha: 4
Mean Squared Error: 23.35986469628359
Mean Absolute Error: 3.260923268350155
</code></pre><h2 id="二分类问题"><a href="#二分类问题" class="headerlink" title="二分类问题"></a>二分类问题</h2><h3 id="任务5：波士顿房价二分类问题"><a href="#任务5：波士顿房价二分类问题" class="headerlink" title="任务5：波士顿房价二分类问题"></a>任务5：波士顿房价二分类问题</h3><p>为了了解分类问题的建模与评估，本任务将连续值的波士顿房价数值使用阈值进行二值化（0,1，例如：廉价房、品质房），可以将房价预测的回归问题，改为简单的二分类问题。</p>
<p>同样是包括四个步骤：数据准备、数据预处理、模型训练、模型评估与选择。</p>
<p>下面的程序使用方法一调用sklearn.metrics中的相应函数计算预测结果的准确率accuracy、f1 score、auc值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, f1_score, roc_auc_score</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"><span class="comment"># 房价数值二值化</span></span><br><span class="line">threshold = np.mean(boston.target)</span><br><span class="line">labels = (boston.target&gt;threshold).astype(np.int_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集划分</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(boston.data, labels, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment"># 省略数据预处理步骤</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment"># 模型训练：我们使用 LogisticRegression（线性回归常用于回归问题，但 Logistic Regression 更适合于二分类问题）</span></span><br><span class="line">lr = LogisticRegression(max_iter=<span class="number">10000</span>)  <span class="comment"># 设置最大迭代次数为10000以确保收敛</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测：对测试集进行预测</span></span><br><span class="line">lr_y_predict = lr.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The accuracy score of LR is&#x27;</span>, accuracy_score(y_test, lr_y_predict))  <span class="comment"># 准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The f1 score of LR is&#x27;</span>, f1_score(y_test, lr_y_predict))  <span class="comment"># F1 分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The auc of LR is&#x27;</span>, roc_auc_score(y_test, lr_y_predict))  <span class="comment"># AUC（曲线下面积）</span></span><br></pre></td></tr></table></figure>
<pre><code>The accuracy score of LR is 0.9117647058823529
The f1 score of LR is 0.8695652173913043
The auc of LR is 0.89002079002079


f:\project python\.conda\lib\site-packages\sklearn\utils\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.

    The Boston housing prices dataset has an ethical problem. You can refer to
    the documentation of this function for further details.

    The scikit-learn maintainers therefore strongly discourage the use of this
    dataset unless the purpose of the code is to study and educate about
    ethical issues in data science and machine learning.

    In this special case, you can fetch the dataset from the original
    source::

        import pandas as pd
        import numpy as np

        data_url = &quot;http://lib.stat.cmu.edu/datasets/boston&quot;
        raw_df = pd.read_csv(data_url, sep=&quot;\s+&quot;, skiprows=22, header=None)
        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
        target = raw_df.values[1::2, 2]

    Alternative datasets include the California housing dataset (i.e.
    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing
    dataset. You can load the datasets as follows::

        from sklearn.datasets import fetch_california_housing
        housing = fetch_california_housing()

    for the California housing dataset and::

        from sklearn.datasets import fetch_openml
        housing = fetch_openml(name=&quot;house_prices&quot;, as_frame=True)

    for the Ames housing dataset.
  warnings.warn(msg, category=FutureWarning)
</code></pre><p>方法二：自己编写函数，计算上述指标。</p>
<p>本实验要求学生至少完成accuracy与f1 score的计算，并打印输出结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="comment"># 计算准确率（Accuracy）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_accuracy</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    correct = np.<span class="built_in">sum</span>(y_true == y_pred)  <span class="comment"># 计算正确预测的数量</span></span><br><span class="line">    total = <span class="built_in">len</span>(y_true)  <span class="comment"># 总样本数</span></span><br><span class="line">    accuracy = correct / total  <span class="comment"># 准确率</span></span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算F1分数（F1 Score）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculate_f1_score</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    cm = confusion_matrix(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 提取混淆矩阵中的 TP, FP, FN</span></span><br><span class="line">    tp = cm[<span class="number">1</span>, <span class="number">1</span>]  <span class="comment"># True Positives</span></span><br><span class="line">    fp = cm[<span class="number">0</span>, <span class="number">1</span>]  <span class="comment"># False Positives</span></span><br><span class="line">    fn = cm[<span class="number">1</span>, <span class="number">0</span>]  <span class="comment"># False Negatives</span></span><br><span class="line">    precision = tp / (tp + fp) <span class="keyword">if</span> (tp + fp) != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    recall = tp / (tp + fn) <span class="keyword">if</span> (tp + fn) != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="comment"># 计算 F1 分数</span></span><br><span class="line">    f1 = <span class="number">2</span> * (precision * recall) / (precision + recall) <span class="keyword">if</span> (precision + recall) != <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> f1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">accuracy = calculate_accuracy(y_test, lr_y_predict)</span><br><span class="line">f1_score = calculate_f1_score(y_test, lr_y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;F1 Score: <span class="subst">&#123;f1_score&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy: 0.9117647058823529
F1 Score: 0.8695652173913043
</code></pre><h3 id="1-准确率-Accuracy-："><a href="#1-准确率-Accuracy-：" class="headerlink" title="1. 准确率 (Accuracy)："></a>1. <strong>准确率 (Accuracy)</strong>：</h3><p>准确率是正确分类的样本数与总样本数之比。</p>
<p>公式：</p>
<script type="math/tex; mode=display">
\text{Accuracy} = \frac{\text{正确预测的数量}}{\text{总样本数}}</script><h3 id="2-F1-分数-F1-Score-："><a href="#2-F1-分数-F1-Score-：" class="headerlink" title="2. F1 分数 (F1 Score)："></a>2. <strong>F1 分数 (F1 Score)</strong>：</h3><p>F1 分数是准确率 (Precision) 和召回率 (Recall) 的调和平均数。</p>
<p>公式：</p>
<script type="math/tex; mode=display">
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}</script><p>其中：</p>
<script type="math/tex; mode=display">
\text{Precision} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Positive}}</script><script type="math/tex; mode=display">
\text{Recall} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Negative}}</script><h3 id="3-AUC-Area-Under-the-Curve-："><a href="#3-AUC-Area-Under-the-Curve-：" class="headerlink" title="3. AUC (Area Under the Curve)："></a>3. <strong>AUC (Area Under the Curve)</strong>：</h3><p>AUC 是 ROC 曲线下面积，用于衡量分类模型的性能，范围在 0 到 1 之间，越接近 1，模型表现越好。AUC 是一个广泛使用的评估二分类问题模型的性能的指标。</p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机4——决策树</title>
    <url>/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h1 id="上机实验：决策树"><a href="#上机实验：决策树" class="headerlink" title="上机实验：决策树"></a>上机实验：决策树</h1><h2 id="任务1：分支节点的选择方法"><a href="#任务1：分支节点的选择方法" class="headerlink" title="任务1：分支节点的选择方法"></a>任务1：分支节点的选择方法</h2><p>现有一个数据集 weekend.txt，目标是根据一个人的特征来预测其周末是否出行。</p>
<p>所有特征均为二元特征，取值为 0 或 1，其中“status”（目标特征也是类别）表示用户的周末是否出行，1 表示出行，0 表示不出行，“marriageStatus”表示申请人是否已婚、“hasChild”表示申请人是否有小孩、“hasAppointment”表示申请人是否有约、“weather”表示天气是否晴朗。</p>
<p>已知信息熵和信息增益的公式为：</p>
<script type="math/tex; mode=display">\text{Entropy}(D)=-\sum_{k=1}^{C}p_k \cdot log_2(p_k)</script><script type="math/tex; mode=display">\text{InfoGain}(D, a)=\text{Entropy}(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|} \cdot\text{Entropy}(D^v)</script><p>请完成以下三个内容：</p>
<ul>
<li><p>请自定义函数 cal_entropy(data, feature_name)计算数据集data关于feature_name的信息熵。输入参数 data 为 DataFrame，feature_name 为目标特征(或类别)的名称；</p>
</li>
<li><p>请调用 cal_entropy() 函数计算决策树分支之前的信息熵，保存为 data_entropy；</p>
</li>
<li><p>请自定义函数 cal_infoGain(data, base_entropy) 计算 weekend.txt 中各个特征的信息增益，保存为列表 infogains，并选择信息增益最大的分支节点 best_feature。</p>
</li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入必要库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据（假设文件为tab分隔，包含特征和目标变量&#x27;status&#x27;）</span></span><br><span class="line">weekend_data = pd.read_table(<span class="string">&#x27;weekend.txt&#x27;</span>, sep=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义熵计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数（如：status特征中&quot;出门&quot;和&quot;不出门&quot;的数量）</span></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（注意：熵公式为负数求和）</span></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 计算初始信息熵（假设目标特征列为&#x27;status&#x27;）</span></span><br><span class="line">data_entropy = cal_entropy(weekend_data, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义信息增益计算函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 获取所有特征名称</span></span><br><span class="line">    feature_list.remove(<span class="string">&#x27;status&#x27;</span>)  <span class="comment"># 移除目标特征（避免计算自身）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布（如：天气特征的&quot;晴朗/下雨/阴天&quot;）</span></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历特征的每个取值</span></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line">            <span class="comment"># 获取特征取当前值的子集</span></span><br><span class="line">            subset = data[data[feature] == value]</span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算子集的熵并累加加权熵</span></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, <span class="string">&#x27;status&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算信息增益（信息增益 = 基础熵 - 条件熵）</span></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到信息增益最大的特征</span></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大增益值</span></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 对应的最优特征名称</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"><span class="comment">## 执行信息增益计算</span></span><br><span class="line">infogains, best_feature = cal_infoGain(weekend_data, data_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 结果输出</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;各特征的信息增益：&#x27;</span>, infogains)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n信息增益最大的特征：&#x27;</span>, best_feature)</span><br></pre></td></tr></table></figure>
<pre><code>各特征的信息增益： [0.0076, 0.0076, 0.0322, 0.0868]
</code></pre><p>​    </p>
<pre><code>信息增益最大的特征： weather
</code></pre><blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc" alt></p>
<h2 id="任务2：常见的决策树算法"><a href="#任务2：常见的决策树算法" class="headerlink" title="任务2：常见的决策树算法"></a>任务2：常见的决策树算法</h2><p>现在有一份有关商品销量的数据集product.csv，数据集的离散型特征信息如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>特征名称</th>
<th>取值说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>天气</td>
<td>1：天气好；0：天气坏</td>
</tr>
<tr>
<td>是否周末</td>
<td>1：是；0：不是</td>
</tr>
<tr>
<td>是否有促销</td>
<td>1：有促销；0：没有促销</td>
</tr>
<tr>
<td>销量</td>
<td>1：销量高；0：销量低</td>
</tr>
</tbody>
</table>
</div>
<p>请完成以下三个内容：</p>
<ul>
<li>请根据提供的商品销量数据集 data，使用 sklearn 中的 DecisionTreeClassifier()函数构建决策树模型，模型选择分支结点的特征以Gini指数为判定准则；</li>
<li>训练模型，并对测试集test_X进行预测，将预测结果存为 pred_y，进行模型评估；</li>
<li>将构建的决策树模型进行可视化。</li>
</ul>
<blockquote>
<p>补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz  <span class="comment"># 补全export_graphviz导入</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;product.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取除目标特征以外的其他特征的数据记录X</span></span><br><span class="line">X = data[[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>]]  <span class="comment"># 使用双括号选择多列</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 对数据集切片，获取目标特征`销量`的数据记录y</span></span><br><span class="line">y = data[<span class="string">&quot;销量&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用train_test_split函数划分训练集train_X, train_y和测试集test_X, test_y</span></span><br><span class="line"><span class="comment">## 测试集所占比例为0.1,random_state为0</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 构建分支节点选择方法为基尼指数的决策树模型tree_model，进行模型训练、测试与性能评估</span></span><br><span class="line">tree_model = DecisionTreeClassifier(criterion=<span class="string">&#x27;gini&#x27;</span>)  <span class="comment"># 设置基尼指数准则</span></span><br><span class="line">tree_model.fit(train_X, train_y)  <span class="comment"># 模型训练</span></span><br><span class="line"></span><br><span class="line">pred_y = tree_model.predict(test_X)  <span class="comment"># 测试集预测</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型分类报告：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y))  <span class="comment"># 输出评估报告</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 决策树可视化（修正特征名称与数据列一致）</span></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line">dot_data = export_graphviz(</span><br><span class="line">    tree_model,</span><br><span class="line">    out_file=<span class="literal">None</span>,</span><br><span class="line">    feature_names=[<span class="string">&quot;天气&quot;</span>, <span class="string">&quot;是否周末&quot;</span>, <span class="string">&quot;是否有促销&quot;</span>],  <span class="comment"># 修正为完整特征名称</span></span><br><span class="line">    class_names=[<span class="string">&quot;销量低&quot;</span>, <span class="string">&quot;销量高&quot;</span>],</span><br><span class="line">    filled=<span class="literal">True</span>,</span><br><span class="line">    rounded=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph</span><br></pre></td></tr></table></figure>
<pre><code>模型分类报告：

              precision    recall  f1-score   support
</code></pre><p>​    </p>
<pre><code>           0       1.00      0.50      0.67         2

           1       0.67      1.00      0.80         2
</code></pre><p>​    </p>
<pre><code>    accuracy                           0.75         4

   macro avg       0.83      0.75      0.73         4

weighted avg       0.83      0.75      0.73         4
</code></pre><p>​    </p>
<p>​<br><img src="/2025/04/03/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA4%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91/main_7_1.svg" alt="svg"><br>​    </p>
<blockquote>
<p>期望输出：</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/f7c9f4d97660416b9ac354a1bcd6c87efcb7a0958cfa4579bf70a83d01ee64f7" alt><br><img src="https://ai-studio-static-online.cdn.bcebos.com/eb46fe19bf43414290f904042a511f25140e1908a2eb4c2e81c52450f1de68bd" alt></p>
<h2 id="任务3：利用任务1的cal-infoGain函数自行实现ID3决策树算法"><a href="#任务3：利用任务1的cal-infoGain函数自行实现ID3决策树算法" class="headerlink" title="任务3：利用任务1的cal_infoGain函数自行实现ID3决策树算法"></a>任务3：利用任务1的cal_infoGain函数自行实现ID3决策树算法</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的熵计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_entropy</span>(<span class="params">data, feature_name</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算给定特征的信息熵</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param feature_name: 需要计算熵的目标特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 保留三位小数的熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    entropy = <span class="number">0</span>  <span class="comment"># 初始化熵值</span></span><br><span class="line"></span><br><span class="line">    num = data.shape[<span class="number">0</span>]  <span class="comment"># 获取数据集总样本数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计目标特征各取值的频数分布</span></span><br><span class="line"></span><br><span class="line">    freq_stats = data[feature_name].value_counts()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个不同取值计算熵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> freq <span class="keyword">in</span> freq_stats:</span><br><span class="line"></span><br><span class="line">        prob = freq / num  <span class="comment"># 计算当前取值的概率</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据信息熵公式累加计算（Σ -p_i log2(p_i)）</span></span><br><span class="line"></span><br><span class="line">        entropy -= prob * np.log2(prob)  <span class="comment"># 等价于 entropy += -prob * log2(prob)</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(entropy, <span class="number">3</span>)  <span class="comment"># 保留三位小数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 任务1的信息增益计算函数（已完整实现）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_infoGain</span>(<span class="params">data, base_entropy</span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    计算所有特征的信息增益并选择最优特征</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param data: 输入的DataFrame数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param base_entropy: 数据集的初始熵值</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: 信息增益列表和最优特征名称</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    infogain_list = []  <span class="comment"># 存储各特征的信息增益</span></span><br><span class="line"></span><br><span class="line">    total_samples = data.shape[<span class="number">0</span>]  <span class="comment"># 总样本数</span></span><br><span class="line"></span><br><span class="line">    feature_list = <span class="built_in">list</span>(data.columns.values)  <span class="comment"># 所有特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自动识别目标特征（假设目标特征不在特征列表中）</span></span><br><span class="line"></span><br><span class="line">    target_feature = [col <span class="keyword">for</span> col <span class="keyword">in</span> feature_list <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> data.columns][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    feature_list = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]  <span class="comment"># 移除目标特征</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个特征计算信息增益</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_list:</span><br><span class="line"></span><br><span class="line">        sub_entropy = <span class="number">0</span>  <span class="comment"># 初始化条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当前特征的取值分布</span></span><br><span class="line"></span><br><span class="line">        value_counts = data[feature].value_counts()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算条件熵</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value, count <span class="keyword">in</span> value_counts.items():</span><br><span class="line"></span><br><span class="line">            subset = data[data[feature] == value]  <span class="comment"># 特征取当前值的子集</span></span><br><span class="line"></span><br><span class="line">            subset_samples = subset.shape[<span class="number">0</span>]  <span class="comment"># 子集样本数</span></span><br><span class="line"></span><br><span class="line">            weight = subset_samples / total_samples  <span class="comment"># 计算权重</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 累加加权熵</span></span><br><span class="line"></span><br><span class="line">            sub_entropy += weight * cal_entropy(subset, target_feature)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算信息增益</span></span><br><span class="line"></span><br><span class="line">        info_gain = base_entropy - sub_entropy</span><br><span class="line"></span><br><span class="line">        infogain_list.append(<span class="built_in">round</span>(info_gain, <span class="number">4</span>))  <span class="comment"># 保留四位小数</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 选择最优特征</span></span><br><span class="line"></span><br><span class="line">    max_gain = <span class="built_in">max</span>(infogain_list)  <span class="comment"># 最大信息增益值</span></span><br><span class="line"></span><br><span class="line">    max_index = infogain_list.index(max_gain)  <span class="comment"># 最大值索引</span></span><br><span class="line"></span><br><span class="line">    best_feature = feature_list[max_index]  <span class="comment"># 最优特征名称</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> infogain_list, best_feature</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## ID3决策树实现</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ID3DecisionTree</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="literal">None</span>  <span class="comment"># 存储决策树结构</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = <span class="literal">None</span>  <span class="comment"># 目标特征名称</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, data, target_feature</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        训练决策树模型</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 包含特征和目标列的DataFrame</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param target_feature: 目标特征名称（如&#x27;销量&#x27;）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.target = target_feature</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取特征列表（排除目标特征）</span></span><br><span class="line"></span><br><span class="line">        features = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> col != target_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建决策树</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.tree = <span class="variable language_">self</span>._build_tree(data, features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_tree</span>(<span class="params">self, data, features</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param data: 当前节点的数据集</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param features: 当前可用的特征列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 字典形式的树节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件1：所有样本属于同一类别</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(data[<span class="variable language_">self</span>.target].unique()) == <span class="number">1</span>:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: data[<span class="variable language_">self</span>.target].values[<span class="number">0</span>],  <span class="comment"># 叶节点类别</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 终止条件2：无剩余特征可用时选择多数类</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> features:</span><br><span class="line"></span><br><span class="line">            class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),  <span class="comment"># 多数类</span></span><br><span class="line"></span><br><span class="line">                <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data)</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算当前数据集的熵</span></span><br><span class="line"></span><br><span class="line">        base_entropy = cal_entropy(data, <span class="variable language_">self</span>.target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取最优特征和信息增益列表</span></span><br><span class="line"></span><br><span class="line">        info_gains, best_feature = cal_infoGain(data, base_entropy)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建当前树节点</span></span><br><span class="line"></span><br><span class="line">        node = &#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;feature&#x27;</span>: best_feature,  <span class="comment"># 分裂特征</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;info_gain&#x27;</span>: info_gains[features.index(best_feature)],  <span class="comment"># 信息增益值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;samples&#x27;</span>: <span class="built_in">len</span>(data),  <span class="comment"># 样本数量</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;children&#x27;</span>: &#123;&#125;  <span class="comment"># 子节点</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建子树（排除当前最优特征）</span></span><br><span class="line"></span><br><span class="line">        remaining_features = [f <span class="keyword">for</span> f <span class="keyword">in</span> features <span class="keyword">if</span> f != best_feature]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历最优特征的所有取值</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> data[best_feature].unique():</span><br><span class="line"></span><br><span class="line">            subset = data[data[best_feature] == value]  <span class="comment"># 获取子集</span></span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 处理空子集（采用父节点多数类）</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> subset.empty:</span><br><span class="line"></span><br><span class="line">                class_counts = data[<span class="variable language_">self</span>.target].value_counts()</span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = &#123;</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;class&#x27;</span>: class_counts.idxmax(),</span><br><span class="line"></span><br><span class="line">                    <span class="string">&#x27;samples&#x27;</span>: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 递归构建子树</span></span><br><span class="line"></span><br><span class="line">                node[<span class="string">&#x27;children&#x27;</span>][value] = <span class="variable language_">self</span>._build_tree(subset, remaining_features)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        对新样本进行预测</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param X: 特征数据（DataFrame格式）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 预测结果列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        predictions = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 遍历每个样本</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _, sample <span class="keyword">in</span> X.iterrows():</span><br><span class="line"></span><br><span class="line">            current_node = <span class="variable language_">self</span>.tree</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 遍历树直到叶节点</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                feature = current_node[<span class="string">&#x27;feature&#x27;</span>]  <span class="comment"># 当前分裂特征</span></span><br><span class="line"></span><br><span class="line">                value = sample[feature]  <span class="comment"># 样本在该特征的取值</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 处理未见过的特征值（采用当前节点多数类）</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> value <span class="keyword">not</span> <span class="keyword">in</span> current_node[<span class="string">&#x27;children&#x27;</span>]:</span><br><span class="line"></span><br><span class="line">                    class_counts = <span class="variable language_">self</span>._get_class_counts(current_node)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 选择样本数最多的类别</span></span><br><span class="line"></span><br><span class="line">                    predictions.append(<span class="built_in">max</span>(class_counts, key=class_counts.get))</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">break</span>  <span class="comment"># 跳出循环</span></span><br><span class="line"></span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 移动到子节点</span></span><br><span class="line"></span><br><span class="line">                current_node = current_node[<span class="string">&#x27;children&#x27;</span>][value]</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 记录叶节点类别</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> current_node:</span><br><span class="line"></span><br><span class="line">                predictions.append(current_node[<span class="string">&#x27;class&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_class_counts</span>(<span class="params">self, node</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归统计节点中的类别分布</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: 类别计数字典</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        counts = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果是叶节点直接返回</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> &#123;node[<span class="string">&#x27;class&#x27;</span>]: node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归统计子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].values():</span><br><span class="line"></span><br><span class="line">            child_counts = <span class="variable language_">self</span>._get_class_counts(child)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> cls, cnt <span class="keyword">in</span> child_counts.items():</span><br><span class="line"></span><br><span class="line">                counts[cls] = counts.get(cls, <span class="number">0</span>) + cnt</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> counts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">visualize</span>(<span class="params">self, feature_names, class_names</span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        可视化决策树</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: graphviz对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        dot = graphviz.Digraph()  <span class="comment"># 创建有向图</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建图形</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._build_graph(dot, <span class="variable language_">self</span>.tree, feature_names, class_names)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_graph</span>(<span class="params">self, dot, node, feature_names, class_names, parent=<span class="literal">None</span>, edge_label=<span class="string">&quot;&quot;</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        递归构建graphviz图形</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param dot: graphviz.Digraph对象</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param node: 当前节点</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param feature_names: 特征名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param class_names: 类别名称列表</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param parent: 父节点（用于连接边）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param edge_label: 边标签（特征取值）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 叶节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;class&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;class_names[<span class="built_in">int</span>(node[<span class="string">&#x27;class&#x27;</span>])]&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),  <span class="comment"># 唯一节点ID</span></span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;box&quot;</span>,  <span class="comment"># 矩形框</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,  <span class="comment"># 填充颜色</span></span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightblue&quot;</span>  <span class="comment"># 浅蓝色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 内部节点样式</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            label = <span class="string">f&quot;<span class="subst">&#123;node[<span class="string">&#x27;feature&#x27;</span>]&#125;</span>\\nIG=<span class="subst">&#123;node[<span class="string">&#x27;info_gain&#x27;</span>]:<span class="number">.3</span>f&#125;</span>\\n<span class="subst">&#123;node[<span class="string">&#x27;samples&#x27;</span>]&#125;</span> samples&quot;</span></span><br><span class="line"></span><br><span class="line">            dot.node(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label,</span><br><span class="line"></span><br><span class="line">                shape=<span class="string">&quot;ellipse&quot;</span>,  <span class="comment"># 椭圆</span></span><br><span class="line"></span><br><span class="line">                style=<span class="string">&quot;filled&quot;</span>,</span><br><span class="line"></span><br><span class="line">                fillcolor=<span class="string">&quot;lightgreen&quot;</span>  <span class="comment"># 浅绿色</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建父节点到当前节点的边</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> parent:</span><br><span class="line"></span><br><span class="line">            dot.edge(</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(parent)),</span><br><span class="line"></span><br><span class="line">                <span class="built_in">str</span>(<span class="built_in">id</span>(node)),</span><br><span class="line"></span><br><span class="line">                label=edge_label  <span class="comment"># 显示特征取值</span></span><br><span class="line"></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归处理子节点</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;children&#x27;</span> <span class="keyword">in</span> node:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> value, child <span class="keyword">in</span> node[<span class="string">&#x27;children&#x27;</span>].items():</span><br><span class="line"></span><br><span class="line">                <span class="variable language_">self</span>._build_graph(</span><br><span class="line"></span><br><span class="line">                    dot,</span><br><span class="line"></span><br><span class="line">                    child,</span><br><span class="line"></span><br><span class="line">                    feature_names,</span><br><span class="line"></span><br><span class="line">                    class_names,</span><br><span class="line"></span><br><span class="line">                    node,  <span class="comment"># 当前节点作为父节点</span></span><br><span class="line"></span><br><span class="line">                    <span class="built_in">str</span>(value)  <span class="comment"># 边标签为特征取值</span></span><br><span class="line"></span><br><span class="line">                )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机实验10--支持向量机</title>
    <url>/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C10--%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<h1 id="上机实验10—支持向量机"><a href="#上机实验10—支持向量机" class="headerlink" title="上机实验10—支持向量机"></a>上机实验10—支持向量机</h1><h2 id="任务1：sklearn中的SVC与惩罚系数C"><a href="#任务1：sklearn中的SVC与惩罚系数C" class="headerlink" title="任务1：sklearn中的SVC与惩罚系数C"></a>任务1：sklearn中的SVC与惩罚系数C</h2><ul>
<li>提供一份糖尿病患者数据集diabetes.csv，该数据集有768个数据样本，9个特征(最后一列为目标特征数据)，并且已经存入变量data。特征的具体信息如下：</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>特征名称</th>
<th>特征含义</th>
<th>取值举例</th>
</tr>
</thead>
<tbody>
<tr>
<td>feature1</td>
<td>怀孕次数</td>
<td>6</td>
</tr>
<tr>
<td>feature2</td>
<td>2小时口服葡萄糖耐受实验中的血浆葡萄浓度</td>
<td>148</td>
</tr>
<tr>
<td>feature3</td>
<td>舒张压 (mm Hg)</td>
<td>72</td>
</tr>
<tr>
<td>feature4</td>
<td>三头肌皮褶厚度(mm)</td>
<td>35</td>
</tr>
<tr>
<td>feature5</td>
<td>2小时血清胰岛素浓度 (mu U/ml)</td>
<td>0</td>
</tr>
<tr>
<td>feature6</td>
<td>体重指数(weight in kg/(height in m)^2)</td>
<td>33.6</td>
</tr>
<tr>
<td>feature7</td>
<td>糖尿病谱系功能(Diabetes pedigree function)</td>
<td>0.627</td>
</tr>
<tr>
<td>feature8</td>
<td>年龄</td>
<td>50</td>
</tr>
<tr>
<td>class</td>
<td>是否患有糖尿病</td>
<td>1：阳性；0：阴性</td>
</tr>
</tbody>
</table>
</div>
<p>主要任务如下：</p>
<ul>
<li>请先将数据使用sklearn中的StandardScaler进行标准化；</li>
<li>然后使用sklearn中的svm.SVC支持向量分类器，构建支持向量机模型（所有参数使用默认参数），对测试集进行预测，将预测结果存为pred_y，并对模型进行评价；</li>
<li>最后新建一个svm.SVC实例clf_new，并设置惩罚系数C=0.3，并利用该支持向量分类器对测试集进行预测，将预测结果存为pred_y_new，并比较两个模型的预测效果。</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;diabetes.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># 将目标特征与其他特征分离</span></span><br><span class="line">X = data.drop(<span class="string">&#x27;class&#x27;</span>, axis=<span class="number">1</span>)  </span><br><span class="line">y = data[<span class="string">&#x27;class&#x27;</span>]  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集train_X, train_y和测试集train_X, train_y</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = <span class="number">.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集标准化，返回结果为scaled_train_X</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaled_train_X = scaler.fit_transform(train_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建支持向量机模型</span></span><br><span class="line">clf = SVC()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">clf.fit(scaled_train_X, train_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集标准化</span></span><br><span class="line">scaled_test_X = scaler.transform(test_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型返回预测值</span></span><br><span class="line">pred_y = clf.predict(scaled_test_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印支持向量的个数，返回结果为列表，[-1标签的支持向量，+1标签的支持向量]</span></span><br><span class="line"><span class="built_in">print</span>(clf.n_support_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用classification_report函数进行模型评价</span></span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建惩罚系数C为0.3的模型，并与之前的模型做比较</span></span><br><span class="line">clf_new = SVC(C=<span class="number">0.3</span>)</span><br><span class="line">clf_new.fit(scaled_train_X, train_y)</span><br><span class="line">pred_y_new = clf_new.predict(scaled_test_X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(clf_new.n_support_)</span><br><span class="line"><span class="built_in">print</span>(classification_report(test_y, pred_y_new))</span><br><span class="line"></span><br><span class="line"><span class="comment">#调整惩罚系数C寻优</span></span><br></pre></td></tr></table></figure>
<pre><code>[187 180]

              precision    recall  f1-score   support
</code></pre><p>​    </p>
<pre><code>           0       0.82      0.90      0.86       107

           1       0.70      0.55      0.62        47
</code></pre><p>​    </p>
<pre><code>    accuracy                           0.79       154

   macro avg       0.76      0.73      0.74       154

weighted avg       0.78      0.79      0.78       154
</code></pre><p>​    </p>
<pre><code>[197 196]

              precision    recall  f1-score   support
</code></pre><p>​    </p>
<pre><code>           0       0.83      0.92      0.87       107

           1       0.75      0.57      0.65        47
</code></pre><p>​    </p>
<pre><code>    accuracy                           0.81       154

   macro avg       0.79      0.75      0.76       154

weighted avg       0.81      0.81      0.80       154
</code></pre><p>​    </p>
<blockquote>
<p>预期结果</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/0768604ae0644fcdb3edd584090f6af7fae81344e0b14da789ec1324ee81bcf0" alt></p>
<h2 id="任务2：SVC选定RBF核函数，并寻优核带宽参数gamma"><a href="#任务2：SVC选定RBF核函数，并寻优核带宽参数gamma" class="headerlink" title="任务2：SVC选定RBF核函数，并寻优核带宽参数gamma"></a>任务2：SVC选定RBF核函数，并寻优核带宽参数gamma</h2><blockquote>
<p>在支持向量分类器中，核函数对其性能有直接的影响。已知径向基函数 RBF 及核矩阵元素为：</p>
<script type="math/tex; mode=display">K(\boldsymbol{x}_i, \boldsymbol{x}_j)=\exp(-\gamma\|\boldsymbol{x}_i-\boldsymbol{x}_j\|^2)</script><p>且对于核矩阵K，有$K_{ij}=K(\boldsymbol{x}_i, \boldsymbol{x}_j).$</p>
</blockquote>
<p>主要任务如下：</p>
<ul>
<li>自定义函数实现径向基函数 rbf_kernel，要求输入参数为两个矩阵 X、Y，以及 gamma；</li>
<li>利用rbf_kernel核函数，计算标准化后的训练集scaled_train_X的核矩阵，并存为 rbf_matrix；</li>
<li>利用rbf_kernel核函数，训练支持向量分类器 clf，并预测标准化后的测试数据 scaled_test_X 的标签，最后评价模型效果。<blockquote>
<p>提示：先计算各自的 Gram 矩阵，然后再使用 np.diag 提取对角线元素，使用 np.tile 将列表扩展成一个矩阵。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rbf_kernel</span>(<span class="params">X, Y, gamma=<span class="number">0.5</span></span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取X和Y的大小</span></span><br><span class="line">    num1 = X.shape[<span class="number">0</span>]</span><br><span class="line">    num2 = Y.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算X和X^T的矩阵乘积</span></span><br><span class="line">    gram_1 = X.dot(X.T)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取gram_1对角线位置的元素，组成大小(num1, 1)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component1</span></span><br><span class="line">    component1 = np.tile(np.diag(gram_1).reshape(-<span class="number">1</span>, <span class="number">1</span>), (<span class="number">1</span>, num2))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算Y和Y^T的乘积</span></span><br><span class="line">    gram_2 = Y.dot(Y.T)</span><br><span class="line">     </span><br><span class="line">    <span class="comment"># 获取gram_2对角线位置的元素，组成(1, num2)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component2</span></span><br><span class="line">    component2 = np.tile(np.diag(gram_2).reshape(<span class="number">1</span>, -<span class="number">1</span>), (num1, <span class="number">1</span>))</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># 计算2X和Y^T的内积 </span></span><br><span class="line">    component3 = <span class="number">2</span> * X.dot(Y.T)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 返回结果</span></span><br><span class="line">    result = np.exp(gamma*(component3 - component1 - component2))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算糖尿病患者训练数据集的核矩阵</span></span><br><span class="line">rbf_matrix = rbf_kernel(scaled_train_X, scaled_train_X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练一个支持向量分类器</span></span><br><span class="line">clf = SVC(kernel=rbf_kernel)</span><br><span class="line">clf.fit(scaled_train_X, train_y)</span><br><span class="line">pred_y = clf.predict(scaled_test_X)</span><br><span class="line"><span class="built_in">print</span> (clf.n_support_)</span><br><span class="line"><span class="built_in">print</span> (classification_report(test_y, pred_y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整gamma值寻找最优</span></span><br></pre></td></tr></table></figure>
<pre><code>[250 208]

              precision    recall  f1-score   support

           0       0.84      0.89      0.86       107

           1       0.71      0.62      0.66        47

    accuracy                           0.81       154

   macro avg       0.77      0.75      0.76       154

weighted avg       0.80      0.81      0.80       154
</code></pre><blockquote>
<p>预期结果</p>
</blockquote>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/09cbd0f9a36e4802941289e87082169b6640e370714642d38606e76575bc5632" alt></p>
<h2 id="任务3：自定义函数实现SVM（选做）"><a href="#任务3：自定义函数实现SVM（选做）" class="headerlink" title="任务3：自定义函数实现SVM（选做）"></a>任务3：自定义函数实现SVM（选做）</h2><p>主要任务如下：</p>
<ul>
<li>读取sklearn中的iris数据集，提取特征与标记，并进行数据划分为训练与测试集；</li>
<li>自定义函数实现SVM；</li>
<li>调用SVM函数进行支持向量机训练，并对测试集进行测试。</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_data</span>():</span><br><span class="line">    iris = load_iris()</span><br><span class="line">    df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">    df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line">    df.columns = [<span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">    data = np.array(df.iloc[:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">        <span class="keyword">if</span> data[i,-<span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">            data[i,-<span class="number">1</span>] = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># print(data)</span></span><br><span class="line">    <span class="keyword">return</span> data[:,:<span class="number">2</span>], data[:,-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据，拆分数据，训练测试集划分</span></span><br><span class="line">X, y = create_data()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.25</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SVM</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_iter=<span class="number">100</span>, kernel=<span class="string">&#x27;linear&#x27;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.max_iter = max_iter</span><br><span class="line">        <span class="variable language_">self</span>._kernel = kernel</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_args</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.m, <span class="variable language_">self</span>.n = features.shape</span><br><span class="line">        <span class="variable language_">self</span>.X = features</span><br><span class="line">        <span class="variable language_">self</span>.Y = labels</span><br><span class="line">        <span class="variable language_">self</span>.b = <span class="number">0.0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将Ei保存在一个列表里</span></span><br><span class="line">        <span class="variable language_">self</span>.alpha = np.ones(<span class="variable language_">self</span>.m)</span><br><span class="line">        <span class="variable language_">self</span>.E = [<span class="variable language_">self</span>._E(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m)]</span><br><span class="line">        <span class="comment"># 松弛变量</span></span><br><span class="line">        <span class="variable language_">self</span>.C = <span class="number">1.0</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_KKT</span>(<span class="params">self, i</span>):</span><br><span class="line">        y_g = <span class="variable language_">self</span>._g(i)*<span class="variable language_">self</span>.Y[i]</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.alpha[i] == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> y_g &gt;= <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.alpha[i] &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">            <span class="keyword">return</span> y_g == <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> y_g &lt;= <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># g(x)预测值，输入xi（X[i]）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_g</span>(<span class="params">self, i</span>):</span><br><span class="line">        r = <span class="variable language_">self</span>.b</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m):</span><br><span class="line">            r += <span class="variable language_">self</span>.alpha[j] * <span class="variable language_">self</span>.Y[j] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[j], <span class="variable language_">self</span>.X[i])</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 核函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kernel</span>(<span class="params">self, x1, x2</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._kernel == <span class="string">&#x27;linear&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> np.dot(x1, x2)</span><br><span class="line">        <span class="keyword">elif</span> <span class="variable language_">self</span>._kernel == <span class="string">&#x27;poly&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="built_in">sum</span>([x1[k]*x2[k] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.n)]) + <span class="number">1</span>)**<span class="number">2</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># E（x）为g(x)对输入x的预测值和y的差</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_E</span>(<span class="params">self, i</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._g(i) - <span class="variable language_">self</span>.Y[i]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_alpha</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 外层循环首先遍历所有满足0&lt;a&lt;C的样本点，检验是否满足KKT</span></span><br><span class="line">        index_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m) <span class="keyword">if</span> <span class="number">0</span> &lt; <span class="variable language_">self</span>.alpha[i] &lt; <span class="variable language_">self</span>.C]</span><br><span class="line">        <span class="comment"># 否则遍历整个训练集</span></span><br><span class="line">        non_satisfy_list = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m) <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> index_list]</span><br><span class="line">        index_list.extend(non_satisfy_list)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> index_list:</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>._KKT(i):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            E1 = <span class="variable language_">self</span>.E[i]</span><br><span class="line">            <span class="comment"># 如果E2是+，选择最小的；如果E2是负的，选择最大的</span></span><br><span class="line">            <span class="keyword">if</span> E1 &gt;= <span class="number">0</span>:</span><br><span class="line">                j = <span class="built_in">min</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.m), key=<span class="keyword">lambda</span> x: <span class="variable language_">self</span>.E[x])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                j = <span class="built_in">max</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.m), key=<span class="keyword">lambda</span> x: <span class="variable language_">self</span>.E[x])</span><br><span class="line">            <span class="keyword">return</span> i, j</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_compare</span>(<span class="params">self, _alpha, L, H</span>):</span><br><span class="line">        <span class="keyword">if</span> _alpha &gt; H:</span><br><span class="line">            <span class="keyword">return</span> H</span><br><span class="line">        <span class="keyword">elif</span> _alpha &lt; L:</span><br><span class="line">            <span class="keyword">return</span> L</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> _alpha      </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.init_args(features, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.max_iter):</span><br><span class="line">            <span class="comment"># train</span></span><br><span class="line">            i1, i2 =<span class="variable language_">self</span>._init_alpha()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 边界</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.Y[i1] == <span class="variable language_">self</span>.Y[i2]:</span><br><span class="line">                L = <span class="built_in">max</span>(<span class="number">0</span>, <span class="variable language_">self</span>.alpha[i1]+<span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.C)</span><br><span class="line">                H = <span class="built_in">min</span>(<span class="variable language_">self</span>.C, <span class="variable language_">self</span>.alpha[i1]+<span class="variable language_">self</span>.alpha[i2])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                L = <span class="built_in">max</span>(<span class="number">0</span>, <span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.alpha[i1])</span><br><span class="line">                H = <span class="built_in">min</span>(<span class="variable language_">self</span>.C, <span class="variable language_">self</span>.C+<span class="variable language_">self</span>.alpha[i2]-<span class="variable language_">self</span>.alpha[i1])</span><br><span class="line">                </span><br><span class="line">            E1 = <span class="variable language_">self</span>.E[i1]</span><br><span class="line">            E2 = <span class="variable language_">self</span>.E[i2]</span><br><span class="line">            <span class="comment"># eta=K11+K22-2K12</span></span><br><span class="line">            eta = <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i1]) + \</span><br><span class="line">                  <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i2]) - \</span><br><span class="line">                  <span class="number">2</span> * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i2])</span><br><span class="line">            <span class="keyword">if</span> eta &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># print(&#x27;eta &lt;= 0&#x27;)</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                </span><br><span class="line">            alpha2_new_unc = <span class="variable language_">self</span>.alpha[i2] + <span class="variable language_">self</span>.Y[i2] * (E2 - E1) / eta</span><br><span class="line">            alpha2_new = <span class="variable language_">self</span>._compare(alpha2_new_unc, L, H)</span><br><span class="line">            </span><br><span class="line">            alpha1_new = <span class="variable language_">self</span>.alpha[i1] + <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.Y[i2] * (<span class="variable language_">self</span>.alpha[i2] - alpha2_new)</span><br><span class="line">            </span><br><span class="line">            b1_new = -E1 - <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i1]) * (alpha1_new-<span class="variable language_">self</span>.alpha[i1]) - <span class="variable language_">self</span>.Y[i2] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i1]) * (alpha2_new-<span class="variable language_">self</span>.alpha[i2])+ <span class="variable language_">self</span>.b </span><br><span class="line">            b2_new = -E2 - <span class="variable language_">self</span>.Y[i1] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i1], <span class="variable language_">self</span>.X[i2]) * (alpha1_new-<span class="variable language_">self</span>.alpha[i1]) - <span class="variable language_">self</span>.Y[i2] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i2], <span class="variable language_">self</span>.X[i2]) * (alpha2_new-<span class="variable language_">self</span>.alpha[i2])+ <span class="variable language_">self</span>.b </span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt; alpha1_new &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">                b_new = b1_new</span><br><span class="line">            <span class="keyword">elif</span> <span class="number">0</span> &lt; alpha2_new &lt; <span class="variable language_">self</span>.C:</span><br><span class="line">                b_new = b2_new</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 选择中点</span></span><br><span class="line">                b_new = (b1_new + b2_new) / <span class="number">2</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 更新参数</span></span><br><span class="line">            <span class="variable language_">self</span>.alpha[i1] = alpha1_new</span><br><span class="line">            <span class="variable language_">self</span>.alpha[i2] = alpha2_new</span><br><span class="line">            <span class="variable language_">self</span>.b = b_new</span><br><span class="line">            </span><br><span class="line">            <span class="variable language_">self</span>.E[i1] = <span class="variable language_">self</span>._E(i1)</span><br><span class="line">            <span class="variable language_">self</span>.E[i2] = <span class="variable language_">self</span>._E(i2)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;train done!&#x27;</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, data</span>):</span><br><span class="line">        r = <span class="variable language_">self</span>.b</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.m):</span><br><span class="line">            r += <span class="variable language_">self</span>.alpha[i] * <span class="variable language_">self</span>.Y[i] * <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X[i], data)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> r &gt; <span class="number">0</span> <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self, X_test, y_test</span>):</span><br><span class="line">        right_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_test)):</span><br><span class="line">            result = <span class="variable language_">self</span>.predict(X_test[i])</span><br><span class="line">            <span class="keyword">if</span> result == y_test[i]:</span><br><span class="line">                right_count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> right_count / <span class="built_in">len</span>(X_test)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_weight</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># linear model</span></span><br><span class="line">        yx = <span class="variable language_">self</span>.Y.reshape(-<span class="number">1</span>, <span class="number">1</span>)*<span class="variable language_">self</span>.X</span><br><span class="line">        <span class="variable language_">self</span>.w = np.dot(<span class="variable language_">self</span>.alpha, yx)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.w</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 调用SVM进行模型训练与测试评估</span></span><br><span class="line">svm = SVM(max_iter=<span class="number">100</span>)</span><br><span class="line">svm.fit(X_train, y_train)</span><br><span class="line">svm.score(X_test, y_test)</span><br></pre></td></tr></table></figure>
<pre><code>0.92
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机实验11--核化分类器判定西瓜好坏</title>
    <url>/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/</url>
    <content><![CDATA[<h1 id="上机实验11：核化分类器判定西瓜好坏"><a href="#上机实验11：核化分类器判定西瓜好坏" class="headerlink" title="上机实验11：核化分类器判定西瓜好坏"></a>上机实验11：核化分类器判定西瓜好坏</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&quot;work/西瓜数据集3.0α.txt&quot;</span>)</span><br><span class="line">data</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">yes = data[data[<span class="string">&#x27;Good melon&#x27;</span>].isin([<span class="string">&#x27;是&#x27;</span>])]</span><br><span class="line">no = data[data[<span class="string">&#x27;Good melon&#x27;</span>].isin([<span class="string">&#x27;否&#x27;</span>])]</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax.scatter(yes[<span class="string">&#x27;Density&#x27;</span>], yes[<span class="string">&#x27;Sugar content&#x27;</span>], marker=<span class="string">&#x27;o&#x27;</span>, c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Yes&#x27;</span>)</span><br><span class="line">ax.scatter(no[<span class="string">&#x27;Density&#x27;</span>], no[<span class="string">&#x27;Sugar content&#x27;</span>], marker=<span class="string">&#x27;x&#x27;</span>, c=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;No&#x27;</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Sugar content&#x27;</span>)</span><br><span class="line">plt.show() <span class="comment"># 可以发现线性不可分</span></span><br></pre></td></tr></table></figure>
<p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_3_0.png" alt="output_3_0"></p>
<h2 id="任务1：SVM分类器判定西瓜好坏"><a href="#任务1：SVM分类器判定西瓜好坏" class="headerlink" title="任务1：SVM分类器判定西瓜好坏"></a>任务1：SVM分类器判定西瓜好坏</h2><p>在SVM分类器中，使用线性核与高斯核进行比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用线性核与高斯核进行比较</span></span><br><span class="line">linear_svc = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>)  <span class="comment"># 线性核</span></span><br><span class="line">rbf_svc = svm.SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>)        <span class="comment"># 高斯核（RBF）</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">temp = &#123;<span class="string">&#x27;是&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;否&#x27;</span>: -<span class="number">1</span>&#125;</span><br><span class="line">X = np.array(data.iloc[:, :<span class="number">2</span>])</span><br><span class="line">y = np.array(data.iloc[:, <span class="number">2</span>].replace(temp))[<span class="literal">None</span>].T</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">linear_svc.fit(X, y)</span><br><span class="line">linear_svc.score(X,y)</span><br><span class="line"><span class="comment"># 查看支持向量</span></span><br><span class="line">linear_svc.support_vectors_</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)





array([[0.666, 0.091],
       [0.243, 0.267],
       [0.343, 0.099],
       [0.639, 0.161],
       [0.657, 0.198],
       [0.36 , 0.37 ],
       [0.593, 0.042],
       [0.719, 0.103],
       [0.697, 0.46 ],
       [0.774, 0.376],
       [0.634, 0.264],
       [0.608, 0.318],
       [0.556, 0.215],
       [0.403, 0.237],
       [0.481, 0.149],
       [0.437, 0.211]])
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rbf_svc.fit(X, y)</span><br><span class="line">rbf_svc.score(X,y)</span><br><span class="line"><span class="comment"># 查看支持向量</span></span><br><span class="line">rbf_svc.support_vectors_</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

array([[0.666, 0.091],
       [0.243, 0.267],
       [0.245, 0.057],
       [0.343, 0.099],
       [0.639, 0.161],
       [0.657, 0.198],
       [0.36 , 0.37 ],
       [0.593, 0.042],
       [0.719, 0.103],
       [0.697, 0.46 ],
       [0.774, 0.376],
       [0.634, 0.264],
       [0.608, 0.318],
       [0.556, 0.215],
       [0.403, 0.237],
       [0.481, 0.149],
       [0.437, 0.211]])
</code></pre><h2 id="任务2：Kernel-Logistic-Regression-判定西瓜好坏"><a href="#任务2：Kernel-Logistic-Regression-判定西瓜好坏" class="headerlink" title="任务2：Kernel Logistic Regression 判定西瓜好坏"></a>任务2：Kernel Logistic Regression 判定西瓜好坏</h2><p>将原始的Logistic Regression 进行核化，使用不同的核函数进行比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.colors <span class="keyword">as</span> colors</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>:</span><br><span class="line">    kern_param = <span class="number">0</span></span><br><span class="line">    X = np.array([])</span><br><span class="line">    a = np.array([])</span><br><span class="line">    kernel = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel=<span class="string">&#x27;poly&#x27;</span>, kern_param=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> kernel == <span class="string">&#x27;poly&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__linear__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> kernel == <span class="string">&#x27;gaussian&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__gaussian__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">0.1</span></span><br><span class="line">        <span class="keyword">elif</span> kernel == <span class="string">&#x27;laplace&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.kernel = <span class="variable language_">self</span>.__laplace__</span><br><span class="line">            <span class="keyword">if</span> kern_param:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = kern_param</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.kern_param = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y, max_rate=<span class="number">100</span>, min_rate=<span class="number">0.001</span>, gd_step=<span class="number">10</span>, epsilon=<span class="number">0.0001</span></span>):</span><br><span class="line">        m = <span class="built_in">len</span>(X)</span><br><span class="line">        <span class="variable language_">self</span>.X = np.vstack([X.T, np.ones(m)]).T</span><br><span class="line">        <span class="comment"># Construct kernel matrix</span></span><br><span class="line">        K =<span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X, <span class="variable language_">self</span>.X, <span class="variable language_">self</span>.kern_param)  <span class="comment"># 填空1：计算核矩阵</span></span><br><span class="line">        <span class="comment"># Gradient descent</span></span><br><span class="line">        <span class="variable language_">self</span>.a = np.zeros([m])</span><br><span class="line">        prev_cost = <span class="number">0</span></span><br><span class="line">        next_cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">        <span class="keyword">while</span> np.fabs(prev_cost-next_cost) &gt; epsilon:</span><br><span class="line">            neg_grad = -<span class="variable language_">self</span>.__gradient__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">            best_rate = rate = max_rate</span><br><span class="line">            min_cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a)</span><br><span class="line">            <span class="keyword">while</span> rate &gt;= min_rate:</span><br><span class="line">                cost = <span class="variable language_">self</span>.__cost__(K, y, <span class="variable language_">self</span>.a+neg_grad*rate)</span><br><span class="line">                <span class="keyword">if</span> cost &lt; min_cost:</span><br><span class="line">                    min_cost = cost</span><br><span class="line">                    best_rate = rate</span><br><span class="line">                rate /= gd_step</span><br><span class="line">            <span class="variable language_">self</span>.a += neg_grad * best_rate</span><br><span class="line">            prev_cost = next_cost</span><br><span class="line">            next_cost = min_cost</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 1. 添加偏置项（与训练数据处理一致）</span></span><br><span class="line">        X = np.vstack([X.T, np.ones(<span class="built_in">len</span>(X))]).T  <span class="comment"># 形状变为 (n_samples, n_features + 1)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 计算核矩阵（训练数据与测试数据之间的核函数值）</span></span><br><span class="line">        K = <span class="variable language_">self</span>.kernel(<span class="variable language_">self</span>.X, X, <span class="variable language_">self</span>.kern_param)  <span class="comment"># 形状：(训练样本数, 测试样本数)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 计算预测得分（关键修正：移除 self.Y 的乘法）</span></span><br><span class="line">        pred = np.dot(<span class="variable language_">self</span>.a, K) </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. Sigmoid转换为概率并二值化</span></span><br><span class="line">        prob = <span class="variable language_">self</span>.__sigmoid__(pred)</span><br><span class="line">        <span class="keyword">return</span> (prob &gt;= <span class="number">0.5</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Kernels</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__linear__</span>(<span class="params">a, b, parameter</span>):</span><br><span class="line">        <span class="keyword">return</span> np.dot(a, np.transpose(b))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__gaussian__</span>(<span class="params">a, b, kern_param</span>):</span><br><span class="line">        mat = np.zeros([<span class="built_in">len</span>(a), <span class="built_in">len</span>(b)])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(b)):</span><br><span class="line">                mat[i][j] = np.exp(-np.<span class="built_in">sum</span>(np.square(np.subtract(a[i], b[j]))) / (<span class="number">2</span> * kern_param * kern_param))</span><br><span class="line">        <span class="keyword">return</span> mat</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__laplace__</span>(<span class="params">a, b, kern_param</span>):</span><br><span class="line">        mat = np.zeros([<span class="built_in">len</span>(a), <span class="built_in">len</span>(b)])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(a)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(b)):</span><br><span class="line">                mat[i][j] = np.exp(-np.linalg.norm(np.subtract(a[i], b[j])) / kern_param)</span><br><span class="line">        <span class="keyword">return</span> mat</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__sigmoid__</span>(<span class="params">X</span>):</span><br><span class="line">        <span class="keyword">return</span> np.exp(X) / (<span class="number">1</span> + np.exp(X))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__cost__</span>(<span class="params">K, y, a</span>):</span><br><span class="line">        <span class="keyword">return</span> -np.dot(y, np.dot(a, K)) + np.<span class="built_in">sum</span>(np.log(<span class="number">1</span> + np.exp(np.dot(a, K))))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__gradient__</span>(<span class="params">cls, K, y, a</span>):</span><br><span class="line">        <span class="keyword">return</span> -np.dot(K, y - cls.__sigmoid__(np.dot(a, K)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read data</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;work/西瓜数据集3.0α.txt&quot;</span>)</span><br><span class="line">X = np.array(data[[<span class="string">&#x27;Density&#x27;</span>, <span class="string">&#x27;Sugar content&#x27;</span>]])</span><br><span class="line">y = np.array(data[<span class="string">&#x27;Good melon&#x27;</span>]) == <span class="string">&#x27;是&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Kernels</span></span><br><span class="line">kernels = [<span class="string">&#x27;poly&#x27;</span>, <span class="string">&#x27;gaussian&#x27;</span>, <span class="string">&#x27;laplace&#x27;</span>]</span><br><span class="line">titles = [<span class="string">&#x27;linear kernel&#x27;</span>, <span class="string">&#x27;gaussian kernel, σ=0.1&#x27;</span>, <span class="string">&#x27;laplace kernel, σ=0.1&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(kernels)):</span><br><span class="line">    <span class="comment"># Training</span></span><br><span class="line">    <span class="comment"># 填空3：实例化并训练模型</span></span><br><span class="line">    model = LogisticRegression(kernel=kernels[i])</span><br><span class="line">    model.fit(X, y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Plot</span></span><br><span class="line">    cmap = colors.LinearSegmentedColormap.from_list(<span class="string">&#x27;watermelon&#x27;</span>, [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>])</span><br><span class="line">    xx, yy = np.meshgrid(np.arange(<span class="number">0.2</span>, <span class="number">0.8</span>, <span class="number">0.01</span>), np.arange(<span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">0.01</span>))</span><br><span class="line">    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">    Z = Z.reshape(xx.shape)</span><br><span class="line">    plt.contourf(xx, yy, Z, cmap=cmap, alpha=<span class="number">0.3</span>, antialiased=<span class="literal">True</span>)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=cmap)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Density&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sugar content&#x27;</span>)</span><br><span class="line">    plt.title(titles[i])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:97: RuntimeWarning: overflow encountered in exp
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_1.png" alt="output_10_1"></p>
<p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_2.png" alt="output_10_2"></p>
<p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C11--%E6%A0%B8%E5%8C%96%E5%88%86%E7%B1%BB%E5%99%A8%E5%88%A4%E5%AE%9A%E8%A5%BF%E7%93%9C%E5%A5%BD%E5%9D%8F/output_10_3.png" alt="output_10_3"></p>
<h3 id="1-线性核（Linear-Kernel）"><a href="#1-线性核（Linear-Kernel）" class="headerlink" title="1. 线性核（Linear Kernel）"></a><strong>1. 线性核（Linear Kernel）</strong></h3><ul>
<li><strong>数学形式</strong>：<br>[<br>K(x_i, x_j) = x_i^T x_j + c \quad (c \text{为可选常数})<br>]</li>
<li><strong>特点</strong>：  <ul>
<li>直接计算特征向量的内积，不进行非线性映射。  </li>
<li>决策边界为线性超平面，计算效率高。  </li>
</ul>
</li>
<li><strong>适用场景</strong>：  <ul>
<li>数据线性可分（如两类可通过一条直线/平面分开）。  </li>
<li>特征维度较高时（避免核方法的计算开销）。  </li>
</ul>
</li>
<li><strong>西瓜数据集表现</strong>：  <ul>
<li>生成直线决策边界，可能误分类非线性分布的样本。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-高斯核（Gaussian-RBF-Kernel）"><a href="#2-高斯核（Gaussian-RBF-Kernel）" class="headerlink" title="2. 高斯核（Gaussian/RBF Kernel）"></a><strong>2. 高斯核（Gaussian/RBF Kernel）</strong></h3><ul>
<li><strong>数学形式</strong>：<br>[<br>K(x_i, x_j) = \exp\left(-\gamma |x_i - x_j|^2\right) \quad (\gamma &gt; 0)<br>]</li>
<li><strong>特点</strong>：  <ul>
<li>基于样本间的欧氏距离（L2距离），隐式映射到无限维空间。  </li>
<li>参数 <code>γ</code> 控制影响范围：<code>γ</code> 越大，局部性越强（对邻近点更敏感）。  </li>
</ul>
</li>
<li><strong>适用场景</strong>：  <ul>
<li>数据非线性可分（如环形分布、复杂流形）。  </li>
<li>特征维度较低或中等时效果最佳。  </li>
</ul>
</li>
<li><strong>西瓜数据集表现</strong>：  <ul>
<li>生成平滑的非线性边界，能捕捉密度与含糖量的复杂交互关系。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-拉普拉斯核（Laplace-Kernel）"><a href="#3-拉普拉斯核（Laplace-Kernel）" class="headerlink" title="3. 拉普拉斯核（Laplace Kernel）"></a><strong>3. 拉普拉斯核（Laplace Kernel）</strong></h3><ul>
<li><strong>数学形式</strong>：<br>[<br>K(x_i, x_j) = \exp\left(-\gamma |x_i - x_j|_1\right) \quad (\gamma &gt; 0)<br>]</li>
<li><strong>特点</strong>：  <ul>
<li>基于曼哈顿距离（L1距离），对异常值鲁棒性更强。  </li>
<li>隐式映射到无限维空间，但形状更尖锐（适合非光滑边界）。  </li>
</ul>
</li>
<li><strong>适用场景</strong>：  <ul>
<li>数据分布不规则或存在离群点。  </li>
<li>特征具有稀疏性（如文本分类）。  </li>
</ul>
</li>
<li><strong>西瓜数据集表现</strong>：  <ul>
<li>生成尖锐的非线性边界，可能更好地处理边缘样本。</li>
</ul>
</li>
</ul>
<p>以下是欧氏距离（Euclidean Distance）与曼哈顿距离（Manhattan Distance）的详细对比：</p>
<hr>
<h3 id="1-数学定义"><a href="#1-数学定义" class="headerlink" title="1. 数学定义"></a><strong>1. 数学定义</strong></h3><div class="table-container">
<table>
<thead>
<tr>
<th>距离类型</th>
<th>公式</th>
<th>几何意义</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>欧氏距离</strong></td>
<td>( \</td>
<td>x - y\</td>
<td><em>2 = \sqrt{\sum</em>{i=1}^n (x_i - y_i)^2} )</td>
<td>两点之间的<strong>直线距离</strong></td>
</tr>
<tr>
<td><strong>曼哈顿距离</strong></td>
<td>( \</td>
<td>x - y\</td>
<td><em>1 = \sum</em>{i=1}^n</td>
<td>x_i - y_i</td>
<td>)</td>
<td>两点在<strong>网格路径</strong>上的行走距离</td>
</tr>
</tbody>
</table>
</div>
<h3 id="5-选择建议"><a href="#5-选择建议" class="headerlink" title="5. 选择建议"></a><strong>5. 选择建议</strong></h3><ul>
<li><strong>优先欧氏距离</strong>：<br>数据分布连续、特征维度较低、需要捕捉局部相似性时（如图像分类）。</li>
<li><strong>优先曼哈顿距离</strong>：<br>数据稀疏（如文本）、存在噪声或异常值、特征维度较高时（如推荐系统）。</li>
</ul>
<hr>
<h3 id="示例对比"><a href="#示例对比" class="headerlink" title="示例对比"></a><strong>示例对比</strong></h3><p>假设两点 ( A(1, 1) ) 和 ( B(4, 5) )：</p>
<ul>
<li><strong>欧氏距离</strong>：<br>[<br>\sqrt{(4-1)^2 + (5-1)^2} = 5<br>]</li>
<li><strong>曼哈顿距离</strong>：<br>[<br>|4-1| + |5-1| = 3 + 4 = 7<br>]</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><ul>
<li><strong>欧氏距离</strong>：强调“直线最短”，适合低维连续数据。  </li>
<li><strong>曼哈顿距离</strong>：强调“网格路径”，适合高维稀疏数据。  </li>
<li><strong>在核函数中的体现</strong>：  <ul>
<li>高斯核通过欧氏距离捕捉平滑边界，拉普拉斯核通过曼哈顿距离增强鲁棒性。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机3——逻辑回归（广告点击率预测）</title>
    <url>/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="广告点击率预测"><a href="#广告点击率预测" class="headerlink" title="广告点击率预测"></a>广告点击率预测</h1><p>广告点击率(CTR)预测是广告行业的典型应用，是评估广告效果的一个非常重要的指标。通过历史数据训练预测模型，对于每天的增量数据进行预测，找出广告的CTR符合标准的样本进行投放。</p>
<h2 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h2><p>数据集来自于kaggle，数据包含了10天的Avazu的广告点击数据，训练集10000个，测试集1000个。每一条广告包含：广告id、时间、广告位置等属性。</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/1682d3186a5d4fedab10c4ad3a7f3656e3db56852e5c4fdbb4fb26005c0ba811" alt></p>
<h2 id="任务1：导入库和数据集与数据预处理"><a href="#任务1：导入库和数据集与数据预处理" class="headerlink" title="任务1：导入库和数据集与数据预处理"></a>任务1：导入库和数据集与数据预处理</h2><ul>
<li>读入训练数据和测试数据，划分data和label</li>
<li>将string类型的特征转化为int型：1）进行 one-hot 编码处理，会得到高维稀疏的特征，增大内存开销；2）使用python内置的hash函数将那些类型为object的特征变量映射为一定范围内的整数(原来的string被映射成了integer)，可以大大降低内存的消耗。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">types_train = &#123;</span><br><span class="line">    <span class="string">&#x27;id&#x27;</span>: np.dtype(<span class="built_in">int</span>),</span><br><span class="line">    <span class="string">&#x27;click&#x27;</span>: np.dtype(<span class="built_in">int</span>),         <span class="comment">#是否点击,1表示被点击,0表示没被点击</span></span><br><span class="line">    <span class="string">&#x27;hour&#x27;</span>: np.dtype(<span class="built_in">int</span>),          <span class="comment">#广告被展现的日期+时间</span></span><br><span class="line">    <span class="string">&#x27;C1&#x27;</span>: np.dtype(<span class="built_in">int</span>),            <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;banner_pos&#x27;</span>: np.dtype(<span class="built_in">int</span>),    <span class="comment">#广告位置</span></span><br><span class="line">    <span class="string">&#x27;site_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),       <span class="comment">#站点Id</span></span><br><span class="line">    <span class="string">&#x27;site_domain&#x27;</span>: np.dtype(<span class="built_in">str</span>),   <span class="comment">#站点域名</span></span><br><span class="line">    <span class="string">&#x27;site_category&#x27;</span>: np.dtype(<span class="built_in">str</span>), <span class="comment">#站点分类</span></span><br><span class="line">    <span class="string">&#x27;app_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),        <span class="comment"># appId</span></span><br><span class="line">    <span class="string">&#x27;app_domain&#x27;</span>: np.dtype(<span class="built_in">str</span>),    <span class="comment"># app域名</span></span><br><span class="line">    <span class="string">&#x27;app_category&#x27;</span>: np.dtype(<span class="built_in">str</span>),  <span class="comment"># app分类</span></span><br><span class="line">    <span class="string">&#x27;device_id&#x27;</span>: np.dtype(<span class="built_in">str</span>),     <span class="comment">#设备Id</span></span><br><span class="line">    <span class="string">&#x27;device_ip&#x27;</span>: np.dtype(<span class="built_in">str</span>),     <span class="comment">#设备Ip</span></span><br><span class="line">    <span class="string">&#x27;device_model&#x27;</span>: np.dtype(<span class="built_in">str</span>),  <span class="comment">#设备型号</span></span><br><span class="line">    <span class="string">&#x27;device_type&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#设备型号</span></span><br><span class="line">    <span class="string">&#x27;device_conn_type&#x27;</span>: np.dtype(<span class="built_in">int</span>),</span><br><span class="line">    <span class="string">&#x27;C14&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C15&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C16&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C17&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C18&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C19&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C20&#x27;</span>: np.dtype(<span class="built_in">int</span>),   <span class="comment">#匿名分类变量</span></span><br><span class="line">    <span class="string">&#x27;C21&#x27;</span>:np.dtype(<span class="built_in">int</span>)     <span class="comment">#匿名分类变量</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加列名</span></span><br><span class="line">header_row = [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;click&#x27;</span>, <span class="string">&#x27;hour&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;banner_pos&#x27;</span>, <span class="string">&#x27;site_id&#x27;</span>, <span class="string">&#x27;site_domain&#x27;</span>, <span class="string">&#x27;site_category&#x27;</span>, \</span><br><span class="line">              <span class="string">&#x27;app_id&#x27;</span>, <span class="string">&#x27;app_domain&#x27;</span>, <span class="string">&#x27;app_category&#x27;</span>, <span class="string">&#x27;device_id&#x27;</span>, <span class="string">&#x27;device_ip&#x27;</span>, <span class="string">&#x27;device_model&#x27;</span>,\</span><br><span class="line">              <span class="string">&#x27;device_type&#x27;</span>, <span class="string">&#x27;device_conn_type&#x27;</span>, <span class="string">&#x27;C14&#x27;</span>, <span class="string">&#x27;C15&#x27;</span>, <span class="string">&#x27;C16&#x27;</span>, <span class="string">&#x27;C17&#x27;</span>, <span class="string">&#x27;C18&#x27;</span>, <span class="string">&#x27;C19&#x27;</span>,\</span><br><span class="line">              <span class="string">&#x27;C20&#x27;</span>, <span class="string">&#x27;C21&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读入训练数据和测试数据</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train_data.csv&#x27;</span>, names=header_row, dtype=types_train)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;test_data.csv&#x27;</span>, names=header_row, dtype=types_train)</span><br><span class="line"><span class="comment"># 去除第0行（表示列的编号，不是样本）</span></span><br><span class="line">train = train.drop(labels=train.index.values[<span class="number">0</span>])</span><br><span class="line">test = test.drop(labels=test.index.values[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(test.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分data和label</span></span><br><span class="line">train_data = train.drop(<span class="string">&#x27;click&#x27;</span>, axis=<span class="number">1</span>) <span class="comment">#去除click 这一列</span></span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br><span class="line">train_label = train[<span class="string">&#x27;click&#x27;</span>] <span class="comment">#提取click 这一列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line"><span class="comment"># 使用pd.get_dummies对非数值型特征进行 one-hot 编码处理，得到高维稀疏的特征</span></span><br><span class="line">train_data1 = pd.get_dummies(train_data)</span><br><span class="line"><span class="built_in">print</span>(train_data1.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编写convert_obj_to_int()函数将string类型的特征转换为int型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_obj_to_int</span>(<span class="params">self</span>):</span><br><span class="line">    object_list_columns = <span class="variable language_">self</span>.columns</span><br><span class="line">    object_list_dtypes = <span class="variable language_">self</span>.dtypes</span><br><span class="line">    new_col_suffix = <span class="string">&#x27;_int&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(object_list_columns)):</span><br><span class="line">        <span class="keyword">if</span> object_list_dtypes[index] == <span class="built_in">object</span>:</span><br><span class="line">            <span class="comment"># 使用hash和map将string特征变量映射为一定范围内的整数</span></span><br><span class="line">            <span class="variable language_">self</span>[object_list_columns[index] + new_col_suffix] = <span class="variable language_">self</span>[object_list_columns[index]].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">hash</span>(x) % (<span class="number">1</span> &lt;&lt; <span class="number">32</span>))</span><br><span class="line">            <span class="variable language_">self</span>.drop([object_list_columns[index]], inplace=<span class="literal">True</span>, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用convert_obj_to_int()函数，将string类型转换为int型    </span></span><br><span class="line">train_data = convert_obj_to_int(train_data)</span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br></pre></td></tr></table></figure>
<pre><code>(1000, 24)
(10000, 23)
(10000, 10531)
(10000, 23)


C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
</code></pre><h2 id="任务2：特征分析"><a href="#任务2：特征分析" class="headerlink" title="任务2：特征分析"></a>任务2：特征分析</h2><p>以广告在网页中的位置(banner_pos)为例，查看banner_pos和最终类标(click)之间的关系。</p>
<ul>
<li>查看banner_pos在数据集中的取值分布；</li>
<li>查看不同banner_pos对点击率click的贡献。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看banner_pos在数据集中的取值分布</span></span><br><span class="line"><span class="built_in">print</span>(train.banner_pos.value_counts()/<span class="built_in">len</span>(train))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看不同banner_pos对点击率click的贡献</span></span><br><span class="line">banner_pos_val = train.banner_pos.unique()</span><br><span class="line">banner_pos_val.sort()</span><br><span class="line">ctr_avg_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> banner_pos_val:</span><br><span class="line">    selected_data = train.loc[train.banner_pos == i]</span><br><span class="line">    ctr_avg = selected_data.click.mean()</span><br><span class="line">    ctr_avg_list.append(ctr_avg)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; banner 位置: &#123;&#125;,  点击率: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, ctr_avg))</span><br></pre></td></tr></table></figure>
<pre><code>banner_pos
0    0.8041
1    0.1951
2    0.0007
4    0.0001
Name: count, dtype: float64
 banner 位置: 0,  点击率: 0.16975500559631887
 banner 位置: 1,  点击率: 0.19067145053818554
 banner 位置: 2,  点击率: 0.14285714285714285
 banner 位置: 4,  点击率: 0.0
</code></pre><h2 id="任务3：模型训练与评估"><a href="#任务3：模型训练与评估" class="headerlink" title="任务3：模型训练与评估"></a>任务3：模型训练与评估</h2><ul>
<li>调用sklearn的逻辑回归函数LogisticRegression()，进行模型训练</li>
<li>对测试集test_data进行预测，计算预测结果的各项指标acc, pre, recall, auc</li>
<li>绘制ROC曲线（使用预测的概率值而不是预测的类标）</li>
<li><strong>选做</strong>：自定义逻辑回归函数MyLogisticRegression()，进行模型训练与预测，与上述结果比较。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_data = test.drop(<span class="string">&#x27;click&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">test_data = convert_obj_to_int(test_data)</span><br><span class="line">test_label = test[<span class="string">&#x27;click&#x27;</span>]</span><br><span class="line"><span class="comment"># 调用sklearn的逻辑回归函数LogisticRegression()</span></span><br><span class="line">clf = linear_model.LogisticRegression(max_iter=<span class="number">1000</span>)  <span class="comment"># 增加最大迭代次数防止不收敛</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">clf.fit(train_data, train_label)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Finish Training!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">pred = clf.predict(test_data)</span><br><span class="line">pred_proba = clf.predict_proba(test_data)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算模型的acc, pre, recall, auc，并输出</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line">acc = accuracy_score(test_label, pred)</span><br><span class="line">pre = precision_score(test_label, pred)</span><br><span class="line">recall = recall_score(test_label, pred)</span><br><span class="line">auc = roc_auc_score(test_label, pred_proba)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy: <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>, Precision: <span class="subst">&#123;pre:<span class="number">.4</span>f&#125;</span>, Recall: <span class="subst">&#123;recall:<span class="number">.4</span>f&#125;</span>, AUC: <span class="subst">&#123;auc:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># 绘制roc曲线</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line">fpr, tpr, _ = roc_curve(test_label, pred_proba)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>))</span><br><span class="line">plt.plot(fpr, tpr, label=<span class="string">f&#x27;AUC = <span class="subst">&#123;auc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>], [<span class="number">0</span>,<span class="number">1</span>], <span class="string">&#x27;k--&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;ROC Curve (sklearn)&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 自定义实现逻辑回归函数MyLogisticRegression()</span></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>Finish Training!
Accuracy: 0.8120, Precision: 0.0000, Recall: 0.0000, AUC: 0.4983


C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
C:\Users\29020\AppData\Local\Temp\ipykernel_71456\1472409378.py:66: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  if object_list_dtypes[index] == object:
f:\Anconda\Anconda\envs\general\Lib\site-packages\sklearn\metrics\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f&quot;&#123;metric.capitalize()&#125; is&quot;, len(result))
</code></pre><p><img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/main_5_2.png" alt="png"></p>
<p>​<br>    Custom Model - Accuracy: 0.8240, Precision: 0.6875, Recall: 0.1170, AUC: 0.6580</p>
<p><img src="/2025/03/21/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA3%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88%E5%B9%BF%E5%91%8A%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E6%B5%8B%EF%BC%89/main_5_4.png" alt="png"></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习——上机实验9--神经网络</title>
    <url>/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<h1 id="上机实验9：神经网络"><a href="#上机实验9：神经网络" class="headerlink" title="上机实验9：神经网络"></a>上机实验9：神经网络</h1><h2 id="任务1：神经元模型"><a href="#任务1：神经元模型" class="headerlink" title="任务1：神经元模型"></a>任务1：神经元模型</h2><ul>
<li>给定数据集X和y</li>
<li>请补全以下代码以实现一个简单的神经元模型（即不包含隐层），并计算模型的参数向量w_vec</li>
</ul>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 输入X和y</span></span><br><span class="line">X = np.array([ [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">y = np.array([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]]).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答 #</span></span><br><span class="line"><span class="comment"># Sigmoid激活函数以及其导数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x, derivative = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># 计算sigmoid的输出</span></span><br><span class="line">    sigmoid_value =<span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">    <span class="keyword">if</span> derivative == <span class="literal">False</span>:     </span><br><span class="line">        <span class="keyword">return</span> sigmoid_value</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> derivative == <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 计算sigmoid的导数</span></span><br><span class="line">        <span class="keyword">return</span> sigmoid_value * (<span class="number">1</span> - sigmoid_value)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代次数</span></span><br><span class="line">iter_num  = <span class="number">1000</span></span><br><span class="line">eta = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化权重向量w</span></span><br><span class="line">num, dim = X.shape</span><br><span class="line">w_vec = np.ones((dim, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(iter_num):</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## X通过权重向量w_vec，实现线性加和，结果为z1</span></span><br><span class="line">    z_1 =  X.dot(w_vec)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 经过激活函数Sigmoid，获得输出a_1</span></span><br><span class="line">    a_1 = sigmoid(z_1)</span><br><span class="line">      </span><br><span class="line">    <span class="comment"># 模型输出a_1与真实值的误差</span></span><br><span class="line">    error = a_1 - y</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 权重更新</span></span><br><span class="line">    w_vec_delta = X.T.dot(error * sigmoid(z_1, derivative=<span class="literal">True</span>))</span><br><span class="line">    w_vec = w_vec + eta*w_vec_delta  </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (w_vec)</span><br></pre></td></tr></table></figure>
<pre><code>[[0.94321144]
 [1.83125284]
 [4.71149329]]
</code></pre><h2 id="任务2：-感知机"><a href="#任务2：-感知机" class="headerlink" title="任务2： 感知机"></a>任务2： 感知机</h2><p>1．感知机是根据输入实例的特征向量$x$对其进行二类分类的线性分类模型：</p>
<script type="math/tex; mode=display">
f(x)=\operatorname{sign}(w \cdot x+b)</script><p>感知机模型对应于输入空间（特征空间）中的分离超平面$w \cdot x+b=0$。</p>
<p>2．感知机学习的策略是极小化损失函数：</p>
<script type="math/tex; mode=display">
\min _{w, b} L(w, b)=-\sum_{x_{i} \in M} y_{i}\left(w \cdot x_{i}+b\right)</script><p>损失函数对应于误分类点到分离超平面的总距离。</p>
<p>3．感知机学习算法是基于随机梯度下降法的对损失函数的最优化算法，有原始形式和对偶形式。算法简单且易于实现。原始形式中，首先任意选取一个超平面，然后用梯度下降法不断极小化目标函数。在这个过程中一次随机选取一个误分类点使其梯度下降。</p>
<p>4．当训练数据集线性可分时，感知机学习算法是收敛的。感知机算法在训练数据集上的误分类次数$k$满足不等式：</p>
<script type="math/tex; mode=display">
k \leqslant\left(\frac{R}{\gamma}\right)^{2}</script><p>当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同。</p>
<ol>
<li>随机梯度下降算法 Stochastic Gradient Descent：</li>
</ol>
<p>随机抽取一个误分类点使其梯度下降。</p>
<p>$w = w + \eta y<em>{i}x</em>{i}$</p>
<p>$b = b + \eta y_{i}$</p>
<p>当实例点被误分类，即位于分离超平面的错误侧，则调整$w$, $b$的值，使分离超平面向该无分类点的一侧移动，直至误分类点被正确分类。</p>
<p><strong>使用iris数据集中两个类别的数据和[sepal length，sepal width]作为特征，进行感知机分类。</strong></p>
<ol>
<li>自定义感知机模型，实现iris数据分类；</li>
<li>调用sklearn中Perceptron函数来分类；</li>
<li>验证感知机为什么不能表示异或（选做）。</li>
</ol>
<h3 id="1-自定义感知机模型，实现iris数据分类"><a href="#1-自定义感知机模型，实现iris数据分类" class="headerlink" title="1. 自定义感知机模型，实现iris数据分类"></a>1. 自定义感知机模型，实现iris数据分类</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">df = pd.DataFrame(iris.data, columns=iris.feature_names)</span><br><span class="line">df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line"></span><br><span class="line">df.columns = [</span><br><span class="line">    <span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>, <span class="string">&#x27;label&#x27;</span></span><br><span class="line">]</span><br><span class="line">df.label.value_counts()</span><br><span class="line"></span><br><span class="line">data = np.array(df.iloc[:<span class="number">100</span>, [<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>]])</span><br><span class="line">X, y = data[:,:-<span class="number">1</span>], data[:,-<span class="number">1</span>]</span><br><span class="line">y = np.array([<span class="number">1</span> <span class="keyword">if</span> i == <span class="number">1</span> <span class="keyword">else</span> -<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> y])</span><br><span class="line"></span><br><span class="line">plt.scatter(df[:<span class="number">50</span>][<span class="string">&#x27;sepal length&#x27;</span>], df[:<span class="number">50</span>][<span class="string">&#x27;sepal width&#x27;</span>], label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.scatter(df[<span class="number">50</span>:<span class="number">100</span>][<span class="string">&#x27;sepal length&#x27;</span>], df[<span class="number">50</span>:<span class="number">100</span>][<span class="string">&#x27;sepal width&#x27;</span>], label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f177628f110&gt;



/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_6_2.png" alt="output_6_2"></p>
<blockquote>
<p>待补全代码</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据线性可分，二分类数据</span></span><br><span class="line"><span class="comment"># 此处为一元一次线性方程</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.w = np.ones(<span class="built_in">len</span>(data[<span class="number">0</span>]) - <span class="number">1</span>, dtype=np.float32)</span><br><span class="line">        <span class="variable language_">self</span>.b = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.l_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">self, x, w, b</span>):</span><br><span class="line">        y = np.sign(np.dot(x, w) + b)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机梯度下降法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X_train, y_train</span>):</span><br><span class="line">        is_wrong = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> is_wrong:</span><br><span class="line">            wrong_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train)):</span><br><span class="line">                X = X_train[d]</span><br><span class="line">                y = y_train[d]</span><br><span class="line">                <span class="keyword">if</span> y * (np.dot(X, <span class="variable language_">self</span>.w) + <span class="variable language_">self</span>.b) &lt;= <span class="number">0</span>: <span class="comment">#判断样本被误分类</span></span><br><span class="line">                    <span class="comment"># 更新权重和偏置</span></span><br><span class="line">                    <span class="variable language_">self</span>.w = <span class="variable language_">self</span>.w + <span class="variable language_">self</span>.l_rate * y * X</span><br><span class="line">                    <span class="variable language_">self</span>.b = <span class="variable language_">self</span>.b + <span class="variable language_">self</span>.l_rate * y</span><br><span class="line">                    wrong_count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> wrong_count == <span class="number">0</span>:</span><br><span class="line">                is_wrong = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Perceptron Model!&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">score</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进行模型训练</span></span><br><span class="line">perceptron = Model()</span><br><span class="line">perceptron.fit(X, y)</span><br><span class="line"></span><br><span class="line">x_points = np.linspace(<span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line">y_ = -(perceptron.w[<span class="number">0</span>] * x_points + perceptron.b) / perceptron.w[<span class="number">1</span>]</span><br><span class="line">plt.plot(x_points, y_)</span><br><span class="line"></span><br><span class="line">plt.plot(data[:<span class="number">50</span>, <span class="number">0</span>], data[:<span class="number">50</span>, <span class="number">1</span>], <span class="string">&#x27;bo&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">plt.plot(data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], <span class="string">&#x27;bo&#x27;</span>, color=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f1773a0c950&gt;
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_9_1.png" alt="output_9_1"></p>
<h3 id="2-调用sklearn中Perceptron函数来分类"><a href="#2-调用sklearn中Perceptron函数来分类" class="headerlink" title="2. 调用sklearn中Perceptron函数来分类"></a>2. 调用sklearn中Perceptron函数来分类</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="comment"># 调用sklearn中Perceptron函数进行分类</span></span><br><span class="line">clf = Perceptron(</span><br><span class="line">    max_iter=<span class="number">5000</span>,      <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">    eta0=<span class="number">0.05</span>,           <span class="comment"># 调整学习率（原0.01可能过小）</span></span><br><span class="line">    shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 训练模型</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"><span class="comment"># Weights assigned to the features.</span></span><br><span class="line"><span class="built_in">print</span>(clf.coef_)</span><br><span class="line"><span class="comment"># 截距 Constants in decision function.</span></span><br><span class="line"><span class="built_in">print</span>(clf.intercept_)</span><br></pre></td></tr></table></figure>
<pre><code>[[ 1.16  -1.935]]
[-0.25]
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 画布大小</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文标题</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.title(<span class="string">&#x27;鸢尾花线性数据示例&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(data[:<span class="number">50</span>, <span class="number">0</span>], data[:<span class="number">50</span>, <span class="number">1</span>], c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Iris-setosa&#x27;</span>,)</span><br><span class="line">plt.scatter(data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">0</span>], data[<span class="number">50</span>:<span class="number">100</span>, <span class="number">1</span>], c=<span class="string">&#x27;orange&#x27;</span>, label=<span class="string">&#x27;Iris-versicolor&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画感知机的线</span></span><br><span class="line">x_ponits = np.arange(<span class="number">4</span>, <span class="number">8</span>)</span><br><span class="line">y_ = -(clf.coef_[<span class="number">0</span>][<span class="number">0</span>]*x_ponits + clf.intercept_)/clf.coef_[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">plt.plot(x_ponits, y_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他部分</span></span><br><span class="line">plt.legend()  <span class="comment"># 显示图例</span></span><br><span class="line">plt.grid(<span class="literal">False</span>)  <span class="comment"># 不显示网格</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f1769a4eb50&gt;



/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_12_2.png" alt="output_12_2"></p>
<h3 id="3-验证感知机为什么不能表示异或（选做）"><a href="#3-验证感知机为什么不能表示异或（选做）" class="headerlink" title="3. 验证感知机为什么不能表示异或（选做）"></a>3. 验证感知机为什么不能表示异或（选做）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Perceptron</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">x=np.array([[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">1</span>]])</span><br><span class="line">y=np.array([<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">plt.plot(x[:<span class="number">2</span>,<span class="number">0</span>],x[:<span class="number">2</span>,<span class="number">1</span>],<span class="string">&#x27;bo&#x27;</span>,color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">plt.plot(x[<span class="number">2</span>:<span class="number">4</span>,<span class="number">0</span>],x[<span class="number">2</span>:<span class="number">4</span>,<span class="number">1</span>],<span class="string">&#x27;bo&#x27;</span>,color=<span class="string">&#x27;blue&#x27;</span>,label=<span class="string">&#x27;-1&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请在下方作答</span></span><br><span class="line"><span class="comment"># 初始化感知机模型</span></span><br><span class="line">clf = Perceptron(</span><br><span class="line">    max_iter=<span class="number">1000</span>,      <span class="comment"># 增加最大迭代次数</span></span><br><span class="line">    eta0=<span class="number">0.1</span>,           <span class="comment"># 学习率</span></span><br><span class="line">    random_state=<span class="number">42</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>        <span class="comment"># 每次迭代打乱数据</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出模型参数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征权重 (w):&quot;</span>, clf.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;截距 (b):&quot;</span>, clf.intercept_)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">predictions = clf.predict(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测结果:&quot;</span>, predictions)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;真实标签:&quot;</span>, y)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<pre><code>特征权重 (w): [[0. 0.]]
截距 (b): [0.]
预测结果: [-1 -1 -1 -1]
真实标签: [ 1  1 -1 -1]


/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/font_manager.py:1331: UserWarning: findfont: Font family [&#39;sans-serif&#39;] not found. Falling back to DejaVu Sans
  (prop.get_family(), self.defaultFamily[fontext]))
</code></pre><p><img src="/2025/04/15/college/%E5%A4%A7%E4%BA%8C%E4%B8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%8A%E6%9C%BA/%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C9--%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/output_14_2.png" alt="output_14_2"></p>
]]></content>
      <categories>
        <category>大二下</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大学</tag>
      </tags>
  </entry>
</search>
